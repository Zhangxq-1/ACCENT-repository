def reorder_suite suite classes reverse False class_count len classes suite_class type suite bins [OrderedSet for i in range class_count + 1 ]partition_suite_by_type suite classes bins reverse reverse reordered_suite suite_class for i in range class_count + 1 reordered_suite.addTests bins[i] return reordered_suite
def _expand_probes probes defaults expected_probes {}for probe_name probe_test in six.iteritems probes if probe_name not in expected_probes.keys expected_probes[probe_name] {}probe_defaults probe_test.pop 'defaults' {} for test_name test_details in six.iteritems probe_test test_defaults test_details.pop 'defaults' {} expected_test_details deepcopy defaults expected_test_details.update probe_defaults expected_test_details.update test_defaults expected_test_details.update test_details if test_name not in expected_probes[probe_name].keys expected_probes[probe_name][test_name] expected_test_detailsreturn expected_probes
def test_records test_data ds ChartDataSource.from_data test_data.records_data assert len ds.columns 2 assert len ds.index 4
def attach_total_voters_to_queryset queryset as_field 'total_voters' model queryset.modeltype apps.get_model 'contenttypes' 'ContentType' .objects.get_for_model model sql 'SELECTcoalesce SUM total_voters 0 FROM \nSELECTcoalesce votes_votes.count 0 total_voters\nFROMvotes_votes\nWHEREvotes_votes.content_type_id {type_id}\nANDvotes_votes.object_id {tbl}.id\n ase'sql sql.format type_id type.id tbl model._meta.db_table qs queryset.extra select {as_field sql} return qs
def _add_theming_locales theme_locale_paths settings.COMPREHENSIVE_THEME_LOCALE_PATHSfor locale_path in theme_locale_paths settings.LOCALE_PATHS + path locale_path
def _guess_autoescape template_name if template_name is None or '.' not in template_name return Falseext template_name.rsplit '.' 1 [1]return ext in ['html' 'htm' 'xml']
def path_to_filesystem root *paths paths [sanitize_path path .strip '/' for path in paths]safe_path rootfor path in paths if not path continuefor part in path.split '/' if not is_safe_filesystem_path_component part raise UnsafePathError part safe_path os.path.join safe_path part return safe_path
def getRectangularGrid diameter loopsComplex maximumComplex minimumComplex zigzag demiradius 0.25 * diameter xStart minimumComplex.real - demiradius.real y minimumComplex.imag - demiradius.imag gridPath []rowIndex 0while y < maximumComplex.imag addGridRow diameter gridPath loopsComplex maximumComplex rowIndex xStart y zigzag y + diameter.imagrowIndex + 1return gridPath
def capture_screenshot_for_step step when if world.auto_capture_screenshots scenario_num step.scenario.feature.scenarios.index step.scenario + 1 step_num step.scenario.steps.index step + 1 step_func_name step.defined_at.function.func_nameimage_name '{prefix 03d}__{num 03d}__{name}__{postfix}'.format prefix scenario_num num step_num name step_func_name postfix when world.capture_screenshot image_name
def run_vcs_tool path action info get_vcs_info get_vcs_root path tools info['actions'][action]for tool args in tools if programs.find_program tool programs.run_program tool args cwd path returnelse cmdnames [name for name args in tools]raise ActionToolNotFound info['name'] action cmdnames
def submit_rescore_entrance_exam_for_student request usage_key student None only_if_higher False check_entrance_exam_problems_for_rescoring usage_key task_type 'rescore_problem_if_higher' if only_if_higher else 'rescore_problem' task_class rescore_problem task_input task_key encode_entrance_exam_and_student_input usage_key student task_input.update {'only_if_higher' only_if_higher} return submit_task request task_type task_class usage_key.course_key task_input task_key
@pytest.fixture scope u'session' def celery_config return {}
def quota_destroy_all_by_project context project_id return IMPL.quota_destroy_all_by_project context project_id
def _get_date_time_format dt_string valid_formats ['%I %M %S%p' '%I %M%p' '%H %M %S' '%H %M' '%Y-%m-%d' '%m-%d-%y' '%m-%d-%Y' '%m/%d/%y' '%m/%d/%Y' '%Y/%m/%d']for dt_format in valid_formats try datetime.strptime dt_string dt_format return dt_formatexcept ValueError continuereturn False
def make_path_result r t rpath '/recipes/' + r tpath '/tasks/' + t return rpath + tpath + '/results/'
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def strategy_saturation_largest_first G colors distinct_colors {v set for v in G}for i in range len G if i 0 node max G key G.degree yield node for v in G[node] distinct_colors[v].add 0 else saturation {v len c for v c in distinct_colors.items if v not in colors }node max saturation key lambda v saturation[v] G.degree v yield node color colors[node]for v in G[node] distinct_colors[v].add color
def initgroups uid gid if not pwd returnusername pwd.getpwuid uid [0]if hasattr os u'initgroups' return os.initgroups username gid groups [gr.gr_gid for gr in grp.getgrall if username in gr.gr_mem ]setgroups groups
def _SetWsdlMethod ns wsdlName inputMM _wsdlMethodNSs.add ns curMM _wsdlMethodMap.get ns wsdlName if isinstance inputMM list if curMM is None _wsdlMethodMap[ ns wsdlName ] inputMMreturn inputMMelif isinstance curMM list raise RuntimeError 'Duplicatewsdlmethod%s%s newclass%svsexisting%s ' % ns wsdlName inputMM[0] curMM[0] else return curMMelif curMM is None or isinstance curMM list _wsdlMethodMap[ ns wsdlName ] inputMMreturn inputMMelse return curMM
def escape_byte_string s s _replace_specials s try return s.decode 'ASCII' except UnicodeDecodeError passif IS_PYTHON3 s_new bytearray append extend s_new.append s_new.extend for b in s if b > 128 extend '\\%3o' % b .encode 'ASCII' else append b return s_new.decode 'ISO-8859-1' else l []append l.appendfor c in s o ord c if o > 128 append '\\%3o' % o else append c return join_bytes l .decode 'ISO-8859-1'
def S_white_simple x if x.ndim 1 x x[ None]return np.dot x.T x
def _find_matching_indices tree bin_X left_mask right_mask left_index np.searchsorted tree bin_X & left_mask right_index np.searchsorted tree bin_X | right_mask side 'right' return left_index right_index
def _disconnect_session session session['client'].auth.logout session['key']
def fix_line_ending content return content.replace '\r\n' '\n' .replace '\r' '\n'
def assert_equal_none logical_line res asse_equal_start_with_none_re.match logical_line or asse_equal_end_with_none_re.match logical_line if res yield 0 'G318 assertEqual A None orassertEqual None A sentencesnotallowed'
def _split_query query qq query.split '' keywords []accum Nonefor kw in qq if accum is None if kw.startswith '"' accum kw[1 ]elif kw keywords.append kw else accum + '' + kw if kw.endswith '"' keywords.append accum[0 -1 ] accum Noneif accum is not None keywords.append accum return [kw.strip for kw in keywords if kw.strip ]
def file_url path return QUrl.fromLocalFile path .toString QUrl.FullyEncoded
def get_timeslice slice_seconds now int time.time slice_count now // slice_seconds slice_start int slice_count * slice_seconds slice_end slice_start + slice_seconds return TimeSlice slice_start slice_end
def _safe_split estimator X y indices train_indices None if hasattr estimator 'kernel' and callable estimator.kernel and not isinstance estimator.kernel GPKernel raise ValueError 'Cannotuseacustomkernelfunction.Precomputethekernelmatrixinstead.' if not hasattr X 'shape' if getattr estimator '_pairwise' False raise ValueError 'Precomputedkernelsoraffinitymatriceshavetobepassedasarraysorsparsematrices.' X_subset [X[idx] for idx in indices]elif getattr estimator '_pairwise' False if X.shape[0] ! X.shape[1] raise ValueError 'Xshouldbeasquarekernelmatrix' if train_indices is None X_subset X[np.ix_ indices indices ]else X_subset X[np.ix_ indices train_indices ]else X_subset safe_indexing X indices if y is not None y_subset safe_indexing y indices else y_subset Nonereturn X_subset y_subset
def cxUniform ind1 ind2 indpb size min len ind1 len ind2 for i in xrange size if random.random < indpb ind1[i] ind2[i] ind2[i] ind1[i] return ind1 ind2
def _reverse_ordering ordering_tuple def invert x return x[1 ] if x.startswith u'-' else u'-' + x return tuple [invert item for item in ordering_tuple]
def get_boost obj boost max log10 1 + get_popularity obj 1.0 if obj.status in VALID_STATUSES boost * BOOST_MULTIPLIER_FOR_PUBLIC_CONTENTreturn boost
def guarded_mul left right if not isinstance left numbers.Integral passelif not isinstance right numbers.Integral passelif left in 0 1 or right in 0 1 passelif left.bit_length + right.bit_length > 664386 raise ValueError u'Valueistoolargetobehandledinlimitedtimeandmemory.' return operator.mul left right
def build_or_pattern patterns name None escape False or_pattern []for pattern in patterns if not or_pattern or_pattern.append ' ?' if name or_pattern.append 'P<' + name + '>' else or_pattern.append ' ' else or_pattern.append '|' or_pattern.append ' ? %s ' % re.escape pattern if escape else pattern or_pattern.append ' ' return ''.join or_pattern
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _with_primary max_staleness selection primary selection.primarysds []for s in selection.server_descriptions if s.server_type SERVER_TYPE.RSSecondary staleness s.last_update_time - s.last_write_date - primary.last_update_time - primary.last_write_date + selection.heartbeat_frequency if staleness < max_staleness sds.append s else sds.append s return selection.with_server_descriptions sds
def _get_bootstrap_sample x y num_reps combined hstack [x y] total_obs len combined num_x len x for i in range num_reps indices randint 0 total_obs total_obs sampled combined.take indices sampled_x sampled[ num_x]sampled_y sampled[num_x ] yield sampled_x sampled_y
def get_integration_manager global _integration_managerif not _integration_manager from reviewboard.integrations.models import IntegrationConfig_integration_manager IntegrationManager IntegrationConfig return _integration_manager
def _checkNetaddrWorksWithPrefixlen net prefixlen version if net & _prefixlenToNetmask prefixlen version net return 1else return 0
def list_servers backend socket '/var/run/haproxy.sock' objectify False ha_conn _get_conn socket ha_cmd haproxy.cmds.listServers backend backend return ha_conn.sendCmd ha_cmd objectify objectify
def patch_os patch_module 'os'
def recursive_walk function data if isinstance data list return list recursive_walk function val for val in data if isinstance data dict return dict key recursive_walk function val for key val in data.iteritems return function data
def cxxflags_contains value return var_contains 'CXXFLAGS' value
@builtin u'Swapthecaseoftext' swapcase apply_func_to_match_groups def replace_swapcase match number file_name metadata dictionaries data functions *args **kwargs return apply_func_to_match_groups match swapcase
def _solve_P_Q U V structure None P U + V Q - U + V if isspmatrix U return spsolve Q P elif structure is None return solve Q P elif structure UPPER_TRIANGULAR return solve_triangular Q P else raise ValueError 'unsupportedmatrixstructure ' + str structure
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def recover request uidb64 None token None UserModel get_user_model try uid force_text urlsafe_base64_decode uidb64 user UserModel._default_manager.get pk uid except TypeError ValueError OverflowError UserModel.DoesNotExist user Noneif user and default_token_generator.check_token user token temp_pwd uuid.uuid4 .hexuser.set_password temp_pwd user.save user authenticate username user.username password temp_pwd user.set_unusable_password user.save login request user return redirect 'users.recover_done' return render request 'users/recover_failed.html'
def _is_task_visible context task if context.is_admin return Trueif task['owner'] is None return Trueif context.owner is not None if context.owner task['owner'] return Truereturn False
def correlation X Y condition None **kwargs return covariance X Y condition **kwargs / std X condition **kwargs * std Y condition **kwargs
def backup_get_all_by_volume context volume_id filters None return IMPL.backup_get_all_by_volume context volume_id filters filters
def volume_up hass hass.services.call DOMAIN SERVICE_VOLUME_UP
def _tgrep_conjunction_action _s _l tokens join_char u'&' tokens [x for x in tokens if x ! join_char ]if len tokens 1 return tokens[0]else return lambda ts lambda n m None l None all predicate n m l for predicate in ts tokens
def set_cache_over_settings destination setting key_prefix value ttl existing destination.settings.get setting {} existing.update value set_cache key_prefix + '.' + setting value ttl destination.settings[setting] value
def ShutdownThreads data_source_thread thread_pool logger.info 'Anerroroccurred.Shuttingdown...' data_source_thread.exit_flag Truethread_pool.Shutdown data_source_thread.join timeout 3.0 if data_source_thread.isAlive logger.warn '%shungwhiletryingtoexit' data_source_thread.GetFriendlyName
def get_single name url module required getter u'__version__' mod get_version_module module name url version_getter getattr mod getter if hasattr version_getter u'__call__' current version_getter else current version_getterreturn name url current required
def withClass classname namespace '' classattr '%s class' % namespace if namespace else 'class' return withAttribute **{classattr classname}
def prioSort elements random.shuffle elements prio_elems [ getPriority e e for e in elements]prio_elems.sort sorted_elems [s for _ s in prio_elems]return sorted_elems
def openshift_builder registry xml_parent data osb XML.SubElement xml_parent 'com.openshift.jenkins.plugins.pipeline.OpenShiftBuilder' mapping [ 'api-url' 'apiURL' 'https //openshift.default.svc.cluster.local' 'bld-cfg' 'bldCfg' 'frontend' 'namespace' 'namespace' 'test' 'auth-token' 'authToken' '' 'commit-ID' 'commitID' '' 'verbose' 'verbose' False 'build-name' 'buildName' '' 'show-build-logs' 'showBuildLogs' False ]convert_mapping_to_xml osb data mapping fail_required True
def setup_sidebar_items data if data.allow_sidebar_items frappe.db.sql u'update`tabPortalMenuItem`setenabled 0' frappe.db.sql u'update`tabPortalMenuItem`setenabled 1\n DCTB DCTB DCTB whereroutein {0} '.format u' '.join [u'"{0}"'.format d for d in data.allow_sidebar_items] if data.remove_sidebar_items frappe.db.sql u'update`tabPortalMenuItem`setenabled 1' frappe.db.sql u'update`tabPortalMenuItem`setenabled 0\n DCTB DCTB DCTB whereroutein {0} '.format u' '.join [u'"{0}"'.format d for d in data.remove_sidebar_items]
def gen_password alphabet 'abcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'password ''for _ in range 20 next_index random.randrange len alphabet password + alphabet[next_index]hashed_pwd gen_hash 'salt' password 'sha512' return password hashed_pwd
def get_action_libs_abs_path pack None entry_point None entry_point_abs_path get_entry_point_abs_path pack pack entry_point entry_point if entry_point_abs_path is not None return os.path.join os.path.dirname entry_point_abs_path ACTION_LIBS_DIR else return None
def setBasicLoggerDEBUG setLoggerClass BasicLogger BasicLogger.setLevel DEBUG
def get_sandbox_python_path inherit_from_parent True inherit_parent_virtualenv True sandbox_python_path []parent_python_path os.environ.get 'PYTHONPATH' '' parent_python_path parent_python_path.split ' ' parent_python_path [path for path in parent_python_path if path]if inherit_from_parent sandbox_python_path.extend parent_python_path if inherit_parent_virtualenv and hasattr sys 'real_prefix' site_packages_dir get_python_lib assert sys.prefix in site_packages_dir sandbox_python_path.append site_packages_dir sandbox_python_path ' '.join sandbox_python_path sandbox_python_path ' ' + sandbox_python_path return sandbox_python_path
def slug_is_numerical slug try float slug except ValueError return Falsereturn True
def _getParameter name index args kwargs default None param kwargs.get name if len args > index if param raise TypeError "Parameter'%s'isspecifiedtwice" % name param args[index]return param or default
def device portnumber enum comm.CommPortIdentifier.getPortIdentifiers ports []while enum.hasMoreElements el enum.nextElement if el.getPortType comm.CommPortIdentifier.PORT_SERIAL ports.append el return ports[portnumber].getName
def assert_in obj in_ None out_ None if in_ is not None for name in in_ assert name in obj if out_ is not None for name in out_ assert name not in obj
def dominating_set G start_with None all_nodes set G if start_with is None start_with arbitrary_element all_nodes if start_with not in G raise nx.NetworkXError 'node{}isnotinG'.format start_with dominating_set {start_with}dominated_nodes set G[start_with] remaining_nodes all_nodes - dominated_nodes - dominating_set while remaining_nodes v remaining_nodes.pop undominated_neighbors set G[v] - dominating_set dominating_set.add v dominated_nodes | undominated_neighborsremaining_nodes - undominated_neighborsreturn dominating_set
def remove_small_objects ar min_size 64 connectivity 1 in_place False _check_dtype_supported ar if in_place out arelse out ar.copy if min_size 0 return outif out.dtype bool selem ndi.generate_binary_structure ar.ndim connectivity ccs np.zeros_like ar dtype np.int32 ndi.label ar selem output ccs else ccs outtry component_sizes np.bincount ccs.ravel except ValueError raise ValueError 'Negativevaluelabelsarenotsupported.Tryrelabelingtheinputwith`scipy.ndimage.label`or`skimage.morphology.label`.' if len component_sizes 2 warn 'Onlyonelabelwasprovidedto`remove_small_objects`.Didyoumeantouseabooleanarray?' too_small component_sizes < min_size too_small_mask too_small[ccs]out[too_small_mask] 0return out
def get_redirect_url course_key usage_key course_key chapter section vertical_unused position final_target_id path_to_location modulestore usage_key if chapter is None redirect_url reverse 'courseware' args unicode course_key elif section is None redirect_url reverse 'courseware_chapter' args unicode course_key chapter elif position is None redirect_url reverse 'courseware_section' args unicode course_key chapter section else redirect_url reverse 'courseware_position' args unicode course_key chapter section navigation_index position redirect_url + '?{}'.format urlencode {'activate_block_id' unicode final_target_id } return redirect_url
def disable_term_protect name call None if call ! 'action' raise SaltCloudSystemExit 'Thedisable_term_protectactionmustbecalledwith-aor--action.' return _toggle_term_protect name 'false'
def test_cnn_fit cnn CondensedNearestNeighbour random_state RND_SEED cnn.fit X Y assert_equal cnn.min_c_ 0 assert_equal cnn.maj_c_ 2 assert_equal cnn.stats_c_[0] 2 assert_equal cnn.stats_c_[1] 6 assert_equal cnn.stats_c_[2] 12
def prepend_root_dir opts path_options root_dir os.path.abspath opts['root_dir'] root_opt opts['root_dir'].rstrip os.sep for path_option in path_options if path_option in opts path opts[path_option]if path root_opt or path.startswith root_opt + os.sep path path[len root_opt ]opts[path_option] salt.utils.path_join root_dir path
def set_X_window_properties win_id **properties import xcb xcb.xprotoconn xcb.connect atoms {name conn.core.InternAtom False len name name for name in properties}utf8_string_atom Nonefor name val in properties.iteritems atom atoms[name].reply .atomtype_atom xcb.xproto.Atom.STRINGif isinstance val unicode if utf8_string_atom is None utf8_string_atom conn.core.InternAtom True len 'UTF8_STRING' 'UTF8_STRING' .reply .atomtype_atom utf8_string_atomval val.encode u'utf-8' conn.core.ChangePropertyChecked xcb.xproto.PropMode.Replace win_id atom type_atom 8 len val val conn.flush conn.disconnect
def from_sequence seq partition_size None npartitions None seq list seq if npartitions and not partition_size partition_size int math.ceil len seq / npartitions if npartitions is None and partition_size is None if len seq < 100 partition_size 1else partition_size int len seq / 100 parts list partition_all partition_size seq name 'from_sequence-' + tokenize seq partition_size d dict name i list part for i part in enumerate parts return Bag d name len d
def getHostByName name timeout None effort 10 return getResolver .getHostByName name timeout effort
def _get_fragments_phase frags return [ 3 - x % 3 % 3 for x in _get_fragments_coord frags ]
@register.assignment_tag takes_context False def assignment_explicit_no_context arg return 'assignment_explicit_no_context-Expectedresult %s' % arg
def belongs_to_folder path fileName if not path.endswith os.path.sep path + os.path.sepreturn fileName.startswith path
def resource_view_clear context data_dict model context['model']_check_access 'resource_view_clear' context data_dict view_types data_dict.get 'view_types' model.ResourceView.delete_all view_types model.repo.commit
def validipport port try assert 0 < int port < 65535 except AssertionError ValueError return Falsereturn True
def floyd_warshall_predecessor_and_distance G weight 'weight' from collections import defaultdictdist defaultdict lambda defaultdict lambda float 'inf' for u in G dist[u][u] 0pred defaultdict dict undirected not G.is_directed for u v d in G.edges data True e_weight d.get weight 1.0 dist[u][v] min e_weight dist[u][v] pred[u][v] uif undirected dist[v][u] min e_weight dist[v][u] pred[v][u] vfor w in G for u in G for v in G if dist[u][v] > dist[u][w] + dist[w][v] dist[u][v] dist[u][w] + dist[w][v] pred[u][v] pred[w][v]return dict pred dict dist
def PickleToFile records outfile encoded_records []for record in records encoded record.Encode encoded_records.append encoded pickle.dump encoded_records outfile protocol pickle.HIGHEST_PROTOCOL
def _scal_elemwise_with_nfunc nfunc nin nout def construct symbol symbolname symbol.__name__inplace symbolname.endswith '_inplace' if inplace msg 'inplace'else msg 'no_inplace'n 'Elemwise{%s %s}' % symbolname msg if inplace scalar_op getattr scal symbolname[ - len '_inplace' ] inplace_scalar_op scalar_op.__class__ scal.transfer_type 0 rval elemwise.Elemwise inplace_scalar_op {0 0} name n nfunc_spec nfunc and nfunc nin nout else scalar_op getattr scal symbolname rval elemwise.Elemwise scalar_op name n nfunc_spec nfunc and nfunc nin nout if getattr symbol '__doc__' False rval.__doc__ symbol.__doc__ + '\n' + rval.__doc__ rval.__epydoc_asRoutine symbolrval.__module__ 'tensor'pprint.assign rval printing.FunctionPrinter symbolname return rvalreturn construct
def get_complete_paths config page input_path os.path.join config[u'docs_dir'] page.input_path output_path os.path.join config[u'site_dir'] page.output_path return input_path output_path
def enqueue *args **kwargs import frappe.utils.background_jobsfrappe.utils.background_jobs.enqueue *args **kwargs
def user return dict form auth
def get_qualifier module qualifier Noneif module.params['version'] > 0 qualifier str module.params['version'] elif module.params['alias'] qualifier str module.params['alias'] return qualifier
def _show_legend ax leg ax.legend loc 1 shadow True fancybox True labelspacing 0.2 borderpad 0.15 ltext leg.get_texts llines leg.get_lines frame leg.get_frame from matplotlib.artist import setpsetp ltext fontsize 'small' setp llines linewidth 1
def patch_time from gevent.hub import sleepimport timepatch_item time 'sleep' sleep
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def trim_var var value makeconf _get_makeconf old_value get_var var if old_value is not None __salt__['file.sed'] makeconf value '' limit var new_value get_var var return {var {'old' old_value 'new' new_value}}
def display_ctl_chars index cc title 'SpecialCharacter'col1_width len title col2_width max map len index.values FMT '{idx <{col1_width}}{name <{col2_width}}{value}'print 'SpeciallineCharacters'.center 40 .rstrip print FMT.format idx 'Index' name 'Name' value 'Value' col1_width col1_width col2_width col2_width print '{0}{1}{2}'.format '-' * col1_width '-' * col2_width '-' * 10 for index_name name in index.items try index getattr termios index_name value cc[index]if value '\xff' value '_POSIX_VDISABLE'else value repr value except AttributeError value 'undef'print FMT.format idx index_name name name value value col1_width col1_width col2_width col2_width print
def setLastRefresh exList cache_db_con db.DBConnection 'cache.db' cache_db_con.upsert 'scene_exceptions_refresh' {'last_refreshed' int time.mktime datetime.datetime.today .timetuple } {'list' exList}
def diversity first_front first last df hypot first_front[0].fitness.values[0] - first[0] first_front[0].fitness.values[1] - first[1] dl hypot first_front[ -1 ].fitness.values[0] - last[0] first_front[ -1 ].fitness.values[1] - last[1] dt [hypot first.fitness.values[0] - second.fitness.values[0] first.fitness.values[1] - second.fitness.values[1] for first second in zip first_front[ -1 ] first_front[1 ] ]if len first_front 1 return df + dl dm sum dt / len dt di sum abs d_i - dm for d_i in dt delta df + dl + di / df + dl + len dt * dm return delta
def handle_sec_error error exception_class None if error 0 returncf_error_string Security.SecCopyErrorMessageString error null output CFHelpers.cf_string_to_unicode cf_error_string CoreFoundation.CFRelease cf_error_string if output is None or output u'' output u'OSStatus%s' % error if exception_class is None exception_class OSErrorraise exception_class output
def flag_file path flag create False path os.path.join path JOB_ADMIN path os.path.join path flag if create try f open path 'w' f.write 'ok\n' f.close return Trueexcept IOError return Falseelse return os.path.exists path
def infinibox_required_together return [['user' 'password']]
def _generate_group_title group return group.name.replace '_' '' .title
def data_spider path ignore ValueError NotImplementedError followlinks True hidden False extra_kwargs None return {os.path.basename path _spider path ignore ignore followlinks followlinks hidden hidden extra_kwargs extra_kwargs }
def test_ee_bad_ratio ratio -1.0 ee EasyEnsemble ratio ratio assert_raises ValueError ee.fit X Y ratio 100.0ee EasyEnsemble ratio ratio assert_raises ValueError ee.fit X Y ratio 'rnd'ee EasyEnsemble ratio ratio assert_raises ValueError ee.fit X Y ratio [0.5 0.5]ee EasyEnsemble ratio ratio assert_raises ValueError ee.fit X Y
def strict_dependencies target dep_context for declared in _resolve_aliases target if isinstance declared dep_context.compiler_plugin_types for r in declared.closure bfs True **dep_context.target_closure_kwargs yield r else yield declared
def validate_exps_in_collection_are_public collection for exploration_id in collection.exploration_ids if rights_manager.is_exploration_private exploration_id raise utils.ValidationError 'Cannotreferenceaprivateexplorationwithinapubliccollection explorationID %s' % exploration_id
@with_setup prepare_stdout def test_output_snippets_with_groups_within_single_quotes_colorful runner Runner feature_name 'single-quoted-snippet' verbosity 3 no_color False runner.run assert_stdout_lines u"\n\x1b[1;37mFeature single-quotedsnippetproposal\x1b[1;30m#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 1\x1b[0m\n\n\x1b[1;37mScenario Proposematchedgroups\x1b[1;30m#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 2\x1b[0m\n\x1b[0;33mGivenIhave'stuffhere'and'more@#$%\u02c6&bizarsutffh3r3'\x1b[1;30m#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 3\x1b[0m\n\n\x1b[1;37m1feature \x1b[0;31m0passed\x1b[1;37m \x1b[0m\n\x1b[1;37m1scenario \x1b[0;31m0passed\x1b[1;37m \x1b[0m\n\x1b[1;37m1step \x1b[0;33m1undefined\x1b[1;37m \x1b[1;32m0passed\x1b[1;37m \x1b[0m\n\n\x1b[0;33mYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u'GivenIhave\\' [^\\']* \\'and\\' [^\\']* \\'' \ndefgiven_i_have_group1_and_group2 step group1 group2 \nassertFalse 'Thisstepmustbeimplemented'\x1b[0m\n"
def _task_info_get task_id global DATAtry task_info DATA['task_info'][task_id]except KeyError msg _LW 'Couldnotfindtaskinfo%s' % task_id LOG.warn msg raise exception.TaskNotFound task_id task_id return task_info
def extract_views_from_urlpatterns urlpatterns base '' namespace None views []for p in urlpatterns if hasattr p 'url_patterns' try patterns p.url_patternsexcept ImportError continueviews.extend extract_views_from_urlpatterns patterns base + p.regex.pattern namespace or [] + p.namespace and [p.namespace] or [] elif hasattr p 'callback' try views.append p.callback base + p.regex.pattern namespace p.name except ViewDoesNotExist continueelse raise TypeError _ '%sdoesnotappeartobeaurlpatternobject' % p return views
def ts_to_str timestamp date datetime.datetime.fromtimestamp timestamp date_string date.strftime '%d/%m/%Y%H %M%Z' return date_string
def _node_ports graph node portinputs {}portoutputs {}for u _ d in graph.in_edges_iter node data True for src dest in d[u'connect'] portinputs[dest] u src for _ v d in graph.out_edges_iter node data True for src dest in d[u'connect'] if isinstance src tuple srcport src[0]else srcport srcif srcport not in portoutputs portoutputs[srcport] []portoutputs[srcport].append v dest src return portinputs portoutputs
def equatePolarDotAzimuth point returnValue equateCylindricalDotAzimuth point returnValue
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def build_server_url *args **kwargs return urljoin get_server_url **kwargs *args
def _toposort data if len data 0 returnfor k v in data.items v.discard k extra_items_in_deps _reduce set.union data.values - set data.keys data.update {item set for item in extra_items_in_deps} while True ordered sorted set item for item dep in data.items if len dep 0 if not ordered breakfor item in ordered yield item data.pop item None for dep in sorted data.values dep - set ordered if len data ! 0 msg u'Cyclicdependenciesexistamongtheseitems {}'raise CondaValueError msg.format u'->'.join repr x for x in data.keys
def Ynm_c n m theta phi from sympy import conjugatereturn conjugate Ynm n m theta phi
def fd f return f.fileno if hasattr f 'fileno' else f
def sync_engines saltenv 'base' return salt.utils.extmods.sync __opts__ 'engines' saltenv saltenv [0]
def wrap_traceback traceback if email .format 'html' try from pygments import highlightfrom pygments.lexers import PythonTracebackLexerfrom pygments.formatters import HtmlFormatterwith_pygments Trueexcept ImportError with_pygments Falseif with_pygments formatter HtmlFormatter noclasses True wrapped highlight traceback PythonTracebackLexer formatter else wrapped '<pre>%s</pre>' % traceback else wrapped tracebackreturn wrapped
def deserialize_contributors node user_dicts auth validate False contribs []for contrib_dict in user_dicts fullname contrib_dict['fullname']visible contrib_dict['visible']email contrib_dict.get 'email' if validate is True fullname sanitize.strip_html fullname if not fullname raise ValidationValueError 'Fullnamefieldcannotbeempty' if email validate_email email if contrib_dict['id'] contributor User.load contrib_dict['id'] else try contributor User.create_unregistered fullname fullname email email contributor.save except ValidationError contributor get_user email email if not contributor.is_registered and node._primary_key not in contributor.unclaimed_records contributor.add_unclaimed_record node node referrer auth.user given_name fullname email email contributor.save contribs.append {'user' contributor 'visible' visible 'permissions' expand_permissions contrib_dict.get 'permission' } return contribs
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def test_ast_good_raise can_compile u' raise ' can_compile u' raiseException ' can_compile u' raisee '
def is_type_factory _type def inner x if type x ! _type raise ValueError "Valuemusthavetype'%s'" % str _type return inner
def exp_create_database db_name demo lang user_password 'admin' login 'admin' country_code None _logger.info 'Createdatabase`%s`.' db_name _create_empty_database db_name _initialize_db id db_name demo lang user_password login country_code return True
def ipexec_validate fname expected_out expected_err '' options None commands import nose.tools as nt out err ipexec fname options commands if err if expected_err nt.assert_equal '\n'.join err.strip .splitlines '\n'.join expected_err.strip .splitlines else raise ValueError 'Runningfile%rproducederror %r' % fname err nt.assert_equal '\n'.join out.strip .splitlines '\n'.join expected_out.strip .splitlines
def maybe_convert_ix *args ixify Truefor arg in args if not isinstance arg np.ndarray list ABCSeries Index ixify Falseif ixify return np.ix_ *args else return args
def get_language_bidi lang get_language if lang is None return Falseelse base_lang get_language .split '-' [0]return base_lang in settings.LANGUAGES_BIDI
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def wrap_callable wrapper fn if hasattr fn '__name__' return update_wrapper wrapper fn else _f wrapper_f.__name__ fn.__class__.__name__if hasattr fn '__module__' _f.__module__ fn.__module__if hasattr fn.__call__ '__doc__' and fn.__call__.__doc__ _f.__doc__ fn.__call__.__doc__elif fn.__doc__ _f.__doc__ fn.__doc__return _f
@depends HAS_ESX_CLI def get_coredump_network_config host username password protocol None port None esxi_hosts None cmd 'systemcoredumpnetworkget'ret {}if esxi_hosts if not isinstance esxi_hosts list raise CommandExecutionError "'esxi_hosts'mustbealist." for esxi_host in esxi_hosts response salt.utils.vmware.esxcli host username password cmd protocol protocol port port esxi_host esxi_host if response['retcode'] ! 0 ret.update {esxi_host {'Error' response.get 'stdout' }} else ret.update {esxi_host {'CoredumpConfig' _format_coredump_stdout response }} else response salt.utils.vmware.esxcli host username password cmd protocol protocol port port if response['retcode'] ! 0 ret.update {host {'Error' response.get 'stdout' }} else stdout _format_coredump_stdout response ret.update {host {'CoredumpConfig' stdout}} return ret
def live_screenshot registry xml_parent data live XML.SubElement xml_parent 'org.jenkinsci.plugins.livescreenshot.LiveScreenshotBuildWrapper' live.set 'plugin' 'livescreenshot' mapping [ 'full-size' 'fullscreenFilename' 'screenshot.png' 'thumbnail' 'thumbnailFilename' 'screenshot-thumb.png' ]convert_mapping_to_xml live data mapping fail_required True
def markmin_escape text return regex_markmin_escape.sub lambda m '\\' + m.group 0 .replace '\\' '\\\\' text
def pickleStringI stringi return unpickleStringI stringi.getvalue stringi.tell
def get url conn urlopen url resp conn.read conn.close return resp
def random_name size 6 chars string.ascii_uppercase + string.digits return 'test-' + ''.join random.choice chars for x in range size
def search_python_list python_code template_names retval []for tn in template_names retval.extend search_python python_code tn retval list set retval retval.sort return retval
def _ca items s if atomp items return itemsif len s 0 return items[0]lst [0] * s[0] stride len items // s[0] if s[0] else 0 for i in range s[0] start i * stride lst[i] _ca items[start start + stride ] s[1 ] return lst
def has_arithmetic_operator line for operator in pep8.ARITHMETIC_OP if operator in line return Truereturn False
def get_xmodule_urls pipeline_js_settings settings.PIPELINE_JS['module-js']if settings.DEBUG paths [path.replace '.coffee' '.js' for path in pipeline_js_settings['source_filenames']]else paths [pipeline_js_settings['output_filename']]return [staticfiles_storage.url path for path in paths]
@step STEP_PREFIX + 'sendingemaildoesnotwork' def email_broken step mail.EmailMessage.send broken_send
def templates_for_host templates if not isinstance templates list tuple templates [templates]theme_dir host_theme_path host_templates []if theme_dir for template in templates host_templates.append u'%s/templates/%s' % theme_dir template host_templates.append template return host_templatesreturn templates
def _api_translate name output kwargs return report output keyword 'value' data Tx kwargs.get 'value' ''
def make_icindervolumemanager_tests client_factory class Tests ICinderVolumeManagerTestsMixin TestCase def setUp self super Tests self .setUp self.client client_factory test_case self return Tests
@open_file 0 mode 'r' def read_p2g path encoding 'utf-8' lines line.decode encoding for line in path G parse_p2g lines return G
def as_floatX variable if isinstance variable float return numpy.cast[theano.config.floatX] variable if isinstance variable numpy.ndarray return numpy.cast[theano.config.floatX] variable return theano.tensor.cast variable theano.config.floatX
@documented_contextmanagerdef hide *groups return _set_output groups False
def replace_network_acl_entry network_acl_id None rule_number None protocol None rule_action None cidr_block None egress None network_acl_name None icmp_code None icmp_type None port_range_from None port_range_to None region None key None keyid None profile None kwargs locals return _create_network_acl_entry replace True **kwargs
@with_setup prepare_stdout def test_output_with_success_colorless_with_table runner Runner feature_name 'success_table' verbosity 3 no_color True runner.run assert_stdout_lines '\nFeature TableSuccess#tests/functional/output_features/success_table/success_table.feature 1\n\nScenario Addtwonumbers\xe2\x99\xa5#tests/functional/output_features/success_table/success_table.feature 2\nGivenIhave0bucks#tests/functional/output_features/success_table/success_table_steps.py 28\nAndthatIhavetheseitems #tests/functional/output_features/success_table/success_table_steps.py 32\n|name|price|\n|Porsche|200000|\n|Ferrari|400000|\nWhenIsellthe"Ferrari"#tests/functional/output_features/success_table/success_table_steps.py 42\nThenIhave400000bucks#tests/functional/output_features/success_table/success_table_steps.py 28\nAndmygaragecontains #tests/functional/output_features/success_table/success_table_steps.py 47\n|name|price|\n|Porsche|200000|\n\n1feature 1passed \n1scenario 1passed \n5steps 5passed \n'
def _get_value_type kind if kind TEXT return APETextValueelif kind BINARY return APEBinaryValueelif kind EXTERNAL return APEExtValueraise ValueError 'unknownkind%r' % kind
def translated_revision locale 'de' **kwargs parent_rev revision is_approved True parent_rev.save translation document parent parent_rev.document locale locale translation.save new_kwargs {'document' translation 'based_on' parent_rev}new_kwargs.update kwargs return revision **new_kwargs
def migrate_admission_plugin_facts facts if 'master' in facts if 'kube_admission_plugin_config' in facts['master'] if 'admission_plugin_config' not in facts['master'] facts['master']['admission_plugin_config'] dict facts['master']['admission_plugin_config'] merge_facts facts['master']['admission_plugin_config'] facts['master']['kube_admission_plugin_config'] additive_facts_to_overwrite [] protected_facts_to_overwrite [] facts['master'].pop 'kube_admission_plugin_config' None return facts
def test_how_to_use_as_vm_logger slogging.configure ' DEBUG eth.vm INFO' log slogging.get_logger 'eth.vm' def run_vm raise_error False log.trace 'op' pc 1 log.trace 'op' pc 2 if raise_error raise Exceptionrecorder slogging.LogRecorder try run_vm raise_error True except log slogging.get_logger 'eth.vm' for x in recorder.pop_records log.info x.pop 'event' **x
def _to_seconds timestr timestr timestr.upper if 'H' in timestr seconds int timestr.replace 'H' '' * 3600 elif 'D' in timestr seconds int timestr.replace 'D' '' * 86400 elif 'W' in timestr seconds 604800else try seconds int timestr except ValueError seconds 604800if seconds > 604800 seconds 604800return seconds
def dumb_css_parser data importIndex data.find '@import' while importIndex ! -1 data data[0 importIndex] + data[ data.find ';' importIndex + 1 ] importIndex data.find '@import' elements [x.split '{' for x in data.split '}' if '{' in x.strip ]elements dict [ a.strip dumb_property_dict b for a b in elements] return elements
def mutCounter individual if random.random > 0.5 individual.update [random.choice ITEMS_NAME ] else val random.choice ITEMS_NAME individual.subtract [val] if individual[val] < 0 del individual[val]return individual
def groebner seq ring method None if method is None method query 'groebner' _groebner_methods {'buchberger' _buchberger 'f5b' _f5b}try _groebner _groebner_methods[method]except KeyError raise ValueError "'%s'isnotavalidGroebnerbasesalgorithm validare'buchberger'and'f5b' " % method domain orig ring.domain None if not domain.has_Field or not domain.has_assoc_Field try orig ring ring ring.clone domain domain.get_field except DomainError raise DomainError "can'tcomputeaGroebnerbasisover%s" % domain else seq [s.set_ring ring for s in seq]G _groebner seq ring if orig is not None G [g.clear_denoms [1].set_ring orig for g in G]return G
def mnc2cum mnc mnc [1] + list mnc kappa [1]for nn m in enumerate mnc[1 ] n nn + 1 kappa.append m for k in range 1 n kappa[n] - comb n - 1 k - 1 exact 1 * kappa[k] * mnc[ n - k ] return kappa[1 ]
def parseLines chunk items {}for lineno line in chunk header data line.split ' ' 1 header header.lower items[header] lineno data.strip return items
def is_content_authored_by content user try return int content.get 'user_id' user.id except ValueError TypeError return False
@pytest.mark.parametrize 'status expected' [ usertypes.LoadStatus.success url.UrlType.success usertypes.LoadStatus.success_https url.UrlType.success_https usertypes.LoadStatus.error url.UrlType.error usertypes.LoadStatus.warn url.UrlType.warn usertypes.LoadStatus.loading url.UrlType.normal usertypes.LoadStatus.none url.UrlType.normal ] def test_on_load_status_changed url_widget status expected url_widget.set_url QUrl 'www.example.com' url_widget.on_load_status_changed status.name assert url_widget._urltype expected
def register linter linter.register_checker ExceptionsChecker linter
def handle_calendar_updates namespace_id calendars log db_session ids_ []added_count 0updated_count 0for calendar in calendars assert calendar.uid is not None 'Gotremoteitemwithnulluid'local_calendar db_session.query Calendar .filter Calendar.namespace_id namespace_id Calendar.uid calendar.uid .first if local_calendar is not None local_calendar.update calendar updated_count + 1else local_calendar Calendar namespace_id namespace_id local_calendar.update calendar db_session.add local_calendar added_count + 1db_session.commit ids_.append local_calendar.uid local_calendar.id log.info 'syncedaddedandupdatedcalendars' added added_count updated updated_count return ids_
def Web_Template key defweb wdir if wdir is None try wdir fix_webname key except wdir ''if not wdir wdir defwebif key key.set wdir if not wdir return ''full_dir real_path sabnzbd.DIR_INTERFACES wdir full_main real_path full_dir DEF_MAIN_TMPL logging.info 'Webdiris%s' full_dir if not os.path.exists full_main if defweb DEF_STDCONFIG return ''logging.warning T 'Cannotfindwebtemplate %s tryingstandardtemplate' full_main full_dir real_path sabnzbd.DIR_INTERFACES DEF_STDINTF full_main real_path full_dir DEF_MAIN_TMPL if not os.path.exists full_main logging.exception 'Cannotfindstandardtemplate %s' full_dir panic_tmpl full_dir exit_sab 1 return real_path full_dir 'templates'
def arrays_to_list_of_tuples arrays colnames first_array arrays[colnames[0]]return [tuple arrays[colname][i] for colname in colnames for i in range len first_array ]
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def clean s lines [l.rstrip for l in s.split '\n' ]return '\n'.join lines
def _get_venv_path_dirs venv venv os.path.abspath venv sitedir _get_venv_sitepackages venv sys_path []addsitedir sys_path sitedir return sys_path
def binArr2int arr from numpy import packbitstmp2 packbits arr.astype int return sum val * 256 ** i for i val in enumerate tmp2[ -1 ]
def fromFile filename f open filename contents cPickle.load f f.close if hasattr contents 'abort' contents.abort return contents
def template_funcs funcs {}for plugin in find_plugins if plugin.template_funcs funcs.update plugin.template_funcs return funcs
def continuous valueString sys.stdout.write str valueString return valueString
def idpXrds request return util.renderXRDS request [OPENID_IDP_2_0_TYPE] [getViewURL request endpoint ]
def get_device_name bdm if isinstance bdm obj_base.NovaObject return bdm.device_nameelse return bdm.get 'device_name' or bdm.get 'mount_device'
def calc_at_skew sequence a sequence.count 'A' + sequence.count 'a' t sequence.count 'T' + sequence.count 't' if a + t 0 return 0.0else return a - t / float a + t
@register.inclusion_tag 'sponsors/templatetags/featured_sponsor_rotation.html' def featured_sponsor_rotation return {'sponsors' Sponsor.objects.featured }
def WignerSemicircle name R return rv name WignerSemicircleDistribution R
def zen request project subproject lang translation get_translation request project subproject lang search_result unitdata get_zen_unitdata translation request if isinstance search_result HttpResponse return search_resultreturn render request u'zen.html' {u'object' translation u'project' translation.subproject.project u'unitdata' unitdata u'search_query' search_result[u'query'] u'filter_name' search_result[u'name'] u'filter_count' len search_result[u'ids'] u'last_section' search_result[u'last_section'] u'search_id' search_result[u'search_id'] u'offset' search_result[u'offset'] u'search_form' search_result[u'form'] u'update_lock' translation.lock_user request.user }
def identity obj return obj
def review_published_cb sender user review to_submitter_only request **kwargs siteconfig SiteConfiguration.objects.get_current if siteconfig.get u'mail_send_review_mail' mail_review review user to_submitter_only request
def resolve_func spec try idx spec.rindex '.' mname spec[ idx]fname spec[ idx + 1 ]module _import_module mname return getattr module fname except ValueError return globals [spec]
@handle_response_format@treeio_login_required@module_admin_required 'treeio.changes' def status_add request response_format 'html' if request.POST form ChangeSetStatusForm request.user.profile request.POST if form.is_valid status form.save return HttpResponseRedirect reverse 'changes_status_view' args [status.id] else form ChangeSetStatusForm request.user.profile context _get_default_context request context.update {'form' form} return render_to_response 'changes/status_add' context context_instance RequestContext request response_format response_format
def encode_path p if not isinstance p unicode raise TypeError u'Canonlyencodeunicode not{}'.format type p return p.encode _FILESYSTEM_ENCODING
def validate_since response cherrypy.serving.responselastmod response.headers.get 'Last-Modified' if lastmod status reason msg _httputil.valid_status response.status request cherrypy.serving.requestsince request.headers.get 'If-Unmodified-Since' if since and since ! lastmod if status > 200 and status < 299 or status 412 raise cherrypy.HTTPError 412 since request.headers.get 'If-Modified-Since' if since and since lastmod if status > 200 and status < 299 or status 304 if request.method in 'GET' 'HEAD' raise cherrypy.HTTPRedirect [] 304 else raise cherrypy.HTTPError 412
def get_unit_changes request unit_id unit get_object_or_404 Unit pk int unit_id unit.check_acl request return render request 'js/changes.html' {'last_changes' unit.change_set.all [ 10] 'last_changes_url' urlencode unit.translation.get_kwargs }
def get_vnc_config_spec client_factory port virtual_machine_config_spec client_factory.create 'ns0 VirtualMachineConfigSpec' opt_enabled client_factory.create 'ns0 OptionValue' opt_enabled.key 'RemoteDisplay.vnc.enabled'opt_enabled.value 'true'opt_port client_factory.create 'ns0 OptionValue' opt_port.key 'RemoteDisplay.vnc.port'opt_port.value portopt_keymap client_factory.create 'ns0 OptionValue' opt_keymap.key 'RemoteDisplay.vnc.keyMap'opt_keymap.value CONF.vnc.keymapextras [opt_enabled opt_port opt_keymap]virtual_machine_config_spec.extraConfig extrasreturn virtual_machine_config_spec
def _f_list_parser fl ref_frame def flist_iter for pair in fl obj force pairif isinstance obj ReferenceFrame yield obj.ang_vel_in ref_frame force elif isinstance obj Point yield obj.vel ref_frame force else raise TypeError 'Firstentryineachforcelistpairmustbeapointorframe.' if not fl vel_list f_list else unzip lambda l list zip *l if l[0] else [ ] vel_list f_list unzip list flist_iter return vel_list f_list
def test_keypoints_censure_color_image_unsupported_error assert_raises ValueError CENSURE .detect np.zeros 20 20 3
def _compactRepr obj alwaysShow None flagNames None fieldNames None sectionNames None if alwaysShow is None alwaysShow []if flagNames is None flagNames []if fieldNames is None fieldNames []if sectionNames is None sectionNames []setFlags []for name in flagNames if name in alwaysShow or getattr obj name False True setFlags.append name displayableArgs _getDisplayableArguments obj alwaysShow fieldNames out ['<' obj.__class__.__name__] + displayableArgs if setFlags out.append 'flags %s' % ' '.join setFlags for name in sectionNames section getattr obj name [] if section out.append '%s %r' % name section out.append '>' return ''.join out
def load_scores_ba_dir dir return FileBinnedArrayDir dir
def _firstResult gen return list gen [0]
def test_random_state_transfer class Graph def __init__ self seed 123 self.rng MRG_RandomStreams seed self.y self.rng.uniform size 1 g1 Graph seed 123 f1 theano.function [] g1.y g2 Graph seed 987 f2 theano.function [] g2.y g2.rng.rstate g1.rng.rstatefor su1 su2 in zip g1.rng.state_updates g2.rng.state_updates su2[0].set_value su1[0].get_value numpy.testing.assert_array_almost_equal f1 f2 decimal 6
def load_byte buf pos end pos + 1 if end > len buf raise BadRarFile 'cannotloadbyte' return S_BYTE.unpack_from buf pos [0] end
def compute_node_statistics context result model_query context func.count models.ComputeNode.id func.sum models.ComputeNode.vcpus func.sum models.ComputeNode.memory_mb func.sum models.ComputeNode.local_gb func.sum models.ComputeNode.vcpus_used func.sum models.ComputeNode.memory_mb_used func.sum models.ComputeNode.local_gb_used func.sum models.ComputeNode.free_ram_mb func.sum models.ComputeNode.free_disk_gb func.sum models.ComputeNode.current_workload func.sum models.ComputeNode.running_vms func.sum models.ComputeNode.disk_available_least base_model models.ComputeNode read_deleted 'no' .first fields 'count' 'vcpus' 'memory_mb' 'local_gb' 'vcpus_used' 'memory_mb_used' 'local_gb_used' 'free_ram_mb' 'free_disk_gb' 'current_workload' 'running_vms' 'disk_available_least' return dict field int result[idx] or 0 for idx field in enumerate fields
def file_move session dc_ref src_file dst_file LOG.debug 'Movingfilefrom% src sto% dst s.' {'src' src_file 'dst' dst_file} vim session.vimmove_task session._call_method vim 'MoveDatastoreFile_Task' vim.service_content.fileManager sourceName str src_file sourceDatacenter dc_ref destinationName str dst_file destinationDatacenter dc_ref session._wait_for_task move_task LOG.debug 'Filemoved'
def _do_for_subarray entry condition func path None if path is None path []if isinstance entry list if condition entry func entry path else for index item in enumerate entry _do_for_subarray item condition func path + [index]
def sysadmin context data_dict return {'success' False 'msg' _ 'Notauthorized' }
def commit_unless_managed using None if using is None using DEFAULT_DB_ALIASconnection connections[using]connection.commit_unless_managed
def libs_from_seqids seq_ids delim '_' all_libs set [i.rsplit delim 1 [0] for i in seq_ids] return all_libs
@Node.subscribe 'before_save' def validate_permissions schema instance node instancecontributor_ids set [user._id for user in node.contributors] permission_ids set node.permissions.keys mismatched_contributors contributor_ids.difference permission_ids if mismatched_contributors raise ValidationValueError 'Contributors{0}missingfrom`permissions`onnode{1}'.format ' '.join mismatched_contributors node._id mismatched_permissions permission_ids.difference contributor_ids if mismatched_permissions raise ValidationValueError 'Permissionkeys{0}missingfrom`contributors`onnode{1}'.format ' '.join mismatched_contributors node._id
def dijkstra_shortest_path graph id1 id2 heuristic None directed False def flatten list while len list > 0 yield list[0] list list[1]G adjacency graph directed directed heuristic heuristic q [ 0 id1 ]visited set while True cost1 n1 path heappop q if n1 not in visited visited.add n1 if n1 id2 return list flatten path [ -1 ] + [n1] path n1 path for n2 cost2 in G[n1].items if n2 not in visited heappush q cost1 + cost2 n2 path
@with_setup step_runner_environ def test_can_point_undefined_steps f Feature.from_string FEATURE2 feature_result f.run scenario_result feature_result.scenario_results[0]assert_equals len scenario_result.steps_undefined 2 assert_equals len scenario_result.steps_passed 1 assert_equals scenario_result.total_steps 3 undefined1 scenario_result.steps_undefined[0]undefined2 scenario_result.steps_undefined[1]assert_equals undefined1.sentence 'Thenthisonehasnodefinition' assert_equals undefined2.sentence 'Andthisonealso'
def collection_get_options collection_name **kwargs cluster cluster_status **kwargs options {'collection.configName' cluster['collections'][collection_name]['configName'] 'router.name' cluster['collections'][collection_name]['router']['name'] 'replicationFactor' int cluster['collections'][collection_name]['replicationFactor'] 'maxShardsPerNode' int cluster['collections'][collection_name]['maxShardsPerNode'] 'autoAddReplicas' cluster['collections'][collection_name]['autoAddReplicas'] is True }if 'rule' in cluster['collections'][collection_name] options['rule'] cluster['collections'][collection_name]['rule']if 'snitch' in cluster['collections'][collection_name] options['snitch'] cluster['collections'][collection_name]['rule']return options
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def version_string_as_tuple s v _unpack_version *s.split u'.' if isinstance v.micro string_t v version_info_t v.major v.minor *_splitmicro *v[2 ] if not v.serial and v.releaselevel and u'-' in v.releaselevel v version_info_t * list v[0 3] + v.releaselevel.split u'-' return v
def fg1 x return x + 2 * np.exp -16 * x ** 2
@csrf_exempt@require_POSTdef password_reset request limiter BadRequestRateLimiter if limiter.is_rate_limit_exceeded request AUDIT_LOG.warning 'Ratelimitexceededinpassword_reset' return HttpResponseForbidden form PasswordResetFormNoActive request.POST if form.is_valid form.save use_https request.is_secure from_email configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL request request domain_override request.get_host tracker.emit SETTING_CHANGE_INITIATED {'setting' 'password' 'old' None 'new' None 'user_id' request.user.id} destroy_oauth_tokens request.user else AUDIT_LOG.info 'Badpassword_resetuserpassedin.' limiter.tick_bad_request_counter request return JsonResponse {'success' True 'value' render_to_string 'registration/password_reset_done.html' {} }
def _convert_host_to_hex host ips []if host is not None for family ip in _convert_host_to_ip host hexip_nf binascii.b2a_hex socket.inet_pton family ip hexip_hf ''for i in range 0 len hexip_nf 8 ipgroup_nf hexip_nf[i i + 8 ]ipgroup_hf socket.ntohl int ipgroup_nf base 16 hexip_hf '%s%08X' % hexip_hf ipgroup_hf ips.append family hexip_hf return ips
def get_output_error_code cmd out_err p process_handler cmd lambda p p.communicate p if out_err is None return '' '' p.returncode out err out_errreturn py3compat.bytes_to_str out py3compat.bytes_to_str err p.returncode
@maintain.deprecated 'Useauth_is_loggedin_userinstead' def auth_is_registered_user return auth_is_loggedin_user
def list_floatingips profile None conn _auth profile return conn.list_floatingips
def instance_type_access_add context flavor_id project_id return IMPL.instance_type_access_add context flavor_id project_id
def pytest_configure config if config.getoption '--qute-profile-subprocs' try shutil.rmtree 'prof' except FileNotFoundError pass
def equateCylindricalDotRadius point returnValue originalRadius abs point.dropAxis if originalRadius > 0.0 radiusMultipler returnValue / originalRadius point.x * radiusMultiplerpoint.y * radiusMultipler
def package_to_path package return package.replace '.' '/'
def get_system_sass_dirs system if system not in 'lms' 'cms' raise ValueError '"system"musteitherbe"lms"or"cms"' dirs []sass_dir path system / 'static' / 'sass' css_dir path system / 'static' / 'css' dependencies SASS_LOOKUP_DEPENDENCIES.get system [] dirs.append {'sass_source_dir' sass_dir 'css_destination_dir' css_dir 'lookup_paths' dependencies + [ sass_dir / 'partials' sass_dir] } if system 'lms' dirs.append {'sass_source_dir' path system / 'static' / 'certificates' / 'sass' 'css_destination_dir' path system / 'static' / 'certificates' / 'css' 'lookup_paths' [ sass_dir / 'partials' sass_dir]} return dirs
def resolve_route path if path not in u'about' u'contact' context get_page_context_from_template path if context return contextreturn get_page_context_from_doctype path else context get_page_context_from_doctype path if context return contextreturn get_page_context_from_template path
def derive_key secret salt iterations 1000 keylen 32 assert type secret in [six.text_type six.binary_type] assert type salt in [six.text_type six.binary_type] assert type iterations in six.integer_types assert type keylen in six.integer_types if type secret six.text_type secret secret.encode 'utf8' if type salt six.text_type salt salt.encode 'utf8' key pbkdf2 secret salt iterations keylen return binascii.b2a_base64 key .strip
def format_otu_map otu_map otu_id_prefix for c in otu_id_prefix if not c.isalnum and not c '.' raise ValueError '%scharisnotallowedinOTUIDs' % c for otu_id seq_ids in otu_map yield '%s%s DCTB %s\n' % otu_id_prefix otu_id ' DCTB '.join seq_ids return
@csrf_protectdef render_flatpage request f if f.registration_required and not request.user.is_authenticated from django.contrib.auth.views import redirect_to_loginreturn redirect_to_login request.path if f.template_name t loader.select_template f.template_name DEFAULT_TEMPLATE else t loader.get_template DEFAULT_TEMPLATE f.title mark_safe f.title f.content mark_safe f.content c RequestContext request {'flatpage' f} response HttpResponse t.render c populate_xheaders request response FlatPage f.id return response
def thumbnails_for_file relative_source_path root None basedir None subdir None prefix None if root is None root settings.MEDIA_ROOTif prefix is None prefix settings.THUMBNAIL_PREFIXif subdir is None subdir settings.THUMBNAIL_SUBDIRif basedir is None basedir settings.THUMBNAIL_BASEDIR source_dir filename os.path.split relative_source_path thumbs_path os.path.join root basedir source_dir subdir if not os.path.isdir thumbs_path return []files all_thumbnails thumbs_path recursive False prefix prefix subdir '' return files.get filename []
def add_capability capability source None limit_access False image None restart False if salt.utils.version_cmp __grains__['osversion'] '10' -1 raise NotImplementedError '`install_capability`isnotavailableonthisversionofWindows {0}'.format __grains__['osversion'] cmd ['DISM' '/Quiet' '/Image {0}'.format image if image else '/Online' '/Add-Capability' '/CapabilityName {0}'.format capability ]if source cmd.append '/Source {0}'.format source if limit_access cmd.append '/LimitAccess' if not restart cmd.append '/NoRestart' return __salt__['cmd.run_all'] cmd
def flip image return image.transpose Image.FLIP_TOP_BOTTOM
def addVertexToAttributeDictionary attributeDictionary vertex if vertex.x ! 0.0 attributeDictionary['x'] str vertex.x if vertex.y ! 0.0 attributeDictionary['y'] str vertex.y if vertex.z ! 0.0 attributeDictionary['z'] str vertex.z
def get_base_lun_name volume base_name extract_provider_location volume.provider_location 'base_lun_name' if base_name is None or base_name 'None' return volume.namereturn base_name
def make_pythonzip global python_filesd realpath join 'private' 'lib' 'python2.7' def select fn if is_blacklist fn return Falsefn realpath fn assert fn.startswith d fn fn[len d ]if fn.startswith '/site-packages/' or fn.startswith '/config/' or fn.startswith '/lib-dynload/' or fn.startswith '/libpymodules.so' return Falsereturn fnpython_files [x for x in listfiles d if select x ]zfn join 'private' 'lib' 'python27.zip' zf ZipFile zfn 'w' for fn in python_files afn fn[len d ]zf.write fn afn zf.close
def _get_item request data usage_key UsageKey.from_string data.get 'locator' item modulestore .get_item usage_key if not has_course_author_access request.user item.location.course_key raise PermissionDenied return item
def is_casava_v180_or_later header_line assert header_line.startswith '@' "Badfastqfilepassedasinput.Headerlinemuststartwith'@'."fields header_line.split ' ' if len fields 10 and fields[7] in 'YN' return Truereturn False
def disk_usage path try st os.statvfs path except UnicodeEncodeError if not PY3 and isinstance path unicode try path path.encode sys.getfilesystemencoding except UnicodeEncodeError passst os.statvfs path else raisefree st.f_bavail * st.f_frsize total st.f_blocks * st.f_frsize used st.f_blocks - st.f_bfree * st.f_frsize percent usage_percent used total _round 1 return sdiskusage total used free percent
def envs ignore_cache False if not ignore_cache env_cache os.path.join __opts__['cachedir'] 'hgfs/envs.p' cache_match salt.fileserver.check_env_cache __opts__ env_cache if cache_match is not None return cache_matchret set for repo in init repo['repo'].open if repo['branch_method'] in 'branches' 'mixed' for branch in _all_branches repo['repo'] branch_name branch[0]if branch_name repo['base'] branch_name 'base'ret.add branch_name if repo['branch_method'] in 'bookmarks' 'mixed' for bookmark in _all_bookmarks repo['repo'] bookmark_name bookmark[0]if bookmark_name repo['base'] bookmark_name 'base'ret.add bookmark_name ret.update [x[0] for x in _all_tags repo['repo'] ] repo['repo'].close return [x for x in sorted ret if _env_is_exposed x ]
def p_parameter_type_list_2 t pass
def to_numpy m **options dtype options.get 'dtype' 'complex' if isinstance m Matrix Expr return sympy_to_numpy m dtype dtype elif isinstance m numpy_ndarray return melif isinstance m scipy_sparse_matrix return m.todense raise TypeError 'Expectedsympy/numpy/scipy.sparsematrix got %r' % m
def build_clonespec config_spec object_ref reloc_spec template if reloc_spec.diskMoveType QUICK_LINKED_CLONE return vim.vm.CloneSpec template template location reloc_spec config config_spec snapshot object_ref.snapshot.currentSnapshot else return vim.vm.CloneSpec template template location reloc_spec config config_spec
def makepatch original modified patch {}for key original_value in original.iteritems modified_value modified.get key None if modified_value is None patch[key] Noneelif original_value ! modified_value if type original_value type {} patch[key] makepatch original_value modified_value else patch[key] modified_valueelse passfor key in modified if key not in original patch[key] modified[key]return patch
def image_member_create context values session None memb_ref models.ImageMember _image_member_update context memb_ref values session session return _image_member_format memb_ref
def staff_member_required view_func @wraps view_func def _checklogin request *args **kwargs if request.user.is_active and request.user.is_staff return view_func request *args **kwargs assert hasattr request 'session' "TheDjangoadminrequiressessionmiddlewaretobeinstalled.EdityourMIDDLEWARE_CLASSESsettingtoinsert'django.contrib.sessions.middleware.SessionMiddleware'."defaults {'template_name' 'admin/login.html' 'authentication_form' AdminAuthenticationForm 'extra_context' {'title' _ 'Login' 'app_path' request.get_full_path REDIRECT_FIELD_NAME request.get_full_path }}return login request **defaults return _checklogin
def try_descendant S C R1_c_list R2 N alpha x beta Y D C.copy A_dict D.A_dictif beta D.n and beta < N D.table.append [None] * len D.A D.p.append beta D.table[alpha][D.A_dict[x]] betaD.table[beta][D.A_dict_inv[x]] alphaD.deduction_stack.append alpha x if not D.process_deductions_check R1_c_list[D.A_dict[x]] R1_c_list[D.A_dict_inv[x]] returnfor w in Y if not D.scan_check 0 w returnif first_in_class D Y descendant_subgroups S D R1_c_list x R2 N Y
def get_mod_num module number if len HOUSE.keys > module mod HOUSE.keys [module]if len HOUSE[mod].keys > number mod_instance HOUSE[mod].keys [number]return mod mod_instance return None None
def test_elemwise3 shape 3 4 5 6 a tcn.shared_constructor theano._asarray numpy.random.rand *shape dtype 'float32' 'a' b tensor.fvector new_val a + b .dimshuffle [2 0 3 1] new_val * tensor.exp 1 + b ** a .dimshuffle [2 0 3 1] f pfunc [b] [] updates [ a new_val ] mode mode_with_gpu has_elemwise Falsefor i node in enumerate f.maker.fgraph.toposort has_elemwise has_elemwise or isinstance node.op tensor.Elemwise assert not has_elemwise f theano._asarray numpy.random.rand 6 dtype 'float32'
def map_download_check request try layer request.session['map_status']if isinstance layer dict url '%srest/process/batchDownload/status/%s' % ogc_server_settings.LOCATION layer['id'] resp content http_client.request url 'GET' status resp.statusif resp.status 400 return HttpResponse content 'Somethingwentwrong' status status else content 'SomethingWentwrong'status 400except ValueError logger.warn 'Usertriedtocheckstatus buthasnodownloadinprogress.' return HttpResponse content content status status
def photo f filename os.path.join os.path.dirname __file__ '..' f assert os.path.exists filename return filename
def aug_assign lhs op rhs if op + ' ' not in Relational.ValidRelationOperator raise ValueError 'Unrecognizedoperator%s' % op return Relational.ValidRelationOperator[ op + ' ' ] lhs rhs
@tf.RegisterShape 'VariableLSTM' def _variable_lstm_shape op input_shape op.inputs[0].get_shape .with_rank 4 state_shape op.inputs[1].get_shape .with_rank 2 memory_shape op.inputs[2].get_shape .with_rank 2 w_m_m_shape op.inputs[3].get_shape .with_rank 3 batch_size input_shape[0].merge_with state_shape[0] batch_size input_shape[0].merge_with memory_shape[0] seq_len input_shape[1]gate_num input_shape[2].merge_with w_m_m_shape[1] output_dim input_shape[3].merge_with state_shape[1] output_dim output_dim.merge_with memory_shape[1] output_dim output_dim.merge_with w_m_m_shape[0] output_dim output_dim.merge_with w_m_m_shape[2] return [[batch_size seq_len output_dim] [batch_size seq_len gate_num output_dim] [batch_size seq_len output_dim]]
def MFI barDs count timeperiod - 2 ** 31 return call_talib_with_hlcv barDs count talib.MFI timeperiod
def concatcsv in_files import os.path as opfrom nipype.utils.filemanip import split_filenameif not isinstance in_files list return in_filesif isinstance in_files[0] list in_files in_files[0]first open in_files[0] u'r' path name ext split_filename in_files[0] out_name op.abspath u'concat.csv' out_file open out_name u'w' out_file.write first.readline first.close for in_file in in_files file_to_read open in_file u'r' scrap_first_line file_to_read.readline for line in file_to_read out_file.write line return out_name
def p_parameter_type_list_opt_1 t pass
def typechain *args if len args 0 raise TypeError 'Noargumentswereprovided.' def annotation value '\nReturnsvalueeithertransformedwithoneofthefunctioninargs or\ncastedtooneoftypesinargs orthevalueitselfifitisinthe\nargs.\n\n raisesValueError Raiseswhencannottransformvalueinanyoneof\nspecifiedways.\n'for arg in args if value arg return valueif isinstance arg type and isinstance value arg return valuetry return arg value except ValueError TypeError passraise ValueError "Couldn'tconvertvalue{!r}toanyspecifiedtypeorfinditinspecifiedvalues.".format value return annotation
def split_dataset_collection_instance dataset_collection_instance collection_type return _split_dataset_collection dataset_collection_instance.collection collection_type
def is_dir_url link link_path url_to_path link.url_without_fragment return os.path.isdir link_path
def test_psdestimator raw io.read_raw_fif raw_fname events read_events event_name picks pick_types raw.info meg True stim False ecg False eog False exclude 'bads' picks picks[1 13 3]epochs Epochs raw events event_id tmin tmax picks picks baseline None 0 preload True epochs_data epochs.get_data psd PSDEstimator 2 * np.pi 0 np.inf y epochs.events[ -1 ]X psd.fit_transform epochs_data y assert_true X.shape[0] epochs_data.shape[0] assert_array_equal psd.fit epochs_data y .transform epochs_data X assert_raises ValueError psd.fit epochs y assert_raises ValueError psd.transform epochs y
@hook.command 'word' 'wordoftheday' autohelp False def wordoftheday text if not api_key return 'ThiscommandrequiresanAPIkeyfromwordnik.com.'match re.search ' \\d\\d\\d\\d-\\d\\d-\\d\\d ' text date ''if match date match.group 1 url API_URL + 'words.json/wordOfTheDay' if date params {'api_key' api_key 'date' date}day dateelse params {'api_key' api_key}day 'today'json requests.get url params params .json if json word json['word']note json['note']pos json['definitions'][0]['partOfSpeech']definition json['definitions'][0]['text']out 'Thewordfor\x02{}\x02is\x02{}\x02 '.format day word out + '\x0305 {} \x0305'.format pos out + '\x0310{}\x0310'.format note out + '\x02Definition \x02\x0303{}\x0303'.format definition return ''.join out.split else return "SorryIcouldn'tfindthewordoftheday checkoutthisawesomeotterinstead{}".format 'http //i.imgur.com/pkuWlWx.gif'
@get '/scan/<taskid>/status' def scan_status taskid if taskid not in DataStore.tasks logger.warning '[%s]InvalidtaskIDprovidedtoscan_status ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} if DataStore.tasks[taskid].engine_process is None status 'notrunning'else status 'terminated' if DataStore.tasks[taskid].engine_has_terminated is True else 'running' logger.debug '[%s]Retrievedscanstatus' % taskid return jsonize {'success' True 'status' status 'returncode' DataStore.tasks[taskid].engine_get_returncode }
def bot_data_in session *args **kwargs text args[0] if args else None if text is None returnif text.strip in _IDLE_COMMAND session.update_session_counters idle True returnkwargs.pop 'options' None session.player.execute_cmd text text session session session.update_session_counters
def _create_identity id_type None username None password None tenant_id None tenant_name None api_key None verify_ssl None return_context False if id_type cls _import_identity id_type else cls settings.get 'identity_class' if not cls raise exc.IdentityClassNotDefined 'Noidentityclasshasbeendefinedforthecurrentenvironment.' if verify_ssl is None verify_ssl get_setting 'verify_ssl' context cls username username password password tenant_id tenant_id tenant_name tenant_name api_key api_key verify_ssl verify_ssl if return_context return contextelse global identityidentity context
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def resource_allocation_index G ebunch None def predict u v return sum 1 / G.degree w for w in nx.common_neighbors G u v return _apply_prediction G predict ebunch
def translate_pattern pattern anchor 1 prefix None is_regex 0 if is_regex if isinstance pattern str return re.compile pattern else return patternif pattern pattern_re glob_to_re pattern else pattern_re ''if prefix is not None empty_pattern glob_to_re '' prefix_re glob_to_re prefix [ - len empty_pattern ]pattern_re '^' + os.path.join prefix_re '.*' + pattern_re elif anchor pattern_re '^' + pattern_re return re.compile pattern_re
def test_traverse_postorder_duplicate_subtrees subtree ET u'+' ET 1 ET 2 tree ET u'+' subtree subtree traversal [n.value for n in tree.traverse_postorder ]assert traversal [1 2 u'+' 1 2 u'+' u'+']
def getPathByKey key xmlElement if key not in xmlElement.attributeDictionary return []word str xmlElement.attributeDictionary[key] .strip evaluatedLinkValue getEvaluatedLinkValue word xmlElement if evaluatedLinkValue.__class__ list return getPathByList evaluatedLinkValue xmlElementObject getXMLElementObject evaluatedLinkValue if xmlElementObject None return []return xmlElementObject.getPaths [0]
def compare_search_obj obj_a obj_b assert _num_difference obj_a obj_b 0 compare_attrs obj_a obj_b list obj_a.__dict__ if not isinstance obj_a SearchIO.HSPFragment assert len obj_a len obj_b 'length %ivs%ifor%rvs%r' % len obj_a len obj_b obj_a obj_b for item_a item_b in zip obj_a obj_b assert compare_search_obj item_a item_b return True
def get_plugin_manager return get_config .pluginmanager
def itemmap func d factory dict rv factory rv.update map func iteritems d return rv
def matchmark colitem markexpr return eval markexpr {} MarkMapping colitem.keywords
def fields2csv_head fields prefix '' line []for field subfields in fields.iteritems if subfields is True or callable subfields line.append prefix + field elif isinstance subfields dict line + fields2csv_head subfields prefix prefix + field + '.' return line
def _check_group_auth context data_dict if not data_dict return Truemodel context['model']user context['user']pkg context.get 'package' api_version context.get 'api_version' or '1' group_blobs data_dict.get 'groups' [] groups set for group_blob in group_blobs if isinstance group_blob dict id group_blob.get 'id' or group_blob.get 'name' if not id continueelse id group_blobgrp model.Group.get id if grp is None raise logic.NotFound _ 'Groupwasnotfound.' groups.add grp if pkg pkg_groups pkg.get_groups groups groups - set pkg_groups for group in groups if not authz.has_user_permission_for_group_or_org group.id user 'update' return Falsereturn True
def auth_traps_enabled name status True ret {'name' name 'changes' {} 'comment' str 'result' None}vname 'EnableAuthenticationTraps'current_status __salt__['win_snmp.get_auth_traps_enabled'] if status current_status ret['comment'] '{0}alreadycontainstheprovidedvalue.'.format vname ret['result'] Trueelif __opts__['test'] ret['comment'] '{0}willbechanged.'.format vname ret['changes'] {'old' current_status 'new' status}else ret['comment'] 'Set{0}tocontaintheprovidedvalue.'.format vname ret['changes'] {'old' current_status 'new' status}ret['result'] __salt__['win_snmp.set_auth_traps_enabled'] status status return ret
def make_sample_node_table bt mf_dict sids bt.ids header '#NodeID DCTB NodeType DCTB Abundance DCTB ' + ' DCTB '.join mf_dict[sids[0]].keys lines [header] + [ '%s DCTB sample DCTB %s DCTB ' % sid bt.data sid axis 'sample' .sum + ' DCTB '.join mf_dict[sid].values for sid in sids] return lines
def list_compatible workflows get_compatible feedback alfred.Feedback for w in workflows subtitle 'v' + unicode w.version + '' + w.description feedback.addItem title w.name subtitle subtitle icon w.icon valid 'no' if feedback.isEmpty feedback.addItem title 'Nocompatibleworkflowsfound' valid 'no' autocomplete '' else feedback.addItem title 'Goback' valid 'no' icon 'back.png' autocomplete '' feedback.output
def get_settings_priority priority if isinstance priority six.string_types return SETTINGS_PRIORITIES[priority]else return priority
def cubehelix gamma 1.0 s 0.5 r -1.5 h 1.0 def get_color_function p0 p1 def color x xg x ** gamma a h * xg * 1 - xg / 2 phi 2 * np.pi * s / 3 + r * x return xg + a * p0 * np.cos phi + p1 * np.sin phi return colorreturn {u'red' get_color_function -0.14861 1.78277 u'green' get_color_function -0.29227 -0.90649 u'blue' get_color_function 1.97294 0.0 }
def __prepare_fancyarrow_dpi_cor_test fig2 plt.figure u'fancyarrow_dpi_cor_test' figsize 4 3 dpi 50 ax fig2.add_subplot 111 ax.set_xlim [0 1] ax.set_ylim [0 1] ax.add_patch mpatches.FancyArrowPatch posA 0.3 0.4 posB 0.8 0.6 lw 3 arrowstyle u'->' mutation_scale 100 return fig2
def get_configured_projects user AbstractNode apps.get_model 'osf.AbstractNode' configured_project_ids set user_subscriptions get_all_user_subscriptions user for subscription in user_subscriptions if subscription is None continuenode subscription.ownerif not isinstance node AbstractNode or subscription.none.filter id user.id .exists and not node.parent_id or node._id not in user.notifications_configured or node.is_collection continuewhile node.parent_id and not node.is_deleted node node.parent_nodeif not node.is_deleted configured_project_ids.add node._id return list configured_project_ids
def spawn_public_stream args keyword None if keyword if keyword[0] '#' keyword keyword[1 ]args.track_keywords keywordg['keyword'] keywordelse g['keyword'] 'Global'g['PREFIX'] u2str emojize format_prefix keyword g['keyword'] g['listname'] ''th threading.Thread target stream args c['PUBLIC_DOMAIN'] args th.daemon Trueth.start
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def setpassword name password return update name name password password
def verify_indices_all_unique obj axis_names [ 'index' 'index' 'columns' 'items' 'major_axis' 'minor_axis' ][ obj.ndim - 1 ]for axis_name index in zip axis_names obj.axes if index.is_unique continueraise ValueError 'Duplicateentriesin{type}.{axis} {dupes}.'.format type type obj .__name__ axis axis_name dupes sorted index[index.duplicated ] return obj
def kill_all_jobs ret []for data in running ret.append signal_job data['jid'] salt_SIGKILL return ret
def body request return HttpResponse request.body
def continuation_tokens cli width return [ Token u'.' * width - 1 + u'' ]
def cpu_has_flags flags cpu_info get_cpu_info if not isinstance flags list flags [flags]for flag in flags if not list_grep cpu_info '.*%s.*' % flag return Falsereturn True
def _check_for_setattr instance module instance.get_parent_until try stmts module.used_names['setattr']except KeyError return Falsereturn any instance.start_pos < stmt.start_pos < instance.end_pos for stmt in stmts
def getAddIndexedGrid grid vertexes z indexedGrid []for row in grid indexedRow []indexedGrid.append indexedRow for pointComplex in row vector3index Vector3Index len vertexes pointComplex.real pointComplex.imag z indexedRow.append vector3index vertexes.append vector3index return indexedGrid
def create_element tag attributes None sub_elements None if tag elem XmlET.Element tag if attributes for k v in attributes.items elem.set k v if sub_elements for k v in sub_elements.items if v if k 'packages' for v_tuple in v sub_elem XmlET.SubElement elem 'package' sub_elem_name sub_elem_version v_tuplesub_elem.set 'name' sub_elem_name sub_elem.set 'version' sub_elem_version elif isinstance v list sub_elem XmlET.SubElement elem k for v_tuple in v if len v_tuple 2 v_tag v_tuple[0]v_text v_tuple[1]if v_text v_elem XmlET.SubElement sub_elem v_tag v_elem.text v_textelse sub_elem XmlET.SubElement elem k sub_elem.text vreturn elemreturn None
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def rule_absent name method port None proto 'tcp' direction 'in' port_origin 'd' ip_origin 's' ttl None reload False ip nameret {'name' name 'changes' {} 'result' True 'comment' 'Rulenotpresent.'}exists __salt__['csf.exists'] method ip port port proto proto direction direction port_origin port_origin ip_origin ip_origin ttl ttl if not exists return retelse rule __salt__['csf.remove_rule'] method method ip ip port port proto proto direction direction port_origin port_origin ip_origin ip_origin comment '' ttl ttl if rule comment 'Rulehasbeenremoved.'if reload if __salt__['csf.reload'] comment + 'Csfreloaded.'else comment + 'Csfunabletobereloaded.'ret['comment'] commentret['changes']['Rule'] 'Removed'return ret
def id_or_nid song_dict return song_dict.get u'id' or song_dict[u'nid']
def detect stream try json.loads stream return Trueexcept ValueError return False
def patch_object *args **kwargs warnings.warn 'Pleaseusepatch.objectinstead.' DeprecationWarning 2 return _patch_object *args **kwargs
def render_to_response_best_match request template_name dictionary None dictionary dictionary or {} dictionary[u'feincms_page'] Page.objects.best_match_for_request request return render request template_name dictionary
def _get_http_proxy_url http_proxy_url ''host __salt__['config.option'] 'proxy_host' port __salt__['config.option'] 'proxy_port' username __salt__['config.option'] 'proxy_username' password __salt__['config.option'] 'proxy_password' if host and port if username and password http_proxy_url 'http //{0} {1}@{2} {3}'.format username password host port else http_proxy_url 'http //{0} {1}'.format host port return http_proxy_url
def tokenize_input input_sent vocab input_tok []for sent in input_sent text_int [ -1 if t not in vocab else vocab[t] for t in tokenize sent ]input_tok.append np.array text_int return np.array input_tok
def build_collection type dataset_instances dataset_collection model.DatasetCollection set_collection_elements dataset_collection type dataset_instances return dataset_collection
def get_tiles_height_width_ratio n_tiles width_ratio 1.0 width int np.ceil np.sqrt n_tiles * width_ratio return get_tiles_height_width n_tiles desired_width width
def zero_one_loss y_true y_pred normalize True sample_weight None score accuracy_score y_true y_pred normalize normalize sample_weight sample_weight if normalize return 1 - score else if sample_weight is not None n_samples np.sum sample_weight else n_samples _num_samples y_true return n_samples - score
def get_path_uid path if hasattr os 'O_NOFOLLOW' fd os.open path os.O_RDONLY | os.O_NOFOLLOW file_uid os.fstat fd .st_uidos.close fd elif not os.path.islink path file_uid os.stat path .st_uidelse raise OSError '%sisasymlink;Willnotreturnuidforsymlinks' % path return file_uid
def _str_elem config key _value config.pop key '' if _valid_str _value config[key] _value
def _get_nonstar_args func return func.func_code.co_varnames[ func.func_code.co_argcount]
def get_org_from_db org country if org.lower 'gvt' if country 'Guinea' return 'MinisteredelaSante'else return 'MoH%s' % country if org.startswith 'WHO' return 'WorldHealthOrganisation'row db otable.name org .select table.id limitby 0 1 .first if row return orgrow db otable.acronym org .select table.name limitby 0 1 .first if row return row.nameif org in new_org new_org[org] + 1else new_org[org] 1return org
def ae_save token token_key import gdata.alt.app_enginekey_name ''.join 'gd_auth_token' token_key return gdata.alt.app_engine.set_token key_name token_to_blob token
@requires_segment_infodef readonly_indicator pl segment_info text u'RO' return text if int vim_getbufoption segment_info u'readonly' else None
def _make_text_block name content content_type None if content_type 'xhtml' return u'<%stype "xhtml"><divxmlns "%s">%s</div></%s>\n' % name XHTML_NAMESPACE content name if not content_type return u'<%s>%s</%s>\n' % name escape content name return u'<%stype "%s">%s</%s>\n' % name content_type escape content name
@register 'role' def _check_role brain match_kind match target_dict cred_dict return match.lower in [x.lower for x in cred_dict['roles']]
def _description_of path from charade.universaldetector import UniversalDetectoru UniversalDetector for line in open path 'rb' u.feed line u.close result u.resultif result['encoding'] return '%s %swithconfidence%s' % path result['encoding'] result['confidence'] else return '%s noresult' % path
def canonical_form k v SPECIAL_SNOWFLAKES set ['set-cookie' 'set-cookie2'] k k.lower if k in SPECIAL_SNOWFLAKES yield k v else for sub_val in v.split ' ' yield k sub_val.strip
def posix_to_ldml fmt locale buf []pc Falsequoted []for c in fmt if not pc and c.isalpha quoted.append c if c ! "'" else "''" continueif quoted buf.append "'" buf.append ''.join quoted buf.append "'" quoted []if pc if c '%' buf.append '%' elif c 'x' buf.append locale.date_formats['short'].pattern elif c 'X' buf.append locale.time_formats['medium'].pattern else buf.append POSIX_TO_LDML[c] pc Falseelif c '%' pc Trueelse buf.append c if quoted buf.append "'" buf.append ''.join quoted buf.append "'" return ''.join buf
def test_lex_expression_symbols objs tokenize ' foobar ' assert objs [HyExpression [HySymbol 'foo' HySymbol 'bar' ] ]
def setup_axes1 fig rect tr Affine2D .scale 2 1 .rotate_deg 30 grid_helper floating_axes.GridHelperCurveLinear tr extremes -0.5 3.5 0 4 ax1 floating_axes.FloatingSubplot fig rect grid_helper grid_helper fig.add_subplot ax1 aux_ax ax1.get_aux_axes tr grid_helper.grid_finder.grid_locator1._nbins 4grid_helper.grid_finder.grid_locator2._nbins 4return ax1 aux_ax
def get_resource resource_name key identifier_fields profile 'pagerduty' subdomain None api_key None if 'pagerduty_util.resource_cache' not in __context__ __context__['pagerduty_util.resource_cache'] {}if resource_name not in __context__['pagerduty_util.resource_cache'] if resource_name 'services' action resource_name + '?include[] escalation_policy' else action resource_name__context__['pagerduty_util.resource_cache'][resource_name] _query action action profile profile subdomain subdomain api_key api_key [resource_name]for resource in __context__['pagerduty_util.resource_cache'][resource_name] for field in identifier_fields if resource[field] key if resource_name 'schedules' full_resource_info _query action '{0}/{1}'.format resource_name resource['id'] profile profile subdomain subdomain api_key api_key return full_resource_inforeturn resourcereturn None
def framework_info filename is_framework STRICT_FRAMEWORK_RE.match filename if not is_framework return Nonereturn is_framework.groupdict
def get_xyz_coords illuminant observer illuminant illuminant.upper try return illuminants[illuminant][observer]except KeyError raise ValueError "Unknownilluminant/observercombination '{0}' '{1}' ".format illuminant observer
def action name def decorator func func.wsgi_action namereturn funcreturn decorator
def get_projects_with_bugs projects mysite.search.models.Project.objects.annotate bug_count Count 'bug' .filter bug_count__gt 0 .order_by u'display_name' return projects
def _cpu_tot_time times tot sum times if LINUX tot - getattr times 'guest' 0 tot - getattr times 'guest_nice' 0 return tot
def in6_getnsmac a a struct.unpack '16B' a [ -4 ]mac '33 33 'mac + ' '.join map lambda x '%.2x' % x a return mac
def user_has_permission user_db permission_type if not cfg.CONF.rbac.enable return Trueresolver resolvers.get_resolver_for_permission_type permission_type permission_type result resolver.user_has_permission user_db user_db permission_type permission_type return result
def _get_old_license_titles migrate_engine titles {}select_licenses 'SELECTid nameFROMlicense;'q migrate_engine.execute select_licenses for id title in q titles[id] titlereturn titles
def _quote_arg arg if '"' not in arg and '' in arg return '"%s"' % arg return arg
def _check_gle_response response response _unpack_response response assert response['number_returned'] 1 result response['data'][0]_check_command_response result if result.get 'wtimeout' False raise WTimeoutError result.get 'errmsg' result.get 'err' result.get 'code' result error_msg result.get 'err' '' if error_msg is None return resultif error_msg.startswith 'notmaster' raise NotMasterError error_msg result details resultif 'errObjects' in result for errobj in result['errObjects'] if errobj.get 'err' error_msg details errobjbreakcode details.get 'code' if code in 11000 11001 12582 raise DuplicateKeyError details['err'] code result raise OperationFailure details['err'] code result
def table shape fill None return [[fill for j in range shape[1] ] for i in range shape[0] ]
def reload_library global libraryavailable[ ] library update_user_library _base_library
def make_external_id product domain getattr settings 'DOMAIN' None if not domain domain 'marketplace-dev'external_id domain.split '.' [0]return '{0} {1}'.format external_id product.pk
def _set_proc_title process_name libc ctypes.CDLL ctypes.util.find_library 'c' name_buffer ctypes.create_string_buffer len process_name + 1 name_buffer.value process_nametry libc.setproctitle ctypes.byref name_buffer except AttributeError pass
def _rec_strip g v if not v return dup_strip g w v - 1 return dmp_strip [_rec_strip c w for c in g] v
def test_flush jobs bg.BackgroundJobManager j jobs.new sleeper j.join nt.assert_equal len jobs.completed 1 nt.assert_equal len jobs.dead 0 jobs.flush nt.assert_equal len jobs.completed 0
def redirect_to_custom_form request auth_entry kwargs backend_name request.backend.nameprovider_id provider.Registry.get_from_pipeline {'backend' backend_name 'kwargs' kwargs} .provider_idform_info AUTH_ENTRY_CUSTOM[auth_entry]secret_key form_info['secret_key']if isinstance secret_key unicode secret_key secret_key.encode 'utf-8' custom_form_url form_info['url']data_str json.dumps {'auth_entry' auth_entry 'backend_name' backend_name 'provider_id' provider_id 'user_details' kwargs['details']} digest hmac.new secret_key msg data_str digestmod hashlib.sha256 .digest request.session['tpa_custom_auth_entry_data'] {'data' base64.b64encode data_str 'hmac' base64.b64encode digest 'post_url' custom_form_url}return redirect reverse 'tpa_post_to_custom_auth_form'
def _sympy_tensor_product *matrices if not all isinstance m Matrix for m in matrices raise TypeError 'SequenceofMatricesexpected got %s' % repr matrices matrix_expansion matrices[ -1 ]for mat in reversed matrices[ -1 ] rows mat.rowscols mat.colsfor i in range rows start matrix_expansion * mat[ i * cols ] for j in range cols - 1 start start.row_join matrix_expansion * mat[ i * cols + j + 1 ] if i 0 next startelse next next.col_join start matrix_expansion nextreturn matrix_expansion
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def Reset *args for mock in args mock._Reset
def find_file path tgt_env 'base' **kwargs fnd {'path' '' 'rel' ''}if os.path.isabs path or tgt_env not in envs return fndfor repo in init env_root _env_root repo tgt_env if env_root is None continueif repo['mountpoint'] and not path.startswith repo['mountpoint'] + os.path.sep continuerepo_path path[len repo['mountpoint'] ].lstrip os.path.sep if repo['root'] repo_path os.path.join repo['root'] repo_path full os.path.join env_root repo_path if os.path.isfile full fnd['rel'] pathfnd['path'] fulltry fnd['stat'] list os.stat full except Exception passreturn fndreturn fnd
def is_release return VERSION[6]
def importer test global JobDestinationglobal JobMappingExceptionif test class JobDestionation object def __init__ self *kwd self.id kwd.get 'id' self.nativeSpec kwd.get 'params' ['nativeSpecification']self.runner kwd.get 'runner' from galaxy.jobs.mapper import JobMappingExceptionelse from galaxy.jobs import JobDestinationfrom galaxy.jobs.mapper import JobMappingException
def create_folder root '.' folder None folder_path os.path.join root folder if folder and not os.path.isdir folder_path try os.makedirs folder_path except OSError raise CuckooOperationalError 'Unabletocreatefolder %s' % folder_path
def asquare cdfvals axis 0 ndim len cdfvals.shape nobs cdfvals.shape[axis]slice_reverse [slice None ] * ndim islice [None] * ndim islice[axis] slice None slice_reverse[axis] slice None None -1 asqu - 2.0 * np.arange 1.0 nobs + 1 [islice] - 1 * np.log cdfvals + np.log 1 - cdfvals[slice_reverse] / nobs .sum axis - nobs return asqu
def resource_type_versioned_topic resource_type version None _validate_resource_type resource_type cls resources.get_resource_cls resource_type return topics.RESOURCE_TOPIC_PATTERN % {'resource_type' resource_type 'version' version or cls.VERSION }
def _assert_inside fro to from .source_space import _get_solidstot_angle _get_solids to['rr'][to['tris']] fro['rr'] if np.abs tot_angle / 2 * np.pi - 1.0 > 1e-05 .any raise RuntimeError 'Surface%sisnotcompletelyinsidesurface%s' % _surf_name[fro['id']] _surf_name[to['id']]
def _chunk_data X slices slices [sl for sl in slices if len sl ]selected_times np.hstack [np.ravel sl for sl in slices] start np.min selected_times stop np.max selected_times + 1 slices_chunk [ sl - start for sl in slices]X_chunk X[ start stop]return X_chunk slices_chunk
def cgsnapshot_destroy context cgsnapshot_id return IMPL.cgsnapshot_destroy context cgsnapshot_id
def writeestr dst edict os.unlink dst.as_pathname Res.FSpCreateResFile dst 'RSED' 'rsrc' smAllScripts output Res.FSpOpenResFile dst WRITE Res.UseResFile output for num in edict.keys res Res.Resource Pstring edict[num][0] res.AddResource 'Estr' num '' res.WriteResource Res.CloseResFile output
def assert_same_dict data expected_data diffs diff_dicts data expected_data if diffs raise DiffAssertionError diffs
def dup_max_norm f K if not f return K.zeroelse return max dup_abs f K
def corpus path encoding 'utf-8' for s in open path encoding encoding s map lambda w w.split '/' s.strip .split '' s map lambda w w[0].replace '&slash;' '/' w[1] s yield s
def id_to_ec2_vol_id volume_id if uuidutils.is_uuid_like volume_id ctxt context.get_admin_context int_id get_int_id_from_volume_uuid ctxt volume_id return id_to_ec2_id int_id 'vol-%08x' else return id_to_ec2_id volume_id 'vol-%08x'
def libvlc_event_attach p_event_manager i_event_type f_callback user_data f _Cfunctions.get 'libvlc_event_attach' None or _Cfunction 'libvlc_event_attach' 1 1 1 1 None ctypes.c_int EventManager ctypes.c_uint Callback ctypes.c_void_p return f p_event_manager i_event_type f_callback user_data
def make_links_absolute root base_url def link_repl href return urljoin base_url href rewrite_links root link_repl
def _parse_composites fh d {}for line in fh line line.rstrip if not line continueif line.startswith 'EndComposites' return dvals line.split ';' cc vals[0].split name numParts cc[1] _to_int cc[2] pccParts []for s in vals[1 -1 ] pcc s.split name dx dy pcc[1] _to_float pcc[2] _to_float pcc[3] pccParts.append name dx dy d[name] pccPartsraise RuntimeError u'Badcompositesparse'
def is_valid_nickname entry try return bool NICKNAME_PATTERN.match entry except TypeError return False
def numeric_part s m re_numeric_part.match s if m return int m.group 1 return None
def _linux_bin_exists binary for search_cmd in 'which' 'type-ap' try return __salt__['cmd.retcode'] '{0}{1}'.format search_cmd binary 0 except salt.exceptions.CommandExecutionError passtry return len __salt__['cmd.run_all'] 'whereis-b{0}'.format binary ['stdout'].split > 1 except salt.exceptions.CommandExecutionError return False
def _ss data c None if c is None c mean data T total count _sum x - c ** 2 for x in data U total2 count2 _sum x - c for x in data assert T U and count count2 total - total2 ** 2 / len data assert not total < 0 'negativesumofsquaredeviations %f' % total return T total
def threaded_reactor global _twisted_threadtry from twisted.internet import reactorexcept ImportError return None None if not _twisted_thread from twisted.python import threadablefrom threading import Thread_twisted_thread Thread target lambda reactor.run installSignalHandlers False _twisted_thread.setDaemon True _twisted_thread.start return reactor _twisted_thread
def try_enum cls val try return cls val except ValueError return val
def person_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'pr' 'person'
def jacobi_normalized n a b x nfactor S 2 ** a + b + 1 * gamma n + a + 1 * gamma n + b + 1 / 2 * n + a + b + 1 / factorial n * gamma n + a + b + 1 return jacobi n a b x / sqrt nfactor
def installed_pkgs cmd 'pkgutil--pkgs'return __salt__['cmd.run'] cmd .split '\n'
def create_or_update_trigger_type_db trigger_type assert isinstance trigger_type dict trigger_type_api TriggerTypeAPI **trigger_type trigger_type_api.validate trigger_type_api TriggerTypeAPI.to_model trigger_type_api ref ResourceReference.to_string_reference name trigger_type_api.name pack trigger_type_api.pack existing_trigger_type_db get_trigger_type_db ref if existing_trigger_type_db is_update Trueelse is_update Falseif is_update trigger_type_api.id existing_trigger_type_db.idtrigger_type_db TriggerType.add_or_update trigger_type_api extra {'trigger_type_db' trigger_type_db}if is_update LOG.audit 'TriggerTypeupdated.TriggerType.id %s' % trigger_type_db.id extra extra else LOG.audit 'TriggerTypecreated.TriggerType.id %s' % trigger_type_db.id extra extra return trigger_type_db
def name_to_pathname name return name.replace ' ' '/'
def _faa_di_bruno_partitions n if n < 1 raise ValueError 'Expectedapositiveinteger;got%sinstead' % n try return _faa_di_bruno_cache[n]except KeyError raise NotImplementedError 'Higherordertermsnotyetimplemented.'
def can_eliminate_tool_dependency metadata_dict name dependency_type version td_dict metadata_dict.get 'tool_dependencies' {} for td_key td_val in td_dict.items if td_key 'set_environment' for td in td_val n td.get 'name' None t td.get 'type' None if n name and t dependency_type return Falseelse n td_val.get 'name' None t td_val.get 'type' None v td_val.get 'version' None if n name and t dependency_type and v version return Falsereturn True
@cli.command context_settings CONTEXT_SETTINGS @click.argument 'crashfile' type ExistingFilePath callback check_not_none @click.option '-r' '--rerun' is_flag True flag_value True help 'Reruncrashednode.' @click.option '-d' '--debug' is_flag True flag_value True help 'EnablePythondebuggerwhenre-executing.' @click.option '-i' '--ipydebug' is_flag True flag_value True help 'EnableIPythondebuggerwhenre-executing.' @click.option '-w' '--dir' type ExistingDirPath help 'Directorywheretorunthenodein.' def crash crashfile rerun debug ipydebug dir from .crash_files import display_crash_filedebug 'ipython' if ipydebug else debug if debug 'ipython' import sysfrom IPython.core import ultratbsys.excepthook ultratb.FormattedTB mode 'Verbose' color_scheme 'Linux' call_pdb 1 display_crash_file crashfile rerun debug dir
def gcs_get_request url return requests.request 'GET' url verify False
def mock_render_to_string template_name context return str template_name sorted context.iteritems
def assert_multi_index_is_product testcase index *levels testcase.assertIsInstance index MultiIndex '%sisnotaMultiIndex' % index testcase.assertEqual set index set product *levels
def submit_barcodes release_barcode query mbxml.make_barcode_request release_barcode return _do_mb_post 'release' query
def _deserialize_blobs artifact_type blobs_from_db artifact_properties for blob_name blob_value in six.iteritems blobs_from_db if not blob_value continueif isinstance artifact_type.metadata.attributes.blobs.get blob_name declarative.ListAttributeDefinition val []for v in blob_value b definitions.Blob size v['size'] locations v['locations'] checksum v['checksum'] item_key v['item_key'] val.append b elif len blob_value 1 val definitions.Blob size blob_value[0]['size'] locations blob_value[0]['locations'] checksum blob_value[0]['checksum'] item_key blob_value[0]['item_key'] else raise exception.InvalidArtifactPropertyValue message _ 'Blob% name smaynothavemultiplevalues' name blob_name artifact_properties[blob_name] val
def get_instance_value label return _check_range_and_return 'instance' label -1 9 -1
def get_configuration_tag api return api.persistence_service.configuration_hash
def _link_active kwargs highlight_actions kwargs.get 'highlight_actions' kwargs.get 'action' '' .split return c.controller kwargs.get 'controller' and c.action in highlight_actions
def getDeprecated self decorators for a in decorators if isinstance a ast.CallFunc decorator a.asList if isinstance decorator[0] ast.Getattr getAttr decorator[0].asList name getAttr[0].namefn self.expandName name + '.' + getAttr[1] else fn self.expandName decorator[0].name if fn 'twisted.python.deprecate.deprecated' try self._deprecated_info deprecatedToUsefulText self.name decorator except AttributeError pass
def _dup_rr_trivial_gcd f g K if not f or g return [] [] [] elif not f if K.is_nonnegative dup_LC g K return g [] [K.one] else return dup_neg g K [] [ - K.one ] elif not g if K.is_nonnegative dup_LC f K return f [K.one] [] else return dup_neg f K [ - K.one ] [] return None
def group_type_get_all context inactive False filters None marker None limit None sort_keys None sort_dirs None offset None list_result False return IMPL.group_type_get_all context inactive filters marker marker limit limit sort_keys sort_keys sort_dirs sort_dirs offset offset list_result list_result
def publish_string source source_path None destination_path None reader None reader_name 'standalone' parser None parser_name 'restructuredtext' writer None writer_name 'pseudoxml' settings None settings_spec None settings_overrides None config_section None enable_exit_status False output pub publish_programmatically source_class io.StringInput source source source_path source_path destination_class io.StringOutput destination None destination_path destination_path reader reader reader_name reader_name parser parser parser_name parser_name writer writer writer_name writer_name settings settings settings_spec settings_spec settings_overrides settings_overrides config_section config_section enable_exit_status enable_exit_status return output
def save_telemetry_submission data pce _ PersistentCacheEntry.objects.get_or_create defaults {'data' None} **LAST_DATA_KWARGS pce.data datapce.save
@pick_context_manager_readerdef s3_image_get context image_id result model_query context models.S3Image read_deleted 'yes' .filter_by id image_id .first if not result raise exception.ImageNotFound image_id image_id return result
def _solve_hyper_RE f x RE g k terms Add.make_args RE if len terms 2 gs list RE.atoms Function P Q map RE.coeff gs m gs[1].args[0] - gs[0].args[0] if m < 0 P Q Q P m abs m return rsolve_hypergeometric f x P Q k m
def addressable type_constraint return _addressable_wrapper AddressableDescriptor type_constraint
def failureAsJSON failure return dict failure.__getstate__ type dict __module__ failure.type.__module__ __name__ failure.type.__name__
def GetRemoteAppIdFromServer server path remote_token None if not remote_token random.seed remote_token str random.random [2 ]remote_token str remote_token urlargs {'rtok' remote_token}response server.Send path payload None **urlargs if not response.startswith '{' raise ConfigurationError 'Invalidresponserecievedfromserver %s' % response app_info yaml.load response if not app_info or 'rtok' not in app_info or 'app_id' not in app_info raise ConfigurationError 'Errorparsingapp_idlookupresponse' if str app_info['rtok'] ! remote_token raise ConfigurationError 'Tokenvalidationfailedduringapp_idlookup. sent%s got%s ' % repr remote_token repr app_info['rtok'] return app_info['app_id']
def _copytobuffer x isfloat Falseislist Falseistuple Falseif hasattr x 'shape' if x.shape return _copytobuffer_return_scalar x else try x.dtype.charinx x.copy order 'C' .astype 'd' return inx False False False except try x.typecode inx x.astype 'd' return inx False False False except raise TypeError 'inputmustbeanarray list tupleorscalar' elif hasattr x 'typecode' inx array 'd' x elif type x list inx array 'd' x islist Trueelif type x tuple inx array 'd' x istuple Trueelse return _copytobuffer_return_scalar x return inx isfloat islist istuple
def serialized function function.STRING Truereturn function
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
def inject_into_urllib3 connection.ssl_wrap_socket ssl_wrap_socketutil.HAS_SNI HAS_SNIutil.IS_PYOPENSSL True
def get_input_stream environ safe_fallback True stream environ['wsgi.input']content_length get_content_length environ if environ.get 'wsgi.input_terminated' return streamif content_length is None return safe_fallback and _empty_stream or stream return LimitedStream stream content_length
def strip_files files argv_max 256 * 1024 while files cmd list STRIPCMD pathlen sum len s + 1 for s in cmd while pathlen < argv_max and files f files.pop cmd.append f pathlen + len f + 1 if len cmd > len STRIPCMD all_files cmd[len STRIPCMD ]unwritable_files tuple filter None None if os.access x os.W_OK else x os.stat x .st_mode for x in all_files [os.chmod x stat.S_IWRITE | old_mode for x old_mode in unwritable_files]subprocess.check_call cmd [os.chmod x old_mode for x old_mode in unwritable_files]
@pytest.mark.parametrize u'pattern' [pattern1 pattern2] def test_issue118 doc pattern ORG doc.vocab.strings[u'ORG']matcher Matcher doc.vocab {u'BostonCeltics' u'ORG' {} pattern } assert len list doc.ents 0 matches [ ent_type start end for ent_id ent_type start end in matcher doc ]assert matches [ ORG 9 11 ORG 10 11 ] doc.ents matches[ 1]ents list doc.ents assert len ents 1 assert ents[0].label ORG assert ents[0].start 9 assert ents[0].end 11
def ConnectNoSSL host 'localhost' port 443 user 'root' pwd '' service 'hostd' adapter 'SOAP' namespace None path '/sdk' version None keyFile None certFile None thumbprint None b64token None mechanism 'userpass' if hasattr ssl '_create_unverified_context' sslContext ssl._create_unverified_context else sslContext Nonereturn Connect host host port port user user pwd pwd service service adapter adapter namespace namespace path path version version keyFile keyFile certFile certFile thumbprint thumbprint sslContext sslContext b64token b64token mechanism mechanism
def win_handle_is_a_console handle from ctypes import byref POINTER windll WINFUNCTYPEfrom ctypes.wintypes import BOOL DWORD HANDLEFILE_TYPE_CHAR 2FILE_TYPE_REMOTE 32768INVALID_HANDLE_VALUE DWORD -1 .valueGetConsoleMode WINFUNCTYPE BOOL HANDLE POINTER DWORD 'GetConsoleMode' windll.kernel32 GetFileType WINFUNCTYPE DWORD DWORD 'GetFileType' windll.kernel32 if handle INVALID_HANDLE_VALUE or handle is None return Falsereturn GetFileType handle & ~ FILE_TYPE_REMOTE FILE_TYPE_CHAR and GetConsoleMode handle byref DWORD
def _expand_path path path os.path.expandvars path path os.path.expanduser path return path
def discussion_category_id_access course user discussion_id xblock None if discussion_id in course.top_level_discussion_topic_ids return Truetry if not xblock key get_cached_discussion_key course.id discussion_id if not key return Falsexblock modulestore .get_item key return has_required_keys xblock and has_access user 'load' xblock course.id except DiscussionIdMapIsNotCached return discussion_id in get_discussion_categories_ids course user
def generate_alton_commands hotfix_hash template textwrap.dedent '\n@altoncutamiforstage-edx-edxappfromprod-edx-edxappwithedx_platform_version {hotfix_hash}\n@altoncutamiforprod-edge-edxappfromprod-edge-edxappwithedx_platform_version {hotfix_hash}\n@altoncutamiforprod-edx-edxappfromprod-edx-edxappwithedx_platform_version {hotfix_hash}\n' return template.strip .format hotfix_hash hotfix_hash
def object_dict objects by_ref False error_message None error_dict None if by_ref items obj.ref obj for obj in objects else items obj.name obj for obj in objects ordered OrderedDict for key value in items if key in ordered error_message error_message or 'Duplicatekey{key}' error_dict error_dict or {} raise ModelError error_message.format key key **error_dict ordered[key] valuereturn ordered
@membership_requireddef message_create request slug topic_id template_name 'groups/messages/message_form.html' group get_object_or_404 Group slug slug topic get_object_or_404 GroupTopic pk topic_id group group if request.method 'POST' form GroupMessageForm request.POST if form.is_valid message form.save commit False message.user request.usermessage.topic topicmessage.save return redirect request topic else form GroupMessageForm return render request template_name {'group' group 'topic' topic 'form' form}
def echo_to_hierarchy text_object parent text_objectwhile parent._parent parent parent._parentdef _do_print text_object indent '' 'printsrecursively.'debug indent + as_unicode text_object try for child in text_object._children _do_print child indent indent + '' except AttributeError pass_do_print parent
def read_raw_fif fname allow_maxshield False preload False add_eeg_ref False verbose None return Raw fname fname allow_maxshield allow_maxshield preload preload add_eeg_ref add_eeg_ref verbose verbose
def addObserver section name target attr None dtype str callback None default None observers config.observers.setdefault section.lower name.lower {} if not attr tokens name.lower .split attr tokens[0] + ''.join t.title for t in tokens[1 ] log.debug 'Subscribing%s.%s' target attr attr intern attr targetref weakref.ref target observers.setdefault targetref attr callback val _getProperty section name dtype default setattr target attr val if callback callback val
def ExtractSharedMSVSSystemIncludes configs generator_flags all_system_includes OrderedSet configs[0].get 'msvs_system_include_dirs' [] for config in configs[1 ] system_includes config.get 'msvs_system_include_dirs' [] all_system_includes all_system_includes & OrderedSet system_includes if not all_system_includes return Noneenv GetGlobalVSMacroEnv GetVSVersion generator_flags expanded_system_includes OrderedSet [ExpandMacros include env for include in all_system_includes] if any [ '$' in include for include in expanded_system_includes] return Nonefor config in configs includes config.get 'msvs_system_include_dirs' [] if includes new_includes [i for i in includes if i not in all_system_includes ]config['msvs_system_include_dirs'] new_includesreturn expanded_system_includes
def get_default_currency company get_default_company if company return frappe.db.get_value u'Company' company u'default_currency'
def _close_event event params params['epochs'].drop params['bads'] params['epochs'].info['bads'] params['info']['bads']logger.info 'Channelsmarkedasbad %s' % params['epochs'].info['bads']
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def eglGetDisplay display EGL_DEFAULT_DISPLAY res _lib.eglGetDisplay display if not res or res EGL_NO_DISPLAY raise RuntimeError 'Couldnotcreatedisplay' return res
def enable_inheritance path objectType clear False dc daclConstants objectType dc.getObjectTypeBit objectType path dc.processPath path objectType return _set_dacl_inheritance path objectType True None clear
def explode_dn dn notypes 0 flags 0 if not dn return []dn_decomp str2dn dn flags rdn_list []for rdn in dn_decomp if notypes rdn_list.append '+'.join [escape_dn_chars avalue or '' for atype avalue dummy in rdn] else rdn_list.append '+'.join [' '.join atype escape_dn_chars avalue or '' for atype avalue dummy in rdn] return rdn_list
def only_ci decorated_func @wraps decorated_func def _inner_func *args **kwds if is_running_on_ci return decorated_func *args **kwds return _inner_func
def plan return s3_rest_controller rheader s3db.proc_rheader hide_filter True
def find_root_thrifts basedirs sources log None root_sources set sources for source in sources root_sources.difference_update find_includes basedirs source log log return root_sources
def test_dont_collect_non_function_callable testdir testdir.makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir.runpytest '-rw' result.stdout.fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def cgconfig_start return service_cgconfig_control 'start'
def password_change_email user from r2.lib.pages import PasswordChangeEmailreturn _system_email user.email PasswordChangeEmail user user .render style 'email' Email.Kind.PASSWORD_CHANGE user user
def ParseIndexDefinitions document open_fn None try return yaml_object.BuildSingleObject IndexDefinitions document except yaml_errors.EmptyConfigurationFile return None
def test_init_custom_parameters tpot_obj TPOTClassifier population_size 500 generations 1000 mutation_rate 0.05 crossover_rate 0.9 scoring 'accuracy' num_cv_folds 10 verbosity 1 random_state 42 disable_update_check True assert tpot_obj.population_size 500 assert tpot_obj.generations 1000 assert tpot_obj.mutation_rate 0.05 assert tpot_obj.crossover_rate 0.9 assert tpot_obj.scoring_function 'accuracy' assert tpot_obj.num_cv_folds 10 assert tpot_obj.max_time_mins is None assert tpot_obj.verbosity 1 assert tpot_obj._optimized_pipeline is None assert tpot_obj._fitted_pipeline is None assert not tpot_obj._pset is None assert not tpot_obj._toolbox is None
def GetRemoteAppId servername path auth_func rpc_server_factory appengine_rpc.HttpRpcServer rtok None secure False save_cookies False server rpc_server_factory servername auth_func GetUserAgent GetSourceName save_cookies save_cookies debug_data False secure secure app_id GetRemoteAppIdFromServer server path rtok return app_id server
def sig_mult s m return sig monomial_mul s[0] m s[1]
def create_upload_url success_path max_bytes_per_blob None max_bytes_total None rpc None gs_bucket_name None rpc create_upload_url_async success_path max_bytes_per_blob max_bytes_per_blob max_bytes_total max_bytes_total rpc rpc gs_bucket_name gs_bucket_name return rpc.get_result
def copy_descriptor descriptor newname None if newname is None newname descriptor.nameif descriptor.is_discrete newf Orange.data.DiscreteVariable newname values descriptor.values base_value descriptor.base_value ordered descriptor.ordered newf.attributes dict descriptor.attributes elif descriptor.is_continuous newf Orange.data.ContinuousVariable newname newf.number_of_decimals descriptor.number_of_decimalsnewf.attributes dict descriptor.attributes else newf type descriptor newname newf.attributes dict descriptor.attributes return newf
def task_status_update_many context data_dict results []model context['model']deferred context.get 'defer_commit' context['defer_commit'] Truefor data in data_dict['data'] results.append _get_action 'task_status_update' context data if not deferred context.pop 'defer_commit' if not context.get 'defer_commit' model.Session.commit return {'results' results}
def _match_impl expr op other **kw return _boolean_compare expr operators.match_op _check_literal expr operators.match_op other result_type type_api.MATCHTYPE negate operators.notmatch_op if op is operators.match_op else operators.match_op **kw
def uniform_cdf x if x < 0 return 0elif x < 1 return xelse return 1
def is_lucas_prp n n as_int n if n 2 return Trueif n < 2 or n % 2 0 return Falseif is_square n False return False D P Q _lucas_selfridge_params n if D 0 return False U V Qk _lucas_sequence n P Q n + 1 return U 0
def is_gtk_desktop if sys.platform.startswith 'linux' xdg_desktop os.environ.get 'XDG_CURRENT_DESKTOP' '' if xdg_desktop gtk_desktops ['Unity' 'GNOME' 'XFCE']if any [xdg_desktop.startswith d for d in gtk_desktops] return Trueelse return Falseelse return Falseelse return False
def create_url hostname port None isSecure False if port is not None netloc '%s %d' % hostname port elif isSecure netloc u'{} 443'.format hostname else netloc u'{} 80'.format hostname if isSecure scheme u'rss'else scheme u'rs'return u'{} //{}'.format scheme netloc
def _do_lin_field_coeff bem_rr tris tn ta rmags cosmags ws bins coeff np.zeros bins[ -1 ] + 1 len bem_rr for tri tri_nn tri_area in zip tris tn ta tri_rr bem_rr[tri]zz []for trr in tri_rr diff rmags - trr dl np.sum diff * diff axis 1 c fast_cross_3d diff tri_nn[np.newaxis ] x tri_area * np.sum c * cosmags axis 1 / 3.0 * dl * np.sqrt dl zz + [np.bincount bins weights x * ws minlength bins[ -1 ] + 1 ]coeff[ tri] + np.array zz .Treturn coeff
def find_file path tgt_env 'base' **kwargs fnd {'path' '' 'rel' ''}if os.path.isabs path or tgt_env not in envs return fndfor repo in init env_root _env_root repo tgt_env if env_root is None continueif repo['mountpoint'] and not path.startswith repo['mountpoint'] + os.path.sep continuerepo_path path[len repo['mountpoint'] ].lstrip os.path.sep if repo['root'] repo_path os.path.join repo['root'] repo_path full os.path.join env_root repo_path if os.path.isfile full fnd['rel'] pathfnd['path'] fulltry fnd['stat'] list os.stat full except Exception passreturn fndreturn fnd
def as_url scheme host None port None user None password None path None query None sanitize False mask u'**' parts [u'{0} //'.format scheme ]if user or password if user parts.append safequote user if password if sanitize parts.extend [u' ' mask] if mask else [u' '] else parts.extend [u' ' safequote password ] parts.append u'@' parts.append safequote host if host else u'' if port parts.extend [u' ' port] parts.extend [u'/' path] return u''.join str part for part in parts if part
def package_finder argv try command InstallCommand except TypeError from pip.baseparser import create_main_parsercommand InstallCommand create_main_parser options _ loads dumps command.parser .parse_args argv possible_options ['find_links' FORMAT_CONTROL_ARG 'allow_external' 'allow_unverified' 'allow_all_external' 'allow_all_prereleases' 'pre' 'process_dependency_links']kwargs {}for option in possible_options kw attr option if isinstance option tuple else option option value getattr options attr MARKER if value is not MARKER kwargs[kw] valueindex_urls [options.index_url] + options.extra_index_urls if options.no_index index_urls []index_urls + getattr options 'mirrors' [] if hasattr command '_build_session' kwargs['session'] command._build_session options return PackageFinder index_urls index_urls **kwargs
def get_view_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'view_page' check_global check_global use_cache use_cache return page_ids
def setLastRefresh exList cache_db_con db.DBConnection 'cache.db' cache_db_con.upsert 'scene_exceptions_refresh' {'last_refreshed' int time.mktime datetime.datetime.today .timetuple } {'list' exList}
def require_playable handler def test_can_play self exploration_id **kwargs if exploration_id in feconf.DISABLED_EXPLORATION_IDS self.render_template 'pages/error/disabled_exploration.html' iframe_restriction None returnif feconf.EXPLORATION_URL_EMBED_PREFIX in self.request.uri or self.request.get 'iframed' self.values['iframed'] Trueif rights_manager.Actor self.user_id .can_play feconf.ACTIVITY_TYPE_EXPLORATION exploration_id return handler self exploration_id **kwargs else raise self.PageNotFoundExceptionreturn test_can_play
def addFeatures features simplify GIS.simplify_f []append _f.appendfor feature in features geojson simplify feature output 'geojson' if geojson f dict type 'Feature' geometry json.loads geojson append f return _f
def gettempdirb return _os.fsencode gettempdir
def test_timeit_special_syntax @register_line_magicdef lmagic line ip get_ipython ip.user_ns['lmagic_out'] line_ip.run_line_magic 'timeit' '-n1-r1%lmagicmyline' nt.assert_equal _ip.user_ns['lmagic_out'] 'myline' _ip.run_cell_magic 'timeit' '-n1-r1' '%lmagicmyline2' nt.assert_equal _ip.user_ns['lmagic_out'] 'myline2'
def DEFINE_float name default help CONFIG.AddOption type_info.Float name name default default description help
def write_output pin value import Adafruit_BBIO.GPIO as GPIOGPIO.output pin value
def fix_code source options None encoding None apply_config False options _get_options options apply_config if not isinstance source unicode source source.decode encoding or get_encoding sio io.StringIO source return fix_lines sio.readlines options options
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def detect_gzip contents return contents[ 2] '\x1f\x8b'
def isLineIntersectingInsideXSegment beginComplex endComplex segmentFirstX segmentSecondX y xIntersection getXIntersectionIfExists beginComplex endComplex y if xIntersection None return Falseif xIntersection < min segmentFirstX segmentSecondX return Falsereturn xIntersection < max segmentFirstX segmentSecondX
def sessions app url 'http //localhost 8080/manager' timeout 180 return _simple_cmd 'sessions' app url timeout timeout
def list_namespace namespace type_pattern filter ignore_case False show_all False pattern_list filter.split '.' if len pattern_list 1 return filter_ns namespace name_pattern pattern_list[0] type_pattern type_pattern ignore_case ignore_case show_all show_all else filtered filter_ns namespace name_pattern pattern_list[0] type_pattern 'all' ignore_case ignore_case show_all show_all results {}for name obj in filtered.items ns list_namespace dict_dir obj type_pattern '.'.join pattern_list[1 ] ignore_case ignore_case show_all show_all for inner_name inner_obj in ns.items results[ '%s.%s' % name inner_name ] inner_objreturn results
def test_ada_fit_single_class ada ADASYN random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning ada.fit X y_single_class
def _parse_homehub_response data_str root ET.fromstring data_str dirty_json root.find 'known_device_list' .get 'value' clean_json unquote dirty_json.replace "'" '"' .replace '{' '{"' .replace ' "' '" "' .replace '" ' '" "' known_devices [x for x in json.loads clean_json if x]devices {}for device in known_devices name device.get 'name' mac device.get 'mac' if _MAC_REGEX.match mac or ' ' in mac for mac_addr in mac.split ' ' if _MAC_REGEX.match mac_addr devices[mac_addr] nameelse devices[mac] namereturn devices
def fromPickle filename f open filename contents cPickle.load f f.close return contents
def _calculate lemmas stems n sum len lemmas[word] for word in lemmas gdmt gdnt gumt gwmt 0.0 0.0 0.0 0.0 for lemma in lemmas lemmacount len lemmas[lemma] gdmt + lemmacount * lemmacount - 1 gdnt + lemmacount * n - lemmacount umt wmt _calculate_cut lemmas[lemma] stems gumt + umtgwmt + wmtreturn gumt / 2 gdmt / 2 gwmt / 2 gdnt / 2
def enabled2py val try return LDAP_VALUES[val]except KeyError passtry return int val except ValueError passreturn utf8_decode val
def fix_case name for s r in LOCALE_NORMALIZATION.items name name.replace s r return name
def list_ostypes return list_items 'ostypes' True 'ID'
def getLoopWithoutCloseEnds close loop if len loop < 2 return loopif abs loop[0] - loop[ -1 ] > close return loopreturn loop[ -1 ]
def parse_autopart rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--type' dest 'type' action 'store' parser.add_argument '--encrypted' dest 'encrypted' action 'store_true' parser.add_argument '--passphrase' dest 'passphrase' action 'store' parser.add_argument '--escrowcert' dest 'escrowcert' action 'store' parser.add_argument '--backuppassphrase' dest 'backuppassphrase' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
def server_power status host None admin_username None admin_password None module None return __execute_cmd 'serveraction{0}'.format status host host admin_username admin_username admin_password admin_password module module
def guess_first_nonoption gparser subcmds_map gparser copy.deepcopy gparser def print_usage_nousage self file None passgparser.print_usage print_usage_nousageprev_interspersed gparser.allow_interspersed_argsgparser.disable_interspersed_args cwords os.environ['COMP_WORDS'].split error_func gparser.errortry instancemethod type OptionParser.error gparser.error instancemethod error_override gparser OptionParser gopts args gparser.parse_args cwords[1 ] except SystemExit return Nonefinally gparser.error instancemethod error_func gparser OptionParser value Noneif args subcmdname args[0]try value subcmds_map[subcmdname]except KeyError passgparser.allow_interspersed_args prev_interspersedreturn value
def predict_false args return False
def response_namespace k v if k[ 8] 'headers.' cherrypy.serving.response.headers[k.split '.' 1 [1]] velse setattr cherrypy.serving.response k v
def test_import_gzip_reader data file __file__ .read data_gz_sio cStringIO.StringIO gz gzip.GzipFile fileobj data_gz_sio mode 'wb' gz.write data gz.close data_gz data_gz_sio.getvalue old_peek_size beeswax.create_table.IMPORT_PEEK_SIZEbeeswax.create_table.IMPORT_PEEK_SIZE len data_gz - 1024 try reader beeswax.create_table.GzipFileReaderlines reader.readlines data_gz_sio 'utf-8' assert_true lines is not None lines_joined '\n'.join lines assert_equal data[ len lines_joined ] lines_joined finally beeswax.create_table.IMPORT_PEEK_SIZE old_peek_size
def file_info_from_modpath modpath path None context_file None if context_file is not None context os.path.dirname context_file else context context_fileif modpath[0] 'xml' try return _file_from_modpath ['_xmlplus'] + modpath[1 ] path context except ImportError return _file_from_modpath modpath path context elif modpath ['os' 'path'] return os.path.__file__ imp.PY_SOURCE return _file_from_modpath modpath path context
def hpsTimeScale hfreq hmag stocEnv timeScaling if timeScaling.size % 2 ! 0 raise ValueError 'Timescalingarraydoesnothaveanevensize' L hfreq[ 0].sizemaxInTime max timeScaling[ 2] maxOutTime max timeScaling[1 2] outL int L * maxOutTime / maxInTime inFrames L - 1 * timeScaling[ 2] / maxInTime outFrames outL * timeScaling[1 2] / maxOutTime timeScalingEnv interp1d outFrames inFrames fill_value 0 indexes timeScalingEnv np.arange outL yhfreq hfreq[round indexes[0] ]yhmag hmag[round indexes[0] ]ystocEnv stocEnv[round indexes[0] ]for l in indexes[1 ] yhfreq np.vstack yhfreq hfreq[round l ] yhmag np.vstack yhmag hmag[round l ] ystocEnv np.vstack ystocEnv stocEnv[round l ] return yhfreq yhmag ystocEnv
def addXIntersectionIndexesFromXIntersections index xIntersectionIndexList xIntersections for xIntersection in xIntersections xIntersectionIndexList.append XIntersectionIndex index xIntersection
def category_structure category site return {'description' category.title 'htmlUrl' '%s //%s%s' % PROTOCOL site.domain category.get_absolute_url 'rssUrl' '%s //%s%s' % PROTOCOL site.domain reverse 'zinnia category_feed' args [category.tree_path] 'categoryId' category.pk 'parentId' category.parent and category.parent.pk or 0 'categoryDescription' category.description 'categoryName' category.title}
def remove_task_app project_directory task_app_location os.path.join PROJECT_DIRECTORY '{{cookiecutter.project_slug}}/taskapp' shutil.rmtree task_app_location
def plugin_unloaded bh_thread.kill bh_regions.clear_all_regions
def putchunk fp cid *data data ''.join data fp.write o32 len data + cid fp.write data hi lo Image.core.crc32 data Image.core.crc32 cid fp.write o16 hi + o16 lo
def chordal_graph_cliques G if not is_chordal G raise nx.NetworkXError 'Inputgraphisnotchordal.' cliques set for C in nx.connected.connected_component_subgraphs G cliques | _connected_chordal_graph_cliques C return cliques
def trim_makeopts value return trim_var 'MAKEOPTS' value
def conv_mul lin_op rh_val transpose False is_abs False constant mul lin_op.data {} is_abs constant rh_val map intf.from_1D_to_2D [constant rh_val] if transpose constant np.flipud constant return fftconvolve rh_val constant mode 'valid' elif constant.size > rh_val.size return fftconvolve constant rh_val mode 'full' else return fftconvolve rh_val constant mode 'full'
def get url conn urlopen url resp conn.read conn.close return resp
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def xl_cell_to_rowcol cell_str if not cell_str return 0 0 match range_parts.match cell_str col_str match.group 2 row_str match.group 4 expn 0col 0for char in reversed col_str col + ord char - ord 'A' + 1 * 26 ** expn expn + 1row int row_str - 1 col - 1return row col
def reset noGamma True OK init if noGamma and OK setVideoMode NOGAMMACORRECT
def dipole_potential x y r_sq x ** 2 + y ** 2 theta np.arctan2 y x z np.cos theta / r_sq return np.max z - z / np.max z - np.min z
@with_intl_app buildername 'html' cleanenv True def test_i18n_footnote_break_refid app app.builder.build ['footnote'] result app.outdir / 'footnote.html' .text encoding 'utf-8'
def find_field name field_list related_query if related_query matches [f for f in field_list if f.field.related_query_name name ]else matches [f for f in field_list if f.name name ]if len matches ! 1 return Nonereturn matches[0]
def get_unity data value 1 data_copy data.copy data_copy['_charts_ones'] valuereturn data_copy['_charts_ones']
def _format_nsn number metadata num_format carrier_code None intl_number_formats metadata.intl_number_formatif len intl_number_formats 0 or num_format PhoneNumberFormat.NATIONAL available_formats metadata.number_formatelse available_formats metadata.intl_number_formatformatting_pattern _choose_formatting_pattern_for_number available_formats number if formatting_pattern is None return numberelse return _format_nsn_using_pattern number formatting_pattern num_format carrier_code
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def str_to_array s import numpy as npfrom numpy import inf nanif s.startswith u'array' s s[6 -1 ]if s.startswith u'[' a np.array eval s dtype float else a np.atleast_1d float s return a
def discard_config return __proxy__['napalm.call'] 'discard_config' **{}
def org_site_staff_config r table current.s3db.hrm_human_resourcesettings current.deployment_settingsif settings.has_module 'vol' if settings.get_hrm_show_staff if settings.get_org_site_volunteers field table.typefield.label current.T 'Type' field.readable field.writable Trueelif settings.get_org_site_volunteers table.type.default 2field table.organisation_idfield.default r.record.organisation_idfield.writable Falsefield.comment None
def getIdleDelay **kwargs _gsession _GSettings user kwargs.get 'user' schema 'org.gnome.desktop.session' key 'idle-delay' return _gsession._get
def cxSet ind1 ind2 temp set ind1 ind1 & ind2ind2 ^ tempreturn ind1 ind2
def tabulate_summary certificates kubeconfigs etcd_certs router_certs registry_certs items certificates + kubeconfigs + etcd_certs + router_certs + registry_certs summary_results {'system_certificates' len certificates 'kubeconfig_certificates' len kubeconfigs 'etcd_certificates' len etcd_certs 'router_certs' len router_certs 'registry_certs' len registry_certs 'total' len items 'ok' 0 'warning' 0 'expired' 0}summary_results['expired'] len [c for c in items if c['health'] 'expired' ] summary_results['warning'] len [c for c in items if c['health'] 'warning' ] summary_results['ok'] len [c for c in items if c['health'] 'ok' ] return summary_results
def rs_hadamard_exp p1 inverse False R p1.ringif R.domain ! QQ raise NotImplementedErrorp R.zeroif not inverse for exp1 v1 in p1.items p[exp1] v1 / int ifac exp1[0] else for exp1 v1 in p1.items p[exp1] v1 * int ifac exp1[0] return p
def _is_ipython shell if 'IPython' not in sys.modules return Falsetry from IPython.core.interactiveshell import InteractiveShellexcept ImportError try from IPython.iplib import InteractiveShellexcept ImportError return Falsereturn isinstance shell InteractiveShell
def _handle_subset_cert_request config domains cert existing ' '.join cert.names question 'Youhaveanexistingcertificatethatcontainsaportionofthedomainsyourequested ref {0} {br}{br}Itcontainsthesenames {1}{br}{br}Yourequestedthesenamesforthenewcertificate {2}.{br}{br}Doyouwanttoexpandandreplacethisexistingcertificatewiththenewcertificate?'.format cert.configfile.filename existing ' '.join domains br os.linesep if config.expand or config.renew_by_default or zope.component.getUtility interfaces.IDisplay .yesno question 'Expand' 'Cancel' cli_flag '--expand' force_interactive True return 'renew' cert else reporter_util zope.component.getUtility interfaces.IReporter reporter_util.add_message 'Toobtainanewcertificatethatcontainsthesenameswithoutreplacingyourexistingcertificatefor{0} youmustusethe--duplicateoption.{br}{br}Forexample {br}{br}{1}--duplicate{2}'.format existing sys.argv[0] ''.join sys.argv[1 ] br os.linesep reporter_util.HIGH_PRIORITY raise errors.Error USER_CANCELLED
def hsv_value image_filter image *args **kwargs hsv color.rgb2hsv image[ 3] value hsv[ 2].copy value image_filter value *args **kwargs hsv[ 2] convert value hsv.dtype return color.hsv2rgb hsv
def encryptAES_http_request s http_key m md5.new m.update http_key http_key m.hexdigest http_key str http_key cipher AES.new http_key encrypted EncodeAES cipher s return encrypted http_key
def get_service_account_name deadline None rpc create_rpc deadline make_get_service_account_name_call rpc rpc.wait return rpc.get_result
def user_can_edit_setting_type user model return user.has_perm u'{}.change_{}'.format model._meta.app_label model._meta.model_name
def _getYearCentRE cent 0 3 distance 3 now MyTime.now MyTime.alternateNow cent lambda year f cent[0] t cent[1] str year [f t] exprset set cent now[0].year + i for i in -1 distance if len now and now[1] exprset | set cent now[1].year + i for i in -1 distance return ' ? %s ' % '|'.join exprset if len exprset > 1 else ''.join exprset
def _parse_tokens tokens index 0parsed_tokens []num_tokens len tokens while index < num_tokens tok Token *tokens[index] assert tok.token_type ! token.INDENT if tok.token_type tokenize.NEWLINE breakif tok.token_string in u' [{' container index _parse_container tokens index if not container return Noneparsed_tokens.append container else parsed_tokens.append Atom tok index + 1return parsed_tokens
def softmax_numpy x stable_x x.T - x.max axis 1 .Tnumer np.exp stable_x return numer.T / numer.sum axis 1 .T
def safe_union a b if not isinstance a list raise TypeError 'Expectedfirstargumenttobealist butgot' + str type a assert isinstance b list c []for x in a + b if x not in c c.append x return c
def getTricomplexTimesOther firstTricomplex otherTricomplex tricomplexTimesOther [getTricomplexTimesColumn firstTricomplex otherTricomplex[0] ]tricomplexTimesOther.append getTricomplexTimesColumn firstTricomplex otherTricomplex[1] tricomplexTimesOther.append getTricomplexTimesColumn firstTricomplex otherTricomplex[2] + firstTricomplex[2] return tricomplexTimesOther
def get_meth_class obj if PY2 return obj.im_classelse return obj.__self__.__class__
def detrend_mean x axis None x np.asarray x if axis is not None and axis + 1 > x.ndim raise ValueError u'axis %s outofbounds' % axis if not x.ndim return np.array 0.0 dtype x.dtype if axis 0 or axis is None or x.ndim < 1 return x - x.mean axis ind [slice None ] * x.ndim ind[axis] np.newaxisreturn x - x.mean axis [ind]
def subtract_mean_percentile image selem out None mask None shift_x False shift_y False p0 0 p1 1 return _apply percentile_cy._subtract_mean image selem out out mask mask shift_x shift_x shift_y shift_y p0 p0 p1 p1
def parse_count source return source.get_while DIGITS
def is_leap_year builder year_val actual_year builder.add year_val Constant.int DATETIME64 1970 multiple_of_4 cgutils.is_null builder builder.and_ actual_year Constant.int DATETIME64 3 not_multiple_of_100 cgutils.is_not_null builder builder.srem actual_year Constant.int DATETIME64 100 multiple_of_400 cgutils.is_null builder builder.srem actual_year Constant.int DATETIME64 400 return builder.and_ multiple_of_4 builder.or_ not_multiple_of_100 multiple_of_400
def load_manifest package_name bootstrap_version '0.7' if package_name in _bootstrapped returnsys.path _generate_python_path package_name _rospack + sys.path
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _change_uid_gid uid gid None if not os.geteuid 0 returnos.setgid gid os.setuid uid
def return_json_file request match CONTENT_TYPE_RE.match request.META['CONTENT_TYPE'] if match charset match.group 1 else charset settings.DEFAULT_CHARSETobj_dict json.loads request.body.decode charset obj_json json.dumps obj_dict cls DjangoJSONEncoder ensure_ascii False response HttpResponse obj_json.encode charset status 200 content_type 'application/json;charset %s' % charset response['Content-Disposition'] 'attachment;filename testfile.json'return response
def connection_info_for db_or_uri if db_or_uri.startswith 'postgresql //' 'postgres //' us urlparse.urlsplit db_or_uri if len us.path > 1 db_name us.path[1 ]elif us.username db_name us.usernameelse db_name us.hostnamereturn db_name {'dsn' db_or_uri} connection_info {'database' db_or_uri}for p in 'host' 'port' 'user' 'password' cfg tools.config[ 'db_' + p ]if cfg connection_info[p] cfgreturn db_or_uri connection_info
def getNewDerivation elementNode return GridDerivation elementNode
def needs_renewal name window None if window is not None and window in 'force' 'Force' True return Truereturn _renew_by name window < datetime.datetime.today
def get_mnist withlabel True ndim 1 scale 1.0 dtype numpy.float32 label_dtype numpy.int32 train_raw _retrieve_mnist_training train _preprocess_mnist train_raw withlabel ndim scale dtype label_dtype test_raw _retrieve_mnist_test test _preprocess_mnist test_raw withlabel ndim scale dtype label_dtype return train test
def make_clique_bipartite G fpos None create_using None name None B create_using if create_using is not None else networkx.Graph B.clear B.add_nodes_from G bipartite 1 for i cl in enumerate find_cliques G name - i - 1 B.add_node name bipartite 0 B.add_edges_from v name for v in cl return B
def primorial n nth True if nth n as_int n else n int n if n < 1 raise ValueError 'primorialargumentmustbe> 1' p 1if nth for i in range 1 n + 1 p * prime i else for i in primerange 2 n + 1 p * ireturn p
def fsencoding s encoding sys.getfilesystemencoding if isinstance s unicode s s.encode encoding return s
def remove_masquerade zone None permanent True if zone cmd '--zone {0}--remove-masquerade'.format zone else cmd '--remove-masquerade'if permanent cmd + '--permanent'return __firewall_cmd cmd
def normalize_dotted_fields document if isinstance document list prev documentfor i in prev normalize_dotted_fields i elif isinstance document dict for field in list document if '.' in field parts field.split '.' prev documentfor part in parts[ -1 ] if part not in prev prev[part] {}prev prev[part]if isinstance document[field] dict list normalize_dotted_fields document[field] prev[parts[ -1 ]] document[field]document.pop field elif isinstance document[field] dict list normalize_dotted_fields document[field]
def demo_grid_with_single_cbar fig grid ImageGrid fig 142 nrows_ncols 2 2 axes_pad 0.0 share_all True label_mode 'L' cbar_location 'top' cbar_mode 'single' Z extent get_demo_image for i in range 4 im grid[i].imshow Z extent extent interpolation 'nearest' grid.cbar_axes[0].colorbar im for cax in grid.cbar_axes cax.toggle_label False grid.axes_llc.set_xticks [ -2 0 2] grid.axes_llc.set_yticks [ -2 0 2]
def ion matplotlib.interactive True install_repl_displayhook
def haddr_to_int addr try return int addr.replace ' ' '' 16 except raise ValueError
def test_bool_symbol assert And A True A assert And A True True A assert And A False is false assert And A True False is false assert Or A True is true assert Or A False A
def _scale_params subject_to subject_from scale subjects_dir subjects_dir get_subjects_dir subjects_dir raise_error True if subject_from is None ! scale is None raise TypeError 'Needtoprovideeitherbothsubject_fromandscaleparameters orneither.' if subject_from is None cfg read_mri_cfg subject_to subjects_dir subject_from cfg['subject_from']n_params cfg['n_params']scale cfg['scale']else scale np.asarray scale if scale.ndim 0 n_params 1elif scale.shape 3 n_params 3else raise ValueError 'Invalidshapeforscaleparameer.Needscalarorarrayoflength3.Got%s.' % str scale if n_params 1 nn_scale Noneelif n_params 3 nn_scale 1.0 / scale else raise RuntimeError 'Invalidn_paramsvalue %s' % repr n_params return subjects_dir subject_from scale nn_scale
def mine_on_chain chain parent None transactions [] coinbase None if not parent parent chain.headif coinbase chain.coinbase coinbasechain._update_head parent for t in transactions chain.add_transactions t assert chain.head_candidate.difficulty 1 m ethpow.Miner chain.head_candidate rounds 100nonce 0while True b m.mine rounds rounds start_nonce nonce if b breaknonce + roundsassert b.header.check_pow chain.add_block b return b
def get_bearing aLocation1 aLocation2 off_x aLocation2.lon - aLocation1.lon off_y aLocation2.lat - aLocation1.lat bearing 90.0 + math.atan2 - off_y off_x * 57.2957795 if bearing < 0 bearing + 360.0return bearing
def _cleanup for inst in _ACTIVE[ ] res inst.isalive if res is not True try _ACTIVE.remove inst except ValueError pass
def reboot zone single False altinit None smf_options None ret {'status' True}boot_options ''if single boot_options '-s{0}'.format boot_options if altinit boot_options '-i{0}{1}'.format altinit boot_options if smf_options boot_options '-m{0}{1}'.format smf_options boot_options if boot_options ! '' boot_options '--{0}'.format boot_options.strip res __salt__['cmd.run_all'] 'zoneadm{zone}reboot{boot_opts}'.format zone '-u{0}'.format zone if _is_uuid zone else '-z{0}'.format zone boot_opts boot_options ret['status'] res['retcode'] 0 ret['message'] res['stdout'] if ret['status'] else res['stderr'] ret['message'] ret['message'].replace 'zoneadm ' '' if ret['message'] '' del ret['message']return ret
def parseApplication app return Direction app[0] app[1 ]
def encodestring s pieces []for i in range 0 len s MAXBINSIZE chunk s[i i + MAXBINSIZE ]pieces.append binascii.b2a_base64 chunk return ''.join pieces
def getBranchMatrix elementNode branchMatrix Matrix matrixChildElement elementNode.getFirstChildByLocalName 'matrix' if matrixChildElement ! None branchMatrix branchMatrix.getFromElementNode matrixChildElement '' branchMatrix branchMatrix.getFromElementNode elementNode 'matrix.' if elementNode.xmlObject None return branchMatrixelementNodeMatrix elementNode.xmlObject.getMatrix4X4 if elementNodeMatrix None return branchMatrixreturn elementNodeMatrix.getOtherTimesSelf branchMatrix.tetragrid
def dup_gf_sqf_list f K all False f dup_convert f K K.dom coeff factors gf_sqf_list f K.mod K.dom all all for i f k in enumerate factors factors[i] dup_convert f K.dom K k return K.convert coeff K.dom factors
def rslice n allow_empty False minlen 0 if allow_empty or n 0 else 1 slicelen randrange minlen n + 1 return randslice_from_slicelen slicelen n
def GetRequestContext global _threadLocalContextreturn _threadLocalContext.__dict__.setdefault 'reqCtx' StringDict
def address_ ret {}cmd 'hciconfig'out __salt__['cmd.run'] cmd .splitlines dev ''for line in out if line.startswith 'hci' comps line.split ' ' dev comps[0]ret[dev] {'device' dev 'path' '/sys/class/bluetooth/{0}'.format dev }if 'BDAddress' in line comps line.split ret[dev]['address'] comps[2]if 'DOWN' in line ret[dev]['power'] 'off'if 'UPRUNNING' in line ret[dev]['power'] 'on'return ret
def pem2der pem_string pem_string pem_string.replace '\r' '' first_idx pem_string.find '-----\n' + 6 if pem_string.find '-----BEGIN' first_idx ! -1 raise Exception 'pem2der expectsonlyonePEM-encodedobject' last_idx pem_string.rfind '-----' 0 pem_string.rfind '-----' base64_string pem_string[first_idx last_idx]base64_string.replace '\n' '' der_string base64.b64decode base64_string return der_string
def get_string string_index_node rich_nodes string_index_node.findall '{%s}r' % SHEET_MAIN_NS if rich_nodes reconstructed_text []for rich_node in rich_nodes partial_text get_text rich_node reconstructed_text.append partial_text return unicode ''.join reconstructed_text return get_text string_index_node
def srun cmd **kwargs return run 'sudo' + cmd **kwargs
def assert_mail_count count msg None from django.core import mailif msg is None msg u' '.join [e.subject for e in mail.outbox] msg u'%d! %d%s' % len mail.outbox count msg assert_equals len mail.outbox count msg
def coerce_url_to_protocol url protocol 'http' parsed_url UrlParser url parsed_url.scheme protocolreturn parsed_url.unparse
def write_log_file log_data log_f log_f.write 'Detailsforremovalofreverseprimers\n' log_f.write 'Originalfastafilepath %s\n' % log_data['fasta_fp'] log_f.write 'Totalseqsinfasta %d\n' % log_data['total_seqs'] log_f.write 'Mappingfilepath %s\n' % log_data['mapping_fp'] log_f.write 'Truncationoption %s\n' % log_data['truncate_option'] log_f.write 'Mismatchesallowed %d\n' % log_data['primer_mismatches'] log_f.write 'Totalseqswritten %d\n' % log_data['seqs_written'] log_f.write 'SampleIDsnotfound %d\n' % log_data['sample_id_not_found'] log_f.write 'Reverseprimersnotfound %d\n' % log_data['reverse_primer_not_found']
def dmp_primitive_prs f g u K if not u return dup_primitive_prs f g K else raise MultivariatePolynomialError f g
def print_item item product item['product']print '-%s[%s] %s ' % product['title'] product['author']['name'] product['link']
def get_human_readable_time_string time_msec return time.strftime '%B%d%H %M %S' time.gmtime time_msec / 1000.0
def shall_skip module opts if path.getsize module < 2 return Truefilename path.basename module if filename ! '__init__.py' and filename.startswith '_' and not opts.includeprivate return Truereturn False
def CDLHIKKAKEMOD barDs count return call_talib_with_ohlc barDs count talib.CDLHIKKAKEMOD
def _search quidditch retries 5 passed Falseclean Truecomment ''while not passed log.debug 'Searching.triesleft {0}'.format retries passed quidditch.AutoSearch log.debug 'Donesearching {0}'.format str passed if isinstance passed Exception clean Falsecomment + 'Failedintheseeking/parsingprocess \n DCTB DCTB {0}\n'.format passed retries - 1if retries comment + '{0}triestogo.retrying\n'.format str retries else comment + 'outofretries.thisupdateroundfailed.\n'return comment True retries passed Falseif clean comment + 'Searchwasdonewithouterror.\n'return comment True retries
def critical_pair f g ring domain ring.domainltf Polyn f .LTltg Polyn g .LTlt monomial_lcm ltf[0] ltg[0] domain.one um term_div lt ltf domain vm term_div lt ltg domain fr lbp_mul_term lbp Sign f Polyn f .leading_term Num f um gr lbp_mul_term lbp Sign g Polyn g .leading_term Num g vm if lbp_cmp fr gr -1 return Sign gr vm g Sign fr um f else return Sign fr um f Sign gr vm g
def _codons2re codons reg ''for i in izip *codons if len set i 1 reg + ''.join set i else reg + '[' + ''.join set i + ']' return reg
def _multinomial_loss_grad w X Y alpha sample_weight n_classes Y.shape[1]n_features X.shape[1]fit_intercept w.size n_classes * n_features + 1 grad np.zeros n_classes n_features + bool fit_intercept loss p w _multinomial_loss w X Y alpha sample_weight sample_weight sample_weight[ np.newaxis]diff sample_weight * p - Y grad[ n_features] safe_sparse_dot diff.T X grad[ n_features] + alpha * w if fit_intercept grad[ -1 ] diff.sum axis 0 return loss grad.ravel p
def add_course_milestone course_id relationship milestone if not settings.FEATURES.get 'MILESTONES_APP' return Nonereturn milestones_api.add_course_milestone course_id relationship milestone
def get_root_of doctype result frappe.db.sql_list u'selectnamefrom`tab%s`\n DCTB DCTB wherelft 1andrgt selectmax rgt from`tab%s`wheredocstatus<2 ' % doctype doctype return result[0] if result else None
def organisation_type return s3_rest_controller
def id_shown_with_wait context id_str **kwargs return _shown_elem_with_wait context By.ID id_str **kwargs
def loadAliasFile domains filename None fp None result {}if fp is None fp file filename else filename getattr fp 'name' '<unknown>' i 0prev ''for line in fp i + 1line line.rstrip if line.lstrip .startswith '#' continueelif line.startswith '' or line.startswith ' DCTB ' prev prev + line else if prev handle result prev filename i prev lineif prev handle result prev filename i for u a in result.items addr smtp.Address u result[u] AliasGroup a domains u return result
def volume_admin_metadata_update context volume_id metadata delete add True update True return IMPL.volume_admin_metadata_update context volume_id metadata delete add update
def send_msg_v2 module token room msg_from msg msg_format 'text' color 'yellow' notify False api NOTIFY_URI_V2 headers {'Authorization' 'Bearer%s' % token 'Content-Type' 'application/json'}body dict body['message'] msgbody['color'] colorbody['message_format'] msg_formatbody['notify'] notifyPOST_URL api + NOTIFY_URI_V2 url POST_URL.replace '{id_or_name}' urllib.pathname2url room data json.dumps body if module.check_mode module.exit_json changed False response info fetch_url module url data data headers headers method 'POST' if info['status'] in [200 204] return response.read else module.fail_json msg 'failedtosendmessage returnstatus %s' % str info['status']
def make_formatters config stream_openers default_stream_opener StreamOpener stream sys.stdout formatter_list []for i name in enumerate config.format stream_opener default_stream_openerif i < len stream_openers stream_opener stream_openers[i]formatter_class select_formatter_class name formatter_object formatter_class stream_opener config formatter_list.append formatter_object return formatter_list
def insert_enterprise_pipeline_elements pipeline if not enterprise_enabled returnadditional_elements 'enterprise.tpa_pipeline.set_data_sharing_consent_record' 'enterprise.tpa_pipeline.verify_data_sharing_consent' insert_point pipeline.index 'social.pipeline.social_auth.load_extra_data' for index element in enumerate additional_elements pipeline.insert insert_point + index element
def find_tag fid node findkind if node['directory'] is not None for subnode in node['directory'] if subnode.kind findkind return read_tag fid subnode.pos return None
def shorten_line tokens source indentation indent_word max_line_length aggressive False experimental False previous_line u'' for candidate in _shorten_line tokens tokens source source indentation indentation indent_word indent_word aggressive aggressive previous_line previous_line yield candidate if aggressive for key_token_strings in SHORTEN_OPERATOR_GROUPS shortened _shorten_line_at_tokens tokens tokens source source indentation indentation indent_word indent_word key_token_strings key_token_strings aggressive aggressive if shortened is not None and shortened ! source yield shortened if experimental for shortened in _shorten_line_at_tokens_new tokens tokens source source indentation indentation max_line_length max_line_length yield shortened
def redirect_param location params *args **kwargs return HttpResponseRedirect resolve_url location *args **kwargs + params
def test_install_package_with_utf8_setup script data to_install data.packages.join 'SetupPyUTF8' script.pip 'install' to_install
def get_pub_key vm_ return config.get_cloud_config_value 'ssh_pubkey' vm_ __opts__ search_global False
def filter_displayed_blocks block unused_view frag unused_context if getattr block 'show_in_read_only_mode' False return fragreturn Fragment _ u'Thistypeofcomponentcannotbeshownwhileviewingthecourseasaspecificstudent.'
def getNewRepository return FillRepository
def do_nothing return
def generate_ticket domain result __salt__['cmd.run'] 'icinga2pkiticket--cn{0}'.format domain return result
def notes document notes domhelpers.findElementsWithAttribute document 'class' 'note' notePrefix dom.parseString '<strong>Note </strong>' .documentElementfor note in notes note.childNodes.insert 0 notePrefix
def all_from_module module mod mod_import module if not mod return {}members getmembers mod predicate lambda obj getmodule obj in mod None return dict key val for key val in members if not key.startswith '_'
def Probability2 yes no return yes / yes + no
def agent_check_pass consul_url None checkid None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not checkid raise SaltInvocationError 'Requiredargument"checkid"ismissing.' if 'note' in kwargs query_params['note'] kwargs['note']function 'agent/check/pass/{0}'.format checkid res _query consul_url consul_url function function query_params query_params method 'GET' if res['res'] ret['res'] Trueret['message'] 'Check{0}markedaspassing.'.format checkid else ret['res'] Falseret['message'] 'Unabletoupdatecheck{0}.'.format checkid return ret
@with_setup prepare_stdout def test_background_with_header from lettuce import step world@step u'thevariable" \\w+ "holds \\d+ ' def set_variable step name value setattr world name int value @step u'thevariable" \\w+ "isequalto \\d+ ' def check_variable step name expected expected int expected expect world .to.have.property name .being.equal expected @step u'thevariable" \\w+ "times \\d+ isequalto \\d+ ' def multiply_and_verify step name times expected times int times expected int expected getattr world name * times .should.equal expected filename bg_feature_name 'header' runner Runner filename verbosity 1 runner.run assert_stdout_lines '..\n1feature 1passed \n2scenarios 2passed \n7steps 7passed \n'
def server_security_groups request instance_id security_groups []nclient novaclient request resp body nclient.client.get '/servers/%s/os-security-groups' % instance_id if body sg_objs [NovaSecurityGroup nclient.security_groups sg loaded True for sg in body.get 'security_groups' [] ]security_groups [SecurityGroup sg for sg in sg_objs]for sg in security_groups rule_objects [SecurityGroupRule rule for rule in sg.rules]sg.rules rule_objectsreturn security_groups
def is_threshold_graph G return is_threshold_sequence list d for n d in G.degree
def group_by_object stream stream iter stream current next stream current_key current.cls current.id group [current]for message in stream if message.cls message.id ! current_key yield current_key group group []group.append message current messagecurrent_key current.cls current.id yield current_key group
def _remove_in_process_courses courses in_process_course_actions def format_course_for_view course '\nReturnadictofthedatawhichtheviewrequiresforeachcourse\n'return {'display_name' course.display_name 'course_key' unicode course.location.course_key 'url' reverse_course_url 'course_handler' course.id 'lms_link' get_lms_link_for_item course.location 'rerun_link' _get_rerun_link_for_item course.id 'org' course.display_org_with_default 'number' course.display_number_with_default 'run' course.location.run}in_process_action_course_keys [uca.course_key for uca in in_process_course_actions]courses [format_course_for_view course for course in courses if not isinstance course ErrorDescriptor and course.id not in in_process_action_course_keys ]return courses
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_docker_client cluster address def get_path name return cluster.certificates_path.child name .pathtls TLSConfig client_cert get_path 'user.crt' get_path 'user.key' ssl_version ssl.PROTOCOL_TLSv1 assert_hostname False verify get_path 'cluster.crt' return dockerpy_client base_url 'https //{} {}'.format address DOCKER_PORT tls tls timeout 100 version '1.21'
def parse_host host default_port None if host.startswith '[' pos host.rfind '] ' if pos ! -1 return host[1 pos] int host[ pos + 2 ] else return host[1 -1 ] default_port pos host.rfind ' ' if pos -1 or pos ! host.find ' ' return host default_port name _ port host.partition ' ' return name int port
def invalid_email_reason email_address field if email_address is None return 'Noneemailaddressfor%s.' % field if isinstance email_address users.User email_address email_address.email if not isinstance email_address basestring return 'Invalidemailaddresstypefor%s.' % field stripped_address email_address.strip if not stripped_address return 'Emptyemailaddressfor%s.' % field return None
def load_and_handle_cert cert_string now base64decode False if base64decode _cert_string cert_string.decode 'base-64' else _cert_string cert_stringcert_loaded OpenSSL.crypto.load_certificate OpenSSL.crypto.FILETYPE_PEM _cert_string cert_serial cert_loaded.get_serial_number cert_subjects []for name value in cert_loaded.get_subject .get_components cert_subjects.append '{} {}'.format name value i 0checked_all_extensions Falsewhile not checked_all_extensions try ext cert_loaded.get_extension i except IndexError san Nonechecked_all_extensions Trueelse if ext.get_short_name 'subjectAltName' san extchecked_all_extensions Trueelse i + 1if san is not None cert_subjects.extend str san .split ' ' cert_subject ' '.join cert_subjects cert_expiry cert_loaded.get_notAfter cert_expiry_date datetime.datetime.strptime cert_expiry '%Y%m%d%H%M%SZ' time_remaining cert_expiry_date - now return cert_subject cert_expiry_date time_remaining cert_serial
def get_session stored_refresh_token service get_oauth_service r service.get_raw_access_token data {'refresh_token' stored_refresh_token 'grant_type' 'refresh_token'} return service.get_session r.json ['access_token']
@login_required@permission_required_or_403 'forums_forum.post_delete_forum' Forum 'slug__iexact' 'forum_slug' def delete_post request forum_slug thread_id post_id forum get_object_or_404 Forum slug forum_slug thread get_object_or_404 Thread pk thread_id forum forum post get_object_or_404 Post pk post_id thread thread if request.method 'GET' return render request 'forums/confirm_post_delete.html' {'forum' forum 'thread' thread 'post' post} log.warning 'User%sisdeletingpostwithid %s' % request.user post.id post.delete statsd.incr 'forums.delete_post' try Thread.objects.get pk thread_id goto reverse 'forums.posts' args [forum_slug thread_id] except Thread.DoesNotExist goto reverse 'forums.threads' args [forum_slug] return HttpResponseRedirect goto
def ccittFaxEncode stream parameters encodedStream ''return -1 'CcittFaxEncodenotsupportedyet'
def popup_inputbox title text par_widget h2 1w2 par_widget.width * 6 // 7 x par_widget.width - w2 // 2 - 1 + par_widget.x y par_widget.height - h2 // 2 - 1 + par_widget.y borders curses.newwin h2 + 2 w2 + 2 y x borders.border borders.addstr 0 w2 - len title // 2 '%s' % title borders.refresh return inputbox text x + 1 y + 1 w2 h2
@_uniquedef uninstallation_paths dist r csv.reader FakeFile dist.get_metadata_lines 'RECORD' for row in r path os.path.join dist.location row[0] yield path if path.endswith '.py' dn fn os.path.split path base fn[ -3 ]path os.path.join dn base + '.pyc' yield path
def get_host_name hostname get_address_override if not hostname try hostname socket.gethostname except passif not hostname or hostname 'localhost' or hostname.startswith '127.' hostname get_local_address return hostname
def _get_score_from_submissions submissions_scores block if submissions_scores submission_value submissions_scores.get unicode block.location if submission_value attempted True weighted_earned weighted_possible submission_valueassert weighted_earned > 0.0 and weighted_possible > 0.0 return None None + weighted_earned weighted_possible + attempted
def test_server_threading FileSystem.pushd current_directory 'django' 'coconut' status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 1' assert_equals status 0 out
def onlyif condition msg if callable condition skip_condition lambda not condition else skip_condition lambda not condition return skipif skip_condition msg
def _dumx_remove dumx dumx_flat p0 res []for dx in dumx if p0 not in dx res.append dx continuek dx.index p0 if k % 2 0 p0_paired dx[ k + 1 ]else p0_paired dx[ k - 1 ]dx.remove p0 dx.remove p0_paired dumx_flat.remove p0 dumx_flat.remove p0_paired res.append dx
def test_cache_existing_metadata_file config_stub tmpdir config_stub.data {'storage' {'cache-size' 1024} 'general' {'private-browsing' False}}url 'http //qutebrowser.org'content 'foobar'metadata QNetworkCacheMetaData metadata.setUrl QUrl url assert metadata.isValid disk_cache cache.DiskCache str tmpdir device disk_cache.prepare metadata assert device is not None device.write content disk_cache.insert device disk_cache.updateMetaData metadata files list tmpdir.visit fil lambda path path.isfile assert len files 1 assert disk_cache.fileMetaData str files[0] metadata
def register_save id driver SAVE[id.upper ] driver
def from_text rdclass rdtype ttl *text_rdatas return from_text_list rdclass rdtype ttl text_rdatas
def tensors_allclose a_tensors b_tensors rtol 0 atol 1e-07 if type a_tensors is not list and type b_tensors is not list a_tensors [a_tensors]b_tensors [b_tensors]results []for a_tensor b_tensor in zip a_tensors b_tensors if isinstance a_tensor Tensor a_tensor a_tensor.get if isinstance b_tensor Tensor b_tensor b_tensor.get results.append allclose_with_out a_tensor.astype b_tensor.dtype b_tensor rtol rtol atol atol return all results
def _find_common_roots paths paths [x.split os.path.sep for x in paths]root {}for chunks in sorted paths key len reverse True node rootfor chunk in chunks node node.setdefault chunk {} node.clear rv set def _walk node path for prefix child in iteritems node _walk child path + prefix if not node rv.add '/'.join path _walk root return rv
def template_instantiate call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thetemplate_instantiatefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}vm_name kwargs.get 'vm_name' None template_id kwargs.get 'template_id' None template_name kwargs.get 'template_name' None if vm_name is None raise SaltCloudSystemExit "Thetemplate_instantiatefunctionrequiresa'vm_name'tobeprovided." if template_id if template_name log.warning "Boththe'template_id'and'template_name'argumentswereprovided.'template_id'willtakeprecedence." elif template_name template_id get_template_id kwargs {'name' template_name} else raise SaltCloudSystemExit "Thetemplate_instantiatefunctionrequireseithera'template_id'ora'template_name'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.template.instantiate auth int template_id vm_name data {'action' 'template.instantiate' 'instantiated' response[0] 'instantiated_vm_id' response[1] 'vm_name' vm_name 'error_code' response[2]}return data
def getInteriorSegments loops segments interiorSegments []for segment in segments center 0.5 * segment[0].point + segment[1].point if euclidean.getIsInFilledRegion loops center interiorSegments.append segment return interiorSegments
def FormatClassToJava input return 'L' + input.replace '.' '/' + ';'
def muting md build_mute_dict dict_data True printNicely 'All ' + str len md + 'people.' for name in md user '' + cycle_color md[name] user + color_func c['TWEET']['nick'] '' + name + '' printNicely user c['IGNORE_LIST'] [n for n in md]
def getIdleActivation **kwargs _gsession _GSettings user kwargs.get 'user' schema 'org.gnome.desktop.screensaver' key 'idle-activation-enabled' return _gsession._get
def get_flinalg_funcs names arrays debug 0 ordering []for i in range len arrays t arrays[i].dtype.charif t not in _type_conv t 'd'ordering.append t i if ordering ordering.sort required_prefix _type_conv[ordering[0][0]]else required_prefix 'd'if ordering and has_column_major_storage arrays[ordering[0][1]] suffix1 suffix2 '_c' '_r' else suffix1 suffix2 '_r' '_c' funcs []for name in names func_name required_prefix + name func getattr _flinalg func_name + suffix1 getattr _flinalg func_name + suffix2 None funcs.append func return tuple funcs
def construct_streamreader_callback process handler implied_arg 0partial_args 0handler_to_inspect handlerif isinstance handler partial partial_args len handler.args handler_to_inspect handler.funcif inspect.ismethod handler_to_inspect implied_arg 1num_args get_num_args handler_to_inspect elif inspect.isfunction handler_to_inspect num_args get_num_args handler_to_inspect else implied_arg 1num_args get_num_args handler_to_inspect.__call__ net_args num_args - implied_arg - partial_args handler_args if net_args 1 handler_args if net_args 2 handler_args process.stdin elif net_args 3 handler_args process.stdin weakref.ref process def fn chunk args handler_argsif len args 2 args handler_args[0] handler_args[1] return handler chunk *args return fn
def get_static_index_page with_shutdown template '\n<!DOCTYPEHTMLPUBLIC"-//W3C//DTDHTML4.01Frameset//EN""http //www.w3.org/TR/html4/frameset.dtd">\n<HTML>\n<!--NaturalLanguageToolkit WordnetInterface GraphicalWordnetBrowser\nCopyright C 2001-2017NLTKProject\nAuthor JussiSalmela<jtsalmela@users.sourceforge.net>\nURL <http //nltk.org/>\nForlicenseinformation seeLICENSE.TXT-->\n<HEAD>\n<TITLE>NLTKWordnetBrowser</TITLE>\n</HEAD>\n\n<framesetrows "7%% 93%%">\n<framesrc "%s"name "header">\n<framesrc "start_page"name "body">\n</frameset>\n</HTML>\n'if with_shutdown upper_link 'upper.html'else upper_link 'upper_2.html'return template % upper_link
def p_rule_empty2 p p[3].insert 0 [] p[0] p[1] p[3]
def cuthill_mckee_ordering G heuristic None for c in nx.connected_components G for n in connected_cuthill_mckee_ordering G.subgraph c heuristic yield n
def list_nodes_min ret {}cmd '{0}listvms'.format vboxcmd for line in salt.modules.cmdmod.run cmd .splitlines if not line.strip continuecomps line.split name comps[0].replace '"' '' ret[name] Truereturn ret
def csr_managed name **kwargs old __salt__['x509.read_csr'] name file_args kwargs _get_file_args name **kwargs file_args['contents'] __salt__['x509.create_csr'] text True **kwargs ret __states__['file.managed'] **file_args if ret['changes'] new __salt__['x509.read_csr'] file_args['contents'] if old ! new ret['changes'] {'Old' old 'New' new}return ret
def _get_unicode data force False if isinstance data binary_type return data.decode u'utf-8' elif data is None return u''elif force if PY2 return unicode data else return str data else return data
def once_git_check_commit_title subp subprocess.Popen ['git' 'log' '--no-merges' '--pretty %s' '-1'] stdout subprocess.PIPE title subp.communicate [0]if subp.returncode raise Exception 'gitlogfailedwithcode%s' % subp.returncode git_keywords ' I[0-9a-f]{8 40} | [Bb]ug|[Ll][Pp] [\\s\\# ]* \\d+ | [Bb]lue[Pp]rint|[Bb][Pp] [\\s\\# ]* [A-Za-z0-9\\-]+ 'GIT_REGEX re.compile git_keywords error Falseif GIT_REGEX.search title is not None and len title.split < 3 print "N801 gitcommittitle '%s' shouldprovideanaccuratedescriptionofthechange notjustareferencetoabugorblueprint" % title.strip error Trueif len title.decode 'utf-8' > 72 print "N802 gitcommittitle '%s' shouldbeunder50chars" % title.strip error Truereturn error
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def gaussian_kl_divergence mean ln_var assert isinstance mean variable.Variable assert isinstance ln_var variable.Variable J mean.sizevar exponential.exp ln_var return sum.sum mean * mean + sum.sum var - sum.sum ln_var - J * 0.5
def auto_auth browser username email staff course_id AutoAuthPage browser username username email email course_id course_id staff staff .visit
def _is_ipv6_enabled if socket.has_ipv6 sock Nonetry sock socket.socket socket.AF_INET6 socket.SOCK_STREAM sock.bind HOSTv6 0 return Trueexcept socket.error passfinally if sock sock.close return False
def interpret_in_shape xshape if isinstance xshape int np.integer return xshape 1 elif len xshape 2 return xshapeelse return np.prod xshape 1
def test_iba_error_y_score_prob y_true y_pred _ make_prediction binary True aps make_index_balanced_accuracy alpha 0.5 squared True average_precision_score assert_raises AttributeError aps y_true y_pred brier make_index_balanced_accuracy alpha 0.5 squared True brier_score_loss assert_raises AttributeError brier y_true y_pred kappa make_index_balanced_accuracy alpha 0.5 squared True cohen_kappa_score assert_raises AttributeError kappa y_true y_pred ras make_index_balanced_accuracy alpha 0.5 squared True roc_auc_score assert_raises AttributeError ras y_true y_pred
def get_recommended_content_for_user account settings record_views False src SRC_EXPLORE prefs AccountSRPrefs.for_user account recs get_recommended_content prefs src settings if record_views sr_data {r.sr r.src for r in recs}AccountSRFeedback.record_views account sr_data return recs
def clobber_in_except node if isinstance node astroid.AssAttr return True node.attrname 'object%r' % node.expr.as_string elif isinstance node astroid.AssName name node.nameif is_builtin name return True name 'builtins' else stmts node.lookup name [1]if stmts and not isinstance stmts[0].ass_type astroid.Assign astroid.AugAssign astroid.ExceptHandler return True name 'outerscope line%s ' % stmts[0].fromlineno return False None
def min_edge_dominating_set G if not G raise ValueError 'Expectednon-emptyNetworkXgraph!' return maximal_matching G
def mosaic w imgs imgs iter imgs img0 imgs.next pad np.zeros_like img0 imgs it.chain [img0] imgs rows grouper w imgs pad return np.vstack map np.hstack rows
def unquote str return re_escaped_char.sub _sub_replacement str[1 -1 ]
def lambda_notation tokens local_dict global_dict result []flag False toknum tokval tokens[0]tokLen len tokens if toknum NAME and tokval 'lambda' if tokLen 2 result.extend tokens elif tokLen > 2 result.extend [ NAME 'Lambda' OP ' ' OP ' ' OP ' ' OP ' ' ] for tokNum tokVal in tokens[1 ] if tokNum OP and tokVal ' ' tokVal ' 'flag Trueif not flag and tokNum OP and tokVal in ['*' '**'] raise TokenError 'Starredargumentsinlambdanotsupported' if flag result.insert -1 tokNum tokVal else result.insert -2 tokNum tokVal else result.extend tokens return result
def test_classification_report_imbalanced_multiclass_with_digits iris datasets.load_iris y_true y_pred _ make_prediction dataset iris binary False expected_report 'prerecspef1geoibasupsetosa0.826090.791670.921570.808510.864090.7408524versicolor0.333330.096770.863640.150000.438090.1872731virginica0.418600.900000.545450.571430.626450.3720820avg/total0.513750.533330.797330.473100.624640.4137075'report classification_report_imbalanced y_true y_pred labels np.arange len iris.target_names target_names iris.target_names digits 5 assert_equal _format_report report expected_report expected_report 'prerecspef1geoibasup00.830.790.920.810.860.742410.330.100.860.150.440.193120.420.900.550.570.630.3720avg/total0.510.530.800.470.620.4175'report classification_report_imbalanced y_true y_pred assert_equal _format_report report expected_report
def currentframe n 0 f inspect.currentframe for x in range n + 1 f f.f_backreturn f
def libvlc_media_library_retain p_mlib f _Cfunctions.get 'libvlc_media_library_retain' None or _Cfunction 'libvlc_media_library_retain' 1 None None MediaLibrary return f p_mlib
def is_page_candidate urlLink urlTitle title artist title slugify title.lower artist slugify artist.lower sitename re.search u'// [^/]+ /.*' slugify urlLink.lower .group 1 urlTitle slugify urlTitle.lower if urlTitle.find title ! -1 return Truetokens [ by + '_' + artist for by in BY_TRANS] + [artist sitename sitename.replace 'www.' '' ] + LYRICS_TRANS songTitle re.sub u' %s ' % u'|'.join tokens u'' urlTitle songTitle songTitle.strip '_|' typoRatio 0.9return difflib.SequenceMatcher None songTitle title .ratio > typoRatio
@receiver post_save sender User def create_profile_callback sender instance created False **kwargs if created for auto in AutoGroup.objects.all if re.match auto.match instance.email instance.groups.add auto.group Token.objects.create user instance Profile.objects.get_or_create user instance
def verify_equivalency fasta_seqs qual_scores if len fasta_seqs ! len qual_scores raise ValueError 'Numberofsequencesnotequalininputfasta' + 'andqualfile.' qual_scores_labels set qual_scores.keys for label in fasta_seqs.keys if label not in qual_scores_labels raise ValueError 'Fastalabel%snotfoundinqualityscore' % label + 'file.' if len fasta_seqs[label] ! len qual_scores[label] raise ValueError 'Sequence%sdoesnothaveequivalent' % label + 'basepositionsbetweenfastaandqualityscorefile.'
def getAcceptable accept_header have_types accepted parseAcceptHeader accept_header preferred matchTypes accepted have_types return [mtype for mtype _ in preferred]
def save_list_setting settings filename name new_value old_value None new_value list set new_value new_value sorted new_value key lambda s s.lower if old_value is not None if old_value new_value returnsettings.set name new_value sublime.save_settings filename
def _labeledInput activeInputs cellsPerCol 32 if cellsPerCol 0 cellsPerCol 1cols activeInputs.size / cellsPerCol activeInputs activeInputs.reshape cols cellsPerCol cols cellIdxs activeInputs.nonzero if len cols 0 return 'NONE'items [ ' %d ' % len cols ]prevCol -1 for col cellIdx in zip cols cellIdxs if col ! prevCol if prevCol ! -1 items.append ']' items.append 'Col%d [' % col prevCol colitems.append '%d ' % cellIdx items.append ']' return ''.join items
def line_2d_to_3d line zs 0 zdir u'z' line.__class__ Line3Dline.set_3d_properties zs zdir
def row2feature row id_field geometry_field feature {'type' 'Feature' 'properties' _copy row }geometry feature['properties'].pop geometry_field feature['geometry'] _loadshape _unhexlify geometry feature['id'] feature['properties'].pop id_field return feature
def _next_tree candidate left rest _split_tree candidate left_height max left rest_height max rest valid rest_height > left_height if valid and rest_height left_height if len left > len rest valid Falseelif len left len rest and left > rest valid Falseif valid return candidateelse p len left new_candidate _next_rooted_tree candidate p if candidate[p] > 2 new_left new_rest _split_tree new_candidate new_left_height max new_left suffix range 1 new_left_height + 2 new_candidate[ - len suffix ] suffixreturn new_candidate
def double_complex_from_npy_cdouble var res '_complexstuff.double_complex_from_npy_cdouble {} '.format var return res
def item_from_env env item_name item env.get item_name None if item is None logging.error 'ERROR %scouldnotbefoundinenv!' % item_name return item
def list_vhosts runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user res __salt__['cmd.run_all'] [__context__['rabbitmqctl'] 'list_vhosts' '-q'] runas runas python_shell False _check_response res return _output_to_list res['stdout']
def error_out resource reason None status 'error' reason _clean_reason reason try LOG.debug 'Setting% object_type s% object_id stoerrordueto % reason s' {'object_type' resource.obj_name 'object_id' resource.id 'reason' reason} resource.status statusresource.save except Exception LOG.exception _LE 'Failedsetting% object_type s% object_id sto% status sstatus.' {'object_type' resource.obj_name 'object_id' resource.id 'status' status}
@cronjobs.registerdef reindex_users_that_contributed_yesterday if settings.STAGE returntoday datetime.now yesterday today - timedelta days 1 user_ids list Answer.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter reviewed__gte yesterday reviewed__lt today .values_list 'reviewer_id' flat True index_task.delay UserMappingType list set user_ids
def MakeBadSignatureResponse return '{"status" 21003}'
def on_configure config settings config['settings']skip_migration_if_applied settings 'social_auth' 'social_auth_association'
def load_batch fpath label_key 'labels' f open fpath 'rb' if sys.version_info < 3 d cPickle.load f else d cPickle.load f encoding 'bytes' d_decoded {}for k v in d.items d_decoded[k.decode 'utf8' ] vd d_decodedf.close data d['data']labels d[label_key]data data.reshape data.shape[0] 3 32 32 return data labels
def parsePrivateKey s try return parsePEMKey s private True except return parseXMLKey s private True
def app_db_migrated conn c get_db_connection journalist_tables c.execute 'PRAGMAtable_info journalists ' .fetchall table_names set [table[1] for table in journalist_tables] return 'last_token' in table_names
def require_http_methods request_method_list def decorator func @wraps func def inner request *args **kwargs if request.method not in request_method_list logger.warning 'MethodNotAllowed %s %s' request.method request.path extra {'status_code' 405 'request' request} return HttpResponseNotAllowed request_method_list return func request *args **kwargs return innerreturn decorator
def render_parallel children if len children 1 return children[0]children_latex [k.latex for k in children if k.latex ! '||' ]latex '\\|'.join children_latex tall any k.tall for k in children return LatexRendered latex tall tall
def make_instance_save instance fields fail_message def save self commit True return save_instance self instance fields fail_message commit return save
@pytest.yield_fixture autouse True def application app create_app Config ctx app.app_context ctx.push yield app ctx.pop
def _check_ip_available ip_addr for vm_name vm_details in six.iteritems get_resources_vms includeConfig True vm_config vm_details['config']if ip_addr in vm_config['ip_address'] or vm_config['ip_address'] ip_addr log.debug 'IP"{0}"isalreadydefined'.format ip_addr return Falselog.debug "IP'{0}'isavailabletobedefined".format ip_addr return True
def local_edge_connectivity G u v flow_func None auxiliary None residual None cutoff None if flow_func is None flow_func default_flow_funcif auxiliary is None H build_auxiliary_edge_connectivity G else H auxiliarykwargs dict flow_func flow_func residual residual if flow_func is shortest_augmenting_path kwargs['cutoff'] cutoffkwargs['two_phase'] Trueelif flow_func is edmonds_karp kwargs['cutoff'] cutoffelif flow_func is dinitz kwargs['cutoff'] cutoffelif flow_func is boykov_kolmogorov kwargs['cutoff'] cutoffreturn nx.maximum_flow_value H u v **kwargs
def get_support target_tree trees len_trees None term_names sorted term.name for term in target_tree.find_clades terminal True bitstrs {}size len_treesif size is None try size len trees except TypeError raise TypeError 'Treesdoesnotsupportlen trees youmustprovidethenumberofreplicatesintreesastheoptionalparameterlen_trees.' for clade in target_tree.find_clades terminal False bitstr _clade_to_bitstr clade term_names bitstrs[bitstr] clade 0 for tree in trees for clade in tree.find_clades terminal False bitstr _clade_to_bitstr clade term_names if bitstr in bitstrs c t bitstrs[bitstr]c.confidence t + 1 * 100.0 / size bitstrs[bitstr] c t + 1 return target_tree
def block_print higher lower r0 g0 b0 lower[ 3] r1 g1 b1 higher[ 3]if c['24BIT'] is True sys.stdout.write '\x1b[38;2;%d;%d;%dm\x1b[48;2;%d;%d;%dm\xe2\x96\x84\x1b[0m' % r1 g1 b1 r0 g0 b0 else i0 rgb2short r0 g0 b0 i1 rgb2short r1 g1 b1 sys.stdout.write '\x1b[38;5;%sm\x1b[48;5;%sm\xe2\x96\x84\x1b[0m' % i1 i0
def _UpdateUserHistory user t auth ts _history.get user [] [ -30 ]ts.append t auth _history[user] tsreturn ts
def cublas_init pass
def stats r total sum r avg float total / float len r sdsq sum [ i - avg ** 2 for i in r] s sorted list r return dict list zip [u'med' u'avg' u'stddev' u'min' u'max'] s[ len s // 2 ] avg sdsq / len r ** 0.5 min r max r
def remove_duplicates errors passed defaultdict list for error in errors key error.linter error.number if key in DUPLICATES if key in passed[error.lnum] continuepassed[error.lnum] DUPLICATES[key] yield error
def prune_dump sessionid out __salt__['cmd.run_all'] 'xfsinvutil-s{0}-F'.format sessionid _verify_run out data _xfs_prune_output out['stdout'] sessionid if data return dataraise CommandExecutionError 'SessionUUID"{0}"wasnotfound.'.format sessionid
def all_enabled user None features FeatureState.get_all _world active {}for feature in features experiment feature.config.get 'experiment' if experiment and FeatureState.is_user_experiment experiment variant feature.variant user if variant active[feature.name] {'experiment_id' experiment.get 'experiment_id' 'variant' variant}elif feature.is_enabled user active[feature.name] Truereturn active
def shared_empty dim 2 dtype None if dtype is None dtype theano.config.floatXshp tuple [1] * dim return theano.shared np.zeros shp dtype dtype
def addSymmetricXPath outputs path x vertexes []loops [getSymmetricXLoop path vertexes - x getSymmetricXLoop path vertexes x ]outputs.append getPillarOutput loops
@login_required@ensure_csrf_cookie@require_http_methods 'GET' 'POST' 'PUT' @ensure_valid_course_keydef import_handler request course_key_string courselike_key CourseKey.from_string course_key_string library isinstance courselike_key LibraryLocator if library root_name LIBRARY_ROOTsuccessful_url reverse_library_url 'library_handler' courselike_key context_name 'context_library'courselike_module modulestore .get_library courselike_key import_func import_library_from_xmlelse root_name COURSE_ROOTsuccessful_url reverse_course_url 'course_handler' courselike_key context_name 'context_course'courselike_module modulestore .get_course courselike_key import_func import_course_from_xmlreturn _import_handler request courselike_key root_name successful_url context_name courselike_module import_func
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_python_inc plat_specific 0 prefix None if prefix is None prefix plat_specific and EXEC_PREFIX or PREFIX if os.name 'posix' if python_build buildir os.path.dirname sys.executable if plat_specific inc_dir buildirelse srcdir os.path.abspath os.path.join buildir get_config_var 'srcdir' inc_dir os.path.join srcdir 'Include' return inc_dirreturn os.path.join prefix 'include' 'python' + get_python_version elif os.name 'nt' return os.path.join prefix 'include' elif os.name 'os2' return os.path.join prefix 'Include' else raise DistutilsPlatformError "Idon'tknowwherePythoninstallsitsCheaderfilesonplatform'%s'" % os.name
def get_model_queryset model request None if use_draft request return model.objects.drafts return model.objects.public
def isResultNode node return node and node.getType 'result'
def addCollarShaft collarLength derivation elementNode negatives positives if collarLength < 0.0 addShaft derivation negatives positives returnconnectionEnd Vector3 0.0 0.0 derivation.faceWidth + collarLength copyShallow derivation.elementNode.getCopyShallow copyShallow.attributes['path'] [Vector3 0.0 0.0 derivation.faceWidth connectionEnd]collarDerivation extrude.ExtrudeDerivation copyShallow addCollarShaftSetDerivation collarDerivation collarLength derivation elementNode negatives positives
def riemann_cyclic_replace t_r free sorted t_r.free key lambda x x[1] m n p q [x[0] for x in free]t0 S 2 / 3 * t_r t1 - S 1 / 3 * t_r.substitute_indices m m n q p n q p t2 S 1 / 3 * t_r.substitute_indices m m n p p n q q t3 t0 + t1 + t2 return t3
def generalized_exponential theta d theta np.asarray theta dtype np.float64 d np.asarray d dtype np.float64 if d.ndim > 1 n_features d.shape[1]else n_features 1lth theta.sizeif n_features > 1 and lth 2 theta np.hstack [np.repeat theta[0] n_features theta[1]] elif lth ! n_features + 1 raise Exception 'Lengthofthetamustbe2or%s' % n_features + 1 else theta theta.reshape 1 lth td theta[ 0 -1 ].reshape 1 n_features * np.abs d ** theta[ -1 ] r np.exp - np.sum td 1 return r
def OSXSplitPathspec pathspec return client_utils_linux.LinSplitPathspec pathspec GetMountpoints
def parse_set_diff source info items [parse_set_imp_union source info ]while source.match '--' items.append parse_set_imp_union source info if len items 1 return items[0]return SetDiff info items
def get_review_request_id commit_message server_url commit_id None repository None regex settings.HOSTINGSVCS_HOOK_REGEX % {u'server_url' server_url} pattern re.compile regex settings.HOSTINGSVCS_HOOK_REGEX_FLAGS match pattern.search commit_message if match try review_request_id int match.group u'id' except ValueError logging.error u'ThereviewrequestIDmustbeaninteger.' review_request_id Noneelif commit_id assert repositorytry review_request ReviewRequest.objects.get commit_id six.text_type commit_id repository repository review_request_id review_request.display_idexcept ReviewRequest.DoesNotExist review_request_id Nonereturn review_request_id
def ismount path try s1 os.stat path s2 os.stat join path '..' except os.error return Falsedev1 s1.st_devdev2 s2.st_devif dev1 ! dev2 return Trueino1 s1.st_inoino2 s2.st_inoif ino1 ino2 return Truereturn False
def parse_mf_results mf py_files []extensions []for item in mf.flatten if item.identifier '__main__' continuesrc item.filenameif src and src ! '-' if isinstance item Script py_files.append item elif isinstance item Extension extensions.append item else py_files.append item py_files.sort key lambda v v.filename extensions.sort key lambda v v.filename return py_files extensions
def closest_matches_monocular ref_pts pupil_pts max_dispersion 1 / 15.0 ref ref_ptspupil0 pupil_ptspupil0_ts np.array [p['timestamp'] for p in pupil0] def find_nearest_idx array value idx np.searchsorted array value side 'left' try if abs value - array[ idx - 1 ] < abs value - array[idx] return idx - 1 else return idxexcept IndexError return idx - 1 matched []if pupil0 for r in ref_pts closest_p0_idx find_nearest_idx pupil0_ts r['timestamp'] closest_p0 pupil0[closest_p0_idx]dispersion max closest_p0['timestamp'] r['timestamp'] - min closest_p0['timestamp'] r['timestamp'] if dispersion < max_dispersion matched.append {'ref' r 'pupil' closest_p0} else passreturn matched
def unesc s esc_chars for c in esc_chars esc_str u'\\' + c s s.replace esc_str c return s
def auth u p global user passworduser upassword p
def folder_exists folderName return os.path.isdir folderName
def _nt_quote_args args for i in range len args if string.find args[i] '' ! -1 args[i] '"%s"' % args[i] return args
def test_all_mail_present monkeypatch g get_auth_handler monkeypatch {'all' 'ALL' 'inbox' 'INBOX' 'trash' 'TRASH'} assert g.verify_account AccountStub
def get_file filename return os.path.join TEST_DIR filename
def get_parents x collection None if collection is None collection random_variables node_dict {node.value node for node in collection}output set [] nodes set [x] while nodes node nodes.pop if isinstance node RandomVariable node node.value candidate_node node_dict.get node None if candidate_node and candidate_node ! x output.add candidate_node else nodes.update node.op.inputs return list output
def _get_release_date xblock user None reset_to_default Falsetry reset_to_default xblock.start.year < 1900 except ValueError reset_to_default Trueif reset_to_default and user xblock.start DEFAULT_START_DATExblock _update_with_callback xblock user return get_default_time_display xblock.start if xblock.start ! DEFAULT_START_DATE else None
def sample_path path num 10 space numpy.linspace 0.0 1.0 num endpoint True return [path.pointAtPercent float p for p in space]
def DeleteAsync keys **kwargs config _GetConfigFromKwargs kwargs if getattr config 'read_policy' None EVENTUAL_CONSISTENCY raise datastore_errors.BadRequestError 'read_policyisonlysupportedonreadoperations.' keys _ NormalizeAndTypeCheckKeys keys return _GetConnection .async_delete config keys
def transform_hr t lamda def _check_args lamda cond lamda > 0 return condif not np.all _check_args lamda raise ValueError 'invalidargs' term np.log 1.0 - t / t * 0.5 / lamda from scipy.stats import normtransf 1 - t * norm._cdf lamda + term + t * norm._cdf lamda - term return transf
def test_get_words_c expected_words ['f' 'float' 'foo' 'h' 'i' 'include' 'int' 'main' 'n' 'printf' 'pvar' 'return' 'stdio' 'struct' 'var' 'x' 'y']assert sorted expected_words sorted get_words_by_filename 'example.c' assert sorted expected_words sorted get_words_by_content 'example.c'
def close *args if len args 0 figManager _pylab_helpers.Gcf.get_active if figManager is None returnelse _pylab_helpers.Gcf.destroy figManager.num elif len args 1 arg args[0]if arg u'all' _pylab_helpers.Gcf.destroy_all elif isinstance arg six.integer_types _pylab_helpers.Gcf.destroy arg elif hasattr arg u'int' _pylab_helpers.Gcf.destroy arg.int elif is_string_like arg allLabels get_figlabels if arg in allLabels num get_fignums [allLabels.index arg ]_pylab_helpers.Gcf.destroy num elif isinstance arg Figure _pylab_helpers.Gcf.destroy_fig arg else raise TypeError u'Unrecognizedargumenttype%stoclose' % type arg else raise TypeError u'closetakes0or1arguments'
def http_connect_raw ipaddr port method path headers None query_string None ssl False if not port port 443 if ssl else 80 if ssl conn HTTPSConnection '%s %s' % ipaddr port else conn BufferedHTTPConnection '%s %s' % ipaddr port if query_string path + '?' + query_string conn.path pathconn.putrequest method path skip_host headers and 'Host' in headers if headers for header value in headers.iteritems conn.putheader header str value conn.endheaders return conn
def multiproduct seq start 1 if not seq return startif isinstance seq dict seq iter seq.items units startmulti []for base exp in seq if not exp continueelif exp 1 units * baseelse if exp % 2 units * basemulti.append base exp // 2 return units * multiproduct multi ** 2
def pkg_commit_hash pkg_path pth os.path.join pkg_path COMMIT_INFO_FNAME if not os.path.isfile pth raise IOError u'Missingcommitinfofile%s' % pth cfg_parser ConfigParser cfg_parser.read pth archive_subst cfg_parser.get u'commithash' u'archive_subst_hash' if not archive_subst.startswith u'$Format' return u'archivesubstitution' archive_subst install_subst cfg_parser.get u'commithash' u'install_hash' if install_subst ! u'' return u'installation' install_subst proc subprocess.Popen u'gitrev-parse--shortHEAD' stdout subprocess.PIPE stderr subprocess.PIPE cwd pkg_path shell True repo_commit _ proc.communicate if repo_commit if PY3 repo_commit repo_commit.decode return u'repository' repo_commit.strip return u' nonefound ' u'<notfound>'
def nudge_dataset X Y direction_vectors [[[0 1 0] [0 0 0] [0 0 0]] [[0 0 0] [1 0 0] [0 0 0]] [[0 0 0] [0 0 1] [0 0 0]] [[0 0 0] [0 0 0] [0 1 0]]]shift lambda x w convolve x.reshape 8 8 mode 'constant' weights w .ravel X np.concatenate [X] + [np.apply_along_axis shift 1 X vector for vector in direction_vectors] Y np.concatenate [Y for _ in range 5 ] axis 0 return X Y
def existing_user_fields fields user_fields get_user_model ._meta.fieldsuser_field_names [field.name for field in user_fields]return [field for field in fields if field in user_field_names ]
def multivariateCauchy mu sigma onlyDiagonal True if not onlyDiagonal u s d svd sigma coeffs sqrt s else coeffs diag sigma r rand len mu res coeffs * tan pi * r - 0.5 if not onlyDiagonal res dot d dot res u return res + mu
def students_require_certificate course_id enrolled_students statuses_to_regenerate None if statuses_to_regenerate students_require_certificates enrolled_students.filter generatedcertificate__course_id course_id generatedcertificate__status__in statuses_to_regenerate return list students_require_certificates else students_already_have_certs User.objects.filter ~ Q generatedcertificate__status CertificateStatuses.unavailable generatedcertificate__course_id course_id return list set enrolled_students - set students_already_have_certs
def sinica_parse s tokens re.split u' [ |] ' s for i in range len tokens if tokens[i] u' ' tokens[ i - 1 ] tokens[i] tokens[i] tokens[ i - 1 ] elif u' ' in tokens[i] fields tokens[i].split u' ' if len fields 2 tokens[i] fields[1]else tokens[i] u' ' + fields[ -2 ] + u'' + fields[ -1 ] + u' ' elif tokens[i] u'|' tokens[i] u''treebank_string u''.join tokens return Tree.fromstring treebank_string remove_empty_top_bracketing True
def validate_string option value if isinstance value string_type return valueraise TypeError 'Wrongtypefor%s valuemustbeaninstanceof%s' % option string_type.__name__
def decoder conv_func return lambda s conv_func s.decode u'utf-8'
def row_factory cursor row return Logline sqlite_cursor cursor.description sqlite_row row
def _GetBlobstoreMetadata blob_key try blob_info datastore.Get datastore.Key.from_path blobstore.BLOB_INFO_KIND blob_key namespace '' return blob_info['size'] blob_info['content_type'] blob_key except datastore_errors.EntityNotFoundError return None None None
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def _api_eval_sort name output kwargs import sabnzbd.tvsortname kwargs.get 'name' '' value kwargs.get 'value' '' title kwargs.get 'title' multipart kwargs.get 'movieextra' '' path sabnzbd.tvsort.eval_sort value title name multipart if path is None return report output _MSG_NOT_IMPLEMENTED else return report output keyword 'result' data path
def config_course_cohorts_legacy course discussions cohorted cohorted_discussions None auto_cohort_groups None always_cohort_inline_discussions None def to_id name '\nHelpermethodtoconvertadiscussiontopicnametoadatabaseidentifier\n'return topic_name_to_id course name topics dict name {'sort_key' 'A' 'id' to_id name } for name in discussions course.discussion_topics topicsconfig {'cohorted' cohorted}if cohorted_discussions is not None config['cohorted_discussions'] [to_id name for name in cohorted_discussions]if auto_cohort_groups is not None config['auto_cohort_groups'] auto_cohort_groupsif always_cohort_inline_discussions is not None config['always_cohort_inline_discussions'] always_cohort_inline_discussionscourse.cohort_config configtry modulestore .update_item course ModuleStoreEnum.UserID.test except NotImplementedError pass
def group_snapshot_get_all_by_group context group_id filters None return IMPL.group_snapshot_get_all_by_group context group_id filters
def quotes_historical_yahoo_ochl ticker date1 date2 asobject False adjusted True cachename None return _quotes_historical_yahoo ticker date1 date2 asobject asobject adjusted adjusted cachename cachename ochl True
def test_enn_fit_single_class enn EditedNearestNeighbours random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning enn.fit X y_single_class
def cluster_commit ret {'comment' '' 'success' False}cmd __execute_cmd 'riak-admin' 'clustercommit' if cmd['retcode'] ! 0 ret['comment'] cmd['stdout']else ret['comment'] cmd['stdout']ret['success'] Truereturn ret
def _load_csv F if PY2 names F.readline .strip .split ' ' else names F.readline .decode 'ascii' .strip .split ' ' rec np.loadtxt F skiprows 0 delimiter ' ' dtype 'a22 f4 f4' rec.dtype.names namesreturn rec
def get_bcaddress_version strAddress addr b58decode strAddress 25 if addr is None return Noneversion addr[0]checksum addr[ -4 ]vh160 addr[ -4 ]h3 sha256 sha256 vh160 .digest .digest if h3[0 4] checksum return ord version return None
def OpenDocumentDrawing doc OpenDocument 'application/vnd.oasis.opendocument.graphics' doc.drawing Drawing doc.body.addElement doc.drawing return doc
def get_word_index path 'reuters_word_index.pkl' path get_file path origin 'https //s3.amazonaws.com/text-datasets/reuters_word_index.pkl' f open path 'rb' if sys.version_info < 3 data cPickle.load f else data cPickle.load f encoding 'latin1' f.close return data
def cpickle_dumps obj if isinstance obj dict return cPickle.dumps obj 1 return cPickle.dumps obj cPickle.HIGHEST_PROTOCOL
def _make_voxel_ras_trans move ras voxel_size assert voxel_size.ndim 1 assert voxel_size.size 3 rot ras.T * voxel_size[np.newaxis ] assert rot.ndim 2 assert rot.shape[0] 3 assert rot.shape[1] 3 trans np.c_[ np.r_[ rot np.zeros 1 3 ] np.r_[ move 1.0 ] ]t Transform 'mri_voxel' 'mri' trans return t
@sopel.module.event u'KICK' @sopel.module.rule u'.*' @sopel.module.priority u'low' def hold_ground bot trigger if bot.config.admin.hold_ground channel trigger.senderif trigger.args[1] bot.nick bot.join channel
def parse_atom tokens options token tokens.current result []if token in ' [' tokens.move matching pattern {' ' [' ' Required] '[' [']' Optional]}[token]result pattern *parse_expr tokens options if tokens.move ! matching raise tokens.error "unmatched'%s'" % token return [result]elif token 'options' tokens.move return [AnyOptions ]elif token.startswith '--' and token ! '--' return parse_long tokens options elif token.startswith '-' and token not in '-' '--' return parse_shorts tokens options elif token.startswith '<' and token.endswith '>' or token.isupper return [Argument tokens.move ]else return [Command tokens.move ]
def ensure_dirs_exist path outdir os.path.dirname path if outdir ! '' and not os.path.isdir outdir os.makedirs outdir return path
def create_css_gradient base_color stop QPointF 0 0 finalStop QPointF 0 1 gradient create_gradient base_color stop finalStop return css_gradient gradient
def getVertexesByKey key xmlElement return euclidean.getConcatenatedList evaluate.getTransformedPathsByKey key xmlElement
def get_form_data if is_form_submitted formdata request.formif request.files formdata formdata.copy formdata.update request.files return formdatareturn None
def stdin_loop options modules sender tags global ALIVEnext_heartbeat int time.time + 600 while ALIVE time.sleep 15 reload_changed_config_modules modules options sender tags now int time.time if now > next_heartbeat LOG.info 'Heartbeat %dcollectorsrunning ' % sum 1 for col in all_living_collectors next_heartbeat now + 600
def ifftn x shape None axes None overwrite_x False return _raw_fftn_dispatch x shape axes overwrite_x -1
@require_roledef get_session_user_info request return [request.user.id request.user.username request.user]
def bitsource zcontext url zsock zcontext.socket zmq.PUB zsock.bind url while True zsock.send_string ones_and_zeros B * 2 time.sleep 0.01
def test_simple_bar bar Bar rng [ -3 -32 -39 ]bar.add 'test1' rng bar.add 'test2' map abs rng bar.x_labels map str rng bar.title 'Bartest'q bar.render_pyquery assert len q '.axis.x' 1 assert len q '.axis.y' 1 assert len q '.legend' 2 assert len q '.plot.seriesrect' 2 * 3
def blockList2Matrix l dims [m.shape[0] for m in l]s sum dims res zeros s s index 0for i in range len l d dims[i]m l[i]res[index index + d index index + d ] mindex + dreturn res
def md5_encode t m hashlib.md5 t return m.hexdigest
def get_publish_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'publish_page' check_global check_global use_cache use_cache return page_ids
def get_locales_dict global locales_dictif not locales_dict locales _get_locales locales_dict {}for locale in locales locales_dict[str locale ] Locale.parse locale return locales_dict
def ireport_vehicle return s3_rest_controller 'irs' 'ireport_vehicle'
def detach_volume name None kwargs None instance_id None call None if call ! 'action' raise SaltCloudSystemExit 'Thedetach_volumeactionmustbecalledwith-aor--action.' if not kwargs kwargs {}if 'volume_id' not in kwargs log.error 'Avolume_idisrequired.' return Falseparams {'Action' 'DetachVolume' 'VolumeId' kwargs['volume_id']}data aws.query params return_url True location get_location provider get_provider opts __opts__ sigver '4' return data
def conv_transpose2d input weight bias None stride 1 padding 0 output_padding 0 groups 1 f ConvNd _pair stride _pair padding _pair 1 True _pair output_padding groups return f input weight bias if bias is not None else f input weight
def get_plugins return _cache
def set_cover_tilt_position hass tilt_position entity_id None data {ATTR_ENTITY_ID entity_id} if entity_id else {} data[ATTR_TILT_POSITION] tilt_positionhass.services.call DOMAIN SERVICE_SET_COVER_TILT_POSITION data
def imgVRange h va fontSize if va 'baseline' iyo 0elif va in 'text-top' 'top' iyo fontSize - h elif va 'middle' iyo fontSize - 1.2 * fontSize + h * 0.5 elif va in 'text-bottom' 'bottom' iyo fontSize - 1.2 * fontSize elif va 'super' iyo 0.5 * fontSize elif va 'sub' iyo -0.5 * fontSize elif hasattr va 'normalizedValue' iyo va.normalizedValue fontSize else iyo vareturn iyo iyo + h
def write_flv_header stream stream.write 'FLV\x01' stream.write '\x05' stream.write '\x00\x00\x00 DCTB ' stream.write '\x00\x00\x00\x00'
def _MakeArgs amazon_collection_map google_collection_map request_list []for url label in amazon_collection_map.iteritems request_list.append CloudMetadataRequest bios_version_regex AMAZON_BIOS_REGEX service_name_regex AMAZON_SERVICE_REGEX instance_type 'AMAZON' timeout 1.0 url url label label for url label in google_collection_map.iteritems request_list.append CloudMetadataRequest bios_version_regex GOOGLE_BIOS_REGEX service_name_regex GOOGLE_SERVICE_REGEX headers {'Metadata-Flavor' 'Google'} instance_type 'GOOGLE' timeout 1.0 url url label label return request_list
def rename name kwargs call None if call ! 'action' raise SaltCloudSystemExit 'Therenameactionmustbecalledwith-aor--action.' log.info 'Renaming{0}to{1}'.format name kwargs['newname'] set_tags name {'Name' kwargs['newname']} call 'action' salt.utils.cloud.rename_key __opts__['pki_dir'] name kwargs['newname']
def veoh_download url output_dir '.' merge False info_only False **kwargs if re.match 'http //www.veoh.com/watch/\\w+' url item_id match1 url 'http //www.veoh.com/watch/ \\w+ ' elif re.match 'http //www.veoh.com/m/watch.php\\?v \\.*' url item_id match1 url 'http //www.veoh.com/m/watch.php\\?v \\w+ ' else raise NotImplementedError 'CannotfinditemID' veoh_download_by_id item_id output_dir '.' merge False info_only info_only **kwargs
def _topo_reorder entries get_parents lambda commit commit.parents todo collections.deque pending {}num_children defaultdict int for entry in entries todo.append entry for p in get_parents entry.commit num_children[p] + 1while todo entry todo.popleft commit entry.commitcommit_id commit.idif num_children[commit_id] pending[commit_id] entrycontinuefor parent_id in get_parents commit num_children[parent_id] - 1if not num_children[parent_id] parent_entry pending.pop parent_id None if parent_entry todo.appendleft parent_entry yield entry
def dmp_sub_ground f c u K return dmp_sub_term f dmp_ground c u - 1 0 u K
def random_func lib opts args query decargs args if opts.album objs list lib.albums query else objs list lib.items query objs random_objs objs opts.album opts.number opts.time opts.equal_chance for obj in objs print_ format obj
def ld_mnist test_only False file_urls ['http //yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz' 'http //yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz' 'http //yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz' 'http //yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']local_urls maybe_download file_urls FLAGS.data_dir train_data extract_mnist_data local_urls[0] 60000 28 1 train_labels extract_mnist_labels local_urls[1] 60000 test_data extract_mnist_data local_urls[2] 10000 28 1 test_labels extract_mnist_labels local_urls[3] 10000 if test_only return test_data test_labels else return train_data train_labels test_data test_labels
def spectral_ordering G weight 'weight' normalized False tol 1e-08 method 'tracemin' if len G 0 raise nx.NetworkXError 'graphisempty.' G _preprocess_graph G weight find_fiedler _get_fiedler_func method order []for component in nx.connected_components G size len component if size > 2 L nx.laplacian_matrix G component x None if method ! 'lobpcg' else _rcm_estimate G component fiedler find_fiedler L x normalized tol [1]order.extend u for x c u in sorted zip fiedler range size component else order.extend component return order
def update_vote_lookups user thing direction key prequeued_vote_key user thing grace_period int g.vote_queue_grace_period.total_seconds direction Vote.serialize_direction direction g.gencache.set key direction time grace_period + 1 rel_cls VotesByAccount.rel thing.__class__ LastModified.touch user._fullname rel_cls._last_modified_name
def require_sales_admin func def wrapped request course_id try course_key CourseKey.from_string course_id except InvalidKeyError log.error u'Unabletofindcoursewithcoursekey%s' course_id return HttpResponseNotFound access auth.user_has_role request.user CourseSalesAdminRole course_key if access return func request course_id else return HttpResponseForbidden return wrapped
def netmask mask if not isinstance mask string_types return Falseoctets mask.split '.' if not len octets 4 return Falsereturn ipv4_addr mask and octets sorted octets reverse True
@synchronized IO_LOCK def load_admin _id remove False do_pickle True silent False path os.path.join cfg.admin_dir.get_path _id logging.info 'Loadingdatafor%sfrom%s' _id path if not os.path.exists path logging.info '%smissing' path return Nonetry f open path 'rb' if do_pickle data cPickle.load f else data f.read f.close if remove os.remove path except if not silent excepterror str sys.exc_info [0] logging.error T 'Loading%sfailedwitherror%s' path excepterror logging.info 'Traceback ' exc_info True return Nonereturn data
def _GetTemplatePath template_file return os.path.join os.path.dirname __file__ 'templates' template_file
def log_likelihood emp_cov precision p precision.shape[0]log_likelihood_ - np.sum emp_cov * precision + fast_logdet precision log_likelihood_ - p * np.log 2 * np.pi log_likelihood_ / 2.0return log_likelihood_
def query query_type 'list_nodes' client _get_client info client.query query_type return info
def mutESLogNormal individual c indpb size len individual t c / math.sqrt 2.0 * math.sqrt size t0 c / math.sqrt 2.0 * size n random.gauss 0 1 t0_n t0 * n for indx in xrange size if random.random < indpb individual.strategy[indx] * math.exp t0_n + t * random.gauss 0 1 individual[indx] + individual.strategy[indx] * random.gauss 0 1 return individual
@click.command @click.option '--name' help 'FullName' prompt True @click.option '--email' help 'Email' prompt True @click.option '--password' help 'Password' prompt True hide_input True confirmation_prompt True @click.option '--role' help 'Role' prompt True def cli name None email None password None role None create_user name email password role
def is_bin_str data if '\x00' in data return Trueif not data return Falsetext_characters ''.join [chr x for x in range 32 127 ] + list '\n\r DCTB \x08' if six.PY3 trans ''.maketrans '' '' text_characters nontext data.translate trans else trans string.maketrans '' '' nontext data.translate trans text_characters if len nontext / len data > 0.3 return Truereturn False
def ip_missing mod_attr IPY_SHOULD_IMPL.write mod_attr + '\n' IPY_SHOULD_IMPL.flush
def _convert_nnn val word '' mod rem val % 100 val // 100 if rem > 0 word to_19[rem] + 'Hundred' if mod > 0 word + ''if mod > 0 word + _convert_nn mod return word
def test_convert_np_array mixin_cols t QTable mixin_cols ta t.as_array m mixin_cols['m']dtype_kind m.dtype.kind if hasattr m 'dtype' else 'O' assert ta['m'].dtype.kind dtype_kind
def educateSingleBackticks str str re.sub '`' '&#8216;' str str re.sub "'" '&#8217;' str return str
def align_log_prob i j source_sents target_sents alignment params l_s sum source_sents[ i - offset - 1 ] for offset in range alignment[0] l_t sum target_sents[ j - offset - 1 ] for offset in range alignment[1] try m l_s + l_t / params.AVERAGE_CHARACTERS / 2 delta l_s * params.AVERAGE_CHARACTERS - l_t / math.sqrt m * params.VARIANCE_CHARACTERS except ZeroDivisionError return float '-inf' return - LOG2 + norm_logsf abs delta + math.log params.PRIORS[alignment]
def assert_false expr msg None if expr _report_failure msg
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def write_name_list fid kind data write_string fid kind ' '.join data
def predicative adjective w adjective.lower if w in adjective_predicative return adjective_predicative[w]if w.endswith 'ari' return w + 'o' if w.endswith 'ali' 'ili' 'esi' 'nti' 'ori' return w[ -1 ] + 'e' if w.endswith 'isti' return w[ -1 ] + 'a' if w.endswith 'che' 'ghe' return w[ -2 ] + 'a' if w.endswith 'chi' 'ghi' return w[ -2 ] + 'o' if w.endswith 'i' return w[ -1 ] + 'o' if w.endswith 'e' return w[ -1 ] + 'a' return adjective
def _is_number_matching_desc national_number number_desc if number_desc is None return Falsenational_re re.compile number_desc.national_number_pattern or U_EMPTY_STRING return _is_number_possible_for_desc national_number number_desc and fullmatch national_re national_number
@treeio_login_requireddef ajax_ticket_lookup request response_format 'html' tickets []if request.GET and 'term' in request.GET tickets Ticket.objects.filter name__icontains request.GET['term'] [ 10]return render_to_response 'services/ajax_ticket_lookup' {'tickets' tickets} context_instance RequestContext request response_format response_format
def kolmogorov x if x < 0.27 return 1.0if x > 3.2 return 0.0x -2.0 * x * x k 0for i in reversed xrange 1 27 + 1 2 k 1 - k * exp x * i return 2.0 * k
def visiblename name all None _hidden_names '__builtins__' '__doc__' '__file__' '__path__' '__module__' '__name__' '__slots__' '__package__' if name in _hidden_names return 0if name.startswith '__' and name.endswith '__' return 1if all is not None return name in all else return not name.startswith '_'
@dispatch object def scrub_keys o raise NotImplementedError 'scrub_keysnotimplementedfortype%r' % type o .__name__
def stl_case_activity_owner_group table row db current.dbs3db current.s3dbstable s3db.org_servicertable stable.with_alias 'root_service' left [stable.on stable.id table.service_id rtable.on rtable.id stable.root_service ]query table.id row[table._id] row db query .select rtable.name left left limitby 0 1 .first if not row return Noneroot_service_name row.nameif not root_service_name return Noneif root_service_name INDIVIDUAL_SUPPORT owner_group_uuid 'CASE_MANAGEMENT'elif root_service_name MENTAL_HEALTH owner_group_uuid 'MENTAL_HEALTH'else owner_group_uuid 'GROUP_ACTIVITIES'gtable current.auth.settings.table_groupquery gtable.uuid owner_group_uuid & gtable.deleted ! True group db query .select gtable.id limitby 0 1 .first return group.id if group else None
def dmp_prs_resultant f g u K if not u return dup_prs_resultant f g K if dmp_zero_p f u or dmp_zero_p g u return dmp_zero u - 1 [] R S dmp_inner_subresultants f g u K if dmp_degree R[ -1 ] u > 0 return dmp_zero u - 1 R return S[ -1 ] R
def playlist_to_mpd_format playlist *args **kwargs return tracks_to_mpd_format playlist.tracks *args **kwargs
def assert_has_extension test credential name value expected X509Extension name False value x509 credential.certificate.originalvalues []for i in range x509.get_extension_count extension x509.get_extension i if extension.get_short_name name values.append extension.get_data test.assertIn expected.get_data values
def unique values values com._asarray_tuplesafe values f lambda htype caster _unique_object values htype caster return _hashtable_algo f values
def ldap_hash_password password password_utf8 trunc_password password .encode 'utf-8' h passlib.hash.ldap_salted_sha1.encrypt password_utf8 return h
def cfunc sig locals {} cache False **options sig sigutils.normalize_signature sig def wrapper func from .ccallback import CFuncres CFunc func sig locals locals options options if cache res.enable_caching res.compile return resreturn wrapper
def _raise_error_routes iface option expected msg _error_msg_routes iface option expected log.error msg raise AttributeError msg
def encipher_shift msg key symbols None msg _ A _prep msg '' symbols shift len A - key % len A key A[shift ] + A[ shift] return translate msg key A
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
def network_io_counters interface None if not interface return dict psutil.net_io_counters ._asdict else stats psutil.net_io_counters pernic True if interface in stats return dict stats[interface]._asdict else return False
def _autogen_docstring base msg u''addendum docstring.Appender msg u'\n\n' return lambda func addendum docstring.copy_dedent base func
def recompose_xfm in_bval in_xfms import numpy as npimport os.path as opbvals np.loadtxt in_bval out_matrix np.array [np.eye 4 ] * len bvals xfms iter [np.loadtxt xfm for xfm in in_xfms] out_files []for i b in enumerate bvals if b 0.0 mat np.eye 4 else mat next xfms out_name op.abspath u'eccor_%04d.mat' % i out_files.append out_name np.savetxt out_name mat return out_files
def _ensure_loaded start_path for root folder files in os.walk start_path for phile in fnmatch.filter files '*.py' path os.path.join root phile try __import__ path.replace '/' '.' [ -3 ] globals locals except Exception pass
def handler_from_provider provider_name from inbox.auth import module_registryauth_mod module_registry.get provider_name if auth_mod is None info providers.get provider_name None if info provider_type info.get 'type' None if provider_type auth_mod module_registry.get 'generic' if auth_mod is None raise NotSupportedError 'Nylasdoesnotsupporttheemailprovider.' auth_handler_class getattr auth_mod auth_mod.AUTH_HANDLER_CLS auth_handler auth_handler_class provider_name provider_name return auth_handler
def get_context_manager context return _context_manager_from_context context or main_context_manager
def p_const_list_seq p _parse_seq p
def make_weighted_tree fn ls **kwargs if not ls raise ValueError 'Calledmake_weighted_treewithemptylist' ls.sort while len ls > 1 a ls.pop 0 b ls.pop 0 insort ls a[0] + b[0] fn a[1] b[1] return ls[0][1]
def add_spelling ix fieldnames commit True from whoosh.filedb.filereading import SegmentReaderwriter ix.writer storage writer.storageschema writer.schemasegments writer.segmentsfor segment in segments filename segment.dawg_filenamer SegmentReader storage schema segment f storage.create_file filename dawg DawgBuilder field_root True for fieldname in fieldnames ft fieldname for word in r.lexicon fieldname dawg.insert ft + tuple word dawg.write f for fieldname in fieldnames schema[fieldname].spelling Trueif commit writer.commit merge False
def add_charset charset header_enc None body_enc None output_charset None if body_enc SHORTEST raise ValueError 'SHORTESTnotallowedforbody_enc' CHARSETS[charset] header_enc body_enc output_charset
def _quit_editor caller del caller.db._multidesc_editkeycaller.msg 'Exitededitor.'
def _declarative_constructor self **kwargs cls_ type self for k in kwargs if not hasattr cls_ k raise TypeError '%risaninvalidkeywordargumentfor%s' % k cls_.__name__ setattr self k kwargs[k]
@hello.get permission NO_PERMISSION_REQUIRED def get_hello request settings request.registry.settingsproject_name settings['project_name']project_version settings['project_version']data dict project_name project_name project_version project_version http_api_version settings['http_api_version'] project_docs settings['project_docs'] url request.route_url hello.name eos get_eos request if eos data['eos'] eosdata['settings'] {}public_settings request.registry.public_settingsfor setting in list public_settings data['settings'][setting] settings[setting]if Authenticated in request.effective_principals data['user'] request.get_user_info data['capabilities'] request.registry.api_capabilitiesreturn data
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def get_tox_env parser get_parser args parser.parse_args if args.tox_env is not None tox_env args.tox_envelif TOX_ENV_VAR in os.environ tox_env os.environ[TOX_ENV_VAR]else tox_env get_tox_env_from_version return tox_env
def get_request_body text syntax True entities True sentiment True body {'document' {'type' 'PLAIN_TEXT' 'content' text} 'features' {'extract_syntax' syntax 'extract_entities' entities 'extract_document_sentiment' sentiment} 'encoding_type' 'UTF32'}return body
def calcHA1 pszAlg pszUserName pszRealm pszPassword pszNonce pszCNonce preHA1 None if preHA1 and pszUserName or pszRealm or pszPassword raise TypeError 'preHA1isincompatiblewiththepszUserName pszRealm andpszPasswordarguments' if preHA1 is None m algorithms[pszAlg] m.update pszUserName m.update ' ' m.update pszRealm m.update ' ' m.update pszPassword HA1 m.digest else HA1 preHA1.decode 'hex' if pszAlg 'md5-sess' m algorithms[pszAlg] m.update HA1 m.update ' ' m.update pszNonce m.update ' ' m.update pszCNonce HA1 m.digest return HA1.encode 'hex'
def now return datetime.datetime.now TimeZoneInfo.local
def default_catalogue_backend msg "Thereisno'%s'backendinCATALOGUE" % DEFAULT_CATALOGUE_ALIAS assert DEFAULT_CATALOGUE_ALIAS in settings.CATALOGUE msgreturn settings.CATALOGUE[DEFAULT_CATALOGUE_ALIAS]
def inplace_logistic_derivative Z delta delta * Zdelta * 1 - Z
def update_live_symlinks config for renewal_file in storage.renewal_conf_files config storage.RenewableCert renewal_file config update_symlinks True
def IsPythonVersionCorrect path from ycmd import utilsif not EndsWithPython path return Falsecommand [path u'-S' u'-c' u'importsys;major minor sys.version_info[ 2];good_python major 2andminor> 6 or major 3andminor> 3 ormajor>3;sys.exit notgood_python ']return utils.SafePopen command .wait 0
def test_stratified_table_cube tab1 [[[8 9] [6 7]] [[4 9] [5 5]] [[8 8] [9 11]]]tab2 np.asarray tab1 .Tct1 ctab.StratifiedTable tab1 ct2 ctab.StratifiedTable tab2 assert_allclose ct1.oddsratio_pooled ct2.oddsratio_pooled assert_allclose ct1.logodds_pooled ct2.logodds_pooled
def dedent_nodetext_formatter nodetext has_options caller None return dedent nodetext
def dumpNetConnections net nodes net.controllers + net.switches + net.hosts dumpNodeConnections nodes
@check_job_access_permission @check_job_edition_permission def create_coordinator_data request coordinator data_type if data_type 'input' data_instance DataInput coordinator coordinator DataForm DataInputFormelse data_instance DataOutput coordinator coordinator DataForm DataOutputFormresponse {'status' -1 'data' 'None'}if request.method 'POST' data_form DataForm request.POST instance data_instance coordinator coordinator prefix data_type if data_form.is_valid data_form.save response['status'] 0response['data'] reverse 'oozie edit_coordinator' kwargs {'coordinator' coordinator.id} request.info _ 'Coordinatordatacreated' else response['data'] data_form.errorselse response['data'] _ 'APOSTrequestisrequired.' return JsonResponse response
def _make_unique l return sorted set l
def isThereAFirstWord firstWord lines startIndex for lineIndex in xrange startIndex len lines line lines[lineIndex]splitLine getSplitLineBeforeBracketSemicolon line if firstWord getFirstWord splitLine return Truereturn False
def batch_fetch_art lib albums force maxwidth None for album in albums if album.artpath and not force message 'hasalbumart'else local_paths None if force else [album.path] path art_for_album album local_paths maxwidth if path album.set_art path False album.store message ui.colorize 'green' 'foundalbumart' else message ui.colorize 'red' 'noartfound' log.info u'{0}-{1} {2}'.format album.albumartist album.album message
def numel x **kwargs return chunk.sum np.ones_like x **kwargs
def tvar a limits None inclusive True True axis 0 ddof 1 a asarray a a a.astype float .ravel if limits is None n len a return a.var * n / n - 1.0 am _mask_to_limits a limits inclusive return np.ma.var am ddof ddof axis axis
def floor mat target None if not target target materr_code _cudamat.apply_floor mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def _longest d return collections.OrderedDict k d[k] for k in sorted d key len reverse True
def get_rdm_disk hardware_devices uuid if hardware_devices.__class__.__name__ 'ArrayOfVirtualDevice' hardware_devices hardware_devices.VirtualDevicefor device in hardware_devices if device.__class__.__name__ 'VirtualDisk' and device.backing.__class__.__name__ 'VirtualDiskRawDiskMappingVer1BackingInfo' and device.backing.lunUuid uuid return device
def get_session_config return copy.deepcopy _session['config']
def dup_zz_cyclotomic_factor f K lc_f tc_f dup_LC f K dup_TC f K if dup_degree f < 0 return Noneif lc_f ! 1 or tc_f not in [ -1 1] return Noneif any bool cf for cf in f[1 -1 ] return Nonen dup_degree f F _dup_cyclotomic_decompose n K if not K.is_one tc_f return Felse H []for h in _dup_cyclotomic_decompose 2 * n K if h not in F H.append h return H
@utils.arg 'host' metavar '<hostname>' help _ 'Nameofhost.' @utils.arg '--action' metavar '<action>' dest 'action' choices ['startup' 'shutdown' 'reboot'] help _ 'Apoweraction startup reboot orshutdown.' def do_host_action cs args result cs.hosts.host_action args.host args.action utils.print_list [result] ['HOST' 'power_action']
def switch_user request lti_user lti_consumer edx_user authenticate username lti_user.edx_user.username lti_user_id lti_user.lti_user_id lti_consumer lti_consumer if not edx_user raise PermissionDenied login request edx_user
def evalf_subs prec subs newsubs {}for a b in subs.items b S b if b.is_Float b b._eval_evalf prec newsubs[a] breturn newsubs
def configurable_test_state name changes True result True comment '' ret {'name' name 'changes' {} 'result' False 'comment' comment}change_data {'testing' {'old' 'Unchanged' 'new' 'Somethingpretendedtochange'}}if changes 'Random' if random.choice [True False] ret['changes'] change_dataelif changes is True ret['changes'] change_dataelif changes is False ret['changes'] {}else err "Youhavespecifiedthestateoption'Changes'withinvalidarguments.Itmustbeeither'True' 'False' or'Random'"raise SaltInvocationError err if result 'Random' ret['result'] random.choice [True False] elif result is True ret['result'] Trueelif result is False ret['result'] Falseelse raise SaltInvocationError "Youhavespecifiedthestateoption'Result'withinvalidarguments.Itmustbeeither'True' 'False' or'Random'" if __opts__['test'] ret['result'] True if changes is False else None ret['comment'] 'Thisisatest' if not comment else comment return ret
def profile_list request page 1 template_name 'userena/profile_list.html' paginate_by 50 extra_context None **kwargs warnings.warn 'views.profile_listisdeprecated.UseProfileListViewinstead' DeprecationWarning stacklevel 2 try page int request.GET.get 'page' None except TypeError ValueError page pageif userena_settings.USERENA_DISABLE_PROFILE_LIST and not request.user.is_staff raise Http404profile_model get_profile_model queryset profile_model.objects.get_visible_profiles request.user if not extra_context extra_context dict return ProfileListView.as_view queryset queryset paginate_by paginate_by page page template_name template_name extra_context extra_context **kwargs request
def in_ipython_frontend try ip get_ipython return 'zmq' in str type ip .lower except passreturn False
def batch_normalization x mean var beta gamma epsilon 0.001 if not hasattr T.nnet.bn 'batch_normalization_test' return _old_batch_normalization x mean var beta gamma epsilon if mean.ndim 1 reduction_axes range x.ndim - 1 else reduction_axes [i for i in range x.ndim if mean.broadcastable[i]]return T.nnet.bn.batch_normalization_test x gamma beta mean var reduction_axes epsilon
def availableVersions local True forceCheck False if local return _localVersions forceCheck else return sorted list set _localVersions forceCheck + _remoteVersions forceCheck reverse True
def get_effective_router appname if not routers or appname not in routers return Nonereturn Storage routers[appname]
def _content_length_rewriter state state.body list state.body length sum len block for block in state.body if state.status_code in constants.NO_BODY_RESPONSE_STATUSES state.body []del state.headers['Content-Length']elif state.environ.get 'REQUEST_METHOD' 'HEAD' if length logging.warning 'DroppingunexpectedbodyinresponsetoHEADrequest' state.body []elif not state.allow_large_response and length > constants.MAX_RUNTIME_RESPONSE_SIZE logging.error 'Responsetoolarge %d maxis%d' length constants.MAX_RUNTIME_RESPONSE_SIZE new_response 'HTTPresponsewastoolarge %d.Thelimitis %d.\n' % length constants.MAX_RUNTIME_RESPONSE_SIZE state.status '500InternalServerError'state.headers['Content-Type'] 'text/html'state.headers['Content-Length'] str len new_response state.body [new_response]else state.headers['Content-Length'] str length
def obj_sha type chunks sha sha1 sha.update object_header type chunks_length chunks if isinstance chunks bytes sha.update chunks else for chunk in chunks sha.update chunk return sha.digest
def parse_date date_string assume_utc False as_utc True default None from dateutil.parser import parseif not date_string return UNDEFINED_DATEif default is None func datetime.utcnow if assume_utc else datetime.now default func .replace day 15 hour 0 minute 0 second 0 microsecond 0 tzinfo _utc_tz if assume_utc else _local_tz if iso_pat .match date_string is not None dt parse date_string default default else dt parse date_string default default dayfirst parse_date_day_first if dt.tzinfo is None dt dt.replace tzinfo _utc_tz if assume_utc else _local_tz return dt.astimezone _utc_tz if as_utc else _local_tz
def test_laplace_mask image np.zeros 9 9 image[3 -3 3 -3 ] 1result filters.laplace image ksize 3 mask np.zeros 9 9 bool assert np.all result 0
def tokensMatch expectedTokens receivedTokens ignoreErrorOrder ignoreErrors False checkSelfClosing Falsefor token in expectedTokens if token[0] 'StartTag' and len token 4 or token[0] 'EndTag' and len token 3 checkSelfClosing Truebreakif not checkSelfClosing for token in receivedTokens if token[0] 'StartTag' or token[0] 'EndTag' token.pop if not ignoreErrorOrder and not ignoreErrors return expectedTokens receivedTokens else tokens {'expected' [[] []] 'received' [[] []]}for tokenType tokenList in zip tokens.keys expectedTokens receivedTokens for token in tokenList if token ! 'ParseError' tokens[tokenType][0].append token elif not ignoreErrors tokens[tokenType][1].append token return tokens['expected'] tokens['received']
def baseline assess_tables return s3_rest_controller
def send_remote_request request result_queue logging.debug 'Sendingremoterequest {0}'.format request.body result_queue.put urlfetch request
def template_source request template_name request.GET.get u'template' None if template_name is None return HttpResponseBadRequest u'"template"keyisrequired' loaders []for loader_name in settings.TEMPLATE_LOADERS loader find_template_loader loader_name if loader is not None loaders.append loader for loader in loaders try source display_name loader.load_template_source template_name breakexcept TemplateDoesNotExist source u'TemplateDoesNotExist %s' % template_name try from pygments import highlightfrom pygments.lexers import HtmlDjangoLexerfrom pygments.formatters import HtmlFormattersource highlight source HtmlDjangoLexer HtmlFormatter source mark_safe source source.pygmentized Trueexcept ImportError passreturn render_to_response u'debug_toolbar/panels/template_source.html' {u'source' source u'template_name' template_name}
def _hm_event_handler hass proxy device caller attribute value try channel int device.split ' ' [1] address device.split ' ' [0]hmdevice hass.data[DATA_HOMEMATIC].devices[proxy].get address except TypeError ValueError _LOGGER.error 'Eventhandlingchannelconverterror!' returnif attribute not in hmdevice.EVENTNODE return_LOGGER.debug 'Event%sfor%schannel%i' attribute hmdevice.NAME channel if attribute in HM_PRESS_EVENTS hass.add_job hass.bus.async_fire EVENT_KEYPRESS {ATTR_NAME hmdevice.NAME ATTR_PARAM attribute ATTR_CHANNEL channel} returnif attribute in HM_IMPULSE_EVENTS hass.add_job hass.bus.async_fire EVENT_KEYPRESS {ATTR_NAME hmdevice.NAME ATTR_CHANNEL channel} return_LOGGER.warning 'EventisunknownandnotforwardedtoHA'
def pull_tar url name verify False return _pull_image 'tar' url name verify verify
def python_int_bitwidth return struct.calcsize 'l' * 8
def bash_wrap cmd_str log.warning 'bash_wrap isdeprecatedandwillberemovedinv0.6.0' return "bash-c'%s'" % cmd_str.replace "'" "'\\''"
def maybe_make_aware dt tz None if is_naive dt dt to_utc dt return localize dt timezone.utc if tz is None else timezone.tz_or_local tz
def get_gravatar email size 80 default 'identicon' if userena_settings.USERENA_MUGSHOT_GRAVATAR_SECURE base_url 'https //secure.gravatar.com/avatar/'else base_url '//www.gravatar.com/avatar/'gravatar_url '% base_url s% gravatar_id s?' % {'base_url' base_url 'gravatar_id' md5 email.lower .encode 'utf-8' .hexdigest } gravatar_url + urlencode {'s' str size 'd' default} return gravatar_url
def mutualinfo_kde_2sample y x normed True nobs len x x np.asarray x float y np.asarray y float kde_x gaussian_kde x.T x.T kde_y gaussian_kde y.T x.T mi_obs np.log kde_x - np.log kde_y if len mi_obs ! nobs raise ValueError 'Wrongnumberofobservations' mi mi_obs.mean if normed mi_normed np.sqrt 1.0 - np.exp -2 * mi return mi_normedelse return mi
def hacks_for_phantomjs browser if isinstance browser webdriver.PhantomJS js "\nwindow.confirm function message {\nreturntrue;\n}\nwindow.alert window.prompt window.confirm;\n\n//REF http //stackoverflow.com/questions/13536752/phantomjs-click-a-link-on-a-page?rq 1\n//REF http //stackoverflow.com/questions/2705583/how-to-simulate-a-click-with-javascript/2706236#2706236\nwindow.eventFire function el etype {\nif el.fireEvent {\nel.fireEvent 'on'+etype ;\n}else{\nvarevObj document.createEvent 'Events' ;\nevObj.initEvent etype true false ;\nel.dispatchEvent evObj ;\n}\n};\n\n//shorteralternativeofabovemethod\nwindow.simulateClick function el {\nvare document.createEvent 'MouseEvents' ;\ne.initEvent 'click' true true ;\nel.dispatchEvent e ;\n};\n"browser.execute_script '%s' % js
def _pretty_hex hex_str if len hex_str % 2 ! 0 hex_str '0' + hex_str return ' '.join [hex_str[i i + 2 ] for i in range 0 len hex_str 2 ] .upper
@calculator 272696576 def calculate_perf_counter_bulk_count previous current property_name n0 previous[property_name]n1 current[property_name]d0 previous['Timestamp_Sys100NS']d1 current['Timestamp_Sys100NS']f current['Frequency_Sys100NS']if n0 is None or n1 is None returnreturn n1 - n0 / d1 - d0 / f
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def check_header_dups header errors for curr_elem in range len header if header.count header[curr_elem] ! 1 errors.append '%sfoundinheader%dtimes.' % header[curr_elem] header.count header[curr_elem] + 'Headerfieldsmustbeunique. DCTB %d %d' % 0 curr_elem return errors
def PassphraseCallback verify False prompt1 'Enterpassphrase ' prompt2 'Verifypassphrase ' while 1 try p1 getpass.getpass prompt1 if verify p2 getpass.getpass prompt2 if p1 p2 breakelse breakexcept KeyboardInterrupt return Nonereturn p1
def alias_function fun name doc None alias_fun types.FunctionType fun.__code__ fun.__globals__ name fun.__defaults__ fun.__closure__ alias_fun.__dict__.update fun.__dict__ if doc and isinstance doc six.string_types alias_fun.__doc__ docelse orig_name fun.__name__alias_msg '\nThisfunctionisanaliasof``{0}``.\n'.format orig_name alias_fun.__doc__ alias_msg + fun.__doc__ return alias_fun
def getLayerThickness xmlElement if xmlElement None return 0.4return xmlElement.getCascadeFloat 0.4 'layerThickness'
def find_skips start results {}debug 'Searchingin%s' start for root _dirs files in os.walk start for name in files if name.startswith 'test_' and name.endswith 'py' path os.path.join root name debug 'Searchingin%s' path temp_result find_skips_in_file path for method_name bug_no in temp_result if results.get bug_no result_dict results.get bug_no if result_dict.get name result_dict[name].append method_name else result_dict[name] [method_name]results[bug_no] result_dictelse results[bug_no] {name [method_name]}return results
def init_simple_stream_logging level logging.INFO streams None format None date_format None if not streams streams [sys.stdout]if not format format '% asctime s% message s'if not date_format date_format '%H %M %S'logging.basicConfig level level handlers []formatter WrappingLogFormatter format format date_format date_format for stream in streams log_handler logging.StreamHandler stream log_handler.setLevel level log_handler.setFormatter formatter handlers + [log_handler]logging.getLogger '' .handlers handlers
def _dnsname_to_stdlib name def idna_encode name "\nBorrowedwholesalefromthePythonCryptographyProject.Itturnsout\nthatwecan'tjustsafelycall`idna.encode` itcanexplodefor\nwildcardnames.Thisavoidsthatproblem.\n"import idnafor prefix in [u'*.' u'.'] if name.startswith prefix name name[len prefix ]return prefix.encode 'ascii' + idna.encode name return idna.encode name name idna_encode name if sys.version_info > 3 0 name name.decode 'utf-8' return name
def public_url app user_or_service None if user_or_service if app.subdomain_host host user_or_service.hostelse host public_host app return host + user_or_service.server.base_url else return public_host app + app.proxy.public_server.base_url
def bookmark_absent name force False recursive False return _absent name 'bookmark' force recursive
def string2lines astring tab_width 8 convert_whitespace 0 whitespace re.compile '[\x0b\x0c]' if convert_whitespace astring whitespace.sub '' astring return [s.expandtabs tab_width .rstrip for s in astring.splitlines ]
def status_code code redirect dict headers dict location REDIRECT_LOCATION code_map {301 redirect 302 redirect 303 redirect 304 dict data '' 305 redirect 307 redirect 401 dict headers {'WWW-Authenticate' 'Basicrealm "FakeRealm"'} 402 dict data 'Fuckyou payme!' headers {'x-more-info' 'http //vimeo.com/22053820'} 406 dict data json.dumps {'message' 'Clientdidnotrequestasupportedmediatype.' 'accept' ACCEPTED_MEDIA_TYPES} headers {'Content-Type' 'application/json'} 407 dict headers {'Proxy-Authenticate' 'Basicrealm "FakeRealm"'} 418 dict data ASCII_ART headers {'x-more-info' 'http //tools.ietf.org/html/rfc2324'} }r make_response r.status_code codeif code in code_map m code_map[code]if 'data' in m r.data m['data']if 'headers' in m r.headers m['headers']return r
def getNewRepository return FillRepository
def ValidatePropertyLink name value ValidateStringLength name value max_len _MAX_LINK_PROPERTY_LENGTH
@validatordef truthy value return value and not isinstance value six.string_types or value.strip
@xframe_options_sameorigindef _edit_document_collision request orig_rev curr_rev is_async_submit is_raw rev_form doc_form section_id rev doc content kuma.wiki.content.parse request.POST['content'] .injectSectionIDs .serialize if doc.is_template curr_content curr_rev.contentelse parsed_content kuma.wiki.content.parse curr_rev.content parsed_content.injectSectionIDs if section_id parsed_content.extractSection section_id curr_content parsed_content.serialize if is_raw response HttpResponse 'CONFLICT' response.status_code 409return responsecontext {'collision' True 'revision_form' rev_form 'document_form' doc_form 'content' content 'current_content' curr_content 'section_id' section_id 'original_revision' orig_rev 'current_revision' curr_rev 'revision' rev 'document' doc}return render request 'wiki/edit.html' context
@utils.arg 'hypervisor' metavar '<hypervisor>' help _ 'NameorIDofthehypervisortoshowtheuptimeof.' def do_hypervisor_uptime cs args hyper _find_hypervisor cs args.hypervisor hyper cs.hypervisors.uptime hyper utils.print_dict hyper.to_dict
def create_firewall_rule protocol action profile None **kwargs conn _auth profile return conn.create_firewall_rule protocol action **kwargs
def conn_from_flowtuple ft sip sport dip dport offset relts ftreturn {'src' sip 'sport' sport 'dst' dip 'dport' dport 'offset' offset 'time' relts}
def _distribute info if info[0].func is info[2] for arg in info[0].args if arg.func is info[1] conj argbreakelse return info[0]rest info[2] *[a for a in info[0].args if a is not conj ] return info[1] *list map _distribute [ info[2] c rest info[1] info[2] for c in conj.args] elif info[0].func is info[1] return info[1] *list map _distribute [ x info[1] info[2] for x in info[0].args] else return info[0]
def get_navigator_auth_password return NAVIGATOR.AUTH_PASSWORD_SCRIPT.get
def parse_pkt pkt if pkt.haslayer TCP and pkt.getlayer TCP .dport 80 and pkt.haslayer Raw return parse_http pkt elif pkt.haslayer TCP and pkt.getlayer TCP .dport 21 return parse_ftp pkt elif pkt.haslayer TCP and pkt.getlayer TCP .dport 389 return parse_ldap pkt return None None
def rgb_tuple_to_hsv rgb rgb_0_to_1 array rgb / 255.0 hsv rgb_to_hsv *tuple rgb_0_to_1 return hsv[0] * 360 hsv[1] * 100 hsv[2] * 100
def __within2 value within None errmsg None dtype None valid _value False value if dtype try _value dtype value valid _value in within except ValueError passelse valid _value in within if errmsg is None if dtype typename getattr dtype '__name__' hasattr dtype '__class__' and getattr dtype.__class__ 'name' dtype errmsg "{0}within'{1}'".format typename within else errmsg "within'{0}'".format within return valid _value errmsg
def _list_existing filesystem glob paths globs _constrain_glob glob paths time_start time.time listing []for g in sorted globs logger.debug 'Listing%s' g if filesystem.exists g listing.extend filesystem.listdir g logger.debug '%d%slistingstook%fstoreturn%ditems' len globs filesystem.__class__.__name__ time.time - time_start len listing return set listing
def fclusterdata X t criterion 'inconsistent' metric 'euclidean' depth 2 method 'single' R None X np.asarray X order 'c' dtype np.double if type X ! np.ndarray or len X.shape ! 2 raise TypeError 'TheobservationmatrixXmustbeannbymnumpyarray.' Y distance.pdist X metric metric Z linkage Y method method if R is None R inconsistent Z d depth else R np.asarray R order 'c' T fcluster Z criterion criterion depth depth R R t t return T
@depends HAS_ESX_CLI def set_coredump_network_config host username password dump_ip protocol None port None host_vnic 'vmk0' dump_port 6500 esxi_hosts None cmd 'systemcoredumpnetworkset-v{0}-i{1}-o{2}'.format host_vnic dump_ip dump_port ret {}if esxi_hosts if not isinstance esxi_hosts list raise CommandExecutionError "'esxi_hosts'mustbealist." for esxi_host in esxi_hosts response salt.utils.vmware.esxcli host username password cmd protocol protocol port port esxi_host esxi_host if response['retcode'] ! 0 response['success'] Falseelse response['success'] Trueret.update {esxi_host response} else response salt.utils.vmware.esxcli host username password cmd protocol protocol port port if response['retcode'] ! 0 response['success'] Falseelse response['success'] Trueret.update {host response} return ret
def __space_delimited_list value valid _value errmsg False value 'space-delimitedstring' try if hasattr value '__iter__' valid Trueelse _value value.split if _value [] raise ValueErrorvalid Trueexcept AttributeError passexcept ValueError passreturn valid _value errmsg
def wasLastResponseHTTPError threadData getCurrentThreadData return threadData.lastHTTPError and threadData.lastHTTPError[0] threadData.lastRequestUID
def default_index func @wraps func def check_default_index self *args **kwargs if self._file_path ! self._index_path raise AssertionError 'Cannotcall%ronindicesthatdonotrepresentthedefaultgitindex' % func.__name__ return func self *args **kwargs return check_default_index
def extract_data input_dir output_dir if os.path.isdir output_dir print 'Usingextracteddataat%s.' % output_dir returnfor filename in 'data_object_label_2.zip' 'data_object_image_2.zip' 'devkit_object.zip' filename os.path.join input_dir filename zf zipfile.ZipFile filename 'r' print 'Unzipping%s...' % filename zf.extractall output_dir
def conv3d input filters input_shape None filter_shape None border_mode 'valid' subsample 1 1 1 filter_flip True filter_dilation 1 1 1 input as_tensor_variable input filters as_tensor_variable filters conv_op AbstractConv3d imshp input_shape kshp filter_shape border_mode border_mode subsample subsample filter_flip filter_flip filter_dilation filter_dilation return conv_op input filters
def store_minions opts jid minions mminion None syndic_id None if mminion is None mminion salt.minion.MasterMinion opts states False rend False job_cache opts['master_job_cache']minions_fstr '{0}.save_minions'.format job_cache try mminion.returners[minions_fstr] jid minions syndic_id syndic_id except KeyError raise KeyError "Returner'{0}'doesnotsupportfunctionsave_minions".format job_cache
def sendMessage qry try getUserName except return _skypeError if qry 'skypeupdate' _writeFriends _getAvatars return len _readFriends .__str__ + 'friendsfoundandcached!' else m qry.partition ' ' ret skype 'MESSAGE' + m[0] + '' + m[2] if 'SENDING' in ret return 'Messagesentto' + m[0] else return 'ERRORsendingmessageto ' + m[0]
def find_snippet_files ft directory patterns ['%s.snippets' '%s_*.snippets' os.path.join '%s' '*' ]ret set directory os.path.expanduser directory for pattern in patterns for fn in glob.glob os.path.join directory pattern % ft ret.add os.path.realpath fn return ret
@signals.contributor_removed.connectdef remove_contributor_from_subscriptions node user if user._id not in node.admin_contributor_ids node_subscriptions get_all_node_subscriptions user node for subscription in node_subscriptions subscription.remove_user_from_subscription user
def dup_terms_gcd f K if dup_TC f K or not f return 0 f i 0for c in reversed f if not c i + 1else breakreturn i f[ - i ]
def get_reverse_primers id_map rev_primers {}for n in id_map.items rev_primers[n[1]['BarcodeSequence']] [str DNASequence curr_rev_primer .rc for curr_rev_primer in n[1]['ReversePrimer'].split ' ' ]return rev_primers
def theano_parzen data mu sigma x dataa x.dimshuffle 0 'x' 1 - mu.dimshuffle 'x' 0 1 / sigma E log_mean_exp -0.5 * a ** 2 .sum 2 Z mu.shape[1] * T.log sigma * numpy.sqrt numpy.pi * 2 return E - Z
def delete_entity_from_table key datastore datastore.batch_delete APP_ENTITY_TABLE [key]
def register_opts config config.register_opts METER_PUBLISH_OPTS group 'publisher_rpc'
def get_exception_data e err_data {'type' e.__class__.__name__ 'message' e 'detail' ''}return err_data
def hg_file_finder dirname '.' if not dirname dirname '.'if hg is None return find_files_with_cmd dirname return find_files_with_lib dirname
def _binary_compiler tmpl return lambda self l r tmpl % self.compile l self.compile r
def test_get_items mixin_cols attrs 'name' 'unit' 'dtype' 'format' 'description' 'meta' m mixin_cols['m']m.info.name 'm'm.info.format '{0}'m.info.description 'd'm.info.meta {'a' 1}t QTable [m] for item in [1 3] np.array [0 2] slice 1 3 t2 t[item]m2 m[item]assert_table_name_col_equal t2 'm' m[item] for attr in attrs assert getattr t2['m'].info attr getattr m.info attr assert getattr m2.info attr getattr m.info attr
def test_process_never_started qtbot quit_pyproc quit_pyproc.after_test
def get_problems_in_section section problem_descriptors defaultdict if not isinstance section UsageKey section_key UsageKey.from_string section else section_key sectionsection_descriptor modulestore .get_item section_key depth 3 for subsection in section_descriptor.get_children for vertical in subsection.get_children for component in vertical.get_children if component.location.category 'problem' and getattr component 'has_score' False problem_descriptors[unicode component.location ] componentreturn problem_descriptors
def p_function p if p[1] 'oneway' oneway Truebase 1else oneway Falsebase 0if p[ len p - 1 ] ' ' throws []else throws p[ len p - 1 ]p[0] [oneway p[ base + 1 ] p[ base + 2 ] p[ base + 4 ] throws]
def TestHuntHelper client_mock client_ids check_flow_errors False token None iteration_limit None TestHuntHelperWithMultipleMocks dict [ client_id client_mock for client_id in client_ids] check_flow_errors check_flow_errors iteration_limit iteration_limit token token
@not_implemented_for 'undirected' def weakly_connected_component_subgraphs G copy True for comp in weakly_connected_components G if copy yield G.subgraph comp .copy else yield G.subgraph comp
def process_iter def add pid proc Process pid _pmap[proc.pid] procreturn procdef remove pid _pmap.pop pid None a set pids b set _pmap.keys new_pids a - b gone_pids b - a for pid in gone_pids remove pid for pid proc in sorted list _pmap.items + list dict.fromkeys new_pids .items try if proc is None yield add pid elif proc.is_running yield proc else yield add pid except NoSuchProcess remove pid except AccessDenied if proc is None and pid in _pmap try yield _pmap[pid] except KeyError passelse raise
def translate_jobconf_for_all_versions variable return sorted set [variable] + list _JOBCONF_MAP.get variable {} .values
def validate_modules try jwt.rsa_loadexcept AttributeError raise ImproperlyConfigured 'PyJWT-Mozillanotimported.ThisisbecausethereisanotherJWTmoduleinstalled.TheJWTmoduleimportedisat {0}.Thiscanusuallybefixedbyrunning `pipuninstallPyJWT`and`pipuninstallPyJWT-mozilla`and`pipinstall--force--no-depsPyJWT-mozilla`'.format jwt.__file__
def _convert_timestamp value if isinstance value datetime.datetime value _microseconds_from_datetime value * 1e-06 return value
def onRequestCreateAccount registerName password datas INFO_MSG 'onRequestCreateAccount registerName %s' % registerName commitName registerNamerealAccountName commitNameKBEngine.createAccountResponse commitName realAccountName datas KBEngine.SERVER_SUCCESS
def filter_email_recipients_from_hooks to_field cc_field signal **kwargs if signal in _hooks for hook in _hooks[signal] to_field hook.get_to_field to_field **kwargs cc_field hook.get_cc_field cc_field **kwargs return to_field cc_field
def remove_port zone port permanent True cmd '--zone {0}--remove-port {1}'.format zone port if permanent cmd + '--permanent'return __firewall_cmd cmd
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def test_isiterable t1 Time.now assert not isiterable t1 t2 Time ['1999-01-0100 00 00.123456789' '2010-01-0100 00 00'] format 'iso' scale 'utc' assert isiterable t2
def _comp_coords hsp seq_type inter_lens assert seq_type in 'hit' 'query' seq_step 1 if hsp[ '%s_strand' % seq_type ] > 0 else -1 fstart hsp[ '%s_start' % seq_type ]fend fstart + len hsp[seq_type][0].replace '-' '' .replace '>' '' .replace '<' '' * seq_step coords [ fstart fend ]for idx block in enumerate hsp[seq_type][1 ] bstart coords[ -1 ][1] + inter_lens[idx] * seq_step bend bstart + seq_step * len block.replace '-' '' coords.append bstart bend if seq_step ! 1 for idx coord in enumerate coords coords[idx] coords[idx][1] coords[idx][0] return coords
def p_struct_or_union_specifier_2 t pass
def warning message env Environment env.loader FileSystemLoader osp.join CONFDIR_PATH 'templates' warning env.get_template 'warning.html' return warning.render css_path CSS_PATH text message
def makeLMS2RGB nm powerRGB interpolateCones interpolate.interp1d wavelength_5nm cones_SmithPokorny coneSens interpolateCones nm rgb_to_cones numpy.dot coneSens numpy.transpose powerRGB cones_to_rgb numpy.linalg.inv rgb_to_cones return cones_to_rgb
def register linter linter.register_checker ExceptionsChecker linter
def database_job pkg_id pkg_title pkg_dict call_action u'package_show' id pkg_id pkg_dict[u'title'] + pkg_titlepkg_dict call_action u'package_update' **pkg_dict
def html_keep_url text idx 0final ''link_tags re.compile ' ?<!["\'] ftp|http|https \\/\\/ \\w+ {0 1}\\w*@ ? [^\\s<"\']+ [0-9]+ ? \\/|\\/ [^\\s<"\'] ? ?![^\\s<"\']*["\']|[^\\s<"\']*</a> ' for item in re.finditer link_tags text final + text[idx item.start ]final + '<ahref "%s"target "_blank">%s</a>' % item.group 0 item.group 0 idx item.end final + text[idx ]return final
def _PrintErrorAndExit stream msg exit_code 2 stream.write msg sys.exit exit_code
def prefetch_one_level instances prefetcher attname rel_qs rel_obj_attr instance_attr single cache_name prefetcher.get_prefetch_queryset instances additional_prl getattr rel_qs '_prefetch_related_lookups' [] if additional_prl rel_qs._prefetch_related_lookups []all_related_objects list rel_qs rel_obj_cache {}for rel_obj in all_related_objects rel_attr_val rel_obj_attr rel_obj rel_obj_cache.setdefault rel_attr_val [] .append rel_obj for obj in instances instance_attr_val instance_attr obj vals rel_obj_cache.get instance_attr_val [] if single setattr obj cache_name vals[0] if vals else None else qs getattr obj attname .all qs._result_cache valsqs._prefetch_done Trueobj._prefetched_objects_cache[cache_name] qsreturn all_related_objects additional_prl
def side sankey n 1 prior len sankey.diagrams for i in range 0 2 * n 2 sankey.add flows [1 -1 ] orientations [ -1 -1 ] patchlabel str prior + i prior prior + i - 1 connect 1 0 alpha 0.5 sankey.add flows [1 -1 ] orientations [1 1] patchlabel str prior + i + 1 prior prior + i connect 1 0 alpha 0.5
def list_triggers name location '\\' pythoncom.CoInitialize task_service win32com.client.Dispatch 'Schedule.Service' task_service.Connect task_folder task_service.GetFolder location task_definition task_folder.GetTask name .Definitiontriggers task_definition.Triggersret []for trigger in triggers ret.append trigger.Id return ret
def ip_address_validators protocol unpack_ipv4 if protocol ! u'both' and unpack_ipv4 raise ValueError u"Youcanonlyuse`unpack_ipv4`if`protocol`issetto'both'" try return ip_address_validator_map[protocol.lower ]except KeyError raise ValueError u"Theprotocol'%s'isunknown.Supported %s" % protocol list ip_address_validator_map
def constr_tmul constraints values is_abs products []for constr val in zip constraints values products.append tmul constr.expr val is_abs return sum_dicts products
def safe_unpickle string try return pickle.loads string except return None
def get_filepath fileorpath if isinstance fileorpath basestring return fileorpathelif isinstance fileorpath DjangoFile return fileorpathelif hasattr fileorpath 'file_path' return fileorpath.file_pathelif hasattr fileorpath 'path' return fileorpath.pathelif hasattr fileorpath 'name' return fileorpath.namereturn fileorpath
def _clearSuite suite suite._tests []
def diff_texts a b filename a a.splitlines b b.splitlines return difflib.unified_diff a b filename filename ' original ' ' refactored ' lineterm ''
def nipy_spectral rc u'image' cmap u'nipy_spectral' im gci if im is not None im.set_cmap cm.nipy_spectral
def cgconfig_condrestart return service_cgconfig_control 'condrestart'
def rmfile path if osp.isfile path if is_win os.chmod path 511 os.remove path
@utils_routes.route '/pic/<path filename>' def send_pic filename return send_from_directory os.path.realpath '.' + '/static/' filename
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def get_vm_status vmid None name None if vmid is not None log.debug 'get_vm_status VMID{0}'.format vmid vmobj _get_vm_by_id vmid elif name is not None log.debug 'get_vm_status name{0}'.format name vmobj _get_vm_by_name name else log.debug 'get_vm_status NoIDorNAMEgiven' raise SaltCloudExecutionFailurelog.debug 'VMfound {0}'.format vmobj if vmobj is not None and 'node' in vmobj log.debug 'VM_STATUS Hasdesiredinfo.Retrieving.. {0} '.format vmobj['name'] data query 'get' 'nodes/{0}/{1}/{2}/status/current'.format vmobj['node'] vmobj['type'] vmobj['vmid'] return datalog.error 'VMorrequestedstatusnotfound..' return False
def get url conn urlopen url resp conn.read conn.close return resp
def _set_deep data_structure dot_path_or_list value_to_set assert hasattr data_structure '__setitem__' search_path Noneparam_type type dot_path_or_list if param_type in tuple list search_path dot_path_or_listelif param_type str search_path dot_path_or_list.split '.' assert len search_path > 0 'Missingvalidsearchpath'current_item data_structurefor search_key in search_path[ -1 ] current_item.setdefault search_key dict current_item current_item[search_key]current_item[search_path[ -1 ]] value_to_setreturn data_structure
def merge_valid_keys params valid_keys extra merged {}if not extra return mergedfor key in valid_keys if key in extra params[key] extra[key]merged[key] extra[key]return merged
def encode_to_py3bytes_or_py2str s fallback_encoding 'utf8'if IS_PY3 if isinstance s bytes passelse s str s try s bytes s DEFAULT_ENCODING except UnicodeEncodeError s bytes s fallback_encoding else try s unicode s DEFAULT_ENCODING except TypeError s unicode s try s s.encode DEFAULT_ENCODING except s s.encode fallback_encoding 'replace' return s
def parse_repository_tag repo_path tag_separator u' 'digest_separator u'@'if digest_separator in repo_path repo tag repo_path.rsplit digest_separator 1 return repo tag digest_separator repo tag repo_path u'' if tag_separator in repo_path repo tag repo_path.rsplit tag_separator 1 if u'/' in tag repo tag repo_path u'' return repo tag tag_separator
def _auth_key nonce username password digest _password_digest username password md5hash md5 data '%s%s%s' % nonce username digest md5hash.update data.encode 'utf-8' return _unicode md5hash.hexdigest
@_docstring 'work' def get_work_by_id id includes [] return _do_mb_query 'work' id includes
def fixed_ip_disassociate_all_by_timeout context host time return IMPL.fixed_ip_disassociate_all_by_timeout context host time
def _check_audience payload_dict audience if audience is None returnaudience_in_payload payload_dict.get 'aud' if audience_in_payload is None raise AppIdentityError 'Noaudfieldintoken {0}'.format payload_dict if audience_in_payload ! audience raise AppIdentityError 'Wrongrecipient {0}! {1} {2}'.format audience_in_payload audience payload_dict
def check_for_language lang_code for path in all_locale_paths if gettext_module.find 'django' path [to_locale lang_code ] is not None return Truereturn False
def get_root_key_from_entity_key key tokens key.split KIND_SEPARATOR return tokens[0] + KIND_SEPARATOR
def update_scene_exceptions indexer_id scene_exceptions season -1 [sickrage.srCore.cacheDB.db.delete x[u'doc'] for x in sickrage.srCore.cacheDB.db.get_many u'scene_exceptions' indexer_id with_doc True if x[u'doc'][u'season'] season ]sickrage.srCore.srLogger.info u'Updatingsceneexceptions' if indexer_id in exceptionsCache exceptionsCache[indexer_id] {}exceptionsCache[indexer_id][season] scene_exceptionsfor cur_exception in scene_exceptions sickrage.srCore.cacheDB.db.insert {u'_t' u'scene_exceptions' u'indexer_id' indexer_id u'show_name' cur_exception u'season' season}
def delete_course_update location update passed_id user if not passed_id return HttpResponseBadRequest try course_updates modulestore .get_item location except ItemNotFoundError return HttpResponseBadRequest course_update_items list reversed get_course_update_items course_updates passed_index _get_index passed_id if 0 < passed_index < len course_update_items course_update_item course_update_items[ passed_index - 1 ]course_update_item['status'] CourseInfoModule.STATUS_DELETEDcourse_update_items[ passed_index - 1 ] course_update_itemsave_course_update_items location course_updates course_update_items user return _get_visible_update course_update_items else return HttpResponseBadRequest _ 'Invalidcourseupdateid.'
def gf_irreducible n p K while True f gf_random n p K if gf_irreducible_p f p K return f
def _is_lun_id_available_on_host client host lun_id mapping client.get_volume_mappings_for_host host['hostRef'] used_lun_ids _get_used_lun_ids_for_mappings mapping return lun_id not in used_lun_ids
def sanitiseBase32 data data data.upper if '1' in data log.info 'Founda"1"inBase32-encoded"%s".Assumingit\'sactually"I".' % data data data.replace '1' 'I' if '0' in data log.info 'Founda"0"inBase32-encoded"%s".Assumingit\'sactually"O".' % data data data.replace '0' 'O' return data
def create_default_context context ssl.SSLContext ssl.PROTOCOL_SSLv23 context.verify_mode ssl.CERT_NONEcontext.check_hostname Falsecontext.options | ossllib.SSL_OP_NO_SSLv2context.options | ossllib.SSL_OP_NO_SSLv3context.options | ossllib.SSL_OP_NO_COMPRESSIONcontext.options | ossllib.SSL_OP_CIPHER_SERVER_PREFERENCEcontext.options | ossllib.SSL_OP_SINGLE_DH_USEcontext.options | ossllib.SSL_OP_SINGLE_ECDH_USEcontext._ctx.set_mode ossllib.SSL_MODE_ENABLE_PARTIAL_WRITE | ossllib.SSL_MODE_ACCEPT_MOVING_WRITE_BUFFER | ossllib.SSL_MODE_AUTO_RETRY return context
def colorTuple c return c.red c.green c.blue c.alpha
def test_history superConsole.SendKeys 'outputRedirectStart{ }True{ }{ENTER}' testRegex ''superConsole.SendKeys 'print"first"{ENTER}' testRegex + 'first'superConsole.SendKeys 'print"second"{ENTER}' testRegex + 'second'superConsole.SendKeys 'print"third"{ENTER}' testRegex + 'third'superConsole.SendKeys 'print"fourth"{ENTER}' testRegex + 'fourth'superConsole.SendKeys 'print"fifth"{ENTER}' testRegex + 'fifth'superConsole.SendKeys '{UP}{UP}{UP}{ENTER}' testRegex + 'third'superConsole.SendKeys '{UP}{ENTER}' testRegex + 'third'superConsole.SendKeys '{UP}{UP}{UP}{DOWN}{ENTER}' testRegex + 'second'superConsole.SendKeys '{UP}{ENTER}' testRegex + 'second'superConsole.SendKeys '{DOWN}{ENTER}' testRegex + 'third'superConsole.SendKeys '{DOWN}{ENTER}' testRegex + 'fourth'superConsole.SendKeys '{DOWN}{ENTER}' testRegex + 'fifth'superConsole.SendKeys '{UP}{UP}{ESC}print"sixth"{ENTER}' testRegex + 'sixth'superConsole.SendKeys '{UP}{ENTER}' testRegex + 'sixth'superConsole.SendKeys '{UP}{DOWN}{DOWN}{DOWN}{DOWN}{DOWN}{DOWN}{ENTER}' testRegex + 'sixth'superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex
def _get_closest_end end_after begin_after end_iter iter end_after begin_iter iter begin_after while True try e next end_iter except raise NoEnvError 'Noclosingenvironmentdetected' try b next begin_iter except breakif not e.begin > b.begin breakreturn e
def parseDict parent parent.count 0while True key Object parent 'key[]' yield key if key['bytecode'].value '0' break yield Object parent 'value[]' parent.count + 1
def _aspect_preserving_resize image smallest_side smallest_side tf.convert_to_tensor smallest_side dtype tf.int32 shape tf.shape image height shape[0]width shape[1] new_height new_width _smallest_size_at_least height width smallest_side image tf.expand_dims image 0 resized_image tf.image.resize_bilinear image [new_height new_width] align_corners False resized_image tf.squeeze resized_image resized_image.set_shape [None None 3] return resized_image
def sanitize_timestamp timestamp if not timestamp return timestampif not isinstance timestamp datetime.datetime timestamp timeutils.parse_isotime timestamp return timeutils.normalize_time timestamp
def check_returncode p out code p.returncodeif code 0 returnerrmap [None RarWarning RarFatalError RarCRCError RarLockedArchiveError RarWriteError RarOpenError RarUserError RarMemoryError RarCreateError RarNoFilesError RarWrongPassword]if UNRAR_TOOL ALT_TOOL errmap [None]if code > 0 and code < len errmap exc errmap[code]elif code 255 exc RarUserBreakelif code < 0 exc RarSignalExitelse exc RarUnknownErrorif out msg '%s[%d] %s' % exc.__doc__ p.returncode out else msg '%s[%d]' % exc.__doc__ p.returncode raise exc msg
def get_test_providers_dir if not os.path.isdir TEST_PROVIDERS_DOWNLOAD_DIR os.makedirs TEST_PROVIDERS_DOWNLOAD_DIR return TEST_PROVIDERS_DIR
def validate_repository_name app name user if name in ['None' None ''] return 'Entertherequiredrepositoryname.'if name in ['repos'] return 'Theterm<b>%s</b>isareservedwordinthetoolshed soitcannotbeusedasarepositoryname.' % name check_existing get_repository_by_name_and_owner app name user.username if check_existing is not None if check_existing.deleted return 'Youownadeletedrepositorynamed<b>%s</b> pleasechooseadifferentname.' % escape name else return 'Youalreadyownarepositorynamed<b>%s</b> pleasechooseadifferentname.' % escape name if len name < 2 return 'Repositorynamesmustbeatleast2charactersinlength.'if len name > 80 return 'Repositorynamescannotbemorethan80charactersinlength.'if not VALID_REPOSITORYNAME_RE.match name return 'Repositorynamesmustcontainonlylower-caseletters numbersandunderscore.'return ''
def dup_rshift f n K return f[ - n ]
def encode_packet packet packet_buff struct.pack '!HH' packet['opcode'] packet['session_id'] if packet['opcode'] in OPCODE_RRQ OPCODE_WRQ packet_buff + packet['file_name'] + '\x00' for k v in packet['options'].iteritems packet_buff + '%s\x00%s\x00' % k v elif packet['opcode'] OPCODE_DATA packet_buff + struct.pack '!H' packet['block_number'] packet_buff + packet['data']elif packet['opcode'] OPCODE_ACK packet_buff + struct.pack '!H' packet['block_number'] elif packet['opcode'] OPCODE_ERROR packet_buff + struct.pack '!H' packet['error_code'] packet_buff + packet['error_msg'] + '\x00' elif packet['opcode'] OPCODE_OACK for k v in packet['options'].iteritems packet_buff + '%s\x00%s\x00' % k v return packet_buff
def render_courseware request usage_key from courseware.views.views import render_xblockreturn render_xblock request unicode usage_key check_if_enrolled False
def Cauchy name x0 gamma return rv name CauchyDistribution x0 gamma
def projection if settings.get_security_map and not s3_has_role MAP_ADMIN auth.permission.fail return s3_rest_controller
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def benchmark_score_from_merged benchmark env_id episode_lengths episode_rewards episode_types return benchmark.score benchmark env_id episode_lengths episode_rewards episode_types
def _incompat_bottleneck_version method if method not in ['sum' 'prod'] return Falsetry import bottleneck as bnreturn bn.__version__ > LooseVersion '1.0' except ImportError return False
def axis name None cols None values None units None ax {}cNameOrder ['name' 'units' 'title']if name is not None ax['name'] nameif values is not None ax['values'] valuesif units is not None ax['units'] unitsif cols is not None ax['cols'] []for c in cols if type c ! list and type c ! tuple c [c]col {}for i in range 0 len c col[cNameOrder[i]] c[i]ax['cols'].append col return ax
def _options_browser cfg ret_config defaults virtualname options for option in options value _fetch_option cfg ret_config virtualname options[option] if value yield option value continueif defaults if option in defaults log.info 'Usingdefaultfor%s%s' virtualname option yield option defaults[option] continuecontinue
def genDelimiter fileName if fileName.endswith '.csv' '.CSV' delim ' 'else delim ' DCTB 'return delim
def _handle_broken_tcl_tk if is_win and is_venv basedir os.path.join base_prefix 'tcl' files os.listdir basedir for f in files abs_path os.path.join basedir f if f.startswith 'tcl' and os.path.isdir abs_path os.environ['TCL_LIBRARY'] abs_pathelif f.startswith 'tk' and os.path.isdir abs_path os.environ['TK_LIBRARY'] abs_pathelif f.startswith 'tix' and os.path.isdir abs_path os.environ['TIX_LIBRARY'] abs_path
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def regex_filter query model filters regexp_op_map {'postgresql' '~' 'mysql' 'REGEXP' 'oracle' 'REGEXP_LIKE' 'sqlite' 'REGEXP'}db_string CONF.sql_connection.split ' ' [0].split '+' [0]db_regexp_op regexp_op_map.get db_string 'LIKE' for filter_name in filters.iterkeys try column_attr getattr model filter_name except AttributeError continueif 'property' type column_attr .__name__ continuequery query.filter column_attr.op db_regexp_op str filters[filter_name] return query
def consider_constant x warnings.warn 'consider_constant isdeprecated usezero_grad ordisconnected_grad instead.' stacklevel 3 return consider_constant_ x
def getMaximumByVector3Paths paths maximum Vector3 -9.876543219876543e+17 -9.876542319876543e+17 -9.876543219876543e+17 for path in paths for point in path maximum.maximize point return maximum
def resource_path resource *elements return _join_path_tuple resource_path_tuple resource *elements
def get_unit_name measurement_unit length 'long' locale LC_NUMERIC locale Locale.parse locale unit _find_unit_pattern measurement_unit locale locale if not unit raise UnknownUnitError unit measurement_unit locale locale return locale.unit_display_names.get unit {} .get length
def sids test_songs return [s.sid for s in test_songs]
def is_maximal_matching G matching if isinstance matching dict matching matching_dict_to_set matching if not is_matching G matching return Falseall_edges set map frozenset G.edges matched_edges set map frozenset matching unmatched_edges all_edges - matched_edges return all not is_matching G matching | {e} for e in unmatched_edges
def dt_to_decimal utc decimal.getcontext .prec 30return decimal.Decimal str calendar.timegm utc.utctimetuple + decimal.Decimal str utc.microsecond / decimal.Decimal '1000000.0'
def runstest_1samp x cutoff 'mean' correction True if cutoff 'mean' cutoff np.mean x elif cutoff 'median' cutoff np.median x xindicator x > cutoff .astype int return Runs xindicator .runs_test correction correction
def order_angles_golden_ratio theta interval 180def angle_distance a b difference a - b return min abs difference % interval abs difference % - interval remaining list np.argsort theta index remaining.pop 0 angle theta[index] yield index angle_increment interval * 1 - np.sqrt 5 - 1 / 2 while remaining angle angle + angle_increment % interval insert_point np.searchsorted theta[remaining] angle index_below insert_point - 1 index_above 0 if insert_point len remaining else insert_point distance_below angle_distance angle theta[remaining[index_below]] distance_above angle_distance angle theta[remaining[index_above]] if distance_below < distance_above yield remaining.pop index_below else yield remaining.pop index_above
def _init_python_printing stringify_func **settings import sysfrom sympy.core.compatibility import builtinsdef _displayhook arg "Python'spretty-printerdisplayhook.\n\nThisfunctionwasadaptedfrom \n\nhttp //www.python.org/dev/peps/pep-0217/\n\n"if arg is not None builtins._ Noneprint stringify_func arg **settings builtins._ argsys.displayhook _displayhook
def store_item context builder arrayty val ptr align None if arrayty.aligned else 1 return context.pack_value builder arrayty.dtype val ptr align align
def insert_into_file fileobj data start end buffer StringIO fileobj.seek end copyfileobj fileobj buffer -1 buffer.flush buffer.seek 0 fileobj.seek start fileobj.write data fileobj.flush fileobj.truncate delta fileobj.tell - end copyfileobj buffer fileobj -1 fileobj.flush buffer.close return delta
def _bytes_iterator_py3 bytes_ for b in bytes_ yield bytes [b]
def unique_resolved_paths paths rps _slashappend_or_add_error resolve_parent p 'unique_resolved_paths' for p in paths return frozenset x for x in rps if x is not None
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def get_system_info key default None from sqlalchemy.exc import ProgrammingErrortry obj meta.Session.query SystemInfo .filter_by key key .first if obj return obj.valueexcept ProgrammingError meta.Session.rollback return default
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
def run_paired_t bt s1 s2 test_stats []pvals []s1_indices [bt.index i axis 'sample' for i in s1]s2_indices [bt.index i axis 'sample' for i in s2]for data in bt.iter_data axis 'observation' test_stat pval t_paired data.take s1_indices data.take s2_indices test_stats.append test_stat pvals.append pval return test_stats pvals
def printf builder format *args assert isinstance format str mod builder.modulecstring voidptr_tfmt_bytes make_bytearray format + '\x00' .encode 'ascii' global_fmt global_constant mod 'printf_format' fmt_bytes fnty ir.FunctionType int32_t [cstring] var_arg True fn mod.get_global 'printf' if fn is None fn ir.Function mod fnty name 'printf' ptr_fmt builder.bitcast global_fmt cstring return builder.call fn [ptr_fmt] + list args
def replace_named_groups pattern named_group_indices [ m.start 0 m.end 0 m.group 1 for m in named_group_matcher.finditer pattern ]group_pattern_and_name []for start end group_name in named_group_indices unmatched_open_brackets prev_char 1 None for idx val in enumerate list pattern[end ] if unmatched_open_brackets 0 group_pattern_and_name.append pattern[start end + idx ] group_name breakif val ' ' and prev_char ! '\\' unmatched_open_brackets + 1elif val ' ' and prev_char ! '\\' unmatched_open_brackets - 1prev_char valfor group_pattern group_name in group_pattern_and_name pattern pattern.replace group_pattern group_name return pattern
def validate_mailgun_webhook timestamp token signature message ''.join timestamp token expected_mac hmac.new g.secrets['mailgun_api_key'] message hashlib.sha256 .hexdigest if not constant_time_compare expected_mac signature g.stats.simple_event 'mailgun.incoming.bad_signature' return Falseif abs int timestamp - time.time > MAX_TIMESTAMP_DEVIATION g.stats.simple_event 'mailgun.incoming.bad_timestamp' return Falsereturn True
@receiver user_logged_out def handle_customer_logout sender **kwargs kwargs[u'request'].customer SimpleLazyObject lambda CustomerModel.objects.get_from_request kwargs[u'request']
def get_doc_url page anchor '' if '-dev' in VERSION version 'latest'else version 'weblate-%s' % VERSION url 'https //docs.weblate.org/en/%s/%s.html' % version page if anchor ! '' url + '#%s' % anchor return url
def parse_config_string config_string issue_warnings True config_dict {}my_splitter shlex.shlex config_string posix True my_splitter.whitespace ' 'my_splitter.whitespace_split Truefor kv_pair in my_splitter kv_pair kv_pair.strip if not kv_pair continuekv_tuple kv_pair.split ' ' 1 if len kv_tuple 1 if issue_warnings TheanoConfigWarning.warn "Configkey'%s'hasnovalue ignoringit" % kv_tuple[0] stacklevel 1 else k v kv_tupleconfig_dict[k] vreturn config_dict
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def permutedims expr perm if not isinstance expr NDimArray raise TypeError 'expressionhastobeanN-dimarray' from sympy.combinatorics import Permutationif not isinstance perm Permutation perm Permutation list perm if perm.size ! expr.rank raise ValueError 'wrongpermutationsize' iperm ~ perm indices_span perm [range i for i in expr.shape] new_array [None] * len expr for i idx in enumerate itertools.product *indices_span t iperm idx new_array[i] expr[t]new_shape perm expr.shape return expr.func new_array new_shape
def merge_cookies cookiejar cookies if not isinstance cookiejar cookielib.CookieJar raise ValueError 'YoucanonlymergeintoCookieJar' if isinstance cookies dict cookiejar cookiejar_from_dict cookies cookiejar cookiejar overwrite False elif isinstance cookies cookielib.CookieJar try cookiejar.update cookies except AttributeError for cookie_in_jar in cookies cookiejar.set_cookie cookie_in_jar return cookiejar
def write_chunk outfile tag data '' outfile.write struct.pack '!I' len data outfile.write tag outfile.write data checksum zlib.crc32 tag checksum zlib.crc32 data checksum outfile.write struct.pack '!i' checksum
def get_plot_commands import inspectexclude {u'colormaps' u'colors' u'connect' u'disconnect' u'get_plot_commands' u'get_current_fig_manager' u'ginput' u'plotting' u'waitforbuttonpress'}exclude | set colormaps this_module inspect.getmodule get_plot_commands commands set for name obj in list six.iteritems globals if name.startswith u'_' or name in exclude continueif inspect.isfunction obj and inspect.getmodule obj is this_module commands.add name return sorted commands
def skip_if_configuration_set configuration value message None if getattr config configuration value if message is not None raise SkipTest message else raise SkipTest
def to_slug value incoming None errors 'strict' value safe_decode value incoming errors value unicodedata.normalize 'NFKD' value .encode 'ascii' 'ignore' .decode 'ascii' value SLUGIFY_STRIP_RE.sub '' value .strip .lower return SLUGIFY_HYPHENATE_RE.sub '-' value
@receiver post_save sender User def user_post_save_callback sender **kwargs user kwargs['instance']emit_field_changed_events user user sender._meta.db_table excluded_fields ['last_login' 'first_name' 'last_name'] hidden_fields ['password']
def is_nonstring_iterable obj return isinstance obj Iterable and not isinstance obj string_types
def comparison_negative logical_line match COMPARE_NEGATIVE_REGEX.search logical_line if match pos match.start 1 if match.group 2 'in' yield pos "E713testformembershipshouldbe'notin'" else yield pos "E714testforobjectidentityshouldbe'isnot'"
def validate_filters action filters if action in settings.snapshot_actions filtertypes settings.snapshot_filtertypes else filtertypes settings.index_filtertypes for f in filters if f['filtertype'] not in filtertypes raise ConfigurationError '"{0}"filtertypeisnotcompatiblewithaction"{1}"'.format f['filtertype'] action return filters
def hfloat f p 5 i int f return i if i f else u'{0 .{p}}'.format f p p
def session_info consul_url None session None **kwargs ret {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not session raise SaltInvocationError 'Requiredargument"session"ismissing.' query_params {}if 'dc' in kwargs query_params['dc'] kwargs['dc']function 'session/info/{0}'.format session ret _query consul_url consul_url function function query_params query_params return ret
def test_3d_separations c1 ICRS ra 1 * u.deg dec 1 * u.deg distance 9 * u.kpc c2 ICRS ra 1 * u.deg dec 1 * u.deg distance 10 * u.kpc sep3d c2.separation_3d c1 assert isinstance sep3d Distance assert_allclose sep3d - 1 * u.kpc 0 * u.kpc atol 1e-12 * u.kpc
def delete_security_group security_group profile None conn _auth profile return conn.delete_security_group security_group
def wigner_6j j_1 j_2 j_3 j_4 j_5 j_6 prec None res -1 ** int j_1 + j_2 + j_4 + j_5 * racah j_1 j_2 j_5 j_4 j_3 j_6 prec return res
def DefineFlags flag_values FLAGS module_bar.DefineFlags flag_values flag_values gflags.DEFINE_boolean 'tmod_foo_bool' True 'Booleanflagfrommodulefoo.' flag_values flag_values gflags.DEFINE_string 'tmod_foo_str' 'default' 'Stringflag.' flag_values flag_values gflags.DEFINE_integer 'tmod_foo_int' 3 'Sampleintflag.' flag_values flag_values
def _decorate_axes ax freq kwargs if not hasattr ax '_plot_data' ax._plot_data []ax.freq freqxaxis ax.get_xaxis xaxis.freq freqif not hasattr ax 'legendlabels' ax.legendlabels [kwargs.get 'label' None ]else ax.legendlabels.append kwargs.get 'label' None ax.view_interval Noneax.date_axis_info None
def first_in_class C Y [] n C.nlamda -1 nu [None] * n mu [None] * n next_alpha Falsefor alpha in range 1 n for beta in range lamda + 1 nu[mu[beta]] Nonefor w in Y if C.table[alpha][C.A_dict[w]] ! alpha next_alpha Truebreakif next_alpha next_alpha Falsecontinuemu[0] alphanu[alpha] 0lamda 0for beta in range n for x in C.A gamma C.table[beta][C.A_dict[x]]delta C.table[mu[beta]][C.A_dict[x]]if gamma is None or delta is None next_alpha Truebreakif nu[delta] is None lamda + 1nu[delta] lamdamu[lamda] deltaif nu[delta] < gamma return Falseif nu[delta] > gamma next_alpha Truebreakif next_alpha next_alpha Falsebreakreturn True
def scan opts ret {}for root dirs files in os.walk opts['root'] for fn_ in files full os.path.join root fn_ if full.endswith '.py' ret.update mod_data opts full return ret
def cache_tip_names tree if hasattr tree '_tip_names' returnelse for n in tree.postorder if n.isTip n._tip_names [n.Name]else n._tip_names reduce add [c._tip_names for c in n.Children]
def get_preferred_arguments_encoding return locale.getdefaultlocale [1] or u'latin1'
def _get_css_imports data inline False imports _get_css_imports_cssutils data inline if imports is None imports _get_css_imports_regex data return imports
def test_read_normal_names_include table '\n#comment withblanklineabove \n \nCol1Col2Col3\n \n1.2"hello"3\n2.4\'sworlds7\n \n'reader ascii.get_reader Reader ascii.RST names 'name1' 'name2' 'name3' include_names 'name1' 'name3' dat reader.read table assert_equal dat.colnames ['name1' 'name3'] assert_almost_equal dat[1][0] 2.4 assert_equal dat[0][1] 3
def min_cost_flow_cost G demand 'demand' capacity 'capacity' weight 'weight' return nx.network_simplex G demand demand capacity capacity weight weight [0]
def ip_numstr_to_quad num n int num packed struct.pack '>L' n bytes struct.unpack 'BBBB' packed return '.'.join map str bytes
def append_period text if text[ -1 ] '"' return text[0 -1 ] + '."' return text
def _find_rteq a l x i bisect_right a x lo l if i ! len a + 1 and a[ i - 1 ] x return i - 1 raise ValueError
def close_svn_review_request payload server_url review_id_to_commits_map defaultdict list commit_message payload.get u'message' branch_name payload.get u'changeset_url' u'SVNRepository' revision u'%s%d' % u'Revision ' payload.get u'revision' review_request_id get_review_request_id commit_message server_url None commit_entry u'%s %s ' % branch_name revision review_id_to_commits_map[review_request_id].append commit_entry close_all_review_requests review_id_to_commits_map
def pick_char array0 unique []duplicate []for i in array0 if i in duplicate passelif i in unique duplicate.append i unique.remove i else unique.append i return unique[0]
def apply_provider_facts facts provider_facts if not provider_facts return factscommon_vars [ 'hostname' 'ip' 'public_hostname' 'public_ip' ]for h_var ip_var in common_vars ip_value provider_facts['network'].get ip_var if ip_value facts['common'][ip_var] ip_valuefacts['common'][h_var] choose_hostname [provider_facts['network'].get h_var ] facts['common'][h_var] facts['provider'] provider_factsreturn facts
def init mpstate return CmdlongModule mpstate
def moveHost host oldSwitch newSwitch newPort None hintf sintf host.connectionsTo oldSwitch [0]oldSwitch.moveIntf sintf newSwitch port newPort return hintf sintf
def test_list_command script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' 'simple2 3.0' result script.pip 'list' expect_stderr True assert WARN_FORMAT in result.stderr str result assert 'simple 1.0 ' in result.stdout str result assert 'simple2 3.0 ' in result.stdout str result
def get_locales_from_config locales_offered config.get 'ckan.locales_offered' '' .split filtered_out config.get 'ckan.locales_filtered_out' '' .split locale_default [config.get 'ckan.locale_default' 'en' ]locale_order config.get 'ckan.locale_order' '' .split known_locales get_locales all_locales set known_locales | set locales_offered | set locale_order | set locale_default all_locales - set filtered_out return all_locales
def add_advanced_component page menu_index name page.wait_for_component_menu click_css page 'button>span.large-advanced-icon' menu_index require_notification False page.wait_for_element_visibility '.new-component-advanced' 'Advancedcomponentmenuisvisible' component_css 'button[data-category {}]'.format name page.wait_for_element_visibility component_css 'Advancedcomponent{}isvisible'.format name click_css page component_css 0
def _azimuth2math azimuth elevation theta np.radians 90 - azimuth % 360 phi np.radians 90 - elevation return theta phi
def subdict d keys result {}for key in keys if key in d result[key] d[key]return result
def track_from_url url timeout DEFAULT_ASYNC_TIMEOUT param_dict dict url url return _upload param_dict timeout data None
def entity_from_protobuf pb key Noneif pb.HasField 'key' key key_from_protobuf pb.key entity_props {}entity_meanings {}exclude_from_indexes []for prop_name value_pb in _property_tuples pb value _get_value_from_value_pb value_pb entity_props[prop_name] valueis_list isinstance value list meaning _get_meaning value_pb is_list is_list if meaning is not None entity_meanings[prop_name] meaning value if is_list exclude_values set value_pb.exclude_from_indexes for value_pb in value_pb.array_value.values if len exclude_values ! 1 raise ValueError 'Foranarray_value subvaluesmusteitherallbeindexedorallexcludedfromindexes.' if exclude_values.pop exclude_from_indexes.append prop_name elif value_pb.exclude_from_indexes exclude_from_indexes.append prop_name entity Entity key key exclude_from_indexes exclude_from_indexes entity.update entity_props entity._meanings.update entity_meanings return entity
def test_softmax def softmax values m np.max values e np.exp values - m return e / np.sum e x K.placeholder ndim 2 f K.function [x] [activations.softmax x ] test_values get_standard_values result f [test_values] [0]expected softmax test_values assert_allclose result expected rtol 1e-05
def test_Ellipse2D amplitude 7.5 x0 y0 15 15 theta Angle 45 u'deg' em models.Ellipse2D amplitude x0 y0 7 3 theta.radian y x np.mgrid[0 30 0 30]e em x y assert np.all e[ e > 0 ] amplitude assert e[ y0 x0 ] amplitude rotation models.Rotation2D angle theta.degree point1 [2 0]point2 rotation *point1 point1 np.array point1 + [x0 y0] point2 np.array point2 + [x0 y0] e1 models.Ellipse2D amplitude x0 y0 7 3 theta 0.0 e2 models.Ellipse2D amplitude x0 y0 7 3 theta theta.radian assert e1 *point1 e2 *point2
def define_xml_str xml conn __get_conn return conn.defineXML xml is not None
def categorize df columns None index None **kwargs if columns is None columns list df.select_dtypes ['object' 'category'] .columns elif is_scalar columns columns [columns]categories [get_categories df[col] for col in columns]if index is False index Noneelse index get_categories df.index index is None values compute index *categories **kwargs categories {c v for c v in zip columns values[1 ] if v is not None }if not len categories and index is None return dfreturn df.map_partitions _categorize_block categories values[0]
def make_linkcode_resolve package url_fmt revision _get_git_revision return partial _linkcode_resolve revision revision package package url_fmt url_fmt
def mksalt method None if method is None method methods[0]s '${}$'.format method.ident if method.ident else '' s + ''.join _sr.choice _saltchars for char in range method.salt_chars return s
def unrar_check rar version 0original ''if rar try version run_simple rar except return version original original 'AlexanderRoshal' in version m re.search 'RAR\\s \\d+ \\. \\d+ ' version if m version int m.group 1 * 100 + int m.group 2 else version 0return version original
def primary_key_hash keys if isinstance keys[0] six.text_type keys[0] keys[0].encode 'utf-8' return hashlib.sha1 keys[0] .hexdigest
def gruntz e z z0 dir '+' if not z.is_Symbol raise NotImplementedError 'SecondargumentmustbeaSymbol' r Noneif z0 oo r limitinf e z elif z0 - oo r limitinf e.subs z - z z else if str dir '-' e0 e.subs z z0 - 1 / z elif str dir '+' e0 e.subs z z0 + 1 / z else raise NotImplementedError "dirmustbe'+'or'-'" r limitinf e0 z return r.rewrite 'intractable' deep True
def pr_instance_type pe_id if pe_id etable current.s3db.pr_pentityrow current.db etable.pe_id pe_id .select etable.instance_type limitby 0 1 .first if row return row.instance_typereturn None
def seuclidean u v V u _validate_vector u v _validate_vector v V _validate_vector V dtype np.float64 if V.shape[0] ! u.shape[0] or u.shape[0] ! v.shape[0] raise TypeError 'Vmustbea1-Darrayofthesamedimensionasuandv.' return np.sqrt u - v ** 2 / V .sum
def float_round value precision_digits None precision_rounding None rounding_method 'HALF-UP' rounding_factor _float_check_precision precision_digits precision_digits precision_rounding precision_rounding if rounding_factor 0 or value 0 return 0.0normalized_value value / rounding_factor epsilon_magnitude math.log abs normalized_value 2 epsilon 2 ** epsilon_magnitude - 53 if rounding_method 'HALF-UP' normalized_value + cmp normalized_value 0 * epsilon rounded_value round normalized_value elif rounding_method 'UP' sign cmp normalized_value 0 normalized_value - sign * epsilon rounded_value math.ceil abs normalized_value * sign result rounded_value * rounding_factor return result
def send_notification user email_dict import ckan.lib.mailerif not user.get 'email' returntry ckan.lib.mailer.mail_recipient user['display_name'] user['email'] email_dict['subject'] email_dict['body'] except ckan.lib.mailer.MailerException raise
def monkeypatch_tarfile_copyfileobj import tarfilefrom wal_e import copyfileobjtarfile.copyfileobj copyfileobj.copyfileobj
def serversetting accessing_obj accessed_obj *args **kwargs if not args or not args[0] return Falseif len args < 2 setting args[0]val 'True'else setting val args[0] args[1] if val 'True' val Trueelif val 'False' val Falseelif val.isdigit val int val if setting in settings._wrapped.__dict__ return settings._wrapped.__dict__[setting] val return False
def to_gettext rule rule PluralRule.parse rule used_tags rule.tags | set [_fallback_tag] _compile _GettextCompiler .compile_get_index [tag for tag in _plural_tags if tag in used_tags ].indexresult [ 'nplurals %d;plural ' % len used_tags ]for tag ast in rule.abstract result.append '%s?%d ' % _compile ast _get_index tag result.append '%d ' % _get_index _fallback_tag return ''.join result
def get_stores ret dict cmd "Get-ChildItem-Path'Cert \\'|Select-ObjectLocationName StoreNames"items _cmd_run cmd cmd as_json True for item in items ret[item['LocationName']] list for store in item['StoreNames'] ret[item['LocationName']].append store return ret
def cerr *args cprint 'stderr' *args
def _toEndpoint description certificate None from twisted.internet import reactortry port int description except ValueError return endpoints.serverFromString reactor description warnings.warn 'Specifyingplainportsand/oracertificateisdeprecatedsinceTwisted11.0;useendpointdescriptionsinstead.' category DeprecationWarning stacklevel 3 if certificate ctx SSLContextFactory certificate return endpoints.SSL4ServerEndpoint reactor port ctx return endpoints.TCP4ServerEndpoint reactor port
def gcodePath newType pathType layerThickness startPoint if layerThickness < 0.0 layerThickness 0.01if profile.getProfileSetting 'spiralize' 'True' layerThickness profile.getProfileSettingFloat 'layer_height' return {'type' newType 'pathType' pathType 'layerThickness' layerThickness 'points' [startPoint] 'extrusion' [0.0]}
def pidof target if isinstance target tubes.ssh.ssh_channel return [target.pid]elif isinstance target tubes.sock.sock local target.sock.getsockname remote target.sock.getpeername def match c return c.raddr c.laddr c.status local remote 'ESTABLISHED' return [c.pid for c in psutil.net_connections if match c ]elif isinstance target tuple host port targethost socket.gethostbyname host def match c return c.raddr host port return [c.pid for c in psutil.net_connections if match c ]elif isinstance target tubes.process.process return [target.proc.pid]else return pid_by_name target
def CreateCryptKeyset name return _CreateKeyset name keyinfo.DECRYPT_AND_ENCRYPT keyinfo.AES
def getVoronoiLoopByPoint inside loop outside insideMinusOutside inside - outside insideMinusOutside / abs insideMinusOutside rotation complex insideMinusOutside.real - insideMinusOutside.imag rotatedInside inside * rotation rotatedLoop euclidean.getRotatedComplexes rotation loop rotatedOutside outside * rotation midX 0.5 * rotatedInside.real + rotatedOutside.real voronoiLoop []for pointIndex point in enumerate loop nextIndex pointIndex + 1 % len loop addVoronoiPoint point loop[nextIndex] midX voronoiLoop rotatedLoop[pointIndex] rotatedLoop[nextIndex] return voronoiLoop
def flatten_reply reply nodes dupes {} set for item in reply [dupes.add name for name in item if name in nodes ]nodes.update item if dupes warnings.warn DuplicateNodenameWarning W_DUPNODE.format pluralize len dupes u'name' u' '.join sorted dupes return nodes
def fd_by_path paths stats set for path in paths try fd os.open path os.O_RDONLY except OSError continuetry stats.add os.fstat fd [1 3] finally os.close fd def fd_in_stats fd try return os.fstat fd [1 3] in stats except OSError return Falsereturn [_fd for _fd in range get_fdmax 2048 if fd_in_stats _fd ]
def add_page_if_missing request try return {'feincms_page' Page.objects.for_request request best_match True }except Page.DoesNotExist return {}
def parse_cmdline argv global BASE_DIRECTORY VERBOSE SUMMARYDEFAULT_BASE_DIR os.path.join os.path.dirname os.path.realpath sys.argv[0] 'collectors' parser OptionParser description 'Runspylintrecursivelyonadirectory' parser.add_option '-b' '--base-dir' dest 'base_directory' metavar 'DIR' default DEFAULT_BASE_DIR help 'Directorytostartlinting' parser.add_option '-v' '--verbose' dest 'verbose' action 'store_true' default False help 'Verbosemode logdebugmessages .' parser.add_option '-a' '--show-all' dest 'show_all' action 'store_true' default False help 'Bydefault weareonlyshowingerrorlines' parser.add_option '-s' '--summary' dest 'summary' action 'store_true' default False help 'Showsummaryreport' options args parser.parse_args args argv[1 ] VERBOSE options.verboseBASE_DIRECTORY options.base_directoryreturn options args
def get_seq_number name head tail os.path.splitext name if tail '.ts' match set num match_ts name else num tail[1 ]if num.isdigit return int num else return 0
def get_per_lib_sff_fps sff_dir for dirpath dirnames fnames in walk sff_dir for fname in fnames if fname.endswith '.sff' libname _ splitext fname yield libname join dirpath fname
def stripascii string ord_ ord if sys.version_info[0] < 3 else lambda x x i len string while i i - 1if 8 < ord_ string[i] < 127 breakelse i -1 return string[ i + 1 ]
def auth_basic check realm 'private' text 'Accessdenied' def decorator func def wrapper *a **ka user password request.auth or None None if user is None or not check user password response.headers['WWW-Authenticate'] 'Basicrealm "%s"' % realm return HTTPError 401 text return func *a **ka return wrapperreturn decorator
def acos x np import_module 'numpy' if isinstance x int float if abs x > 1 return interval - np.inf np.inf is_valid False else return interval np.arccos x np.arccos x elif isinstance x interval if x.is_valid is False or x.start > 1 or x.end < -1 return interval - np.inf np.inf is_valid False elif x.start < -1 or x.end > 1 return interval - np.inf np.inf is_valid None else start np.arccos x.start end np.arccos x.end return interval start end is_valid x.is_valid
def csvwrite inlist stringify False out_list []for entry in inlist if stringify new_entry []for val in entry if not isinstance val basestring val str val new_entry.append val entry new_entrythis_line ' '.join [elem_quote val for val in entry] out_list.append this_line return out_list
def get_time_zone_offset time_zone date_time None date_time datetime.now utc if date_time is None else date_time return _format_time_zone_string time_zone date_time '%z'
@pytest.mark.skipif not ON_WINDOWS reason 'Windows-onlyUNCfunctionality' def test_uncpushd_push_base_push_rempath xonsh_builtins pass
@_docstring 'series' def get_series_by_id id includes [] return _do_mb_query 'series' id includes
def zmap scores compare axis 0 ddof 0 scores compare map np.asanyarray [scores compare] mns compare.mean axis axis sstd compare.std axis axis ddof ddof if axis and mns.ndim < compare.ndim return scores - np.expand_dims mns axis axis / np.expand_dims sstd axis axis else return scores - mns / sstd
def get_cohorted_user_partition course for user_partition in course.user_partitions if user_partition.scheme CohortPartitionScheme return user_partitionreturn None
def key_entry entry name value entryif stat.S_ISDIR value[0] name + '/'return name
def ode_almost_linear eq func order match return ode_1st_linear eq func order match
def generic_weighted_projected_graph B nodes weight_function None if B.is_multigraph raise nx.NetworkXError 'notdefinedformultigraphs' if B.is_directed pred B.predG nx.DiGraph else pred B.adjG nx.Graph if weight_function is None def weight_function G u v return len set G[u] & set pred[v] G.graph.update B.graph G.add_nodes_from n B.node[n] for n in nodes for u in nodes nbrs2 set n for nbr in set B[u] for n in B[nbr] - set [u] for v in nbrs2 weight weight_function B u v G.add_edge u v weight weight return G
def getIcons filename None icons {}if filename is None filename join dirname abspath __file__ 'base.png' im Image.open filename icons['24'] pilToBitmap im scaleFactor 0.5 icons['24add'] pilToBitmap im scaleFactor 0.5 filename128 filename[ -4 ] + '128.png' if False im Image.open filename128 else im Image.open filename icons['48'] pilToBitmap im add Image.open join dirname abspath __file__ 'add.png' im.paste add [0 0 add.size[0] add.size[1]] mask add icons['48add'] pilToBitmap im return icons
def invalidate_cms_page_cache version _get_cache_version _set_cache_version version + 1
def isbow vec if scipy.sparse.issparse vec vec vec.todense .tolist try id_ val_ vec[0] id_ val_ int id_ float val_ except IndexError return Trueexcept Exception return Falsereturn True
@synchronized IO_LOCK def remove_data _id path path os.path.join path _id try if os.path.exists path os.remove path logging.info '%sremoved' path except logging.debug 'Failedtoremove%s' path
def PathCollection mode 'agg' *args **kwargs if mode 'raw' return RawPathCollection *args **kwargs elif mode 'agg+' return AggPathCollection *args **kwargs return AggFastPathCollection *args **kwargs
def load_check_from_places check_config check_name checks_places agentConfig load_success load_failure {} {} for check_path_builder in checks_places check_path check_path_builder check_name if not os.path.exists check_path continue check_is_valid check_class load_failure get_valid_check_class check_name check_path if not check_is_valid continue load_success load_failure _initialize_check check_config check_name check_class agentConfig _update_python_path check_config log.debug 'Loaded%s' % check_path breakreturn load_success load_failure
def copy_sample_file app filename dest_path None if dest_path is None dest_path os.path.abspath app.config.tool_data_path sample_file_name basic_util.strip_path filename copied_file sample_file_name.replace '.sample' '' full_source_path os.path.abspath filename full_destination_path os.path.join dest_path sample_file_name if full_source_path ! full_destination_path shutil.copy full_source_path full_destination_path if not os.path.lexists os.path.join dest_path copied_file shutil.copy full_source_path os.path.join dest_path copied_file
def struct_variable_codeblocks variable policies id symbol_table sub name 'V%i' % id if variable not in symbol_table symbol_table[variable] namesub dict sub sub['id'] idsub['fail'] failure_code_init sub sub['py_ptr'] 'py_%s' % name sub['stor_ptr'] 'storage_%s' % name struct_builder CodeBlock * [apply_policy policy variable name sub for policy in policies[0]] + [sub] sub['id'] id + 1 sub['fail'] failure_code sub sub['py_ptr'] 'py_%s' % name sub['stor_ptr'] 'storage_%s' % name block CodeBlock * [apply_policy policy variable name sub for policy in policies[1]] + [sub] return struct_builder block
def get_cache_mtime if os.path.exists APT_UPDATE_SUCCESS_STAMP_PATH return os.stat APT_UPDATE_SUCCESS_STAMP_PATH .st_mtimeelif os.path.exists APT_LISTS_PATH return os.stat APT_LISTS_PATH .st_mtimeelse return 0
def can_view_courses_for_username requesting_user target_username if requesting_user.username target_username return Trueelif not target_username raise TypeError 'target_usernamemustbespecified' else staff GlobalStaff return staff.has_user requesting_user
def resolve_media_files document resource for field in resource_media_fields document resource if isinstance document[field] list resolved_list []for file_id in document[field] resolved_list.append resolve_one_media file_id resource document[field] resolved_listelse document[field] resolve_one_media document[field] resource
def delete_doc doctype None name None force 0 ignore_doctypes None for_reload False ignore_permissions False flags None import frappe.model.delete_docfrappe.model.delete_doc.delete_doc doctype name force ignore_doctypes for_reload ignore_permissions flags
@never_cache@login_required@psa @require_POST@csrf_protectdef disconnect request backend association_id None return do_disconnect request.backend request.user association_id redirect_name REDIRECT_FIELD_NAME
def objtag accessing_obj accessed_obj *args **kwargs return accessed_obj.tags.get *args
def get_cert_file try current_path os.path.realpath __file__ ca_cert_path os.path.join current_path '..' '..' '..' 'conf' 'cacert.pem' return os.path.abspath ca_cert_path except Exception return None
def bytes_iterator bytes_ raise Exception 'Shouldbeoverriden'
def _convert_write_result operation command result affected result.get 'n' 0 res {'ok' 1 'n' affected}errmsg result.get 'errmsg' result.get 'err' '' if errmsg if result.get 'wtimeout' res['writeConcernError'] {'errmsg' errmsg 'code' 64 'errInfo' {'wtimeout' True}}else error {'index' 0 'code' result.get 'code' 8 'errmsg' errmsg}if 'errInfo' in result error['errInfo'] result['errInfo']res['writeErrors'] [error]return resif operation 'insert' res['n'] len command['documents'] elif operation 'update' if 'upserted' in result res['upserted'] [{'index' 0 '_id' result['upserted']}]elif result.get 'updatedExisting' is False and affected 1 update command['updates'][0]_id update['u'].get '_id' update['q'].get '_id' res['upserted'] [{'index' 0 '_id' _id}]return res
def bytes2human n if not isinstance n integer_types raise TypeError n prefix {}for i s in enumerate _SYMBOLS prefix[s] 1 << i + 1 * 10 for s in reversed _SYMBOLS if n > prefix[s] value int float n / prefix[s] return '%s%s' % value s return '%sB' % n
def clear_trans_cache global _SKIN_CACHEdummy _SKIN_CACHE_SKIN_CACHE {}del dummysabnzbd.WEBUI_READY True
def import_date_time format _strptime None if not _strptime _strptime datetime.datetime.strptimedef import_date_time_lambda value if not value return Nonereturn _strptime value format return import_date_time_lambda
def _safe_split estimator X y indices train_indices None if hasattr estimator 'kernel' and callable estimator.kernel and not isinstance estimator.kernel GPKernel raise ValueError 'Cannotuseacustomkernelfunction.Precomputethekernelmatrixinstead.' if not hasattr X 'shape' if getattr estimator '_pairwise' False raise ValueError 'Precomputedkernelsoraffinitymatriceshavetobepassedasarraysorsparsematrices.' X_subset [X[idx] for idx in indices]elif getattr estimator '_pairwise' False if X.shape[0] ! X.shape[1] raise ValueError 'Xshouldbeasquarekernelmatrix' if train_indices is None X_subset X[np.ix_ indices indices ]else X_subset X[np.ix_ indices train_indices ]else X_subset safe_indexing X indices if y is not None y_subset safe_indexing y indices else y_subset Nonereturn X_subset y_subset
def parse_keywords strings [] keywords {}for string in strings if ' ' in string funcname indices string.split ' ' else funcname indices string None if funcname not in keywords if indices inds []for x in indices.split ' ' if x[ -1 ] 'c' inds.append int x[ -1 ] 'c' else inds.append int x indices tuple inds keywords[funcname] indicesreturn keywords
def remove_check module check_id consul_api get_consul_api module if check_id in consul_api.agent.checks consul_api.agent.check.deregister check_id module.exit_json changed True id check_id module.exit_json changed False id check_id
def check_color option opt value if re.match '[a-z0-9]+$' value re.I return valueif re.match '#[a-f0-9]{6}' value re.I return valuemsg 'option%s invalidcolor %r shouldbeeitherhexadecimalvalueorpredefinedcolor'raise OptionValueError msg % opt value
@jsonifydef delete_record self arg_dict cmd ['xenstore-rm' '/local/domain/% dom_id s/% path s' % arg_dict ] ret result _run_command cmd return result
@validate 'form' def valid_page_in_book arch return not arch.xpath '//page[not ancestor notebook ]'
def get_default_mrcluster global MR_CACHEglobal MR_NAME_CACHEtry all_mrclusters return MR_CACHE.get MR_NAME_CACHE except KeyError candidates all_mrclusters if candidates return candidates.values [0]return None
def user_update userid **connection_args conn_args _login **connection_args try if conn_args method 'user.update'params {'userid' userid}params _params_extend params _ignore_name True **connection_args ret _query method params conn_args['url'] conn_args['auth'] return ret['result']['userids']else raise KeyErrorexcept KeyError return ret
def deserialize_instance model data {} ret model for k v in data.items if v is not None try f model._meta.get_field k if isinstance f DateTimeField v dateparse.parse_datetime v elif isinstance f TimeField v dateparse.parse_time v elif isinstance f DateField v dateparse.parse_date v except FieldDoesNotExist passsetattr ret k v return ret
def getipbyhost hostname return socket.gethostbyname hostname
def must_not_be_rejected func @functools.wraps func def wrapped *args **kwargs node get_or_http_error Node kwargs.get 'nid' kwargs.get 'pid' allow_deleted True if node.sanction and node.sanction.is_rejected raise HTTPError http.GONE data dict message_long 'Thisregistrationhasbeenrejected' return func *args **kwargs return wrapped
def get_configuration options agent_config options[u'agent-config']configuration yaml.safe_load agent_config.getContent validate_configuration configuration configuration configuration['control-service'].setdefault 'port' 4524 path agent_config.parent configuration['ca-certificate'] Certificate.loadPEM path.child 'cluster.crt' .getContent configuration['node-credential'] NodeCredential.from_path path 'node' return configuration
def require_map_reduce conn try import spidermonkeyexcept BaseException try from ming import mimif hasattr conn 'conn' and isinstance conn.conn mim.Connection import testtoolsraise testtools.testcase.TestSkipped 'requiresspidermonkey' except ImportError import testtoolsraise testtools.testcase.TestSkipped 'requiresmim'
def make_gax_publisher_api credentials None host None if credentials is None channel insecure_channel host else channel make_secure_channel credentials DEFAULT_USER_AGENT PublisherClient.SERVICE_ADDRESS return PublisherClient channel channel
def _get_col_attributes col attrs ColumnDict attrs['name'] col.info.nametype_name col.info.dtype.type.__name__if not six.PY2 and type_name.startswith 'bytes' 'str' type_name 'string'if type_name.endswith '_' type_name type_name[ -1 ]attrs['datatype'] type_namefor attr nontrivial xform in 'unit' lambda x x is not None str 'format' lambda x x is not None None 'description' lambda x x is not None None 'meta' lambda x x None col_attr getattr col.info attr if nontrivial col_attr attrs[attr] xform col_attr if xform else col_attr return attrs
@sopel.module.event u'INVITE' @sopel.module.rule u'.*' @sopel.module.priority u'low' def invite_join bot trigger if trigger.admin or bot.config.admin.auto_accept_invite bot.join trigger.args[1] return
def s_block_start name group None encoder None dep None dep_value None dep_values [] dep_compare ' ' block blocks.block name blocks.CURRENT group encoder dep dep_value dep_values dep_compare blocks.CURRENT.push block return True
def spsModelSynth tfreq tmag tphase stocEnv N H fs ys SM.sineModelSynth tfreq tmag tphase N H fs yst STM.stochasticModelSynth stocEnv H H * 2 y ys[ min ys.size yst.size ] + yst[ min ys.size yst.size ] return y ys yst
def to_bytes text default 0 mult_key_org text.lstrip '-1234567890' mult_key mult_key_org.lower mult_key_len len mult_key if mult_key.endswith 'b' mult_key mult_key[0 -1 ]try multiplier BYTE_MULTIPLIERS[mult_key]if mult_key_len text text[0 - mult_key_len ]return int text * multiplier except KeyError msg _ 'Unknownbytemultiplier %s' % mult_key_org raise TypeError msg except ValueError return default
def ec2_credentials_get user_id None name None access None profile None **connection_args kstone auth profile **connection_args ret {}if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}if not access return {'Error' 'Accesskeyisrequired'}ec2_credentials kstone.ec2.get user_id user_id access access profile profile **connection_args ret[ec2_credentials.user_id] {'user_id' ec2_credentials.user_id 'tenant' ec2_credentials.tenant_id 'access' ec2_credentials.access 'secret' ec2_credentials.secret}return ret
def sigmoid_numpy x assert not isinstance x theano.gof.Variable return 1.0 / 1.0 + np.exp - x
@plugins.command 'uninstall' @click.argument 'plugin_identifier' def uninstall_plugin plugin_identifier validate_plugin plugin_identifier plugin get_plugin_from_all plugin_identifier click.secho '[+]Uninstallingplugin{}...'.format plugin.name fg 'cyan' try plugin_manager.uninstall_plugins [plugin] except AttributeError pass
def warn_limited msg args if args msg _hash_limit_string msg 10 args warnings.warn msg exc.SAWarning stacklevel 2
def find_selected nodes for node in nodes if hasattr node 'selected' return nodeelif hasattr node 'ancestor' result find_selected node.children if result return result
def contrib_setup_py name description additional_classifiers None **kwargs if not name.startswith u'pantsbuild.pants.contrib.' raise ValueError u"Contribpluginpackagenamesmuststartwith'pantsbuild.pants.contrib.' given{}".format name return pants_setup_py name description additional_classifiers additional_classifiers namespace_packages [u'pants' u'pants.contrib'] **kwargs
def fake_participant db is_admin False random_identities True username faker.first_name + fake_text_id 3 ctime faker.date_time_between '-3y' '-4w' try insert_fake_data db 'participants' username username username_lower username.lower ctime ctime is_admin is_admin balance 0 anonymous_giving random.randrange 5 0 balanced_customer_href faker.uri is_suspicious False claimed_time ctime + datetime.timedelta days 7 email_address '{}@example.com'.format username participant Participant.from_username username fake_exchange_route db participant if random_identities if random.randrange 100 < 66 fake_participant_identity participant if random.randrange 100 < 33 fake_participant_identity participant if random.randrange 100 < 50 fake_participant_identity participant except IntegrityError return fake_participant db is_admin return participant
def epsilon_closure state result state.epsilon_closureif result is None result {}state.epsilon_closure resultadd_to_epsilon_closure result state return result
def computeChunkHeightMap materials blocks HeightMap None lightAbsorption materials.lightAbsorption[blocks]heights extractHeights lightAbsorption heights heights.swapaxes 0 1 if HeightMap is None return heights.astype 'uint8' else HeightMap[ ] heightsreturn HeightMap
def set_transparent_torification new_transparent_torification global transparent_torificationstay_open new_transparent_torification
def _MPpow x y z return MP pow x y z
def simplify_jobs joblist pass
def full2sparse_clipped vec topn eps 1e-09 if topn < 0 return []vec np.asarray vec dtype float nnz np.nonzero abs vec > eps [0]biggest nnz.take argsort abs vec .take nnz topn reverse True return list zip biggest vec.take biggest
def _print_tree node level 0 if type node is list neon_logger.display '' * level + ' '.join native_str s for s in node[0 3] if len node > 3 _print_tree node[3] level + 1 if len node > 4 _print_tree node[4] level + 1 else neon_logger.display '' * level + native_str node
def test_tab_completion_caseinsensitive superConsole.SendKeys 'outputRedirectStart{ }True{ }{ENTER}' testRegex ''superConsole.SendKeys 'importSystem{ENTER}' superConsole.SendKeys 'printSystem.r{TAB}{ENTER}' testRegex + "<type'Random'>"superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def execute_java classpath main jvm_options None args None executor None workunit_factory None workunit_name None workunit_labels None cwd None workunit_log_config None distribution None create_synthetic_jar True synthetic_jar_dir None runner _get_runner classpath main jvm_options args executor cwd distribution create_synthetic_jar synthetic_jar_dir workunit_name workunit_name or main return execute_runner runner workunit_factory workunit_factory workunit_name workunit_name workunit_labels workunit_labels workunit_log_config workunit_log_config
def installHandler fd if fd -1 signal.signal signal.SIGCHLD signal.SIG_DFL else def noopSignalHandler *args passsignal.signal signal.SIGCHLD noopSignalHandler signal.siginterrupt signal.SIGCHLD False return signal.set_wakeup_fd fd
def parse_channel_modes mode_string return _parse_modes mode_string 'bklvohq'
def _add_candidate items results info log.debug u'Candidate {0}-{1}'.format info.artist info.album if not info.tracks log.debug 'Notracks.' returnif info.album_id in results log.debug u'Duplicate.' returnfor req_tag in config['match']['required'].as_str_seq if getattr info req_tag is None log.debug u'Ignored.Missingrequiredtag {0}'.format req_tag return mapping extra_items extra_tracks assign_items items info.tracks dist distance items info mapping penalties [key for _ key in dist]for penalty in config['match']['ignored'].as_str_seq if penalty in penalties log.debug u'Ignored.Penalty {0}'.format penalty returnlog.debug u'Success.Distance {0}'.format dist results[info.album_id] hooks.AlbumMatch dist info mapping extra_items extra_tracks
def petersen_graph create_using None description ['adjacencylist' 'PetersenGraph' 10 [[2 5 6] [1 3 7] [2 4 8] [3 5 9] [4 1 10] [1 8 9] [2 9 10] [3 6 10] [4 6 7] [5 7 8]]]G make_small_undirected_graph description create_using return G
def _cleanupEnvironment if issubclass urllib2.socket.socket socks.socksocket socks.unwrapmodule urllib2 if hasattr socket '_ready' socket._ready.clear
def draw_random G **kwargs draw G random_layout G **kwargs
def checkFloat s try float s return Trueexcept ValueError return False
def map_version version version_map if version is None raise TypeErrorif not version_map raise ValueErrorif isinstance version_map dict version_map sorted LooseVersion k v for k v in version_map.items req_version LooseVersion version for min_version value in reversed version_map if req_version > min_version return valueelse return version_map[0][1]
def col name None dtype None if dtype is None dtype config.floatXtype CudaNdarrayType dtype dtype broadcastable False True return type name
def _FormatEta eta_usec eta datetime.datetime.fromtimestamp eta_usec / 1000000 return eta.strftime '%Y/%m/%d%H %M %S'
def force_encoding text encoding return text.encode encoding errors 'replace' .decode encoding
def getTwistPrecision elementNode return getCascadeFloatWithoutSelf 5.0 elementNode 'twistPrecision'
def with_confirmation proc TIMEOUT _set_confirmation proc True proc.sendline u'ehcotest' proc.sendline u'fuck' assert proc.expect [TIMEOUT u'echotest'] assert proc.expect [TIMEOUT u'enter'] assert proc.expect_exact [TIMEOUT u'ctrl+c'] proc.send '\n' assert proc.expect [TIMEOUT u'test']
def createLinkPath elementNode elementNode.localName 'path'elementNode.linkObject Path
def make_wsgi_chain *args **kwargs app HTTPGitApplication *args **kwargs wrapped_app LimitedInputFilter GunzipFilter app return wrapped_app
def evaluate_inipath path if sabnzbd.WIN32 path unicoder path path os.path.normpath os.path.abspath path inipath os.path.join path DEF_INI_FILE if os.path.isdir path return inipathelif os.path.isfile path or os.path.isfile path + '.bak' return pathelse _dirpart name os.path.split path if name.find '.' < 1 return inipathelse return path
def register_plugin_calls *funcs wrapped_dict {}for func in funcs wrapped_dict[func.__name__] _handle_serialization func XenAPIPlugin.dispatch wrapped_dict
def xonsh_pathsearch pattern pymode False lineno None col None pymode ast.NameConstant value pymode lineno lineno col_offset col searchfunc pattern RE_SEARCHPATH.match pattern .groups pattern ast.Str s pattern lineno lineno col_offset col pathobj Falseif searchfunc.startswith '@' func searchfunc[1 ]elif 'g' in searchfunc func '__xonsh_globsearch__'pathobj 'p' in searchfunc else func '__xonsh_regexsearch__'pathobj 'p' in searchfunc func ast.Name id func ctx ast.Load lineno lineno col_offset col pathobj ast.NameConstant value pathobj lineno lineno col_offset col return xonsh_call '__xonsh_pathsearch__' args [func pattern pymode pathobj] lineno lineno col col
def MIN ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.MIN timeperiod
def systemInformationType2bis a L2PseudoLength l2pLength 21 b TpPd pd 6 c MessageType mesType 2 d NeighbourCellsDescription e RachControlParameters f Si2bisRestOctets packet a / b / c / d / e / f return packet
def encode string encoding None if type string is not ustr return stringreturn string.encode encoding or u'utf-8' u'replace'
def test_wiskott skip_if_no_data data Wiskott assert isfinite data.X
def getOutput gcodeText repository None if gcodeText '' return ''if repository is None repository GcodeTimeSegmentRepository settings.getReadRepository repository return GcodeTimeSegmentSkein .getCraftedGcode gcodeText repository
def changed *a **kw item a[0]if type item ! dict raise errors.AnsibleFilterError '|changedexpectsadictionary' if not 'changed' in item changed Falseif 'results' in item and type item['results'] list and type item['results'][0] dict for result in item['results'] changed changed or result.get 'changed' False else changed item.get 'changed' False return changed
def invert_graph graph inverted {}for key in graph for value in graph[key] inverted.setdefault value set .add key return inverted
def clear_session request *names for name in names try del request.session[name]except KeyError pass
def _detect_compressor fileobj fileobj.seek 0 first_bytes fileobj.read _MAX_PREFIX_LEN fileobj.seek 0 if first_bytes.startswith _ZLIB_PREFIX return 'zlib'elif first_bytes.startswith _GZIP_PREFIX return 'gzip'elif first_bytes.startswith _BZ2_PREFIX return 'bz2'elif first_bytes.startswith _LZMA_PREFIX return 'lzma'elif first_bytes.startswith _XZ_PREFIX return 'xz'elif first_bytes.startswith _ZFILE_PREFIX return 'compat'return 'not-compressed'
def getCraftSequence return 'carvescalebottomprefacewideninsetfillmultiplyspeedtemperatureraftskirtchambertowerjitterclipsmoothstretchskincombcoolhopwipeoozebanesplodgehomelashfilletlimitunpausedimensionaltshellalterationexport'.split
def nova_not_in logical_line split_line logical_line.split if len split_line 5 and split_line[0] 'if' and split_line[1] 'not' and split_line[3] 'in' and not split_line[2].startswith ' ' yield logical_line.find 'not' "N902 Usethe'notin'operatorforcollectionmembershipevaluation"
def task_locale def set_nikola_test_locales try out subprocess.check_output ['locale' '-a'] out out.decode 'utf-8' locales []languages set for line in out.splitlines if line.endswith '.utf8' or line.endswith '.UTF-8' and '_' in line lang line.split '_' [0]if lang not in languages try locale.setlocale locale.LC_ALL str line except continuelanguages.add lang locales.append lang line if len locales 2 breakif len locales ! 2 return Falseelse os.environ['NIKOLA_LOCALE_DEFAULT'] ' '.join locales[0] os.environ['NIKOLA_LOCALE_OTHER'] ' '.join locales[1] finally locale.resetlocale return {'actions' [set_nikola_test_locales] 'verbosity' 2}
def numpy_to_sympy m **options return Matrix m
def make_digest_acl_credential username password credential username.encode 'utf-8' + ' ' + password.encode 'utf-8' cred_hash b64encode hashlib.sha1 credential .digest .strip return username + ' ' + cred_hash.decode 'utf-8'
def getInstanceDetails api server instance {'id' server['LINODEID'] 'name' server['LABEL'] 'public' [] 'private' []}for ip in api.linode_ip_list LinodeId server['LINODEID'] if ip['ISPUBLIC'] and 'ipv4' not in instance instance['ipv4'] ip['IPADDRESS']instance['fqdn'] ip['RDNS_NAME']if ip['ISPUBLIC'] instance['public'].append {'ipv4' ip['IPADDRESS'] 'fqdn' ip['RDNS_NAME'] 'ip_id' ip['IPADDRESSID']} else instance['private'].append {'ipv4' ip['IPADDRESS'] 'fqdn' ip['RDNS_NAME'] 'ip_id' ip['IPADDRESSID']} return instance
def _check_upload_response_headers headers body if 'status' not in headers try d jsonutils.loads body if 'image' in d and 'status' in d['image'] returnexcept Exception raise exception.UploadException body
def get_config ini_path os.path.join THIS_DIRECTORY 'version.ini' if not os.path.exists ini_path ini_path os.path.join THIS_DIRECTORY '../../../version.ini' if not os.path.exists ini_path raise RuntimeError "Couldn'tfindversion.ini" config ConfigParser.SafeConfigParser config.read ini_path return config
def get_foreign namespace name try return get_foreign_struct namespace name except ForeignError return None
def load_router full_router_path path_bits full_router_path.split u'.' if len path_bits < 2 raise ImproperlyConfigured u"Theprovidedrouter'%s'isnotacompletePythonpathtoaBaseRoutersubclass." % full_router_path return import_class full_router_path
def on_report_to_master client_id data data['content-length'] stats['content-length']stats['content-length'] 0
def form_ntuples_from_machines machines n 2 mapping_func default_mappings ntuples [] mappings failures mapping_func machines for key in mappings key_machines mappings[key]total_machines len key_machines while len key_machines > n ntuples.append key_machines[0 n] key_machines key_machines[n ]for mach in key_machines failures.append mach 'machinecannotbetupled' return ntuples failures
def black_out x t W samples batch_size x.shape[0]neg_emb embed_id.embed_id samples W neg_y matmul.batch_matmul neg_emb x neg_y reshape.reshape neg_y neg_y.shape[ -1 ] pos_emb expand_dims.expand_dims embed_id.embed_id t W 1 pos_y matmul.batch_matmul pos_emb x pos_y reshape.reshape pos_y pos_y.shape[ -1 ] logz logsumexp.logsumexp concat.concat [pos_y neg_y] axis 1 blogz bneg_y broadcast.broadcast reshape.reshape logz batch_size 1 neg_y ny exponential.log 1 - exponential.exp bneg_y - blogz py reshape.reshape pos_y batch_size loss py - logz + _sum.sum ny axis 1 return - _sum.sum loss / batch_size
def versions_information return salt.version.versions_information
def create_regex_extractor pattern ereg re.compile pattern re.S def _extractor txt htmlpage None if txt is None returnm ereg.search txt if m return htmlregion u''.join [g for g in m.groups or m.group if g] _extractor.__name__ 'Regex %s' % pattern.encode 'utf-8' return _extractor
def _ZeroPad addr_string chunks addr_string.split ' ' total_length len chunks if total_length > 8 raise socket.error 'Toomanyaddresschunksin%s expected8' % addr_string double_colon Falseaddr_array []for chunk in chunks if chunk chunk_len len chunk if chunk_len > 4 raise socket.error 'Chunkmustbelength4 %s' % addr_string if chunk_len ! 4 chunk '0' * 4 - chunk_len + chunk addr_array.append chunk elif double_colon raise socket.error 'Morethanonedoublecolonin%s' % addr_string else double_colon Trueaddr_array.extend ['0000'] * 8 - total_length + 1 if len addr_array ! 8 raise socket.error 'Badaddresslength expected8chunks %s' % addr_array return ''.join addr_array
def _new_extension name value critical 0 issuer None _pyfree 1 if name 'subjectKeyIdentifier' and value.strip '0123456789abcdefABCDEF ' is not '' raise salt.exceptions.SaltInvocationError 'valuemustbeprecomputedhash' try ctx M2Crypto.m2.x509v3_set_nconf _fix_ctx ctx issuer if ctx is None raise MemoryError 'NotenoughmemorywhencreatinganewX509extension' x509_ext_ptr M2Crypto.m2.x509v3_ext_conf None ctx name value lhash Noneexcept AttributeError lhash M2Crypto.m2.x509v3_lhash ctx M2Crypto.m2.x509v3_set_conf_lhash lhash _fix_ctx ctx issuer x509_ext_ptr M2Crypto.m2.x509v3_ext_conf lhash ctx name value if x509_ext_ptr is None raise M2Crypto.X509.X509Error "CannotcreateX509_Extensionwithname'{0}'andvalue'{1}'".format name value x509_ext M2Crypto.X509.X509_Extension x509_ext_ptr _pyfree x509_ext.set_critical critical return x509_ext
def format_blocks blocks assert isinstance blocks tuple and all isinstance x int for x in blocks return _PrettyBlocks blocks
def replace_dots_in_field_names document for key value in list document.items if isinstance value dict value replace_dots_in_field_names value if isinstance key string_types and key.find '.' ! -1 del document[key]document[key.replace '.' '_' ] valuereturn document
def _is_sparse x if not isinstance x scipy.sparse.spmatrix np.ndarray tuple list raise NotImplementedError 'thisfunctionshouldonlybecalledonsparse.scipy.sparse.spmatrixornumpy.ndarray not ' x return isinstance x scipy.sparse.spmatrix
def loop_until_state_found reactor get_states state_matches timeout def state_reached d get_states def find_match states for state in states if state_matches state return statereturn Noned.addCallback find_match return dd loop_until reactor state_reached _timeout reactor d timeout.total_seconds return d
def fiducials subject None fid_file None subjects_dir None _check_mayavi_version from ._backend import _check_backend_check_backend from ._fiducials_gui import FiducialsFramegui FiducialsFrame subject subjects_dir fid_file fid_file gui.configure_traits return gui
def meta_nonempty x if isinstance x pd.Index return _nonempty_index x elif isinstance x pd.Series idx _nonempty_index x.index return _nonempty_series x idx elif isinstance x pd.DataFrame idx _nonempty_index x.index data {i _nonempty_series x.iloc[ i] idx for i c in enumerate x.columns }res pd.DataFrame data index idx columns np.arange len x.columns res.columns x.columnsreturn reselif is_scalar x return _nonempty_scalar x else raise TypeError 'ExpectedIndex Series DataFrame orscalar got{0}'.format type x .__name__
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def test_require_file_from_local_file from fabtools.require import file as require_filetry baz_contents 'Thisisthecontentsofthebarfile' fd filename mkstemp tmp_file os.fdopen fd 'w' tmp_file.write baz_contents tmp_file.close require_file 'baz' source filename assert is_file 'baz' assert run 'catbaz' baz_contents finally os.remove filename run 'rm-fbaz'
@deprecated 'UseTimedeltaWin64fieldtype' def durationWin64 field assert hasattr field 'value' and hasattr field 'size' assert field.size 64 delta doDurationWin64 field.value return humanDuration delta
def parse_uid uid if UIDFieldMixin.UID_SEPARATOR not in uid raise ValueError 'Invaliduid %s' % uid parsed uid.split UIDFieldMixin.UID_SEPARATOR if len parsed < 2 raise ValueError 'Invalidormalformeduid %s' % uid resource_type parsed[0]uid_remainder parsed[1 ]return resource_type uid_remainder
def _dont_fail_not_exist error if isinstance error AzureMissingResourceHttpError return Falseelse raise error
def base64image src return base64.b64encode _get_file src
def get_unsupported_lower_protocol if Version CASSANDRA_VERSION > Version '3.0' return 2else return None
def _build_m3u_filename basename basename re.sub '[\\s /\\\\\'\\"]' '_' basename date datetime.datetime.now .strftime '%Y%m%d_%Hh%M' path normpath os.path.join config['importfeeds']['dir'].as_filename date + '_' + basename + '.m3u' return path
def runTests vm tests None pre '' post '' prompt Prompt uninstallNtpd False if uninstallNtpd removeNtpd vm vm.expect prompt if Branch checkOutBranch vm branch Branch vm.expect prompt if not tests tests []if pre log '*Runningcommand' pre vm.sendline pre vm.expect prompt testfns testDict if tests log '*Runningtests' for test in tests if test not in testfns raise Exception 'Unknowntest ' + test log '*Runningtest' test fn testfns[test]fn vm vm.expect prompt if post log '*Runningpost-testcommand' post vm.sendline post vm.expect prompt
def test_oss_sample_wrong_X oss OneSidedSelection random_state RND_SEED oss.fit X Y assert_raises RuntimeError oss.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def NDP_Attack_Fake_Router ra iface None mac_src_filter None ip_src_filter None def is_request req mac_src_filter ip_src_filter '\nCheckifpacketreqisarequest\n'if not Ether in req and IPv6 in req and ICMPv6ND_RS in req return 0mac_src req[Ether].srcif mac_src_filter and mac_src ! mac_src_filter return 0ip_src req[IPv6].srcif ip_src_filter and ip_src ! ip_src_filter return 0return 1def ra_reply_callback req iface '\nCallbackthatsendsanRAinreplytoanRS\n'src req[IPv6].srcsendp ra iface iface verbose 0 print 'FakeRAsentinresponsetoRSfrom%s' % src if not iface iface conf.ifacesniff_filter 'icmp6'sniff store 0 filter sniff_filter lfilter lambda x is_request x mac_src_filter ip_src_filter prn lambda x ra_reply_callback x iface iface iface
def invert_tree root if root None return Nonetemp root.rightroot.right root.leftroot.left tempinvert_tree root.left invert_tree root.right return root
def decode_uuid obj return uuid.UUID bytes str obj
def tvar a limits None inclusive True True axis 0 ddof 1 a asarray a a a.astype float .ravel if limits is None n len a return a.var * n / n - 1.0 am _mask_to_limits a limits inclusive return np.ma.var am ddof ddof axis axis
def save_comment request unit unit.commented_by request.userunit.commented_on timezone.now .replace microsecond 0 language request.translation_project.languageform unit_comment_form_factory language request.POST instance unit request request if form.is_valid form.save user request.userdirectory unit.store.parentctx {'unit' unit 'language' language 'cantranslate' check_user_permission user 'translate' directory 'cansuggest' check_user_permission user 'suggest' directory }t loader.get_template 'editor/units/xhr_comment.html' return JsonResponse {'comment' t.render context ctx request request } return JsonResponseBadRequest {'msg' _ 'Commentsubmissionfailed.' }
def number_of_friends user return len user['friends']
def B64HexDecode s padding True s utf8 s if not _valid_char_re.match s raise TypeError 'Invalidcharacters' pad_needed len s % _PAD_LEN if pad_needed if padding raise TypeError 'Invalidpadding' else s + ' ' * pad_needed translated s.translate _b64hex_to_std return base64.b64decode translated
def check_map mapping_file barcode_type 'golay_12' added_demultiplex_field None if barcode_type 0 has_barcodes Falsevar_len_barcodes Falseelif barcode_type 'variable_length' has_barcodes Truevar_len_barcodes Trueelse has_barcodes Truevar_len_barcodes False header mapping_data run_description errors warnings process_id_map mapping_file has_barcodes has_barcodes disable_primer_check True added_demultiplex_field added_demultiplex_field variable_len_barcodes var_len_barcodes for warning in warnings if 'differsthanlength' in warning raise ValueError 'Detectedvariablelengthbarcodes ifthese' + 'arebeingused use-bvariable_length' if errors raise ValueError 'Errorsfoundinmappingfile pleasecheck' + 'mappingfilewithvalidate_mapping_file.py' return header mapping_data
def macro name def inner view context model column m context.resolve name if not m return mreturn m model model column column return inner
def HeaderPrintGenericDetails message which MUA_HP_HEADERS return [k for k v in message.items if k.lower in which ]
def infer_name self context None frame stmts self.lookup self.name if not stmts parent_function _higher_function_scope self.scope if parent_function _ stmts parent_function.lookup self.name if not stmts raise UnresolvableName self.name context context.clone context.lookupname self.namereturn _infer_stmts stmts context frame
def get_init_version abs_path None if abs_path is None abs_path find_repo LEGACY_REPO repo migrate.versioning.repository.Repository abs_path oldest int min repo.versions.versions if oldest < 1 return Nonereturn oldest - 1
def obj_equal_prims obj_1 obj_2 ignore None def _strip prim keys if isinstance prim dict for k in keys prim.pop k None for v in prim.values _strip v keys if isinstance prim list for v in prim _strip v keys return primif ignore is not None keys ['nova_object.changes'] + ignore else keys ['nova_object.changes']prim_1 _strip obj_1.obj_to_primitive keys prim_2 _strip obj_2.obj_to_primitive keys return prim_1 prim_2
def GeneratePythonPaths *p suffixes imp.get_suffixes return [ os.path.join *p + s for s m t in suffixes]
def reconcile_against_document args for d in args check_if_advance_entry_modified d validate_allocated_amount d doc frappe.get_doc d.voucher_type d.voucher_no doc.make_gl_entries cancel 1 adv_adj 1 if d.voucher_type u'JournalEntry' update_reference_in_journal_entry d doc else update_reference_in_payment_entry d doc doc frappe.get_doc d.voucher_type d.voucher_no doc.make_gl_entries cancel 0 adv_adj 1
@lower_getattr_generic types.EnumClass def enum_class_lookup context builder ty val attr member getattr ty.instance_class attr return context.get_constant_generic builder ty.dtype member.value
def attachment_specs_get context attachment_id return IMPL.attachment_specs_get context attachment_id
def getGNUTranslatorFilesUnmodified return archive.getFilesWithFileTypesWithoutWords getImportPluginFileNames
def get_auth_params_from_request request return request.user.username request.user.token.id request.user.tenant_id base.url_for request 'compute' base.url_for request 'identity'
def compare a b if HAVE_COMPARE_DIGEST return hmac.compare_digest a b result len a ^ len b for i in xrange len b result | ord a[ i % len a ] ^ ord b[i] return result 0
def recvfd socketfd data flags ancillary recv1msg socketfd [ cmsg_level cmsg_type packedFD ] ancillary[unpackedFD] unpack 'i' packedFD return unpackedFD data
def ip4_hex arg numbers list map int arg.split '.' return '{ 02x}{ 02x}{ 02x}{ 02x}'.format *numbers
def delimit delimiters content if len delimiters ! 2 raise ValueError u'`delimiters`mustbeoflength2.Got%r' % delimiters return u''.join [delimiters[0] content delimiters[1]]
def parse_entry entry_str separator ' ' entry {}for line in entry_str.splitlines if len line 0 continuetry name value line.split separator 1 except ValueError continuename name.strip value value.strip if name 'index' value int value entry[name] valuereturn entry
def sca ax managers _pylab_helpers.Gcf.get_all_fig_managers for m in managers if ax in m.canvas.figure.axes _pylab_helpers.Gcf.set_active m m.canvas.figure.sca ax returnraise ValueError u'Axesinstanceargumentwasnotfoundinafigure.'
def regions language x a language.lower [] for tag language region iso639 iso3166 in LANGUAGE_REGION.items if iso639 x a.append iso3166 return sorted a key lambda tag tag.lower ! x and tag or ''
def delete_exploration_summary exploration_id exp_models.ExpSummaryModel.get exploration_id .delete
@pytest.mark.parametrize u'mode' modes def test_gaussian_eval_2D mode model Gaussian2D 1 0 0 20 20 x np.arange -100 101 y np.arange -100 101 x y np.meshgrid x y values model x y disc_values discretize_model model -100 101 -100 101 mode mode assert_allclose values disc_values atol 0.001
@context.quietfunc@with_devicedef logcat stream False if stream return process ['logcat'] else return process ['logcat' '-d'] .recvall
def ridder f a b args xtol _xtol rtol _rtol maxiter _iter full_output False disp True if not isinstance args tuple args args if xtol < 0 raise ValueError 'xtoltoosmall %g< 0 ' % xtol if rtol < _rtol raise ValueError 'rtoltoosmall %g<%g ' % rtol _rtol r _zeros._ridder f a b xtol rtol maxiter args full_output disp return results_c full_output r
def admin_or_self method def decorated_method self name current self.get_current_user if current is None raise web.HTTPError 403 if not current.admin if not isinstance current orm.Service raise web.HTTPError 403 if current.name ! name raise web.HTTPError 403 if name not in self.services raise web.HTTPError 404 return method self name return decorated_method
def metadef_object_count context namespace_name session None session session or get_session return metadef_object_api.count context namespace_name session
def dup_rr_div f g K df dup_degree f dg dup_degree g q r dr [] f df if not g raise ZeroDivisionError 'polynomialdivision' elif df < dg return q r lc_g dup_LC g K while True lc_r dup_LC r K if lc_r % lc_g breakc K.exquo lc_r lc_g j dr - dg q dup_add_term q c j K h dup_mul_term g c j K r dup_sub r h K _dr dr dr dup_degree r if dr < dg breakelif not dr < _dr raise PolynomialDivisionFailed f g K return q r
def test_secondary Chart chart Chart rng [83 0.12 -34 59]chart.add 'Firstserie' rng chart.add 'Secondaryserie' map lambda x x * 2 rng secondary True assert chart.render_pyquery
def tests path None if path is None path os.path.join os.path.dirname __file__ 'testplan.org' return TestReaderStateMachine .extract_tests path
def follow_all_url parser token bits token.split_contents if len bits ! 2 raise TemplateSyntaxError 'Acceptedformat{%follow_all_url[instance]%}' else return DisplayActivityFollowUrl bits[1] actor_only False
def p_command_data_bad p p[0] 'MALFORMEDNUMBERLISTINDATA'
def verify cypher key return gluechops cypher key['e'] key['n'] encrypt_int
def _int_to_json value if isinstance value int value str value return value
def _upgrade fields sig sig.update chord_size fields.get u'chord_size' return sig
def blackwhite clip RGB [1 1 1] preserve_luminosity True if RGB 'CRT_phosphor' RGB [0.2125 0.7154 0.0721] R G B 1.0 * np.array RGB / sum RGB if preserve_luminosity else 1 def fl im im R * im[ 0] + G * im[ 1] + B * im[ 2] return np.dstack 3 * [im] .astype 'uint8' return clip.fl_image fl
def test_comments feature Feature.from_string FEATURE10 assert_equals feature.max_length 55
def dt_to_timestamp dt if dt.tzinfo td dt - EPOCH_AWARE else td dt - EPOCH_NAIVE return total_seconds td
def rewrite_single_shorthand_state_decl data for sid states in six.iteritems data if isinstance states six.string_types data[sid] {states []}
def update_axes_image image_axes image image_axes.set_array image h w image.shape[ 2]image_axes.set_extent 0 w h 0
def toURINormal xri return iriToURI toIRINormal xri
def test_int_x_labels line Line line.add 'test1' range 100 line.truncate_label -1 line.x_labels list range 11 q line.render_pyquery assert len q '.dots' 100 assert len q '.axis.x' 1 assert q '.axis.xtext' .map texts ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10']
def _calculate_qa_comment_scores link cid_tree comments responder_ids link.responder_idsparent_cids []for comment in comments if comment.author_id in responder_ids and comment.parent_id parent_cids.append comment.parent_id parent_comments Comment._byID parent_cids return_dict False comments.extend parent_comments all_child_cids []for comment in comments child_cids cid_tree.get comment._id None if child_cids all_child_cids.extend child_cids all_child_comments Comment._byID all_child_cids comment_sorter {}for comment in comments child_cids cid_tree.get comment._id child_comments all_child_comments[cid] for cid in child_cids sort_value comment._qa child_comments responder_ids comment_sorter[comment._id36] sort_valuereturn comment_sorter
def get_env_for_subprocess_command env os.environ.copy if 'PYTHONPATH' in env del env['PYTHONPATH']return env
def consumer_oauth_url_request backend url user_or_id redirect_uri '/' json True user UserSocialAuth.resolve_user_or_id user_or_id oauth_info user.social_auth.filter provider backend.AUTH_BACKEND.name [0]token Token.from_string oauth_info.tokens['access_token'] request build_consumer_oauth_request backend token url redirect_uri response '\n'.join dsa_urlopen request.to_url .readlines if json response simplejson.loads response return response
def type_token_ratio string n 100 punctuation PUNCTUATION def window a n 100 if n > 0 for i in xrange max len a - n + 1 1 yield a[i i + n ] s string.lower .split s [w.strip punctuation for w in s]return mean 1.0 * len set x / max len x 1 for x in window s n
def create_security_group_rule security_group remote_group_id None direction 'ingress' protocol None port_range_min None port_range_max None ethertype 'IPv4' profile None conn _auth profile return conn.create_security_group_rule security_group remote_group_id direction protocol port_range_min port_range_max ethertype
def tokenize readline from itertools import chain repeat encoding consumed detect_encoding readline rl_gen iter readline '' empty repeat '' return _tokenize chain consumed rl_gen empty .__next__ encoding
def readInFilter fname filter ''tmpfd open fname 'r' for line in tmpfd if '#' in line line line.split '#' [0] + '\n' filter + linetmpfd.close return filter
def bind_ack data if data[2] ! '\x0c' return Falseif data[36 38] ! '\x00\x00' return Falsereturn True
def _check_origin origin info coord_frame 'head' disp False if isinstance origin string_types if origin ! 'auto' raise ValueError 'originmustbeanumericalarray or"auto" not%s' % origin if coord_frame 'head' R origin fit_sphere_to_headshape info verbose False units 'm' [ 2]logger.info 'Automaticoriginfit headofradius%0.1fmm' % R * 1000.0 del Relse origin 0.0 0.0 0.0 origin np.array origin float if origin.shape ! 3 raise ValueError 'originmustbea3-elementarray' if disp origin_str ' '.join [ '%0.1f' % o * 1000 for o in origin] logger.info 'Usingorigin%smminthe%sframe' % origin_str coord_frame return origin
def _ip src dst payload ipHeader 'E\x00' + _H 20 + len payload + '\x00\x01\x00\x00@\x11' + _H 0 + socket.inet_pton socket.AF_INET nativeString src + socket.inet_pton socket.AF_INET nativeString dst checksumStep1 sum struct.unpack '!10H' ipHeader carry checksumStep1 >> 16 checksumStep2 checksumStep1 & 65535 + carry checksumStep3 checksumStep2 ^ 65535 ipHeader ipHeader[ 10] + struct.pack '!H' checksumStep3 + ipHeader[12 ] return ipHeader + payload
def get_domain_workgroup pythoncom.CoInitialize conn wmi.WMI for computer in conn.Win32_ComputerSystem if computer.PartOfDomain return {'Domain' computer.Domain}else return {'Workgroup' computer.Domain}
def _oneD_norm_2 a raise NotImplementedError
@_refresh_mine_cache@_api_version 1.12 @_ensure_existsdef pause name orig_state state name if orig_state 'stopped' return {'result' False 'state' {'old' orig_state 'new' orig_state} 'comment' "Container'{0}'isstopped cannotpause".format name }return _change_state name 'pause' 'paused'
def samplemat dims aa np.zeros dims for i in range min dims aa[ i i ] ireturn aa
def completeness_score labels_true labels_pred return homogeneity_completeness_v_measure labels_true labels_pred [1]
def QuotedFileName fname import regutil stringtry fname.index '' return '"%s"' % fname except ValueError return fname
def start_file filename from qtpy.QtCore import QUrlfrom qtpy.QtGui import QDesktopServicesurl QUrl url.setUrl filename return QDesktopServices.openUrl url
def permission_required perm login_url None redirect REDIRECT_FIELD_NAME only_active True redirect_func lambda u not u.is_authenticated if only_active deny_func lambda u not u.is_active and u.has_perm perm else deny_func lambda u not u.has_perm perm redirect_url_func lambda login_url return user_access_decorator redirect_func redirect_field redirect redirect_url_func redirect_url_func deny_func deny_func
def features out __salt__['cmd.run_all'] 'mkfs.btrfs-Olist-all' salt.utils.fsutils._verify_run out ret {}for line in [re.sub '\\s+' '' line for line in out['stderr'].split '\n' if '-' in line ] option description line.split '-' 1 ret[option] descriptionreturn ret
def test_softmax_weight_init nvis 5num_classes 10MLP layers [Softmax num_classes 's' irange 0.1 ] nvis nvis MLP layers [Softmax num_classes 's' istdev 0.1 ] nvis nvis MLP layers [Softmax num_classes 's' sparse_init 2 ] nvis nvis
def get_image_dir_path instance return os.path.join CONF.instances_path instance['name']
@testdef rgb h if h[ 2] '\x01\xda' return u'rgb'
def json_generator items root expand False yield '{"%s" [' % root first Truefor item in items if first first Falseelse yield ' ' yield json.dumps _rep item expand expand yield ']}'
def _fast_cross_nd_sum a b c return a[... 1] * b[... 2] - a[... 2] * b[... 1] * c[... 0] + a[... 2] * b[... 0] - a[... 0] * b[... 2] * c[... 1] + a[... 0] * b[... 1] - a[... 1] * b[... 0] * c[... 2]
def _extend_port_trunk_details core_plugin port_res port_db if port_db.trunk_port subports {x.port_id {'segmentation_id' x.segmentation_id 'segmentation_type' x.segmentation_type 'port_id' x.port_id} for x in port_db.trunk_port.sub_ports}ports core_plugin.get_ports context.get_admin_context filters {'id' subports} for port in ports subports[port['id']]['mac_address'] port['mac_address']trunk_details {'trunk_id' port_db.trunk_port.id 'sub_ports' [x for x in subports.values ]}port_res['trunk_details'] trunk_detailsreturn port_res
def classifierWrapper classifier classifierType testSample R -1 P -1 if classifierType 'knn' [R P] classifier.classify testSample elif classifierType 'svm' or classifierType 'randomforest' or classifierType 'gradientboosting' or 'extratrees' R classifier.predict testSample.reshape 1 -1 [0]P classifier.predict_proba testSample.reshape 1 -1 [0]return [R P]
def is_valid target if nick_re.match target return Trueelse return False
def distances_along_curve X X np.diff X axis 0 return vector_lengths X axis 1
def encode_wanted remote local want {}if 'ts_data' in local if remote['ts_data'] > local['ts_data'] want['data'] Trueif 'ts_meta' in local and remote['ts_meta'] > local['ts_meta'] want['meta'] Trueif 'ts_ctype' in local and remote['ts_ctype'] > local['ts_ctype'] and remote['ts_ctype'] > remote['ts_data'] want['meta'] Trueelse want['data'] Truewant['meta'] Trueif want key_map dict data 'd' meta 'm' parts ''.join v for k v in sorted key_map.items if want.get k return '%s%s' % urllib.parse.quote remote['object_hash'] parts return None
def get_all_tensor_children tensor children_list []children_list.append tensor if tensor.op for t in tensor.op.outputs children_list + get_all_tensor_children t return list set children_list
def change_TV_DOWNLOAD_DIR tv_download_dir if tv_download_dir '' sickbeard.TV_DOWNLOAD_DIR ''return Trueif ek os.path.normpath sickbeard.TV_DOWNLOAD_DIR ! ek os.path.normpath tv_download_dir if helpers.makeDir tv_download_dir sickbeard.TV_DOWNLOAD_DIR ek os.path.normpath tv_download_dir logger.log u'ChangedTVdownloadfolderto' + tv_download_dir else return Falsereturn True
def is_block_gradient op return isinstance op _ElemwiseNoGradient
def requires_pillow_jpeg func @wraps func def decorated_func *args **kwargs '\nExecutethefunctionifwehaveJPEGsupportinPillow.\n'try from PIL import Imageexcept ImportError raise SkipTest 'Pillowisnotinstalled ornotfound ' if not getattr Image.core 'jpeg_decoder' False raise SkipTest 'PillowcannotopenJPEGfiles' return func *args **kwargs return decorated_func
def for_unsigned_dtypes_combination names 'dtype' full None return for_dtypes_combination _unsigned_dtypes names names full full
@events.on_finish channel '^room-' def finish request socket context try user context['user']except KeyError returnleft {'action' 'leave' 'name' user.name 'id' user.id}socket.broadcast_channel left user.delete
def assert_valid_call prompt default cli_flag force_interactive msg 'InvalidIDisplaycallforthisprompt \n{0}'.format prompt if cli_flag msg + '\nYoucansetananswertothispromptwiththe{0}flag'.format cli_flag assert default is not None or force_interactive msg
def match_fs disk dev_path fs_type fs_makeopt if disk['fs_type'] ! fs_type return Falseelif disk['fs_mkfs'] fs_makeopt return Trueelif fsinfo.match_mkfs_option fs_type dev_path fs_makeopt if disk['fs_mkfs'] ! '?' raise Exception "mkfsoptionstringsdifferbutauto-detectioncodethinksthey'reidentical" else return Trueelse return False
def lazy_cache key None time_expire None cache_model 'ram' def decorator f key key time_expire time_expire cache_model cache_model key key or repr f def g *c **d from gluon import currentreturn current.cache key time_expire cache_model f *c **d g.__name__ f.__name__return greturn decorator
def p_service p thrift thrift_stack[ -1 ]if len p 8 extends thriftfor name in p[4].split '.' extends getattr extends name None if extends is None raise ThriftParserError "Can'tfindservice%rforservice%rtoextend" % p[4] p[2] if not hasattr extends 'thrift_services' raise ThriftParserError "Can'textends%r notaservice" % p[4] else extends Noneval _make_service p[2] p[ len p - 2 ] extends setattr thrift p[2] val _add_thrift_meta 'services' val
def write_xspf f tuples xml XmlWriter f indentAmount '' xml.prolog xml.start 'playlist' {'xmlns' 'http //xspf.org/ns/0/' 'version' '1'} xml.start 'trackList' for tupe in tuples xml.start 'track' xml.elem 'creator' tupe[0] xml.elem 'title' tupe[1] xml.elem 'location' tupe[2] xml.end xml.end xml.end f.close
def _get_user_and_profile username try existing_user User.objects.get username username existing_user_profile UserProfile.objects.get user existing_user except ObjectDoesNotExist raise UserNotFound return existing_user existing_user_profile
@register.filter is_safe False def length_is value arg try return len value int arg except ValueError TypeError return u''
def as_unicode text encoding u'utf-8' if isinstance text unicode return textelif text None return u''elif isinstance text basestring return unicode text encoding else return unicode text
def get_barcode curr_seq barcode_len raw_barcode curr_seq[0 barcode_len]raw_seq curr_seq[barcode_len ]return raw_barcode raw_seq
def geos_version_info ver geos_version .decode m version_regex.match ver if not m raise GEOSException 'Couldnotparseversioninfostring"%s"' % ver return {key m.group key for key in 'version' 'release_candidate' 'capi_version' 'major' 'minor' 'subminor' }
def expandpath path path os.path.expandvars path if path.startswith u'~' path os.path.expanduser path return path
def filter_token access_token_ref if access_token_ref access_token_ref access_token_ref.copy access_token_ref.pop 'access_secret' None return access_token_ref
def test_non_iterable_value Chart chart Chart no_prefix True chart.add 'A' 1 chart.add 'B' 2 if not chart._dual chart.x_labels 'red' 'green' 'blue' chart1 chart.render chart Chart no_prefix True chart.add 'A' [1] chart.add 'B' [2] if not chart._dual chart.x_labels 'red' 'green' 'blue' chart2 chart.render assert chart1 chart2
def kit_import_csv file request.vars.filename.filetry budget_import_csv file session.flash T 'Datauploaded' except session.error T 'UnabletoparseCSVfile!' redirect URL f 'kit'
def generate_key key_length 64 if hasattr random 'SystemRandom' choice random.SystemRandom .choiceelse choice random.choicereturn ''.join map lambda x choice string.digits + string.letters range key_length
@synchronized DIR_LOCK def cleanup_empty_directories path path os.path.normpath path while 1 repeat Falsefor root dirs files in os.walk path topdown False if not dirs and not files and root ! path try remove_dir root repeat Trueexcept passif not repeat breaktry remove_dir path except pass
def group seq multiple True if not seq return [] current groups [seq[0]] [] for elem in seq[1 ] if elem current[ -1 ] current.append elem else groups.append current current [elem]groups.append current if multiple return groupsfor i current in enumerate groups groups[i] current[0] len current return groups
def make_resource return {'url' 'http //www.example.com' 'description' 'exampleresourcedescription' 'format' 'txt' 'name' 'exampleresource'}
def _use_str_for_masked_values format_func return lambda format_ val str val if val is np.ma.masked else format_func format_ val
def SMTP port 25 **kwargs return rule port **kwargs
def _module_name *components return '.'.join components
def from_ctypes ctypeobj if ctypeobj is None return types.noneassert isinstance ctypeobj type ctypeobjdef _convert_internal ctypeobj if issubclass ctypeobj ctypes._Pointer valuety _convert_internal ctypeobj._type_ if valuety is not None return types.CPointer valuety else return _FROM_CTYPES.get ctypeobj ty _convert_internal ctypeobj if ty is None raise TypeError 'Unsupportedctypestype %s' % ctypeobj return ty
def test_lazy_log called_print []class Expensive object def __repr__ self called_print.append 1 return 'expensivedatapreparation'slogging.configure log_json True log slogging.get_logger log.trace 'no' data Expensive assert not called_print log.info 'yes' data Expensive assert called_print.pop
def TickJob session session.ui.notify 'Tick!'
def get_docs_version version None positions 2 version get_complete_version version candidate_pos _get_candidate_pos version if positions > candidate_pos positions candidate_posif _is_development_candidate version return 'dev'return _get_version_string version[ positions]
def get_transparent_torification return transparent_torification
def find_creation_sequence G cs []H Gwhile H.order > 0 dsdict dict H.degree ds [ d v for v d in dsdict.items ]ds.sort if ds[ -1 ][0] 0 cs.extend zip dsdict ['i'] * len ds - 1 + ['d'] breakwhile ds[0][0] 0 d iso ds.pop 0 cs.append iso 'i' d bigv ds.pop cs.append bigv 'd' H H.subgraph H.neighbors bigv cs.reverse return cs
def index_if predicate seq idx 0for x in seq if predicate x return idxidx + 1return idx
def number_aware_tokenizer doc token_pattern re.compile u' ?u \\b\\w\\w+\\b' tokens token_pattern.findall doc tokens [ '#NUMBER' if token[0] in '0123456789_' else token for token in tokens]return tokens
def is_valid_ip_address address if address.lower in '127.0.0.1' 'localhost' ' 1' ' ffff 127.0.0.1' return Trueelif address.lower in 'unknown' '' return Falseelif address.count '.' 3 if address.startswith ' ffff ' address address[7 ]if hasattr socket 'inet_aton' try socket.inet_aton address return Trueexcept socket.error return Falseelse match REGEX_IPv4.match address if match and all 0 < int match.group i < 256 for i in 1 2 3 4 return Truereturn Falseelif hasattr socket 'inet_pton' try socket.inet_pton socket.AF_INET6 address return Trueexcept socket.error return Falseelse return True
def get_localizable_attributes obj locale {}try if obj.label locale['label'] obj.labelexcept passtry if obj.description locale['description'] obj.descriptionexcept passreturn locale
def codegen name_expr language prefix None project 'project' to_files False header True empty True argument_sequence None global_vars None code_gen get_code_generator language project if isinstance name_expr[0] string_types name_expr [name_expr]if prefix is None prefix name_expr[0][0]routines []for name expr in name_expr routines.append code_gen.routine name expr argument_sequence global_vars return code_gen.write routines prefix to_files header empty
def _pairwise_callable X Y metric **kwds X Y check_pairwise_arrays X Y if X is Y out np.zeros X.shape[0] Y.shape[0] dtype 'float' iterator itertools.combinations range X.shape[0] 2 for i j in iterator out[ i j ] metric X[i] Y[j] **kwds out out + out.T for i in range X.shape[0] x X[i]out[ i i ] metric x x **kwds else out np.empty X.shape[0] Y.shape[0] dtype 'float' iterator itertools.product range X.shape[0] range Y.shape[0] for i j in iterator out[ i j ] metric X[i] Y[j] **kwds return out
def get_simple_split branchfile index branchfile.find '/' if index -1 return None None branch file branchfile.split '/' 1 return branch file
def _get_volume_creation_time volume try return volume.extra['create_time']except KeyError return parse_date volume.extra['created_at'] .replace tzinfo tzutc
def lint_command tool_xml lint_ctx root tool_xml.getroot commands root.findall 'command' if len commands > 1 lint_ctx.error 'Morethanonecommandtagfound behaviorundefined.' returnif len commands 0 lint_ctx.error 'Nocommandtagfound mustspecifyacommandtemplatetoexecute.' returncommand get_command tool_xml if 'TODO' in command lint_ctx.warn 'CommandtemplatecontainsTODOtext.' command_attrib command.attribinterpreter_type Nonefor key value in command_attrib.items if key 'interpreter' interpreter_type valueelif key 'detect_errors' detect_errors valueif detect_errors not in ['default' 'exit_code' 'aggressive'] lint_ctx.warn 'Unknowndetect_errorsattribute[%s]' % detect_errors else lint_ctx.warn 'Unknownattribute[%s]encounteredoncommandtag.' % key interpreter_info ''if interpreter_type interpreter_info 'withinterpreteroftype[%s]' % interpreter_type if interpreter_type lint_ctx.info "Commandusesdeprecated'interpreter'attribute." lint_ctx.info 'Toolcontainsacommand%s.' % interpreter_info
def muladd_with_overflow builder a b c p builder.smul_with_overflow a b prod builder.extract_value p 0 prod_ovf builder.extract_value p 1 s builder.sadd_with_overflow prod c res builder.extract_value s 0 ovf builder.or_ prod_ovf builder.extract_value s 1 return res ovf
def decode_base64 text encoding 'utf-8' text to_bytes text encoding return to_unicode base64.b64decode text encoding
def isValidColor color try color float color return Trueexcept Exception if isinstance color basestring and len color return color.lower in colors255.keys or color[0] '#' or color[0 2] '0x' return type color in [tuple list numpy.ndarray] or not color
def _transform_messages_base64 messages transform key None for message in messages if key is not None message message[key]if 'data' in message message['data'] transform message['data']
def isBeingWritten filepath ctime max os.path.getctime filepath os.path.getmtime filepath if ctime > time.time - 60 return Truereturn False
def test_cnn_fit_sample cnn CondensedNearestNeighbour random_state RND_SEED X_resampled y_resampled cnn.fit_sample X Y X_gt np.array [[ -0.10903849 -0.12085181 ] [0.01936241 0.17799828] [0.05230552 0.09043907] [ -1.25020462 -0.40402054 ] [0.70524765 0.39816382] [0.35831463 1.33483198] [ -0.284881 -0.62730973 ] [0.03394306 0.03986753] [ -0.01252787 0.34102657] [0.15198585 0.12512646]] y_gt np.array [0 0 1 1 1 2 2 2 2 2] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def is_isolate G n return G.degree n 0
def test_inter_process_cache x y theano.tensor.dvectors 'xy' f theano.function [x y] [MyOp x MyOp y ] f numpy.arange 60 numpy.arange 60 if theano.config.mode 'FAST_COMPILE' or theano.config.cxx '' assert MyOp.nb_called 0 else assert MyOp.nb_called 1 x y theano.tensor.dvectors 'xy' f theano.function [x y] [MyOp x MyOp y ] f numpy.arange 60 numpy.arange 60 if theano.config.mode 'FAST_COMPILE' or theano.config.cxx '' assert MyOp.nb_called 0 else assert MyOp.nb_called 1
def downloaded_reqs_from_path path argv finder package_finder argv return [DownloadedReq req argv finder for req in _parse_requirements path finder ]
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def polar *args **kwargs if gcf .get_axes if not isinstance gca PolarAxes warnings.warn u'Tryingtocreatepolarplotonanaxisthatdoesnothaveapolarprojection.' ax gca polar True ret ax.plot *args **kwargs return ret
def inotify_code_changed class EventHandler pyinotify.ProcessEvent modified_code Nonedef process_default self event if event.path.endswith '.mo' EventHandler.modified_code I18N_MODIFIEDelse EventHandler.modified_code FILE_MODIFIEDwm pyinotify.WatchManager notifier pyinotify.Notifier wm EventHandler def update_watch sender None **kwargs if sender and getattr sender 'handles_files' False returnmask pyinotify.IN_MODIFY | pyinotify.IN_DELETE | pyinotify.IN_ATTRIB | pyinotify.IN_MOVED_FROM | pyinotify.IN_MOVED_TO | pyinotify.IN_CREATE | pyinotify.IN_DELETE_SELF | pyinotify.IN_MOVE_SELF for path in gen_filenames only_new True wm.add_watch path mask request_finished.connect update_watch update_watch notifier.check_events timeout None notifier.read_events notifier.process_events notifier.stop return EventHandler.modified_code
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@manager.option '-a' '--accounts' dest 'accounts' type unicode default u'all' def run_change_reporter accounts account_names _parse_accounts accounts sm_run_change_reporter account_names
def req_job_reset r **attr if r.interactive if r.component and r.component.alias 'job' job_id r.component_idif job_id S3Task.reset job_id current.session.confirmation current.T 'Jobreactivated' r.component_id Noneredirect r.url method ''
def update_font basefont weight None italic None underline None pixelSize None pointSize None font QFont basefont if weight is not None font.setWeight weight if italic is not None font.setItalic italic if underline is not None font.setUnderline underline if pixelSize is not None font.setPixelSize pixelSize if pointSize is not None font.setPointSize pointSize return font
@pytest.mark.parametrize 'lang' settings.AMO_LANGUAGES def test_get_locale_from_lang lang locale get_locale_from_lang lang assert isinstance locale Locale assert locale.language lang[ 2] separator filter None [ sep if sep in lang else None for sep in '-' '_' ] if separator territory lang.split separator[0] [1]assert locale.territory territory
def _get_comments group_tasks comments {}for status human in _COMMENTS num_tasks _get_number_of_tasks_for status group_tasks if num_tasks space '' if status in _PENDING_SUB_STATUSES else '' comments[status] '{space}*{num_tasks}{human} \n'.format space space num_tasks num_tasks human human return comments
def change_vulns table return [dict tab id vulnid for vulnid tab in table.iteritems ]
def cinder_one_import_per_line logical_line pos logical_line.find ' ' parts logical_line.split if pos > -1 and parts[0] 'import' or parts[0] 'from' and parts[2] 'import' and not is_import_exception parts[1] yield pos 'CINDERN301 oneimportperline'
def get_programs_data user None programs_list get_programs user program_types get_program_types user program_types_lookup_dict {program_type['name'] program_type for program_type in program_types}for program in programs_list program['logo_image'] program_types_lookup_dict[program['type']]['logo_image']return programs_list
def EscapeCppDefine s s EscapeShellArgument s s EscapeMakeVariableExpansion s return s.replace '#' '\\#'
def whitesource registry xml_parent data whitesource XML.SubElement xml_parent 'org.whitesource.jenkins.WhiteSourcePublisher' whitesource.set 'plugin' 'whitesource' policies ['global' 'enable' 'disable']mappings [ 'policies' 'jobCheckPolicies' 'global' policies 'override-token' 'jobApiToken' '' 'product-token' 'product' '' 'version' 'productVersion' '' 'project-token' 'projectToken' '' 'requester-email' 'requesterEmail' '' ]helpers.convert_mapping_to_xml whitesource data mappings fail_required True XML.SubElement whitesource 'libIncludes' .text ''.join data.get 'includes' [] XML.SubElement whitesource 'libExcludes' .text ''.join data.get 'excludes' [] XML.SubElement whitesource 'ignorePomModules' .text 'false'
def packbits myarray if myarray.dtype.kind not in 'biu' raise TypeError 'Expectedaninputarrayofintegerorbooleandatatype' myarray myarray.ravel packed_size myarray.size + 7 // 8 packed cupy.zeros packed_size dtype cupy.uint8 cupy.ElementwiseKernel 'rawTmyarray rawint32myarray_size' 'uint8packed' 'for intj 0;j<8;++j {\nintk i*8+j;\nintbit k<myarray_size&&myarray[k]! 0;\npacked| bit<< 7-j ;\n}' 'packbits_kernel' myarray myarray.size packed return packed
def qObjectReport verbose False global qObjCachecount {}for obj in findObj 'PyQt' if isinstance obj QtCore.QObject oid id obj if oid not in QObjCache QObjCache[oid] typeStr obj + '' + obj.objectName try QObjCache[oid] + '' + obj.parent .objectName QObjCache[oid] + '' + obj.text except passprint 'checkobj' oid str QObjCache[oid] if obj.parent is None walkQObjectTree obj count verbose typs list count.keys typs.sort for t in typs print count[t] ' DCTB ' t
def getSense form pos 'noun' senseno 0 return getWord form pos [senseno]
def load_extension ext_name configs [] configs dict configs pos ext_name.find ' ' if pos > 0 ext_args ext_name[ pos + 1 -1 ]ext_name ext_name[ pos]pairs [x.split ' ' for x in ext_args.split ' ' ]configs.update [ x.strip y.strip for x y in pairs] ext_module 'markdown.extensions'module_name_new_style '.'.join [ext_module ext_name] module_name_old_style '_'.join ['mdx' ext_name] try module __import__ module_name_new_style {} {} [ext_module] except ImportError try module __import__ module_name_old_style except ImportError message WARN "Failedloadingextension'%s'from'%s'or'%s'" % ext_name module_name_new_style module_name_old_style return Nonetry return module.makeExtension configs.items except AttributeError message CRITICAL "Failedtoinitiateextension'%s'" % ext_name
def matchingDict d selection require_existence False for k v in list selection.items if k in d if isinstance v list if d[k] not in v return Falseelif d[k] ! v return Falseelif require_existence return Falsereturn True
def _SendRecv port int os.getenv DEVSHELL_ENV 0 if port 0 raise NoDevshellServer sock socket.socket sock.connect 'localhost' port data CREDENTIAL_INFO_REQUEST_JSONmsg '{0}\n{1}'.format len data data sock.sendall _helpers._to_bytes msg encoding 'utf-8' header sock.recv 6 .decode if '\n' not in header raise CommunicationError 'sawnonewlineinthefirst6bytes' len_str json_str header.split '\n' 1 to_read int len_str - len json_str if to_read > 0 json_str + sock.recv to_read socket.MSG_WAITALL .decode return CredentialInfoResponse json_str
def validate_textbooks_json text try textbooks json.loads text except ValueError raise TextbookValidationError 'invalidJSON' if not isinstance textbooks list tuple raise TextbookValidationError 'mustbeJSONlist' for textbook in textbooks validate_textbook_json textbook all_ids [textbook['id'] for textbook in textbooks if 'id' in textbook ]unique_ids set all_ids if len all_ids > len unique_ids raise TextbookValidationError 'IDsmustbeunique' return textbooks
def decorate_depth tree for node in tree.levelorder include_self True if node.Parent is None node.Score 0else node.Score node.Parent.Score + 1 return tree
def _construct_signal_from_epochs epochs events sfreq tmin n_epochs n_channels n_times epochs.shapetmax tmin + n_times / float sfreq start np.min events[ 0] + int tmin * sfreq stop np.max events[ 0] + int tmax * sfreq + 1 n_samples stop - start n_epochs n_channels n_times epochs.shapeevents_pos events[ 0] - events[ 0 0 ] raw np.zeros n_channels n_samples for idx in range n_epochs onset events_pos[idx]offset onset + n_times raw[ onset offset] epochs[idx]return raw
def calculate_sha256 body as_hex False checksum hashlib.sha256 for chunk in iter lambda body.read 1024 * 1024 '' checksum.update chunk if as_hex return checksum.hexdigest else return checksum.digest
def instance_type_extra_specs_get context flavor_id return IMPL.instance_type_extra_specs_get context flavor_id
def print_undefined_step_snippets undefined_steps stream None colored True if not undefined_steps returnif not stream stream sys.stderrmsg u'\nYoucanimplementstepdefinitionsforundefinedstepswith'msg + u'thesesnippets \n\n'printed set for step in undefined_steps if step in printed continueprinted.add step msg + make_undefined_step_snippet step if colored from behave.formatter.ansi_escapes import escapesmsg escapes['undefined'] + msg + escapes['reset'] stream.write msg stream.flush
def _serialize_node_search node data {'id' node._id 'title' node.title 'etal' len node.visible_contributors > 1 'isRegistration' node.is_registration}if node.is_registration data['title'] + ' registration 'data['dateRegistered'] node.registered_date.isoformat else data['dateCreated'] node.date_created.isoformat data['dateModified'] node.date_modified.isoformat first_author node.visible_contributors[0]data['firstAuthor'] first_author.family_name or first_author.given_name or first_author.fullname return data
def topological_sort elems result []visited set def visit n if n not in visited visited.add n if n in elems map visit elems[n] result.append n map visit elems return result
def min_max_axis X axis if isinstance X sp.csr_matrix or isinstance X sp.csc_matrix return sparse_min_max X axis axis else _raise_typeerror X
def expand_complex expr deep True return sympify expr .expand deep deep complex True basic False log False mul False power_exp False power_base False multinomial False
def file_list *packages errors []ret []cmd ['pacman' '-Ql']if len packages > 0 and os.path.exists packages[0] packages list packages cmd.extend '-r' packages.pop 0 cmd.extend packages out __salt__['cmd.run'] cmd output_loglevel 'trace' python_shell False for line in salt.utils.itertools.split out '\n' if line.startswith 'error' errors.append line else comps line.split ret.append ''.join comps[1 ] return {'errors' errors 'files' ret}
def md5_key_mangler key return md5 key.encode 'ascii' .hexdigest
def _get_makeconf old_conf '/etc/make.conf'new_conf '/etc/portage/make.conf'if __salt__['file.file_exists'] old_conf return old_confelif __salt__['file.file_exists'] new_conf return new_conf
def rand_nonzero shape eps 0.0003 r numpy.asarray numpy.random.rand *shape dtype config.floatX r r * 1 - eps + eps * r > 0.5 r r * 2 - 1 return r
def http_code_description http_code description HTTP_STATUS_CODES.get try_int http_code if isinstance description list return u' {0} '.format u' '.join description return description
def S_ISGITLINK m return stat.S_IFMT m S_IFGITLINK
def info return _nodetool 'info'
def _generative *assertions @util.decoratordef generate fn *args **kw self args[0]._clone for assertion in assertions assertion self fn.__name__ fn self *args[1 ] **kw return selfreturn generate
def _preprocess_widget widget name module_name widget['module_name']import_name module_name + '.views' module_views __import__ import_name fromlist [str module_name ] if hasattr module_views name if 'title' not in widget widget['title'] getattr module_views name .__doc__widget copy.deepcopy widget if 'view' not in widget widget['view'] getattr module_views name return widget
def convert_translations_to_dict js_translations plural n_plural _get_plural_forms js_translations translations_dict {'plural' plural 'catalog' {} 'fallback' None}if js_translations._fallback is not None translations_dict['fallback'] convert_translations_to_dict js_translations._fallback for key value in js_translations._catalog.items if key '' continueif type key in str unicode translations_dict['catalog'][key] valueelif type key tuple if key[0] not in translations_dict['catalog'] translations_dict['catalog'][key[0]] [''] * n_plural translations_dict['catalog'][key[0]][int key[1] ] valuereturn translations_dict
def _get_valid_trace_context trace_context assert isinstance trace_context TraceContext dict if isinstance trace_context dict trace_context TraceContext **trace_context return trace_context
def find_xem_absolute_numbering indexer_id indexer absolute_number if indexer_id is None or absolute_number is None return absolute_numberindexer_id int indexer_id indexer int indexer xem_refresh indexer_id indexer main_db_con db.DBConnection rows main_db_con.select 'SELECTscene_absolute_numberFROMtv_episodesWHEREindexer ?andshowid ?andabsolute_number ?andscene_absolute_number! 0' [indexer indexer_id absolute_number] if rows return int rows[0]['scene_absolute_number']
def reapAllProcesses for process in list reapProcessHandlers.values process.reapProcess
def adapt_references subtree destination_course_key export_fs subtree.runtime.export_fs export_fsfor field_name field in subtree.fields.iteritems if field.is_set_on subtree if isinstance field Reference value field.read_from subtree if value is not None field.write_to subtree field.read_from subtree .map_into_course destination_course_key elif field_name 'children' [adapt_references child destination_course_key export_fs for child in subtree.get_children ]elif isinstance field ReferenceList field.write_to subtree [ele.map_into_course destination_course_key for ele in field.read_from subtree ] elif isinstance field ReferenceValueDict field.write_to subtree {key ele.map_into_course destination_course_key for key ele in field.read_from subtree .iteritems }
def extract_external_port client container_identifier internal_port container_details client.inspect_container container_identifier network_settings container_details[u'NetworkSettings']ports network_settings[u'Ports']details ports[u'{}/tcp'.format internal_port ]host_port int details[0][u'HostPort'] Message.new message_type u'acceptance extract_external_port' host_port host_port .write return host_port
def build_routes iface **settings iface iface.lower opts _parse_routes iface settings try template JINJA.get_template 'route_eth.jinja' except jinja2.exceptions.TemplateNotFound log.error 'Couldnotloadtemplateroute_eth.jinja' return ''add_routecfg template.render route_type 'add' routes opts['routes'] iface iface del_routecfg template.render route_type 'del' routes opts['routes'] iface iface if 'test' in settings and settings['test'] return _read_temp add_routecfg + del_routecfg filename _write_file_routes iface add_routecfg _DEB_NETWORK_UP_DIR 'route-{0}' results _read_file filename filename _write_file_routes iface del_routecfg _DEB_NETWORK_DOWN_DIR 'route-{0}' results + _read_file filename return results
def _dict_reorder rep gens new_gens gens list gens monoms rep.keys coeffs rep.values new_monoms [[] for _ in range len rep ]used_indices set for gen in new_gens try j gens.index gen used_indices.add j for M new_M in zip monoms new_monoms new_M.append M[j] except ValueError for new_M in new_monoms new_M.append 0 for i _ in enumerate gens if i not in used_indices for monom in monoms if monom[i] raise GeneratorsError 'unabletodropgenerators' return map tuple new_monoms coeffs
def _tupleize dct return [ key val for key val in dct.items ]
def block_until_instance_ready booting_instance wait_time 5 extra_wait_time 20 _id booting_instance.id_instance EC2.Instance id _id _state _instance.state['Name']_ip _instance.public_ip_addresswhile _state ! 'running' or _ip is None time.sleep wait_time _instance EC2.Instance id _id _state _instance.state['Name']_ip _instance.public_ip_addressblock_until_ssh_open _ip time.sleep extra_wait_time return _instance
def nonnegative_int argument value int argument if value < 0 raise ValueError 'negativevalue;mustbepositiveorzero' return value
def base_context s '' log None ctx.contexts[ -1 ] ''ctx.contexts[ -2 ] sif s and log log 'Context %s' % get_context
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def addPathToGroup derivation groupDictionaryCopy path targetMatrix totalIndex for pointIndex point in enumerate path arrayElement derivation.target.getCopy derivation.elementNode.getIDSuffix totalIndex derivation.elementNode arrayDictionary arrayElement.attributesarrayDictionary['visible'] str derivation.visible .lower arrayDictionary.update groupDictionaryCopy euclidean.removeTrueFromDictionary arrayDictionary 'visible' vertexMatrix matrix.Matrix matrix.getTranslateTetragridByTranslation point zAngle totalIndex * 50.0 rotationMatrix getRotationMatrix arrayDictionary derivation path point pointIndex arrayElementMatrix vertexMatrix.getSelfTimesOther rotationMatrix.getSelfTimesOther targetMatrix.tetragrid .tetragrid arrayDictionary.update arrayElementMatrix.getAttributes 'matrix.' arrayDictionary['_arrayIndex'] totalIndexarrayDictionary['_arrayPoint'] pointtotalIndex + 1
def epoch return datetime 1970 1 1
def extract_data input_dir output_dir if os.path.isdir output_dir print 'Usingextracteddataat%s.' % output_dir returnfor filename in 'data_object_label_2.zip' 'data_object_image_2.zip' 'devkit_object.zip' filename os.path.join input_dir filename zf zipfile.ZipFile filename 'r' print 'Unzipping%s...' % filename zf.extractall output_dir
def set_dirty_and_flush_changes non_const_func def flush_changes self *args **kwargs rval non_const_func self *args **kwargs self._dirty Trueself.write return rvalflush_changes.__name__ non_const_func.__name__return flush_changes
def remove_invalid_filter_options context filters allowed_search_options if context.is_admin returnunknown_options [opt for opt in filters if opt not in allowed_search_options ]bad_options ' '.join unknown_options LOG.debug "Removingoptions'%s'fromquery." bad_options for opt in unknown_options del filters[opt]
def get_mock_request user None request RequestFactory .get '/' if user is not None request.user userelse request.user AnonymousUser request.is_secure lambda True request.get_host lambda 'edx.org' crum.set_current_request request return request
def qiime_open fp permission 'U' if is_gzip fp return gzip_open fp else return open fp permission
def prettify jsonobj prettify True if not prettify return json.dumps jsonobj json_str json.dumps jsonobj indent 2 sort_keys True if pygments try lexer get_lexer_for_mimetype 'application/json' return pygments.highlight json_str lexer TerminalFormatter except passreturn json_str
def seq2str sequence quote "'" sep ' ' lastsep 'and' sequence [ quote + unic item + quote for item in sequence]if not sequence return ''if len sequence 1 return sequence[0]last_two lastsep.join sequence[ -2 ] return sep.join sequence[ -2 ] + [last_two]
def filename_match filename if not options.filename return Truefor pattern in options.filename if fnmatch filename pattern return True
def _extract_nodes html_tree filename search_expr _XPATH_FIND_NODESfor name in _IGNORE_NODES search_expr + '[not ancestor-or-self %s ]' % name return html_tree.xpath search_expr
def get_cached_trees queryset current_path []top_nodes []if queryset parent_attr queryset[0]._mptt_meta.parent_attrroot_level Nonefor obj in queryset node_level obj.get_level if root_level is None root_level node_levelif node_level < root_level raise ValueError _ u'Node%snotindepth-firstorder' % type queryset obj._cached_children []while len current_path > node_level - root_level current_path.pop -1 if node_level root_level top_nodes.append obj else _parent current_path[ -1 ]setattr obj parent_attr _parent _parent._cached_children.append obj if root_level 0 setattr obj u'_mptt_use_cached_ancestors' True current_path.append obj return top_nodes
def test_write_noheader_no_pad out StringIO ascii.write dat out Writer ascii.FixedWidthNoHeader delimiter_pad None assert_equal_splitlines out.getvalue '|1.2|"hello"|1|a|\n|2.4|\'sworlds|2|2|\n'
def safecall f name *args **kwargs lwork kwargs.get 'lwork' None if lwork in None -1 kwargs['lwork'] -1 ret f *args **kwargs kwargs['lwork'] ret[ -2 ][0].real.astype numpy.int ret f *args **kwargs if ret[ -1 ] < 0 raise ValueError 'illegalvaluein%d-thargumentofinternal%s' % - ret[ -1 ] name return ret[ -2 ]
def userdel pwfile user return __salt__['webutil.userdel'] pwfile user
def p_expression_name t try t[0] names[t[1]]except LookupError print u"Undefinedname'%s'" % t[1] t[0] 0
def show_notification name text None **kwargs if not text raise SaltInvocationError 'Missingrequiredargumenttext.' ret {'name' name 'changes' {} 'result' True 'comment' text}return ret
def getClosestPointOnSegment segmentBegin segmentEnd point segmentDifference segmentEnd - segmentBegin if abs segmentDifference < 0.0 return segmentBeginpointMinusSegmentBegin point - segmentBegin beginPlaneDot getDotProduct pointMinusSegmentBegin segmentDifference differencePlaneDot getDotProduct segmentDifference segmentDifference intercept beginPlaneDot / differencePlaneDot intercept max intercept 0.0 intercept min intercept 1.0 return segmentBegin + segmentDifference * intercept
def generate_library_search_paths lib extra_dirs COMMON_LIB_PATHS ld_so_conf_filename Ldconfig.LD_SO_CONF if os.sep in lib paths [lib]else l Ldconfig search_paths l.ldconfig ld_so_conf_filename extra_dirs paths path_joiner lib search_paths return paths
def award_enrollment_badge user config CourseEventBadgesConfiguration.current .enrolled_settingsenrollments user.courseenrollment_set.filter is_active True .count award_badge config enrollments user
def test_finder_only_installs_data_require data finder PackageFinder [] [data.index_url 'datarequire' ] session PipSession links finder.find_all_candidates 'fakepackage' expected ['1.0.0' '9.9.9']if sys.version_info < 2 7 expected.append '2.6.0' elif 2 7 < sys.version_info < 3 expected.append '2.7.0' elif sys.version_info > 3 3 expected.append '3.3.0' assert set [str v.version for v in links] set expected
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _filter_names names names [n for n in names if n not in EXCLUDE_NAMES ]for pattern in EXCLUDE_PATTERNS names [n for n in names if not fnmatch.fnmatch n pattern and not n.endswith '.py' ]return names
def read_bitpacked_deprecated file_obj byte_count count width debug_logging raw_bytes array.array ARRAY_BYTE_STR file_obj.read byte_count .tolist mask _mask_for_bits width index 0res []word 0bits_in_word 0while len res < count and index < len raw_bytes if debug_logging logger.debug u'index %d' index logger.debug u'bitsinword %d' bits_in_word logger.debug u'word %s' bin word if bits_in_word > width offset bits_in_word - width value word & mask << offset >> offset if debug_logging logger.debug u'offset %d' offset logger.debug u'value %d %s ' value bin value res.append value bits_in_word - widthelse word word << 8 | raw_bytes[index] index + 1bits_in_word + 8return res
@register.simple_tag takes_context True def avatar_url context user size resolution u'1x' service_id None if resolution not in u'1x' u'2x' raise ValueError u'resolutionshouldbe"1x"or"2x" not%r.' % resolution service avatar_services.for_user user service_id if service is None logging.error u'Couldnotgetasuitableavatarserviceforuser%s.' user return mark_safe u'' urls service.get_avatar_urls request context[u'request'] user user size size return urls[resolution]
def reset_docker_settings DockerUtil .set_docker_settings {} {}
def safe_repr fmt *args **kwargs if not is_py3 fmt fmt.decode 'utf-8' out fmt.format *args **kwargs return out.encode 'utf-8' else return fmt.format *args **kwargs
def ungettext singular plural number return do_ntranslate singular plural number 'ungettext'
def write_flv_header stream stream.write 'FLV\x01' stream.write '\x05' stream.write '\x00\x00\x00 DCTB ' stream.write '\x00\x00\x00\x00'
def approx_fprime_cs x f epsilon None args kwargs {} n len x epsilon _get_epsilon x 1 epsilon n increments np.identity n * 1j * epsilon partials [ f x + ih *args **kwargs .imag / epsilon[i] for i ih in enumerate increments ]return np.array partials .T
def getPathsByLists vertexLists vector3Lists getVector3ListsRecursively vertexLists paths []addToPathsRecursively paths vector3Lists return paths
def qnwlogn n mu None sig2 None nodes weights qnwnorm n mu sig2 return np.exp nodes weights
def resnet_v2_200 inputs num_classes None is_training True global_pool True output_stride None reuse None scope 'resnet_v2_200' blocks [resnet_utils.Block 'block1' bottleneck [ 256 64 1 ] * 2 + [ 256 64 2 ] resnet_utils.Block 'block2' bottleneck [ 512 128 1 ] * 23 + [ 512 128 2 ] resnet_utils.Block 'block3' bottleneck [ 1024 256 1 ] * 35 + [ 1024 256 2 ] resnet_utils.Block 'block4' bottleneck [ 2048 512 1 ] * 3 ]return resnet_v2 inputs blocks num_classes is_training is_training global_pool global_pool output_stride output_stride include_root_block True reuse reuse scope scope
def bucket_copy self CopySource Key ExtraArgs None Callback None SourceClient None Config None return self.meta.client.copy CopySource CopySource Bucket self.name Key Key ExtraArgs ExtraArgs Callback Callback SourceClient SourceClient Config Config
def test_random_tree T nx.random_tree 10 seed 1234 assert_true nx.is_tree T
def migrate_add_message_prefix context max_count force False return IMPL.migrate_add_message_prefix context max_count force
def _get_test_cluster reactor control_node environ.get 'FLOCKER_ACCEPTANCE_CONTROL_NODE' if control_node is None raise SkipTest 'SetacceptancetestingcontrolnodeIPaddressusingthe' + 'FLOCKER_ACCEPTANCE_CONTROL_NODEenvironmentvariable.' agent_nodes_env_var environ.get 'FLOCKER_ACCEPTANCE_NUM_AGENT_NODES' if agent_nodes_env_var is None raise SkipTest 'SetthenumberofconfiguredacceptancetestingnodesusingtheFLOCKER_ACCEPTANCE_NUM_AGENT_NODESenvironmentvariable.' num_agent_nodes int agent_nodes_env_var certificates_path FilePath environ['FLOCKER_ACCEPTANCE_API_CERTIFICATES_PATH'] hostname_to_public_address_env_var environ.get 'FLOCKER_ACCEPTANCE_HOSTNAME_TO_PUBLIC_ADDRESS' '{}' hostname_to_public_address json.loads hostname_to_public_address_env_var return connected_cluster reactor control_node certificates_path num_agent_nodes hostname_to_public_address
def get_key key host None port None db None password None server _connect host port db password return server.get key
def _check_guts_eq attr old new last_build if old ! new logger.info 'Buildingbecause%schanged' attr return Truereturn False
def form_hmac form data []for bf in form if form.empty_permitted and not form.has_changed value bf.data or '' else value bf.field.clean bf.data or '' if isinstance value basestring value value.strip data.append bf.name value pickled pickle.dumps data pickle.HIGHEST_PROTOCOL key_salt 'django.contrib.formtools'return salted_hmac key_salt pickled .hexdigest
def get_app_qt4 *args **kwargs from IPython.external.qt_for_kernel import QtGuiapp QtGui.QApplication.instance if app is None if not args args [''] app QtGui.QApplication *args **kwargs return app
def p_const_map p p[0] dict p[2]
def get_loaded_rules rules_paths for path in rules_paths if path.name ! '__init__.py' rule Rule.from_path path if rule.is_enabled yield rule
def has_subdirectories path include exclude show_all try return len listdir path include exclude show_all folders_only True > 1 except IOError OSError return False
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _check_to_native self in_string encoding py2_expected py3_expected if PY3 self.assertEqual to_native in_string encoding py3_expected else self.assertEqual to_native in_string encoding py2_expected
def generate_cert domain result __salt__['cmd.run'] 'icinga2pkinew-cert--cn{0}--key/etc/icinga2/pki/{0}.key--cert/etc/icinga2/pki/{0}.crt'.format domain return result
def renumerate it return zip xrange len it - 1 -1 -1 reversed it
def get_backend_api cluster_id backend_config_filename environ.get 'FLOCKER_ACCEPTANCE_TEST_VOLUME_BACKEND_CONFIG' if backend_config_filename is None raise SkipTest 'ThistestrequirestheabilitytoconstructanIBlockDeviceAPIinordertoverifyconstruction.PleasesetFLOCKER_ACCEPTANCE_TEST_VOLUME_BACKEND_CONFIGtoayamlfilepathwiththedatasetconfiguration.' backend_name environ.get 'FLOCKER_ACCEPTANCE_VOLUME_BACKEND' if backend_name is None raise SkipTest 'Setacceptancetestingvolumebackendusingthe' + 'FLOCKER_ACCEPTANCE_VOLUME_BACKENDenvironmentvariable.' if backend_name in 'loopback' 'zfs' raise SkipTest "TheloopbackbackendAPIcan'tbeusedremotely." backend_config_filepath FilePath backend_config_filename full_backend_config yaml.safe_load backend_config_filepath.getContent backend_config full_backend_config.get backend_name if 'backend' in backend_config backend_config.pop 'backend' backend backend_loader.get backend_name return get_api backend pmap backend_config reactor cluster_id
def CDLDARKCLOUDCOVER barDs count penetration -4e+37 return call_talib_with_ohlc barDs count talib.CDLDARKCLOUDCOVER penetration
def _record_from_json value field if _not_null value field record {}record_iter zip field.fields value['f'] for subfield cell in record_iter converter _CELLDATA_FROM_JSON[subfield.field_type]if subfield.mode 'REPEATED' value [converter item['v'] subfield for item in cell['v']]else value converter cell['v'] subfield record[subfield.name] valuereturn record
def ipv4_to_int ip return struct.unpack '!I' addrconv.ipv4.text_to_bin ip [0]
def addToThreadsRemoveFromSurroundings oldOrderedLocation surroundingLoops skein if len surroundingLoops < 1 returnwhile len surroundingLoops > 0 getTransferClosestSurroundingLoop oldOrderedLocation surroundingLoops skein
def create_thread name conn thread threading.Thread target conn.start name name thread.setDaemon True return thread
def test_imap_missing_spam constants monkeypatch folder_base [ '\\HasNoChildren' '/' u'INBOX' '\\Noselect' '\\HasChildren' '/' u'SKIP' '\\HasNoChildren' '\\Drafts' '/' u'Drafts' '\\HasNoChildren' '\\Sent' '/' u'Sent' '\\HasNoChildren' '\\Sent' '/' u'SentItems' '\\HasNoChildren' '\\Trash' '/' u'Trash' '\\HasNoChildren' '/' u'reference' ]check_missing_generic 'spam' folder_base localized_folder_names['spam'] 'imap' constants monkeypatch
def deactivateAaPdpContextAccept a TpPd pd 8 b MessageType mesType 84 packet a / b return packet
@sopel.module.commands u'load' @sopel.module.priority u'low' @sopel.module.thread False def pm_f_load bot trigger if trigger.is_privmsg f_load bot trigger
def _get_status status if status not in STATUS_CODES raise ValueError 'Unknownstatuscode' return STATUS_CODES[status]
@receiver pre_delete sender GoldUser def delete_customer sender instance **__ if sender GoldUser and instance.stripe_id is not None utils.delete_customer instance.stripe_id
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def serviceLanes stacks duration 1.0 start time.time while start + duration > time.time for stack in stacks stack.serviceAll if all [ not stack.txMsgs for stack in stacks] console.terse 'Servicestacksdonenormally\n' breaktime.sleep 0.05 for stack in stacks console.terse 'Stack{0}remotes {1}\n'.format stack.name stack.nameRemotes console.terse 'Servicestacksexit\n'
def test_amo_locale_not_in_django activate 'mn' en trans_real._translations['en-US']mn trans_real._translations['mn']assert en ! mn assert en._catalog ! mn._catalog
def get_diff_text old new filename newline u'\n'diff difflib.unified_diff old new u'original/' + filename u'fixed/' + filename lineterm newline text u''for line in diff text + lineif text and not line.endswith newline text + newline + u'\\Nonewlineatendoffile' + newline return text
def doc *args return os.path.join _prefix u'share' u'doc' u'git-cola' *args
@contextlib.contextmanagerdef temporary_mutation obj **kwargs def is_dict_like thing return hasattr thing 'has_key' def get thing attr default if is_dict_like thing return thing.get attr default else return getattr thing attr default def set_value thing attr val if is_dict_like thing thing[attr] valelse setattr thing attr val def delete thing attr if is_dict_like thing del thing[attr]else delattr thing attr NOT_PRESENT object old_values {}for attr new_value in kwargs.items old_values[attr] get obj attr NOT_PRESENT set_value obj attr new_value try yield finally for attr old_value in old_values.items if old_value is NOT_PRESENT delete obj attr else set_value obj attr old_value
def mount module args mount_bin module.get_bin_path 'mount' required True name args['name']cmd [mount_bin]if ismount name return remount module mount_bin args if get_platform .lower 'openbsd' if module.params['fstab'] is not None module.fail_json msg 'OpenBSDdoesnotsupportalternatefstabfiles.DonotspecifythefstabparameterforOpenBSDhosts' else cmd + _set_fstab_args args['fstab'] cmd + [name] rc out err module.run_command cmd if rc 0 return 0 '' else return rc out + err
def get_phases_by_plugin name return list get_plugin_by_name name .phase_handlers
def getGeometryOutputByArguments arguments elementNode return getGeometryOutput None elementNode
def can_file_be_synced_on_current_platform path can_be_synced Truefullpath os.path.join os.environ['HOME'] path library_path os.path.join os.environ['HOME'] 'Library/' if platform.system constants.PLATFORM_LINUX if fullpath.startswith library_path can_be_synced Falsereturn can_be_synced
def AddPluginsSubparsers classes sorted export_plugins.plugin.ExportPlugin.classes.itervalues key lambda cls cls.name subparsers flags.PARSER.add_subparsers title 'Subcommands' for cls in classes if not cls.name continuesubparser subparsers.add_parser cls.name help cls.description plugin_obj cls plugin_obj.ConfigureArgParser subparser subparser.set_defaults func plugin_obj.Run
def str_get_dummies arr sep '|' arr arr.fillna '' try arr sep + arr + sep except TypeError arr sep + arr.astype str + sep tags set for ts in arr.str.split sep tags.update ts tags sorted tags - set [''] dummies np.empty len arr len tags dtype np.int64 for i t in enumerate tags pat sep + t + sep dummies[ i] lib.map_infer arr.values lambda x pat in x return dummies tags
def parse_expr s local_dict global_dict {}exec_ 'fromsympyimport*' global_dict try a parse s.strip mode 'eval' except SyntaxError raise SympifyError 'Cannotparse%s.' % repr s a Transform local_dict global_dict .visit a e compile a '<string>' 'eval' return eval e global_dict local_dict
def _transform_equals_sign tokens local_dict global_dict result []if OP ' ' in tokens result.append NAME 'Eq' result.append OP ' ' for index token in enumerate tokens if token OP ' ' result.append OP ' ' continueresult.append token result.append OP ' ' else result tokensreturn result
def security_group_get context security_group_id columns_to_join None return IMPL.security_group_get context security_group_id columns_to_join
def install_atlas chdir SRC_DIR apt_command 'build-depatlas' if glob.glob '*atlas*.deb' run_command 'dpkg-i*atlas*.deb' returnapt_command 'sourceatlas' chdir 'atlas-*' run_command 'fakerootdebian/rulescustom' run_command 'dpkg-i../*atlas*.deb'
def _col_chunks l max_rows row_first False if row_first ncols len l // max_rows + len l % max_rows > 0 for i in range ncols yield [l[j] for j in range i len l ncols ] else for i in range 0 len l max_rows yield l[i i + max_rows ]
def encrypt data iv Random.new .read AES.block_size cipher _create_cipher iv return iv + cipher.encrypt data
def condition_yaw heading relative False if relative is_relative 1else is_relative 0msg vehicle.message_factory.command_long_encode 0 0 mavutil.mavlink.MAV_CMD_CONDITION_YAW 0 heading 0 1 is_relative 0 0 0 vehicle.send_mavlink msg
def test_expected_operation_order expected instructions.CHECK_FETCH instructions.FETCH instructions.CHECK_EXTRACT instructions.EXTRACT instructions.UNLINK instructions.LINK instructions.SYMLINK_CONDA instructions.RM_EXTRACTED instructions.RM_FETCHED assert expected instructions.ACTION_CODES
def enforce credentials action target do_raise True init extra {}if do_raise extra.update exc exception.ForbiddenAction action action do_raise do_raise return _ENFORCER.enforce action target credentials **extra
def org_customise_org_resource_fields method s3db current.s3dbtable s3db.org_resourcetable.location_id.represent s3db.gis_LocationRepresent sep '|' list_fields ['organisation_id' 'location_id' 'parameter_id' 'value' 'comments']if method in 'datalist' 'profile' table.modified_by.represent s3_auth_user_represent_nametable.modified_on.represent lambda dt S3DateTime.datetime_represent dt utc True list_fields + ['modified_by' 'modified_on' 'organisation_id$logo']s3db.configure 'org_resource' list_fields list_fields
def see_other location to location falcon.HTTP_303
def test_rus_sample_wrong_X rus RandomUnderSampler random_state RND_SEED rus.fit X Y assert_raises RuntimeError rus.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def _safe_value obj key value typ obj._type key return isinstance typ SAFE_TYPES and isinstance value typ.model_type
def extract_parameters_for_action_alias_db action_alias_db format_str param_stream formats []formats action_alias_db.get_format_strings if format_str not in formats raise ValueError 'Formatstring"%s"isnotavailableonthealias"%s"' % format_str action_alias_db.name result extract_parameters format_str format_str param_stream param_stream return result
def withRequest f f.withRequest Truereturn f
def get_current_ccx course_key if not isinstance course_key CourseKey raise ValueError 'get_current_ccxrequiresaCourseKeyinstance' if not isinstance course_key CCXLocator return Noneccx_cache request_cache.get_cache 'ccx' if course_key not in ccx_cache ccx_cache[course_key] CustomCourseForEdX.objects.get pk course_key.ccx return ccx_cache[course_key]
def test_reset ip.reset nvars_user_ns len ip.user_ns nvars_hidden len ip.user_ns_hidden ip.user_ns['x'] 1ip.user_ns['y'] 1ip.reset nt.assert_equal len ip.user_ns nvars_user_ns nt.assert_equal len ip.user_ns_hidden nvars_hidden
def constant_app status headers body def application unused_environ start_response start_response status headers return [body]return application
def trainKNN features K [Xt Yt] listOfFeatures2Matrix features knn kNN Xt Yt K return knn
def get_admin_users admins return [get_user email e for e in admins]
def find_vm_by_id content vm_id vm_id_type 'vm_name' datacenter None cluster None si content.searchIndexvm Noneif vm_id_type 'dns_name' vm si.FindByDnsName datacenter datacenter dnsName vm_id vmSearch True elif vm_id_type 'inventory_path' vm si.FindByInventoryPath inventoryPath vm_id if type vm ! type vim.VirtualMachine vm Noneelif vm_id_type 'uuid' vm si.FindByUuid datacenter datacenter instanceUuid vm_id vmSearch True elif vm_id_type 'ip' vm si.FindByIp datacenter datacenter ip vm_id vmSearch True elif vm_id_type 'vm_name' folder Noneif cluster folder clusterelif datacenter folder datacenter.hostFoldervm find_vm_by_name content vm_id folder return vm
@receiver m2m_changed sender LocalSite.users.through def _on_local_site_users_changed sender instance model action pk_set **kwargs if action u'post_add' if isinstance instance User users [instance]local_sites LocalSite.objects.filter id__in pk_set else users User.objects.filter id__in pk_set local_sites [instance]for user in users for local_site in local_sites local_site_user_added.send sender LocalSite user user local_site local_site
def _RemainingDataSize input_buffer current_position input_buffer.tell input_buffer.seek 0 2 remaining_data_size input_buffer.tell - current_position input_buffer.seek current_position return remaining_data_size
def do_striptags value if hasattr value '__html__' value value.__html__ return Markup unicode value .striptags
def addRackHole derivation vector3RackProfiles x xmlElement rackHole euclidean.getComplexPolygon complex x - derivation.rackHoleBelow derivation.rackHoleRadius -13 vector3RackProfiles.append euclidean.getVector3Path rackHole
def abbr S max ellipsis u'...' if S is None return u'???'if len S > max return ellipsis and S[ max - len ellipsis ] + ellipsis or S[ max] return S
def threshold_sauvola image window_size 15 k 0.2 r None if r is None imin imax dtype_limits image clip_negative False r 0.5 * imax - imin m s _mean_std image window_size return m * 1 + k * s / r - 1
def _get_presser fig callbacks fig.canvas.callbacks.callbacks['button_press_event']func Nonefor key val in callbacks.items if val.func.__class__.__name__ 'partial' func val.funcbreakassert func is not None return func
def create_permission_grant_for_resource_db role_db resource_db permission_types permission_types _validate_permission_types resource_db resource_db permission_types permission_types resource_uid resource_db.get_uid resource_type resource_db.get_resource_type result create_permission_grant role_db role_db resource_uid resource_uid resource_type resource_type permission_types permission_types return result
def _format_timedelta time result str strip_microseconds time parts result.split if len parts 3 and len parts[ -1 ] 7 return '%s%s%s' % tuple parts else return result
def timestamps registry xml_parent data XML.SubElement xml_parent 'hudson.plugins.timestamper.TimestamperBuildWrapper'
def load_graph_xml xml filename load_all False ret []try root objectify.fromstring xml except Exception return []if root.tag ! 'graphs' return []if not hasattr root 'graph' return []for g in root.graph name g.attrib['name']expressions [e.text for e in g.expression]if load_all ret.append GraphDefinition name e g.description.text expressions filename continueif have_graph name continuefor e in expressions if expression_ok e ret.append GraphDefinition name e g.description.text expressions filename breakreturn ret
def get_language_bidi lang get_language if lang is None return Falseelse base_lang get_language .split '-' [0]return base_lang in settings.LANGUAGES_BIDI
def run_child_process test_info test_info.start_server sys.exit 0
def _formatparam param value None quote True if value is not None and len value > 0 if isinstance value tuple param + '*'value utils.encode_rfc2231 value[2] value[0] value[1] if quote or tspecials.search value return '%s "%s"' % param utils.quote value else return '%s %s' % param value else return param
def imread_qt filename qtimg QImage if not qtimg.load filename raise IOError 'Unabletoloadfile%s' % filename if qtimg.depth 1 raise IOError '1-bitimagescurrentlynotsupported' arrayptr qtimg.bits bytes_per_pixel qtimg.depth // 8 pixels_per_line qtimg.bytesPerLine // bytes_per_pixel img_size pixels_per_line * qtimg.height * bytes_per_pixel arrayptr.setsize img_size img np.array arrayptr if bytes_per_pixel > 1 img img.reshape qtimg.height pixels_per_line bytes_per_pixel img img[ qtimg.width ]else img img.reshape qtimg.height pixels_per_line img img[ qtimg.width ]if bytes_per_pixel 4 and not qtimg.hasAlphaChannel img img[ 2 -1 ]elif bytes_per_pixel 4 img[ 0 3] img[ 2 -1 ]return img
def create_txt_response name txt_records return dns.rrset.from_text_list name 60 'IN' 'TXT' txt_records
def preprocess_on_cluster sff_fps log_fp fasta_fp None out_fp '/tmp/' squeeze False verbose False primer STANDARD_BACTERIAL_PRIMER cmd 'denoiser_preprocess.py-i%s-l%s-o%s' % ' '.join sff_fps log_fp out_fp if fasta_fp cmd + '-f%s' % fasta_fp if squeeze cmd + '-s'if verbose cmd + '-v'if primer cmd + '-p%s' % primer submit_jobs [cmd] 'pp_' + make_tmp_name 6 wait_for_file out_fp + '/prefix_mapping.txt' 10
def assertUndefinedComparison testCase s1 s2 testCase.assertFalse s1 s2 testCase.assertFalse s1 < s2 testCase.assertFalse s1 < s2 testCase.assertFalse s1 > s2 testCase.assertFalse s1 > s2
def organisation_needs_skill s3.prep lambda r r.method 'options' and r.representation 's3json' return s3_rest_controller
@salt.utils.decorators.depends 'time' fallback_function _fallbackfunc def depends_will_not_fallback ret {'ret' True 'time' time.time }return ret
def JoinPath stem '' *parts parts [SmartUnicode path for path in parts]result stem + NormalizePath u'/'.join parts .replace '//' '/' result result.rstrip '/' return result or '/'
def qualname_func _blah pass
def crc string return '%08x' % binascii.crc32 string.encode 'utf-8' & 4294967295
def _jinja_env loader jinja2.PackageLoader 'cubes' 'templates' env jinja2.Environment loader loader return env
def unique_id token_id return cms.cms_hash_token token_id
def retry_facebook_invite modeladmin request queryset invites list queryset user_invites defaultdict list for invite in invites user_invites[invite.user].append invite for user invites in user_invites.items profile get_profile user graph profile.get_offline_graph if not graph error_message 'couldntconnecttothegraph useraccesstokenis%s' % profile.access_token messages.error request error_message continuelogger.info 'gotgraph%sforuser%s retrying%sinvites' graph user len invites for invite in invites invite_result invite.resend graph message 'User%ssentattempttosentwithid%ss6is%s' % user invite_result.wallpost_id not invite_result.error if invite_result.error message + 'goterror%s' % invite_result.error_message messages.info request message profile.update_invite_denormalizations profile.save
def get_default_domain request get_name True domain_id request.session.get 'domain_context' None domain_name request.session.get 'domain_context_name' None if VERSIONS.active > 3 and domain_id is None domain_id request.user.user_domain_iddomain_name request.user.user_domain_nameif get_name and not request.user.is_federated try domain domain_get request domain_id domain_name domain.nameexcept exceptions.NotAuthorized LOG.debug 'Cannotretrievedomaininformationforuser %s thatdoesnothaveanadminroleonproject %s ' % request.user.username request.user.project_name except Exception LOG.warning 'UnabletoretrieveDomain %s' % domain_id domain base.APIDictWrapper {'id' domain_id 'name' domain_name} return domain
def _print_baremetal_nodes_list nodes def _parse_address fields macs []for interface in fields.interfaces macs.append interface['address'] return ' '.join '%s' % i for i in macs formatters {'MACAddress' _parse_address}_translate_baremetal_node_keys nodes utils.print_list nodes ['ID' 'Host' 'TaskState' 'CPUs' 'Memory_MB' 'Disk_GB' 'MACAddress' 'PMAddress' 'PMUsername' 'PMPassword' 'TerminalPort'] formatters formatters
def _time_from_json value field if _not_null value field return _time_from_iso8601_time_naive value
def flagsmaildir2imap maildirflaglist retval []for imapflag maildirflag in flagmap if maildirflag in maildirflaglist retval.append imapflag return ' ' + ''.join sorted retval + ' '
def _load_coverage F header_length 6 dtype np.int16 header [F.readline for i in range header_length ]make_tuple lambda t t.split [0] float t.split [1] header dict [make_tuple line for line in header] M np.loadtxt F dtype dtype nodata int header['NODATA_value'] if nodata ! -9999 M[nodata] -9999 return M
def loopbackUNIX server client noisy True path tempfile.mktemp from twisted.internet import reactorf policies.WrappingFactory protocol.Factory serverWrapper _FireOnClose f server f.noisy noisyf.buildProtocol lambda addr serverWrapper serverPort reactor.listenUNIX path f clientF LoopbackClientFactory client clientF.noisy noisyreactor.connectUNIX path clientF d clientF.deferredd.addCallback lambda x serverWrapper.deferred d.addCallback lambda x serverPort.stopListening return d
def get_user_diff ipa_user module_user result []sshpubkey Noneif 'ipasshpubkey' in module_user module_user['sshpubkeyfp'] [get_ssh_key_fingerprint pubkey for pubkey in module_user['ipasshpubkey']]sshpubkey module_user['ipasshpubkey']del module_user['ipasshpubkey']for key in module_user.keys mod_value module_user.get key None ipa_value ipa_user.get key None if isinstance ipa_value list and not isinstance mod_value list mod_value [mod_value]if isinstance ipa_value list and isinstance mod_value list mod_value sorted mod_value ipa_value sorted ipa_value if mod_value ! ipa_value result.append key if sshpubkey is not None del module_user['sshpubkeyfp']module_user['ipasshpubkey'] sshpubkeyreturn result
def getRandomComplex begin end endMinusBegin end - begin return begin + complex random.random * endMinusBegin.real random.random * endMinusBegin.imag
def diff_encode line transform coords [transform x y for x y in line.coords]pairs zip coords[ ] coords[1 ] diffs [ x2 - x1 y2 - y1 for x1 y1 x2 y2 in pairs]return coords[ 1] + [ x y for x y in diffs if x y ! 0 0 ]
def chunked iterable n iterable iter iterable while 1 t tuple islice iterable n if t yield t else return
def update_parent_status doc if doc.communication_type ! u'Communication' returnparent doc.get_parent_doc if not parent returnstatus_field parent.meta.get_field u'status' if status_field options status_field.options or u'' .splitlines if u'Replied' in options to_status u'Open' if doc.sent_or_received u'Received' else u'Replied' if to_status in options parent.db_set u'status' to_status update_mins_to_first_communication parent doc parent.run_method u'notify_communication' doc parent.notify_update
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def edge_betweenness_centrality_subset G sources targets normalized False weight None b dict.fromkeys G 0.0 b.update dict.fromkeys G.edges 0.0 for s in sources if weight is None S P sigma shortest_path G s else S P sigma dijkstra G s weight b _accumulate_edges_subset b S P sigma s targets for n in G del b[n]b _rescale_e b len G normalized normalized directed G.is_directed return b
def is_known_type item return isinstance item MaskedArray or get_type_string item is not None
def modify_cache_cluster name wait 600 security_groups None region None key None keyid None profile None **args if security_groups if not isinstance security_groups list security_groups [security_groups]sgs __salt__['boto_secgroup.convert_to_group_ids'] groups security_groups region region key key keyid keyid profile profile if 'SecurityGroupIds' not in args args['SecurityGroupIds'] []args['SecurityGroupIds'] + sgsargs dict [ k v for k v in args.items if not k.startswith '_' ] return _modify_resource name name_param 'CacheClusterId' desc 'cachecluster' res_type 'cache_cluster' wait wait status_param 'CacheClusterStatus' region region key key keyid keyid profile profile **args
def pythonize_path path return path.replace '/' '.'
def ClusterController *args **kwargs controller Controller *args **kwargs Intf 'eth0' node controller .updateIP return controller
def _getAccessibleAttribute attributeName if attributeName in globalAccessibleAttributeDictionary return globalAccessibleAttributeDictionary[attributeName]return None
def to_bool input default False if input is None value defaultelse int_value to_int input default None if int_value is None value defaultelse value bool int_value return value
def register_cmap name None cmap None data None lut None if name is None try name cmap.nameexcept AttributeError raise ValueError u'ArgumentsmustincludeanameoraColormap' if not cbook.is_string_like name raise ValueError u'Colormapnamemustbeastring' if isinstance cmap colors.Colormap cmap_d[name] cmapreturnif lut is None lut mpl.rcParams[u'image.lut']cmap colors.LinearSegmentedColormap name data lut cmap_d[name] cmap
def quarter_plot x dates None ylabel None ax None from pandas import DataFrameif dates is None from statsmodels.tools.data import _check_period_index_check_period_index x freq 'Q' else from pandas import Series PeriodIndexx Series x index PeriodIndex dates freq 'Q' xticklabels ['q1' 'q2' 'q3' 'q4']return seasonal_plot x.groupby lambda y y.quarter xticklabels ylabel ylabel ax ax
def _cache_lockfuncs global _LOCKFUNCS_LOCKFUNCS {}for modulepath in settings.LOCK_FUNC_MODULES _LOCKFUNCS.update utils.callables_from_module modulepath
def arma_impulse_response ar ma nobs 100 impulse np.zeros nobs impulse[0] 1.0return signal.lfilter ma ar impulse
def valid_subscribe_topic value invalid_chars '\x00' if isinstance value str and all c not in value for c in invalid_chars return vol.Length min 1 max 65535 value raise vol.Invalid 'InvalidMQTTtopicname'
@track_state_change device_tracker.ENTITY_ID_ALL_DEVICES def track_devices hass entity_id old_state new_state if not TARGET_ID returnif new_state.state STATE_HOME and not core.is_on hass TARGET_ID core.turn_on hass TARGET_ID elif new_state.state STATE_NOT_HOME and core.is_on hass TARGET_ID core.turn_off hass TARGET_ID
@testing.requires_testing_data@requires_freesurfer@requires_nibabel def test_read_volume_from_src aseg_fname op.join subjects_dir 'sample' 'mri' 'aseg.mgz' labels_vol ['Left-Amygdala' 'Brain-Stem' 'Right-Amygdala']src read_source_spaces fname vol_src setup_volume_source_space 'sample' mri aseg_fname pos 5.0 bem fname_bem volume_label labels_vol subjects_dir subjects_dir src + vol_srcvolume_src get_volume_labels_from_src src 'sample' subjects_dir volume_label volume_src[0].namevolume_label 'Left-' + volume_label.replace '-lh' '' assert_equal volume_label src[2]['seg_name'] assert_equal src[2]['type'] 'vol'
def mssql_old_passwd password salt uppercase True binsalt hexdecode salt unistr ''.join map lambda c '%s\x00' if ord c < 256 else '%s' % utf8encode c password retVal '0100%s%s%s' % salt sha1 unistr + binsalt .hexdigest sha1 unistr.upper + binsalt .hexdigest return '0x%s' % retVal.upper if uppercase else retVal.lower
def _make_masked_array data mask if len data return ma.array np.array data mask np.array mask dtype u'bool' else return ma.array np.array data
def is_image_sharable context image **kwargs if context.is_admin return Trueif context.owner is None return Falseif context.owner image['owner'] return Trueif 'membership' in kwargs member kwargs['membership']if member is None return Falseelse members image_member_find context image_id image['id'] member context.owner if members member members[0]else return Falsereturn member['can_share']
def get_token host port headers auth_data url api_url host port '/Users/AuthenticateByName' r requests.post url headers headers data auth_data return r.json .get 'AccessToken'
def in6_getifaddr ret []i dnet.intf for int in i ifname int['name']v6 []if int.has_key 'alias_addrs' v6 int['alias_addrs']for a in v6 if a.type ! dnet.ADDR_TYPE_IP6 continuexx str a .split '/' [0]addr scapy.utils6.in6_ptop xx scope scapy.utils6.in6_getscope addr ret.append xx scope ifname return ret
def twinx ax None if ax is None ax gca ax1 ax.twinx draw_if_interactive return ax1
def maybe_s_to_ms v return int float v * 1000.0 if v is not None else v
def stringc text color if ANSIBLE_COLOR return '\n'.join [ u'\x1b[%sm%s\x1b[0m' % codeCodes[color] t for t in text.split '\n' ] else return text
def timestampID db table t intTime 1000 while db.scalar 'selectidfrom%swhereid ?' % table t t + 1return t
def _get_terminal_size_tput try cols int subprocess.check_call shlex.split 'tputcols' rows int subprocess.check_call shlex.split 'tputlines' return cols rows except pass
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
@pytest.fixture scope 'function' def httpbin_secure_untrusted monkeypatch httpbin_secure monkeypatch.delenv 'REQUESTS_CA_BUNDLE' return httpbin_secure
@commands u'link' @example u'.linkhttp //example.com' def meetinglink bot trigger if not ismeetingrunning trigger.sender bot.say u"Can'tdothat startmeetingfirst" returnif not trigger.group 2 bot.say u'try.actionsomeonewilldosomething' returnif not ischair trigger.nick trigger.sender bot.say u'Onlymeetingheadorchairscandothat' returnlink trigger.group 2 if not link.startswith u'http' link u'http //' + link try title find_title link verify bot.config.core.verify_ssl except title u''logplain u'LINK %s[%s]' % link title trigger.sender logHTML_listitem u'<ahref "%s">%s</a>' % link title trigger.sender bot.say u'\x02LINK\x0f ' + link
def is_instance obj klass return issubclass type obj klass
def is_ubuntu if sys.platform.startswith 'linux' and osp.isfile '/etc/lsb-release' release_info open '/etc/lsb-release' .read if 'Ubuntu' in release_info return Trueelse return Falseelse return False
def NetshStaticIp interface ip u'127.0.0.9' subnet u'255.255.255.255' gw u'127.0.0.1' args ['/c' 'netsh' 'interface' 'ip' 'set' 'address' interface 'static' ip subnet gw '1']res client_utils_common.Execute 'cmd' args time_limit -1 bypass_whitelist True return res
def signal signal None valid_signals {'forcestop' 'stop-force' 'securestart' 'start-security' 'start' 'start' 'stop' 'stop'}if signal not in valid_signals returncmd '{0}/bin/catalina.sh{1}'.format __catalina_home valid_signals[signal] __salt__['cmd.run'] cmd
def as_int n try result int n if result ! n raise TypeErrorexcept TypeError raise ValueError '%sisnotaninteger' % n return result
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def default_export_transform value if value is None return u''else return unicode value
def write_pnm file width height pixels meta bitdepth meta['bitdepth']maxval 2 ** bitdepth - 1 planes meta['planes']assert planes in 1 2 3 4 if planes in 1 3 if 1 planes fmt 'P5'else fmt 'P6'file.write '%s%d%d%d\n' % fmt width height maxval if planes in 2 4 if 2 planes tupltype 'GRAYSCALE_ALPHA'else tupltype 'RGB_ALPHA'file.write 'P7\nWIDTH%d\nHEIGHT%d\nDEPTH%d\nMAXVAL%d\nTUPLTYPE%s\nENDHDR\n' % width height planes maxval tupltype vpr planes * width fmt '>%d' % vpr if maxval > 255 fmt fmt + 'H' else fmt fmt + 'B' for row in pixels file.write struct.pack fmt *row file.flush
def list_unsubscribe t owner slug get_slug try t.lists.subscribers.destroy slug slug owner_screen_name owner printNicely green 'Done.' except debug_option printNicely light_magenta "I'msorryyoucannotunsubscribetothislist."
@click.command 'download-translations' def download_translations from bench.utils import download_translations_pdownload_translations_p
def get_ips linode_id None if linode_id ips _query 'linode' 'ip.list' args {'LinodeID' linode_id} else ips _query 'linode' 'ip.list' ips ips['DATA']ret {}for item in ips node_id str item['LINODEID'] if item['ISPUBLIC'] 1 key 'public_ips'else key 'private_ips'if ret.get node_id is None ret.update {node_id {'public_ips' [] 'private_ips' []}} ret[node_id][key].append item['IPADDRESS'] if linode_id _all_ips {'public_ips' [] 'private_ips' []}matching_id ret.get str linode_id if matching_id _all_ips['private_ips'] matching_id['private_ips']_all_ips['public_ips'] matching_id['public_ips']ret _all_ipsreturn ret
def get_tests_modules basepath this_dir_path gui True packages None py_ext '.py'for dirpath dirnames filenames in os.walk basepath for dirname in list dirnames if dirname[0] '.' dirnames.remove dirname if is_package dirpath and filenames pkg_name dirpath[ len basepath + len os.sep ].replace '/' '.' if packages and pkg_name not in packages continuefilenames filter lambda x x.startswith 'test_' and x.endswith py_ext filenames for name in filenames try yield importlib.import_module '.%s.%s' % pkg_name name[ - len py_ext ] 'tkinter.test' except test.support.ResourceDenied if gui raise
def y1p_zeros nt complex False if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'Argumentsmustbescalarpositiveinteger.' kf 2kc not complex return specfun.cyzo nt kf kc
def find_candidates_in_parent_dirs filenames path candidates [filename for filename in filenames if os.path.exists os.path.join path filename ]if not candidates parent_dir os.path.join path u'..' if os.path.abspath parent_dir ! os.path.abspath path return find_candidates_in_parent_dirs filenames parent_dir return candidates path
def get_year_and_month_format locale return locale_year_and_month_formats.get locale.language.lower u'MMMy'
def _activities_about_user_query user_id import ckan.model as modelq model.Session.query model.Activity q q.filter model.Activity.object_id user_id return q
def _execute_tasks tasks batch_size 24 remaining_tasks [] + tasks currently_running_tasks set [] while remaining_tasks or currently_running_tasks if currently_running_tasks for task in list currently_running_tasks task.join 1 if not task.isAlive currently_running_tasks.remove task while remaining_tasks and len currently_running_tasks < batch_size task remaining_tasks.pop currently_running_tasks.add task task.start task.start_time time.time time.sleep 5 if remaining_tasks log '----------------------------------------' log 'Numberofunstartedtasks %s' % len remaining_tasks _check_all_tasks tasks log '----------------------------------------'
@treeio_login_required@handle_response_format@_process_mass_formdef index request response_format 'html' if request.GET filters FilterForm request.GET if filters.is_valid query _get_filter_query request.GET else query Q else query Q filters FilterForm events Object.filter_by_request request Event.objects.filter query context _get_default_context request context.update {'events' events 'filters' filters} return render_to_response 'events/index' context context_instance RequestContext request response_format response_format
def mean input labels None index None count sum _stats input labels index return sum / numpy.asanyarray count .astype numpy.float
def _get_oauth2_client_id_and_secret settings_instance secret_json getattr settings_instance 'GOOGLE_OAUTH2_CLIENT_SECRETS_JSON' None if secret_json is not None return _load_client_secrets secret_json else client_id getattr settings_instance 'GOOGLE_OAUTH2_CLIENT_ID' None client_secret getattr settings_instance 'GOOGLE_OAUTH2_CLIENT_SECRET' None if client_id is not None and client_secret is not None return client_id client_secret else raise exceptions.ImproperlyConfigured 'MustspecifyeitherGOOGLE_OAUTH2_CLIENT_SECRETS_JSON orbothGOOGLE_OAUTH2_CLIENT_IDandGOOGLE_OAUTH2_CLIENT_SECRETinsettings.py'
def withparent meth def wrapped self *args **kwargs res meth self *args **kwargs if getattr self 'parent' None is not None getattr self.parent meth.__name__ *args **kwargs return reswrapped.__name__ meth.__name__return wrapped
def generate_presigned_post self Bucket Key Fields None Conditions None ExpiresIn 3600 bucket Bucketkey Keyfields Fieldsconditions Conditionsexpires_in ExpiresInif fields is None fields {}if conditions is None conditions []post_presigner S3PostPresigner self._request_signer serializer self._serializeroperation_model self.meta.service_model.operation_model 'CreateBucket' request_dict serializer.serialize_to_request {'Bucket' bucket} operation_model prepare_request_dict request_dict endpoint_url self.meta.endpoint_url conditions.append {'bucket' bucket} if key.endswith '${filename}' conditions.append ['starts-with' '$key' key[ - len '${filename}' ]] else conditions.append {'key' key} fields['key'] keyreturn post_presigner.generate_presigned_post request_dict request_dict fields fields conditions conditions expires_in expires_in
def get_first_id lines result set for line in lines if line.startswith '>' result.add line[1 ].split [0] return result
@utils.arg '--hypervisor' metavar '<hypervisor>' default None help _ 'Typeofhypervisor.' def do_agent_list cs args result cs.agents.list args.hypervisor columns ['Agent_id' 'Hypervisor' 'OS' 'Architecture' 'Version' 'Md5hash' 'Url']utils.print_list result columns
def prox_l1 Y alpha n_orient n_positions Y.shape[0] // n_orient norms np.sqrt Y * Y.conj .real.T.reshape -1 n_orient .sum axis 1 shrink np.maximum 1.0 - alpha / np.maximum norms alpha 0.0 shrink shrink.reshape -1 n_positions .Tactive_set np.any shrink > 0.0 axis 1 shrink shrink[active_set]if n_orient > 1 active_set np.tile active_set[ None] [1 n_orient] .ravel Y Y[active_set]if len Y > 0 for o in range n_orient Y[o n_orient] * shrinkreturn Y active_set
def serializeTransform transformObj return ''.join [ command + ' ' + ''.join [scourUnitlessLength number for number in numbers] + ' ' for command numbers in transformObj]
def test_constructed_module ModuleType type sys TopModule ModuleType 'TopModule' sys.modules['TopModule'] TopModuleSubModule ModuleType 'SubModule' SubModule.Object object TopModule.SubModule SubModuletry import TopModule.SubModuleAssertUnreachable except ImportError passdel sys.modules['TopModule']
def gammamomentcond distfn params mom2 quantile None def cond params alpha scale paramsmom2s distfn.stats alpha 0.0 scale return np.array mom2 - mom2s return cond
def _default_locale_fallback request document_slug document_locale fallback_doc Noneredirect_url Nonefallback_reason Nonetry fallback_doc Document.objects.get locale settings.WIKI_DEFAULT_LANGUAGE slug document_slug translation fallback_doc.translated_to document_locale if translation and translation.current_revision url translation.get_absolute_url redirect_url urlparams url query_dict request.GET elif translation and fallback_doc.current_revision fallback_reason 'translation_not_approved'elif fallback_doc.current_revision fallback_reason 'no_translation'except Document.DoesNotExist passreturn fallback_doc fallback_reason redirect_url
def allow_unvouched function _set_attribute_func function '_allow_unvouched' True return function
def IsBlankLine line return not line or line.isspace
def send_process return s3db.inv_send_process
def network_create request **kwargs LOG.debug 'network_create kwargs %s' % kwargs body {'network' kwargs}network quantumclient request .create_network body body .get 'network' return Network network
def cityblock u v u _validate_vector u v _validate_vector v return abs u - v .sum
def SampleSum dists n pmf Pmf RandomSum dists for i in range n return pmf
def textile value try import textileexcept ImportError warnings.warn "ThePythontextilelibraryisn'tinstalled." RuntimeWarning return valuereturn textile.textile force_text value encoding 'utf-8' output 'utf-8'
def window_by_index idx if not window_registry raise NoWindow else key sorted window_registry [idx]return window_registry[key]
def _get_email_config intent require_valid_intent intent return config_domain.Registry.get_config_property feconf.VALID_MODERATOR_ACTIONS[intent]['email_config']
def sum_squares expr return quad_over_lin expr 1
def get_warning_statistics return get_statistics 'W'
def get_from_identity session key passive instance session.identity_map.get key if instance is not None state attributes.instance_state instance if state.expired if not passive & attributes.SQL_OK return attributes.PASSIVE_NO_RESULTelif not passive & attributes.RELATED_OBJECT_OK return instancetry state._load_expired state passive except orm_exc.ObjectDeletedError session._remove_newly_deleted [state] return Nonereturn instanceelse return None
def p_empty t pass
def build_graph ifilenames graph num_threads 1 tags False if tags eat graph.consume_fasta_and_tag_with_reads_parserelse eat graph.consume_fasta_with_reads_parserfor _ ifile in enumerate ifilenames rparser khmer.ReadParser ifile threads []for _ in range num_threads cur_thread threading.Thread target eat args rparser threads.append cur_thread cur_thread.start for thread in threads thread.join
def assert_all_finite X _assert_all_finite X.data if sp.issparse X else X
def get_course_and_check_access course_key user depth 0 if not has_studio_read_access user course_key raise PermissionDenied course_module modulestore .get_course course_key depth depth return course_module
@FileSystem.in_directory current_directory 'django' 'grocery' def test_django_admin_media_serving_on_django_125 os.environ['PYTHONPATH'] '%s %s' % FileSystem.join lib_directory 'Django-1.2.5' OLD_PYTHONPATH status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 2./features/' assert_equals status 0 out lines out.splitlines f '\n\n'f + '*' * 100 f + '\n' + '\n'.join lines assert u"Preparingtoservedjango'sadminsitestaticfiles..." in lines fassert u"Django'sbuiltinserverisrunningat0.0.0.0 7000" in lines fassert u'Runningonport7000...OK' in lines fassert u'Fetchingadminmedia...OK' in lines fassert u'Fetchingstaticfiles...OK' in lines fassert u'FetchingCSSfiles ...OK' in lines fassert u'Fetchingjavascriptfiles ...OK' in lines f
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def generate_fake_facility_groups names 'Class4E' 'Class5B' facilities None if not facilities facilities generate_fake_facilities facility_groups []for facility in facilities for name in names found_facility_groups FacilityGroup.objects.filter facility facility name name if found_facility_groups facility_group found_facility_groups[0]logging.info "Retrievedfacilitygroup'%s'" % name else facility_group FacilityGroup facility facility name name facility_group.save logging.info "Createdfacilitygroup'%s'" % name facility_groups.append facility_group return facility_groups facilities
def backwards_move_org_source apps schema_editor RemoteOrganization apps.get_model u'oauth' u'RemoteOrganization' SocialAccount apps.get_model u'socialaccount' u'SocialAccount' for account in SocialAccount.objects.all rows account.remote_organizations.update account None source account.provider
def parse_startup pkt values []plen endian_int pkt[0 4] pkt pkt[8 ]tmp ''for i in xrange plen - 8 tmp + pkt[i].decode 'hex' if pkt[i] '00' values.append tmp tmp ''return values
def getIsPathEntirelyOutsideTriangle begin center end vector3Path loop [begin.dropAxis center.dropAxis end.dropAxis ]for vector3 in vector3Path point vector3.dropAxis if euclidean.isPointInsideLoop loop point return Falsereturn True
def mapping data_source geom_name 'geom' layer_key 0 multi_geom False if isinstance data_source str data_source DataSource data_source elif isinstance data_source DataSource passelse raise TypeError 'DatasourceparametermustbeastringoraDataSourceobject.' _mapping {}for field in data_source[layer_key].fields mfield field.lower if mfield[ -1 ] '_' mfield + 'field'_mapping[mfield] fieldgtype data_source[layer_key].geom_typeif multi_geom gtype.to_multi _mapping[geom_name] str gtype .upper return _mapping
def test_replace_long_type replaced replace_hy_obj long_type 0 HyInteger 13 assert replaced HyInteger 0
def isAddedPointOnPathIntersectingPath begin path point pointIndex segment point - begin segmentLength abs segment if segmentLength < 0.0 return FalsenormalizedSegment segment / segmentLength segmentYMirror complex normalizedSegment.real - normalizedSegment.imag pointRotated segmentYMirror * point beginRotated segmentYMirror * begin if euclidean.isXSegmentIntersectingPath path[max 0 pointIndex - 20 pointIndex] pointRotated.real beginRotated.real segmentYMirror pointRotated.imag return Truereturn euclidean.isXSegmentIntersectingPath path[ pointIndex + 1 pointIndex + 21 ] pointRotated.real beginRotated.real segmentYMirror pointRotated.imag
def getDebugging return Deferred.debug
def GetTypeChecker field if field.cpp_type _FieldDescriptor.CPPTYPE_STRING and field.type _FieldDescriptor.TYPE_STRING return UnicodeValueChecker if field.cpp_type _FieldDescriptor.CPPTYPE_ENUM return EnumValueChecker field.enum_type return _VALUE_CHECKERS[field.cpp_type]
def update_named_ports mig named_ports changed Falseexisting_ports []new_ports []if hasattr mig.instance_group 'named_ports' existing_ports sorted mig.instance_group.named_ports key lambda x x['name'] if named_ports is not None new_ports sorted named_ports key lambda x x['name'] if existing_ports ! new_ports if mig.instance_group.set_named_ports named_ports changed Truereturn changed
def cleanPolygon elem options global numPointsRemovedFromPolygonpts parseListOfPoints elem.getAttribute 'points' N len pts / 2 if N > 2 startx starty pts[ 2] endx endy pts[ -2 ]if startx endx and starty endy del pts[ -2 ]numPointsRemovedFromPolygon + 1elem.setAttribute 'points' scourCoordinates pts options True
def umask use_sudo False func use_sudo and run_as_root or run return func 'umask'
def _get_comment_and_context request comment_id try cc_comment Comment id comment_id .retrieve _ context _get_thread_and_context request cc_comment['thread_id'] return cc_comment context except CommentClientRequestError raise CommentNotFoundError 'Commentnotfound.'
def mock_software_secure_post_error url headers None data None **kwargs response requests.Response response.status_code 400return response
def str_decode arr encoding errors 'strict' if encoding in _cpython_optimized_decoders f lambda x x.decode encoding errors else decoder codecs.getdecoder encoding f lambda x decoder x errors [0] return _na_map f arr
def makeExtension *args **kwargs return SuperFencesCodeExtension *args **kwargs
def fix_headers soup data header_rows soup.find_all 'th' for t in header_rows if 'Version ' in t.text if t.next_sibling.text '$Revision$' t.parent.extract if t.next_sibling.text '' t.parent.extract if 'Last-Modified ' in t.text if '$Date$' in t.next_sibling.text t.parent.extract if t.next_sibling.text '' t.parent.extract if t.text 'Title ' data['title'] t.next_sibling.textif t.text 'Content-Type ' t.parent.extract if 'Version ' in t.text and 'N/A' in t.next_sibling.text t.parent.extract return soup data
def get_configuration_url name urls configuration_helpers.get_value 'urls' default {} return urls.get name or EMPTY_URL
@conference_signals.osf4m_user_created.connectdef queue_osf4m_welcome_email user conference node root node.get_addon 'osfstorage' .get_root root_children [child for child in root.children if child.is_file]mails.queue_mail to_addr user.username mail mails.WELCOME_OSF4M send_at timezone.now + settings.WELCOME_OSF4M_WAIT_TIME user user conference conference.name fullname user.fullname fid root_children[0]._id if len root_children else None
def split filenames format_string shards parsed_formats parser.parse format_string sizes [files.stat filename .st_size for filename in filenames]size_per_shard float sum sizes / shards if not size_per_shard returnif parsed_formats[0].can_split return _deep_split filenames size_per_shard parsed_formats else return _shallow_split filenames size_per_shard parsed_formats sizes
def _getargs func import typesif sys.version_info > 3 0 if isinstance func types.MethodType func func.__func__co func.__code__else if isinstance func types.MethodType func func.im_funcco func.func_codereturn co.co_varnames[ co.co_argcount]
def outputRedirectStart errToOut False global STDOUT_TEMPglobal STDERR_TEMPSTDOUT_TEMP open 'ip_session.log' 'w' sys.stdout STDOUT_TEMPif errToOut STDERR_TEMP STDOUT_TEMPelse STDERR_TEMP open 'ip_session_stderr.log' 'w' sys.stderr STDERR_TEMP
def no_dipy global HAVE_DIPYreturn not HAVE_DIPY
def test_assumptions m n symbols 'mn' integer True positive True diof diophantine n ** 2 + m * n - 500 assert diof set [ 5 20 40 10 95 5 121 4 248 2 499 1 ] a b symbols 'ab' integer True positive False diof diophantine a * b + 2 * a + 3 * b - 6 assert diof set [ -15 -3 -9 -4 -7 -5 -6 -6 -5 -8 -4 -14 ]
def get_maintenance if not database return Nonemaintenance_state database.maintenance.find_one {'maintenance' True} if maintenance_state return {'start' maintenance_state.get 'start' 'end' maintenance_state.get 'end' }else return None
def _hasSubstring key text escapedKey re.escape key return bool re.search '\\W' + escapedKey + '\\W' text
def convert_tokens tokens if tokens 'None' return Noneelif isinstance tokens basestring or not isinstance tokens collections.Iterable return tokenselif isinstance tokens dict return {convert_tokens k convert_tokens v for k v in tokens.items }else return [convert_tokens v for v in tokens]
def _should_send_email self try return self.get_profile .should_send_emailexcept Profile.DoesNotExist return True
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def textile value try import textileexcept ImportError warnings.warn "ThePythontextilelibraryisn'tinstalled." RuntimeWarning return valuereturn textile.textile force_text value encoding 'utf-8' output 'utf-8'
@tf.RegisterGradient 'VariableLSTM' def _variable_lstm_grad op act_grad gate_grad mem_grad initial_state op.inputs[1]initial_memory op.inputs[2]w_m_m op.inputs[3]act op.outputs[0]gate_raw_act op.outputs[1]memory op.outputs[2]return rnn.variable_lstm_grad initial_state initial_memory w_m_m act gate_raw_act memory act_grad gate_grad mem_grad
def demultiplex_sequences file_data keep_barcode False barcode_type 'golay_12' max_bc_errors 1.5 start_index 1 write_unassigned_reads False disable_bc_correction False added_demultiplex_field None header mapping_data check_map file_data['mapping_file'] barcode_type added_demultiplex_field ids_bcs_added_field get_ids_bcs_added_field header mapping_data barcode_type added_demultiplex_field bc_lens get_bc_lens ids_bcs_added_field all_bcs [curr_bc[0] for curr_bc in ids_bcs_added_field.keys ] log_data bc_freqs seq_counts corrected_bc_count assign_seqs file_data ids_bcs_added_field bc_lens all_bcs keep_barcode barcode_type max_bc_errors start_index write_unassigned_reads disable_bc_correction added_demultiplex_field return log_data bc_freqs seq_counts corrected_bc_count
def user_home request return shortcuts.redirect horizon.get_user_home request.user
def suiteVisit suite visitor warnings.warn 'TestvisitorsdeprecatedinTwisted8.0' category DeprecationWarning for case in suite._tests visit getattr case 'visit' None if visit is not None visit visitor elif isinstance case pyunit.TestCase case itrial.ITestCase case case.visit visitor elif isinstance case pyunit.TestSuite suiteVisit case visitor else case.visit visitor
def get_public_modules path base_package None result []for subdir _ files in os.walk path if any [part.startswith '_' for part in subdir.split os.path.sep ] continue _ rel_dir subdir.split path rel_dir rel_dir.lstrip os.path.sep for filename in files if is_valid_module filename mod_name _ os.path.splitext filename rel_path os.path.join rel_dir mod_name if base_package is not None rel_path os.path.join base_package rel_path rel_path rel_path.replace os.path.sep '.' if mod_name '__init__' result.append rel_path[ - len '.__init__' ] else result.append rel_path return result
def QueryValueEx key value_name regqueryvalueex advapi32['RegQueryValueExW']regqueryvalueex.restype ctypes.c_longregqueryvalueex.argtypes [ctypes.c_void_p ctypes.c_wchar_p LPDWORD LPDWORD LPBYTE LPDWORD]size 256data_type ctypes.wintypes.DWORD while True tmp_size ctypes.wintypes.DWORD size buf ctypes.create_string_buffer size rc regqueryvalueex key.handle value_name LPDWORD ctypes.byref data_type ctypes.cast buf LPBYTE ctypes.byref tmp_size if rc ! ERROR_MORE_DATA breakif size > 10 * 1024 * 1024 raise exceptions.WindowsError 'ValuetoobigtobereadbyGRR.' size * 2if rc ! ERROR_SUCCESS raise ctypes.WinError 2 return Reg2Py buf tmp_size.value data_type.value data_type.value
def get_testfile_path name return os.path.join os.path.dirname os.path.realpath __file__ name
def denoise_nl_means image patch_size 7 patch_distance 11 h 0.1 multichannel None fast_mode True if multichannel is None warn 'denoise_nl_meanswilldefaulttomultichannel Falseinv0.15' multichannel Trueif image.ndim 2 image image[... np.newaxis]multichannel Trueif image.ndim ! 3 raise NotImplementedError 'Non-localmeansdenoisingisonlyimplementedfor2DgrayscaleandRGBimagesor3-Dgrayscaleimages.' if multichannel if fast_mode return np.squeeze np.array _fast_nl_means_denoising_2d image patch_size patch_distance h else return np.squeeze np.array _nl_means_denoising_2d image patch_size patch_distance h elif fast_mode return np.array _fast_nl_means_denoising_3d image s patch_size d patch_distance h h else return np.array _nl_means_denoising_3d image patch_size patch_distance h
def default_serialize_error req resp exception representation Nonepreferred req.client_prefers 'application/xml' 'text/xml' 'application/json' if preferred is None accept req.accept.lower if '+json' in accept preferred 'application/json'elif '+xml' in accept preferred 'application/xml'if preferred is not None if preferred 'application/json' representation exception.to_json else representation exception.to_xml resp.body representationresp.content_type preferred + ';charset UTF-8' resp.append_header 'Vary' 'Accept'
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_reset_network cs args _find_server cs args.server .reset_network
def get_theme_dirs themes_dir None return [_dir for _dir in os.listdir themes_dir if is_theme_dir themes_dir / _dir ]
@register.tag 'get_current_timezone' def get_current_timezone_tag parser token args token.contents.split if len args ! 3 or args[1] ! 'as' raise TemplateSyntaxError "'get_current_timezone'requires'asvariable' got%r " % args return GetCurrentTimezoneNode args[2]
def create_eq lh_op rh_op None constr_id None if constr_id is None constr_id get_id expr get_constr_expr lh_op rh_op return LinEqConstr expr constr_id lh_op.size
@socketio.on 'connect' namespace '/home' def on_connect_home pass
def is_isomorphic T1 T2 T1 np.asarray T1 order 'c' T2 np.asarray T2 order 'c' if type T1 ! np.ndarray raise TypeError 'T1mustbeanumpyarray.' if type T2 ! np.ndarray raise TypeError 'T2mustbeanumpyarray.' T1S T1.shapeT2S T2.shapeif len T1S ! 1 raise ValueError 'T1mustbeone-dimensional.' if len T2S ! 1 raise ValueError 'T2mustbeone-dimensional.' if T1S[0] ! T2S[0] raise ValueError 'T1andT2musthavethesamenumberofelements.' n T1S[0]d1 {}d2 {}for i in xrange 0 n if T1[i] in d1 if not T2[i] in d2 return Falseif d1[T1[i]] ! T2[i] or d2[T2[i]] ! T1[i] return Falseelif T2[i] in d2 return Falseelse d1[T1[i]] T2[i]d2[T2[i]] T1[i]return True
def download_plugin file_ global PLUGIN_EXTENSIONplugins_installed_before set __get_all_plugin_descriptors fileName os.path.join resources.PLUGINS os.path.basename file_ content urlopen file_ f open fileName u'wb' f.write content.read f.close zipFile zipfile.ZipFile fileName u'r' zipFile.extractall resources.PLUGINS zipFile.close os.remove fileName plugins_installed_after set __get_all_plugin_descriptors new_plugin plugins_installed_after - plugins_installed_before .pop return new_plugin
def test_skip_duplicates_by_default testdir a testdir.mkdir 'a' fh a.join 'test_a.py' fh.write _pytest._code.Source '\nimportpytest\ndeftest_real \npass\n' result testdir.runpytest a.strpath a.strpath result.stdout.fnmatch_lines ['*collected1item*']
def quick_sort collection total_elements len collection if total_elements < 1 return collectionless []equal []greater []pivot collection[0]equal.append pivot for i in range 1 total_elements element collection[i]if element < pivot less.append element elif element pivot equal.append element else greater.append element return quick_sort less + equal + quick_sort greater
def test_sobel_h_vertical i j np.mgrid[ -5 6 -5 6]image j > 0 .astype float * np.sqrt 2 result filters.sobel_h image assert_allclose result 0 atol 1e-10
def schema_list dbname db_user None db_password None db_host None db_port None ret {}query ''.join ['SELECTpg_namespace.nspnameas"name" pg_namespace.nspaclas"acl" pg_roles.rolnameas"owner"FROMpg_namespaceLEFTJOINpg_rolesONpg_roles.oid pg_namespace.nspowner'] rows psql_query query host db_host user db_user port db_port maintenance_db dbname password db_password for row in rows retrow {}for key in 'owner' 'acl' retrow[key] row[key]ret[row['name']] retrowreturn ret
def binom_tost count nobs low upp tt1 binom_test count nobs alternative 'larger' prop low tt2 binom_test count nobs alternative 'smaller' prop upp return np.maximum tt1 tt2 tt1 tt2
def k_crust G k None core_number None if core_number is None core_number find_cores G if k is None k max core_number.values - 1 nodes v for v in core_number if core_number[v] < k return G.subgraph nodes .copy
def serialize_object obj if getattr obj 'to_dict' None value obj.to_dict elif getattr obj 'to_serializable_dict' None value obj.to_serializable_dict mask_secrets True else value repr obj return value
def _has_distortion wcs return any getattr wcs dist_attr is not None for dist_attr in [u'cpdis1' u'cpdis2' u'det2im1' u'det2im2' u'sip']
def get_ipython from IPython.core.interactiveshell import InteractiveShellif InteractiveShell.initialized return InteractiveShell.instance
def push_session document session_id None url 'default' app_path '/' io_loop None coords _SessionCoordinates dict session_id session_id url url app_path app_path session ClientSession session_id coords.session_id websocket_url coords.websocket_url io_loop io_loop session.push document return session
@with_setup step_runner_environ def test_ignore_case_on_step_definitions f Feature.from_string FEATURE3 feature_result f.run scenario_result feature_result.scenario_results[0]assert_equals len scenario_result.steps_passed 3 assert_equals scenario_result.total_steps 3 assert all [s.has_definition for s in scenario_result.scenario.steps]
def generic_passthrough_kodi_set results try setting_value results[0]except IndexError setting_value Nonereturn setting_value
def _dup_left_decompose f h K g i {} 0 while f q r dup_div f h K if dup_degree r > 0 return Noneelse g[i] dup_LC r K f i q i + 1 return dup_from_raw_dict g K
def set_security_groups mounttargetid securitygroup keyid None key None profile None region None **kwargs client _get_conn key key keyid keyid profile profile region region client.modify_mount_target_security_groups MountTargetId mounttargetid SecurityGroups securitygroup
def warn msg stacklevel 3 if isinstance msg compat.string_types warnings.warn msg exc.SAWarning stacklevel stacklevel else warnings.warn msg stacklevel stacklevel
def db_replace_record obj if isinstance obj collections.Mapping for k v in six.iteritems obj if isinstance v api.Command obj[k] v.resultelif isinstance obj collections.Sequence and not isinstance obj six.string_types for i v in enumerate obj if isinstance v api.Command try obj[i] v.resultexcept TypeError return type obj getattr v 'result' v for v in obj elif isinstance obj api.Command obj obj.resultreturn obj
def _download_args options return dict version options.version download_base options.download_base downloader_factory options.downloader_factory to_dir options.to_dir
def vmware_path datastore datacenter path path '/folder/%s' % path.lstrip '/' datacenter datacenter.replace '&' '%26' if not path.startswith '/' path '/' + path params dict dsName datastore if datacenter params['dcPath'] datacenterparams urllib.urlencode params return '%s?%s' % path params
def pretty_depth depth np.clip depth 0 2 ** 10 - 1 depth depth >> 2depth depth.astype np.uint8 return depth
def drop_db name **client_args if not db_exists name **client_args log.info "DB'{0}'doesnotexist".format name return Falseclient _client **client_args client.drop_database name return True
def format_binary_sff_as_fna sff_file output_file None qual False if output_file is None output_file StringIO _ reads parse_binary_sff sff_file for read in reads output_file.write format_read_as_fna read qual return output_file
def compute_mul tree neg inputs treeif inputs is None raise AssertionError 'Function`compute_mul`foundamissingleaf didyouforgettocall`simplify_mul`onthetreefirst?' elif isinstance inputs list rval tensor.mul *list map compute_mul inputs else rval inputsif neg rval - rval return rval
def wildcards_overlap name1 name2 if not name1 and not name2 return Trueif not name1 or not name2 return Falsefor matched1 matched2 in _character_matches name1 name2 if wildcards_overlap name1[matched1 ] name2[matched2 ] return Truereturn False
def _mouse_click event params if event.button ! 1 returnif event.inaxes is None if params['n_channels'] > 100 returnax params['ax']ylim ax.get_ylim pos ax.transData.inverted .transform event.x event.y if pos[0] > params['t_start'] or pos[1] < 0 or pos[1] > ylim[0] returnparams['label_click_fun'] pos if event.inaxes params['ax_vscroll'] if 'fig_selection' in params.keys _handle_change_selection event params else ch_start max int event.ydata - params['n_channels'] // 2 0 if params['ch_start'] ! ch_start params['ch_start'] ch_startparams['plot_fun'] elif event.inaxes params['ax_hscroll'] _plot_raw_time event.xdata - params['duration'] / 2 params params['update_fun'] params['plot_fun'] elif event.inaxes params['ax'] params['pick_bads_fun'] event
def user_can_delete_review request review is_editor acl.check_reviewer request is_author review.addon.has_author request.user return review.user_id request.user.id or not is_author and is_editor or acl.action_allowed request 'Users' 'Edit' or acl.action_allowed request 'Apps' 'ModerateReview'
def assertContainsAll haystack needles test_case for needle in reversed needles if needle in haystack needles.remove needle if needles test_case.fail '{haystack}didnotcontain{needles}'.format haystack haystack needles needles
def le a b return a < b
def hamming M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym w _cos_win M [0.54 0.46] return _truncate w needs_trunc
def get_page_from_path path preview False draft False try return get_page_queryset_from_path path preview draft .get except Page.DoesNotExist return None
def lineage_for_certname config certname def update_cert_for_name_match candidate_lineage rv 'Returncertifithasnamecertname elsereturnrv\n'matching_lineage_name_cert rvif candidate_lineage.lineagename certname matching_lineage_name_cert candidate_lineagereturn matching_lineage_name_certreturn _search_lineages config update_cert_for_name_match None
def addLoopsXSegmentIntersections lineLoopsIntersections loops segmentFirstX segmentSecondX segmentYMirror y for loop in loops addLoopXSegmentIntersections lineLoopsIntersections loop segmentFirstX segmentSecondX segmentYMirror y
def sort_by_announcement courses key lambda course course.sorting_score courses sorted courses key key return courses
def test_download_wheel_archive script data wheel_filename 'colander-0.9.9-py2.py3-none-any.whl'wheel_path os.path.join data.find_links wheel_filename result script.pip 'download' wheel_path '-d' '.' '--no-deps' assert Path 'scratch' / wheel_filename in result.files_created
def update_chain graph loc du ud ins graph.get_ins_from_loc loc for var in ins.get_used_vars for def_loc in set ud[ var loc ] du[ var def_loc ].remove loc ud[ var loc ].remove def_loc if not ud.get var loc ud.pop var loc if def_loc > 0 and not du[ var def_loc ] du.pop var def_loc def_ins graph.get_ins_from_loc def_loc if def_ins.is_call def_ins.remove_defined_var elif def_ins.has_side_effect continueelse update_chain graph def_loc du ud graph.remove_ins def_loc
def locked_volume_id_operation f external False def lvo_inner1 inst *args **kwargs lock_tag inst.driver_prefixcall_args inspect.getcallargs f inst *args **kwargs if call_args.get 'volume' volume_id call_args['volume'].idelif call_args.get 'snapshot' volume_id call_args['snapshot'].volume.idelse err_msg _ 'Thedecoratedmethodmustaccepteitheravolumeorasnapshotobject' raise exception.VolumeBackendAPIException data err_msg @utils.synchronized '%s-%s' % lock_tag volume_id external external def lvo_inner2 return f inst *args **kwargs return lvo_inner2 return lvo_inner1
def CancelBatchJob client batch_job max_poll_attempts MAX_POLL_ATTEMPTS batch_job_service client.GetService 'BatchJobService' 'v201605' batch_job['status'] 'CANCELING'operation {'operator' 'SET' 'operand' batch_job}batch_job_service.mutate [operation] poll_attempt 0while poll_attempt in range max_poll_attempts and batch_job['status'] ! 'CANCELED' sleep_interval 30 * 2 ** poll_attempt + random.randint 0 10000 / 1000 print 'BatchJobnotfinishedcanceling sleepingfor%sseconds.' % sleep_interval time.sleep sleep_interval batch_job GetBatchJob client batch_job['id'] poll_attempt + 1if batch_job['status'] 'CANCELED' print 'BatchJobwithID"%d"hasbeensuccessfullycanceled.' % batch_job['id'] else print 'BatchJobwithID"%d"failedtocancelafterpolling%dtimes.' % batch_job['id'] max_poll_attempts
def label_to_bin mpls_label is_bos True return type_desc.Int3.from_user mpls_label << 4 | is_bos
def _check_pyenv ret user None if not __salt__['pyenv.is_installed'] user ret['result'] Falseret['comment'] 'pyenvisnotinstalled.'return ret
def _collection_to_search_dict collection rights rights_manager.get_collection_rights collection.id doc {'id' collection.id 'title' collection.title 'category' collection.category 'objective' collection.objective 'language_code' collection.language_code 'tags' collection.tags 'rank' _get_search_rank collection.id }doc.update _collection_rights_to_search_dict rights return doc
def ToggleInteractiveWindow if edit is None CreateInteractiveWindow elif edit.NeedRecreateWindow edit.RecreateWindow else CloseInteractiveWindow
def _powerlaw_sequence gamma low high condition length max_iters for i in range max_iters seq []while not length seq seq.append _zipf_rv_below gamma low high if condition seq return seqraise nx.ExceededMaxIterations 'Couldnotcreatepowerlawsequence'
def CheckSectionSpacing filename clean_lines class_info linenum error if class_info.last_line - class_info.starting_linenum < 24 or linenum < class_info.starting_linenum returnmatched Match '\\s* public|protected|private ' clean_lines.lines[linenum] if matched prev_line clean_lines.lines[ linenum - 1 ]if not IsBlankLine prev_line and not Search '\\b class|struct \\b' prev_line and not Search '\\\\$' prev_line end_class_head class_info.starting_linenumfor i in range class_info.starting_linenum linenum if Search '\\{\\s*$' clean_lines.lines[i] end_class_head ibreakif end_class_head < linenum - 1 error filename linenum 'whitespace/blank_line' 3 '"%s "shouldbeprecededbyablankline' % matched.group 1
def get_report_view request dates DateForm data request.GET if not dates.is_valid logger.info 'Datesparsedwerenotvalid.' return {}if dates.cleaned_data.get 'start' and dates.cleaned_data.get 'end' return {'range' 'custom' 'start' dates.cleaned_data['start'].strftime '%Y%m%d' 'end' dates.cleaned_data['end'].strftime '%Y%m%d' }elif dates.cleaned_data.get 'last' return {'range' dates.cleaned_data['last'] 'last' str dates.cleaned_data['last'] + 'days' }logger.info 'Missing"startandend"or"last"' return {}
def set_eng_float_format accuracy 3 use_eng_prefix False set_option 'display.float_format' EngFormatter accuracy use_eng_prefix set_option 'display.column_space' max 12 accuracy + 9
def get_env_init_command package result 'gcloud' 'beta' 'emulators' package 'env-init' extra EXTRA.get package return result + extra
def pagingRequestType3 a L2PseudoLength l2pLength 19 b TpPd pd 6 c MessageType mesType 36 d PageModeAndChannelNeeded e TmsiPTmsi f TmsiPTmsi g TmsiPTmsi h TmsiPTmsi i P3RestOctets packet a / b / c / d / e / f / g / h / i return packet
def _covar_mstep_diag gmm X responsibilities weighted_X_sum norm min_covar avg_X2 np.dot responsibilities.T X * X * norm avg_means2 gmm.means_ ** 2 avg_X_means gmm.means_ * weighted_X_sum * norm return avg_X2 - 2 * avg_X_means + avg_means2 + min_covar
def UpdateResourcesFromResFile dstpath srcpath types None names None languages None res GetResources srcpath types names languages UpdateResourcesFromDict dstpath res
def list_startup_disks ret salt.utils.mac_utils.execute_return_result 'systemsetup-liststartupdisks' return ret.splitlines
def topic_subscription_push client to_delete TOPIC_NAME 'topic_subscription_push-%d' % _millis SUB_PUSH 'topic_subscription_push-sub-%d' % _millis PUSH_URL 'https //api.example.com/push-endpoint'topic client.topic TOPIC_NAME topic.create to_delete.append topic subscription topic.subscription SUB_PUSH push_endpoint PUSH_URL subscription.create subscription.modify_push_configuration push_endpoint None subscription.modify_push_configuration push_endpoint PUSH_URL
def AddRoundKey algInstance keyBlock for column in range algInstance.Nb for row in range 4 algInstance.state[column][row] ^ keyBlock[column][row]
def _unsigned_zero dtype assert dtype.kind 'u' return 1 << dtype.itemsize * 8 - 1
def libvlc_media_get_mrl p_md f _Cfunctions.get 'libvlc_media_get_mrl' None or _Cfunction 'libvlc_media_get_mrl' 1 string_result ctypes.c_void_p Media return f p_md
def _unpack_opargs code if sys.version_info[0] < 3 code list map ord code extended_arg 0n len code offset i 0while i < n op code[i]i + CODE_LENif op > HAVE_ARGUMENT arg code[i] | extended_arg for j in range ARG_LEN arg | code[ i + j ] << 8 * j i + ARG_LENif op EXTENDED_ARG extended_arg arg << 8 * ARG_LEN continueelse arg Nonei + NO_ARG_LENextended_arg 0 yield offset op arg i offset i
def _encode_list name value check_keys opts lname gen_list_name data ''.join [_name_value_to_bson next lname item check_keys opts for item in value] return '\x04' + name + _PACK_INT len data + 5 + data + '\x00'
def float_to_rational flt int_part int flt error flt - int_part if abs error < 0.0001 return int_part 1 den num float_to_rational 1.0 / error return int_part * den + num den
def seeother url return redirect url '303SeeOther'
def test_theano_rng rngs [make_theano_rng rng_or_seed 42 which_method 'uniform' make_theano_rng rng_or_seed RandomStreams 42 which_method 'uniform' make_theano_rng default_seed 42 make_theano_rng ]functions [theano.function [] rng.uniform size 100 for rng in rngs]random_numbers functions[0] equals numpy.ones 100 for function in functions[1 ] equal random_numbers function equals * equalassert equals.all
def compressed_one_hot labels dtype None out None simplify_binary True mode 'stack' sparse False labels _validate_labels labels ndim 1 labels_ labels.copy uniq np.unique labels_ for i e in enumerate uniq labels_[ labels_ e ] iif simplify_binary and len uniq 2 return labels_.reshape labels_.shape[0] 1 uniq else return OneHotFormatter len uniq dtype dtype .format labels_ mode mode sparse sparse uniq
@command 'reverseall' def reverse_playlist if g.last_search_query None None or 'func' not in g.last_search_query[1] g.content content.logo g.message 'Noplaylistloaded'returnsongs_list_or_func g.last_search_query[1]['func']if callable songs_list_or_func songs reversed songs_list_or_func 0 None else songs reversed songs_list_or_func paginatesongs list songs g.message c.y + 'Reversedentireplaylist' + c.w g.content content.generate_songlist_display
def _cmp_by_aspath path1 path2 as_path1 path1.get_pattr BGP_ATTR_TYPE_AS_PATH as_path2 path2.get_pattr BGP_ATTR_TYPE_AS_PATH assert as_path1 and as_path2 l1 as_path1.get_as_path_len l2 as_path2.get_as_path_len assert l1 is not None and l2 is not None if l1 > l2 return path2elif l2 > l1 return path1else return None
def unite iterable return set chain.from_iterable iterable
def gitignore_template language return gh.gitignore_template language
def compile_controllers folder path pjoin folder 'controllers' for fname in listdir path '.+\\.py$' data read_file pjoin path fname exposed find_exposed_functions data for function in exposed command data + '\nresponse._vars response._caller %s \n' % function filename pjoin folder 'compiled' 'controllers.%s.%s.py' % fname[ -3 ] function write_file filename command save_pyc filename os.unlink filename
def file_upload_echo request r dict [ k f.name for k f in request.FILES.items ] return HttpResponse json.dumps r
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def _defaultSysPathFactory return sys.path
def md5sum_str user_str if not isinstance user_str basestring console.error_exit 'Notavalidbasestringtypetocalculatemd5.' m md5.md5 m.update user_str return m.hexdigest
def prefix_validation_error error prefix code params if error.error_list [error] error_params error.params or {} return ValidationError message format_lazy '{}{}' SimpleLazyObject lambda prefix % params SimpleLazyObject lambda error.message % error_params code code params dict error_params **params return ValidationError [prefix_validation_error e prefix code params for e in error.error_list]
def cc_binary_config append None **kwargs blade_config.update_config 'cc_binary_config' append kwargs
def _AddConfigurationToMSVS p spec tools config config_type config_name attributes _GetMSVSAttributes spec config config_type tool_list _ConvertToolsToExpectedForm tools p.AddConfig _ConfigFullName config_name config attrs attributes tools tool_list
def ex_mod_init low if __salt__['config.get'] 'ebuild.enforce_nice_config' False __salt__['portage_config.enforce_nice_config'] return True
def private_key_managed name bits 2048 passphrase None cipher 'aes_128_cbc' new False verbose True **kwargs file_args kwargs _get_file_args name **kwargs new_key Falseif _check_private_key name bits passphrase new file_args['contents'] __salt__['x509.get_pem_entry'] name pem_type 'RSAPRIVATEKEY' else new_key Truefile_args['contents'] __salt__['x509.create_private_key'] text True bits bits passphrase passphrase cipher cipher verbose verbose ret __states__['file.managed'] **file_args if ret['changes'] and new_key ret['changes'] 'Newprivatekeygenerated'return ret
@transaction.non_atomic_requests@require_POSTdef generate_user_cert request course_id if not request.user.is_authenticated log.info u'Anonusertryingtogeneratecertificatefor%s' course_id return HttpResponseBadRequest _ 'Youmustbesignedinto{platform_name}tocreateacertificate.' .format platform_name configuration_helpers.get_value 'PLATFORM_NAME' settings.PLATFORM_NAME student request.usercourse_key CourseKey.from_string course_id course modulestore .get_course course_key depth 2 if not course return HttpResponseBadRequest _ 'Courseisnotvalid' if not is_course_passed course None student request return HttpResponseBadRequest _ 'Yourcertificatewillbeavailablewhenyoupassthecourse.' certificate_status certs_api.certificate_downloadable_status student course.id if certificate_status['is_downloadable'] return HttpResponseBadRequest _ 'Certificatehasalreadybeencreated.' elif certificate_status['is_generating'] return HttpResponseBadRequest _ 'Certificateisbeingcreated.' else certs_api.generate_user_certificates student course.id course course generation_mode 'self' _track_successful_certificate_generation student.id course.id return HttpResponse
def vector_path *names return pkg_resources.resource_filename __name__ os.path.join 'testdata' *names
def _row_to_dict row d for fld in row.keys val row[fld]if val is None val ''if _verify_var_type val d[ '$' + fld ] _as_str val
def test_write_noheader_normal out StringIO ascii.write dat out Writer ascii.FixedWidthNoHeader assert_equal_splitlines out.getvalue '|1.2|"hello"|1|a|\n|2.4|\'sworlds|2|2|\n'
def allowed_from_settings settings principals perms_settings {k aslist v for k v in settings.items if k.endswith '_principals' }from_settings {}for key allowed_principals in perms_settings.items resource_name permission _ key.split '_' if resource_name not in PERMISSIONS_INHERITANCE_TREE.keys continueif not bool set principals & set allowed_principals continueif permission 'create' permission '%s %s' % resource_name permission resource_name {'bucket' '' 'collection' 'bucket' 'group' 'bucket' 'record' 'collection'}[resource_name]from_settings.setdefault resource_name set .add permission return from_settings
def _end_of_life_tween_factory handler registry deprecation_msg 'Theserviceyouaretryingtoconnectnolongerexistsatthislocation.'def eos_tween request eos_date registry.settings['eos']eos_url registry.settings['eos_url']eos_message registry.settings['eos_message']if not eos_date return handler request eos_date dateparser.parse eos_date if eos_date > datetime.now code 'soft-eol'request.response handler request else code 'hard-eol'request.response errors.http_error HTTPGone errno errors.ERRORS.SERVICE_DEPRECATED message deprecation_msg errors.send_alert request eos_message url eos_url code code return request.responsereturn eos_tween
def iterable obj try len obj except return Falsereturn True
def get_all_files folder strip_prefix '' prefix None all_files []def iterate path path_dirs path_files storage.listdir path for dirname in sorted path_dirs full os.path.join path dirname all_files.append full iterate full for filename in sorted path_files full os.path.join path filename all_files.append full iterate folder if prefix is not None all_files [os.path.join prefix fname[ len strip_prefix + 1 ] for fname in all_files]return all_files
def _compute_style_grad F G G_style layer Fl Gl F[layer] G[layer] c Fl.shape[0] ** -2 * Fl.shape[1] ** -2 El Gl - G_style[layer] loss c / 4 * El ** 2 .sum grad c * sgemm 1.0 El Fl * Fl > 0 return loss grad
def p_function_seq p _parse_seq p
def clearEvents eventType None if not havePygame or not display.get_init defDisplay pyglet.window.get_platform .get_default_display for win in defDisplay.get_windows win.dispatch_events if eventType 'mouse' returnglobal _keyBuffer_keyBuffer []elif eventType 'mouse' junk evt.get [locals.MOUSEMOTION locals.MOUSEBUTTONUP locals.MOUSEBUTTONDOWN] elif eventType 'keyboard' junk evt.get [locals.KEYDOWN locals.KEYUP] elif eventType 'joystick' junk evt.get [locals.JOYAXISMOTION locals.JOYBALLMOTION locals.JOYHATMOTION locals.JOYBUTTONUP locals.JOYBUTTONDOWN] else junk evt.get
@pytest.mark.skipif 'notHAS_YAML' def test_write_full t T_DTYPES[ 'bool' 'int64' 'float64' 'str' ]lines ['#%ECSV0.9' '#---' '#datatype ' '#-name bool' '#unit m/s' '#datatype bool' '#description descr_bool' '#meta {metabool 1}' '#-name int64' '#unit m/s' '#datatype int64' '#description descr_int64' '#meta {metaint64 1}' '#-name float64' '#unit m/s' '#datatype float64' '#description descr_float64' '#meta {metafloat64 1}' '#-name str' '#unit m/s' '#datatype string' '#description descr_str' '#meta {metastr 1}' '#meta !!omap' '#-comments [comment1 comment2]' 'boolint64float64str' 'False00.0"ab0"' 'True11.0"ab 1"' 'False22.0ab2']out StringIO t.write out format 'ascii.ecsv' assert out.getvalue .splitlines lines
def markup_description description if apply_markdown description apply_markdown description else description escape description .replace u'\n' u'<br/>' description u'<p>' + description + u'</p>' return mark_safe description
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def csv_fields series rv []fields set for row in series fields.update row['data'] rv.append row['data'] row['data'].update count row['count'] date row['date'] return rv fields
def escape_new_line original return smart_decode original .replace u'\\' u'\\\\' .replace u'\r' u'\\r' .replace u'\n' u'\\n'
def clear_ccx_field_info_from_ccx_map ccx block name try clean_ccx_key _clean_ccx_key block.location ccx_override_map _get_overrides_for_ccx ccx .setdefault clean_ccx_key {} ccx_override_map.pop name ccx_override_map.pop name + '_id' ccx_override_map.pop name + '_instance' except KeyError pass
def render_value_in_context value context value template_localtime value use_tz context.use_tz value localize value use_l10n context.use_l10n value force_text value if context.autoescape and not isinstance value SafeData or isinstance value EscapeData return escape value else return value
def chain *rules def chain_rl expr for rule in rules expr rule expr return exprreturn chain_rl
def add_dict_to_cookiejar cj cookie_dict return cookiejar_from_dict cookie_dict cj
def cos_func arg return libm.cos arg
def get_mx_domains domain dns_resolver _dns_resolver mx_records []try mx_records dns_resolver .query domain 'MX' except NoNameservers log.error 'NoMXservers' domain domain except NXDOMAIN log.error 'Nosuchdomain' domain domain except Timeout log.error 'Timeoutduringresolution' domain domain raiseexcept NoAnswer log.error 'Noanswerfromprovider' domain domain mx_records _fallback_get_mx_domains domain return [str rdata.exchange .lower for rdata in mx_records]
def version_diff v1 v2 if v1 is None or v2 is None return Nonev1_parts v1.split '.' v2_parts v2.split '.' v1_parts + ['0'] * len v2_parts - len v1_parts v2_parts + ['0'] * len v1_parts - len v2_parts for v1p v2p in zip v1_parts v2_parts cur_diff int v1p - int v2p if cur_diff return cur_diffreturn 0
def modname path base os.path.basename path filename ext os.path.splitext base return filename
def set_trace import pdbimport sysstdout sys.stdoutsys.stdout sys.__stdout__pdb.Pdb .set_trace sys._getframe .f_back
def remote_scp command password_list log_filename None transfer_timeout 600 login_timeout 20 logging.debug "TryingtoSCPwithcommand'%s' timeout%ss" command transfer_timeout if log_filename output_func utils.log_lineoutput_params log_filename else output_func Noneoutput_params session aexpect.Expect command output_func output_func output_params output_params try _remote_scp session password_list transfer_timeout login_timeout finally session.close
def replace_query_param url key val scheme netloc path query fragment urlparse.urlsplit url query_dict QueryDict query .copy query_dict[key] valquery query_dict.urlencode return urlparse.urlunsplit scheme netloc path query fragment
def dd_object_to_id obj obj_type id_value 'id' if isinstance obj obj_type return getattr obj id_value elif isinstance obj basestring return objelse raise TypeError 'Invalidtype%slookingforbasestringor%s' % type obj .__name__ obj_type.__name__
def stddev_from_average timeseries series pandas.Series [x[1] for x in timeseries] mean series.mean stdDev series.std t tail_avg timeseries return abs t - mean > 3 * stdDev
def test_map_effects selection names _map_effects n_factors 2 effects 'A' assert_true names ['A'] selection names _map_effects n_factors 2 effects ['A' 'A B'] assert_true names ['A' 'A B'] selection names _map_effects n_factors 3 effects 'A*B' assert_true names ['A' 'B' 'A B'] selection names _map_effects n_factors 3 effects 'A*C' assert_true names ['A' 'B' 'A B' 'C' 'A C' 'B C' 'A B C'] assert_raises ValueError _map_effects n_factors 2 effects 'C' assert_raises ValueError _map_effects n_factors 27 effects 'all'
def new data None return SHA224Hash .new data
@contextfilterdef number_format context value value str value negative Falseaddzero Noneif value[0] '-' value value[1 ]negative Trueif '.' in value point value.rindex '.' if point len value - 2 addzero Trueelse point len value while point < len value - 3 if value[ len value - 1 ] '0' value value[ len value - 1 ]else breakwhile point > 3 value value[ point - 3 ] + ' ' + value[ point - 3 ] point value.index ' ' if addzero value + '0'if negative value '-' + value return value
def available_calculators return CALCULATED_AGGREGATIONS.keys
def wait_rm name recurse False profile None return {'name' name 'changes' {} 'result' True 'comment' ''}
def _has_required_boto3 if not HAS_BOTO3 return Falseelif LooseVersion boto3.__version__ < LooseVersion required_boto3_version return Falseelse return True
def debug host 'localhost' port 6000 authkey 'secretpassword' init host port authkey qdb.do_debug
def formstyle_table_inline form fields *args **kwargs def render_row row_id label widget comment hidden False _class 'hide' if hidden else None row TR TD label _class 'w2p_fl' TD widget _id row_id _class _class if comment row.append TD DIV _class 'tooltip' _title '%s|%s' % label comment _class 'w2p_fc' return rowif args hidden kwargs.get 'hidden' False return render_row form fields args[0] args[1] hidden hidden else parent TABLE for row_id label widget comment in fields row render_row row_id label widget comment parent.append row return parent
@pytest.mark.parametrize u'testframe' totest_frames def test_gcrs_icrs_moonish testframe moonish GCRS MOONDIST_CART obstime testframe.obstime moonicrs moonish.transform_to ICRS assert 0.97 * u.au < moonicrs.distance < 1.03 * u.au
def ldapUrlEscape s return quote s .replace ' ' '%2C' .replace '/' '%2F'
def FromImport package_name name_leafs for leaf in name_leafs leaf.remove children [Leaf token.NAME 'from' Leaf token.NAME package_name prefix '' Leaf token.NAME 'import' prefix '' Node syms.import_as_names name_leafs ]imp Node syms.import_from children return imp
def whitespace_around_comma logical_line line logical_linefor m in WHITESPACE_AFTER_COMMA_REGEX.finditer line found m.start + 1 if ' DCTB ' in m.group yield found "E242tabafter'%s'" % m.group [0] else yield found "E241multiplespacesafter'%s'" % m.group [0]
def monkeypatch_class name bases namespace assert len bases 1 'Exactlyonebaseclassrequired'base bases[0]for name value in namespace.iteritems if name ! '__metaclass__' and name ! '__doc__' setattr base name value return base
def copy2 src dst shutil.copy2 fsencoding src fsencoding dst
def deploy_mission_hrquantity row if hasattr row 'deploy_mission' row row.deploy_missiontry mission_id row.idexcept AttributeError return 0db current.dbtable db.deploy_assignmentcount table.id.count row db table.mission_id mission_id .select count .first if row return row[count]else return 0
def flatten_applications series for row in series if 'data' in row new {}for app versions in row['data'].items app amo.APP_GUIDS.get app if not app continueappname unicode app.pretty for ver count in versions.items key ''.join [appname ver] new[key] countrow['data'] new yield row
def docformat docstring docdict None if not docstring return docstringif docdict is None docdict {}if not docdict return docstringlines docstring.expandtabs .splitlines if len lines < 2 icount 0else icount indentcount_lines lines[1 ] indent '' * icount indented {}for name dstr in docdict.items lines dstr.expandtabs .splitlines try newlines [lines[0]]for line in lines[1 ] newlines.append indent + line indented[name] '\n'.join newlines except IndexError indented[name] dstrreturn docstring % indented
def get_config_root *append from hadoop.conf import HDFS_CLUSTERSyarn_site_path HDFS_CLUSTERS['default'].HADOOP_CONF_DIR.get return os.path.abspath os.path.join yarn_site_path '..' *append
def _AbsUrl relative_url context unused_args return urlparse.urljoin context.Lookup 'base-url' relative_url
def check_incomplete_vs_complete complete cfg.complete_dir.get_path if misc.same_file cfg.download_dir.get_path complete if misc.real_path 'X' cfg.download_dir cfg.download_dir cfg.download_dir.set os.path.join complete 'incomplete' else cfg.download_dir.set 'incomplete'
def dup_from_dict f K if not f return [] n h max f.keys [] if type n is int for k in range n -1 -1 h.append f.get k K.zero else n nfor k in range n -1 -1 h.append f.get k K.zero return dup_strip h
def search_iter db query limit None batch 100 count search_count db query if not count raise StopIterationremain countif limit is not None remain min remain limit offset 1prev_ids []while remain batch min batch remain ids search db query offset batch .read .strip .split assert len ids batch 'Got%i expected%i' % len ids batch if ids prev_ids raise RuntimeError 'Samesearchresultsforpreviousoffset' for identifier in ids if identifier in prev_ids raise RuntimeError 'Result%swasinpreviousbatch' % identifier yield identifier offset + batchremain - batchprev_ids ids
def show_state_usage queue False **kwargs conflict _check_queue queue kwargs if conflict is not None return conflictpillar kwargs.get 'pillar' pillar_enc kwargs.get 'pillar_enc' if pillar_enc is None and pillar is not None and not isinstance pillar dict raise SaltInvocationError 'Pillardatamustbeformattedasadictionary unlesspillar_encisspecified.' st_ salt.state.HighState __opts__ pillar pillar_enc pillar_enc st_.push_active try ret st_.compile_state_usage finally st_.pop_active _set_retcode ret return ret
def _weighted_percentile array sample_weight percentile 50 sorted_idx np.argsort array weight_cdf stable_cumsum sample_weight[sorted_idx] percentile_idx np.searchsorted weight_cdf percentile / 100.0 * weight_cdf[ -1 ] return array[sorted_idx[percentile_idx]]
def p_jump_statement_2 t pass
def read_int16_matrix fid rows cols return _unpack_matrix fid rows cols dtype '>i2' out_dtype np.int16
def pre_run_code_hook self return None
def gauss_laguerre n n_digits x Dummy 'x' p laguerre_poly n x polys True p1 laguerre_poly n + 1 x polys True xi []w []for r in p.real_roots if isinstance r RootOf r r.eval_rational S 1 / 10 ** n_digits + 2 xi.append r.n n_digits w.append r / n + 1 ** 2 * p1.subs x r ** 2 .n n_digits return xi w
def add_arg f *args **kwargs if not hasattr f 'arguments' f.arguments []if args kwargs not in f.arguments f.arguments.insert 0 args kwargs
def infix bp func class Operator TokenBase lbp bpdef led self left parser self.first leftself.second parser.expression bp return selfdef eval self context try return func context self.first self.second except Exception return Falsereturn Operator
def find_toplevel_job_dir start_dir job_dir start_dirwhile not os.path.exists os.path.join job_dir '.autoserv_execute' if job_dir '/' return Nonejob_dir os.path.dirname job_dir return job_dir
def get_tree base exclude coverage the_coverage tree {}runs coverage.data.executed_files for path in runs if not _skip_file path exclude and not os.path.isdir path _graft path tree return tree
def painting clip saturation 1.4 black 0.006 return clip.fl_image lambda im to_painting im saturation black
def ls_ active None cache True path None contextvar 'lxc.ls{0}'.format path if active contextvar + '.active'if cache and contextvar in __context__ return __context__[contextvar]else ret []cmd 'lxc-ls'if path cmd + '-P{0}'.format pipes.quote path if active cmd + '--active'output __salt__['cmd.run_stdout'] cmd python_shell False for line in output.splitlines ret.extend line.split __context__[contextvar] retreturn ret
def convert_to_camel data components data.split '_' return components[0] + ''.join x.title for x in components[1 ]
def methods_equivalent meth1 meth2 return getattr meth1 '__func__' meth1 is getattr meth2 '__func__' meth2
def test_completion_for_bash script bash_completion '_pip_completion \n{\nCOMPREPLY $ COMP_WORDS "${COMP_WORDS[*]}"\\\nCOMP_CWORD $COMP_CWORD\\\nPIP_AUTO_COMPLETE 1$1 \n}\ncomplete-odefault-F_pip_completionpip'result script.pip 'completion' '--bash' assert bash_completion in result.stdout 'bashcompletioniswrong'
def test_external_js_and_css_resource_embedding class CustomModel1 Model __javascript__ 'external_js_1'__css__ 'external_css_1'class CustomModel2 Model __javascript__ ['external_js_2' 'external_js_3']__css__ ['external_css_2' 'external_css_3']class CustomModel3 Model __javascript__ ['external_js_1' 'external_js_3']__css__ ['external_css_1' 'external_css_2']r resources.Resources assert 'external_js_1' in r.js_files assert 'external_css_1' in r.css_files assert 'external_js_2' in r.js_files assert 'external_js_3' in r.js_files assert 'external_css_2' in r.css_files assert 'external_css_3' in r.css_files assert r.css_files.count 'external_css_1' 1 assert r.css_files.count 'external_css_2' 1 assert r.js_files.count 'external_js_3' 1 assert r.js_files.count 'external_js_1' 1
def _requires_npn func @wraps func def wrapper *args **kwargs if not _lib.Cryptography_HAS_NEXTPROTONEG raise NotImplementedError 'NPNnotavailable.' return func *args **kwargs return wrapper
def set_api_params module module_params api_params dict for param in module_params module_param module.params.get param None if module_param api_params[pc param ] module_paramreturn api_params
def validating_string_param registry xml_parent data pdef base_param registry xml_parent data True 'hudson.plugins.validating__string__parameter.ValidatingStringParameterDefinition' XML.SubElement pdef 'regex' .text data['regex']XML.SubElement pdef 'failedValidationMessage' .text data['msg']
def evaluate op op_str a b raise_on_error False use_numexpr True **eval_kwargs use_numexpr use_numexpr and _bool_arith_check op_str a b if use_numexpr return _evaluate op op_str a b raise_on_error raise_on_error **eval_kwargs return _evaluate_standard op op_str a b raise_on_error raise_on_error
def transfer_events_to_another_collection client source_collection destination_collection dry reverse False schemas_match make_sure_keen_schemas_match source_collection destination_collection client if not schemas_match raise ValueError 'Thetwoprovidedschemasinkeendonotmatch youwillneedtodoabitmorework.' events_from_source extract_events_from_keen client source_collection for event in events_from_source event['keen'].pop 'created_at' event['keen'].pop 'id' if reverse remove_events_from_keen client destination_collection events_from_source dry else add_events_to_keen client destination_collection events_from_source dry logger.info 'Transferred{}eventsfromthe{}collectiontothe{}collection'.format len events_from_source source_collection destination_collection
def unassign_floating_ip kwargs None call None if call ! 'function' log.error 'Theinassign_floating_ipfunctionmustbecalledwith-for--function.' return Falseif not kwargs kwargs {}if 'floating_ip' not in kwargs log.error 'AfloatingIPisrequired.' return Falseresult query method 'floating_ips' command kwargs['floating_ip'] + '/actions' args {'type' 'unassign'} http_method 'post' return result
def pearson v1 v2 v1 v2 array v1 array v2 if not v1.size v2.size > 1 raise ValueError "Oneormorevectorsisn'tlongenoughtocorrelateortheyhaveunequallengths." return corrcoef v1 v2 [0][1]
def mw_search server query num search_url u'http //%s/w/api.php?format json&action query&list search&srlimit %d&srprop timestamp&srwhat text&srsearch ' % server num search_url + queryquery json.loads web.get search_url if u'query' in query query query[u'query'][u'search']return [r[u'title'] for r in query]else return None
def channelModeModify VgcsTargetModeIdentication_presence 0 MultiRateConfiguration_presence 0 a TpPd pd 6 b MessageType mesType 8 c ChannelDescription2 d ChannelMode packet a / b / c / d if VgcsTargetModeIdentication is 1 e VgcsTargetModeIdenticationHdr ieiVTMI 1 eightBitVTMI 0 packet packet / e if MultiRateConfiguration is 1 f MultiRateConfigurationHdr ieiMRC 3 eightBitMRC 0 packet packet / f return packet
def matrix_power M n result 1for i in xrange n result theano.dot result M return result
def test_completion_for_fish script fish_completion 'function__fish_complete_pip\nset-lxCOMP_WORDS commandline-o ""\nset-lxCOMP_CWORD math contains-i-- commandline-t $COMP_WORDS -1 \nset-lxPIP_AUTO_COMPLETE1\nstringsplit\\-- eval$COMP_WORDS[1] \nend\ncomplete-fa" __fish_complete_pip "-cpip'result script.pip 'completion' '--fish' assert fish_completion in result.stdout 'fishcompletioniswrong'
def expand_path s if os.name 'nt' s s.replace '$\\' 'IPYTHON_TEMP' s os.path.expandvars os.path.expanduser s if os.name 'nt' s s.replace 'IPYTHON_TEMP' '$\\' return s
def test_cnn_sk_estimator check_estimator CondensedNearestNeighbour
def _split_auth_string auth_string prev Nonefor item in auth_string.split ' ' try if prev.count '"' 1 prev '%s %s' % prev item continueexcept AttributeError if prev None prev itemcontinueelse raise StopIteration yield prev.strip prev item yield prev.strip raise StopIteration
def _except_import_error node if not isinstance node astroid.TryExcept returnreturn any map is_import_error node.handlers
@comm_guard BoundVariable ANY_TYPE def unify_walk bv o U if bv.value o return Uelse return False
def expect_element __funcname _qualified_name **named def _expect_element collection if isinstance collection set frozenset collection_for_error_message tuple sorted collection else collection_for_error_message collectiontemplate "% funcname s expectedavaluein{collection}forargument'% argname s' butgot% actual sinstead.".format collection collection_for_error_message return make_check ValueError template complement op.contains collection repr funcname __funcname return preprocess **valmap _expect_element named
def _DeepCopySomeKeys in_dict keys d {}for key in keys if key not in in_dict continued[key] copy.deepcopy in_dict[key] return d
def signed content private_key_name 'signing.key' command ['openssl' 'dgst' '-sha256' '-sign' join tests_dir private_key_name ] out err out_and_err command input content return out
@with_setup prepare_stdout def test_output_when_could_not_find_features path fs.relpath join abspath dirname __file__ 'no_features' 'unexistent-folder' runner Runner path verbosity 3 no_color False runner.run assert_stdout_lines '\x1b[1;31mOops!\x1b[0m\n\x1b[1;37mcouldnotfindfeaturesat\x1b[1;33m./%s\x1b[0m\n' % path
def listdir_remove_fs query_dir original orig_listdir query_dir result []for fname in original if TEST_PLUGIN_NAME not in fname result.append fname return result
def expect warn_type message for filter in _warnings.filters if filter[0] 'ignore' and issubclass warn_type filter[2] returnEXPECTED.append ' ' + warn_type.__name__ + ' ' + message + '\n'
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
def increase_indent func def wrapper *args **kwargs global _debug_indent_debug_indent + 1try return func *args **kwargs finally _debug_indent - 1return wrapper
def min_cost_flow G demand 'demand' capacity 'capacity' weight 'weight' return nx.network_simplex G demand demand capacity capacity weight weight [1]
def recommend_for_brands brands return []
def getFunctionLists fileName fileText archive.getFileText fileName functionList []functionLists [functionList]lines archive.getTextLines fileText for line in lines lineStripped line.strip if lineStripped.startswith 'def' bracketIndex lineStripped.find ' ' if bracketIndex > -1 lineStripped lineStripped[ bracketIndex]functionList.append lineStripped elif line.startswith 'class' functionList []functionLists.append functionList return functionLists
def _get_option_list options return ' '.join ['{0} {1}'.format x y for x y in six.iteritems options ]
def info return _nodetool 'info'
def dmp_mul_term f c i u K if not u return dup_mul_term f c i K v u - 1 if dmp_zero_p f u return fif dmp_zero_p c v return dmp_zero u else return [dmp_mul cf c v K for cf in f] + dmp_zeros i v K
def _extract_jdk_version java_version_out match re.search 'RuntimeEnvironment\\ build .*? \\ ' java_version_out if match is None return None version build match.group 1 .split '-' release version.split '_' [0].split '.' [1]update str int version.split '_' [1] return '% release su% update s-% build s' % locals
def run_bare_wsgi_app application env dict os.environ env['wsgi.input'] sys.stdinenv['wsgi.errors'] sys.stderrenv['wsgi.version'] 1 0 env['wsgi.run_once'] Trueenv['wsgi.url_scheme'] wsgiref.util.guess_scheme env env['wsgi.multithread'] Falseenv['wsgi.multiprocess'] Falseresult application env _start_response if result is not None for data in result sys.stdout.write data
@jsonrpc_method 'plugins.is_authenticated' def plugins_is_authenticated request sessionid engine import_module settings.SESSION_ENGINE session engine.SessionStore sessionid try user_id session[auth.SESSION_KEY]backend_path session[auth.BACKEND_SESSION_KEY]backend auth.load_backend backend_path user backend.get_user user_id except KeyError http_auth sessionid.decode 'base64' request type 'request' object {'META' {'HTTP_AUTHORIZATION' http_auth}} if FreeBasicAuthentication .is_authenticated request user request.userelse return Falseif user and user.is_authenticated return Truereturn False
def genrepo return _genrepo opts __opts__ fire_event False
def list_enabled_plugins runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user cmd [_get_rabbitmq_plugin 'list' '-m' '-e']ret __salt__['cmd.run_all'] cmd python_shell False runas runas _check_response ret return _output_to_list ret['stdout']
def _minify_json data import jsonreturn json.dumps json.loads data
def _create_srt_file content None content content or SRT_content srt_file tempfile.NamedTemporaryFile suffix '.srt' srt_file.content_type 'application/x-subrip;charset utf-8'srt_file.write content srt_file.seek 0 return srt_file
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def child_max dependencies dependents scores result dict num_needed dict k len v for k v in dependencies.items current set k for k v in num_needed.items if v 0 while current key current.pop score scores[key]children dependencies[key]if children score + max result[child] for child in children result[key] scorefor parent in dependents[key] num_needed[parent] - 1if num_needed[parent] 0 current.add parent return result
def rapid val get_vars.get 'val' True if val '0' val Falseelse val Truesession.s3.rapid_data_entry valresponse.view 'xml.html'return dict item str session.s3.rapid_data_entry
def length_hint obj default 0 if not isinstance default int msg "'%s'objectcannotbeinterpretedasaninteger" % type default .__name__ raise TypeError msg try return len obj except TypeError passtry hint type obj .__length_hint__except AttributeError return defaulttry val hint obj except TypeError return defaultif val is NotImplemented return defaultif not isinstance val int msg '__length_hint__mustbeinteger not%s' % type val .__name__ raise TypeError msg if val < 0 msg '__length_hint__ shouldreturn> 0'raise ValueError msg return val
def get_filter filetypes ext if not ext return ALL_FILTERfor title ftypes in filetypes if ext in ftypes return _create_filter title ftypes else return ''
def reverse_order order items []for item in order.split ' ' item item.lower .split direction 'asc' if item[1 ] ['desc'] else 'desc' items.append '%s%s' % item[0] direction return ' '.join items
def resolve_answers exploration_id state_name rule_str answers assert isinstance answers list answer_log StateRuleAnswerLogModel.get_or_create exploration_id state_name rule_str for answer in answers if answer not in answer_log.answers logging.error 'Answer%snotfoundinanswerlogforrule%sofexploration%s state%s handler%s' % answer rule_str exploration_id state_name _OLD_SUBMIT_HANDLER_NAME else del answer_log.answers[answer]answer_log.put
def CORREL ds1 ds2 count timeperiod - 2 ** 31 data1 value_ds_to_numpy ds1 count if data1 is None return Nonedata2 value_ds_to_numpy ds2 count if data2 is None return Nonereturn talib.CORREL data1 data2 timeperiod
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_POSTdef mark_student_can_skip_entrance_exam request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id student_identifier request.POST.get 'unique_student_identifier' student get_student_from_identifier student_identifier __ created EntranceExamConfiguration.objects.get_or_create user student course_id course_id if created message _ 'Thisstudent %s willskiptheentranceexam.' % student_identifier else message _ 'Thisstudent %s isalreadyallowedtoskiptheentranceexam.' % student_identifier response_payload {'message' message}return JsonResponse response_payload
def test_show_fixtures_and_test testdir p testdir.makepyfile '\nimportpytest\n@pytest.fixture\ndefarg \nassertFalse\ndeftest_arg arg \nassertFalse\n' result testdir.runpytest '--setup-plan' p assert result.ret 0 result.stdout.fnmatch_lines ['*SETUPFarg*' '*test_arg fixturesused arg ' '*TEARDOWNFarg*']
def isframe object return isinstance object types.FrameType
def process_hour hour_date SLEEPTIME 180log_dir os.path.join RAW_LOG_DIR hour_date files_missing [os.path.join log_dir '%s.log.bz2' % h for h in g.TRAFFIC_LOG_HOSTS]files_missing [f for f in files_missing if not s3_key_exists s3_connection f ]while files_missing print 'Missinglog s %s sleeping' % files_missing sleep SLEEPTIME files_missing [f for f in files_missing if not s3_key_exists s3_connection f ]process_pixel_log os.path.join log_dir '*'
def _CompileFilters config filters []for filter_type in iterkeys config compiler FILTER_COMPILERS.get filter_type if compiler is not None for filter_config in _ListOf config[filter_type] compiledFilter compiler filter_config filters.append compiledFilter return filters
def check_sampleid_duplicates header mapping_data errors sample_id_field 'SampleID'correction 1try sample_id_ix header.index sample_id_field except ValueError return errorssample_ids []missing_sample_ids []for curr_data in range len mapping_data if len mapping_data[curr_data][sample_id_ix] 0 errors.append 'MissingSampleID. DCTB %d %d' % curr_data + correction sample_id_ix missing_sample_ids.append curr_data + correction sample_ids.append mapping_data[curr_data][sample_id_ix] dups duplicates_indices sample_ids for curr_dup in dups for curr_loc in dups[curr_dup] if curr_loc + correction not in missing_sample_ids errors.append 'DuplicateSampleID%sfound. DCTB %d %d' % curr_dup curr_loc + correction sample_id_ix return errors
def out2in *local_opts **kwargs name kwargs and kwargs.pop 'name' None if len local_opts > 1 local_opts LocalOptGroup *local_opts else local_opts local_optsif not name name local_opts.__name__ret TopoOptimizer local_opts order 'out_to_in' failure_callback TopoOptimizer.warn_inplace **kwargs if name ret.__name__ namereturn ret
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def subnet_group_present name subnet_ids None subnet_names None description None tags None region None key None keyid None profile None ret {'name' name 'result' True 'comment' '' 'changes' {}}exists __salt__['boto_elasticache.subnet_group_exists'] name name tags tags region region key key keyid keyid profile profile if not exists if __opts__['test'] ret['comment'] 'Subnetgroup{0}issettobecreated.'.format name ret['result'] Nonereturn retcreated __salt__['boto_elasticache.create_subnet_group'] name name subnet_ids subnet_ids subnet_names subnet_names description description tags tags region region key key keyid keyid profile profile if not created ret['result'] Falseret['comment'] 'Failedtocreate{0}subnetgroup.'.format name return retret['changes']['old'] Noneret['changes']['new'] nameret['comment'] 'Subnetgroup{0}created.'.format name return retret['comment'] 'Subnetgrouppresent.'return ret
def parse_request request if not re.match '.*HTTP/.*\r\n' request return Nonehttp HTTPRequest request if http.error_code return Nonereturn http
def test_read_twoline_normal table '\nCol1Col2\n-------------\n1.2xx"hello"\n2.4\'sworlds\n'dat ascii.read table Reader ascii.FixedWidthTwoLine assert_equal dat.dtype.names 'Col1' 'Col2' assert_almost_equal dat[1][0] 2.4 assert_equal dat[0][1] '"hello"' assert_equal dat[1][1] "'sworlds"
def dot inp matrix if 'int' in inp.dtype and inp.ndim 2 return matrix[inp.flatten ]elif 'int' in inp.dtype return matrix[inp]elif 'float' in inp.dtype and inp.ndim 3 shape0 inp.shape[0]shape1 inp.shape[1]shape2 inp.shape[2]return TT.dot inp.reshape shape0 * shape1 shape2 matrix else return TT.dot inp matrix
def GetOrderedIntersection handler_list results _Intersect handler_list results sorted results key lambda h h.pattern _ReorderHandlers results _GivePropertiesFromGeneralToSpecific results return _RemoveRedundantHandlers results
def CreateFilter pc task return CreateTasksFilter pc [task]
def download_setuptools version DEFAULT_VERSION download_base DEFAULT_URL to_dir os.curdir delay 15 downloader_factory get_best_downloader to_dir os.path.abspath to_dir tgz_name 'setuptools-%s.tar.gz' % version url download_base + tgz_name saveto os.path.join to_dir tgz_name if not os.path.exists saveto log.warn 'Downloading%s' url downloader downloader_factory downloader url saveto return os.path.realpath saveto
def read_user_variable var_name default_value return click.prompt var_name default default_value
def padded_key key symbols filter True syms list uniq symbols if len syms ! len symbols extra ''.join sorted set [i for i in symbols if symbols.count i > 1 ] raise ValueError 'duplicatecharactersinsymbols %s' % extra extra set key - set syms if extra raise ValueError 'charactersinkeybutnotsymbols %s' % ''.join sorted extra key0 ''.join list uniq key return key0 + ''.join [i for i in syms if i not in key0 ]
def test_unique_prefix_completion superConsole.SendKeys 'outputRedirectStart{ }{ }{ENTER}' testRegex ''superConsole.SendKeys 'printz{TAB}{ENTER}' testRegex + 'zoltar'superConsole.SendKeys 'printyo{TAB}{ENTER}' testRegex + 'yorick'superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex AreEqual removePrompts getTestOutput [1] []
def savez file *args **kwds args map cupy.asnumpy args for key in kwds kwds[key] cupy.asnumpy kwds[key] numpy.savez file *args **kwds
def get_slice_bounds builder slicestruct start slicestruct.startstop slicestruct.stopzero start.type 0 one start.type 1 is_step_negative builder.icmp_signed '<' slicestruct.step zero lower builder.select is_step_negative builder.add stop one start upper builder.select is_step_negative builder.add start one stop return lower upper
def _parse_udevadm_info udev_info devices []dev {}for line in line.strip for line in udev_info.splitlines if line line line.split ' ' 1 if len line ! 2 continue query data lineif query 'E' if query not in dev dev[query] {} key val data.strip .split ' ' 1 try val int val except ValueError try val float val except ValueError passdev[query][key] valelse if query not in dev dev[query] []dev[query].append data.strip elif dev devices.append _normalize_info dev dev {}if dev _normalize_info dev devices.append _normalize_info dev return devices
def _restore_webroot_config config renewalparams if 'webroot_map' in renewalparams if not cli.set_by_cli 'webroot_map' config.namespace.webroot_map renewalparams['webroot_map']elif 'webroot_path' in renewalparams logger.debug 'Ancientrenewalconffilewithoutwebroot-map restoringwebroot-path' wp renewalparams['webroot_path']if isinstance wp str wp [wp]config.namespace.webroot_path wp
def _band_count a nrows ncols a.shapeml 0for k in range - nrows + 1 0 if np.diag a k .any ml - k breakmu 0for k in range nrows - 1 0 -1 if np.diag a k .any mu kbreakreturn ml mu
def _ensure_trans trans fro 'mri' to 'head' if isinstance fro string_types from_str frofrom_const _str_to_frame[fro]else from_str _frame_to_str[fro]from_const frodel froif isinstance to string_types to_str toto_const _str_to_frame[to]else to_str _frame_to_str[to]to_const todel toerr_str 'transmustgo%s<->%s provided' % from_str to_str if trans is None raise ValueError '%sNone' % err_str if set [trans['from'] trans['to']] ! set [from_const to_const] raise ValueError '%stransis%s->%s' % err_str _frame_to_str[trans['from']] _frame_to_str[trans['to']] if trans['from'] ! from_const trans invert_transform trans return trans
def get_repository_dependency_tups_from_repository_metadata app repository_metadata deprecated_only False dependency_tups []if repository_metadata is not None metadata repository_metadata.metadataif metadata repository_dependencies_dict metadata.get 'repository_dependencies' None if repository_dependencies_dict is not None repository_dependency_tups repository_dependencies_dict.get 'repository_dependencies' None if repository_dependency_tups is not None for repository_dependency_tup in repository_dependency_tups toolshed name owner changeset_revision pir oicct common_util.parse_repository_dependency_tuple repository_dependency_tup repository tool_shed.util.repository_util.get_repository_by_name_and_owner app name owner if repository if deprecated_only if repository.deprecated dependency_tups.append repository_dependency_tup else dependency_tups.append repository_dependency_tup else log.debug 'Cannotlocaterepository%sownedby%sforinclusioninrepositorydependencytups.' % name owner return dependency_tups
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
@command 'r\\s? \\d{1 4} ' def related num if g.browse_mode ! 'normal' g.message 'Relateditemsmustrefertoaspecificvideoitem'g.message c.y + g.message + c.w g.content content.generate_songlist_display returng.current_page 0item g.model[ int num - 1 ]related_search item
def describe_data_brief data items OrderedDict if data is None return itemsif isinstance data SqlTable items['Datainstances'] data.approx_len else items['Datainstances'] len data items.update describe_domain_brief data.domain return items
def _connected_chordal_graph_cliques G if G.number_of_nodes 1 x frozenset G.nodes return set [x] else cliques set unnumbered set G.nodes v random.choice list unnumbered unnumbered.remove v numbered set [v] clique_wanna_be set [v] while unnumbered v _max_cardinality_node G unnumbered numbered unnumbered.remove v numbered.add v new_clique_wanna_be set G.neighbors v & numbered sg G.subgraph clique_wanna_be if _is_complete_graph sg new_clique_wanna_be.add v if not new_clique_wanna_be > clique_wanna_be cliques.add frozenset clique_wanna_be clique_wanna_be new_clique_wanna_beelse raise nx.NetworkXError 'Inputgraphisnotchordal.' cliques.add frozenset clique_wanna_be return cliques
def butterworthFilter data wPass wStop None gPass 2.0 gStop 20.0 order 1 dt None btype 'low' bidir True try import scipy.signalexcept ImportError raise Exception 'butterworthFilter requiresthepackagescipy.signal.' if dt is None try tvals data.xvals 'Time' dt tvals[ -1 ] - tvals[0] / len tvals - 1 except dt 1.0if wStop is None wStop wPass * 2.0 ord Wn scipy.signal.buttord wPass * dt * 2.0 wStop * dt * 2.0 gPass gStop b a scipy.signal.butter ord Wn btype btype return applyFilter data b a bidir bidir
def get_host_port spec default_port args spec.split ' ' 1 + [default_port] [ 2]args[1] int args[1] return args[0] args[1]
def cleanup_oauth_url redirect_uri if '?' in redirect_uri redirect_base redirect_query redirect_uri.split '?' 1 query_dict_items QueryDict redirect_query .items else query_dict_items QueryDict '' True excluded_query_items [ k v for k v in query_dict_items if k.lower in DROP_QUERY_PARAMS ]for k v in excluded_query_items redirect_uri remove_query_param redirect_uri k redirect_uri redirect_uri.strip '?' redirect_uri redirect_uri.strip '&' return redirect_uri
def cbInsecureLogin result proto username password if result.lower 'y' return proto.login username password .addCallback cbAuthentication proto return defer.fail Exception 'Loginfailedforsecurityreasons.'
def _check_color_dim val val np.atleast_2d val if val.shape[1] not in 3 4 raise RuntimeError 'Valuemusthaveseconddimensionofsize3or4' return val val.shape[1]
def get_displayable_exp_summary_dicts exploration_summaries exploration_ids [exploration_summary.id for exploration_summary in exploration_summaries]view_counts stats_jobs_continuous.StatisticsAggregator.get_views_multi exploration_ids displayable_exp_summaries []for ind exploration_summary in enumerate exploration_summaries if not exploration_summary continuesummary_dict {'id' exploration_summary.id 'title' exploration_summary.title 'activity_type' feconf.ACTIVITY_TYPE_EXPLORATION 'category' exploration_summary.category 'created_on_msec' utils.get_time_in_millisecs exploration_summary.exploration_model_created_on 'objective' exploration_summary.objective 'language_code' exploration_summary.language_code 'last_updated_msec' utils.get_time_in_millisecs exploration_summary.exploration_model_last_updated 'human_readable_contributors_summary' get_human_readable_contributors_summary exploration_summary.contributors_summary 'status' exploration_summary.status 'ratings' exploration_summary.ratings 'community_owned' exploration_summary.community_owned 'tags' exploration_summary.tags 'thumbnail_icon_url' utils.get_thumbnail_icon_url_for_category exploration_summary.category 'thumbnail_bg_color' utils.get_hex_color_for_category exploration_summary.category 'num_views' view_counts[ind]}displayable_exp_summaries.append summary_dict return displayable_exp_summaries
def has_staff_access_to_preview_mode user obj course_key None if course_key is None if isinstance obj CourseDescriptor or isinstance obj CourseOverview course_key obj.idelif isinstance obj ErrorDescriptor course_key obj.location.course_keyelif isinstance obj XModule course_key obj.descriptor.course_keyelif isinstance obj XBlock course_key obj.location.course_keyelif isinstance obj CCXLocator course_key obj.to_course_locator elif isinstance obj CourseKey course_key objelif isinstance obj UsageKey course_key obj.course_keyif course_key is None if GlobalStaff .has_user user return ACCESS_GRANTEDelse return ACCESS_DENIEDreturn _has_access_to_course user 'staff' course_key course_key
def assertRequestTransmissionFailed self deferred reasonTypes return assertWrapperExceptionTypes self deferred RequestTransmissionFailed reasonTypes
def __bootstrap__ import osimport imphere os.path.join os.path.dirname __file__ imp.load_source __name__ os.path.join here 'noname_wrapped.not_py'
def client name **kwargs return _run name 'chef.client' kwargs
def evaluate_slice_index arg if hasattr arg '__index__' return operator.index arg else raise TypeError 'sliceindicesmustbeintegersorNoneorhavean__index__method'
def test_start_detached fake_proc argv ['foo' 'bar']fake_proc._proc.startDetached.return_value True 0 fake_proc.start_detached *argv fake_proc._proc.startDetached.assert_called_with * list argv + [None]
def needs_review msg def skip_func func return skipif True msg func return skip_func
def _group_flat_tags tag tags grouped [tag]name tag.get 'name' '' .lower while tags and tags[0].get 'name' '' .lower name grouped.append tags.pop 0 return grouped
def _zfs_storagepool reactor pool FLOCKER_POOL mount_root None volume_config_path None if mount_root is None mount_root FLOCKER_MOUNTPOINTelse mount_root FilePath mount_root if volume_config_path is None config_path DEFAULT_CONFIG_PATHelse config_path FilePath volume_config_path pool zfs.StoragePool reactor reactor name pool mount_root mount_root api VolumeService config_path config_path pool pool reactor reactor api.startService return api
def repr_flag flag return u'{0}{1}{2}'.format u'R' if flag & READ else u'' u'W' if flag & WRITE else u'' u'!' if flag & ERR else u''
def _split_map_maybe function sequence marker None annotated x function x for x in sequence original mapped tee annotated return x for x y in original if y is marker y for x y in mapped if y is not marker
def iter_roots roots for saltenv dirs in six.iteritems roots for dir_ in dirs if not os.path.isdir dir_ continuefor ret in _iter_dir dir_ saltenv yield ret
def year_crumb date year date.strftime '%Y' return Crumb year reverse 'zinnia entry_archive_year' args [year]
def need_deployment if os.path.exists OPTIONS.saltdir shutil.rmtree OPTIONS.saltdir old_umask os.umask 63 os.makedirs OPTIONS.saltdir os.umask old_umask euid os.geteuid dstat os.stat OPTIONS.saltdir if dstat.st_uid ! euid need_deployment if dstat.st_mode ! 16832 need_deployment sudo_gid os.environ.get 'SUDO_GID' if sudo_gid try os.chown OPTIONS.saltdir -1 int sudo_gid stt os.stat OPTIONS.saltdir os.chmod OPTIONS.saltdir stt.st_mode | stat.S_IWGRP | stat.S_IRGRP | stat.S_IXGRP except OSError sys.stdout.write '\n\nUnabletosetpermissionsonthindirectory.\nIfsudo_userissetandisnotroot becertaintheuserisinthesamegroup\nastheloginuser' sys.exit 1 sys.stdout.write '{0}\ndeploy\n'.format OPTIONS.delimiter sys.exit EX_THIN_DEPLOY
def is_file_into_dir filename dirname try res not os.path.relpath filename dirname .startswith u'.' except ValueError res Falsereturn res
def test_singleshot timer assert not timer.isSingleShot timer.setSingleShot True assert timer.isSingleShot timer.start assert timer.isActive timer.timeout.emit assert not timer.isActive
def filtercomments source trailing_comments []comment Truewhile comment if re.search '^\\s*\\/\\*' source comment source[ 0 source.index '*/' + 2 ]elif re.search '^\\s*\\/\\/' source comment re.search '^\\s*\\/\\/' source .group 0 else comment Noneif comment source re.sub '^\\s+' '' source[len comment ] trailing_comments.append comment return '\n'.join trailing_comments + source
@click.command 'sudoers' @click.argument 'user' def setup_sudoers user from bench.utils import setup_sudoerssetup_sudoers user
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
def _make_xy_sfunc func ndim_output False if ndim_output def sfunc x y return np.array [func a y.ravel for a in x] [ 0]else def sfunc x y return np.array [func a y.ravel for a in x] sfunc.__name__ '.'.join ['score_func' func.__module__ func.__name__] sfunc.__doc__ func.__doc__return sfunc
def get_static_web_help_page return '\n<!DOCTYPEHTMLPUBLIC"-//W3C//DTDHTML4.01//EN""http //www.w3.org/TR/html4/strict.dtd">\n<html>\n<!--NaturalLanguageToolkit WordnetInterface GraphicalWordnetBrowser\nCopyright C 2001-2017NLTKProject\nAuthor JussiSalmela<jtsalmela@users.sourceforge.net>\nURL <http //nltk.org/>\nForlicenseinformation seeLICENSE.TXT-->\n<head>\n<metahttp-equiv \'Content-Type\'content \'text/html;charset us-ascii\'>\n<title>NLTKWordnetBrowserdisplayof *Help*</title>\n</head>\n<bodybgcolor \'#F5F5F5\'text \'#000000\'>\n<h2>NLTKWordnetBrowserHelp</h2>\n<p>TheNLTKWordnetBrowserisatooltouseinbrowsingtheWordnetdatabase.IttriestobehaveliketheWordnetproject\'swebbrowserbutthedifferenceisthattheNLTKWordnetBrowserusesalocalWordnetdatabase.\n<p><b>YouareusingtheJavascriptclientpartoftheNLTKWordnetBrowseServer.</b>Weassumeyourbrowserisintabsheetsenabledmode.</p>\n<p>ForbackgroundinformationonWordnet seetheWordnetprojecthomepage <ahref "http //wordnet.princeton.edu/"><b>http //wordnet.princeton.edu/</b></a>.FormoreinformationontheNLTKproject seetheprojecthome \n<ahref "http //nltk.sourceforge.net/"><b>http //nltk.sourceforge.net/</b></a>.TogetanideaofwhattheWordnetversionusedbythisbrowserincludeschoose<b>ShowDatabaseInfo</b>fromthe<b>View</b>submenu.</p>\n<h3>Wordsearch</h3>\n<p>Thewordtobesearchedistypedintothe<b>NewWord</b>fieldandthesearchstartedwithEnterorbyclickingthe<b>Search</b>button.Thereisnouppercase/lowercasedistinction thesearchwordistransformedtolowercasebeforethesearch.</p>\n<p>Inaddition theworddoesnothavetobeinbaseform.Thebrowsertriestofindthepossiblebaseform s bymakingcertainmorphologicalsubstitutions.Typing<b>fLIeS</b>asanobscureexamplegivesone<ahref "MfLIeS">this</a>.Clickthepreviouslinktoseewhatthiskindofsearchlookslikeandthencomebacktothispagebyusingthe<b>Alt+LeftArrow</b>keycombination.</p>\n<p>Theresultofasearchisadisplayofoneormore\n<b>synsets</b>foreverypartofspeechinwhichaformofthe\nsearchwordwasfoundtooccur.Asynsetisasetofwords\nhavingthesamesenseormeaning.Eachwordinasynsetthatis\nunderlinedisahyperlinkwhichcanbeclickedtotriggeran\nautomaticsearchforthatword.</p>\n<p>Everysynsethasahyperlink<b>S </b>atthestartofits\ndisplayline.Clickingthatsymbolshowsyouthenameofevery\n<b>relation</b>thatthissynsetispartof.Everyrelationnameisahyperlinkthatopensupadisplayforthatrelation.Clickingitanothertimeclosesthedisplayagain.Clickinganotherrelationnameonalinethathasanopenedrelationclosestheopenrelationandopenstheclickedrelation.</p>\n<p>Itisalsopossibletogivetwoormorewordsorcollocationstobesearchedatthesametimeseparatingthemwithacommalikethis<ahref "Mcheerup clearup">cheerup clearup</a> forexample.Clickthepreviouslinktoseewhatthiskindofsearchlookslikeandthencomebacktothispagebyusingthe<b>Alt+LeftArrow</b>keycombination.Asyoucouldseethesearchresultincludesthesynsetsfoundinthesameorderthantheformsweregiveninthesearchfield.</p>\n<p>\nTherearealsowordlevel lexical relationsrecordedintheWordnetdatabase.Openingthiskindofrelationdisplayslineswithahyperlink<b>W </b>attheirbeginning.Clickingthislinkshowsmoreinfoonthewordinquestion.</p>\n<h3>TheButtons</h3>\n<p>The<b>Search</b>and<b>Help</b>buttonsneednomoreexplanation.</p>\n<p>The<b>ShowDatabaseInfo</b>buttonshowsacollectionofWordnetdatabasestatistics.</p>\n<p>The<b>ShutdowntheServer</b>buttonisshownforthefirstclientoftheBrowServerprogrami.e.fortheclientthatisautomaticallylaunchedwhentheBrowServerisstartedbutnotforthesucceedingclientsinordertoprotecttheserverfromaccidentalshutdowns.\n</p></body>\n</html>\n'
def _aligned_zeros shape dtype float order 'C' align None dtype np.dtype dtype if align is None align dtype.alignmentif not hasattr shape '__len__' shape shape size functools.reduce operator.mul shape * dtype.itemsize buf np.empty size + align + 1 np.uint8 offset buf.__array_interface__['data'][0] % align if offset ! 0 offset align - offset buf buf[offset offset + size + 1 ][ -1 ]data np.ndarray shape dtype buf order order data.fill 0 return data
def _render_value_in_context value context value localtime value use_tz context.use_tz value localize value use_l10n context.use_l10n value force_unicode value if context.autoescape and not isinstance value SafeData or isinstance value EscapeData return escape value else return value
def check_cat_sidebar url addon cache.clear for type_ in [amo.ADDON_EXTENSION amo.ADDON_THEME amo.ADDON_SEARCH] addon.update type type_ r Client .get url assert pq r.content '#side-nav' .attr 'data-addontype' str type_
def get_users return User.find Q 'is_registered' 'eq' True
def _align_32 f pos f.tell if pos % 4 ! 0 f.seek pos + 4 - pos % 4 return
def textbrowser text None widget QtWidgets.QTextBrowser widget.setOpenExternalLinks True if text widget.setText text return widget
def agent_build_get_all context hypervisor None return IMPL.agent_build_get_all context hypervisor
def rel_has_nofollow rel return True if rel is not None and 'nofollow' in rel.split else False
def scala_library name srcs [] deps [] resources [] source_encoding None warnings None exported_deps [] provided_deps [] **kwargs target ScalaLibrary name srcs deps resources source_encoding warnings exported_deps provided_deps kwargs blade.blade.register_target target
def bokeh_issue name rawtext text lineno inliner options None content None app inliner.document.settings.env.apptry issue_num int text if issue_num < 0 raise ValueErrorexcept ValueError msg inliner.reporter.error 'Githubissuenumbermustbeanumbergreaterthanorequalto1;"%s"isinvalid.' % text line lineno prb inliner.problematic rawtext rawtext msg return [prb] [msg] node make_gh_link_node app rawtext 'issue' '#' 'issues' str issue_num options return [node] []
def hubble_deep_field return load 'hubble_deep_field.jpg'
def writebyproteinrec outprotrec handle fields GAF20FIELDS for outrec in outprotrec writerec outrec handle fields fields
def keyring_create **kwargs return ceph_cfg.keyring_create **kwargs
def get_url_prefix return getattr _local 'prefix' None
def get_prop_spec client_factory spec_type properties prop_spec client_factory.create 'ns0 PropertySpec' prop_spec.type spec_typeprop_spec.pathSet propertiesreturn prop_spec
def add_caching_to_response response request None etag None if not etag if 'Cache-Control' not in response.headers response.headers['Cache-Control'] 'no-cache'returnassert request is not None if response.code not in 200 304 returnresponse.headers['Etag'] etagif 'Access-Control-Allow-Origin' not in response.headers response.headers['Access-Control-Allow-Origin'] 'https //gratipay.com'if request.line.uri.querystring.get 'etag' response.headers['Cache-Control'] 'public max-age 31536000'else response.headers['Cache-Control'] 'public max-age 5'
def is_eligible_node node if node._id POPULAR_LINKS_NODE or node._id NEW_AND_NOTEWORTHY_LINKS_NODE return Falsefor contrib in node.contributors if contrib._id in NEW_AND_NOTEWORTHY_CONTRIBUTOR_BLACKLIST logger.info 'Node{}skippedbecauseacontributor {} isblacklisted.'.format node._id contrib._id return Falsereturn True
def _get_gating_info course xblock info {}if xblock.category 'sequential' and course.enable_subsection_gating if not hasattr course 'gating_prerequisites' setattr course 'gating_prerequisites' gating_api.get_prerequisites course.id info['is_prereq'] gating_api.is_prerequisite course.id xblock.location info['prereqs'] [p for p in course.gating_prerequisites if unicode xblock.location not in p['namespace'] ] prereq prereq_min_score gating_api.get_required_content course.id xblock.location info['prereq'] prereqinfo['prereq_min_score'] prereq_min_scoreif prereq info['visibility_state'] VisibilityState.gatedreturn info
def _verts_within_dist graph sources max_dist dist_map {}verts_added_last []for source in sources dist_map[source] 0verts_added_last.append source while len verts_added_last > 0 verts_added []for i in verts_added_last v_dist dist_map[i]row graph[i ]neighbor_vert row.indicesneighbor_dist row.datafor j d in zip neighbor_vert neighbor_dist n_dist v_dist + d if j in dist_map if n_dist < dist_map[j] dist_map[j] n_distelif n_dist < max_dist dist_map[j] n_distverts_added.append j verts_added_last verts_addedverts np.sort np.array list dist_map.keys dtype np.int dist np.array [dist_map[v] for v in verts] return verts dist
def _datetime_from_microseconds value return _EPOCH + datetime.timedelta microseconds value
def fixed_ip_update context address values return IMPL.fixed_ip_update context address values
def getWindowGivenTextRepository fileName gcodeText repository skein SkeinlayerSkein skein.parseGcode fileName gcodeText repository return SkeinWindow repository skein
def scale_for_robust_loss_function J f rho J_scale rho[1] + 2 * rho[2] * f ** 2 J_scale[ J_scale < EPS ] EPSJ_scale ** 0.5f * rho[1] / J_scale return left_multiply J J_scale copy False f
def rand_char bad '' chars allchars return rand_base 1 bad chars
def sample2d f x_args try f sympify f except SympifyError raise ValueError 'fcouldnotbeinterprettedasaSymPyfunction' try x x_min x_max x_n x_argsexcept AttributeError raise ValueError 'x_argsmustbeatupleoftheform var min max n ' x_l float x_max - x_min x_d x_l / float x_n X np.arange float x_min float x_max + x_d x_d Y np.empty len X for i in range len X try Y[i] float f.subs x X[i] except TypeError Y[i] Nonereturn X Y
def notify notificationName message if sabnzbd.FOUNDATION pool Foundation.NSAutoreleasePool.alloc .init nc Foundation.NSDistributedNotificationCenter.defaultCenter nc.postNotificationName_object_ notificationName message del pool
def _eager_tasklet tasklet @utils.wrapping tasklet def eager_wrapper *args **kwds fut tasklet *args **kwds _run_until_rpc return futreturn eager_wrapper
def decorate_numtips tree for n in tree.postorder include_self True if n.istip n.Score 1else n.Score len n.tips return tree
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def example1_build_temple x y **kwargs room create_object rooms.Room key 'temple' + str x + str y room.db.desc "Inwhat fromtheoutside appearedtobeagrandandancienttempleyou'vesomehowfoundyourselfinthetheEvenniaInn!Itconsistsofonelargeroomfilledwithtables.Thebardiskextendsalongtheeastwall wheremultiplebarrelsandbottleslinetheshelves.Thebarkeepseemsbusyhandingoutaleandchattingwiththepatrons whicharearowdyandcheerfullot keepingthesoundlevelonlyjustbelowthunderous.Thisisararespotofmirthonthisdreadmoor."kwargs['caller'].msg room.key + '' + room.dbref return room
def test_instance_stack_is_not_the_same_as_class_level class MyFs io.FileSystem passMyFs.stack.append 'foo' MyFs.stack.append 'bar' assert_equals MyFs .stack []
def validate_runner_parameter_attribute_override action_ref param_name attr_name runner_param_attr_value action_param_attr_value param_values_are_the_same action_param_attr_value runner_param_attr_value if attr_name not in RUNNER_PARAM_OVERRIDABLE_ATTRS and not param_values_are_the_same raise InvalidActionParameterException 'Theattribute"%s"fortherunnerparameter"%s"inaction"%s"cannotbeoverridden.' % attr_name param_name action_ref return True
def threshold_isodata image nbins 256 return_all False hist bin_centers histogram image.ravel nbins if len bin_centers 1 if return_all return bin_centerselse return bin_centers[0]hist hist.astype np.float32 csuml np.cumsum hist csumh np.cumsum hist[ -1 ] [ -1 ] - hist intensity_sum hist * bin_centers csumh[ -1 ] 1l np.cumsum intensity_sum / csuml h np.cumsum intensity_sum[ -1 ] [ -1 ] - intensity_sum / csumh all_mean l + h / 2.0 bin_width bin_centers[1] - bin_centers[0] distances all_mean - bin_centers thresholds bin_centers[ distances > 0 & distances < bin_width ]if return_all return thresholdselse return thresholds[0]
def auth_decorator check_auth def decorator method def decorated self *args **kwargs check_auth self return method self *args **kwargs decorated.__name__ method.__name__decorated.__doc__ method.__doc__return decorateddecorator.__name__ check_auth.__name__decorator.__doc__ check_auth.__doc__return decorator
def context_from_sample api keywords dirname desc uri if uri is None uri BASE_HG_URI + dirname.replace '/' '%2F' else uri ''.join uri if api is None return Noneelse entry DIRECTORY[api]context {'api' api 'version' entry['version'] 'api_name' wiki_escape entry.get 'title' entry.get 'description' 'api_desc' wiki_escape entry['description'] 'api_icon' entry['icons']['x32'] 'keywords' keywords 'dir' dirname 'uri' uri 'desc' wiki_escape desc }return context
def genelatex body wrap lt LaTeXTool.instance breqn wrap and lt.use_breqn and kpsewhich 'breqn.sty' yield u '\\documentclass{article}' packages lt.packagesif breqn packages packages + ['breqn'] for pack in packages yield u '\\usepackage{{{0}}}'.format pack yield u '\\pagestyle{empty}' if lt.preamble yield lt.preamble yield u '\\begin{document}' if breqn yield u '\\begin{dmath*}' yield body yield u '\\end{dmath*}' elif wrap yield u'$${0}$$'.format body else yield body yield u'\\end{document}'
def _cg_simp_add e cg_part []other_part []e expand e for arg in e.args if arg.has CG if isinstance arg Sum other_part.append _cg_simp_sum arg elif isinstance arg Mul terms 1for term in arg.args if isinstance term Sum terms * _cg_simp_sum term else terms * termif terms.has CG cg_part.append terms else other_part.append terms else cg_part.append arg else other_part.append arg cg_part other _check_varsh_871_1 cg_part other_part.append other cg_part other _check_varsh_871_2 cg_part other_part.append other cg_part other _check_varsh_872_9 cg_part other_part.append other return Add *cg_part + Add *other_part
def _overload_dummy *args **kwds raise NotImplementedError u'Youshouldnotcallanoverloadedfunction.Aseriesof@overload-decoratedfunctionsoutsideastubmoduleshouldalwaysbefollowedbyanimplementationthatisnot@overload-ed.'
def tidy_input_string s s ''.join s.split .lower return s
def x509_verify cacert cert binary False ca x509_parse_cert cacert crt x509_parse_cert cert binary return crt.verify ca.get_pubkey
def choice_validator optdict name value if not value in optdict['choices'] msg 'option%s invalidvalue %r shouldbein%s'raise optik_ext.OptionValueError msg % name value optdict['choices'] return value
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def _prepare_nodes workflow root objs serializers.deserialize 'xml' etree.tostring root node Nonenodes []for obj in objs obj.object.workflow workflowif type obj.object is Node node obj.objectelse node.node_type obj.object.node_typefull_node obj.objectfor k v in vars node .items if not k.startswith '_' and k not in 'node_type' 'workflow' 'node_ptr_id' setattr full_node k v full_node.workflow workflowfull_node.node_type type full_node .node_typefull_node.node_ptr_id Nonefull_node.id Nonenodes.append full_node return nodes
def init_spider_log spider_global_variable spider_logger logging.getLogger 'MSpiderLogs' spider_logger.setLevel logging.DEBUG console_handler logging.StreamHandler console_handler.setLevel logging.DEBUG formatter logging.Formatter '[% asctime s][% levelname s]% message s' console_handler.setFormatter formatter spider_logger.addHandler console_handler spider_global_variable.spider_logger spider_loggerspider_logger.info 'WelcometoMspider!!!' spider_logger.info '---------------------------'
def reconstruct A B z f factorint igcd A B for p e in f.items if e ! 1 raise ValueError 'aandbshouldbesquare-free' z * preturn z
def str_to_date string return datetime.strptime string config.DATE_FORMAT if string else None
def _authenticated func @functools.wraps func def func_wrapper driver *args **kwargs try return func driver *args **kwargs except exception.NotAuthorized if args[0] 'login' raisedriver.login return func driver *args **kwargs return func_wrapper
def make_channel host port credentials _ google.auth.default scopes [SPEECH_SCOPE] http_request google.auth.transport.requests.Request target '{} {}'.format host port return google.auth.transport.grpc.secure_authorized_channel credentials http_request target
def EC2Token_filter_factory global_conf **local_conf conf global_conf.copy conf.update local_conf def filter app return EC2Token app conf return filter
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def default_help_formatter quick_helps ret ''for line in quick_helps cmd_path param_hlp cmd_hlp lineret + ''.join cmd_path + '' if param_hlp ret + param_hlp + '' ret + '-' + cmd_hlp + '\n' return ret
def _disk_profile profile hypervisor **kwargs default [{'system' {'size' '8192'}}]if hypervisor in ['esxi' 'vmware'] overlay {'format' 'vmdk' 'model' 'scsi' 'pool' '[{0}]'.format kwargs.get 'pool' '0' }elif hypervisor in ['qemu' 'kvm'] overlay {'format' 'qcow2' 'model' 'virtio' 'pool' __salt__['config.option'] 'virt.images' }else overlay {}disklist __salt__['config.get'] 'virt disk' {} .get profile default for key val in six.iteritems overlay for i disks in enumerate disklist for disk in disks if key not in disks[disk] disklist[i][disk][key] valreturn disklist
def init mpstate return CmdlongModule mpstate
def convert_to_relative basePath fileName if fileName.startswith basePath fileName fileName.replace basePath u'' if fileName.startswith os.path.sep fileName fileName[1 ]return fileName
def suspend_to_ram set_power_state 'mem'
@pytest.mark.skipif sys.version_info[ 2] < 3 3 reason 'Python3.4+showschainedexceptionsonmultiprocess' def test_exception_handling_no_traceback testdir p1 testdir.makepyfile '\nfrommultiprocessingimportPool\n\ndefprocess_task n \nassertn 10\n\ndefmultitask_job \ntasks [1]\nwithPool processes 1 aspool \npool.map process_task tasks \n\ndeftest_multitask_job \nmultitask_job \n' result testdir.runpytest p1 '--tb long' result.stdout.fnmatch_lines [' *FAILURES* ' '*multiprocessing.pool.RemoteTraceback *' 'Traceback mostrecentcalllast ' '*assertn 10' 'Theaboveexceptionwasthedirectcauseofthefollowingexception ' '>*multitask_job ']
def sequence seq limits None seq sympify seq if is_sequence seq Tuple return SeqPer seq limits else return SeqFormula seq limits
def find_invited_user email default None User apps.get_model settings.AUTH_USER_MODEL try return User.objects.get email email except User.DoesNotExist return default
def condense_hex_colors css regex re.compile ' [^\\"\' \\s] \\s* # [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] ' match regex.search css while match first match.group 3 + match.group 5 + match.group 7 second match.group 4 + match.group 6 + match.group 8 if first.lower second.lower css css.replace match.group match.group 1 + match.group 2 + '#' + first match regex.search css match.end - 3 else match regex.search css match.end return css
def p_integer t t[0] t[1]
def dup_resultant f g K includePRS False if includePRS return dup_prs_resultant f g K return dup_prs_resultant f g K [0]
def _recursive_escape value esc conditional_escape if isinstance value dict return type value esc k _recursive_escape v for k v in value.iteritems elif isinstance value list tuple return type value _recursive_escape v for v in value elif isinstance value basestring return esc value elif isinstance value int long float or value in True False None return valuereturn esc DjangoJSONEncoder .default value
def central_diff_weights Np ndiv 1 if Np < ndiv + 1 raise ValueError 'Numberofpointsmustbeatleastthederivativeorder+1.' if Np % 2 0 raise ValueError 'Thenumberofpointsmustbeodd.' from scipy import linalgho Np >> 1 x arange - ho ho + 1.0 x x[ newaxis]X x ** 0.0 for k in range 1 Np X hstack [X x ** k ] w product arange 1 ndiv + 1 axis 0 * linalg.inv X [ndiv] return w
def placeholder *args **kwargs warnings.simplefilter 'default' DeprecationWarning warnings.warn 'ed.placeholder isdeprecated;usetf.placeholder instead.' DeprecationWarning x tf.placeholder *args **kwargs tf.add_to_collection 'PLACEHOLDERS' x return x
def getMedian alist tmp list alist tmp.sort alen len tmp if alen % 2 1 return tmp[ alen // 2 ]else return tmp[ alen // 2 ] + tmp[ alen // 2 - 1 ] / 2
def tree_selection_items tree_item selected []for idx in range tree_item.childCount child tree_item.child idx if child.isSelected selected.append child return selected
def month_plot x dates None ylabel None ax None from pandas import DataFrameif dates is None from statsmodels.tools.data import _check_period_index_check_period_index x freq 'M' else from pandas import Series PeriodIndexx Series x index PeriodIndex dates freq 'M' xticklabels ['j' 'f' 'm' 'a' 'm' 'j' 'j' 'a' 's' 'o' 'n' 'd']return seasonal_plot x.groupby lambda y y.month xticklabels ylabel ylabel ax ax
def initial_state_with_taps layer dimensions None state initial_state layer dimensions if state is not None return dict initial state taps [ -1 ] else return None
def _show image title class UI tkinter.Label def __init__ self master im if im.mode '1' self.image BitmapImage im foreground 'white' master master else self.image PhotoImage im master master tkinter.Label.__init__ self master image self.image bg 'black' bd 0 if not tkinter._default_root raise IOError 'tkinternotinitialized' top tkinter.Toplevel if title top.title title UI top image .pack
def modelformset_factory model form ModelForm formfield_callback None formset BaseModelFormSet extra 1 can_delete False can_order False max_num None fields None exclude None form modelform_factory model form form fields fields exclude exclude formfield_callback formfield_callback FormSet formset_factory form formset extra extra max_num max_num can_order can_order can_delete can_delete FormSet.model modelreturn FormSet
def UnicodeFromCodePage string codepage ctypes.windll.kernel32.GetOEMCP try return string.decode 'cp%s' % codepage except UnicodeError try return string.decode 'utf16' 'ignore' except UnicodeError return string.decode 'utf8' 'ignore'
def _url_to_local_path url path destination urllib.parse.urlparse url .pathif len destination < 2 or destination[0] ! '/' raise ValueError 'InvalidURL' destination os.path.join path urllib.request.url2pathname destination [1 ] return destination
def replace_argument script from_ to replaced_in_the_end re.sub u'{}$'.format re.escape from_ u'{}'.format to script count 1 if replaced_in_the_end ! script return replaced_in_the_endelse return script.replace u'{}'.format from_ u'{}'.format to 1
def string_to_bitlist data data [ord c for c in data]result []for ch in data i 7while i > 0 if ch & 1 << i ! 0 result.append 1 else result.append 0 i - 1return result
def _setDNSCache def _getaddrinfo *args **kwargs if args in kb.cache.addrinfo return kb.cache.addrinfo[args]else kb.cache.addrinfo[args] socket._getaddrinfo *args **kwargs return kb.cache.addrinfo[args]if not hasattr socket '_getaddrinfo' socket._getaddrinfo socket.getaddrinfosocket.getaddrinfo _getaddrinfo
def p_primary_expression t pass
def _consensus_alphabet alphabets base _consensus_base_alphabet alphabets gap Nonestop Nonenew_letters ''for alpha in alphabets if not hasattr alpha 'gap_char' passelif gap is None gap alpha.gap_charelif gap alpha.gap_char passelse raise ValueError 'Morethanonegapcharacterpresent' if not hasattr alpha 'stop_symbol' passelif stop is None stop alpha.stop_symbolelif stop alpha.stop_symbol passelse raise ValueError 'Morethanonestopsymbolpresent' if hasattr alpha 'new_letters' for letter in alpha.new_letters if letter not in new_letters and letter ! gap and letter ! stop new_letters + letteralpha baseif new_letters alpha AlphabetEncoder alpha new_letters if gap alpha Gapped alpha gap_char gap if stop alpha HasStopCodon alpha stop_symbol stop return alpha
def lat2zone lat zone int round lat / 8.0 + 9.5 return 'CDEFGHJKLMNPQRSTUVWX'[zone]
def list_of_true_keys d ret []for key in d if d[key] ret.append key return ret
def validate_settings from django.conf import settingsfrom django_facebook import settings as facebook_settingsif facebook_settings.FACEBOOK_SKIP_VALIDATE returnif not facebook_settings.FACEBOOK_APP_ID logger.warn u'WarningFACEBOOK_APP_IDisntspecified' if not facebook_settings.FACEBOOK_APP_SECRET logger.warn u'WarningFACEBOOK_APP_SECRETisntspecified' if facebook_settings.FACEBOOK_STORE_LIKES or facebook_settings.FACEBOOK_STORE_FRIENDS if not facebook_settings.FACEBOOK_CELERY_STORE msg u'StoringfriendsorlikeswithoutusingCelerywillsignificantlyslowdownyourlogin\nItsrecommendedtoenableFACEBOOK_CELERY_STOREordisableFACEBOOK_STORE_FRIENDSandFACEBOOK_STORE_LIKES'logger.warn msg required [u'django_facebook.context_processors.facebook' u'django.core.context_processors.request']context_processors settings.TEMPLATE_CONTEXT_PROCESSORSfor context_processor in required if context_processor not in context_processors logger.warn u'Requiredcontextprocessor%swasntfound' context_processor backends settings.AUTHENTICATION_BACKENDSrequired u'django_facebook.auth_backends.FacebookBackend'if required not in backends logger.warn u'Requiredauthbackend%swasntfound' required
def prettify_index index initial_indent 3 indent '' * initial_indent output 'kind {}\n'.format index.entity_type if index.ancestor output + '{}ancestor yes\n'.format indent output + '{}properties \n'.format indent for prop in index.property_list output + '{}-name {}\n'.format indent prop.name if prop.direction prop.DESCENDING output + '{}direction desc\n'.format indent + '' return output
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
@typeof_impl.register type def typeof_type val c if issubclass val BaseException return types.ExceptionClass val if issubclass val tuple and hasattr val '_asdict' return types.NamedTupleClass val
def cxOracle_py3_bug func from unittest import expectedFailurefrom django.db import connectionreturn expectedFailure func if connection.vendor 'oracle' else func
@lower_builtin 'number.item' types.Boolean @lower_builtin 'number.item' types.Number def number_item_impl context builder sig args return args[0]
def _sqrtdenest0 expr if is_sqrt expr n d expr.as_numer_denom if d is S.One if n.base.is_Add args sorted n.base.args key default_sort_key if len args > 2 and all x ** 2 .is_Integer for x in args try return _sqrtdenest_rec n except SqrtdenestStopIteration passexpr sqrt _mexpand Add *[_sqrtdenest0 x for x in args] return _sqrtdenest1 expr else n d [_sqrtdenest0 i for i in n d ]return n / d if isinstance expr Expr args expr.argsif args return expr.func *[_sqrtdenest0 a for a in args] return expr
def get_exploration_from_model exploration_model run_conversion True versioned_exploration_states {'states_schema_version' exploration_model.states_schema_version 'states' copy.deepcopy exploration_model.states }if run_conversion and exploration_model.states_schema_version ! feconf.CURRENT_EXPLORATION_STATES_SCHEMA_VERSION _migrate_states_schema versioned_exploration_states return exp_domain.Exploration exploration_model.id exploration_model.title exploration_model.category exploration_model.objective exploration_model.language_code exploration_model.tags exploration_model.blurb exploration_model.author_notes exploration_model.skin_customizations versioned_exploration_states['states_schema_version'] exploration_model.init_state_name versioned_exploration_states['states'] exploration_model.param_specs exploration_model.param_changes exploration_model.version created_on exploration_model.created_on last_updated exploration_model.last_updated
def varmap func var context None name None if context is None context set objid id var if objid in context return func name '<...>' context.add objid if isinstance var dict ret dict k varmap func v context k for k v in six.iteritems var elif isinstance var list tuple if all isinstance v list tuple and len v 2 for v in var ret [[k varmap func v context k ] for k v in var]else ret [varmap func f context name for f in var]else ret func name var context.remove objid return ret
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _url_collapse_path path path_parts path.split '/' head_parts []for part in path_parts[ -1 ] if part '..' head_parts.pop elif part and part ! '.' head_parts.append part if path_parts tail_part path_parts.pop if tail_part if tail_part '..' head_parts.pop tail_part ''elif tail_part '.' tail_part ''else tail_part ''splitpath '/' + '/'.join head_parts tail_part collapsed_path '/'.join splitpath return collapsed_path
def encipher_rsa i key n e keyreturn pow i e n
def change_password username password _xml '<RIBCLVERSION "2.0">\n<LOGINUSER_LOGIN "adminname"PASSWORD "password">\n<USER_INFOMODE "write">\n<MOD_USERUSER_LOGIN "{0}">\n<PASSWORDvalue "{1}"/>\n</MOD_USER>\n</USER_INFO>\n</LOGIN>\n</RIBCL>'.format username password return __execute_cmd 'Change_password' _xml
def _find_observable_paths extra_files None rv set os.path.abspath x for x in sys.path for filename in extra_files or rv.add os.path.dirname os.path.abspath filename for module in list sys.modules.values fn getattr module '__file__' None if fn is None continuefn os.path.abspath fn rv.add os.path.dirname fn return _find_common_roots rv
def label_add_hosts id hosts host_objs models.Host.smart_get_bulk hosts label models.Label.smart_get id if label.platform models.Host.check_no_platform host_objs label.host_set.add *host_objs
@parse_data@set_databasedef get_content_parents ids None **kwargs if ids Parent Item.alias parent_values Item.select Parent .join Parent on Item.parent Parent.pk .where Item.id.in_ ids .distinct if parent_values is None parent_values list return parent_valueselse return list
def index_to_three i return dindex_to_3[i]
def toUTF8 s return s.encode 'utf_8'
def max_clique G if G is None raise ValueError 'ExpectedNetworkXgraph!' cgraph nx.complement G iset _ clique_removal cgraph return iset
def bitbucket registry xml_parent data bbtrig XML.SubElement xml_parent 'com.cloudbees.jenkins.plugins.BitBucketTrigger' XML.SubElement bbtrig 'spec' .text ''
def _tupleize dct return [ key val for key val in dct.items ]
def getInsetPointsByInsetLoop insetLoop inside loops radius insetPointsByInsetLoop []for pointIndex in xrange len insetLoop pointBegin insetLoop[ pointIndex + len insetLoop - 1 % len insetLoop ]pointCenter insetLoop[pointIndex]pointEnd insetLoop[ pointIndex + 1 % len insetLoop ]if getIsInsetPointInsideLoops inside loops pointBegin pointCenter pointEnd radius insetPointsByInsetLoop.append pointCenter return insetPointsByInsetLoop
def save_form form update_user None is_draft True **kwargs obj super MediaForm form .save commit False **kwargs if update_user obj.updated_by update_userobj.is_draft is_draftobj.save return obj
def _read_pcfg_production input return _read_production input standard_nonterm_parser probabilistic True
@image_comparison baseline_images [u'legend_auto1'] remove_text True def test_legend_auto1 fig plt.figure ax fig.add_subplot 111 x np.arange 100 ax.plot x 50 - x u'o' label u'y 1' ax.plot x x - 50 u'o' label u'y -1' ax.legend loc 0
def rbf x y 0.0 sigma 1.0 l 1.0 x tf.convert_to_tensor x y tf.convert_to_tensor y sigma tf.convert_to_tensor sigma l tf.convert_to_tensor l dependencies [tf.verify_tensor_all_finite x msg '' tf.verify_tensor_all_finite y msg '' tf.assert_positive sigma tf.assert_positive l ]x control_flow_ops.with_dependencies dependencies x y control_flow_ops.with_dependencies dependencies y sigma control_flow_ops.with_dependencies dependencies sigma l control_flow_ops.with_dependencies dependencies l return tf.pow sigma 2.0 * tf.exp -1.0 / 2.0 * tf.pow l 2.0 * tf.pow x - y 2.0
def info return _nodetool 'info'
def altz_to_utctz_str altz utci -1 * int float altz / 3600 * 100 utcs str abs utci utcs '0' * 4 - len utcs + utcs prefix utci < 0 and '-' or '+' return prefix + utcs
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def locate_config apache_ctl try proc subprocess.Popen [apache_ctl '-V'] stdout subprocess.PIPE stderr subprocess.PIPE output _ proc.communicate except OSError sys.exit _NO_APACHECTL server_root config_file ''for line in output.splitlines if 'HTTPD_ROOT' in line server_root line[ line.find '"' + 1 -1 ]elif 'SERVER_CONFIG_FILE' in line config_file line[ line.find '"' + 1 -1 ]if not server_root and config_file sys.exit 'UnabletolocateApacheconfiguration.Pleaserunthisscriptagainandspecify--server-rootand--config-file' return server_root config_file
def ModularIntegerFactory _mod _dom _sym parent try _mod _dom.convert _mod except CoercionFailed ok Falseelse ok Trueif not ok or _mod < 1 raise ValueError 'modulusmustbeapositiveinteger got%s' % _mod key _mod _dom _sym try cls _modular_integer_cache[key]except KeyError class cls ModularInteger mod dom sym _mod _dom _sym _parent parentif _sym cls.__name__ 'SymmetricModularIntegerMod%s' % _mod else cls.__name__ 'ModularIntegerMod%s' % _mod _modular_integer_cache[key] clsreturn cls
def new_figure_manager num *args **kwargs FigureClass kwargs.pop 'FigureClass' Figure thisFig FigureClass *args **kwargs canvas FigureCanvasTemplate thisFig manager FigureManagerTemplate canvas num return manager
def _get_key_id alias region None key None keyid None profile None key_metadata describe_key alias region key keyid profile ['key_metadata']return key_metadata['KeyId']
def get_next_redirect_url request redirect_field_name 'next' redirect_to get_request_param request redirect_field_name if not get_adapter request .is_safe_url redirect_to redirect_to Nonereturn redirect_to
def get_deps_all return {'hiddenimports' sorted set kivy_modules + collect_submodules 'kivy.core' 'excludes' []}
def _get_test_tolerance type_char mattype None rtol {'f' 3000 * np.finfo np.float32 .eps 'F' 3000 * np.finfo np.float32 .eps 'd' 2000 * np.finfo np.float64 .eps 'D' 2000 * np.finfo np.float64 .eps }[type_char]atol rtoltol 0if mattype is aslinearoperator and type_char in 'f' 'F' tol 30 * np.finfo np.float32 .eps rtol * 5if mattype is csr_matrix and type_char in 'f' 'F' rtol * 5return tol rtol atol
def validate_key_csr privkey csr None if privkey.pem and not crypto_util.valid_privkey privkey.pem raise errors.Error 'Theprovidedkeyisnotavalidkey' if csr if csr.form 'der' csr_obj OpenSSL.crypto.load_certificate_request OpenSSL.crypto.FILETYPE_ASN1 csr.data csr util.CSR csr.file OpenSSL.crypto.dump_certificate OpenSSL.crypto.FILETYPE_PEM csr_obj 'pem' if csr.data and not crypto_util.valid_csr csr.data raise errors.Error 'TheprovidedCSRisnotavalidCSR' if csr.data and privkey.pem if not crypto_util.csr_matches_pubkey csr.data privkey.pem raise errors.Error 'ThekeyandCSRdonotmatch'
def test_reset_in _ip.run_cell 'parrot' store_history True nt.assert_true 'parrot' in [_ip.user_ns[x] for x in '_i' '_ii' '_iii' ] _ip.magic '%reset-fin' nt.assert_false 'parrot' in [_ip.user_ns[x] for x in '_i' '_ii' '_iii' ] nt.assert_equal len set _ip.user_ns['In'] 1
def _patch_cmdutils monkeypatch stubs symbol cmd_utils stubs.FakeCmdUtils {'stop' stubs.FakeCommand name 'stop' desc 'stopqutebrowser' 'drop' stubs.FakeCommand name 'drop' desc 'dropalluserdata' 'roll' stubs.FakeCommand name 'roll' desc 'nevergonnagiveyouup' 'hide' stubs.FakeCommand name 'hide' hide True 'depr' stubs.FakeCommand name 'depr' deprecated True } monkeypatch.setattr symbol cmd_utils
def NO_MERGE writer segments return segments
def get_period_alias offset_str return _offset_to_period_map.get offset_str None
def get_poem def canceler d delayed_call.cancel d Deferred canceler from twisted.internet import reactordelayed_call reactor.callLater 5 send_poem d return d
def test_flaskgroup def create_app info return Flask 'flaskgroup' @click.group cls FlaskGroup create_app create_app def cli **params pass@cli.command def test click.echo current_app.name runner CliRunner result runner.invoke cli ['test'] assert result.exit_code 0 assert result.output 'flaskgroup\n'
def dhcp_options_exists dhcp_options_id None name None dhcp_options_name None tags None region None key None keyid None profile None if name log.warning 'boto_vpc.dhcp_options_exists nameparameterisdeprecatedusedhcp_options_nameinstead.' dhcp_options_name namereturn resource_exists 'dhcp_options' name dhcp_options_name resource_id dhcp_options_id tags tags region region key key keyid keyid profile profile
def css_escape s s re.sub ' ^-$|[!"#\\$%&\\\' *+ ./ ;< >?@\\[\\\\\\]^`{|}~] ' '\\\\\\1' s s re.sub '^ -? \\d ' lambda m '%s\\%x' % m.group 1 ord m.group 2 s s re.sub ' [\\t\\n\\v\\f\\r] ' lambda m '\\%x' % ord m.group 1 s return s
@FileSystem.in_directory current_directory 'django' 'alfaces' def test_limit_by_app_getting_all_apps_by_comma status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 3--no-color--apps foobar donothing' assert_equals status 0 out assert 'TestthedjangoappDONOTHING' in out assert 'TestthedjangoappFOOBAR' in out
def forgiving_round value precision 0 try value round float value precision return int value if precision 0 else value except ValueError TypeError return value
def object_upload_file self Filename ExtraArgs None Callback None Config None return self.meta.client.upload_file Filename Filename Bucket self.bucket_name Key self.key ExtraArgs ExtraArgs Callback Callback Config Config
def libvlc_media_player_get_media p_mi f _Cfunctions.get 'libvlc_media_player_get_media' None or _Cfunction 'libvlc_media_player_get_media' 1 class_result Media ctypes.c_void_p MediaPlayer return f p_mi
def make_template resource_definitions version 'heat_template_version' '2015-04-30' child_env None tmpl template.Template dict [version] env child_env for name defn in resource_definitions tmpl.add_resource defn name return tmpl
def remove_record module gcdns record overwrite module.boolean module.params['overwrite'] ttl module.params['ttl']record_data module.params['record_data']if record is None return Falseif not overwrite if not _records_match record.data['ttl'] record.data['rrdatas'] ttl record_data module.fail_json msg 'cannotdeleteduetonon-matchingttlorrecord_data ' + 'ttl %d record_data %s' % ttl record_data + 'originalttl %d originalrecord_data %s' % record.data['ttl'] record.data['rrdatas'] changed False if not module.check_mode gcdns.delete_record record return True
def getModelParamsFromName gymName importName 'model_params.%s_model_params' % gymName.replace '' '_' .replace '-' '_' print 'Importingmodelparamsfrom%s' % importName try importedModelParams importlib.import_module importName .MODEL_PARAMSexcept ImportError raise Exception "Nomodelparamsexistfor'%s'.Runswarmfirst!" % gymName return importedModelParams
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field.source in validated_data and isinstance validated_data[field.source] list dict for field in serializer._writable_fields u'The`.{method_name} `methoddoesnotsupportwritablenestedfieldsbydefault.\nWriteanexplicit`.{method_name} `methodforserializer`{module}.{class_name}` orset`read_only True`onnestedserializerfields.'.format method_name method_name module serializer.__class__.__module__ class_name serializer.__class__.__name__ assert not any u'.' in field.source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer.fields.items u'The`.{method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault.\nWriteanexplicit`.{method_name} `methodforserializer`{module}.{class_name}` orset`read_only True`ondotted-sourceserializerfields.'.format method_name method_name module serializer.__class__.__module__ class_name serializer.__class__.__name__
def clean_global_runtime_state reset_runtracker True reset_subsystem False if reset_runtracker RunTracker.global_instance .reset reset_options False if reset_subsystem Subsystem.reset IntermediateTargetFactoryBase.reset Goal.clear OptionsInitializer.reset
def require_global_staff func @wraps func def wrapped request *args **kwargs if GlobalStaff .has_user request.user return func request *args **kwargs else return HttpResponseForbidden u'Mustbe{platform_name}stafftoperformthisaction.'.format platform_name settings.PLATFORM_NAME return login_required wrapped
def is_websocket headers return 'upgrade' in headers.get 'Connection' '' .lower and headers.get 'Upgrade' .lower 'websocket'
def basecompiledir_ls subdirs []others []for f in os.listdir config.base_compiledir if os.path.isdir os.path.join config.base_compiledir f subdirs.append f else others.append f subdirs sorted subdirs others sorted others print 'Basecompilediris%s' % theano.config.base_compiledir print 'Sub-directories possiblecompilecaches ' for d in subdirs print '%s' % d if not subdirs print ' None ' if others print print 'Otherfilesinbase_compiledir ' for f in others print '%s' % f
def getproxies_environment proxies {}for name value in os.environ.items name name.lower if value and name[ -6 ] '_proxy' proxies[name[ -6 ]] valuereturn proxies
def init mpstate return CmdlongModule mpstate
def ignore_patterns *patterns def _ignore_patterns path names ignored_names []for pattern in patterns ignored_names.extend fnmatch.filter names pattern return set ignored_names return _ignore_patterns
def ExpandWindowsEnvironmentVariables data_string knowledge_base win_environ_regex re.compile '% [^%]+? %' components []offset 0for match in win_environ_regex.finditer data_string components.append data_string[offset match.start ] kb_value getattr knowledge_base 'environ_%s' % match.group 1 .lower None if isinstance kb_value basestring and kb_value components.append kb_value else components.append '%%%s%%' % match.group 1 offset match.end components.append data_string[offset ] return ''.join components
def update_user_library library for stylelib_path in iter_user_libraries styles read_style_directory stylelib_path update_nested_dict library styles return library
def test_get_version test_apps capsys from flask import __version__ as flask_verfrom sys import version as py_verclass MockCtx object resilient_parsing Falsecolor Nonedef exit self returnctx MockCtx get_version ctx None 'test' out err capsys.readouterr assert flask_ver in out assert py_ver in out
def gf_crt1 M K E S [] [] p prod M start K.one for m in M E.append p // m S.append K.gcdex E[ -1 ] m [0] % m return p E S
def trg_trigger uid res_type res_id cr return WorkflowService.new cr uid res_type res_id .trigger
def FTOU val return val
@receiver user_registered @receiver local_site_user_added def _add_default_groups sender user local_site None **kwargs if local_site default_groups local_site.groups.filter is_default_group True else default_groups Group.objects.filter is_default_group True local_site None for default_group in default_groups default_group.users.add user
def get_user_by_username_or_email username_or_email if '@' in username_or_email return User.objects.get email username_or_email else return User.objects.get username username_or_email
def zmq_version_info major ffi.new 'int*' minor ffi.new 'int*' patch ffi.new 'int*' C.zmq_version major minor patch return int major[0] int minor[0] int patch[0]
def _integrate_plugins import sysfrom airflow.plugins_manager import macros_modulesfor macros_module in macros_modules sys.modules[macros_module.__name__] macros_moduleglobals [macros_module._name] macros_moduleimport os as _osif not _os.environ.get 'AIRFLOW_USE_NEW_IMPORTS' False from zope.deprecation import deprecated as _deprecatedfor _macro in macros_module._objects macro_name _macro.__name__globals [macro_name] _macro_deprecated macro_name "Importingpluginmacro'{i}'directlyfrom'airflow.macros'hasbeendeprecated.Pleaseimportfrom'airflow.macros.[plugin_module]'instead.SupportfordirectimportswillbedroppedentirelyinAirflow2.0.".format i macro_name
def atomic_open filename mode 'w' if mode in 'r' 'rb' 'r+' 'rb+' 'a' 'ab' raise TypeError "Readorappendmodesdon'tworkwithatomic_open" ntf tempfile.NamedTemporaryFile mode prefix '.___atomic_write' dir os.path.dirname filename delete False return _AtomicWFile ntf ntf.name filename
def dup_subresultants f g K return dup_inner_subresultants f g K [0]
def get_fqdn return socket.getfqdn
def _convert_record2fits format recformat kind dtype _dtype_to_recformat format shape dtype.shapeitemsize dtype.base.itemsizeif dtype.char 'U' itemsize itemsize // 4 option str itemsize ndims len shape repeat 1if ndims > 0 nel np.array shape dtype 'i8' .prod if nel > 1 repeat nelif kind 'a' ntot int repeat * int option output_format str ntot + 'A' elif recformat in NUMPY2FITS if repeat ! 1 repeat str repeat else repeat ''output_format repeat + NUMPY2FITS[recformat] else raise ValueError 'Illegalformat{}.'.format format return output_format
def get_dummy_vm_create_spec client_factory name data_store_name config_spec client_factory.create 'ns0 VirtualMachineConfigSpec' config_spec.name nameconfig_spec.guestId 'otherGuest'vm_file_info client_factory.create 'ns0 VirtualMachineFileInfo' vm_file_info.vmPathName '[' + data_store_name + ']' config_spec.files vm_file_infotools_info client_factory.create 'ns0 ToolsConfigInfo' tools_info.afterPowerOn Truetools_info.afterResume Truetools_info.beforeGuestStandby Truetools_info.beforeGuestShutdown Truetools_info.beforeGuestReboot Trueconfig_spec.tools tools_infoconfig_spec.numCPUs 1config_spec.memoryMB 4controller_key -101 controller_spec create_controller_spec client_factory controller_key disk_spec create_virtual_disk_spec client_factory 1024 controller_key device_config_spec [controller_spec disk_spec]config_spec.deviceChange device_config_specreturn config_spec
def surrogate_escape error chars error.object[error.start error.end]assert len chars 1 val ord chars val + 56320return __builtin__.unichr val error.end
def convert_timedelta obj if not PY2 and isinstance obj bytes bytearray obj obj.decode 'ascii' m TIMEDELTA_RE.match obj if not m return Nonetry groups list m.groups groups[ -1 ] _convert_second_fraction groups[ -1 ] negate -1 if groups[0] else 1 hours minutes seconds microseconds groups[1 ]tdelta datetime.timedelta hours int hours minutes int minutes seconds int seconds microseconds int microseconds * negate return tdeltaexcept ValueError return None
def _system_copy_in_b bcpy b nrhs raise NotImplementedError
def signature fn import inspectif six.PY2 argspec inspect.getargspec fn args argspec.argsif len args > 0 args tuple args[1 ] if args[0] u'self' else args return args argspec.keywords signature inspect.signature fn args []keywords Nonefor arg in signature.parameters.values if arg.kind arg.VAR_KEYWORD keywords arg.nameelif arg.kind arg.VAR_POSITIONAL continueelse args.append arg.name return tuple args keywords
def _nanmean a axis None if axis return np.nansum a axis / np.sum 1 - np.isnan a axis else return np.nansum a / np.sum 1 - np.isnan a
def gf_factor f p K lc f gf_monic f p K if gf_degree f < 1 return lc [] factors []for g n in gf_sqf_list f p K [1] for h in gf_factor_sqf g p K [1] factors.append h n return lc _sort_factors factors
def get_username_from_uid uid if isinstance uid int return pwd.getpwuid uid .pw_namereturn uid
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def s3_comments name 'comments' **attr from s3widgets import s3_comments_widgetT current.Tif 'label' not in attr attr['label'] T 'Comments' if 'represent' not in attr attr['represent'] lambda comments XML comments if comments else current.messages['NONE'] if 'widget' not in attr attr['widget'] s3_comments_widgetif 'comment' not in attr attr['comment'] DIV _class 'tooltip' _title '%s|%s' % T 'Comments' T 'Pleaseusethisfieldtorecordanyadditionalinformation includingahistoryoftherecordifitisupdated.' f S3ReusableField name 'text' **attr return f
def mobile_view request url '/' if not url url '/' view args kwargs resolve url if view mobile_view raise Http404 'OMG Iseemyself!' kwargs['request'] requestkwargs['response_format'] 'html'response view *args **kwargs if response.status_code 302 and not response['Location'][ 2] '/m' response['Location'] '/m' + response['Location'] return response
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def entriefy data convert lambda tup Entry *tup if is_python3 return map convert data.items return imap convert data.iteritems
def gen_test func None timeout None if timeout is None timeout get_async_test_timeout def wrap f f gen.coroutine f @functools.wraps f def wrapper self return self.io_loop.run_sync functools.partial f self timeout timeout return wrapperif func is not None return wrap func else return wrap
def getLargestInsetLoopFromLoop loop radius loops getInsetLoopsFromLoop radius loop return euclidean.getLargestLoop loops
def play_nice_with_threads sleep True weak False deadline None if weak or threading.activeCount < 4 time.sleep 0 return 0deadline time.time + 5 if deadline is None else deadline while True activity_threshold 180 - time.time + LAST_USER_ACTIVITY / 120 delay max 0.001 min 0.1 0.1 * activity_threshold if not sleep breakif LIVE_USER_ACTIVITIES < 1 time.sleep delay else time.sleep max delay 0.25 if QUITTING or LIVE_USER_ACTIVITIES < 1 breakif time.time > deadline breakreturn delay
def _dct x type n None axis -1 overwrite_x False normalize None x0 n copy_made __fix_shape x n axis 'DCT' if type 1 and n < 2 raise ValueError 'DCT-Iisnotdefinedforsize<2' overwrite_x overwrite_x or copy_made nm _get_norm_mode normalize if np.iscomplexobj x0 return _raw_dct x0.real type n axis nm overwrite_x + 1j * _raw_dct x0.imag type n axis nm overwrite_x else return _raw_dct x0 type n axis nm overwrite_x
def dailymotion_download url output_dir '.' merge True info_only False **kwargs html get_content url info json.loads match1 html 'qualities" {.+?} "' title match1 html '"video_title"\\s* \\s*" [^"]+ "' or match1 html '"title"\\s* \\s*" [^"]+ "' for quality in ['1080' '720' '480' '380' '240' 'auto'] try real_url info[quality][0]['url']if real_url breakexcept KeyError passm3u_url extract_m3u real_url mime ext size 'video/mp4' 'mp4' 0 print_info site_info title mime size if not info_only download_url_ffmpeg m3u_url title ext output_dir output_dir merge merge
def email_recipients recipients note template None extra_context None subject '%s %s' % unicode comm.NOTE_TYPES[note.note_type] note.thread.obj.name for email user_id tok in tokenize_recipients recipients note.thread headers {}if tok headers['Reply-To'] '{0}{1}@{2}'.format comm.REPLY_TO_PREFIX tok settings.POSTFIX_DOMAIN mail_template template or comm.COMM_MAIL_MAP.get note.note_type 'generic' context get_mail_context note user_id context.update extra_context or {} send_mail_jinja subject 'comm/emails/%s.html' % mail_template context recipient_list [email] from_email settings.MKT_REVIEWERS_EMAIL perm_setting 'app_reviewed' headers headers
def set_connection_info url user True section keypath reg_info user try hive _winreg.ConnectRegistry None section try key _winreg.CreateKey hive keypath except passkey _winreg.OpenKey hive keypath mykey _winreg.CreateKey key 'api' _winreg.SetValueEx mykey 'url' None _winreg.REG_SZ url _winreg.CloseKey mykey _winreg.CloseKey key except WindowsError if user set_connection_info url user False passfinally _winreg.CloseKey hive
def get_jobs_summary **filter_data jobs get_jobs **filter_data ids [job['id'] for job in jobs]all_status_counts models.Job.objects.get_status_counts ids for job in jobs job['status_counts'] all_status_counts[job['id']]return rpc_utils.prepare_for_serialization jobs
def get_doc_files files start_path force 0 sync_everything False verbose False document_type [u'doctype' u'page' u'report' u'print_format' u'website_theme' u'web_form' u'email_alert']for doctype in document_type doctype_path os.path.join start_path doctype if os.path.exists doctype_path for docname in os.listdir doctype_path if os.path.isdir os.path.join doctype_path docname doc_path os.path.join doctype_path docname docname + u'.json' if os.path.exists doc_path if not doc_path in files files.append doc_path
def resource_filename filename if hasattr sys 'frozen' return os.path.join os.path.dirname sys.executable filename return pkg_resources.resource_filename qutebrowser.__name__ filename
def filter_song_md song md_list [u'id'] no_singletons True filtered [song[md_type] for md_type in md_list]if len md_list 1 and no_singletons return filtered[0]else return filtered
def test_bytes_hashing import _sha _sha256 _sha512 _md5for hashLib in _sha.new _sha256.sha256 _sha512.sha512 _sha512.sha384 _md5.new x hashLib 'abc' x.update 'abc' temp hashLib bytearray 'abc' x.update bytearray 'abc'
def p_rule2 p p[4].insert 0 p[3] p[0] p[1] p[4]
def clean_component source return source[source.index START_ICONSET ]
def encode_meta_headers headers ret {}for header value in headers.items value encode_utf8 value header header.lower if isinstance header six.string_types and header.startswith USER_METADATA_TYPE header encode_utf8 header ret[header] valuereturn ret
def threaded func return threaded_factory func True
def py_to_val pyval if isinstance pyval bool return 'true' if pyval is True else 'false' elif pyval '' return '""'else return getattr pyval 'record_id' pyval
def DeleteResourceSample client CreateClient doc gdata.docs.data.Resource type 'document' title 'MySampleDoc' doc client.CreateResource doc client.DeleteResource doc
def doc_parse_markup content markup _ _ p doc_rev_parser content TEMPLATE_TITLE_PREFIX + 'test' category TEMPLATES_CATEGORY doc pq p.parse markup return doc p
def recursive_glob path pattern for root dirnames filenames in os.walk path followlinks True for filename in fnmatch.filter filenames pattern yield os.path.join root filename
def test_calc_footprint_3 w wcs.WCS w.wcs.ctype [u'GLON-CAR' u'GLAT-CAR']w.wcs.crpix [1.5 5.5]w.wcs.cdelt [ -0.1 0.1]axes 2 10 ref np.array [[0.1 -0.5 ] [0.1 0.5] [359.9 0.5] [359.9 -0.5 ]] footprint w.calc_footprint axes axes undistort False center False assert_allclose footprint ref
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def expand_attribute_metadata metadata if isinstance metadata compat.string_type metadata {'name' metadata}return metadata
def processElementNodeByGeometry elementNode geometryOutput if geometryOutput ! None elementNode.getXMLProcessor .convertElementNode elementNode geometryOutput
def parseApacheLine s normal musecs vhost responsebytes s.rsplit '' 3 extracted sisynala.main.logline normal extracted.update dict musecs musecs vhost vhost responsebytes responsebytes return extracted
def gen_backend backend 'cpu' rng_seed None datatype np.float32 batch_size 0 stochastic_round False device_id 0 max_devices get_device_count compat_mode None deterministic_update None deterministic None logger logging.getLogger __name__ if NervanaObject.be is not None cleanup_backend else atexit.register cleanup_backend if deterministic_update is not None or deterministic is not None logger.warning 'deterministic_updateanddeterministicargsaredeprecatedinfavorofspecifyingrandomseed' deterministic Nonefrom neon.backends.backend import Backendbe Backend.allocate_backend backend rng_seed rng_seed default_dtype datatype stochastic_round stochastic_round device_id device_id num_devices max_devices compat_mode compat_mode deterministic deterministic logger.info 'Backend {} RNGseed {}'.format backend rng_seed NervanaObject.be bebe.bsz batch_sizereturn be
def package_data pkg root_list data []for root in root_list for dirname _ files in os.walk os.path.join pkg root for fname in files data.append os.path.relpath os.path.join dirname fname pkg return {pkg data}
def instance_remove_security_group context instance_id security_group_id return IMPL.instance_remove_security_group context instance_id security_group_id
def in6_mactoifaceid mac ulbit None if len mac ! 17 return Nonem ''.join mac.split ' ' if len m ! 12 return Nonefirst int m[0 2] 16 if ulbit is None or not ulbit 0 or ulbit 1 ulbit [1 '-' 0][ first & 2 ]ulbit * 2first '%.02x' % first & 253 | ulbit eui64 first + m[2 4] + ' ' + m[4 6] + 'FF FE' + m[6 8] + ' ' + m[8 12] return eui64.upper
def java_fat_library name srcs [] deps [] resources [] source_encoding None warnings None exclusions [] **kwargs target JavaFatLibrary name srcs deps resources source_encoding warnings exclusions kwargs blade.blade.register_target target
def test_prefilter_attribute_errors class X object def __getattr__ self k raise ValueError 'brokenobject' def __call__ self x return xip.user_ns['x'] X ip.magic 'autocall2' try ip.prefilter 'x1' finally del ip.user_ns['x']ip.magic 'autocall0'
def register_output_converter output_type converter global OUTPUT_CONVERTEROUTPUT_CONVERTER[output_type] converter
def release_interface device interface device._ctx.managed_release_interface device interface
def stonith_present name stonith_id stonith_device_type stonith_device_options None cibname None return _item_present name name item 'stonith' item_id stonith_id item_type stonith_device_type extra_args stonith_device_options cibname cibname
@register.simple_tag takes_context True def child_actions context content []for child_action in context[u'menu_action'][u'child_actions'] try content.append child_action.render context except Exception logging.exception u'Errorrenderingchildaction%s' child_action.action_id return u''.join content
@utils.arg '--all-tenants' action 'store_const' const 1 default 0 help _ 'Startserver s inanothertenantbyname Adminonly .' @utils.arg 'server' metavar '<server>' nargs '+' help _ 'NameorIDofserver s .' def do_start cs args find_args {'all_tenants' args.all_tenants}utils.do_action_on_many lambda s _find_server cs s **find_args .start args.server _ 'Requesttostartserver%shasbeenaccepted.' _ 'Unabletostartthespecifiedserver s .'
def isHermitian matlist K return conjugate_transpose matlist K matlist
def test_adjust_log image np.arange 0 255 4 np.uint8 .reshape 8 8 expected np.array [[0 5 11 16 22 27 33 38] [43 48 53 58 63 68 73 77] [82 86 91 95 100 104 109 113] [117 121 125 129 133 137 141 145] [149 153 157 160 164 168 172 175] [179 182 186 189 193 196 199 203] [206 209 213 216 219 222 225 228] [231 234 238 241 244 246 249 252]] dtype np.uint8 result exposure.adjust_log image 1 assert_array_equal result expected
@raises ActionError def test_parse_command_action_error arg_str 'selectorinvalid_action'screenshot._parse_command arg_str
def sign message key if 'p' not in key raise Exception 'Youmustusetheprivatekeywithsign' return chopstring message key['d'] key['p'] * key['q'] encrypt_int
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
@register.inclusion_tag get_template 'inclusion.html' def inclusion_two_params_from_template one two return {'result' 'inclusion_two_params_from_template-Expectedresult %s %s' % one two }
@pytest.mark.parametrize 'parallel' [True False] def test_whitespace_before_comment parallel read_tab text 'a DCTB b DCTB c\n#commentline\n1 DCTB 2 DCTB 3'table read_tab text parallel parallel expected Table [[1] [2] [3]] names 'a' 'b' 'c' assert_table_equal table expected
def _merge_dicts *args ret dict for arg in args ret.update arg return ret
def is_mt_res item return item.startswith 'Packages/MaterialTheme/'
def _LineContainsI18n uwline if style.Get u'I18N_COMMENT' for tok in uwline.tokens if tok.is_comment and re.match style.Get u'I18N_COMMENT' tok.value return Trueif style.Get u'I18N_FUNCTION_CALL' length len uwline.tokens index 0while index < length - 1 if uwline.tokens[ index + 1 ].value u' ' and uwline.tokens[index].value in style.Get u'I18N_FUNCTION_CALL' return Trueindex + 1return False
def write fd data return WriteEvent fd data
def filter sum_dict align_dict filter_attribute low_bound high_bound new_sum_dict FSSP.FSSPSumDict new_align_dict copy.deepcopy align_dict for prot_num in sum_dict attr_value getattr sum_dict[prot_num] filter_attribute if attr_value > low_bound and attr_value < high_bound new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict.abs_res_dict new_align_dict.abs pos_num .pos_align_dict {}for prot_num in prot_numbers new_align_dict.abs pos_num .pos_align_dict[prot_num] align_dict.abs pos_num .pos_align_dict[prot_num]return new_sum_dict new_align_dict
def to_cli_filter bool_or_filter if not isinstance bool_or_filter bool CLIFilter raise TypeError u'ExpectingabooloraCLIFilterinstance.Got%r' % bool_or_filter return {True _always False _never}.get bool_or_filter bool_or_filter
def reduce_with aggregation_fn key values yield key aggregation_fn values
def test1 pm PackageMaker 'reportlab' '1.10' "ReportLab'sOpenSourcePDFtoolkit." pm.build root '/Users/dinu/Desktop/reportlab' DefaultLocation '/Applications/ReportLab' Relocatable 'YES'
def closest_scrapy_cfg path '.' prevpath None if path prevpath return ''path os.path.abspath path cfgfile os.path.join path 'scrapy.cfg' if os.path.exists cfgfile return cfgfilereturn closest_scrapy_cfg os.path.dirname path path
def inspect_error error 'InternalPythonerrorintheinspectmodule.\nBelowisthetracebackfromthisinternalerror.\n'
def get_color_name value if not is_known_type value return CUSTOM_TYPE_COLORfor typ name in list COLORS.items if isinstance value typ return nameelse np_dtype get_numpy_dtype value if np_dtype is None or not hasattr value 'size' return UNSUPPORTED_COLORelif value.size 1 return SCALAR_COLORelse return ARRAY_COLOR
def _handle_links event global treetree spanning_tree._calc_spanning_tree
def test_unique_join_node tmpdir global _sum_operands_sum_operands []os.chdir str tmpdir wf pe.Workflow name u'test' inputspec pe.Node IdentityInterface fields [u'n'] name u'inputspec' inputspec.iterables [ u'n' [3 1 2 1 3] ]pre_join1 pe.Node IncrementInterface name u'pre_join1' wf.connect inputspec u'n' pre_join1 u'input1' join pe.JoinNode SumInterface joinsource u'inputspec' joinfield u'input1' unique True name u'join' wf.connect pre_join1 u'output1' join u'input1' wf.run assert _sum_operands[0] [4 2 3] u'Theuniquejoinoutputvalueisincorrect %s.' % _sum_operands[0]
def systemInformationType10 name 'SyStemInformationType10'fields_desc [BitField 'pd' 0 1 BitField 'msgType' 0 5 BitField 'layer2Header' 0 2 BitField 'si10' 0 160 ]
def close_logger for handler in _logger.handlers _logger.removeHandler handler if isinstance handler logging.FileHandler handler.close
def _meta_links req count meta {config.QUERY_PAGE req.page config.QUERY_MAX_RESULTS req.max_results}if config.OPTIMIZE_PAGINATION_FOR_SPEED is False meta['total'] countreturn meta
def _dpow x y n if n < 0 raise ValueError 'invalidderivativeorder' elif n > y return 0else return poch y - n + 1 n * x ** y - n
def _compute_scalings bn xlim ylim if isinstance ylim[0] tuple list np.ndarray ylim ylim[0][0] ylim[1][0] pos bn.posbn.x_s pos[2] / xlim[1] - xlim[0] bn.x_t pos[0] - bn.x_s * xlim[0] bn.y_s pos[3] / ylim[1] - ylim[0] bn.y_t pos[1] - bn.y_s * ylim[0]
def _which_git_config global_ cwd user password if global_ return ['--global']version_ _LooseVersion version versioninfo False if version_ > _LooseVersion '1.7.10.2' return ['--local']else return ['--file' _git_config cwd user password ]
def plot_day_summary_oclh ax quotes ticksize 3 colorup u'k' colordown u'r' return _plot_day_summary ax quotes ticksize ticksize colorup colorup colordown colordown ochl True
def _refine_enc enc rsa ['r' 'rsa' 'ssh-rsa']dss ['d' 'dsa' 'dss' 'ssh-dss']ecdsa ['e' 'ecdsa' 'ecdsa-sha2-nistp521' 'ecdsa-sha2-nistp384' 'ecdsa-sha2-nistp256']ed25519 ['ed25519' 'ssh-ed25519']if enc in rsa return 'ssh-rsa'elif enc in dss return 'ssh-dss'elif enc in ecdsa if enc in ['e' 'ecdsa'] return 'ecdsa-sha2-nistp256'return encelif enc in ed25519 return 'ssh-ed25519'else raise CommandExecutionError "Incorrectencryptionkeytype'{0}'.".format enc
def instance_cache func def _wrapper self *args **kwargs key func.__name__ + args for pair in sorted kwargs.items key + pairif key in self._cache return self._cache[key]data func self *args **kwargs self._cache[key] datareturn datareturn _wrapper
def server_and_port resources worked Falsefor port in xrange 4443 4543 try server HTTPServer 'localhost' port partial RequestHandler resources except socket.error passelse worked Trueserver.socket ssl.wrap_socket server.socket certfile join tests_dir 'certs' 'localhost' 'server.pem' server_side True breakif not worked raise RuntimeError "Couldn'tfindanunusedsocketforthetestingHTTPSserver." return server port
def _validate_constraints supported_constraints model message u'Optimizercannothandle{0}constraints.'if any six.itervalues model.fixed and u'fixed' not in supported_constraints raise UnsupportedConstraintError message.format u'fixedparameter' if any six.itervalues model.tied and u'tied' not in supported_constraints raise UnsupportedConstraintError message.format u'tiedparameter' if any tuple b ! None None for b in six.itervalues model.bounds and u'bounds' not in supported_constraints raise UnsupportedConstraintError message.format u'boundparameter' if model.eqcons and u'eqcons' not in supported_constraints raise UnsupportedConstraintError message.format u'equality' if model.ineqcons and u'ineqcons' not in supported_constraints raise UnsupportedConstraintError message.format u'inequality'
def getCascadeFloatWithoutSelf defaultFloat elementNode key if key in elementNode.attributes value elementNode.attributes[key]functionName 'get' + key[0].upper + key[1 ] if functionName in value if elementNode.parentNode None return defaultFloatelse elementNode elementNode.parentNodereturn elementNode.getCascadeFloat defaultFloat key
def is_html_file path ext os.path.splitext path [1].lower return ext in [u'.html' u'.htm']
def get_access_key return environ.get 'HTTP_ACCESSKEY' ''
def stZCR frame count len frame countZ numpy.sum numpy.abs numpy.diff numpy.sign frame / 2 return numpy.float64 countZ / numpy.float64 count - 1.0
@downgrades 3 def _downgrade_v3 op op.create_table '_new_equities' sa.Column 'sid' sa.Integer unique True nullable False primary_key True sa.Column 'symbol' sa.Text sa.Column 'company_symbol' sa.Text sa.Column 'share_class_symbol' sa.Text sa.Column 'fuzzy_symbol' sa.Text sa.Column 'asset_name' sa.Text sa.Column 'start_date' sa.Integer default 0 nullable False sa.Column 'end_date' sa.Integer nullable False sa.Column 'first_traded' sa.Integer nullable False sa.Column 'auto_close_date' sa.Integer sa.Column 'exchange' sa.Text op.execute '\ninsertinto_new_equities\nselect*fromequities\nwhereequities.first_tradedisnotnull\n' op.drop_table 'equities' op.rename_table '_new_equities' 'equities' op.create_index 'ix_equities_company_symbol' 'equities' ['company_symbol'] op.create_index 'ix_equities_fuzzy_symbol' 'equities' ['fuzzy_symbol']
def dup_mirror f K f list f for i in range len f - 2 -1 -2 f[i] - f[i] return f
def pytest_unconfigure config if config.getoption '--qute-profile-subprocs' stats pstats.Stats for fn in os.listdir 'prof' stats.add os.path.join 'prof' fn stats.dump_stats os.path.join 'prof' 'combined.pstats'
def make_path_relative path rel_to path_filename os.path.basename path path os.path.dirname path path os.path.normpath os.path.abspath path rel_to os.path.normpath os.path.abspath rel_to path_parts path.strip os.path.sep .split os.path.sep rel_to_parts rel_to.strip os.path.sep .split os.path.sep while path_parts and rel_to_parts and path_parts[0] rel_to_parts[0] path_parts.pop 0 rel_to_parts.pop 0 full_parts ['..'] * len rel_to_parts + path_parts + [path_filename] if full_parts [''] return '.' + os.path.sep return os.path.sep.join full_parts
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def icosahedral_graph create_using None description ['adjacencylist' 'PlatonicIcosahedralGraph' 12 [[2 6 8 9 12] [3 6 7 9] [4 7 9 10] [5 7 10 11] [6 7 11 12] [7 12] [] [9 10 11 12] [10] [11] [12] []]]G make_small_undirected_graph description create_using return G
def _parse_query_string_settings query_kwargs settings None def list_from_query_string s return s.split ' ' parsers {'int' int 'float' float 'bool' bool 'list str' lambda s list_from_query_string s 'list escaped' lambda s [urllib2.unquote e for e in list_from_query_string s ] 'list int' lambda s [int i for i in list_from_query_string s ] }settings settings or {} for key in settings if key in query_kwargs query_value query_kwargs[key]needed_type settings[key]if needed_type ! 'str' try query_kwargs[key] parsers[needed_type] query_value except KeyError ValueError del query_kwargs[key]return query_kwargs
def truncate_year dt measure return date dt.year // measure * measure 1 1
def _is_descriptor obj return hasattr obj '__get__' or hasattr obj '__set__' or hasattr obj '__delete__'
def mountroot_for_test test_case mountroot FilePath test_case.mktemp mountroot.makedirs test_case.addCleanup umount_all mountroot return mountroot
def get_imports project pydefined pymodule pydefined.get_module module module_imports.ModuleImports project pymodule if pymodule pydefined return [stmt.import_info for stmt in module.imports]return module.get_used_imports pydefined
def connect_to_cloud_monitoring region None return _create_client ep_name 'monitor' region region
def poisson2d N dtype 'd' format None if N 1 diags asarray [[4]] dtype dtype return dia_matrix diags [0] shape 1 1 .asformat format offsets array [0 - N N -1 1] diags empty 5 N ** 2 dtype dtype diags[0] 4diags[1 ] -1 diags[3 N - 1 N] 0diags[4 N N] 0return dia_matrix diags offsets shape N ** 2 N ** 2 .asformat format
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def ae_load token_key import gdata.alt.app_enginekey_name ''.join 'gd_auth_token' token_key token_string gdata.alt.app_engine.get_token key_name if token_string is not None return token_from_blob token_string else return None
def bzr_wc_target_exists_no_update test 'bzr_wc_target_exists_no_update'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric.api import runfrom fabtools.files import is_dirfrom fabtools import requireassert not is_dir wt require.bazaar.working_copy REMOTE_URL wt version '2' require.bazaar.working_copy REMOTE_URL wt update False assert_wc_exists wt assert run 'bzrrevno%s' % wt '2'
def merge_volume_bindings volumes previous_container affinity {}volume_bindings dict build_volume_binding volume for volume in volumes if volume.external if previous_container old_volumes get_container_data_volumes previous_container volumes warn_on_masked_volume volumes old_volumes previous_container.service volume_bindings.update build_volume_binding volume for volume in old_volumes if old_volumes affinity {u'affinity container' u' ' + previous_container.id }return list volume_bindings.values affinity
def read_epochs_kit input_fname events event_id None mrk None elp None hsp None verbose None epochs EpochsKIT input_fname input_fname events events event_id event_id mrk mrk elp elp hsp hsp verbose verbose return epochs
def enqueue_flag_exploration_email_task exploration_id report_text reporter_id payload {'exploration_id' exploration_id 'report_text' report_text 'reporter_id' reporter_id}taskqueue_services.enqueue_task feconf.TASK_URL_FLAG_EXPLORATION_EMAILS payload 0
def _romberg_diff b c k tmp 4.0 ** k return tmp * c - b / tmp - 1.0
def file_ext filename dot_index filename.find '.' if dot_index -1 return ''return filename[dot_index ]
def image_tag_get_all context image_id session None _check_image_id image_id session session or get_session tags session.query models.ImageTag.value .filter_by image_id image_id .filter_by deleted False .all return [tag[0] for tag in tags]
def verify_structure memlen itemsize ndim shape strides offset if offset % itemsize return Falseif offset < 0 or offset + itemsize > memlen return Falseif any v % itemsize for v in strides return Falseif ndim < 0 return ndim 0 and not shape and not strides if 0 in shape return Trueimin sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] < 0 imax sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] > 0 return 0 < offset + imin and offset + imax + itemsize < memlen
def default_locale_negotiator request name '_LOCALE_'locale_name getattr request name None if locale_name is None locale_name request.params.get name if locale_name is None locale_name request.cookies.get name return locale_name
def cflags_contains value return var_contains 'CFLAGS' value
@check_simple_wiki_locale@mobile_template 'products/{mobile/}products.html' def product_list request template products Product.objects.filter visible True return render request template {'products' products}
def _scale_image image side_length return image.resize side_length side_length Image.ANTIALIAS
def walk top topdown True followlinks False names os.listdir top dirs nondirs [] [] for name in names if path.isdir path.join top name dirs.append name else nondirs.append name if topdown yield top dirs nondirs for name in dirs fullpath path.join top name if followlinks or not path.islink fullpath for x in walk fullpath topdown followlinks yield x if not topdown yield top dirs nondirs
def _lineage block parent block.get_parent while parent yield parent parent parent.get_parent
def LinkFileLock *args **kwds from . import linklockfilereturn _fl_helper linklockfile.LinkLockFile 'lockfile.linklockfile' *args **kwds
def run_wsgi_app application run_bare_wsgi_app add_wsgi_middleware application
def get_default_fetch_deadline return getattr _thread_local_settings 'default_fetch_deadline' None
@memoizedef check key ver return check_version get key ver
def _requires_alpn func @wraps func def wrapper *args **kwargs if not _lib.Cryptography_HAS_ALPN raise NotImplementedError 'ALPNnotavailable.' return func *args **kwargs return wrapper
def asfreq obj freq method None how None normalize False fill_value None if isinstance obj.index PeriodIndex if method is not None raise NotImplementedError "'method'argumentisnotsupported" if how is None how 'E'new_index obj.index.asfreq freq how how new_obj obj.copy new_obj.index new_indexreturn new_objelse if len obj.index 0 return obj.copy dti date_range obj.index[0] obj.index[ -1 ] freq freq dti.name obj.index.namers obj.reindex dti method method fill_value fill_value if normalize rs.index rs.index.normalize return rs
def digest_password realm username password content '%s %s %s' % username realm password if six.PY3 content content.encode 'utf8' return md5 content .hexdigest
def connect_walrus host None aws_access_key_id None aws_secret_access_key None port 8773 path '/services/Walrus' is_secure False **kwargs from boto.s3.connection import S3Connectionfrom boto.s3.connection import OrdinaryCallingFormatif not aws_access_key_id aws_access_key_id config.get 'Credentials' 'euca_access_key_id' None if not aws_secret_access_key aws_secret_access_key config.get 'Credentials' 'euca_secret_access_key' None if not host host config.get 'Boto' 'walrus_host' None return S3Connection aws_access_key_id aws_secret_access_key host host port port path path calling_format OrdinaryCallingFormat is_secure is_secure **kwargs
@when u'wecreatedatabase' def step_db_create context context.cli.sendline u'createdatabase{0};'.format context.conf[u'dbname_tmp'] context.response {u'database_name' context.conf[u'dbname_tmp']}
def get_vol_list ip user passwd cmd 'showvv'showvv_list run_ssh_thread ip user passwd cmd vol_list []line_num 0for line in showvv_list line_num + 1if '-------------------------' in line breakif '-----' in line or 'rcpy.' in line or '.srdata' in line or '0admin' in line continueif line_num > 4 vol_stats line.split vol_list.append vol_stats[1] return vol_list
def isFirstBestMatch result sickrage.srCore.srLogger.debug u'Checkingifweshouldarchiveourfirstbestqualitymatchforepisode' + result.name show_obj result.episodes[0].show any_qualities best_qualities Quality.splitQuality show_obj.quality if best_qualities and show_obj.archive_firstmatch and result.quality in best_qualities return Truereturn False
def at_server_reload_start pass
@magic_arguments @argument '-f' '--foo' help 'anargument' def magic_magic_foo self args return parse_argstring magic_magic_foo args
def _checkblk name blk __salt__['cmd.run'] 'lsblk-ofstype{0}'.format name .splitlines return '' if len blk 1 else blk[1]
def gitConfigBool key if key not in _gitConfig cmd ['git' 'config' '--bool' key]s read_pipe cmd ignore_error True v s.strip _gitConfig[key] v 'true' return _gitConfig[key]
def profile_list request page 1 template_name 'userena/profile_list.html' paginate_by 50 extra_context None **kwargs warnings.warn 'views.profile_listisdeprecated.UseProfileListViewinstead' DeprecationWarning stacklevel 2 try page int request.GET.get 'page' None except TypeError ValueError page pageif userena_settings.USERENA_DISABLE_PROFILE_LIST and not request.user.is_staff raise Http404profile_model get_profile_model queryset profile_model.objects.get_visible_profiles request.user if not extra_context extra_context dict return ProfileListView.as_view queryset queryset paginate_by paginate_by page page template_name template_name extra_context extra_context **kwargs request
def installed_extensions user None host None port None maintenance_db None password None runas None exts []query 'selecta.* b.nspnameasschema_namefrompg_extensiona pg_namespacebwherea.extnamespace b.oid;'ret psql_query query user user host host port port maintenance_db maintenance_db password password runas runas exts {}for row in ret if 'extversion' in row and 'extname' in row exts[row['extname']] rowreturn exts
def messageTypeNames def typeNames for types in registry.values for typ in types yield typ.typeName return set typeNames
def string_b64encode s return base64.urlsafe_b64encode s .strip ' '
def _docker_prefix docker_cmd DEFAULT_DOCKER_COMMAND sudo DEFAULT_SUDO sudo_cmd DEFAULT_SUDO_COMMAND host DEFAULT_HOST **kwds command_parts []if sudo command_parts.append sudo_cmd command_parts.append docker_cmd if host command_parts.extend ['-H' host] return command_parts
def __getLocation__ **kwargs global CURRENT_LATglobal CURRENT_LONif kwargs is not None CURRENT_LAT kwargs['lat']CURRENT_LON kwargs['lon']
def wrapClientTLS connectionCreator wrappedEndpoint if TLSMemoryBIOFactory is None raise NotImplementedError 'OpenSSLnotavailable.Try`pipinstalltwisted[tls]`.' return _WrapperEndpoint wrappedEndpoint lambda protocolFactory TLSMemoryBIOFactory connectionCreator True protocolFactory
def _comp_sums_meg beta ctheta lut_fun n_fact volume_integral sums np.empty n_fact.shape[1] len beta n_chunk 50000000 // 8 * max n_fact.shape * 2 lims np.concatenate [np.arange 0 beta.size n_chunk [beta.size]] for start stop in zip lims[ -1 ] lims[1 ] bbeta np.tile beta[start stop][np.newaxis] n_fact.shape[0] 1 bbeta[0] * beta[start stop]np.cumprod bbeta axis 0 out bbeta np.einsum 'ji jk ijk->ki' bbeta n_fact lut_fun ctheta[start stop] out sums[ start stop] return sums
@handle_response_format@treeio_login_required@module_admin_required def module_view request module_id response_format 'html' module get_object_or_404 Module pk module_id return render_to_response 'core/administration/module_view' {'module' module} context_instance RequestContext request response_format response_format
def test_commandline_basic tmpdir subprocess.check_call [sys.executable VIRTUALENV_SCRIPT str tmpdir.join 'venv' ]
def technical_500_response request exc_type exc_value tb reporter ExceptionReporter request exc_type exc_value tb html reporter.get_traceback_html return HttpResponseServerError html mimetype 'text/html'
def urfftn inarray dim None if dim is None dim inarray.ndimoutarray np.fft.rfftn inarray axes range - dim 0 return outarray / np.sqrt np.prod inarray.shape[ - dim ]
def gf_to_int_poly f p symmetric True if symmetric return [gf_int c p for c in f]else return f
def foo pass
def get_object_in_event klass id_ event_id event get_object_or_404 EventModel event_id obj get_object_or_404 klass id_ if obj.event_id ! event.id raise InvalidServiceError message '{}doesnotbelongtoevent'.format klass.__name__ return obj
def line_integrate field curve vars from sympy.geometry import CurveF sympify field if not F raise ValueError 'Expectingfunctionspecifyingfieldasfirstargument.' if not isinstance curve Curve raise ValueError 'ExpectingCurveentityassecondargument.' if not is_sequence vars raise ValueError 'Expectingorderediterableforvariables.' if len curve.functions ! len vars raise ValueError 'Fieldvariablesizedoesnotmatchcurvedimension.' if curve.parameter in vars raise ValueError 'Curveparameterclasheswithfieldparameters.' Ft Fdldt 0for i var in enumerate vars _f curve.functions[i]_dn diff _f curve.parameter dldt dldt + _dn * _dn Ft Ft.subs var _f Ft Ft * sqrt dldt integral Integral Ft curve.limits .doit deep False return integral
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def trimtail data proportiontocut 0.2 tail 'left' inclusive True True axis None tail str tail .lower [0]if tail 'l' limits proportiontocut None elif tail 'r' limits None proportiontocut else raise TypeError "Thetailargumentshouldbein 'left' 'right' " return trimr data limits limits axis axis inclusive inclusive
def find_states markov_model output mm markov_modelN len mm.states lp_initial numpy.log mm.p_initial + VERY_SMALL_NUMBER lp_transition numpy.log mm.p_transition + VERY_SMALL_NUMBER lp_emission numpy.log mm.p_emission + VERY_SMALL_NUMBER indexes itemindex mm.alphabet output [indexes[x] for x in output]results _viterbi N lp_initial lp_transition lp_emission output for i in range len results states score results[i]results[i] [mm.states[x] for x in states] numpy.exp score return results
def capped_binomial_deviance actual predicted return np.mean capped_log10_likelihood actual predicted
def gnu_hash s h 5381for c in s h h * 33 + ord c return h & 4294967295
def now return datetime.datetime.now TimeZoneInfo.local
def request_httprepr request parsed urlparse_cached request path urlunparse '' '' parsed.path or '/' parsed.params parsed.query '' s '%s%sHTTP/1.1\r\n' % request.method path s + 'Host %s\r\n' % parsed.hostname if request.headers s + request.headers.to_string + '\r\n' s + '\r\n's + request.bodyreturn s
def check_geom result func cargs if isinstance result int result c_void_p result if not result raise GDALException 'Invalidgeometrypointerreturnedfrom"%s".' % func.__name__ return result
def new data None return SHA224Hash .new data
def p_const_list p p[0] p[2]
def clear_dag_task_instances session settings.Session TI TaskInstancetis session.query TI .filter TI.dag_id.in_ DAG_IDS .all for ti in tis logging.info 'DeletingTaskInstance {}'.format ti session.delete ti session.commit
def getargsfromdoc obj if obj.__doc__ is not None return getargsfromtext obj.__doc__ obj.__name__
def _ensure_decoded s if isinstance s np.bytes_ bytes s s.decode pd.get_option 'display.encoding' return s
def getbranches tree if isinstance tree tuple name subtree treea [name]for st in subtree a.extend getbranches st return areturn []
def persist_uploads params if 'files' in params new_files []for upload_dataset in params['files'] f upload_dataset['file_data']if isinstance f FieldStorage assert not isinstance f.file StringIO assert f.file.name ! '<fdopen>' local_filename util.mkstemp_ln f.file.name 'upload_file_data_' f.file.close upload_dataset['file_data'] dict filename f.filename local_filename local_filename elif type f dict and 'local_filename' not in f raise Exception 'UploadedfilewasencodedinawaynotunderstoodbyGalaxy.' if upload_dataset['url_paste'] and upload_dataset['url_paste'].strip ! '' upload_dataset['url_paste'] is_multi_byte datatypes.sniff.stream_to_file StringIO upload_dataset['url_paste'] prefix 'strio_url_paste_' else upload_dataset['url_paste'] Nonenew_files.append upload_dataset params['files'] new_filesreturn params
def __get_username if sys.platform 'win32' return getpass.getuser import pwdreturn pwd.getpwuid os.geteuid .pw_name
@requires_application def test_actual _test_module_properties None
def getNewRepository return FillRepository
def get_bits flags reverse False bits 8 mybits 1 2 4 8 16 32 64 128 256 512 1024 2048 [ bits]rev_num 1if reverse rev_num -1 ret array 'B' ret_append ret.appendfor bit in mybits[ rev_num] ret_append flags & bit ! 0 return ret
def refresh_inventory data None try _inventory.refresh data except AttributeError print '_inventorywasnotinitialized'
def download_api_data filename coord api_base projection s host path p q f urlparse api_base bbox coordinate_latlon_bbox coord projection path join path 'api/0.6/map?bbox %.6f %.6f %.6f %.6f' % bbox conn HTTPConnection host conn.request 'GET' path headers {'Accept-Encoding' 'compress gzip'} resp conn.getresponse assert resp.status 200 resp.status resp.read if resp.getheader 'Content-Encoding' 'gzip' disk open filename 'w' else raise Exception host path disk GzipFile filename 'w' bytes resp.read disk.write bytes disk.close return len bytes / 1024.0
@functools.lru_cache maxsize None def get_finder import_path Finder import_string import_path if not issubclass Finder BaseFinder raise ImproperlyConfigured 'Finder"%s"isnotasubclassof"%s"' % Finder BaseFinder return Finder
def package_activity_list package_id limit offset q _package_activity_query package_id return _activities_at_offset q limit offset
def person_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'pr' 'person'
def unicodise_safe string encoding None return unicodise deunicodise string encoding encoding .replace u'\ufffd' '?'
def get_block_device_mapping image bdm_dict dict bdm getattr image 'block_device_mapping' for device_name in bdm.keys bdm_dict[device_name] {'size' bdm[device_name].size 'snapshot_id' bdm[device_name].snapshot_id 'volume_type' bdm[device_name].volume_type 'encrypted' bdm[device_name].encrypted 'delete_on_termination' bdm[device_name].delete_on_termination}return bdm_dict
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def send_update context old_instance new_instance service None host None if not CONF.notify_on_any_change and not CONF.notify_on_state_change returnupdate_with_state_change Falseold_vm_state old_instance['vm_state']new_vm_state new_instance['vm_state']old_task_state old_instance['task_state']new_task_state new_instance['task_state']if old_vm_state ! new_vm_state update_with_state_change Trueelif CONF.notify_on_state_change if CONF.notify_on_state_change.lower 'vm_and_task_state' and old_task_state ! new_task_state update_with_state_change Trueif update_with_state_change send_update_with_states context new_instance old_vm_state new_vm_state old_task_state new_task_state service host else try _send_instance_update_notification context new_instance service service host host except Exception LOG.exception _ 'Failedtosendstateupdatenotification' instance new_instance
def logged level name None message None def decorate func logname name if name else func.__module__ log logging.getLogger logname logmsg message if message else func.__name__ @wraps func def wrapper *args **kwargs log.log level logmsg return func *args **kwargs return wrapperreturn decorate
def do_translate message translation_function global _defaulteol_message message and message.replace str u'\r\n' str u'\n' .replace str u'\r' str u'\n' or None t getattr _active u'value' None if t is not None result getattr t translation_function eol_message else if _default is None from django.conf import settings_default translation settings.LANGUAGE_CODE result getattr _default translation_function eol_message if isinstance message SafeData return mark_safe result return result
def Date year month day return datetime.date year month day
def issues2dict issues idict {}for i in issues idict[i['number']] ireturn idict
def get_context context host get_request_site_address links []for route page in get_pages .iteritems if not page.no_sitemap links.append {u'loc' urllib.basejoin host urllib.quote page.name.encode u'utf-8' u'lastmod' nowdate } for route data in get_all_page_context_from_doctypes .iteritems links.append {u'loc' urllib.basejoin host urllib.quote route or u'' .encode u'utf-8' u'lastmod' get_datetime data.get u'modified' .strftime u'%Y-%m-%d' } return {u'links' links}
def op_abs_mul lin_op args if lin_op.type in [lo.SCALAR_CONST lo.DENSE_CONST lo.SPARSE_CONST] result np.abs lin_op.data elif lin_op.type is lo.NEG result args[0]elif lin_op.type is lo.MUL coeff mul lin_op.data {} True result coeff * args[0] elif lin_op.type is lo.DIV divisor mul lin_op.data {} True result args[0] / divisor elif lin_op.type is lo.CONV result conv_mul lin_op args[0] is_abs True else result op_mul lin_op args return result
def get_example_filenames example_dir for dirpath dirnames filenames in os.walk example_dir for fname in sorted filenames if not fname.endswith '.py' continuefilename op.join dirpath fname name filename[len example_dir ].lstrip '/\\' [ -3 ]name name.replace '\\' '/' yield filename name
def decorate_fn_with_doc new_fn old_fn additional_text '' def wrapper *args **kw return new_fn *args **kw if old_fn.__doc__ wrapper.__doc__ old_fn.__doc__ + additional_text return wrapper
def splituser host global _userprogif _userprog is None _userprog re.compile '^ .* @ .* $' match _userprog.match host if match return match.group 1 2 return None host
def configure_json_logging stream io.StringIO logging.config.dictConfig {'version' 1 'handlers' {'json' {'class' 'logging.StreamHandler' 'formatter' 'json' 'stream' stream}} 'root' {'level' 'DEBUG' 'handlers' ['json']} 'formatters' {'json' {' ' 'coalib.output.Logging.JSONFormatter'}}} return stream
def diop_general_pythagorean eq param symbols 'm' integer True var coeff diop_type classify_diop eq _dict False if diop_type 'general_pythagorean' return _diop_general_pythagorean var coeff param
def sync_from_app app try modules frappe.get_attr app + u'.config.desktop.get_data' or {} except ImportError return []if isinstance modules dict modules_list []for m desktop_icon in modules.iteritems desktop_icon[u'module_name'] mmodules_list.append desktop_icon else modules_list modulesfor i m in enumerate modules_list desktop_icon_name frappe.db.get_value u'DesktopIcon' {u'module_name' m[u'module_name'] u'app' app u'standard' 1} if desktop_icon_name desktop_icon frappe.get_doc u'DesktopIcon' desktop_icon_name else desktop_icon frappe.get_doc {u'doctype' u'DesktopIcon' u'idx' i u'standard' 1 u'app' app u'owner' u'Administrator'} if u'doctype' in m m[u'_doctype'] m.pop u'doctype' desktop_icon.update m desktop_icon.save return modules_list
def extract_patch textid os downsample temp '${PYLEARN2_DATA_PATH}/textures/brodatz/D%i.gif' % textid fname string_utils.preprocess temp img_i Image.open fname img_i img_i.resize img_i.size[0] / downsample img_i.size[1] / downsample Image.BILINEAR x numpy.random.randint 0 img_i.size[0] - os y numpy.random.randint 0 img_i.size[1] - os patch img_i.crop x y x + os y + os return patch x y
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def time_xlsxwriter_optimised start_time clock workbook xlsxwriter.Workbook 'xlsxwriter_opt.xlsx' {'constant_memory' True} worksheet workbook.add_worksheet for row in range row_max // 2 for col in range col_max worksheet.write_string row * 2 col 'Row %dCol %d' % row col for col in range col_max worksheet.write_number row * 2 + 1 col row + col workbook.close elapsed clock - start_time print_elapsed_time 'xlsxwriter optimised ' elapsed
def text charp if not charp return ''return native ffi.string charp
def bin_prefix cmd return os.path.join get_bin_path cmd
@FileSystem.in_directory current_directory 'django' 'alfaces' def test_limit_by_app_getting_one_app status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 3--no-color--apps foobar' assert_equals status 0 out assert 'TestthedjangoappDONOTHING' not in out assert 'TestthedjangoappFOOBAR' in out
def service_tags_not_in_module_path physical_line filename if 'tempest/scenario' not in filename matches SCENARIO_DECORATOR.match physical_line if matches services matches.group 1 .split ' ' for service in services service_name service.strip .strip "'" modulepath os.path.split filename [0]if service_name in modulepath return physical_line.find service_name 'T107 servicetagshouldnotbeinpath'
def cost_per_mille spend impressions if impressions return 1000.0 * float spend / impressions else return 0
def cluster_depths cluster depths {}depths[cluster] 0for cluster in preorder cluster cl_depth depths[cluster]depths.update dict.fromkeys cluster.branches cl_depth + 1 return depths
def var_str name shape size np.prod shape ind np.indices shape + 1 .reshape -1 size names [ '[' + ' '.join map str i + ']' for i in zip *ind ]names[0] '%s%s' % name names[0] return names
def make_plots filename num_epochs training_cost_xmin 200 test_accuracy_xmin 200 test_cost_xmin 0 training_accuracy_xmin 0 training_set_size 1000 f open filename 'r' test_cost test_accuracy training_cost training_accuracy json.load f f.close plot_training_cost training_cost num_epochs training_cost_xmin plot_test_accuracy test_accuracy num_epochs test_accuracy_xmin plot_test_cost test_cost num_epochs test_cost_xmin plot_training_accuracy training_accuracy num_epochs training_accuracy_xmin training_set_size plot_overlay test_accuracy training_accuracy num_epochs min test_accuracy_xmin training_accuracy_xmin training_set_size
def get_lang from calibre.utils.config_base import prefslang prefs['language']lang os.environ.get 'CALIBRE_OVERRIDE_LANG' lang if lang return langtry lang get_system_locale except import tracebacktraceback.print_exc lang Noneif lang match re.match '[a-z]{2 3} _[A-Z]{2} {0 1}' lang if match lang match.group if lang 'zh' lang 'zh_CN'if not lang lang 'en'return lang
def compile_repl_group source pattern source.expect '<' name parse_name source True True source.expect '>' if name.isdigit index int name if not 0 < index < pattern.groups raise error 'invalidgroupreference' source.string source.pos return indextry return pattern.groupindex[name]except KeyError raise IndexError 'unknowngroup'
def _check_equality tuple1 tuple2 list1 list tuple1 list2 list tuple2 list1.sort list2.sort return list1 list2
def wipe_disks job disk_list for disk in disk_list partition.wipe_filesystem job disk['mountpt']
def find_language locale if not locale return NoneLANGS settings.AMO_LANGUAGES + settings.HIDDEN_LANGUAGES if locale in LANGS return localeloc settings.SHORTER_LANGUAGES.get locale if loc return loclocale to_language locale if locale in LANGS return localereturn None
def create_fake_repository test_case files source_repo FilePath test_case.mktemp source_repo.createDirectoryfor key in files new_file source_repo.preauthChild key if not new_file.parent .exists new_file.parent .makedirs new_file.setContent files[key] return 'file //' + source_repo.path
def getVertexGivenLine line splitLine line.split return Vector3 getFloat splitLine[1] getFloat splitLine[2] getFloat splitLine[3]
def requeue queue index -1 x queue.pop index queue.insert 0 x return x
def normalize_leaf element if not is_leaf element return element left operator right elementoriginal operatoroperator operator.lower if operator '<>' operator '! 'if isinstance right bool and operator in 'in' 'notin' _logger.warning "Thedomainterm'%s'shouldusethe' 'or'! 'operator." % left original right operator ' ' if operator 'in' else '! ' if isinstance right list tuple and operator in ' ' '! ' _logger.warning "Thedomainterm'%s'shouldusethe'in'or'notin'operator." % left original right operator 'in' if operator ' ' else 'notin' return left operator right
def dataset_follower_count context data_dict return _follower_count context data_dict ckan.logic.schema.default_follow_dataset_schema context['model'].UserFollowingDataset
def cbClose result from twisted.internet import reactorreactor.stop
def parse_sample_id_map sample_id_map_f result {}new_samp_id_counts defaultdict int for line in sample_id_map_f line line.strip if line samp_id mapped_id line.split ' DCTB ' if samp_id in result raise ValueError "ThefirstcolumnofthesampleIDmapmustcontainuniquesampleIDs '%s'isrepeated .Thesecondcolumn however maycontainrepeats." % samp_id elif new_samp_id_counts[mapped_id] > 2 raise ValueError "OnlytwooriginalsampleIDsmaymaptothesamenewsampleID.ThenewsampleID'%s'hasmorethantwosampleIDsmappingtoit." % mapped_id else result[samp_id] mapped_idnew_samp_id_counts[mapped_id] + 1return result
@receiver post_save sender ApiAccessRequest dispatch_uid 'api_access_request_post_save_email' def send_request_email sender instance created **kwargs if created _send_new_pending_email instance
def gradient image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._gradient image selem out out mask mask shift_x shift_x shift_y shift_y
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def snapshot domain name None suffix None if name and name.lower domain.lower raise CommandExecutionError 'VirtualMachine{name}isalreadydefined.Pleasechooseanothernameforthesnapshot'.format name name if not name name '{domain}-{tsnap}'.format domain domain tsnap time.strftime '%Y%m%d-%H%M%S' time.localtime if suffix name '{name}-{suffix}'.format name name suffix suffix doc ElementTree.Element 'domainsnapshot' n_name ElementTree.SubElement doc 'name' n_name.text name_get_domain domain .snapshotCreateXML ElementTree.tostring doc return {'name' name}
def extract_link_from_header_simple http_response header_name header_value if not header_value raise StopIterationtry yield http_response.get_url .url_join header_value except ValueError msg 'Theapplicationsenta"%s"headerthatw3affailedtocorrectlyparseasanURL theheadervaluewas "%s"'om.out.debug msg % header_name header_value
def print_fw iterable joins ' ' prefix '' indent 0 width 79 trail False shift_width 4preline '%s%s' % '' * shift_width prefix linew len preline sys.stdout.write preline for i entry in enumerate iterable if not trail and i len iterable - 1 sentry str entry else sentry '%s%s' % str entry joins if linew + len sentry > width sys.stdout.write '\n%s' % preline linew len preline sys.stdout.write sentry linew + len sentry sys.stdout.write '\n'
def getWindowAnalyzeFileGivenText fileName gcodeText repository None if gcodeText '' return Noneif repository None repository settings.getReadRepository SkeinlayerRepository skeinWindow getWindowGivenTextRepository fileName gcodeText repository skeinWindow.updateDeiconify return skeinWindow
def load_ip_q cidr ip_q _all_ips [str i for i in list netaddr.IPNetwork cidr ]base_exclude [str netaddr.IPNetwork cidr .network str netaddr.IPNetwork cidr .broadcast ]USED_IPS.update base_exclude for ip in random.sample _all_ips len _all_ips if ip not in USED_IPS ip_q.put ip
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _get_conn ret None _options _get_options ret database _options.get 'database' timeout _options.get 'timeout' if not database raise Exception 'sqlite3configoption"sqlite3.database"ismissing' if not timeout raise Exception 'sqlite3configoption"sqlite3.timeout"ismissing' log.debug 'Connectingthesqlite3database {0}timeout {1}'.format database timeout conn sqlite3.connect database timeout float timeout return conn
def ensure_pr_fetch modified Falseremotes git.remote .splitlines if u'edx' not in remotes git.remote u'add' u'edx' u'https //github.com/edx/edx-platform.git' modified Trueedx_fetches git.config u'remote.edx.fetch' get_all True .splitlines pr_fetch u'+refs/pull/*/head refs/remotes/edx/pr/*'if pr_fetch not in edx_fetches git.config u'remote.edx.fetch' pr_fetch add True modified Truegit.fetch u'edx' return modified
def unpair address if not salt.utils.validate.net.mac address raise CommandExecutionError 'InvalidBDaddresspassedtobluetooth.unpair' cmd 'bluez-test-deviceremove{0}'.format address out __salt__['cmd.run'] cmd .splitlines return out
def SetThreadName thread name thread.setName '[%s %s]' % GlobalProcess .Type name
def test_run_multiproc_nondaemon_false shouldHaveFailed Falsetry run_multiproc_nondaemon_with_flag False except shouldHaveFailed Trueassert shouldHaveFailed
def CreateClassFromXMLString target_class xml_string string_encoding None encoding string_encoding or XML_STRING_ENCODING if encoding and isinstance xml_string unicode xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _CreateClassFromElementTree target_class tree
def p_morerules p if len p 2 p[0] [[]]elif len p 3 p[0] [p[2]]else p[0] p[1]p[0].append p[3]
def unload_ipython_extension ipython pass
def security_group_rule_count_by_group context security_group_id return IMPL.security_group_rule_count_by_group context security_group_id
def plot_influence conf mse_values prediction_times complexities plt.figure figsize 12 6 host host_subplot 111 axes_class Axes plt.subplots_adjust right 0.75 par1 host.twinx host.set_xlabel 'ModelComplexity %s ' % conf['complexity_label'] y1_label conf['prediction_performance_label']y2_label 'Time s 'host.set_ylabel y1_label par1.set_ylabel y2_label p1 host.plot complexities mse_values 'b-' label 'predictionerror' p2 par1.plot complexities prediction_times 'r-' label 'latency' host.legend loc 'upperright' host.axis['left'].label.set_color p1.get_color par1.axis['right'].label.set_color p2.get_color plt.title 'InfluenceofModelComplexity-%s' % conf['estimator'].__name__ plt.show
@pytest.mark.skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1.5 b -3 x np.arange 100 y m_real x m MyModel f fitting.LevMarLSQFitter fitted_1 f m x y assert np.allclose fitted_1.a 1.5 assert np.allclose fitted_1.b -3 m2 MyModel m2.a.bounds -2 2 f2 fitting.LevMarLSQFitter fitted_2 f2 m2 x y assert np.allclose fitted_1.a 1.5 assert np.allclose fitted_1.b -3 assert np.any f2.fit_info[u'fjac'] ! 0
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _all_number_groups_are_exactly_present numobj normalized_candidate formatted_number_groups candidate_groups re.split NON_DIGITS_PATTERN normalized_candidate if numobj.extension is not None candidate_number_group_index len candidate_groups - 2 else candidate_number_group_index len candidate_groups - 1 if len candidate_groups 1 or candidate_groups[candidate_number_group_index].find national_significant_number numobj ! -1 return Trueformatted_number_group_index len formatted_number_groups - 1 while formatted_number_group_index > 0 and candidate_number_group_index > 0 if candidate_groups[candidate_number_group_index] ! formatted_number_groups[formatted_number_group_index] return Falseformatted_number_group_index - 1candidate_number_group_index - 1return candidate_number_group_index > 0 and candidate_groups[candidate_number_group_index].endswith formatted_number_groups[0]
def co_findloadednames co names {}names.update co_code_findloadednames co for c in co.co_consts if isinstance c type co names.update co_findloadednames c return names
def random_shear x intensity row_axis 1 col_axis 2 channel_axis 0 fill_mode 'nearest' cval 0.0 shear np.random.uniform - intensity intensity shear_matrix np.array [[1 - np.sin shear 0] [0 np.cos shear 0] [0 0 1]] h w x.shape[row_axis] x.shape[col_axis] transform_matrix transform_matrix_offset_center shear_matrix h w x apply_transform x transform_matrix channel_axis fill_mode cval return x
def parse_mime_type mime_type type mime_type.split ';' type plist type[0] type[1 ] try type subtype type.split '/' 1 except ValueError type subtype type.strip or '*' '*' else type type.strip or '*' subtype subtype.strip or '*' params {}for param in plist param param.split ' ' 1 if len param 2 key value param[0].strip param[1].strip if key and value params[key] valuereturn type subtype params
def alert_ack return s3_rest_controller
def builds_chain_fingerprinter registry xml_parent data fingerprinter XML.SubElement xml_parent 'org.jenkinsci.plugins.buildschainfingerprinter.AutomaticFingerprintJobProperty' XML.SubElement fingerprinter 'isPerBuildsChainEnabled' .text str data.get 'per-builds-chain' False .lower XML.SubElement fingerprinter 'isPerJobsChainEnabled' .text str data.get 'per-job-chain' False .lower
def p_atom_tuple p p[0] p[2]
def paragraphs count common True paras []for i in range count if common and i 0 paras.append COMMON_P else paras.append paragraph return paras
def get_redirect_on_fallback language site_id None language get_language_object language site_id return language.get 'redirect_on_fallback' True
def resolve1 x while isinstance x PDFObjRef x x.resolve return x
def write_incron_file_verbose user path return __salt__['cmd.run_all'] _get_incron_cmdstr path runas user python_shell False
@utils.arg 'project' metavar '<project_id>' help _ 'UUIDoftheprojecttocreatethecloudpipefor.' def do_cloudpipe_create cs args cs.cloudpipe.create args.project
def make_test_filename fname purpose base ext os.path.splitext fname return u'%s-%s%s' % base purpose ext
def get_max_id corpus maxid -1 for document in corpus maxid max maxid max [ -1 ] + [fieldid for fieldid _ in document] return maxid
def patch_2d_to_3d patch z 0 zdir u'z' verts get_patch_verts patch patch.__class__ Patch3Dpatch.set_3d_properties verts z zdir
def _base64_md5hash buffer_object hash_obj md5 _write_buffer_to_hash buffer_object hash_obj digest_bytes hash_obj.digest return base64.b64encode digest_bytes
def sameSynapse syn synapses for s in synapses if s[0] syn[0] and s[1] syn[1] and abs s[2] - syn[2] < 0.001 return Truereturn False
def set_memmap_min_size memmap_min_size if memmap_min_size is not None if not isinstance memmap_min_size string_types raise ValueError "'memmap_min_size'hastobeastring." if memmap_min_size[ -1 ] not in ['K' 'M' 'G'] raise ValueError 'Thesizehastobegiveninkilo- mega- orgigabytes e.g. 100K 500M 1G.' set_config 'MNE_MEMMAP_MIN_SIZE' memmap_min_size set_env False
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def _array_clip_val val val np.array val if val.max > 1 or val.min < 0 logger.warning 'valuewillbeclippedbetween0and1' val[...] np.clip val 0 1 return val
def _get_type e try return e.__class__except AttributeError return type e
def check_messages *messages def store_messages func func.checks_msgs messagesreturn funcreturn store_messages
def expand_indent line result 0for char in line if char ' DCTB ' result result / 8 * 8 + 8 elif char '' result + 1else breakreturn result
def view_my_tweets t Twitter auth authen try num int g['stuff'] except num c['HOME_TWEET_NUM']for tweet in reversed t.statuses.user_timeline count num screen_name g['original_name'] draw t tweet printNicely ''
def _valid_ip ip_address octets ip_address.split '.' if len octets ! 4 return Falsefor i octet in enumerate octets try octets[i] int octet except ValueError return False first_octet second_octet third_octet fourth_octet octetsif first_octet < 1 return Falseelif first_octet > 223 return Falseelif first_octet 127 return Falseif first_octet 169 and second_octet 254 return Falsefor octet in second_octet third_octet fourth_octet if octet < 0 or octet > 255 return Falsereturn True
def _match_query query attrs attrs_checked inner query[1 -1 ]if inner.startswith '&' '|' if inner[0] '&' matchfn allelse matchfn anygroups _paren_groups inner[1 ] return matchfn _match_query group attrs attrs_checked for group in groups if inner.startswith '!' return not _match_query query[2 -1 ] attrs attrs_checked k _sep v inner.partition ' ' attrs_checked.add k.lower return _match k v attrs
def register_functions lib ignore_errors def register item return register_function lib item ignore_errors list map register functionList
def jacobi a n assert n > 3 assert n % 2 1 a a % n if a 0 return 0if a 1 return 1 a1 e a 0 while a1 % 2 0 a1 e a1 // 2 e + 1 if e % 2 0 or n % 8 1 or n % 8 7 s 1else s -1 if a1 1 return sif n % 4 3 and a1 % 4 3 s - s return s * jacobi n % a1 a1
def get_remote_method_info method if not callable method return Nonetry method_info method.remoteexcept AttributeError return Noneif not isinstance method_info _RemoteMethodInfo return Nonereturn method_info
def test_basic_call_coroutine @hug.call @asyncio.coroutinedef hello_world return 'HelloWorld!'assert loop.run_until_complete hello_world 'HelloWorld!'
def maybe_get_subscriber_emails stream user_profile try subscribers get_subscriber_emails stream requesting_user user_profile except JsonableError subscribers []return subscribers
def parse_keqv_list l encoded_list [u.encode 'utf-8' for u in l]encoded_parsed urllib2.parse_keqv_list encoded_list return dict k.decode 'utf-8' v.decode 'utf-8' for k v in encoded_parsed.items
def Histogram data values None label None color None agg 'count' bins None yscale 'linear' xgrid False ygrid True continuous_range None **kw if continuous_range and not isinstance continuous_range Range1d raise ValueError 'continuous_rangemustbeaninstanceofbokeh.models.ranges.Range1d' y_range continuous_rangekw['label'] labelkw['values'] valueskw['color'] colorkw['agg'] aggkw['yscale'] yscalekw['xgrid'] xgridkw['ygrid'] ygridkw['y_range'] y_rangekw['bins'] binsreturn create_and_build HistogramBuilder data **kw
def brent func args brack None tol 1.48e-08 full_output 0 maxiter 500 options {'xtol' tol 'maxiter' maxiter}res _minimize_scalar_brent func brack args **options if full_output return res['x'] res['fun'] res['nit'] res['nfev'] else return res['x']
def validate_settings from django.conf import settingsfrom django_facebook import settings as facebook_settingsif facebook_settings.FACEBOOK_SKIP_VALIDATE returnif not facebook_settings.FACEBOOK_APP_ID logger.warn u'WarningFACEBOOK_APP_IDisntspecified' if not facebook_settings.FACEBOOK_APP_SECRET logger.warn u'WarningFACEBOOK_APP_SECRETisntspecified' if facebook_settings.FACEBOOK_STORE_LIKES or facebook_settings.FACEBOOK_STORE_FRIENDS if not facebook_settings.FACEBOOK_CELERY_STORE msg u'StoringfriendsorlikeswithoutusingCelerywillsignificantlyslowdownyourlogin\nItsrecommendedtoenableFACEBOOK_CELERY_STOREordisableFACEBOOK_STORE_FRIENDSandFACEBOOK_STORE_LIKES'logger.warn msg required [u'django_facebook.context_processors.facebook' u'django.core.context_processors.request']context_processors settings.TEMPLATE_CONTEXT_PROCESSORSfor context_processor in required if context_processor not in context_processors logger.warn u'Requiredcontextprocessor%swasntfound' context_processor backends settings.AUTHENTICATION_BACKENDSrequired u'django_facebook.auth_backends.FacebookBackend'if required not in backends logger.warn u'Requiredauthbackend%swasntfound' required
def ParseKindsAndSizes kinds sizes_known Truesize_total 0kinds_and_sizes RetrieveCachedStats if kinds_and_sizes for kind in kinds if kind in kinds_and_sizes size_total + kinds_and_sizes[kind]else sizes_known Falseelse sizes_known Falseif size_total size_total GetPrettyBytes size_total return sizes_known size_total len kinds - 2
def StringSizer field_number is_repeated is_packed tag_size _TagSize field_number local_VarintSize _VarintSizelocal_len lenassert not is_packed if is_repeated def RepeatedFieldSize value result tag_size * len value for element in value l local_len element.encode 'utf-8' result + local_VarintSize l + l return resultreturn RepeatedFieldSizeelse def FieldSize value l local_len value.encode 'utf-8' return tag_size + local_VarintSize l + l return FieldSize
def _init_mac g {}g['LIBDEST'] get_python_lib plat_specific 0 standard_lib 1 g['BINLIBDEST'] get_python_lib plat_specific 1 standard_lib 1 g['INCLUDEPY'] get_python_inc plat_specific 0 import MacOSif not hasattr MacOS 'runtimemodel' g['SO'] '.ppc.slb'else g['SO'] '.%s.slb' % MacOS.runtimemodel g['install_lib'] os.path.join EXEC_PREFIX 'Lib' g['install_platlib'] os.path.join EXEC_PREFIX 'Mac' 'Lib' g['srcdir'] ' 'global _config_vars_config_vars g
def cut_size G S T None weight None edges nx.edge_boundary G S T data weight default 1 if G.is_directed edges chain edges nx.edge_boundary G T S data weight default 1 return sum weight for u v weight in edges
def get_env global _jinja_envif _jinja_env is None _jinja_env create_env return _jinja_env
def get_conf_file_name cfg_root uuid cfg_file ensure_conf_dir False conf_base _get_conf_base cfg_root uuid ensure_conf_dir return '%s.%s' % conf_base cfg_file
def _safe_str obj try return str obj except Exception return object.__str__ obj
def _try_lookup table value default '' try string table[value]except KeyError string defaultreturn string
def unordered_list value def _helper value tabs indent ' DCTB ' * tabs if value[1] return '%s<li>%s\n%s<ul>\n%s\n%s</ul>\n%s</li>' % indent value[0] indent '\n'.join [_helper v tabs + 1 for v in value[1]] indent indent else return '%s<li>%s</li>' % indent value[0] return _helper value 1
def check_available mod return mod in available
def get_exponential_symbol locale LC_NUMERIC return Locale.parse locale .number_symbols.get 'exponential' u'E'
def test_ast_bad_if cant_compile u' if* ' cant_compile u' if*foobar ' cant_compile u' if*12345 '
def delete_user_org userid orgid profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile response requests.delete '{0}/api/orgs/{1}/users/{2}'.format profile['grafana_url'] orgid userid auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def plural_w s number suffix 's' capitalize False numbers 'zero' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'nine' 'ten' number_str numbers[number] if number < len numbers else str number if capitalize number_str number_str.capitalize return s.format number number_str s suffix if number % 100 ! 1 else ''
def tftpboot_location make version os_release str_version str version if make in 'fedora' 'redhat' 'centos' 'virtuozzo' return '/var/lib/tftpboot'elif make 'suse' return '/srv/tftpboot'elif make 'ubuntu' and os.path.exists '/var/lib/tftpboot' return '/var/lib/tftpboot'elif make 'ubuntu' and os.path.exists '/srv/tftp' return '/srv/tftp'elif make 'debian' and int str_version.split '.' [0] < 6 return '/var/lib/tftpboot'elif make 'debian' and int str_version.split '.' [0] > 6 return '/srv/tftp'else return '/tftpboot'
def test_filtfilt x np.r_[ 1 np.zeros 100 ]y filtfilt [1 0] [1 0] x padlen 0 assert_array_equal x y y mne_sosfiltfilt np.array [[1.0 0.0 0.0 1 0.0 0.0]] x padlen 0 assert_array_equal x y
@pytest.mark.parametrize u'testframe' totest_frames def test_cirs_altaz_nodist testframe coo0 CIRS UnitSphericalRepresentation 10 * u.deg 20 * u.deg obstime testframe.obstime coo1 coo0.transform_to testframe .transform_to coo0 assert_allclose coo0.cartesian.xyz coo1.cartesian.xyz
def format_scientific number format None return get_i18n .format_scientific number format
def _get_signature_object func as_instance eat_self if isinstance func type and not as_instance try func func.__init__except AttributeError return Noneeat_self Trueelif not isinstance func FunctionTypes try func func.__call__except AttributeError return Noneif eat_self sig_func partial func None else sig_func functry return func inspect.signature sig_func except ValueError return None
def _sorted_factors factors method if method 'sqf' def key obj poly exp objrep poly.rep.repreturn exp len rep len poly.gens rep else def key obj poly exp objrep poly.rep.repreturn len rep len poly.gens exp rep return sorted factors key key
def convert_char c if c in PRINTABLE_CHARACTERS return celse return '\\x%02x' % ord c
def dup_clear_denoms f K0 K1 None convert False if K1 is None if K0.has_assoc_Ring K1 K0.get_ring else K1 K0common K1.onefor c in f common K1.lcm common K0.denom c if not K1.is_one common f dup_mul_ground f common K0 if not convert return common f else return common dup_convert f K0 K1
def create_test_log_folder if not os.path.isdir sickbeard.LOG_DIR os.mkdir sickbeard.LOG_DIR
def del_store name store saltenv 'base' ret {'name' name 'result' True 'comment' '' 'changes' {}}cert_file __salt__['cp.cache_file'] name saltenv if cert_file is False ret['result'] Falseret['comment'] + 'Certificatefilenotfound.'else cert_serial __salt__['certutil.get_cert_serial'] cert_file serials __salt__['certutil.get_stored_cert_serials'] store if cert_serial in serials out __salt__['certutil.del_store'] cert_file store if 'successfully' in out ret['changes']['removed'] nameelse ret['result'] Falseret['comment'] + 'Failedtoremovethecertificate{0}'.format name else ret['comment'] + '{0}alreadyremoved.'.format name return ret
def add_permalink_methods content_inst for permalink_method in PERMALINK_METHODS setattr content_inst permalink_method.__name__ permalink_method.__get__ content_inst content_inst.__class__
def nquad func ranges args None opts None full_output False depth len ranges ranges [ rng if callable rng else _RangeFunc rng for rng in ranges]if args is None args if opts is None opts [dict [] ] * depth if isinstance opts dict opts [_OptFunc opts ] * depth else opts [ opt if callable opt else _OptFunc opt for opt in opts]return _NQuad func ranges opts full_output .integrate *args
def rs_or_single_client_noauth h client_context.host p client_context.port **kwargs return _mongo_client h p authenticate False **kwargs
def getWithLeastLength path point if len path < 1 return 0shortestPointIndex NoneshortestAdditionalLength 9.999999999876543e+17for pointIndex in xrange len path + 1 additionalLength getAdditionalLength path point pointIndex if additionalLength < shortestAdditionalLength shortestAdditionalLength additionalLengthshortestPointIndex pointIndexreturn shortestPointIndex
def plot_ccpr results exog_idx ax None fig ax utils.create_mpl_ax ax exog_name exog_idx utils.maybe_name_or_idx exog_idx results.model results maybe_unwrap_results results x1 results.model.exog[ exog_idx]x1beta x1 * results.params[exog_idx] ax.plot x1 x1beta + results.resid 'o' from statsmodels.tools.tools import add_constantmod OLS x1beta add_constant x1 .fit params mod.paramsfig abline_plot *params **dict ax ax ax.set_title 'Componentandcomponentplusresidualplot' ax.set_ylabel 'Residual+%s*beta_%d' % exog_name exog_idx ax.set_xlabel '%s' % exog_name return fig
def add_url url pp None script None cat None priority None nzbname None if 'http' not in url returnif not pp or pp '-1' pp Noneif script and script.lower 'default' script Noneif cat and cat.lower 'default' cat Nonelogging.info 'Fetching%s' url msg T 'TryingtofetchNZBfrom%s' % url future_nzo NzbQueue.do.generate_future msg pp script cat url url priority priority nzbname nzbname URLGrabber.do.add url future_nzo return future_nzo.nzo_id
def ensure_schemas for schema in OSF_META_SCHEMAS ensure_schema schema schema['name'] version schema.get 'version' 1
def generateGridData x y return_ticks False x np.arange x[0] x[1] x[2] y np.arange y[0] y[1] y[2] X Y np.meshgrid x y shape X.shapeds ClassificationDataSet 2 1 ds.setField 'input' np.concatenate X.reshape X.size 1 Y.reshape X.size 1 1 ds.setField 'target' np.zeros [X.size 1] ds._convertToOneOfMany if return_ticks return ds x y else return ds X Y
def MimeReplaceFilename header filename start header.find 'filename ' start header.find '"' start end header.find '"' start + 1 + 1 if start > 0 and end > start headernew header[ start + 1 ] + filename + header[ end - 1 ] else headernew header[ ]return headernew
def processes attrs None where None return _osquery_cmd table 'processes' attrs attrs where where
def _find_migrate_repo path os.path.join os.path.abspath os.path.dirname __file__ 'migrate_repo' assert os.path.exists path return path
def is_passing_status cert_status return CertificateStatuses.is_passing_status cert_status
def address_type address return len address 4 and _TYPE_A or _TYPE_AAAA
@require_POST@permission_required 'kbforums.sticky_thread' def sticky_thread request document_slug thread_id doc get_document document_slug request thread get_object_or_404 Thread pk thread_id document doc thread.is_sticky not thread.is_sticky log.info 'User%ssetis_sticky %sonKBthreadwithid %s' % request.user thread.is_sticky thread.id thread.save return HttpResponseRedirect reverse 'wiki.discuss.posts' args [document_slug thread_id]
@treeio_login_requireddef ajax_ticket_lookup request response_format 'html' tickets []if request.GET and 'term' in request.GET tickets Ticket.objects.filter name__icontains request.GET['term'] [ 10]return render_to_response 'services/ajax_ticket_lookup' {'tickets' tickets} context_instance RequestContext request response_format response_format
def list_env saltenv 'base' ret {}if saltenv not in __opts__['file_roots'] return retfor f_root in __opts__['file_roots'][saltenv] ret[f_root] {}for root dirs files in os.walk f_root sub ret[f_root]if root ! f_root sroot rootabove []while not os.path.samefile sroot f_root base os.path.basename sroot if base above.insert 0 base sroot os.path.dirname sroot for aroot in above sub sub[aroot]for dir_ in dirs sub[dir_] {}for fn_ in files sub[fn_] 'f'return ret
def test_set_model completionview model base.BaseCompletionModel filtermodel sortfilter.CompletionFilterModel model for i in range 3 model.appendRow QStandardItem str i completionview.set_model filtermodel assert completionview.model is filtermodel for i in range model.rowCount assert completionview.isExpanded filtermodel.index i 0
def acceptable_title node omit_titles ['test' 'photo' 'workshop' 'data']if any word in str node['title'] .lower for word in omit_titles return Falsereturn True
def image_volume_cache_get_all context **filters return IMPL.image_volume_cache_get_all context **filters
def id return _distro.id
def test_predict_2 tpot_obj TPOTClassifier tpot_obj._optimized_pipeline creator.Individual.from_string 'DecisionTreeClassifier input_matrix ' tpot_obj._pset tpot_obj._fitted_pipeline tpot_obj._toolbox.compile expr tpot_obj._optimized_pipeline tpot_obj._fitted_pipeline.fit training_features training_classes result tpot_obj.predict testing_features assert result.shape testing_features.shape[0]
def getDescriptionFill lines activateFillString getSettingString lines 'fill' 'ActivateFill' if activateFillString None or activateFillString 'False' return ''infillSolidityString getSettingString lines 'fill' 'InfillSolidity' return '_' + infillSolidityString.replace '.' '' + 'fill'
def split_token_in_parts token result []current []for part in token + u' ' if part u' ' if current result.append tuple current current []else current.append part return result
def peers ntp_peers __proxy__['napalm.call'] 'get_ntp_peers' **{} if not ntp_peers.get 'result' return ntp_peersntp_peers_list list ntp_peers.get 'out' {} .keys ntp_peers['out'] ntp_peers_listreturn ntp_peers
def bounds sizes low 0rv []for size in sizes rv.append low low + size low + sizereturn rv
def read_transform fid return read_double_matrix fid rows 4 cols 4
def block_indent text spaces 4 return '\n'.join [ '' * spaces + l for l in pprint.pformat text .splitlines ]
def parse_netntlm_chal headers chal_header ack try header_val2 headers[chal_header]except KeyError returnheader_val2 header_val2.split '' 1 if header_val2[0] 'NTLM' or header_val2[0] 'Negotiate' msg2 header_val2[1]msg2 base64.decodestring msg2 parse_ntlm_chal ack msg2
def mod_watch name **kwargs if kwargs.get 'sfun' in ['wait_set_key' 'wait_set'] return set_ name kwargs.get 'value' kwargs.get 'profile' if kwargs.get 'sfun' in ['wait_rm_key' 'wait_rm'] return rm_ name kwargs.get 'profile' return {'name' name 'changes' {} 'comment' 'etcd.{0[sfun]}doesnotworkwiththewatchrequisite pleaseuseetcd.wait_setoretcd.wait_rm'.format kwargs 'result' False}
def _format_datastore_key key path key.to_path parts []for i in range 0 len path // 2 kind path[ i * 2 ]value path[ i * 2 + 1 ]if isinstance value int long parts.append '%s id %d' % kind value else parts.append '%s name %s' % kind value return '>'.join parts
def _conf_set F alpha 0.05 nobs len F epsilon np.sqrt np.log 2.0 / alpha / 2 * nobs lower np.clip F - epsilon 0 1 upper np.clip F + epsilon 0 1 return lower upper
def parse_hex_escape source info esc expected_len in_set type saved_pos source.posdigits []for i in range expected_len ch source.get if ch not in HEX_DIGITS raise error 'incompleteescape\\%s%s' % type ''.join digits source.string saved_pos digits.append ch try value int ''.join digits 16 except ValueError passelse if value < 1114112 return make_character info value in_set raise error 'badhexescape\\%s%s' % esc ''.join digits source.string saved_pos
def _decode_embedded_list src output []for elem in src if isinstance elem dict elem _decode_embedded_dict elem elif isinstance elem list elem _decode_embedded_list elem elif isinstance elem bytes try elem elem.decode except UnicodeError passoutput.append elem return output
def cxOnePoint ind1 ind2 size min len ind1 len ind2 cxpoint random.randint 1 size - 1 ind1[cxpoint ] ind2[cxpoint ] ind2[cxpoint ] ind1[cxpoint ] return ind1 ind2
def checkout_with_shoppingcart request user course_key course_mode amount cart Order.get_cart_for_user user cart.clear enrollment_mode course_mode.slugCertificateItem.add_to_order cart course_key amount enrollment_mode cart.start_purchase callback_url request.build_absolute_uri reverse 'shoppingcart.views.postpay_callback' payment_data {'payment_processor_name' settings.CC_PROCESSOR_NAME 'payment_page_url' get_purchase_endpoint 'payment_form_data' get_signed_purchase_params cart callback_url callback_url extra_data [unicode course_key course_mode.slug] }return payment_data
def reverseNameFromIPv4Address address tokens list reversed address.split '.' + ['in-addr' 'arpa' ''] return '.'.join tokens
def test_model_extension class DummyModelExtension ModelExtension 'SimplestinstanceofModelExtension'class DummyModel Model 'SimplestinstanceofModel'extensions DummyModelExtension try '\nThisshouldcauseanassertionerrorforpassingatupleinsteadof\nalist\n'model DummyModel extensions extensions except AssertionError passextensions [DummyModelExtension None]try '\nThisshouldcauseanassertionerrorforpassingalistwhereeach\nelementisnotaninstanceofModelExtension\n'model DummyModel extensions extensions except AssertionError passextensions []for i in xrange 3 extensions.append DummyModelExtension '\nThisshouldnotcauseanassertion\n'model DummyModel extensions extensions
def ordLookup libname ord make_name False names ords.get libname.lower if names None if make_name is True return 'ord%d' % ord return Nonename names.get ord if name None return 'ord%d' % ord return name
def house_x_graph create_using None description ['adjacencylist' 'House-with-X-insideGraph' 5 [[2 3 4] [1 3 4] [1 2 4 5] [1 2 3 5] [3 4]]]G make_small_undirected_graph description create_using return G
def write_pid pidfile f open pidfile 'w' try f.write str os.getpid finally f.close
def IsPhrase node text GetQueryNodeText node return node.getType QueryParser.VALUE and text.startswith '"' and text.endswith '"'
def CDLSHOOTINGSTAR barDs count return call_talib_with_ohlc barDs count talib.CDLSHOOTINGSTAR
def _get_spider_loader settings if settings.get 'SPIDER_MANAGER_CLASS' warnings.warn 'SPIDER_MANAGER_CLASSoptionisdeprecated.PleaseuseSPIDER_LOADER_CLASS.' category ScrapyDeprecationWarning stacklevel 2 cls_path settings.get 'SPIDER_MANAGER_CLASS' settings.get 'SPIDER_LOADER_CLASS' loader_cls load_object cls_path try verifyClass ISpiderLoader loader_cls except DoesNotImplement warnings.warn 'SPIDER_LOADER_CLASS previouslynamedSPIDER_MANAGER_CLASS doesnotfullyimplementscrapy.interfaces.ISpiderLoaderinterface.Pleaseaddallmissingmethodstoavoidunexpectedruntimeerrors.' category ScrapyDeprecationWarning stacklevel 2 return loader_cls.from_settings settings.frozencopy
def SignedVarintEncode value result ''if value < 0 value + 1 << 64 bits value & 127 value >> 7while value result + HIGH_CHR_MAP[bits]bits value & 127 value >> 7result + CHR_MAP[bits]return result
def validate_source_string source return unhexlify source if len source 40 and not source.startswith 'http' else source
def _map_oids oids new_oids set for oid in oids if oid in _oid_map new_oids | _oid_map[oid]return oids | new_oids
def grading_context course_structure all_graded_blocks []all_graded_subsections_by_type OrderedDict for chapter_key in course_structure.get_children course_structure.root_block_usage_key for subsection_key in course_structure.get_children chapter_key subsection course_structure[subsection_key]scored_descendants_of_subsection []if subsection.graded for descendant_key in course_structure.post_order_traversal filter_func possibly_scored start_node subsection_key scored_descendants_of_subsection.append course_structure[descendant_key] subsection_info {'subsection_block' subsection 'scored_descendants' [child for child in scored_descendants_of_subsection if getattr child 'has_score' None ]}subsection_format getattr subsection 'format' '' if subsection_format not in all_graded_subsections_by_type all_graded_subsections_by_type[subsection_format] []all_graded_subsections_by_type[subsection_format].append subsection_info all_graded_blocks.extend scored_descendants_of_subsection return {'all_graded_subsections_by_type' all_graded_subsections_by_type 'all_graded_blocks' all_graded_blocks}
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def _pipe_segment_with_colons align colwidth w colwidthif align in [u'right' u'decimal'] return u'-' * w - 1 + u' ' elif align u'center' return u' ' + u'-' * w - 2 + u' ' elif align u'left' return u' ' + u'-' * w - 1 else return u'-' * w
def batch_code_exec caller ptr caller.ndb.batch_stackptrstack caller.ndb.batch_stackdebug caller.ndb.batch_debugcode stack[ptr]caller.msg format_header caller code err BATCHCODE.code_exec code extra_environ {'caller' caller} debug debug if err caller.msg format_code err return Falsereturn True
def proppatch path xml_request collection root ET.fromstring xml_request.encode 'utf8' props_to_set props_from_request root actions 'set' props_to_remove props_from_request root actions 'remove' multistatus ET.Element _tag 'D' 'multistatus' response ET.Element _tag 'D' 'response' multistatus.append response href ET.Element _tag 'D' 'href' href.text _href collection path response.append href for short_name in props_to_remove props_to_set[short_name] ''collection.set_meta props_to_set for short_name in props_to_set _add_propstat_to response short_name 200 return _pretty_xml multistatus
def p_specifier_qualifier_list_2 t pass
def halt return shutdown
def rax_find_network module rax_module network cnw rax_module.cloud_networkstry UUID network except ValueError if network.lower 'public' return cnw.get_server_networks PUBLIC_NET_ID elif network.lower 'private' return cnw.get_server_networks SERVICE_NET_ID else try network_obj cnw.find_network_by_label network except rax_module.exceptions.NetworkNotFound rax_module.exceptions.NetworkLabelNotUnique module.fail_json msg 'Nomatchingnetworkfound %s ' % network else return cnw.get_server_networks network_obj else return cnw.get_server_networks network
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def _load_libcrypto if sys.platform.startswith 'win' return cdll.LoadLibrary 'libeay32' elif getattr sys 'frozen' False and salt.utils.is_smartos return cdll.LoadLibrary glob.glob os.path.join os.path.dirname sys.executable 'libcrypto.so*' [0] else lib find_library 'crypto' if not lib and salt.utils.is_sunos lib glob.glob os.path.join '/opt/local/lib' 'libcrypto.so*' lib lib[0] if len lib > 0 else None if lib return cdll.LoadLibrary lib raise OSError 'CannotlocateOpenSSLlibcrypto'
def set_input_value_and_save page css value set_input_value page css value .send_keys Keys.ENTER page.wait_for_ajax
def candidates items artist album va_likely for plugin in find_plugins for candidate in plugin.candidates items artist album va_likely yield candidate
def test_solve_polynomial_cv_2 assert solve x + 1 / x - 1 x in [[ Rational 1 2 + I * sqrt 3 / 2 Rational 1 2 - I * sqrt 3 / 2 ] [ Rational 1 2 - I * sqrt 3 / 2 Rational 1 2 + I * sqrt 3 / 2 ]]
def ensure_file path ensure_directory_containing path open path 'a+' .close
def _assert_pid_not_reused fun @functools.wraps fun def wrapper self *args **kwargs if not self.is_running raise NoSuchProcess self.pid self._name return fun self *args **kwargs return wrapper
def hash_file filename return u'ed2k //|file|%s|%d|%s|/' % os.path.basename filename os.path.getsize filename hash_filehash filename .upper
def subprocess_Popen command **params startupinfo Noneif os.name 'nt' startupinfo subprocess.STARTUPINFO try startupinfo.dwFlags | subprocess.STARTF_USESHOWWINDOWexcept AttributeError startupinfo.dwFlags | subprocess._subprocess.STARTF_USESHOWWINDOWparams['shell'] Trueif isinstance command list command ''.join command stdin Noneif 'stdin' not in params stdin open os.devnull params['stdin'] stdin.fileno try proc subprocess.Popen command startupinfo startupinfo **params finally if stdin is not None stdin.close return proc
def _int64_feature value if not isinstance value list value [value]return tf.train.Feature int64_list tf.train.Int64List value value
def process_is_alive name_pattern return utils.system "pgrep-f'^ [^/]*/ * %s []|$ '" % name_pattern ignore_status True 0
def patchUserDatabase patch user uid group gid pwent pwd.getpwuid os.getuid grent grp.getgrgid os.getgid database UserDatabase database.addUser user pwent.pw_passwd uid pwent.pw_gid pwent.pw_gecos pwent.pw_dir pwent.pw_shell def getgrnam name result list grent result[result.index grent.gr_name ] groupresult[result.index grent.gr_gid ] gidresult tuple result return {group result}[name]patch pwd 'getpwnam' database.getpwnam patch grp 'getgrnam' getgrnam
def _dashboard_activity_query user_id limit q1 _user_activity_query user_id limit q2 _activities_from_everything_followed_by_user_query user_id limit return _activities_union_all q1 q2
def test_model_found arguments for goal assumptions in arguments g Expression.fromstring goal alist [lp.parse a for a in assumptions]m MaceCommand g assumptions alist max_models 50 found m.build_model for a in alist print '%s' % a print '|-%s %s\n' % g decode_result found
def require_mime *mimes @decoratordef wrap f self request *args **kwargs m Mimer request realmimes set rewrite {'json' 'application/json' 'yaml' 'application/x-yaml' 'xml' 'text/xml' 'pickle' 'application/python-pickle'}for idx mime in enumerate mimes realmimes.add rewrite.get mime mime if not m.content_type in realmimes return rc.BAD_REQUESTreturn f self request *args **kwargs return wrap
def _concat_datetimetz to_concat name None if len set [str x.dtype for x in to_concat] ! 1 raise ValueError 'to_concatmusthavethesametz' tz to_concat[0].tznew_values np.concatenate [x.asi8 for x in to_concat] return to_concat[0]._simple_new new_values tz tz name name
def _get_compute_id local_ips id_to_node_ips matching_instances []for server_id api_addresses in id_to_node_ips.items if api_addresses.intersection local_ips matching_instances.append server_id if len matching_instances 1 and matching_instances[0] return matching_instances[0]raise KeyError "Couldn'tfindmatchingnode."
def compute_exploration_contributors_summary exploration_id snapshots_metadata get_exploration_snapshots_metadata exploration_id current_version len snapshots_metadata contributors_summary collections.defaultdict int while True snapshot_metadata snapshots_metadata[ current_version - 1 ]committer_id snapshot_metadata['committer_id']is_revert snapshot_metadata['commit_type'] 'revert' if not is_revert and committer_id not in feconf.SYSTEM_USER_IDS contributors_summary[committer_id] + 1if current_version 1 breakif is_revert current_version snapshot_metadata['commit_cmds'][0]['version_number']else current_version - 1return contributors_summary
def parse_elements valid_els inner_els element result {}for sub in element t fixtag sub.tag NS_MAP [0]if ' ' in t t t.split ' ' [1]if t in valid_els result[t] sub.text or '' elif t in inner_els.keys inner_result inner_els[t] sub if isinstance inner_result tuple result[inner_result[0]] inner_result[1]else result[t] inner_resultm re.match ' [a-z0-9-]+ -list' t if m and 'count' in sub.attrib result[ '%s-count' % m.group 1 ] int sub.attrib['count'] else _log.info 'in<%s> uncaught<%s>' fixtag element.tag NS_MAP [0] t return result
def set_has_profile_image username is_uploaded upload_dt None if is_uploaded and upload_dt is None raise ValueError 'Nouploaddatetimewassupplied.' elif not is_uploaded upload_dt Nonetry profile UserProfile.objects.get user__username username except ObjectDoesNotExist raise UserNotFound profile.profile_image_uploaded_at upload_dtprofile.save
def split_by_comma_and_whitespace cstr return re.split '[\\s ]+' cstr
def create_java_start_cmd app_name port load_balancer_host max_heap db_location DATASTORE_PATHcmd [ 'cd' + constants.JAVA_APPSERVER + '&&' './appengine-java-sdk-repacked/bin/dev_appserver.sh' '--port ' + str port '--jvm_flag -Dsocket.permit_connect true' '--jvm_flag -Xmx{}m'.format max_heap '--disable_update_check' '--address ' + appscale_info.get_private_ip '--datastore_path ' + db_location '--login_server ' + load_balancer_host '--appscale_version 1' '--APP_NAME ' + app_name '--NGINX_ADDRESS ' + load_balancer_host '--NGINX_PORT anything' os.path.dirname locate_dir '/var/apps/' + app_name + '/app/' 'WEB-INF' ]return ''.join cmd
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def test_url_to_local_path assert_equal _url_to_local_path 'http //google.com/home/why.html' '.' op.join '.' 'home' 'why.html'
def wait objects None timeout None count None if objects is None return get_hub .join timeout timeout result []if count is None return list iwait objects timeout for obj in iwait objects objects timeout timeout result.append obj count - 1if count < 0 breakreturn result
def python_build return _sys_version [4 6]
def create_spider_for_request spidermanager request default_spider None log_none False log_multiple False **spider_kwargs snames spidermanager.find_by_request request if len snames 1 return spidermanager.create snames[0] **spider_kwargs if len snames > 1 and log_multiple log.msg 'Morethanonespidercanhandle %s-%s' % request ' '.join snames log.ERROR if len snames 0 and log_none log.msg 'Unabletofindspiderthathandles %s' % request log.ERROR return default_spider
def number_type numobj region_code region_code_for_number numobj metadata PhoneMetadata.metadata_for_region_or_calling_code numobj.country_code region_code if metadata is None return PhoneNumberType.UNKNOWNnational_number national_significant_number numobj return _number_type_helper national_number metadata
def GetRemoteAppIdFromServer server path remote_token None if not remote_token random.seed remote_token str random.random [2 ]remote_token str remote_token urlargs {'rtok' remote_token}response server.Send path payload None **urlargs if not response.startswith '{' raise ConfigurationError 'Invalidresponserecievedfromserver %s' % response app_info yaml.load response if not app_info or 'rtok' not in app_info or 'app_id' not in app_info raise ConfigurationError 'Errorparsingapp_idlookupresponse' if str app_info['rtok'] ! remote_token raise ConfigurationError 'Tokenvalidationfailedduringapp_idlookup. sent%s got%s ' % repr remote_token repr app_info['rtok'] return app_info['app_id']
def margins a margsums []ranged list range a.ndim for k in ranged marg np.apply_over_axes np.sum a [j for j in ranged if j ! k ] margsums.append marg return margsums
def test_write_table_html_fill_values buffer_output StringIO t Table [[1] [2]] names 'a' 'b' ascii.write t buffer_output fill_values '1' 'Helloworld' format 'html' t_expected Table [['Helloworld'] [2]] names 'a' 'b' buffer_expected StringIO ascii.write t_expected buffer_expected format 'html' assert buffer_output.getvalue buffer_expected.getvalue
def _get_verify_flow_redirect order cert_items CertificateItem.objects.filter order order if cert_items.count > 0 if cert_items.count > 1 log.warning u'Morethanonecertificateiteminorder%s;continuingwiththepayment/verificationflowforthefirstorderitem course%s .' order.id cert_items[0].course_id course_id cert_items[0].course_idurl reverse 'verify_student_payment_confirmation' kwargs {'course_id' unicode course_id } url + '?payment-order-num {order_num}'.format order_num order.id return HttpResponseRedirect url
def balanced_accuracy y_true y_pred all_classes list set np.append y_true y_pred all_class_accuracies []for this_class in all_classes this_class_sensitivity float sum y_pred this_class & y_true this_class / float sum y_true this_class this_class_specificity float sum y_pred ! this_class & y_true ! this_class / float sum y_true ! this_class this_class_accuracy this_class_sensitivity + this_class_specificity / 2.0 all_class_accuracies.append this_class_accuracy return np.mean all_class_accuracies
def smart_path string if os.path.supports_unicode_filenames return smart_unicode string return smart_str string
def nt_to_cw cur_enc cur_nt return array map int ''.join [INT_TO_BS[cur_enc[x]] for x in cur_nt]
def chain_names sg_id sg_name prefix sg_label sg_id sg_name in_chain_name prefix + SUFFIX_IN out_chain_name prefix + SUFFIX_OUT return {'in' in_chain_name 'out' out_chain_name}
def make_shared shape raise NotImplementedError 'TODO implementthefunction'
def test_continue_on_collection_errors_maxfail testdir testdir.makepyfile **COLLECTION_ERROR_PY_FILES res testdir.runpytest '--continue-on-collection-errors' '--maxfail 3' assert res.ret 2 res.stdout.fnmatch_lines ['collected2items/2errors' '*Interrupted stoppingafter3failures*' '*1failed 2error*']
def object_mapper instance return object_state instance .mapper
def user_has_cart_context_processor request def should_display_shopping_cart '\nReturnsabooleaniftheuserhasanitemsinacartwherebytheshoppingcartshouldbe\ndisplayedtotheloggedinuser\n'return request.user.is_authenticated and is_shopping_cart_enabled and Order.does_user_have_cart request.user and Order.user_cart_has_items request.user [PaidCourseRegistration CourseRegCodeItem] return {'should_display_shopping_cart_func' should_display_shopping_cart}
def figshare_root_folder node_settings auth **kwargs if not node_settings.has_auth or not node_settings.folder_id return Nonenode node_settings.ownerreturn [rubeus.build_addon_root node_settings node_settings name node_settings.fetch_folder_name permissions auth nodeUrl node.url nodeApiUrl node.api_url rootFolderType node_settings.folder_path private_key kwargs.get 'view_only' None ]
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
def is_mutating status if not status return Falsemutating set [u'insert' u'update' u'delete'] return status.split None 1 [0].lower in mutating
def clocktime_to_millisecond value return value // Gst.MSECOND
def get_unused_port port s get_unused_port_and_socket s.close return port
def find_degree M deg_f j deg_ffor i in range 0 M.cols if M[ M.rows - 1 i ] 0 j j - 1 else return j if j > 0 else 0
def convert_fastaqual_fastq fasta_file_path qual_file_path conversion_type 'fastaqual_to_fastq' output_directory '.' multiple_output_files False ascii_increment 33 full_fastq False full_fasta_headers False if conversion_type 'fastaqual_to_fastq' convert_fastq fasta_file_path qual_file_path output_directory multiple_output_files ascii_increment full_fastq full_fasta_headers elif conversion_type 'fastq_to_fastaqual' convert_fastaqual fasta_file_path output_directory multiple_output_files ascii_increment full_fastq full_fasta_headers else raise ValueError 'conversion_typemustbefastaqual_to_fastqorfastq_to_fastaqual.'
def onAllSpaceGeometryLoaded spaceID isBootstrap mapping pass
def _compute_delta log_moments eps min_delta 1.0for moment_order log_moment in log_moments if moment_order 0 continueif math.isinf log_moment or math.isnan log_moment sys.stderr.write 'The%d-thorderisinforNan\n' % moment_order continueif log_moment < moment_order * eps min_delta min min_delta math.exp log_moment - moment_order * eps return min_delta
def assert_desired_datasets case deployer desired_manifestations local_datasets local_applications additional_node_config set expected_datasets leases Leases calculator RecordingCalculator NOTHING_TO_DO deployer deployer.set calculator calculator cluster_configuration Deployment nodes {Node uuid deployer.node_uuid hostname deployer.hostname manifestations {manifestation.dataset.dataset_id manifestation for manifestation in desired_manifestations} } | additional_node_config leases leases local_state BlockDeviceDeployerLocalState node_uuid deployer.node_uuid hostname deployer.hostname datasets {dataset.dataset_id dataset for dataset in local_datasets} node_state nonmanifest_datasets local_state.shared_state_changes cluster_state DeploymentState nodes {node_state.set applications local_applications } nonmanifest_datasets nonmanifest_datasets.datasets deployer.calculate_changes configuration cluster_configuration cluster_state cluster_state local_state local_state case.assertEqual {dataset.dataset_id dataset for dataset in expected_datasets} calculator.desired_datasets
def returnToMatches allowed_return_to_urls return_to for allowed_return_to in allowed_return_to_urls return_realm TrustRoot.parse allowed_return_to if return_realm is not None and not return_realm.wildcard and return_realm.validateURL return_to return Truereturn False
def _get_allow_unicode_flag import doctestreturn doctest.register_optionflag 'ALLOW_UNICODE'
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def jnjnp_zeros nt if not isscalar nt or floor nt ! nt or nt > 1200 raise ValueError 'Numbermustbeinteger< 1200.' nt int nt n m t zo specfun.jdzo nt return zo[1 nt + 1 ] n[ nt] m[ nt] t[ nt]
def flowgram_id_to_seq_id_map seqs result {}for id_ seq in seqs fields id_.split seq_id id_flowgram_id fields[1]result[flowgram_id] seq_idreturn result
def _get_server_health_option config for monitor in config['healthmonitors'] if monitor['status'] ACTIVE and monitor['admin_state_up'] breakelse return '' [] server_addon 'checkinter% delay dsfall% max_retries d' % monitor opts [ 'timeoutcheck%ds' % monitor['timeout'] ]if monitor['type'] in constants.HEALTH_MONITOR_HTTP constants.HEALTH_MONITOR_HTTPS opts.append 'optionhttpchk% http_method s% url_path s' % monitor opts.append 'http-checkexpectrstatus%s' % '|'.join _expand_expected_codes monitor['expected_codes'] if monitor['type'] constants.HEALTH_MONITOR_HTTPS opts.append 'optionssl-hello-chk' return server_addon opts
def ext_functest_builder method func def do_test self if not isinstance func types.BuiltinFunctionType raise SkipTest '%sextensionnotfound' % func method self func return do_test
def benchmark_throughputs configuration duration_secs 0.1 X_train y_train X_test y_test generate_dataset configuration['n_train'] configuration['n_test'] configuration['n_features'] throughputs dict for estimator_config in configuration['estimators'] estimator_config['instance'].fit X_train y_train start_time time.time n_predictions 0while time.time - start_time < duration_secs estimator_config['instance'].predict X_test[[0]] n_predictions + 1throughputs[estimator_config['name']] n_predictions / duration_secs return throughputs
@cli_app.command 'security-cleanup' @click.option '--app' default 'app' help 'Yourapplicationinitdirectory package ' @click.option '--appbuilder' default 'appbuilder' help 'yourAppBuilderobject' def security_cleanup app appbuilder _appbuilder import_application app appbuilder _appbuilder.security_cleanup click.echo click.style 'Finishedsecuritycleanup' fg 'green'
@FileSystem.in_directory current_directory 'django' 'dill' def test_model_update status out run_scenario 'leaves' 'update' 1 assert_equals status 0 out status out run_scenario 'leaves' 'update' 2 assert_not_equals status 0 out assert 'IntegrityError PRIMARYKEYmustbeunique' in out status out run_scenario 'leaves' 'update' 3 assert_not_equals status 0 out assert 'The"pk"fieldisrequiredforallupdateoperations' in out status out run_scenario 'leaves' 'update' 4 assert_not_equals status 0 out assert 'Mustusethewrites_modelsdecoratortoupdatemodels' in out
def form_hmac form data []for bf in form if form.empty_permitted and not form.has_changed value bf.data or '' else value bf.field.clean bf.data or '' if isinstance value basestring value value.strip data.append bf.name value pickled pickle.dumps data pickle.HIGHEST_PROTOCOL key_salt 'django.contrib.formtools'return salted_hmac key_salt pickled .hexdigest
def all_status return {'cpuinfo' cpuinfo 'cpustats' cpustats 'diskstats' diskstats 'diskusage' diskusage 'loadavg' loadavg 'meminfo' meminfo 'netdev' netdev 'netstats' netstats 'uptime' uptime 'vmstats' vmstats 'w' w }
def metadef_resource_type_get_all context session None session session or get_session return metadef_resource_type_api.get_all context session
def test_pickle_globals def f x return np.sin x + np.cos x assert set ['np' '__builtins__'] set _loads _dumps f .__globals__.keys
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def add_user_permission doctype name user with_message False if name not in frappe.defaults.get_user_permissions user .get doctype [] if not frappe.db.exists doctype name frappe.throw _ u'{0}{1}notfound' .format _ doctype name frappe.DoesNotExistError frappe.defaults.add_default doctype name user u'UserPermission' elif with_message msgprint _ u'Permissionalreadyset'
def get_current_kernel_arch return platform.machine
@receiver initializing def _on_initializing *args **kwargs from reviewboard.admin.widgets import init_widgetsinit_widgets
def _child_vhds session sr_ref vdi_uuid_list old_snapshots_only False children set for ref rec in _get_all_vdis_in_sr session sr_ref rec_uuid rec['uuid']if rec_uuid in vdi_uuid_list continueparent_uuid _get_vhd_parent_uuid session ref rec if parent_uuid not in vdi_uuid_list continueif old_snapshots_only and not _is_vdi_a_snapshot rec continuechildren.add rec_uuid return list children
def get_status_counts group_by header_groups [] fixed_headers {} **filter_data return get_group_counts group_by header_groups header_groups fixed_headers fixed_headers extra_select_fields tko_rpc_utils.STATUS_FIELDS **filter_data
def bz2_decode input errors 'strict' assert errors 'strict' output bz2.decompress input return output len input
@FileSystem.in_directory current_directory 'django' 'brocolis' def test_harvest_sets_environment_variabled_for_gae status out run_scenario 'leaves' 'appengine' assert_equals status 0 out
def _ems_diff data0 data1 return np.mean data0 axis 0 - np.mean data1 axis 0
def load_fips_ecdsa_key_pair_vectors vector_data vectors []key_data Nonefor line in vector_data line line.strip if not line or line.startswith '#' continueif line[1 -1 ] in _ECDSA_CURVE_NAMES curve_name _ECDSA_CURVE_NAMES[line[1 -1 ]]elif line.startswith 'd ' if key_data is not None vectors.append key_data key_data {'curve' curve_name 'd' int line.split ' ' [1] 16 }elif key_data is not None if line.startswith 'Qx ' key_data['x'] int line.split ' ' [1] 16 elif line.startswith 'Qy ' key_data['y'] int line.split ' ' [1] 16 assert key_data is not None vectors.append key_data return vectors
def fake_urandom n return ''.join chr random.randint 0 255 for _ in xrange n
def williams_correction n a G q 1.0 + a + 1.0 / 6.0 * n return G / q
def register_hosting_service name cls cls.hosting_service_id name_hosting_service_registry.register cls
def _f_ieqcons x_full k_params x_params x_full[ k_params]x_added x_full[k_params ]return np.append x_params + x_added x_added - x_params
def _quota_reservations session context reservations return model_query context models.Reservation read_deleted 'no' session session .filter models.Reservation.uuid.in_ reservations .with_lockmode 'update' .all
def handle500 request return render request 'handlers/500.html' status 500
def find_nodes_with_matching_text page xpath regex xpath_matches page.xpath xpath results []for xp in xpath_matches if re.search regex xp.text_content results.append xp return results
def _clear_user_info_cookie cookie_name _COOKIE_NAME cookie Cookie.SimpleCookie cookie[cookie_name] ''cookie[cookie_name]['path'] '/'cookie[cookie_name]['max-age'] '0'if AppDashboardHelper.USE_SHIBBOLETH cookie[cookie_name]['domain'] AppDashboardHelper.SHIBBOLETH_COOKIE_DOMAINreturn cookie[cookie_name].OutputString
def get_leaking_objects objects None if objects is None gc.collect objects gc.get_objects try ids set id i for i in objects for i in objects ids.difference_update id j for j in gc.get_referents i return [i for i in objects if id i in ids ]finally del objects i
def _make_label_to_row_indices labels result {}for row_index label in enumerate labels short_label tuple label[ 5] if result.get short_label None is None result[short_label] []result[short_label].append row_index return result
def initialize_report report_type start_date end_date start_letter None end_letter None for item in REPORT_TYPES if report_type in item return item[1] start_date end_date start_letter end_letter raise ReportTypeDoesNotExistException
def jseval script try interpreter Popen ['js'] stdin PIPE stdout PIPE except OSError return script result errors interpreter.communicate script if interpreter.poll or errors return scriptreturn result
def write_stream_with_colors_win_py3 stream outfile flush color '\x1b['encoding outfile.encodingfor chunk in stream if color in chunk outfile.write chunk.decode encoding else outfile.buffer.write chunk if flush outfile.flush
def get url conn urlopen url resp conn.read conn.close return resp
def BuildCampaignCriterionOperations campaign_operations criterion_operations [{'xsi_type' 'CampaignCriterionOperation' 'operand' {'xsi_type' 'NegativeCampaignCriterion' 'campaignId' campaign_operation['operand']['id'] 'criterion' {'xsi_type' 'Keyword' 'matchType' 'BROAD' 'text' 'venus'}} 'operator' 'ADD'} for campaign_operation in campaign_operations]return criterion_operations
def open_logfile filename mode 'a' filename os.path.expanduser filename filename os.path.abspath filename dirname os.path.dirname filename if not os.path.exists dirname os.makedirs dirname exists os.path.exists filename log_fp open filename mode if exists log_fp.write '%s\n' % '-' * 60 log_fp.write '%srunon%s\n' % sys.argv[0] time.strftime '%c' return log_fp
def horizon request context {'HORIZON_CONFIG' conf.HORIZON_CONFIG 'True' True 'False' False}return context
def uuid_bin_to_str uuid block1 block2 block3 struct.unpack '<LHH' uuid[ 8] block4 block5 block6 struct.unpack '>HHL' uuid[8 16] return '%08x-%04x-%04x-%04x-%04x%08x' % block1 block2 block3 block4 block5 block6
def leaves tree branches attrgetter 'branches' return node for node in postorder tree branches if node.is_leaf
def _sha1_mangle_key key try key key.encode 'utf-8' errors 'xmlcharrefreplace' except UnicodeError AttributeError passreturn util.sha1_mangle_key key
def group seq multiple True if not seq return [] current groups [seq[0]] [] for elem in seq[1 ] if elem current[ -1 ] current.append elem else groups.append current current [elem]groups.append current if multiple return groupsfor i current in enumerate groups groups[i] current[0] len current return groups
def get_xdg_cache_dir env os.environif os.name 'posix' and sys.platform ! 'darwin' xdg env.get 'XDG_CACHE_HOME' None or os.path.join get_home_dir '.cache' if xdg and _writable_dir xdg return py3compat.cast_unicode xdg fs_encoding return None
def get_mode path if not os.path.exists path return ''func_name '{0}.get_mode'.format __virtualname__ if __opts__.get 'fun' '' func_name log.info 'Thefunction{0}shouldnotbeusedonWindowssystems;seefunctiondocsfordetails.ThevaluereturnedisalwaysNone.'.format func_name return None
def add_ngram sequences token_indice ngram_range 2 new_sequences []for input_list in sequences new_list input_list[ ]for i in range len new_list - ngram_range + 1 for ngram_value in range 2 ngram_range + 1 ngram tuple new_list[i i + ngram_value ] if ngram in token_indice new_list.append token_indice[ngram] new_sequences.append new_list return new_sequences
def auth_field_and_value resource if '|resource' in request.endpoint public_method_list_to_check 'public_methods'else public_method_list_to_check 'public_item_methods'resource_dict app.config['DOMAIN'][resource]auth resource_auth resource request_auth_value auth.get_request_auth_value if auth else None auth_field resource_dict.get 'auth_field' None if request.method not in resource_dict[public_method_list_to_check] else None return auth_field request_auth_value
def parse_set_item source info version info.flags & _ALL_VERSIONS or DEFAULT_VERSION if source.match '\\' return parse_escape source info True saved_pos source.posif source.match '[ ' try return parse_posix_class source info except ParseError source.pos saved_posif version VERSION1 and source.match '[' negate source.match '^' item parse_set_union source info if not source.match ']' raise error 'missing]' source.string source.pos if negate item item.with_flags positive not item.positive return itemch source.get if not ch raise error 'unterminatedcharacterset' source.string source.pos return Character ord ch
def filter_format_number val places None grouping True if not isinstance val int float int return valif places is not None format u'%.' + str places + u'f' elif isinstance val int int format u'%d'else format u'%.02f'locale.setlocale locale.LC_ALL u'' return locale.format format val grouping
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def combine_game_stats games return reduce lambda ps1 ps2 ps1 + ps2 [g.players for g in games if g is not None ]
def _number_of_set_bits_to_ipv4_netmask set_bits return cidr_to_ipv4_netmask _number_of_set_bits set_bits
def cache_cluster_exists name conn None region None key None keyid None profile None return bool describe_cache_clusters name name conn conn region region key key keyid keyid profile profile
def iscoroutinefunction func return getattr func '_is_coroutine' False or hasattr inspect 'iscoroutinefunction' and inspect.iscoroutinefunction func
def _render_template config_file dirname filename os.path.split config_file env Environment loader FileSystemLoader dirname template env.get_template filename config template.render __grains__ return config
def id return _distro.id
def validate_template_limit contain_str if len contain_str > cfg.CONF.max_template_size msg _ 'Templatesize % actual_len sbytes exceedsmaximumallowedsize % limit sbytes .' % {'actual_len' len contain_str 'limit' cfg.CONF.max_template_size} raise exception.RequestLimitExceeded message msg
@pytest.fixture scope u'function' def remove_additional_folders request def fin_remove_additional_folders if os.path.exists u'tests/test-pyhooks/inputpyhooks' utils.rmtree u'tests/test-pyhooks/inputpyhooks' if os.path.exists u'inputpyhooks' utils.rmtree u'inputpyhooks' if os.path.exists u'tests/test-shellhooks' utils.rmtree u'tests/test-shellhooks' request.addfinalizer fin_remove_additional_folders
def option_from_wire otype wire current olen cls get_option_class otype return cls.from_wire otype wire current olen
def serve_protected_thumbnail request path source_path thumbnail_to_original_filename path if not source_path raise Http404 'Filenotfound' try file_obj File.objects.get file source_path is_public False except File.DoesNotExist raise Http404 'Filenotfound' if not file_obj.has_read_permission request if settings.DEBUG raise PermissionDeniedelse raise Http404 'Filenotfound' try thumbnail ThumbnailFile name path storage file_obj.file.thumbnail_storage return thumbnail_server.serve request thumbnail save_as False except Exception raise Http404 'Filenotfound'
@memoizeddef getColor value default None if isinstance value Color return valuevalue str value .strip .lower if value 'transparent' or value 'none' return defaultif value in COLOR_BY_NAME return COLOR_BY_NAME[value]if value.startswith '#' and len value 4 value '#' + value[1] + value[1] + value[2] + value[2] + value[3] + value[3] elif rgb_re.search value r g b [int x for x in rgb_re.search value .groups ]value '#%02x%02x%02x' % r g b else passreturn toColor value default
def testUsingPsychoPyMonitorConfig io launchHubServer psychopy_monitor_name 'testMonitor' display io.devices.displayprint 'DisplayPsychopyMonitorName ' display.getPsychopyMonitorName print 'DisplayDefaultEyeDistance ' display.getDefaultEyeDistance print 'DisplayPhysicalDimensions ' display.getPhysicalDimensions io.quit
def _convert_etree_element_to_queue entry_element queue Queue invalid_queue Truequeue_element entry_element.find './atom content/sb QueueDescription' _etree_sb_feed_namespaces if queue_element is not None mappings [ 'LockDuration' 'lock_duration' None 'MaxSizeInMegabytes' 'max_size_in_megabytes' int 'RequiresDuplicateDetection' 'requires_duplicate_detection' _parse_bool 'RequiresSession' 'requires_session' _parse_bool 'DefaultMessageTimeToLive' 'default_message_time_to_live' None 'DeadLetteringOnMessageExpiration' 'dead_lettering_on_message_expiration' _parse_bool 'DuplicateDetectionHistoryTimeWindow' 'duplicate_detection_history_time_window' None 'EnableBatchedOperations' 'enable_batched_operations' _parse_bool 'MaxDeliveryCount' 'max_delivery_count' int 'MessageCount' 'message_count' int 'SizeInBytes' 'size_in_bytes' int ]for map in mappings if _read_etree_element queue_element map[0] queue map[1] map[2] invalid_queue Falseif invalid_queue raise AzureServiceBusResourceNotFound _ERROR_QUEUE_NOT_FOUND for name value in _ETreeXmlToObject.get_entry_properties_from_element entry_element True .items setattr queue name value return queue
def article_url content return '{content.settings[SITEURL]}/{content.url}'.format content content .encode 'utf-8'
def set_verbose verbose global _verbose_verbose verbose
def get_hub_class global _threadlocaltry hubtype _threadlocal.Hubexcept AttributeError hubtype Noneif hubtype is None hubtype _threadlocal.Hub Hubreturn hubtype
def eval_b x if sys.version_info.major 2 return xelse import codecsreturn codecs.utf_8_encode x [0]
def segment_matches_section segment section sh_size section.header.sh_size + 3 & ~ 3 return section.header.sh_addr segment.addr and sh_size len segment.data
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
def _train_iis xs classes features f_sharp alphas e_empirical max_newton_iterations newton_converge p_yx _calc_p_class_given_x xs classes features alphas N len xs newalphas alphas[ ]for i in range len alphas delta _iis_solve_delta N features[i] f_sharp e_empirical[i] p_yx max_newton_iterations newton_converge newalphas[i] + deltareturn newalphas
def _split_mime_type mime_type if mime_type match _MIME_PATTERN.match mime_type if not match raise _InvalidMIMETypeFormatError 'IncorrectlyformattedMIMEtype %s' % mime_type return match.groups else return 'application' 'octet-stream'
def create_default_options allowed_methods allowed ' '.join allowed_methods def on_options req resp **kwargs resp.status HTTP_204resp.set_header 'Allow' allowed resp.set_header 'Content-Length' '0' return on_options
def simpleMultivariateNormalPdf z detFactorSigma dim len z return exp -0.5 * dot z z / power 2.0 * pi dim / 2.0 * detFactorSigma
def hex_encode input errors 'strict' assert errors 'strict' output binascii.b2a_hex input return output len input
def create_blockdevicedeployer test_case hostname u'192.0.2.1' node_uuid uuid4 eventually_consistent False api loopbackblockdeviceapi_for_test test_case if eventually_consistent api EventuallyConsistentBlockDeviceAPI api async_api _SyncToThreadedAsyncAPIAdapter _sync api _reactor NonReactor _threadpool NonThreadPool return BlockDeviceDeployer hostname hostname node_uuid node_uuid block_device_api api _async_block_device_api async_api mountroot mountroot_for_test test_case
def avail_locations call None if call 'action' raise SaltCloudSystemExit 'Theavail_locationsfunctionmustbecalledwith-for--function orwiththe--list-locationsoption' ret {}conn get_conn service 'SoftLayer_Product_Package' locations conn.getLocations id 50 for location in locations ret[location['id']] {'id' location['id'] 'name' location['name'] 'location' location['longName']}available conn.getAvailableLocations id 50 for location in available if location.get 'isAvailable' 0 is 0 continueret[location['locationId']]['available'] Truereturn ret
def leaky_relu x slope 0.2 return LeakyReLU slope x
def image_description_dict description if description.startswith 'shape ' shape tuple int i for i in description[7 -1 ].split ' ' return dict shape shape if description.startswith '{' and description.endswith '}' return json.loads description.decode 'utf-8' raise ValueError 'unknownimagedescription'
def copy_extras config outdir config[u'outdir']for dst src in config[u'extras'].items dst_path os.path.join outdir dst dst_dir os.path.dirname dst_path if not os.path.isdir dst_dir os.makedirs dst_dir shutil.copy src dst_path
def get_current_reporter return _reporters[ -1 ]
def format_money amount digits None widen 0 locale None if not locale loc get_current_babel_locale else loc get_babel_locale locale if widen 0 and digits is None return format_currency amount.value amount.currency locale loc currency_digits True pattern loc.currency_formats['standard'].patternif digits is not None pattern pattern.replace '.00' '.' + digits * '0' if widen pattern pattern.replace '.00' '.00' + widen * '0' return format_currency amount.value amount.currency pattern loc currency_digits False
def pn_cli module username module.params['pn_cliusername']password module.params['pn_clipassword']cliswitch module.params['pn_cliswitch']if username and password cli '/usr/bin/cli--quiet--user%s %s' % username password else cli '/usr/bin/cli--quiet'if cliswitch if cliswitch 'local' cli + 'switch-local'else cli + 'switch' + cliswitch return cli
def swirl image center None strength 1 radius 100 rotation 0 output_shape None order 1 mode None cval 0 clip True preserve_range False if mode is None warn 'Thedefaultof`mode`in`skimage.transform.swirl`willchangeto`reflect`inversion0.15.' mode 'constant'if center is None center np.array image.shape [ 2] / 2 warp_args {'center' center 'rotation' rotation 'strength' strength 'radius' radius}return warp image _swirl_mapping map_args warp_args output_shape output_shape order order mode mode cval cval clip clip preserve_range preserve_range
def _get_cached_requirements requirements saltenv req_file senv salt.utils.url.parse requirements if senv saltenv senvif req_file not in __salt__['cp.list_master'] saltenv return Falsecached_requirements __salt__['cp.is_cached'] requirements saltenv if not cached_requirements cached_requirements __salt__['cp.cache_file'] requirements saltenv if __salt__['cp.hash_file'] requirements saltenv ! __salt__['cp.hash_file'] cached_requirements saltenv cached_requirements __salt__['cp.cache_file'] requirements saltenv return cached_requirements
def addToPathsRecursively paths vector3Lists if vector3Lists.__class__ Vector3 or vector3Lists.__class__.__name__ 'Vector3Index' paths.append [vector3Lists] returnpath []for vector3List in vector3Lists if vector3List.__class__ list addToPathsRecursively paths vector3List elif vector3List.__class__ Vector3 path.append vector3List if len path > 0 paths.append path
def in6_get_common_plen a b def matching_bits byte1 byte2 for i in range 8 cur_mask 128 >> i if byte1 & cur_mask ! byte2 & cur_mask return ireturn 8tmpA inet_pton socket.AF_INET6 a tmpB inet_pton socket.AF_INET6 b for i in range 16 mbits matching_bits ord tmpA[i] ord tmpB[i] if mbits ! 8 return 8 * i + mbits return 128
def key_from_protobuf pb path_args []for element in pb.path path_args.append element.kind if element.id path_args.append element.id if element.name path_args.append element.name project Noneif pb.partition_id.project_id project pb.partition_id.project_idnamespace Noneif pb.partition_id.namespace_id namespace pb.partition_id.namespace_idreturn Key namespace namespace project project *path_args
def get_network_attach_config_spec client_factory vif_info index vif_limits None config_spec client_factory.create 'ns0 VirtualMachineConfigSpec' vif_spec _create_vif_spec client_factory vif_info vif_limits config_spec.deviceChange [vif_spec]if vif_info['iface_id'] is not None config_spec.extraConfig [_iface_id_option_value client_factory vif_info['iface_id'] index ]return config_spec
def test_format_flake8 if not flake8_available raise SkipTest 'flake8isnotinstalled' total_errors 0for path in list_files rel_path os.path.relpath path theano.__path__[0] if rel_path in whitelist_flake8 continueelse error_num flake8.main.check_file path ignore ignore total_errors + error_numif total_errors > 0 raise AssertionError 'FLAKE8Formatnotrespected'
def encrypted_dict data encryption_key None return_data {}if not data return return_datafor prop_name prop_value in data.items prop_string jsonutils.dumps prop_value encrypted_value encrypt prop_string encryption_key return_data[prop_name] encrypted_valuereturn return_data
def split_url_or_path url_or_path if ' //' in url_or_path return url_or_path.rstrip '/' .rsplit '/' 1 return osp.split url_or_path.rstrip osp.sep
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def test_find_number_2 s 'aghwirougiuhfajlsopka"-987?'r find_number s assert s[r[0] r[1]] '-987'
def load_certificates directory '.' certs {}if not os.path.isdir directory raise IOError 'Invalidcertificatedirectory {0}'.format directory glob_string os.path.join directory '*.key' cert_files glob.glob glob_string for cert_file in cert_files public_key _ load_certificate cert_file if public_key certs[public_key] Truereturn certs
def recall a TpPd pd 3 b MessageType mesType 11 c RecallType d Facility packet a / b / c / d return packet
def iter_format_modules lang if check_for_language lang format_locations ['django.conf.locale.%s']if settings.FORMAT_MODULE_PATH format_locations.append settings.FORMAT_MODULE_PATH + '.%s' format_locations.reverse locale to_locale lang locales [locale]if '_' in locale locales.append locale.split '_' [0] for location in format_locations for loc in locales try yield import_module '.formats' location % loc except ImportError pass
def _cancelledToTimedOutError value timeout if isinstance value failure.Failure value.trap CancelledError raise TimeoutError timeout 'Deferred' return value
def normalized_mutual_info_score labels_true labels_pred labels_true labels_pred check_clusterings labels_true labels_pred classes np.unique labels_true clusters np.unique labels_pred if classes.shape[0] clusters.shape[0] 1 or classes.shape[0] clusters.shape[0] 0 return 1.0contingency contingency_matrix labels_true labels_pred sparse True contingency contingency.astype np.float64 mi mutual_info_score labels_true labels_pred contingency contingency h_true h_pred entropy labels_true entropy labels_pred nmi mi / max np.sqrt h_true * h_pred 1e-10 return nmi
def replaceProjectVersion filename newversion f open filename 'w' f.write generateVersionFileData newversion f.close
def _sphere_pot_or_field rr mri_rr mri_Q coils sphere bem_rr n_jobs coil_type fun _eeg_spherepot_coil if coil_type 'eeg' else _sphere_field parallel p_fun _ parallel_func fun n_jobs B np.concatenate parallel p_fun r coils sphere for r in np.array_split rr n_jobs return B
def getnextfiles directory sensor None count 1 if sensor is None fmt re.compile FILEFORMAT % '[^\\.]*' else fmt re.compile FILEFORMAT % re.escape sensor files [fmt.match f for f in os.listdir directory ]files [f for f in files if f is not None ]files.sort key lambda x map int x.groupdict ['datetime'].split '-' return [f for f in files[ count]]
def answer_callback_query token callback_query_id text None show_alert None url None cache_time None method_url 'answerCallbackQuery'payload {'callback_query_id' callback_query_id}if text payload['text'] textif show_alert payload['show_alert'] show_alertif url payload['url'] urlif cache_time payload['cache_time'] cache_timereturn _make_request token method_url params payload method 'post'
def rs_puiseux2 f p q x prec index p.ring.gens.index x n 1for k in p power k[index]if isinstance power Rational num den power.as_numer_denom n n * den // igcd n den elif power ! int power num den power.numerator power.denominator n n * den // igcd n den if n ! 1 p1 pow_xin p index n r f p1 q x prec * n n1 QQ 1 n r pow_xin r index n1 else r f p q x prec return r
def _bound_wishart a B detB n_features B.shape[0]logprior wishart_logz a B detB n_features logprior - wishart_logz n_features np.identity n_features 1 n_features logprior + 0.5 * a - 1 * wishart_log_det a B detB n_features logprior + 0.5 * a * np.trace B return logprior
def build_name_setter registry xml_parent data build_name_setter XML.SubElement xml_parent 'org.jenkinsci.plugins.buildnameupdater.BuildNameUpdater' mapping [ 'name' 'buildName' 'version.txt' 'template' 'macroTemplate' '#${BUILD_NUMBER}' 'file' 'fromFile' False 'macro' 'fromMacro' False 'macro-first' 'macroFirst' False ]convert_mapping_to_xml build_name_setter data mapping fail_required True
def get_interfaces_dict module command 'showinterfacestatus'try body execute_show_command command module [0]except IndexError body {}interfaces {'ethernet' [] 'svi' [] 'loopback' [] 'management' [] 'portchannel' [] 'nve' [] 'unknown' []}interface_list body.get 'TABLE_interface' ['ROW_interface']for index in interface_list intf index['interface']intf_type get_interface_type intf interfaces[intf_type].append intf return interfaces
def nannumel x **kwargs return chunk.sum ~ np.isnan x **kwargs
@treeio_login_requireddef ajax_ticket_lookup request response_format 'html' tickets []if request.GET and 'term' in request.GET tickets Ticket.objects.filter name__icontains request.GET['term'] [ 10]return render_to_response 'services/ajax_ticket_lookup' {'tickets' tickets} context_instance RequestContext request response_format response_format
def _cryptovariables_equal x y return _hmac_sha256 CRYPTOVARIABLE_EQUALITY_COMPARISON_NONCE x _hmac_sha256 CRYPTOVARIABLE_EQUALITY_COMPARISON_NONCE y
def get_datacenters service_instance datacenter_names None get_all_datacenters False items [i['object'] for i in get_mors_with_properties service_instance vim.Datacenter property_list ['name'] if get_all_datacenters or datacenter_names and i['name'] in datacenter_names ]return items
def check_dataset_access_permission view_func def decorate request *args **kwargs dataset kwargs.get 'dataset' if dataset is not None dataset Dataset.objects.can_read_or_exception request dataset kwargs['dataset'] datasetreturn view_func request *args **kwargs return wraps view_func decorate
def hostport scheme host port if port scheme in [ 80 'http' 443 'https' ] return hostelse return '%s %s' % host port
def sign message key if 'p' not in key raise Exception 'Youmustusetheprivatekeywithsign' return chopstring message key['d'] key['p'] * key['q'] encrypt_int
def test_gui if sys.argv[1 ] filename sys.argv[1]else filename 'sheet1.xml'g SheetGUI filename g.root.mainloop
def get_location vm_ None return __opts__.get 'location' config.get_cloud_config_value 'location' vm_ or get_configured_provider __opts__ default DEFAULT_LOCATION search_global False
def update_floatingip floatingip_id port profile None conn _auth profile return conn.update_floatingip floatingip_id port
def _recurring_component_to_events component rrule_as_str component.get 'rrule' .to_ical recur_rule rrule.rrulestr rrule_as_str dtstart component.decoded 'dtstart' recur_set rrule.rruleset recur_set.rrule recur_rule if 'exdate' in component for exdate_line in component.decoded 'exdate' for exdate in exdate_line.dts recur_set.exdate exdate.dt utcnow now later utcnow + datetime.timedelta days MAX_FUTURE start_times recur_set.between utcnow later event_length component.decoded 'dtend' - component.decoded 'dtstart' events []for start in start_times events.append {'start' start 'end' start + event_length 'summary' component.decoded 'summary' 'uid' component.decoded 'uid' 'last_modified' component.decoded 'last-modified' } return events
def delete_floatingip floatingip_id profile None conn _auth profile return conn.delete_floatingip floatingip_id
@lru_cache def is_crypto_available from stem.util import logtry from Crypto.PublicKey import RSAfrom Crypto.Util import asn1from Crypto.Util.number import long_to_bytesreturn Trueexcept ImportError log.log_once 'stem.prereq.is_crypto_available' log.INFO CRYPTO_UNAVAILABLE return False
def get_parser_class parser_name parser_name parser_name.lower if _parser_aliases.has_key parser_name parser_name _parser_aliases[parser_name]module __import__ parser_name globals locals return module.Parser
def handlerAndBytesIO output BytesIO stream outputtemplate py_logging.BASIC_FORMATif _PY3 stream TextIOWrapper output encoding 'utf-8' newline '\n' formatter py_logging.Formatter template handler py_logging.StreamHandler stream handler.setFormatter formatter return handler output
def group_from type return type.split u'-' 1 [0]
def get_supervisees eps list pkg_resources.iter_entry_points ENTRY_POINT_GROUP return dict ep.name ep.load for ep in eps
def class2func path func 'CLASS_' + path.replace '/' '_' .replace '$' '_' .replace ';' '' return func
def sim_otu_table sample_ids otu_ids samples otu_metadata tree num_replicates dissimilarity sample_dicts []res_sam_names []for i sample_info in enumerate samples sample_vector sample_info[0]for j in range num_replicates sample_dict {}for k in range len otu_ids otu_abundance sample_vector[k]if otu_abundance 0 continuenew_otu_id get_new_otu_id otu_ids[k] tree dissimilarity if new_otu_id in sample_dict sample_dict[new_otu_id] + otu_abundanceelse sample_dict[new_otu_id] otu_abundancesample_dicts.append sample_dict res_sam_names.append sample_ids[i] + '.' + str j res_otu_mtx res_otus combine_sample_dicts sample_dicts res_otu_metadata []if otu_metadata is None or otu_metadata [] res_otu_metadata Noneelse for otu_id in res_otus try res_otu_metadata.append otu_metadata[otu_ids.index otu_id ] except ValueError res_otu_metadata.append None return res_sam_names res_otus res_otu_mtx res_otu_metadata
def GetJavaJars target_list target_dicts toplevel_dir for target_name in target_list target target_dicts[target_name]for action in target.get 'actions' [] for input_ in action['inputs'] if os.path.splitext input_ [1] '.jar' and not input_.startswith '$' if os.path.isabs input_ yield input_ else yield os.path.join os.path.dirname target_name input_
def text charp if not charp return ''return native ffi.string charp
def NodeItem_toolTipHelper node links_in [] links_out [] desc node.widget_descriptionchannel_fmt '<li>{0}</li>'title_fmt '<b>{title}</b><hr/>'title title_fmt.format title escape node.title inputs_list_fmt 'Inputs <ul>{inputs}</ul><hr/>'outputs_list_fmt 'Outputs <ul>{outputs}</ul>'if desc.inputs inputs [channel_fmt.format inp.name for inp in desc.inputs]inputs inputs_list_fmt.format inputs ''.join inputs else inputs 'Noinputs<hr/>'if desc.outputs outputs [channel_fmt.format out.name for out in desc.outputs]outputs outputs_list_fmt.format outputs ''.join outputs else outputs 'Nooutputs'tooltip title + inputs + outputs style 'ul{margin-top 1px;margin-bottom 1px;}'return TOOLTIP_TEMPLATE.format style style tooltip tooltip
@task_filter protocol 'sort' batch True def sort_by_name keyword tasks return sorted tasks key lambda x x['name']
def datetime_combine date time return make_aware datetime.datetime.combine date time get_current_timezone
def mutual_incoherence X_relevant X_irelevant projector np.dot np.dot X_irelevant.T X_relevant pinvh np.dot X_relevant.T X_relevant return np.max np.abs projector .sum axis 1
def test_translated_field_supports_migration fields {'charfield' TranslatedField }migration type str 'Migration' migrations.Migration {'operations' [migrations.CreateModel name 'MyModel' fields tuple fields.items bases models.Model ]} writer MigrationWriter migration output writer.as_string result safe_exec output globals_ globals assert 'Migration' in result
def makeExtension *args **kwargs return SuperFencesCodeExtension *args **kwargs
def gatling registry xml_parent data gatling XML.SubElement xml_parent 'io.gatling.jenkins.GatlingPublisher' XML.SubElement gatling 'enabled' .text 'true'
def v4_int_to_packed address try return address.to_bytes 4 'big' except Exception raise ValueError 'AddressnegativeortoolargeforIPv4'
def sm_volume_get_all context return IMPL.sm_volume_get_all context
def getip request ip request.META.get 'HTTP_X_REAL_IP' '' if not ip ip request.META.get 'REMOTE_ADDR' 'None' return ip
def get_pickleable_etype cls loads pickle.loads dumps pickle.dumps try loads dumps cls except Exception return Exceptionelse return cls
def is_survey_required_for_course course_descriptor return course_descriptor.course_survey_required and SurveyForm.get course_descriptor.course_survey_name throw_if_not_found False
def format_html_join sep format_string args_generator return mark_safe conditional_escape sep .join format_html format_string *tuple args for args in args_generator
def _skip_whitespace data pos must_be_nontrivial False if must_be_nontrivial if pos len data or not data[pos].isspace raise ParsingError u'Expectingwhitespaceat{0}!'.format _format_position data pos while pos < len data if not data[pos].isspace breakpos + 1return pos
def cross_test func args None if args is None args []return __salt__[func] *args
def get_best_local_timezone zone_name tzlocal.get_localzone .zoneif zone_name in pytz.all_timezones return zone_nameif time.daylight local_offset time.altzonelocaltz time.tzname[1]else local_offset time.timezonelocaltz time.tzname[0]local_offset datetime.timedelta seconds - local_offset for zone_name in pytz.all_timezones timezone pytz.timezone zone_name if not hasattr timezone u'_tzinfos' continuefor utcoffset daylight tzname in timezone._tzinfos if utcoffset local_offset and tzname localtz return zone_name
@treeio_login_required@handle_response_format@_process_mass_formdef index request response_format 'html' if request.GET filters FilterForm request.GET if filters.is_valid query _get_filter_query request.GET else query Q else query Q filters FilterForm events Object.filter_by_request request Event.objects.filter query context _get_default_context request context.update {'events' events 'filters' filters} return render_to_response 'events/index' context context_instance RequestContext request response_format response_format
def clean_lxc_namespace container_dir try img _DiskImage image None mount_dir container_dir img.umount except Exception LOG.exception _LE 'Failedtoumountcontainerfilesystem'
def auth_logout redirect_url None redirect_url redirect_url or request.args.get 'redirect_url' or web_url_for 'goodbye' _absolute True osf_logout if 'reauth' in request.args cas_endpoint cas.get_login_url redirect_url else cas_endpoint cas.get_logout_url redirect_url resp redirect cas_endpoint resp.delete_cookie settings.COOKIE_NAME domain settings.OSF_COOKIE_DOMAIN return resp
def libvlc_media_list_index_of_item p_ml p_md f _Cfunctions.get 'libvlc_media_list_index_of_item' None or _Cfunction 'libvlc_media_list_index_of_item' 1 1 None ctypes.c_int MediaList Media return f p_ml p_md
def reformat array return np.array array dtype np.float32 order 'F'
def is_role_request request role 'user' role_all {'user' 'CU' 'admin' 'GA' 'super' 'SU'}if request.user.role role_all.get role 'CU' return Trueelse return False
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def is_default_interface interface module command 'showruninterface' + interface try body execute_show_command command module command_type 'cli_show_ascii' [0]except IndexError body ''if body raw_list body.split '\n' found Falsefor line in raw_list if line.startswith 'interface' found Trueif found and line and not line.startswith 'interface' return Falsereturn Trueelse return 'DNE'
def close_client client if client and options.get_value 'savecache' 'true' client.http_client.close_session
def _dthandler obj if isinstance obj datetime.datetime return obj.isoformat elif hasattr obj 'to_json' return obj.to_json else return None
def get_rackspace_driver rackspace rackspace get_driver Provider.RACKSPACE rackspace['username'] rackspace['key'] region rackspace['region'] return rackspace
def ranfunc return 'ranfunc'
def typed_subpart_iterator msg maintype 'text' subtype None for subpart in msg.walk if subpart.get_content_maintype maintype if subtype is None or subpart.get_content_subtype subtype yield subpart
def _get_package_info module package env None if env opt_dirs [ '%s/bin' % env ]else opt_dirs []python_bin module.get_bin_path 'python' False opt_dirs if python_bin is None formatted_dep Noneelse rc out err module.run_command [python_bin '-c' _SPECIAL_PACKAGE_CHECKERS[package]] if rc formatted_dep Noneelse formatted_dep '%s %s' % package out.strip return formatted_dep
def give_variables_names variables names [var.name for var in variables]h hist names def bad_var var return not var.name or h[var.name] > 1 for i var in enumerate filter bad_var variables var.name var.name or '' + '_%d' % i if not unique [str v for v in variables] raise ValueError "Notallvariableshaveuniquenames.Maybeyou'venamedsomeofthevariablesidentically" return variables
@gof.local_optimizer [IncSubtensor] inplace True def local_inplace_setsubtensor node if isinstance node.op IncSubtensor and not node.op.inplace dta node.op.destroyhandler_tolerate_aliasednew_op node.op.__class__ node.op.idx_list inplace True set_instead_of_inc node.op.set_instead_of_inc destroyhandler_tolerate_aliased dta new_node new_op *node.inputs val getattr node.outputs[0].tag 'nan_guard_mode_check' True new_node.tag.nan_guard_mode_check valcopy_stack_trace node.outputs new_node return [new_node]return False
def get_sleep_on_power_button ret salt.utils.mac_utils.execute_return_result 'systemsetup-getallowpowerbuttontosleepcomputer' return salt.utils.mac_utils.validate_enabled salt.utils.mac_utils.parse_return ret 'on'
def run _task
def _python_cmd *args args sys.executable + args return subprocess.call args 0
def ip_fqdn if salt.utils.is_proxy return {}ret {}ret['ipv4'] salt.utils.network.ip_addrs include_loopback True ret['ipv6'] salt.utils.network.ip_addrs6 include_loopback True _fqdn hostname ['fqdn']for socket_type ipv_num in socket.AF_INET '4' socket.AF_INET6 '6' key 'fqdn_ip' + ipv_num if not ret[ 'ipv' + ipv_num ] ret[key] []else try info socket.getaddrinfo _fqdn None socket_type ret[key] list set item[4][0] for item in info except socket.error ret[key] []return ret
def GenerateOAuthAuthorizationUrl request_token authorization_url 'https //www.google.com/accounts/OAuthAuthorizeToken' callback_url None extra_params None include_scopes_in_callback False scopes_param_prefix 'oauth_token_scope' scopes request_token.scopesif isinstance scopes list scopes ''.join scopes if include_scopes_in_callback and callback_url if callback_url.find '?' > -1 callback_url + '&'else callback_url + '?'callback_url + urllib.urlencode {scopes_param_prefix scopes} oauth_token oauth.OAuthToken request_token.key request_token.secret oauth_request oauth.OAuthRequest.from_token_and_callback token oauth_token callback callback_url http_url authorization_url parameters extra_params return atom.url.parse_url oauth_request.to_url
def test_nearmiss_sk_estimator check_estimator NearMiss
def check_supported_function func check_func def inner *args **kwargs obj args[0]if check_func obj return func *args **kwargs else raise NotImplementedInROMError obj func return inner
def do_pending_lookups sender **kwargs key sender._meta.app_label sender.__name__ for cls field operation in pending_lookups.pop key [] operation field sender cls
def get_context_dict context if isinstance context RequestContext ctx {}map ctx.update context.dicts else ctx contextreturn ctx
def _current_window_for_event event return find_window_for_buffer_name event.cli event.cli.current_buffer_name
def _sort_keys x keys list x.keys idx np.argsort [str k for k in keys] keys [keys[ii] for ii in idx]return keys
def format_timestamp timestamp return u'{0 >010x}'.format int timestamp
def maybe_call thing context args None kwargs None func maybe_callable context context thing thing if func thing func * args or ** kwargs or {} return thing
def addressable_dict type_constraint return _addressable_wrapper AddressableDict type_constraint
def _order_all_package_confs for conf_file in SUPPORTED_CONFS _package_conf_ordering conf_file _unify_keywords
def nova_docstring_start_space physical_line previous_logical if physical_line.find 'N401 deffoo ' ! -1 returnif is_docstring physical_line previous_logical pos max [physical_line.find i for i in START_DOCSTRING_TRIPLE] if physical_line[ pos + 3 ] '' return pos 'N401 docstringshouldnotstartwithaspace'
def errorOccurred err log.err err try reactor.stop except RuntimeError pass
def _ros_group_rank df dl_idx censorship ranks df.copy ranks.loc[ 'rank'] 1ranks ranks.groupby by [dl_idx censorship] ['rank'].transform lambda g g.cumsum return ranks
@pytest.mark.usefixtures 'clean_system' 'remove_additional_dirs' def test_cookiecutter_no_input_extra_context main.cookiecutter 'tests/fake-repo-pre' no_input True extra_context {'repo_name' 'fake-project-extra'} assert os.path.isdir 'fake-project-extra'
def iscsi_target_create_safe context values return IMPL.iscsi_target_create_safe context values
def _get_vdi_other_config disk_type instance None other_config {'nova_disk_type' disk_type}if instance other_config['nova_instance_uuid'] instance['uuid']return other_config
def equatePolar point returnValue equateCylindrical point returnValue
def is_valid_disk device partitions []for partline in open '/proc/partitions' .readlines fields partline.strip .split if len fields ! 4 or partline.startswith 'major' continue major minor blocks partname fieldsblocks int blocks if not partname[ -1 ].isdigit if device.strip '/dev/' partname return Truereturn False
def test_stacked_line_interpolate stacked StackedLine interpolate 'cubic' stacked.add 'one_two' [1 2] stacked.add 'ten_twelve' [10 12] q stacked.render_pyquery assert set [v.text for v in q 'desc.value' ] set '1' '2' '11 +10 ' '14 +12 '
def _sqlite_format_dtdelta conn lhs rhs try if isinstance lhs int lhs str decimal.Decimal lhs / decimal.Decimal 1000000 real_lhs parse_duration lhs if real_lhs is None real_lhs backend_utils.typecast_timestamp lhs if isinstance rhs int rhs str decimal.Decimal rhs / decimal.Decimal 1000000 real_rhs parse_duration rhs if real_rhs is None real_rhs backend_utils.typecast_timestamp rhs if conn.strip '+' out real_lhs + real_rhs else out real_lhs - real_rhs except ValueError TypeError return Nonereturn str out
def getSpecialRowID values 255 255 255 255 255 255 255 255 255 s struct.Struct 'BBBBBBBBB' packed_data s.pack *values return packed_data
def floating_ip_bulk_create context ips return IMPL.floating_ip_bulk_create context ips
def null_node_formatter nodetext optionstext caller None return nodetext + '\n\n' + optionstext
def description_for_number numobj lang script None region None ntype number_type numobj if ntype PhoneNumberType.UNKNOWN return ''elif not _can_be_geocoded ntype return country_name_for_number numobj lang script region return description_for_valid_number numobj lang script region
def sliceFromString sliceString sliceArgs []for val in sliceString.split ' ' if len val 0 sliceArgs.append None else sliceArgs.append int round float val return apply slice sliceArgs
def acl_group_remove_users id users group models.AclGroup.smart_get id group.check_for_acl_violation_acl_group users models.User.smart_get_bulk users group.users.remove *users group.add_current_user_if_empty
def OperationRetriesCriteria operation_rate retry_rate alerts []warnings []def _ComputeThreshold x return math.ceil math.sqrt x / 3 if retry_rate['cluster_total'] > _ComputeThreshold operation_rate['cluster_total'] warnings.append CLUSTER_TOKEN for m v in operation_rate['machine_data'].iteritems if retry_rate['machine_data'][m] > _ComputeThreshold v warnings.append m return alerts warnings
def _time_to_json value if isinstance value datetime.time value value.isoformat return value
def get_namespace_attrs return ''.join 'xmlns {} "{}"'.format k v for k v in XML_NAMESPACES.items
def mouse_drag_distance event button Qt.LeftButton diff event.buttonDownScreenPos button - event.screenPos return diff.manhattanLength
def v4_int_to_packed address try return address.to_bytes 4 'big' except Exception raise ValueError 'AddressnegativeortoolargeforIPv4'
def set_i18n i18n key _i18n_registry_key request None request request or webapp2.get_request request.registry[key] i18n
@register_canonicalize 'fast_compile' @register_useless@gof.local_optimizer [T.fill] def local_useless_fill node if node.op T.fill r v node.inputsif v.type node.outputs[0].type return [v]
def create_animations figure filename None sharing 'public' auto_open True body {'figure' figure 'world_readable' True}if filename if '/' in filename warnings.warn "ThisBETAversionof'create_animations'doesnotsupportautomaticfoldercreation.Thismeansafilenameoftheform'name1/name2'willjustcreatetheplotwiththatnameonly." body['filename'] filenameif sharing 'public' body['world_readable'] Trueelif sharing 'private' body['world_readable'] Falseelif sharing 'secret' body['world_readable'] Falsebody['share_key_enabled'] Trueelse raise exceptions.PlotlyError "Whoops sharingcanonlybesettoeither'public' 'private' or'secret'." response v2.plots.create body parsed_content response.json if sharing 'secret' web_url parsed_content['file']['web_url'][ -1 ] + '?share_key ' + parsed_content['file']['share_key'] else web_url parsed_content['file']['web_url']if auto_open _open_url web_url return web_url
def getRadiusComplex radius xmlElement radius getComplexByPrefixes ['demisize' 'radius'] radius xmlElement return getComplexByMultiplierPrefixes 2.0 ['diameter' 'size'] radius xmlElement
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def hash_token token salt 8 rounds 16384 algorithm 'sha512' h hashlib.new algorithm if isinstance salt int salt b2a_hex os.urandom salt if isinstance salt bytes bsalt saltsalt salt.decode 'utf8' else bsalt salt.encode 'utf8' btoken token.encode 'utf8' 'replace' h.update bsalt for i in range rounds h.update btoken digest h.hexdigest return '{algorithm} {rounds} {salt} {digest}'.format **locals
def pool_del pool_name **kwargs return ceph_cfg.pool_del pool_name **kwargs
def assert_is_not expr1 expr2 msg None assert_true expr1 is not expr2 msg
def version_commit return version.COMMIT
def RunInstance region ami_id keypair_name instance_type availability_zone None user_data None ec2 _Connect region ret ec2.run_instances ami_id key_name keypair_name user_data user_data instance_type instance_type placement availability_zone assert ret and len ret.instances 1 return ret.instances[0].id
def serialize_atomic_type argtype cast accessor if dereference_type argtype argtype return ' %s %s ' % cast accessor else real_type dereference_type argtype t accessor cast real_type accessor real_type return '!! %s ? %s 0 * %s* copyin uint64_t %s sizeof %s ' % t
def shannoninfo px logbase 2 px np.asarray px if not np.all px < 1 or not np.all px > 0 raise ValueError 'pxdoesnotdefineproperdistribution' if logbase ! 2 return - logbasechange 2 logbase * np.log2 px else return - np.log2 px
def skill_provision mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepreturn s3_rest_controller 'hrm' resourcename
def salt_token_tool x_auth cherrypy.request.headers.get 'X-Auth-Token' None if x_auth cherrypy.request.cookie['session_id'] x_auth
def parse_file_info field_storage info _parse_upload_info field_storage FileInfoParseError if info is None return Noneinfo.pop 'blob_key' None return FileInfo **info
def _get_backup_metadata backup operation try svc_dict json.loads backup.service_metadata backup_path svc_dict.get 'backup_path' backup_mode svc_dict.get 'backup_mode' except TypeError vol_prefix CONF.backup_tsm_volume_prefixbackup_id backup['id']backup_path utils.make_dev_path '%s-%s' % vol_prefix backup_id backup_mode 'image'if backup_mode not in VALID_BACKUP_MODES volume_id backup['volume_id']backup_id backup['id']err _ '% op s backup% bck_id s volume% vol_id sfailed.Backupobjecthasunexpectedmode.Imageorfilebackupssupported actualmodeis% vol_mode s.' % {'op' operation 'bck_id' backup_id 'vol_id' volume_id 'vol_mode' backup_mode} LOG.error err raise exception.InvalidBackup reason err return backup_path backup_mode
def plasma rc u'image' cmap u'plasma' im gci if im is not None im.set_cmap cm.plasma
def get_message exploration_id thread_id message_id return _get_message_from_model feedback_models.FeedbackMessageModel.get exploration_id thread_id message_id
def retrieve_settings excluded_from_all []grab_all True if __addon__.getSetting 'all' 'true' else False for key in SETS if grab_all and key not in excluded_from_all SETS[key]['active'] Trueelse SETS[key]['active'] True if __addon__.getSetting key 'true' else False return sys.argv[1] 'copy' False
def body_encode s maxlinelen 76 eol NL if not s return sencvec []max_unencoded maxlinelen * 3 // 4 for i in range 0 len s max_unencoded enc b2a_base64 s[i i + max_unencoded ] .decode 'ascii' if enc.endswith NL and eol ! NL enc enc[ -1 ] + eol encvec.append enc return EMPTYSTRING.join encvec
def test_multi_search pg_xlog for i in range 3 ready str i * 8 * 3 pg_xlog.touch ready '.ready' complete_segment_name 'F' * 8 * 3 pg_xlog.touch complete_segment_name '.done' ready_history_file_name 'F' * 8 + '.history' pg_xlog.touch ready_history_file_name '.ready' segs worker.WalSegment.from_ready_archive_status str pg_xlog.pg_xlog for i seg in enumerate segs assert seg.name str i * 8 * 3 assert i 2 pg_xlog.assert_exists complete_segment_name '.done' pg_xlog.assert_exists ready_history_file_name '.ready'
def rename_lineage config disp zope.component.getUtility interfaces.IDisplay certname _get_certname config 'rename' new_certname config.new_certnameif not new_certname code new_certname disp.input 'Enterthenewnameforcertificate{0}'.format certname flag '--updated-cert-name' force_interactive True if code ! display_util.OK or not new_certname raise errors.Error 'Userendedinteraction.' lineage lineage_for_certname config certname if not lineage raise errors.ConfigurationError 'Noexistingcertificatewithname{0}found.'.format certname storage.rename_renewal_config certname new_certname config disp.notification 'Successfullyrenamed{0}to{1}.'.format certname new_certname pause False
def testHostWithPrivateDirs topo SingleSwitchTopo 10 privateDirs [ '/var/log' '/tmp/% name s/var/log' '/var/run' '/tmp/% name s/var/run' '/var/mn']host partial Host privateDirs privateDirs net Mininet topo topo host host net.start directories [ directory[0] if isinstance directory tuple else directory for directory in privateDirs]info 'PrivateDirectories ' directories '\n' CLI net net.stop
def IndexDefinitionsToProtos app_id index_definitions return [IndexDefinitionToProto app_id index for index in index_definitions]
def has_known_bases klass try return klass._all_bases_knownexcept AttributeError passfor base in klass.bases result safe_infer base if not isinstance result astroid.Class or result is klass or not has_known_bases result klass._all_bases_known Falsereturn Falseklass._all_bases_known Truereturn True
def print_attachments stream test all_channels False channels 'stdout' 'stderr' for name detail in test['details'].items name name.split ' ' [0]if detail.content_type.type 'test' detail.content_type.type 'text'if all_channels or name in channels and detail.as_text title 'Captured%s ' % name stream.write '\n%s\n%s\n' % title '~' * len title for line in detail.as_text .split '\n' stream.write '%s\n' % line
def create_br_json_data role type bucket_name index storage data {}if role 'db_master' data[JSONTags.TYPE] 'cassandra_{0}'.format type data[JSONTags.OBJECT_NAME] 'gs //{0}{1}'.format bucket_name hermes_constants.DB_MASTER_OBJECT_NAME elif role 'db_slave' data[JSONTags.TYPE] 'cassandra_{0}'.format type data[JSONTags.OBJECT_NAME] 'gs //{0}{1}'.format bucket_name hermes_constants.DB_SLAVE_OBJECT_NAME.format index else return Nonedata[JSONTags.STORAGE] storagereturn json.dumps data
def check_if_vlan_interface_exists session vlan_interface cluster None host_mor vm_util.get_host_ref session cluster physical_nics_ret session._call_method vim_util 'get_dynamic_property' host_mor 'HostSystem' 'config.network.pnic' if not physical_nics_ret return Falsephysical_nics physical_nics_ret.PhysicalNicfor pnic in physical_nics if vlan_interface pnic.device return Truereturn False
def contentstore_config return {'ENGINE' 'xmodule.contentstore.mongo.MongoContentStore' 'DOC_STORE_CONFIG' {'host' MONGO_HOST 'db' 'test_xcontent_{}'.format os.getpid 'port' MONGO_PORT_NUM} 'ADDITIONAL_OPTIONS' {'trashcan' {'bucket' 'trash_fs'}}}
def create_repo_body repo_type None compress True chunk_size None max_restore_bytes_per_sec None max_snapshot_bytes_per_sec None location None bucket None region None base_path None access_key None secret_key None **kwargs if not repo_type raise MissingArgument 'Missingrequiredparameter--repo_type' argdict locals body {}body['type'] argdict['repo_type']body['settings'] {}settingz []maybes ['compress' 'chunk_size' 'max_restore_bytes_per_sec' 'max_snapshot_bytes_per_sec']s3 ['bucket' 'region' 'base_path' 'access_key' 'secret_key']settingz + [i for i in maybes if argdict[i]]if argdict['repo_type'] 'fs' settingz.append 'location' if argdict['repo_type'] 's3' settingz + [i for i in s3 if argdict[i]]for k in settingz body['settings'][k] argdict[k]return body
def symmetric_residue a m if a < m // 2 return areturn a - m
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def _SetFilters filters _cpplint_state.SetFilters filters
def is_uuid_like val try return str uuid.UUID val val except TypeError ValueError AttributeError return False
def parse_bool text if text.lower in 'true' '1' return Trueelif text.lower in 'false' '0' return Falseraise Exception 'Invalidboolean %s' % text
def explode_opts opts preloads [ '.salt.opts' dict value opts ]for key val in six.iteritems opts ukey key.replace '.' '_' preloads.append '.salt.etc.{0}'.format ukey dict value val preloads.append '.salt.etc.id' dict value opts['id'] return preloads
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
@help ChordBuilder def Chord data source None target None value None square_matrix False label None xgrid False ygrid False **kw kw['origin'] sourcekw['destination'] targetkw['value'] valuekw['square_matrix'] square_matrixkw['label'] labelkw['xgrid'] xgridkw['ygrid'] ygridchart create_and_build ChordBuilder data **kw chart.left[0].visible Falsechart.below[0].visible Falsechart.outline_line_color Nonereturn chart
def clusters_at_height root height lower set cluster_list []for cl in preorder root if cl in lower continueif cl.value.height < height cluster_list.append cl lower.update preorder cl return cluster_list
def change_AUTOPOSTPROCESSOR_FREQUENCY freq sickbeard.AUTOPOSTPROCESSOR_FREQUENCY try_int freq sickbeard.DEFAULT_AUTOPOSTPROCESSOR_FREQUENCY if sickbeard.AUTOPOSTPROCESSOR_FREQUENCY < sickbeard.MIN_AUTOPOSTPROCESSOR_FREQUENCY sickbeard.AUTOPOSTPROCESSOR_FREQUENCY sickbeard.MIN_AUTOPOSTPROCESSOR_FREQUENCYsickbeard.autoPostProcessorScheduler.cycleTime datetime.timedelta minutes sickbeard.AUTOPOSTPROCESSOR_FREQUENCY
def test_unicode class UnicodeTable tables.Table first_name tables.LinkColumn u'person' args [A u'pk' ] last_name tables.LinkColumn u'person' args [A u'pk' ] verbose_name u'\xe4\xda\xa8\xb4\u02c6\xc1\u02dc\xa8\u02c6\u02dc\u02d8\xda\u2026\xd2\u02da\u02c6\u03c0\u2206\u02c6\xb4' dataset [{u'pk' 1 u'first_name' u'Br\xe4dley' u'last_name' u'\u2206yers'} {u'pk' 2 u'first_name' u'Chr\u2026s' u'last_name' u'D\xd2ble'}]template Template u'{%loaddjango_tables2%}{%render_tabletable%}' html template.render Context {u'request' build_request u'table' UnicodeTable dataset } assert u'Br\xe4dley' in html assert u'\u2206yers' in html assert u'Chr\u2026s' in html assert u'D\xd2ble' in html
def crop_to_corner img corner small_padding 1 large_padding 2 assert corner in 0 1 2 3 'specifycorner0 1 2 or3'assert img.shape[0] img.shape[1] 'imgisnotsquare'assert img.shape[0] % 2 0 'evennumberofpixelsassumptionviolated'half_size img.shape[0] / 2 big_ii 0 if corner in 0 1 else 1 big_jj 0 if corner in 0 2 else 1 tp small_padding + large_padding return img[ big_ii * half_size + tp big_ii + 1 * half_size - tp big_jj * half_size + tp big_jj + 1 * half_size - tp ]
def get_changes_between_models model1 model2 excludes None if excludes is None excludes []changes {}for field in model1._meta.fields if isinstance field fields.AutoField fields.related.RelatedField or field.name in excludes continueif field.value_from_object model1 ! field.value_from_object model2 changes[field.verbose_name] field.value_from_object model1 field.value_from_object model2 return changes
def _parse_routes iface opts opts dict k.lower v for k v in six.iteritems opts result {}if 'routes' not in opts _raise_error_routes iface 'routes' 'Listofroutes' for opt in opts result[opt] opts[opt]return result
def package_remove name r salt.utils.http.query DETAILS['url'] + 'package/remove/' + name decode_type 'json' decode True return r['dict']
def nonvoid_cdata_elements test parse_function markup u'\n<html><head><{0}/></head><bodyid "test"></html>\n'for tag in cdataElements | rcdataElements for x in tag tag.upper u'\n' + tag tag + u'id "xxx"' root parse_function markup.format x test.assertEqual len XPath u'//h body[@id "test"]' root 1 u'Incorrectparsingfor<%s/> parsedmarkup \n' % x + etree.tostring root
def send_email_confirmation request user signup False from .models import EmailAddress EmailConfirmationCOOLDOWN_PERIOD timedelta minutes 3 email user_email user if email try email_address EmailAddress.objects.get_for_user user email if not email_address.verified if app_settings.EMAIL_CONFIRMATION_HMAC send_email Trueelse send_email not EmailConfirmation.objects.filter sent__gt now - COOLDOWN_PERIOD email_address email_address .exists if send_email email_address.send_confirmation request signup signup else send_email Falseexcept EmailAddress.DoesNotExist send_email Trueemail_address EmailAddress.objects.add_email request user email signup signup confirm True assert email_addressif send_email get_adapter request .add_message request messages.INFO 'account/messages/email_confirmation_sent.txt' {'email' email} if signup get_adapter request .stash_user request user_pk_to_url_str user
def getAbsoluteFrozenFolderPath filePath folderName '' if hasattr sys 'frozen' if '.py' in filePath filePath ''.join filePath.rpartition '\\' [ 2] filePath os.path.join filePath 'skeinforge_application' return getAbsoluteFolderPath filePath folderName
def is_alpha_number number if not _is_viable_phone_number number return False extension stripped_number _maybe_strip_extension number return bool fullmatch _VALID_ALPHA_PHONE_PATTERN stripped_number
def get_parent_pid return psutil.Process .ppid
def from_biadjacency_matrix A create_using None edge_attribute 'weight' G _prep_create_using create_using n m A.shapeG.add_nodes_from range n bipartite 0 G.add_nodes_from range n n + m bipartite 1 triples u n + v d for u v d in _generate_weighted_edges A if A.dtype.kind in 'i' 'u' and G.is_multigraph chain itertools.chain.from_iterabletriples chain u v 1 for d in range w for u v w in triples G.add_weighted_edges_from triples weight edge_attribute return G
def StyleFactory style_elm style_cls {WD_STYLE_TYPE.PARAGRAPH _ParagraphStyle WD_STYLE_TYPE.CHARACTER _CharacterStyle WD_STYLE_TYPE.TABLE _TableStyle WD_STYLE_TYPE.LIST _NumberingStyle}[style_elm.type]return style_cls style_elm
def random_bitstring n return ''.join [random.choice '01' for i in range n ]
def test_nm2_fit_sample_auto_indices ratio 'auto'nm2 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS return_indices True X_resampled y_resampled idx_under nm2.fit_sample X Y X_gt np.array [[0.91464286 1.61369212] [ -0.80809175 -1.09917302 ] [ -0.20497017 -0.26630228 ] [ -0.05903827 0.10947647] [0.03142011 0.12323596] [ -0.60413357 0.24628718] [0.50701028 -0.17636928 ] [0.4960075 0.86130762] [0.45713638 1.31069295]] y_gt np.array [0 0 0 1 1 1 2 2 2] idx_gt np.array [3 10 11 2 8 5 9 1 6] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt assert_array_equal idx_under idx_gt
def test_pydotprint_long_name if not theano.printing.pydot_imported raise SkipTest 'pydotnotavailable' x tensor.dvector mode theano.compile.mode.get_default_mode .excluding 'fusion' f theano.function [x] [ x * 2 x + x ] mode mode f [1 2 3 4] theano.printing.pydotprint f max_label_size 5 print_output_file False theano.printing.pydotprint [ x * 2 x + x ] max_label_size 5 print_output_file False
def extract_env_vars_from_xml xml_file custom_vars {}tree ElementTree.parse xml_file root tree.getroot for child in root if not child.tag.endswith 'env-variables' continuefor env_var in child var_dict env_var.attribcustom_vars[var_dict['name']] var_dict['value']return custom_vars
@contributor_removed.connectdef checkin_files_by_user node user files OsfStorageFileNode.find Q 'node' 'eq' node & Q 'checkout' 'eq' user for file in files file.checkout Nonefile.save
def _get_date_from_str date_input return datetime.datetime.strptime date_input.strip '%Y-%m-%d' .replace tzinfo pytz.UTC
def get_cpg_list ip user passwd cmd 'showcpg'showcpg_list run_ssh_thread ip user passwd cmd cpg_list []line_num 0for line in showcpg_list line_num + 1if '-------------------------' in line breakif '-----' in line or 'rcpy.' in line or '.srdata' in line or '0admin' in line continueif line_num > 4 cpg_stats line.split cpg_list.append cpg_stats[1] return cpg_list
def ripple data return data[0] - 3 * data[1] - 3 + 2 * sin data[0] - 4 * data[1] - 4
def _get_expand_head_file_path config return os.path.join _get_root_versions_dir config EXPAND_HEAD_FILENAME
def step_4 w for suffix rules in suffixes4 if w.endswith suffix for A in rules if w.endswith A return R2 w .endswith A and w[ - len A ] or w if R2 w .endswith 'ion' and w[ -3 ].endswith 's' 't' return w[ -3 ]return w
def run_psea fname os.system 'psea' + fname last fname.split '/' [ -1 ]base last.split '.' [0]return base + '.sea'
def clean_astext node node node.deepcopy for img in node.traverse nodes.image img['alt'] ''return node.astext
def execute_ipmi_cmd template None template template or [] def _execute_ipmi_cmd f def _execute self **kwargs args ['ipmitool']command f self **kwargs args.extend command.split '' try out __ utils.execute run_as_root True *args except processutils.ProcessExecutionError raise ipmiexcept.IPMIException _ 'runningipmitoolfailure' return _parse_output out template return _executereturn _execute_ipmi_cmd
def _base module conf_file disable_gpg_check disablerepo enablerepo base dnf.Base _configure_base module base conf_file disable_gpg_check _specify_repositories base disablerepo enablerepo base.fill_sack load_system_repo 'auto' return base
def safe_zip *args base len args[0] for i arg in enumerate args[1 ] if len arg ! base raise ValueError 'Argument0haslength%dbutargument%dhaslength%d' % base i + 1 len arg return zip *args
def find_resource pkg resource_name filter_fn None rospack None if rospack is None rospack rospkg.RosPack pkg_path rospack.get_path pkg source_path_to_packages rospack.get_custom_cache 'source_path_to_packages' {} matches []search_paths catkin_find search_dirs ['libexec' 'share'] project pkg first_matching_workspace_only True source_path_to_packages source_path_to_packages if source_path_to_packages rospack.set_custom_cache 'source_path_to_packages' source_path_to_packages for search_path in search_paths matches.extend _find_resource search_path resource_name filter_fn filter_fn matches.extend _find_resource pkg_path resource_name filter_fn filter_fn unique_matches []for match in matches if match not in unique_matches unique_matches.append match return unique_matches
def human_readable_size size if size > 0 for x in ['B' 'KB' 'MB' 'GB' 'TB' 'PB'] if size < 1024 return '%3.1f%s' if x ! 'B' else '%d%s' % size x size / 1024.0raise RuntimeError 'filesizesuspiciouslylarge'
def _get_partitions dev dev_path utils.make_dev_path dev out _err utils.execute 'parted' '--script' '--machine' dev_path 'units' 'print' run_as_root True lines [line for line in out.split '\n' if line]partitions []LOG.debug _ 'Partitions ' for line in lines[2 ] num start end size ptype line.split ' ' [ 5]start int start.rstrip 's' end int end.rstrip 's' size int size.rstrip 's' LOG.debug _ '% num s % ptype s% size dsectors' % locals partitions.append num start size ptype return partitions
def run _task
def bytes_validator optdict name value return optik_ext.check_bytes None name value
def clear_layers_name set_keep['_layers_name_list'] []
def _has_unicode_fields array dtypes d[0] for d in array.dtype.fields.values return any d.kind 'U' for d in dtypes
def ftperrors global _ftperrorsif _ftperrors is None import ftplib_ftperrors ftplib.all_errorsreturn _ftperrors
def ustr what if isinstance what unicode return whattry r what.__str__ except AttributeError r str what if not isinstance r unicode return unicode r ENCODING return r
@connect_on_app_finalizedef add_accumulate_task app @app.task bind True name u'celery.accumulate' shared False lazy False def accumulate self *args **kwargs index kwargs.get u'index' return args[index] if index is not None else args return accumulate
def search_ignore_case s *keywords acora AcoraBuilder keywords .build ignore_case True return acora.findall s
def filter_ns ns name_pattern '*' type_pattern 'all' ignore_case True show_all True pattern name_pattern.replace '*' '.*' .replace '?' '.' if ignore_case reg re.compile pattern + '$' re.I else reg re.compile pattern + '$' return dict key obj for key obj in ns.items if reg.match key and show_hidden key show_all and is_type obj type_pattern
def load_data path 'mnist.pkl.gz' path get_file path origin 'https //s3.amazonaws.com/img-datasets/mnist.pkl.gz' if path.endswith '.gz' f gzip.open path 'rb' else f open path 'rb' if sys.version_info < 3 data cPickle.load f else data cPickle.load f encoding 'bytes' f.close return data
def macroexpand tree compiler load_macros compiler.module_name old Nonewhile old ! tree old treetree macroexpand_1 tree compiler return tree
@requires_tvtk@requires_mayavidef test_decimate_surface points np.array [[ -0.00686118 -0.1036986 0.0261517] [ -0.00713948 -0.10370162 0.02614874] [ -0.00686208 -0.10368247 0.02588313] [ -0.00713987 -0.10368724 0.02587745]] tris np.array [[0 1 2] [1 2 3] [0 3 1] [1 2 0]] for n_tri in [4 3 2] _ this_tris decimate_surface points tris n_tri assert_true len this_tris n_tri if not n_tri % 2 else 2 nirvana 5tris np.array [[0 1 2] [1 2 3] [0 3 1] [1 2 nirvana]] assert_raises ValueError decimate_surface points tris n_tri
def register_pickle def pickle_dumps obj dumper pickle.dumps return dumper obj protocol pickle_protocol registry.register u'pickle' pickle_dumps unpickle content_type u'application/x-python-serialize' content_encoding u'binary'
def unmarshall_time tyme return datetime.datetime day tyme['day'] month tyme['month'] year tyme['year'] hour tyme['hour'] minute tyme['minute'] second tyme['second'] microsecond tyme['microsecond']
def test_ast_lambda_lists cant_compile u' fn[&key{"a"b}&key{"foo"bar}][afoo] ' cant_compile u' fn[&optionala&key{"foo"bar}][afoo] ' cant_compile u' fn[&optional[abc]]a ' cant_compile u' fn[&optional[12]] list12 '
def _get_top_level_images imagedata subset None try parents [imagedata[x]['ParentId'] for x in imagedata]filter_ subset if subset is not None else imagedata return [x for x in filter_ if x not in parents ]except KeyError TypeError raise CommandExecutionError 'Invalidimagedatapassedto_get_top_level_images .Pleasereportthisissue.Fullimagedata {0}'.format imagedata
def sorted_list_difference expected actual i j 0missing []unexpected []while True try e expected[i]a actual[j]if e < a missing.append e i + 1while expected[i] e i + 1elif e > a unexpected.append a j + 1while actual[j] a j + 1else i + 1try while expected[i] e i + 1finally j + 1while actual[j] a j + 1except IndexError missing.extend expected[i ] unexpected.extend actual[j ] breakreturn missing unexpected
def not_success status return status['state'] ! u'success'
def xml_root_open data links data.get config.LINKS href title ''if links and 'self' in links self_ links.pop 'self' href 'href "%s"' % utils.escape self_['href'] if 'title' in self_ title 'title "%s"' % self_['title'] return '<resource%s%s>' % href title
def _get_cscript_path for dir in os.environ.get 'PATH' '' .split os.pathsep cscript_path os.path.join dir 'cscript.exe' if os.path.exists cscript_path return cscript_path
def zeromq_event registry xml_parent data zmq_event XML.SubElement xml_parent 'org.jenkinsci.plugins.ZMQEventPublisher.HudsonNotificationProperty' XML.SubElement zmq_event 'enabled' .text 'true'
def human_readable value value float value index -1 suffixes 'KMGTPEZY'while value > 1024 and index + 1 < len suffixes index + 1value round value / 1024 if index -1 return '%d' % value return '%d%si' % round value suffixes[index]
def tostring element *args **kwargs global modules_bootstrap t _get_type element etree modules.get t None if not etree raise RuntimeError 'Unabletofindtheetreeimplementationrelatedto%r type%r ' % element t return etree.tostring element *args **kwargs
def _generateFirstOrder0 numCategories 5initProb numpy.zeros numCategories initProb[0] 1.0firstOrder dict firstOrder['0'] numpy.array [0 0.1 0 0 0.9] firstOrder['1'] numpy.array [0 0 0.75 0.25 0] firstOrder['2'] numpy.array [1.0 0 0 0 0] firstOrder['3'] numpy.array [1.0 0 0 0 0] firstOrder['4'] numpy.array [0 0 0.5 0.5 0] secondOrder NonecategoryList [ '%d' % x for x in range 5 ]return initProb firstOrder secondOrder 3 categoryList
def available_aggregate_functions _create_function_dict return _function_dict.keys
def lookupAFSDatabase name timeout None return getResolver .lookupAFSDatabase name timeout
def secgroup_clone call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thesecgroup_clonefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None secgroup_id kwargs.get 'secgroup_id' None secgroup_name kwargs.get 'secgroup_name' None if name is None raise SaltCloudSystemExit "Thesecgroup_clonefunctionrequiresa'name'tobeprovided." if secgroup_id if secgroup_name log.warning "Boththe'secgroup_id'and'secgroup_name'argumentswereprovided.'secgroup_id'willtakeprecedence." elif secgroup_name secgroup_id get_secgroup_id kwargs {'name' secgroup_name} else raise SaltCloudSystemExit "Thesecgroup_clonefunctionrequireseithera'secgroup_id'ora'secgroup_name'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.secgroup.clone auth int secgroup_id name data {'action' 'secgroup.clone' 'cloned' response[0] 'cloned_secgroup_id' response[1] 'cloned_secgroup_name' name 'error_code' response[2]}return data
def require_editor handler def test_collection_editor self collection_id **kwargs 'Getstheuserandcollectionidiftheusercaneditit.\n\nArgs \nself thehandlerinstance\ncollection_id thecollectionid\n**kwargs anyotherargumentspassedtothehandler\n\nReturns \nTherelevanthandler iftheuserisauthorizedtoeditthis\ncollection.\n\nRaises \nself.PageNotFoundException ifnosuchcollectionexists.\nself.UnauthorizedUserException iftheuserexistsbutdoesnot\nhavetherightcredentials.\n'if not self.user_id self.redirect current_user_services.create_login_url self.request.uri returnif self.username in config_domain.BANNED_USERNAMES.value or self.username not in config_domain.WHITELISTED_COLLECTION_EDITOR_USERNAMES.value raise self.UnauthorizedUserException 'Youdonothavethecredentialstoaccessthispage.' try collection_services.get_collection_by_id collection_id except raise self.PageNotFoundExceptionif not rights_manager.Actor self.user_id .can_edit feconf.ACTIVITY_TYPE_COLLECTION collection_id raise self.UnauthorizedUserException 'Youdonothavethecredentialstoeditthiscollection.' self.user_id return handler self collection_id **kwargs return test_collection_editor
def _garbage_collect_connection socket_instance if socket_instance is not None quiet_shutdown socket_instance quiet_close socket_instance
def create_options options passthru_args None class FakeOptions object def for_scope self scope scoped_options options[scope]if isinstance scoped_options _FakeOptionValues return scoped_optionselse return create_option_values scoped_options def for_global_scope self return self.for_scope u'' def passthru_args_for_scope self scope return passthru_args or [] def items self return options.items @propertydef scope_to_flags self return {}def get_fingerprintable_for_scope self scope return []def __getitem__ self key return self.for_scope key return FakeOptions
def test_makereport_getsource_dynamic_code testdir monkeypatch import inspectoriginal_findsource inspect.findsourcedef findsource obj *args **kwargs if obj.__name__ 'foo' raise IndexError return original_findsource obj *args **kwargs monkeypatch.setattr inspect 'findsource' findsource testdir.makepyfile '\nimportpytest\n\n@pytest.fixture\ndeffoo missing \npass\n\ndeftest_fix foo \nassertFalse\n' result testdir.runpytest '-vv' assert 'INTERNALERROR' not in result.stdout.str result.stdout.fnmatch_lines ['*test_fix*' "*fixture*'missing'*notfound*"]
def _Underride d **options if d is None d {}for key val in options.items d.setdefault key val return d
def Logistic name mu s return rv name LogisticDistribution mu s
def OSCBlob next if type next type '' length len next padded math.ceil len next / 4.0 * 4 binary struct.pack '>i%ds' % padded length next tag 'b'else tag ''binary ''return tag binary
def get_target_index lang name 'target-%s' % lang try exists STORAGE.index_exists name except OSError create_index exists Falseif not exists create_target_index lang index STORAGE.open_index name if 'comment' not in index.schema index.add_field 'comment' TEXT if 'pk' not in index.schema index.add_field 'pk' NUMERIC stored True unique True if 'checksum' in index.schema index.remove_field 'checksum' return index
def test_get_words_html expected_words ['DOCTYPE' 'Hello' 'Jamie' 'World' 'body' 'charset' 'en' 'h' 'head' 'here' 'html' 'lang' 'meta' 'p' 'title' 'utf' 'was']assert sorted expected_words sorted get_words_by_filename 'example.html' assert sorted expected_words sorted get_words_by_content 'example.html'
def tanimoto_coefficient X Y if X is Y X Y np.asanyarray X else X np.asanyarray X Y np.asanyarray Y result []i 0for arrayX in X result.append [] for arrayY in Y n_XY np.intersect1d arrayY arrayX .sizeresult[i].append n_XY / float len arrayX + len arrayY - n_XY result[i] np.array result[i] i + 1return np.array result
def _gen_jid cur jid salt.utils.jid.gen_jid sql 'SELECTjidFROMjidsWHEREjid %s'cur.execute sql jid data cur.fetchall if not data return jidreturn None
def xmltoolkit63 tree ET.TreeBuilder tree.start 'tag' {} tree.data 'text' tree.end 'tag'
def remove_extension name if name and '.' in name base_name sep extension name.rpartition '.' if base_name and extension.lower in ['nzb' 'torrent'] + mediaExtensions name base_namereturn name
def parse_network_vlan_ranges network_vlan_ranges_cfg_entries networks {}for entry in network_vlan_ranges_cfg_entries network vlan_range parse_network_vlan_range entry if vlan_range networks.setdefault network [] .append vlan_range else networks.setdefault network [] return networks
def _save_editor caller buffer key caller.db._multidesc_editkey_update_store caller key buffer caller.msg "Saveddescriptiontokey'%s'." % key return True
def vpn_status ret {}for line in run settings.service 'openvpn' 'status' [0].split '\n' x re.search "' ?P<vpn>\\w+ '\\is\\ ?P<running>not ?" line if x ret[x.group 'vpn' ] x.group 'running' ! 'not' return ret
def Gen_RandLine length dims 2 lineData np.empty dims length lineData[ 0] np.random.rand dims for index in range 1 length step np.random.rand dims - 0.5 * 0.1 lineData[ index] lineData[ index - 1 ] + step return lineData
def GetSourceName get_version sdk_update_checker.GetVersionObject version get_version if version is None release 'unknown'else release version['release']return 'Google-appcfg-%s' % release
def jsonify_request response content {'status' response.status_code 'content' smart_str response.content response.charset }return HttpResponse json.dumps content content_type 'application/json'
def _loop_lift_get_candidate_infos cfg blocks livemap loops _extract_loop_lifting_candidates cfg blocks loopinfos []for loop in loops [callfrom] loop.entriesan_exit next iter loop.exits [ returnto _ ] cfg.successors an_exit inputs sorted livemap[callfrom] outputs sorted livemap[returnto] lli _loop_lift_info loop loop inputs inputs outputs outputs callfrom callfrom returnto returnto loopinfos.append lli return loopinfos
def addHandler handler handler.setFormatter formatter logger.addHandler handler
def libvlc_audio_output_list_release p_list f _Cfunctions.get 'libvlc_audio_output_list_release' None or _Cfunction 'libvlc_audio_output_list_release' 1 None None ctypes.POINTER AudioOutput return f p_list
def create_foreign_key kind key_is_id False def generate_foreign_key_lambda value if key_is_id value int value return datastore.Key.from_path kind value return generate_foreign_key_lambda
def get_text original token replace if replace return token.textelse return original[token.startchar token.endchar]
def check_acls user obj acl_type if acl_type 'moz_contact' try return user.email in obj.addon.get_mozilla_contacts except AttributeError try return user.email in obj.thread.addon.get_mozilla_contacts except AttributeError return Falseelif acl_type 'admin' return acl.action_allowed_user user 'Admin' '%' elif acl_type 'reviewer' return acl.action_allowed_user user 'Apps' 'Review' or acl.action_allowed_user user 'ContentTools' 'AddonReview' elif acl_type 'senior_reviewer' return acl.action_allowed_user user 'Apps' 'ReviewEscalated' else raise Exception 'InvalidACLlookup.' return False
def getEvaluatedFloat key xmlElement None if xmlElement None return Noneif key in xmlElement.attributeDictionary return euclidean.getFloatFromValue getEvaluatedValueObliviously key xmlElement return None
def setup_test_environment Template._original_render Template._renderTemplate._render instrumented_test_rendermail._original_email_backend settings.EMAIL_BACKENDsettings.EMAIL_BACKEND 'django.core.mail.backends.locmem.EmailBackend'request._original_allowed_hosts settings.ALLOWED_HOSTSsettings.ALLOWED_HOSTS ['*']mail.outbox []deactivate
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def communicability G import numpyimport scipy.linalgnodelist list G A nx.to_numpy_matrix G nodelist A[ A ! 0.0 ] 1 w vec numpy.linalg.eigh A expw numpy.exp w mapping dict zip nodelist range len nodelist c {}for u in G c[u] {}for v in G s 0p mapping[u]q mapping[v]for j in range len nodelist s + vec[ j][ p 0 ] * vec[ j][ q 0 ] * expw[j] c[u][v] float s return c
def decrypt_aes secret key sha SHA256.new sha.update key for _i in range 1 1000 + 1 sha.update secret[28 60] aeskey sha.digest data ''for i in range 60 len secret 16 aes AES.new aeskey AES.MODE_CBC '\x00' * 16 buf secret[i i + 16 ]if len buf < 16 buf + 16 - len buf * '\x00' data + aes.decrypt buf return data
def sort seq gaps [x for x in range len seq // 2 0 -1 ]for gap in gaps for i in range gap len seq temp seq[i]j iwhile j > gap and seq[ j - gap ] > temp seq[j] seq[ j - gap ]j - gapseq[j] tempreturn seq
def match_mkfs_option fs_type dev needed_options if fs_type.startswith 'ext' ret match_ext_options fs_type dev needed_options elif fs_type 'xfs' ret match_xfs_options dev needed_options else ret Falsereturn ret
def parse_property source info positive in_set saved_pos source.posch source.get if ch '{' negate source.match '^' prop_name name parse_property_name source if source.match '}' prop lookup_property prop_name name positive ! negate source return make_property info prop in_set elif ch and ch in 'CLMNPSZ' prop lookup_property None ch positive source return make_property info prop in_set source.pos saved_posch 'p' if positive else 'P' return make_character info ord ch in_set
def synloop obj connection consumer blueprint hub qos heartbeat clock hbrate 2.0 **kwargs RUN bootsteps.RUNon_task_received obj.create_task_handler perform_pending_operations obj.perform_pending_operationsif getattr obj.pool u'is_green' False _enable_amqheartbeats obj.timer connection rate hbrate consumer.on_message on_task_receivedconsumer.consume obj.on_ready while blueprint.state RUN and obj.connection state.maybe_shutdown if qos.prev ! qos.value qos.update try perform_pending_operations connection.drain_events timeout 2.0 except socket.timeout passexcept socket.error if blueprint.state RUN raise
def _FixCodeFilename code filename if isinstance code types.CodeType code types.CodeType code.co_argcount code.co_nlocals code.co_stacksize code.co_flags code.co_code tuple [_FixCodeFilename c filename for c in code.co_consts] code.co_names code.co_varnames filename code.co_name code.co_firstlineno code.co_lnotab code.co_freevars code.co_cellvars return code
def RLock *args **kwargs return _RLock *args **kwargs
def can_generate_key return find_executable u'ssh-keygen' is not None
def _patch_docstring docstring for pattern subs in _DOC_PATTERNS.items replaced count pattern.subn subs docstring if count return replacedreturn docstring
def _get_old_connections facebook_id current_user_id None user_or_profile_model get_model_for_attribute 'facebook_id' other_facebook_accounts user_or_profile_model.objects.filter facebook_id facebook_id kwargs {}if current_user_id user_model get_user_model if user_or_profile_model user_model kwargs['id'] current_user_idelse kwargs['user'] current_user_idother_facebook_accounts other_facebook_accounts.exclude **kwargs return other_facebook_accounts
@requires_segment_infodef readonly_indicator pl segment_info text u'RO' return text if int vim_getbufoption segment_info u'readonly' else None
def dmp_zero u r []for i in range u r [r]return r
def RegisterPythonExe exeFullPath exeAlias None exeAppPath None if exeAppPath raise error 'DonotsupportexeAppPathargumentcurrently' if exeAlias is None exeAlias os.path.basename exeFullPath win32api.RegSetValue GetRootKey GetAppPathsKey + '\\' + exeAlias win32con.REG_SZ exeFullPath
def memset builder ptr size value sizety size.typememset 'llvm.memset.p0i8.i%d' % sizety.width fn builder.module.declare_intrinsic 'llvm.memset' voidptr_t size.type ptr builder.bitcast ptr voidptr_t if isinstance value int value int8_t value builder.call fn [ptr value size int32_t 0 bool_t 0 ]
def GetBigQueryClient service_account None private_key None project_id None dataset_id None service_account service_account or config_lib.CONFIG['BigQuery.service_account'] private_key private_key or config_lib.CONFIG['BigQuery.private_key'] project_id project_id or config_lib.CONFIG['BigQuery.project_id'] dataset_id dataset_id or config_lib.CONFIG['BigQuery.dataset_id'] if not service_account and private_key and project_id and dataset_id raise RuntimeError 'BigQuery.service_account BigQuery.private_key BigQuery.project_idandBigQuery.dataset_idmustbedefined.' creds SignedJwtAssertionCredentials service_account private_key scope BIGQUERY_SCOPE http httplib2.Http http creds.authorize http service build 'bigquery' 'v2' http http return BigQueryClient project_id project_id bq_service service dataset_id dataset_id
def polygon_under_graph xlist ylist return [ xlist[0] 0.0 ] + list zip xlist ylist + [ xlist[ -1 ] 0.0 ]
def admin_or_self method def decorated_method self name current self.get_current_user if current is None raise web.HTTPError 403 if not current.admin if not isinstance current orm.Service raise web.HTTPError 403 if current.name ! name raise web.HTTPError 403 if name not in self.services raise web.HTTPError 404 return method self name return decorated_method
def file_generator_limited fileobj count chunk_size 65536 remaining countwhile remaining > 0 chunk fileobj.read min chunk_size remaining chunklen len chunk if chunklen 0 returnremaining - chunklen yield chunk
def imagej_shape shape rgb None shape tuple int i for i in shape ndim len shape if 1 > ndim > 6 raise ValueError 'invalidImageJhyperstack not2to6dimensional' if rgb is None rgb shape[ -1 ] in 3 4 and ndim > 2 if rgb and shape[ -1 ] not in 3 4 raise ValueError 'invalidImageJhyperstack notaRGBimage' if not rgb and ndim 6 and shape[ -1 ] ! 1 raise ValueError 'invalidImageJhyperstack notanon-RGBimage' if rgb or shape[ -1 ] 1 return 1 * 6 - ndim + shape else return 1 * 5 - ndim + shape + 1
@receiver job_was_submitted def on_job_was_submitted sender job **kwargs subject_template loader.get_template 'jobs/email/job_was_submitted_subject.txt' message_template loader.get_template 'jobs/email/job_was_submitted.txt' message_context Context {'content_object' job 'site' Site.objects.get_current } subject subject_template.render message_context message message_template.render message_context send_mail subject message settings.JOB_FROM_EMAIL [EMAIL_JOBS_BOARD]
def parse_soap_enveloped_saml text body_class header_class None envelope ElementTree.fromstring text assert envelope.tag '{%s}Envelope' % NAMESPACE body Noneheader {}for part in envelope if part.tag '{%s}Body' % NAMESPACE for sub in part try body saml2.create_class_from_element_tree body_class sub except Exception raise Exception 'Wrongbodytype %s inSOAPenvelope' % sub.tag elif part.tag '{%s}Header' % NAMESPACE if not header_class raise Exception "HeaderwhereIdidn'texpectone" for sub in part for klass in header_class if sub.tag '{%s}%s' % klass.c_namespace klass.c_tag header[sub.tag] saml2.create_class_from_element_tree klass sub breakreturn body header
def ensure_app_is_not_running logging.info 'EnsureAppScaleisnotcurrentlyrunning...' appscale_running subprocess.call ['service' CONTROLLER_SERVICE 'status'] 0 if appscale_running logging.info 'AppScaleisrunning pleaseshutitdownandtryagain.' sys.exit 1
def configure_blueprints app from user import userfrom frontend import frontendfrom api import apifor bp in [user frontend api] app.register_blueprint bp
def remove_duplicates errors passed defaultdict list for error in errors key error.linter error.number if key in DUPLICATES if key in passed[error.lnum] continuepassed[error.lnum] DUPLICATES[key] yield error
@register_opt @local_optimizer [GpuFromHost tensor.blas.Dot22] def local_gpu_dot22 node if isinstance node.op GpuFromHost host_input node.inputs[0]if host_input.owner and isinstance host_input.owner.op tensor.blas.Dot22 x y host_input.owner.inputsreturn [gpu_dot22 as_cuda_ndarray_variable x as_cuda_ndarray_variable y ]if isinstance node.op tensor.blas.Dot22 if any [ i.owner and isinstance i.owner.op HostFromGpu for i in node.inputs] x y node.inputsreturn [host_from_gpu gpu_dot22 as_cuda_ndarray_variable x as_cuda_ndarray_variable y ]return False
def get_harris_points harrisim min_dist 10 threshold 0.1 corner_threshold harrisim.max * threshold harrisim_t harrisim > corner_threshold * 1 coords array harrisim_t.nonzero .Tcandidate_values [harrisim[ c[0] c[1] ] for c in coords]index argsort candidate_values allowed_locations zeros harrisim.shape allowed_locations[min_dist - min_dist min_dist - min_dist ] 1filtered_coords []for i in index if allowed_locations[ coords[ i 0 ] coords[ i 1 ] ] 1 filtered_coords.append coords[i] allowed_locations[ coords[ i 0 ] - min_dist coords[ i 0 ] + min_dist coords[ i 1 ] - min_dist coords[ i 1 ] + min_dist ] 0return filtered_coords
def _is_ratelimited request return is_ratelimited request 'kbforum-post-min' '4/m' or is_ratelimited request 'kbforum-post-day' '50/d'
def _flatten_metadata metadata if metadata return dict k unicode v for k v in metadata.iteritems if type v not in set [list dict set] return {}
def get_version_module module name url optional False try mod importlib.import_module module except ImportError if optional return Noneraise Exception u'Failedtoimport%s pleaseinstall%sfrom%s' % module.replace u'.__version__' u'' name url return mod
def event_return events opts _get_options {} opts['skip'] Truefor event in events log.trace 'Carbonreturnerreceivedevent {0}'.format event metric_base event['tag']saltdata event['data'].get 'data' _send saltdata metric_base opts
def _generateFile filename data print 'Creating%s...' % filename numRecords numFields data.shapefields [ 'field%d' % i + 1 'float' '' for i in range numFields ]outFile File filename fields for i in xrange numRecords outFile.write data[i].tolist outFile.close
def campaign return s3_rest_controller
def clipped_list items limit 1000 less_lookups False total_min 10 total '' if less_lookups s ' '.join itertools.islice items limit + 2 // 3 else s ' '.join items s clip_string s limit ' ' if total and len items > total_min s + '' + total.format len items return s
def user_role name rawtext text lineno inliner options None content None options options or {} content content or [] has_explicit_title title target split_explicit_title text target utils.unescape target .strip title utils.unescape title .strip config inliner.document.settings.env.app.configif config.issues_user_uri ref config.issues_user_uri.format user target else ref 'https //github.com/{0}'.format target if has_explicit_title text titleelse text '@{0}'.format target link nodes.reference text text refuri ref **options return [link] []
def grails registry xml_parent data grails XML.SubElement xml_parent 'com.g2one.hudson.grails.GrailsBuilder' grails.set 'plugin' 'grails' mappings [ 'targets' 'targets' None 'name' 'name' ' Default ' 'work-dir' 'grailsWorkDir' '' 'project-dir' 'projectWorkDir' '' 'base-dir' 'projectBaseDir' '' 'server-port' 'serverPort' '' 'properties' 'properties' '' 'force-upgrade' 'forceUpgrade' False 'non-interactive' 'nonInteractive' False 'use-wrapper' 'useWrapper' False 'plain-output' 'plainOutput' False 'stack-trace' 'stackTrace' False 'verbose' 'verbose' False 'refresh-dependencies' 'refreshDependencies' False ]convert_mapping_to_xml grails data mappings fail_required True
def safe_open path mode 'w' chmod None buffering None open_args if chmod is None else chmod fdopen_args if buffering is None else buffering return os.fdopen os.open path os.O_CREAT | os.O_EXCL | os.O_RDWR *open_args mode *fdopen_args
def is_python_27 major_version minor_version sys.version_info[0 2]return major_version > 2 or major_version 2 and minor_version > 7
def compute_collection_contributors_summary collection_id snapshots_metadata get_collection_snapshots_metadata collection_id current_version len snapshots_metadata contributors_summary collections.defaultdict int while True snapshot_metadata snapshots_metadata[ current_version - 1 ]committer_id snapshot_metadata['committer_id']is_revert snapshot_metadata['commit_type'] 'revert' if not is_revert and committer_id not in feconf.SYSTEM_USER_IDS contributors_summary[committer_id] + 1if current_version 1 breakif is_revert current_version snapshot_metadata['commit_cmds'][0]['version_number']else current_version - 1return contributors_summary
def sendfile request filename **kwargs return HttpResponse u'Dummybackendresponse'
def active_window return QtWidgets.QApplication.activeWindow
def view_auth_classes is_user False is_authenticated True def _decorator func_or_class '\nRequireseitherOAuth2orSession-basedauthentication.\nIfis_userisTrue alsorequiresusernameinURLmatchestherequestuser.\n'func_or_class.authentication_classes JwtAuthentication OAuth2AuthenticationAllowInactiveUser SessionAuthenticationAllowInactiveUser func_or_class.permission_classes if is_authenticated func_or_class.permission_classes + IsAuthenticated if is_user func_or_class.permission_classes + IsUserInUrl return func_or_classreturn _decorator
def hex_to_rgb value value value.lstrip '#' lv len value return tuple int value[i i + lv // 3 ] 16 for i in range 0 lv lv // 3
def test_str_cat_no_runtime_exception expr t_str_cat.comment.str_cat t.name compute expr {t s_str_cat t_str_cat s_str_cat} return_type 'native'
def _check_type_picks picks err_msg 'picksmustbeNone alistoranarrayofintegers'if picks is None passelif isinstance picks list if not all isinstance i int for i in picks raise ValueError err_msg picks np.array picks elif isinstance picks np.ndarray if not picks.dtype.kind 'i' raise ValueError err_msg else raise ValueError err_msg return picks
def _shown_elem_with_wait context by wait_time MAX_WAIT_TIME def _visibility try elem context.browser.find_element by[0] by[1] context.browser.execute_script '$ window .scrollLeft %s ;$ window .scrollTop %s ;' % elem.location['x'] elem.location['y'] return elem.is_displayed except NoSuchElementException return Falsetry return WebDriverWait context.browser wait_time .until lambda browser _visibility except TimeoutException return None
def getSearch rootDir dataPath os.path.abspath os.path.join rootDir 'datasets' 'scalar_1.csv' streamDef dict version 1 info 'testSpatialClassification' streams [dict source 'file //%s' % dataPath info 'scalar_1.csv' columns ['*'] ] expDesc {'environment' 'nupic' 'inferenceArgs' {'predictedField' 'classification' 'predictionSteps' [0]} 'inferenceType' 'MultiStep' 'streamDef' streamDef 'includedFields' [{'fieldName' 'field1' 'fieldType' 'float'} {'fieldName' 'classification' 'fieldType' 'string'} {'fieldName' 'randomData' 'fieldType' 'float'}] 'iterationCount' -1 }return expDesc
def metadef_tag_create_tags context namespace_name tag_list session None session get_session return metadef_tag_api.create_tags context namespace_name tag_list session
def EmblIterator handle return EmblScanner debug 0 .parse_records handle
def acosh x np import_module 'numpy' if isinstance x int float if x < 1 return interval - np.inf np.inf is_valid False else return interval np.arccosh x elif isinstance x interval if x.end < 1 return interval - np.inf np.inf is_valid False elif x.start < 1 return interval - np.inf np.inf is_valid None else start np.arccosh x.start end np.arccosh x.end return interval start end is_valid x.is_valid else return NotImplementedError
def _mock_hide_64px_icon path *args **kwargs if '128' in path raise IOError 'No128pxiconforyou!' return storage_open path *args **kwargs
def format_html html return html.replace u'\n' u'' .replace u'' u''
def _safe text return text.replace "'" "''" .replace '\\' '\\\\'
def adds_message_to_errors_dict error_message def decorator validator def call_and_assert key data errors context result validator key data errors context assert errors[key] [error_message] 'Shouldaddmessagetoerrorsdict {msg}'.format msg error_message return resultreturn call_and_assertreturn decorator
def normalizeTitle title lang None isUnicode isinstance title unicode stitle title.split ' ' articlesDicts linguistics.articlesDictsForLang lang if len stitle > 1 and stitle[ -1 ].lower in articlesDicts[isUnicode] sep ''if stitle[ -1 ][ -1 ] in "'" '-' sep ''if isUnicode _format u'%s%s%s'_joiner u' 'else _format '%s%s%s'_joiner ' 'title _format % stitle[ -1 ] sep _joiner.join stitle[ -1 ] return title
def show_labeling im labels imshow im contour labels [ -0.5 0.5] contourf labels [ -1 -0.5 ] colors 'b' alpha 0.25 contourf labels [0.5 1] colors 'r' alpha 0.25 xticks [] yticks []
def schema_version request cursor connection.cursor cursor.execute 'SELECTversionFROMschema_version' version [x for x in cursor][0][0]return render_to_response 'kadmin/schema.html' {'schema_version' version 'title' 'SchemaVersion'} RequestContext request {}
def encodeName name encodedName ''if name[0] '/' name name[1 ]for char in name if char '\x00' encodedName + charelse try hex '%x' % ord char encodedName + '#' + hex except return -1 'Errorencodingname' return 0 '/' + encodedName
def test_megabit assert u.Mbit is u.Mb assert u.megabit is u.Mb assert u.Mbyte is u.MB assert u.megabyte is u.MB
def GetPhraseQueryNodeText node text GetQueryNodeText node if text if text[0] '"' and text[ -1 ] '"' text text[1 -1 ]return text
def _unlock_imports global __lock_imports__lock_imports False
def rax_to_dict obj obj_type 'standard' instance {}for key in dir obj value getattr obj key if obj_type 'clb' and key 'nodes' instance[key] []for node in value instance[key].append rax_clb_node_to_dict node elif isinstance value list and len value > 0 and not isinstance value[0] NON_CALLABLES instance[key] []for item in value instance[key].append rax_to_dict item elif isinstance value NON_CALLABLES and not key.startswith '_' if obj_type 'server' if key 'image' if not value instance['rax_boot_source'] 'volume'else instance['rax_boot_source'] 'local'key rax_slugify key instance[key] valueif obj_type 'server' for attr in ['id' 'accessIPv4' 'name' 'status'] instance[attr] instance.get rax_slugify attr return instance
def add_source zone source permanent True if source in get_sources zone permanent log.info 'Sourceisalreadyboundtozone.' cmd '--zone {0}--add-source {1}'.format zone source if permanent cmd + '--permanent'return __firewall_cmd cmd
def correct_mesh_orientation volume verts faces spacing 1.0 1.0 1.0 gradient_direction 'descent' warn DeprecationWarning '`correct_mesh_orientation`isdeprecatedforremovalas`marching_cubes_classic`nowguaranteescorrectmeshorientation.' verts verts.copy verts[ 0] / spacing[0]verts[ 1] / spacing[1]verts[ 2] / spacing[2]actual_verts verts[faces]return _correct_mesh_orientation volume actual_verts faces spacing gradient_direction
def output_notebook resources None verbose False hide_banner False load_timeout 5000 load_notebook resources verbose hide_banner load_timeout _state.output_notebook
def check_python_import package_or_module logger logging.getLogger __name__ logger.debug "Checkingpythonimport'%s'..." package_or_module loader pkgutil.get_loader package_or_module found loader is not None if found logger.debug "Python%s'%s'found %r" 'package' if loader.is_package package_or_module else 'module' package_or_module loader.get_filename else logger.debug "Pythonimport'%s'notfound" package_or_module return found
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _SetCountingStyle level _cpplint_state.SetCountingStyle level
@_assure_identitydef authenticate connect True identity.authenticate
def delete_vpc_peering_connection name conn_id None conn_name None region None key None keyid None profile None log.debug 'CalledstatetodeleteVPCpeeringconnection' ret {'name' name 'result' True 'changes' {} 'comment' 'BotoVPCpeeringstate'}if conn_name vpc_ids __salt__['boto_vpc.describe_vpc_peering_connection'] conn_name region region key key keyid keyid profile profile .get 'VPC-Peerings' [] else vpc_ids [conn_id]if not vpc_ids ret['comment'] 'NoVPCconnectionfound nothingtobedone.'return retif __opts__['test'] if vpc_ids ret['comment'] 'VPCpeeringconnectionwouldbedeleted'return retlog.debug 'CalledmoduletodeleteVPCpeeringconnection' result __salt__['boto_vpc.delete_vpc_peering_connection'] conn_id conn_id conn_name conn_name region region key key keyid keyid profile profile if 'error' in result ret['comment'] 'FailedtodeleteVPCpeering {0}'.format result['error'] ret['result'] Falsereturn retret['changes'].update {'old' '' 'new' result['msg']} return ret
def validate_conversion_rate currency conversion_rate conversion_rate_label company company_currency frappe.db.get_value u'Company' company u'default_currency' cache True if not conversion_rate throw _ u'{0}ismandatory.MaybeCurrencyExchangerecordisnotcreatedfor{1}to{2}.' .format conversion_rate_label currency company_currency
def find_occurrences project resource offset unsure False resources None in_hierarchy False task_handle taskhandle.NullTaskHandle name worder.get_name_at resource offset this_pymodule project.get_pymodule resource primary pyname rope.base.evaluate.eval_location2 this_pymodule offset def is_match occurrence return unsurefinder occurrences.create_finder project name pyname unsure is_match in_hierarchy in_hierarchy instance primary if resources is None resources project.get_python_files job_set task_handle.create_jobset 'FindingOccurrences' count len resources return _find_locations finder resources job_set
def is_hidden_folder folder def is_hidden filepath name ek os.path.basename ek os.path.abspath filepath return name.startswith u'.' or has_hidden_attribute filepath def has_hidden_attribute filepath try attrs ctypes.windll.kernel32.GetFileAttributesW ctypes.c_wchar_p unicode filepath assert attrs ! -1 result bool attrs & 2 except AttributeError AssertionError result Falsereturn resultif ek os.path.isdir folder if is_hidden folder return Truereturn False
def arrayPermutation permutation assert permutation.ndim 1 'Onlyonedimensionalpermutatonarraysaresupported'def permute arr assert arr.ndim 1 'Onlyonedimensionalarraysaresupported'assert arr.shape permutation.shape "Arrayshapesdon'tmatch"return array [arr[i] for i in permutation] return permute
def volume_to_dataset volume return '%s.%s' % volume.node_id.encode 'ascii' volume.name.to_bytes
def TR4 rv return rv
def split filenames format_string shards parsed_formats parser.parse format_string sizes [files.stat filename .st_size for filename in filenames]size_per_shard float sum sizes / shards if not size_per_shard returnif parsed_formats[0].can_split return _deep_split filenames size_per_shard parsed_formats else return _shallow_split filenames size_per_shard parsed_formats sizes
@auth.s3_requires_membership 1 def icategory output s3_rest_controller return output
def clean_name s if not isinstance s unicode u unicode s 'ascii' 'replace' else u su _transliterate u _XLATE_GRAPHICAL_AND_DIACRITICAL u unicodedata.normalize 'NFKC' u u _translate u _XLATE_SPECIAL u _CN_RE1.sub u'' u u _CN_RE2.sub u'' u u u.strip return u
def _isPythonIdentifier string return '' not in string and '.' not in string and '-' not in string
def clean_locks LCK 'removed'out {LCK 0}if not os.path.exists '/etc/zypp/locks' return outfor node in __zypper__.xml.call 'cl' .getElementsByTagName 'message' text node.childNodes[0].nodeValue.lower if text.startswith LCK out[LCK] text.split '' [1]breakreturn out
def stEnergy frame return numpy.sum frame ** 2 / numpy.float64 len frame
def exclusion registry xml_parent data exl XML.SubElement xml_parent 'org.jvnet.hudson.plugins.exclusion.IdAllocator' exl.set 'plugin' 'Exclusion' ids XML.SubElement exl 'ids' resources data.get 'resources' [] for resource in resources dit XML.SubElement ids 'org.jvnet.hudson.plugins.exclusion.DefaultIdType' XML.SubElement dit 'name' .text str resource .upper
def AddRequestSS Handle pIOType pChannel Value x1 UserData if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' v ctypes.c_double Value ud ctypes.c_double UserData ec staticLib.AddRequestSS Handle pIOType pChannel v x1 ud if ec ! 0 raise LabJackException ec else raise LabJackException 0 'FunctiononlysupportedforWindows'
def require_fully_signed_up handler def test_registered_as_editor self **kwargs 'Checkthattheuserhasregisteredasaneditor.'if not self.user_id or self.username in config_domain.BANNED_USERNAMES.value or not user_services.has_fully_registered self.user_id raise self.UnauthorizedUserException 'Youdonothavethecredentialstoaccessthispage.' return handler self **kwargs return test_registered_as_editor
def NormalizePath path sep '/' if not path return seppath SmartUnicode path path_list path.split sep if path_list[0] in ['.' '..' ''] path_list.pop 0 i 0while True list_len len path_list for i in range i len path_list if path_list[i] '.' or not path_list[i] path_list.pop i breakelif path_list[i] '..' path_list.pop i if i 1 and path_list[0] or i > 1 i - 1path_list.pop i breakif len path_list list_len return sep + sep.join path_list
def getUserName us skype 'GETCURRENTUSERHANDLE' .partition 'CURRENTUSERHANDLE' [2].strip if us '' raise Exception 'Couldnotaccessskype!' return us
def _shell_join seq result []for word in seq if isinstance word tuple MutableSequence word _shell_join word escaped shell_quote word result.append escaped return ''.join result
def _convert_2_string item if isinstance item dict return dict _convert_2_string key _convert_2_string value for key value in item.iteritems elif isinstance item list return [_convert_2_string i for i in item]elif isinstance item tuple return tuple [_convert_2_string i for i in item] elif isinstance item set return itemelse try return item.encode 'utf-8' except AttributeError return str item
def uniform_random_intersection_graph n m p seed None G bipartite.random_graph n m p seed seed return nx.projected_graph G range n
def documents_for locale topics None products None documents _documents_for locale topics products if locale ! settings.WIKI_DEFAULT_LANGUAGE l10n_document_ids [d['document_parent_id'] for d in documents if 'document_parent_id' in d ]en_documents _documents_for locale settings.WIKI_DEFAULT_LANGUAGE products products topics topics fallback_documents [d for d in en_documents if d['id'] not in l10n_document_ids ]else fallback_documents Nonereturn documents fallback_documents
def get_batch_normalization_updates training_graph allow_duplicates False from ..bricks import BatchNormalizationfrom ..filter import VariableFilter get_application_callvar_filter VariableFilter bricks [BatchNormalization] roles [OUTPUT] all_app_calls map get_application_call var_filter training_graph train_app_calls _training_mode_application_calls all_app_calls if len train_app_calls 0 raise ValueError 'notrainingmodeBatchNormalizationapplicationsfoundingraph' bricks [c.application.brick for c in train_app_calls]if not allow_duplicates and not isdistinct bricks raise ValueError 'multipleapplicationsofthesameBatchNormalizationbrick;passallow_duplicates Truetooverridethischeck' def extract_pair brick_attribute metadata_key app_call return getattr app_call.application.brick brick_attribute app_call.metadata[metadata_key] mean_pair partial extract_pair 'population_mean' 'offset' stdev_pair partial extract_pair 'population_stdev' 'divisor' return sum [ [mean_pair a stdev_pair a ] if not a.application.brick.mean_only else [mean_pair a ] for a in train_app_calls] []
def to_xml items msg [u'<?xmlversion "1.0"?>' u'<items>']for item in items msg.append item.to_xml msg.append u'</items>' return u''.join msg
def DNSServiceProcessResult sdRef _global_lock.acquire try _DNSServiceProcessResult sdRef finally _global_lock.release
def fire_pilight_message protocol data message {pilight.CONF_PROTOCOL protocol}message.update data HASS.bus.fire pilight.EVENT message
def object_array *args array np.empty len args dtype object for i in range len args array[i] args[i]return array
def delete_profiler id models.Profiler.smart_get id .delete
def get_milestone_relationship_types if not settings.FEATURES.get 'MILESTONES_APP' return {}return milestones_api.get_milestone_relationship_types
def location_list arg if isinstance arg tuple return latlng arg else return '|'.join [latlng location for location in as_list arg ]
def test_primary_key_is_inherited t table.Table [ 2 3 2 1 8 7 6 5 ] names 'a' 'b' t.add_index 'a' original_key t.primary_keyassert original_key[0] is 'a' t2 t[ ]t3 t.copy t4 table.Table t assert original_key t2.primary_key assert original_key t3.primary_key assert original_key t4.primary_key assert t.loc[1] t2.loc[1] assert t.loc[1] t3.loc[1] assert t.loc[1] t4.loc[1]
def fork_task_context functor context None context context or Context.get_instance xheader context.hook_get_task_context def wrapped *args **kargs context.hook_load_task_context xheader return functor *args **kargs return wrapped
def write_int fid kind data data_size 4data np.array data dtype '>i4' .T_write fid data kind data_size FIFF.FIFFT_INT '>i4'
def TestHuntHelperWithMultipleMocks client_mocks check_flow_errors False token None iteration_limit None total_flows set token token.SetUID client_mocks [MockClient client_id client_mock token token for client_id client_mock in client_mocks.iteritems ]worker_mock MockWorker check_flow_errors check_flow_errors token token while iteration_limit is None or iteration_limit > 0 client_processed 0for client_mock in client_mocks client_processed + client_mock.Next flows_run []for flow_run in worker_mock.Next total_flows.add flow_run flows_run.append flow_run if client_processed 0 and not flows_run breakif iteration_limit iteration_limit - 1if check_flow_errors CheckFlowErrors total_flows token token
def is_int_list value min None max None return [is_integer mem for mem in is_list value min max ]
def get_dependencies return config.check_driver_dependencies __virtualname__ {'libcloud' HAS_LIBS}
def dashboard_new_activities_count context data_dict _check_access 'dashboard_new_activities_count' context data_dict activities logic.get_action 'dashboard_activity_list' context data_dict return len [activity for activity in activities if activity['is_new']]
def add_to_sys_path pathnames index 0 for pathname in pathnames[ -1 ] sys.path.insert index pathname
def _sym_quad_form x mu A q cdist x mu[np.newaxis] 'mahalanobis' VI A ** 2 .reshape -1 return q
def testWithIO inp out f try oldin sys.stdin sys.stdin inp oldout sys.stdout sys.stdout out x f finally sys.stdin oldinsys.stdout oldoutreturn x
def validate_check_flags val if not val returnfor flag in val.split ' ' name flag.split ' ' [0]if name in EXTRA_FLAGS or name in IGNORE_CHECK_FLAGS continueraise ValidationError _ 'Invalidcheckflag "%s"' % flag
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
def millions x pos return '$%1.1fM' % x * 1e-06
def unpackOpen_direct_tcpip data connHost rest common.getNS data connPort int struct.unpack '>L' rest[ 4] [0] origHost rest common.getNS rest[4 ] origPort int struct.unpack '>L' rest[ 4] [0] return connHost connPort origHost origPort
def tree plist l a f if l > 3 lst []for p in plist p.forward l q p.clone p.left a q.right a lst.append p lst.append q for x in tree lst l * f a f yield None
def search_packages_info query installed_packages dict [ p.project_name.lower p for p in pkg_resources.working_set] for name in query normalized_name name.lower if normalized_name in installed_packages dist installed_packages[normalized_name]package {'name' dist.project_name 'version' dist.version 'location' dist.location 'requires' [dep.project_name for dep in dist.requires ]}filelist os.path.join dist.location dist.egg_name + '.egg-info' 'installed-files.txt' if os.path.isfile filelist package['files'] filelist yield package
def _cgi_FieldStorage__repr__patch self if self.file return 'FieldStorage %r %r ' % self.name self.filename return 'FieldStorage %r %r %r ' % self.name self.filename self.value
def a_is_b a b return a is b
def adapt chart data if isinstance chart pygal.XY return datadata cut data if isinstance chart BaseMap return list map lambda x chart.__class__.x_labels[ int x % len chart.__class__.x_labels ] if x is not None else None data return data
def test_unicode_dups request HttpRequest setattr request '_messages' default_storage request info request u'Titl\xe9' u'Body' info request u'Titl\xe9' u'Body' info request u'AnotherTitl\xe9' u'AnotherBody' storage django_messages.get_messages request assert len storage 2 'Toofewortoomanymessagesrecorded.'
def test_require_file from fabtools.require import file as require_filetry require_file 'foo' assert is_file 'foo' assert run 'catfoo' '' finally run 'rm-ffoo'
def match_command_to_alias command aliases results []for alias in aliases format_strings list_format_strings_from_aliases [alias] for format_string in format_strings try extract_parameters format_str format_string[1] param_stream command except ParseException continueresults.append alias format_string[0] format_string[1] return results
def test_evaluation_report y_real np.array [['a' 'b' 'c'] ['a' 'b' 'e' 'f' 'g'] ['a' 'b']] y_pred np.array [['a' 'b' 'c'] ['a' 'b' 'c' 'd'] ['e' 'f']] labels np.array ['user_id1' 'user_id2' 'user_id3'] expected_report 'precisionrecallf1-score\n\nuser_id11.001.001.00\nuser_id20.400.500.44\nuser_id30.000.000.00\n\navg/total0.470.500.48\n'report evaluation_report y_real y_pred target_names labels assert_equals report expected_report expected_report 'precisionrecallf1-score\n\n01.001.001.00\n10.400.500.44\n20.000.000.00\n\navg/total0.470.500.48\n'report evaluation_report y_real y_pred assert_equals report expected_report
def _activation_summary x tensor_name re.sub '%s_[0-9]*/' % TOWER_NAME '' x.op.name tf.contrib.deprecated.histogram_summary tensor_name + '/activations' x tf.contrib.deprecated.scalar_summary tensor_name + '/sparsity' tf.nn.zero_fraction x
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def pure_driver_debug_trace f @functools.wraps f def wrapper *args **kwargs driver args[0]cls_name driver.__class__.__name__method_name '% cls_name s.% method s' % {'cls_name' cls_name 'method' f.__name__} backend_name driver._get_current_array ._backend_idLOG.debug '[% backend_name s]Enter% method_name s' % {'method_name' method_name 'backend_name' backend_name} result f *args **kwargs LOG.debug '[% backend_name s]Leave% method_name s' % {'method_name' method_name 'backend_name' backend_name} return resultreturn wrapper
@with_open_mode 'w' @with_sizes 'small' def write_bytewise f source for i in xrange 0 len source f.write source[i i + 1 ]
def exception_to_dict fault message None code 500if hasattr fault 'kwargs' code fault.kwargs.get 'code' 500 try if not message message fault.format_message except Exception try message six.text_type fault except Exception message Noneif not message message fault.__class__.__name__u_message utils.safe_truncate message 255 fault_dict dict exception fault fault_dict['message'] u_messagefault_dict['code'] codereturn fault_dict
def _check_and_install_rbenv ret user None ret _check_rbenv ret user if ret['result'] is False if __salt__['rbenv.install'] user ret['result'] Trueret['comment'] 'Rbenvinstalled'else ret['result'] Falseret['comment'] 'Rbenvfailedtoinstall'else ret['result'] Trueret['comment'] 'Rbenvalreadyinstalled'return ret
def compare_ordered vals alpha vals np.asarray vals alphaf alphasortind np.argsort vals pvals vals[sortind]sortrevind sortind.argsort ntests len vals v1 v2 np.triu_indices ntests 1 for i in range 4 for j in range 4 i -1 print i j
def fetch_libzmq savedir dest pjoin savedir 'zeromq' if os.path.exists dest info 'alreadyhave%s' % dest returnpath fetch_archive savedir libzmq_url fname libzmq checksum libzmq_checksum tf tarfile.open path with_version pjoin savedir tf.firstmember.path tf.extractall savedir tf.close shutil.move with_version dest
def clean_sort_param request date_sort 'created' sort request.GET.get 'sort' date_sort order request.GET.get 'order' 'asc' if sort not in 'name' 'created' 'nomination' sort date_sortif order not in 'desc' 'asc' order 'asc'return sort order
def get_cli_body_ssh command response module if 'xml' in response[0] body []elif '^' in response[0] or 'showrun' in response[0] or response[0] '\n' body responseelse try body [json.loads response[0] ]except ValueError module.fail_json msg 'CommanddoesnotsupportJSONoutput' command command return body
def part rebulk Rebulk .regex_defaults flags re.IGNORECASE abbreviations [dash] validator {'__parent__' seps_surround} prefixes ['pt' 'part']def validate_roman match '\nValidatearomanmatchifsurroundedbyseparators\n parammatch \n typematch \n return \n rtype \n'if int_coercable match.raw return Truereturn seps_surround match rebulk.regex build_or_pattern prefixes + '-? ?P<part>' + numeral + ' ' prefixes prefixes validate_all True private_parent True children True formatter parse_numeral validator {'part' compose validate_roman lambda m 0 < m.value < 100 } return rebulk
def bin_perm_rep ndim a 0 b 1 nperms 2 ** ndim perms np.empty nperms ndim type a perms.fill a half_point nperms // 2 perms[half_point 0] bfor j in range 1 ndim half_col perms[ 2 j - 1 ]perms[ half_point j] half_colperms[half_point j] half_colreturn perms
def _get_current_unhelpful old_formatted final {}cursor connection.cursor cursor.execute 'SELECTdoc_id yes no\nFROM\n SELECTwiki_revision.document_idasdoc_id \nSUM limitedvotes.helpful asyes \nSUM NOT limitedvotes.helpful asno\nFROM\n SELECT*FROMwiki_helpfulvote\nWHEREcreated> DATE_SUB CURDATE INTERVAL1WEEK \n aslimitedvotes\nINNERJOINwiki_revisionON\nlimitedvotes.revision_id wiki_revision.id\nINNERJOINwiki_documentON\nwiki_document.id wiki_revision.document_id\nWHEREwiki_document.locale "en-US"\nGROUPBYdoc_id\nHAVINGno>yes\n ascalculated' current_data cursor.fetchall for data in current_data doc_id data[0]yes float data[1] no float data[2] total yes + no if total 0 continuepercentage yes / total if doc_id in old_formatted final[doc_id] {'total' total 'currperc' percentage 'diffperc' percentage - old_formatted[doc_id]['percentage'] }else final[doc_id] {'total' total 'currperc' percentage 'diffperc' 0.0}return final
def blockCombine l l [list map mat row for row in l]hdims [m.shape[1] for m in l[0]]hs sum hdims vdims [row[0].shape[0] for row in l]vs sum vdims res zeros hs vs vindex 0for i row in enumerate l hindex 0for j m in enumerate row res[vindex vindex + vdims[i] hindex hindex + hdims[j] ] mhindex + hdims[j]vindex + vdims[i]return res
def calculators_for_aggregates cube aggregates drilldown_levels None split None functions []for aggregate in aggregates try factory CALCULATED_AGGREGATIONS[aggregate.function]except KeyError raise ArgumentError "Unknownpost-calculationfunction'%s'foraggregate'%s'" % aggregate.function aggregate.name if aggregate.measure source cube.measure_aggregate aggregate.measure else raise InternalError "Nomeasurespecifiedforaggregate'%s'incube'%s'" % aggregate.name cube.name func factory aggregate source.ref drilldown_levels split functions.append func return functions
def _base_class_object_build node member basenames name None localname None klass build_class name or getattr member '__name__' None or localname basenames member.__doc__ klass._newstyle isinstance member type node.add_local_node klass localname try if issubclass member Exception instdict member .__dict__else raise TypeErrorexcept passelse for name obj in instdict.items valnode EmptyNode valnode.object objvalnode.parent klassvalnode.lineno 1klass.instance_attrs[name] [valnode]return klass
def get_user_perms user obj check ObjectPermissionChecker user return check.get_user_perms obj
def threshold_percentile image selem out None mask None shift_x False shift_y False p0 0 return _apply percentile_cy._threshold image selem out out mask mask shift_x shift_x shift_y shift_y p0 p0 p1 0
def _user_activity_query user_id limit q1 _activities_limit _activities_from_user_query user_id limit q2 _activities_limit _activities_about_user_query user_id limit return _activities_union_all q1 q2
def pretty_message string *params output textwrap.dedent string if output.find u'\n' ! -1 output re.sub u' ?< \\S \n ? [^\n DCTB \\d\\*\\- ] ' u'' output if params output output % params output output.strip return output
def print_errors_patch result return make_instancemethod TextTestResult.printErrors result
def registerReapProcessHandler pid process if pid in reapProcessHandlers raise RuntimeError 'Trytoregisteranalreadyregisteredprocess.' try auxPID status os.waitpid pid os.WNOHANG except log.msg 'Failedtoreap%d ' % pid log.err auxPID Noneif auxPID process.processEnded status else reapProcessHandlers[pid] process
def get_event_transaction_id return get_cache 'event_transaction' .get 'id' None
def choose_content_type accept_header supported_types for accept_item in parse_accept_header accept_header for supported_type in supported_types if accept_item.match supported_type return supported_typereturn None
def get_last_accessed_courseware course request user field_data_cache FieldDataCache.cache_for_descriptor_descendents course.id request.user course depth 2 course_module get_module_for_descriptor user request course field_data_cache course.id course course chapter_module get_current_child course_module if chapter_module is not None section_module get_current_child chapter_module if section_module is not None url reverse 'courseware_section' kwargs {'course_id' unicode course.id 'chapter' chapter_module.url_name 'section' section_module.url_name} return urlreturn None
def StringToConstant pString if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' a ctypes.create_string_buffer pString 256 return staticLib.StringToConstant a else raise LabJackException 0 'FunctiononlysupportedforWindows'
@_docstring 'label' def search_labels query '' limit None offset None strict False **fields return _do_mb_search 'label' query fields limit offset strict
def smoothness n if n 1 return 1 1 facs factorint n return max facs max m ** facs[m] for m in facs
def keymap func d factory dict rv factory rv.update zip map func iterkeys d itervalues d return rv
def parse_commit repo committish committish to_bytes committish return repo[committish]
def validate_dependencies if not app_is_installed 'treebeard' raise ImproperlyConfigured 'djangoCMSrequiresdjango-treebeard.Pleaseinstallitandadd"treebeard"toINSTALLED_APPS.'
def scoverage registry xml_parent data scoverage XML.SubElement xml_parent 'org.jenkinsci.plugins.scoverage.ScoveragePublisher' scoverage.set 'plugin' 'scoverage' mappings [ 'report-directory' 'reportDir' None 'report-file' 'reportFile' None ]helpers.convert_mapping_to_xml scoverage data mappings fail_required True
def unescape s assert isinstance s basestring s s.replace ' DCTB ' ' ' s s.replace '\\ ' ' ' s s.replace '\\n' '\n' s s.replace '\\\\' '\\' return s
def EncodePOSIXShellList list encoded_arguments []for argument in list encoded_arguments.append EncodePOSIXShellArgument argument return ''.join encoded_arguments
def quota_usage_refresh context resources keys until_refresh max_age project_id None user_id None return IMPL.quota_usage_refresh context resources keys until_refresh max_age project_id project_id user_id user_id
def variables_and_orphans i o def expand r if r.owner and r not in i l list r.owner.inputs + list r.owner.outputs l.reverse return lvariables stack_search deque o expand 'dfs' orphans [r for r in variables if r.owner is None and r not in i ]return variables orphans
def start_recording env None recorder_proxy.clear_for_current_request if env is None env os.environif not config.should_record env returnif memcache.add lock_key 0 time config.LOCK_TIMEOUT namespace config.KEY_NAMESPACE recorder_proxy.set_for_current_request Recorder env if config.DEBUG logging.debug 'Setrecorder'
@click.command @click.option '--name' help 'FullName' prompt True @click.option '--email' help 'Email' prompt True @click.option '--password' help 'Password' prompt True hide_input True confirmation_prompt True @click.option '--role' help 'Role' prompt True def cli name None email None password None role None create_user name email password role
def flocker_keypair return ComparableKeyPair keypair KeyPair.generate crypto.TYPE_RSA size 4096
def inconsistent Z d 2 Z np.asarray Z order 'c' Zs Z.shapeis_valid_linkage Z throw True name 'Z' if not d np.floor d or d < 0 raise ValueError 'Thesecondargumentdmustbeanonnegativeintegervalue.' [Z] _copy_arrays_if_base_present [Z] n Zs[0] + 1 R np.zeros n - 1 4 dtype np.double _hierarchy.inconsistent Z R int n int d return R
def row_sort cell return column_index_from_string cell.column
def filter_factory global_conf **local_conf conf global_conf.copy conf.update local_conf register_swift_info 'tempauth' account_acls True def auth_filter app return TempAuth app conf return auth_filter
def conda_versions pkg_name file_name j json.load open file_name ret list for pkg in j['packages'].values if pkg['name'] pkg_name ret.append '%s--%s' % pkg['version'] pkg['build'] return ret
def set_id device minor system_id _validate_device device try int minor except Exception raise CommandExecutionError 'Invalidminornumberpassedtopartition.set_id' if system_id not in system_types raise CommandExecutionError 'Invalidsystem_idpassedtopartition.set_id' cmd 'sfdisk--change-id{0}{1}{2}'.format device minor system_id out __salt__['cmd.run'] cmd .splitlines return out
@app.route '/send-multiple' methods ['POST'] def multi_send_create account g.namespace.accountif account.discriminator 'easaccount' raise InputError 'Multiplesendisnotsupportedforthisprovider.' data request.get_json force True draft create_message_from_json data g.namespace g.db_session is_draft False validate_draft_recipients draft draft.mark_as_sending g.db_session.add draft request.environ['log_context']['draft_public_id'] draft.public_idreturn g.encoder.jsonify draft
def _iterate_over_sub_policies sub_policies check_statement_func for sub_policy_name in sub_policies sub_policy sub_policies[sub_policy_name]_iterate_over_statements sub_policy check_statement_func
def check_message_extractors dist name value assert name 'message_extractors' if not isinstance value dict raise DistutilsSetupError 'thevalueofthe"message_extractors"parametermustbeadictionary'
def SetVariableList output variable_name values if not values return SetVariable output variable_name '' if len values 1 return SetVariable output variable_name values[0] output.write 'list APPEND' output.write variable_name output.write '\n"' output.write '"\n"'.join [CMakeStringEscape value for value in values] output.write '" \n'
def copyto dst src casting 'same_kind' where None if not numpy.can_cast src.dtype dst.dtype casting raise TypeError 'Cannotcast%sto%sin%scastingmode' % src.dtype dst.dtype casting if dst.size 0 returnif where is None if _can_memcpy dst src dst.data.copy_from src.data src.nbytes else core.elementwise_copy src dst else core.elementwise_copy_where src where dst
def brick_get_connector protocol driver None use_multipath False device_scan_attempts 3 *args **kwargs root_helper get_root_helper return connector.InitiatorConnector.factory protocol root_helper driver driver use_multipath use_multipath device_scan_attempts device_scan_attempts *args **kwargs
def preprocess file_or_url output None temp_suffix '.txt' temp_prefix 'inc' result Nonepath Noneif not output fd path tempfile.mkstemp suffix temp_suffix prefix temp_prefix output open path 'w' atexit.register unlink_quietly path os.close fd result pathelse result outputIncluder file_or_url output output return result
def request_minidom url **kwargs response request_response url **kwargs if response is not None return minidom.parseString response.content
def make_default_signal_map name_map {'SIGTSTP' None 'SIGTTIN' None 'SIGTTOU' None 'SIGTERM' 'terminate'}signal_map dict getattr signal name target for name target in name_map.items if hasattr signal name return signal_map
def remote_command client_ip command process_output []d run_ssh reactor 'ubuntu' client_ip command handle_stdout process_output.append d.addCallback lambda process_result process_result process_output return d
def order_mod x m if m < 1 return 0assert gcd x m 1 z xresult 1while z ! 1 z z * x % m result result + 1 return result
def get_group_type ctxt id expected_fields None if id is None msg _ 'idcannotbeNone' raise exception.InvalidGroupType reason msg if ctxt is None ctxt context.get_admin_context return db.group_type_get ctxt id expected_fields expected_fields
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_named_colors_mapping return _colors_full_map
def bubble a count 0for i in range len a - 1 for j in range len a - i - 1 if a[ j + 1 ] < a[j] a[j] a[ j + 1 ] a[ j + 1 ] a[j] count + 1return count
def subsumes fstruct1 fstruct2 return fstruct2 unify fstruct1 fstruct2
@jsonifydef delete_record self arg_dict cmd ['xenstore-rm' '/local/domain/% dom_id s/% path s' % arg_dict ] ret result _run_command cmd return result
def NotFound message None if message return _NotFound message elif ctx.get 'app_stack' return ctx.app_stack[ -1 ].notfound else return _NotFound
def test_default_values raw events _get_data [ 2]epoch_1 Epochs raw events[ 1] preload True epoch_2 Epochs raw events[ 1] tmin -0.2 tmax 0.5 preload True assert_equal hash epoch_1 hash epoch_2
def extract_meta_refresh html soup BeautifulSoup html 'html.parser' element soup.find 'meta' attrs {'http-equiv' 'refresh'} if element try wait_part url_part element['content'].split ';' except ValueError return Noneelse if url_part.lower .startswith 'url ' return url_part[4 ].replace '"' '' .replace "'" ''
def make_plot source xname yname line_color xdr None ydr None if xdr is None xdr DataRange1d if ydr is None ydr DataRange1d plot Plot x_range xdr y_range ydr min_border 50 plot.add_layout LinearAxis 'below' plot.add_layout LinearAxis 'left' plot.add_glyph source Line x xname y yname line_color line_color plot.add_tools PanTool WheelZoomTool return plot
def _get_method_info cls result {}methods inspect.getmembers cls inspect.ismethod for name method in methods if name.startswith '_' continueresult[name] method _get_arg_count method return result
def from_migration_import module_name fromlist module_path 'glance.db.sqlalchemy.migrate_repo.versions.%s' % module_name module __import__ module_path globals locals fromlist 0 return [getattr module item for item in fromlist]
def segments_intersect s1 s2 x1 y1 x2 y2 s1 x3 y3 x4 y4 s2den y4 - y3 * x2 - x1 - x4 - x3 * y2 - y1 n1 x4 - x3 * y1 - y3 - y4 - y3 * x1 - x3 n2 x2 - x1 * y1 - y3 - y2 - y1 * x1 - x3 if den 0 return Falseu1 n1 / den u2 n2 / den return 0.0 < u1 < 1.0 and 0.0 < u2 < 1.0
def manifest_list extension mods None db None debug None if debug is not None _logger.warning 'odoo.addons.web.main.manifest_list debugparameterisdeprecated' files manifest_glob extension addons mods db db include_remotes True return [wp for _fp wp in files]
def _parse_oneof_validator error types []for context in error.context if context.validator u'oneOf' _ error_msg _parse_oneof_validator context return path_string context.path error_msg if context.validator u'required' return None context.message if context.validator u'additionalProperties' invalid_config_key parse_key_from_error_msg context return None u"containsunsupportedoption '{}'".format invalid_config_key if context.path return path_string context.path u'contains{} whichisaninvalidtype itshouldbe{}'.format json.dumps context.instance _parse_valid_types_from_validator context.validator_value if context.validator u'uniqueItems' return None u'containsnonuniqueitems pleaseremoveduplicatesfrom{}'.format context.instance if context.validator u'type' types.append context.validator_value valid_types _parse_valid_types_from_validator types return None u'containsaninvalidtype itshouldbe{}'.format valid_types
def publishToNewObserver observer eventDict textFromEventDict if 'log_time' not in eventDict eventDict['log_time'] eventDict['time']if 'log_format' not in eventDict text textFromEventDict eventDict if text is not None eventDict['log_text'] texteventDict['log_format'] u'{log_text}'if 'log_level' not in eventDict if 'logLevel' in eventDict try level fromStdlibLogLevelMapping[eventDict['logLevel']]except KeyError level Noneelif 'isError' in eventDict if eventDict['isError'] level LogLevel.criticalelse level LogLevel.infoelse level LogLevel.infoif level is not None eventDict['log_level'] levelif 'log_namespace' not in eventDict eventDict['log_namespace'] u'log_legacy'if 'log_system' not in eventDict and 'system' in eventDict eventDict['log_system'] eventDict['system']observer eventDict
def connect_consumer message *args **kwargs message.reply_channel.send {u'accept' True}
def dummy_func x shape return np.ones shape
def mutual_info_regression X y discrete_features 'auto' n_neighbors 3 copy True random_state None return _estimate_mi X y discrete_features False n_neighbors copy random_state
def metadef_property_delete context namespace_name property_name session None session session or get_session return metadef_property_api.delete context namespace_name property_name session
def _get_nodes_supported_instances cpu_arch None if not cpu_arch return []return [ cpu_arch obj_fields.HVType.BAREMETAL obj_fields.VMMode.HVM ]
def unbits s endian 'big' if endian 'little' u lambda s chr int s[ -1 ] 2 elif endian 'big' u lambda s chr int s 2 else raise ValueError "unbits 'endian'mustbeeither'little'or'big'" out ''cur ''for c in s if c in ['1' 1 True] cur + '1'elif c in ['0' 0 False] cur + '0'else raise ValueError 'unbits cannotdecodethevalue%rintoabit' % c if len cur 8 out + u cur cur ''if cur out + u cur.ljust 8 '0' return ''.join out
def _get_gcp_credentials module require_valid_json True check_libcloud False service_account_email credentials_file project_id _get_gcp_ansible_credentials module service_account_email credentials_file project_id _get_gcp_environment_credentials service_account_email credentials_file project_id service_account_email credentials_file project_id _get_gcp_libcloud_credentials service_account_email credentials_file project_id if credentials_file is None or project_id is None or service_account_email is None if check_libcloud is True module.fail_json msg 'MissingGCEconnectionparametersinlibcloudsecretsfile.' return Noneelif credentials_file is None or project_id is None module.fail_json msg 'GCPconnectionerror enabletodetermineproject %s orcredentialsfile %s ' % project_id credentials_file _validate_credentials_file module credentials_file require_valid_json require_valid_json check_libcloud check_libcloud return {'service_account_email' service_account_email 'credentials_file' credentials_file 'project_id' project_id}
def schedule_guard global SCHEDULE_GUARD_FLAGSCHEDULE_GUARD_FLAG True
def test_mpl_preserve_dpi f create_figure width height f.canvas.get_width_height s mplhooks.figure_to_tight_array f 0.5 * width 0.5 * height False exp DPIobs f.dpiplt.close f assert exp obs
def _parse_tal_channel tal_channel_data tals bytearray for chan in tal_channel_data for s in chan i int s tals.extend np.uint8 [ i % 256 i // 256 ] regex_tal ' [+-]\\d+\\.?\\d* \x15 \\d+\\.?\\d* ? \x14.*? \x14\x00'tal_list re.findall regex_tal tals.decode 'latin-1' events []for ev in tal_list onset float ev[0] duration float ev[2] if ev[2] else 0 for annotation in ev[3].split '\x14' [1 ] if annotation events.append [onset duration annotation] return events
def s3_gis_location_parents r **attr table r.resource.tableif not s3_has_permission 'read' table r.unauthorised if r.representation 'html' output dict raise HTTP 501 ERROR.BAD_FORMAT elif r.representation 'json' if r.id parents gis.get_parents r.id if parents _parents {}for parent in parents _parents[parent.level] parent.idoutput json.dumps _parents separators SEPARATORS return outputelse raise HTTP 404 ERROR.NO_MATCH else raise HTTP 404 ERROR.BAD_RECORD else raise HTTP 415 ERROR.BAD_FORMAT
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def generateSequences nPatterns 10 patternLen 500 patternActivity 50 hubs [2 6] seqLength [5 6 7] nSimpleSequences 50 nHubSequences 50 patterns generateCoincMatrix nCoinc nPatterns length patternLen activity patternActivity seqList generateSimpleSequences nCoinc nPatterns seqLength seqLength nSeq nSimpleSequences + generateHubSequences nCoinc nPatterns hubs hubs seqLength seqLength nSeq nHubSequences return seqList patterns
def framesFromBytes data buffer FrameBuffer buffer.receiveData data return list buffer
def reset noGamma True OK init if noGamma and OK setVideoMode NOGAMMACORRECT
def dict_to_pdnode d e dict for k v in iteritems d if v is not None if isinstance v list v ' DCTB '.join [str x for x in v] else v str v v str v v v.replace '"' "'" e[k] vpynode pd.Node **e return pynode
def is_excluded root excludes for exclude in excludes if fnmatch root exclude return Truereturn False
def get_readme_files_dict_for_display app tool_shed_url repo_info_dict name next iter repo_info_dict repo_info_tuple repo_info_dict[name] description repository_clone_url changeset_revision ctx_rev repository_owner repository_dependencies installed_td repository_util.get_repo_info_tuple_contents repo_info_tuple tool_shed_url common_util.get_tool_shed_url_from_tool_shed_registry app tool_shed_url params dict name name owner repository_owner changeset_revision changeset_revision pathspec ['repository' 'get_readme_files']raw_text url_get tool_shed_url password_mgr app.tool_shed_registry.url_auth tool_shed_url pathspec pathspec params params readme_files_dict json.loads raw_text return readme_files_dict
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def get_children cluster if is_leaf cluster raise TypeError 'aleafclusterhasnochildren' else return cluster[1]
def splitPathInfo pathinfo if pathinfo '/' return None None None if _pathinfo_pat.match pathinfo or '' path _pathinfo_pat.match pathinfo layer row column zoom extension [path.group p for p in 'lyxze']coord Coordinate int row int column int zoom elif _preview_pat.match pathinfo or '' path _preview_pat.match pathinfo layer extension path.group 'l' 'html' coord Noneelse raise Core.KnownUnknown 'Badpath "%s".Iwasexpectingsomethingmorelike"/example/0/0/0.png"' % pathinfo return layer coord extension
def findBaseImage flavor size '8G' image path.join VMImageDir flavor + '-base.qcow2' if path.exists image perms stat image [ST_MODE] & 511 if perms ! 292 raise Exception 'Error-baseimage%siswritable.' % image + 'Aremultiplebuildsrunning?ifnot remove%sandtryagain.' % image else run 'mkdir-p%s' % VMImageDir iso findiso flavor log '*Creatingimagefile' image run 'qemu-imgcreate-fqcow2%s%s' % image size installUbuntu iso image log '*Write-protectingimage' image os.chmod image 292 kernel initrd extractKernel image flavor log '*Usingbaseimage' image 'andkernel' kernel return image kernel initrd
def read_exactly socket n data six.binary_type while len data < n next_data read socket n - len data if not next_data raise SocketError 'UnexpectedEOF' data + next_datareturn data
def metadef_tag_get_all context namespace_name filters None marker None limit None sort_key None sort_dir None session None session session or get_session return metadef_tag_api.get_all context namespace_name session filters marker limit sort_key sort_dir
def find_id_with_wait context id_str **kwargs return _find_elem_with_wait context By.ID id_str **kwargs
def CherryPyWSGIServer bind_addr wsgi_app numthreads 10 server_name None max -1 request_queue_size 5 timeout 10 shutdown_timeout 5 max_threads maxif max_threads < 0 max_threads 0return Rocket bind_addr 'wsgi' {'wsgi_app' wsgi_app} min_threads numthreads max_threads max_threads queue_size request_queue_size timeout timeout
def generate_wcs length 14 assert type length in six.integer_types return u''.join [random.choice WCS_SECRET_CHARSET for _ in range length ] .encode 'ascii'
def organization_member_create context data_dict _check_access 'organization_member_create' context data_dict return _group_or_org_member_create context data_dict is_org True
def copy_test_to_media module name mezzanine_path path_for_import module test_path os.path.join mezzanine_path u'static' u'test' name to_path os.path.join settings.MEDIA_ROOT name to_dir os.path.dirname to_path if not os.path.exists to_dir os.makedirs to_dir if os.path.isdir test_path copy copytreeelse copy copyfiletry copy test_path to_path except OSError pass
def _make_position location_string offset 0 if location_string '?' return SeqFeature.UnknownPosition try return SeqFeature.ExactPosition max 0 offset + int location_string except ValueError passif location_string.startswith '<' try return SeqFeature.BeforePosition max 0 offset + int location_string[1 ] except ValueError passelif location_string.startswith '>' try return SeqFeature.AfterPosition max 0 offset + int location_string[1 ] except ValueError passelif location_string.startswith '?' try return SeqFeature.UncertainPosition max 0 offset + int location_string[1 ] except ValueError passraise NotImplementedError "Cannotparselocation'%s'" % location_string
def cmd *args return ''.join str arg for arg in args if arg
def notify notificationName message if sabnzbd.FOUNDATION pool Foundation.NSAutoreleasePool.alloc .init nc Foundation.NSDistributedNotificationCenter.defaultCenter nc.postNotificationName_object_ notificationName message del pool
def bokeh_commit name rawtext text lineno inliner options None content None app inliner.document.settings.env.appnode make_gh_link_node app rawtext 'commit' 'commit' 'commit' text options return [node] []
def clear_path graph reg loc1 loc2 logger.debug 'clear_path reg %s loc1 %s loc2 %s ' reg loc1 loc2 node1 graph.get_node_from_loc loc1 node2 graph.get_node_from_loc loc2 if node1 is node2 return clear_path_node graph reg loc1 + 1 loc2 if not clear_path_node graph reg loc1 + 1 node1.ins_range[1] return Falsepath build_path graph node1 node2 for node in path locs node.ins_rangeend_loc loc2 if locs[0] < loc2 < locs[1] else locs[1] if not clear_path_node graph reg locs[0] end_loc return Falsereturn True
def UpdateResourcesFromDataFile dstpath srcpath type_ names None languages None src open srcpath 'rb' data src.read src.close UpdateResources dstpath data type_ names languages
def assign_funcs modname service module None pack None if pack global __salt____salt__ packmod sys.modules[modname]setattr mod '_get_conn' get_connection_func service module module setattr mod '_cache_id' cache_id_func service setattr mod '_exactly_one' exactly_one
def parseRequest_pty_req data term rest common.getNS data cols rows xpixel ypixel struct.unpack '>4L' rest[ 16] modes ignored common.getNS rest[16 ] winSize rows cols xpixel ypixel modes [ ord modes[i] struct.unpack '>L' modes[ i + 1 i + 5 ] [0] for i in range 0 len modes - 1 5 ]return term winSize modes
def suite s TestSuite for test_suite in test_suites s.addTest test_suite return s
def Date year month day return datetime.date year month day
def get_configuration_value name default None configuration get_current_site_configuration return configuration.get_value name default
def worktree_browser_widget parent update True settings None view Browser parent update update settings settings view.tree.setModel GitRepoModel view.tree view.ctl BrowserController view.tree if update view.tree.refresh return view
def _ensure_scope level global_dict None local_dict None resolvers target None **kwargs return Scope level + 1 global_dict global_dict local_dict local_dict resolvers resolvers target target
def get_author_name user email True full_name user.first_nameif full_name u'' full_name user.usernameif not email return full_namereturn u'%s<%s>' % full_name user.email
def hr_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'hrm' 'human_resource'
def ai_zeros nt kf 1if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'ntmustbeapositiveintegerscalar.' return specfun.airyzo nt kf
def interlink_removed_content generator current_lang generator.settings['DEFAULT_LANG']for content in _GENERATOR_DB[generator] url _NATIVE_CONTENT_URL_DB[content.source_path]relpath relpath_to_site current_lang content.lang content.override_url posixpath.join relpath url
def get_auto_step_size max_squared_sum alpha_scaled loss fit_intercept if loss in 'log' 'multinomial' return 4.0 / max_squared_sum + int fit_intercept + 4.0 * alpha_scaled elif loss 'squared' return 1.0 / max_squared_sum + int fit_intercept + alpha_scaled else raise ValueError "UnknownlossfunctionforSAGsolver got%sinsteadof'log'or'squared'" % loss
@register.inclusion_tag 'utilities/render_form.html' def render_form form return {'form' form}
def useVersion requestedVersion imported _psychopyComponentsImported if imported msg _translate 'PleaserequestaversionbeforeimportinganyPsychoPymodules. Found {} ' raise RuntimeError msg.format imported reqdMajorMinorPatch fullVersion requestedVersion logging.exp 'Requested useVersion {} {}'.format requestedVersion reqdMajorMinorPatch if not reqdMajorMinorPatch msg _translate 'Unknownversion`{}`' raise ValueError msg.format requestedVersion if psychopy.__version__ ! reqdMajorMinorPatch if not _gitPresent msg _translate 'Pleaseinstallgit;neededbyuseVersion ' raise RuntimeError msg _switchToVersion reqdMajorMinorPatch reload psychopy reload logging reload web if _versionTuple reqdMajorMinorPatch > 1 80 reload tools logging.exp 'Versionnowsetto {}'.format psychopy.__version__ return psychopy.__version__
def GetEntityViaMemcache entity_key entity memcache.get entity_key if entity is not None return entitykey ndb.Key urlsafe entity_key entity key.get if entity is not None memcache.set entity_key entity return entity
def _rm_mods pre_mods post_mods pre set post set for mod in pre_mods pre.add mod['module'] for mod in post_mods post.add mod['module'] return pre - post
def __get_all_plugin_descriptors global PLUGIN_EXTENSIONreturn [pf for pf in os.listdir resources.PLUGINS if pf.endswith PLUGIN_EXTENSION ]
def get_script_choices choices return [ script get_script_name script for script in choices] + [ '' '' ]
def batch_iterator X batch_size 64 n_samples X.shape[0]n_batches n_samples // batch_size batch_end 0for b in range n_batches batch_begin b * batch_size batch_end batch_begin + batch_size X_batch X[batch_begin batch_end] yield X_batch if n_batches * batch_size < n_samples yield X[batch_end ]
def get_timedelta_conversion_factor src_unit dest_unit return _get_conversion_multiplier DATETIME_UNITS[src_unit] DATETIME_UNITS[dest_unit]
def _check_tips cursor conflicting_tips cursor.one '\nSELECTcount * \nFROM\n \nSELECT*FROMtips\nEXCEPT\nSELECTDISTINCTON tipper tippee mtime *\nFROMtips\nORDERBYtipper tippee mtime\n ASfoo\n' assert conflicting_tips 0
def libvlc_audio_equalizer_new f _Cfunctions.get 'libvlc_audio_equalizer_new' None or _Cfunction 'libvlc_audio_equalizer_new' None ctypes.c_void_p return f
def make_instance_save instance fields fail_message def save self commit True return save_instance self instance fields fail_message commit return save
def p_expression_uminus t t[0] - t[2]
def _model_to_prospective_search_schema model add_entry from google.appengine.ext import dbfor name model_property in model.properties .iteritems model_class model_property.__class__if issubclass model_class db.ListProperty model_class _GetModelTypeForListPropertyType model_property.item_type _add_schema_entry model_class name add_entry
def mac_ver release '' versioninfo '' '' '' machine '' info _mac_ver_xml if info is not None return infoinfo _mac_ver_gestalt if info is not None return inforeturn release versioninfo machine
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def load_module name file_ pathname description suffix mode type_ descriptionif type_ PKG_DIRECTORY if name in sys.modules mod sys.modules[name]else mod new_module name sys.modules[name] modfilename os.path.join pathname '__init__.py' mod.__file__ filenameexecfile filename mod.__dict__ mod.__dict__ return modelse raise NotImplementedError 'OnlyimportingpackagesissupportedonAppEngine'
def localdate value None timezone None return localtime value timezone .date
def dmp_zeros n u K if not n return []if u < 0 return [K.zero] * n else return [dmp_zero u for i in range n ]
def Property deprecation None removal None alternative None description None def _inner fun return _deprecated_property fun deprecation deprecation removal removal alternative alternative description description or fun.__name__ return _inner
def func_std_string func_name if func_name[ 2] '~' 0 name func_name[2]if name.startswith '<' and name.endswith '>' return '{%s}' % name[1 -1 ] else return nameelse return '%s %d %s ' % func_name
def get_llite_stats directory fs out []for fspath in os.listdir directory if fs in fspath logging.debug 'openingfile' + str directory + '/' + str fspath + '/stats' try llite_stats open '%s/%s/stats' % directory fspath except IOError llite_stats []for line in llite_stats item re.split '\\s+' line.rstrip out.append item return out
def test_evoked_detrend ave read_evokeds fname 0 ave_normal read_evokeds fname 0 ave.detrend 0 ave_normal.data - np.mean ave_normal.data axis 1 [ np.newaxis]picks pick_types ave.info meg True eeg True exclude 'bads' assert_true np.allclose ave.data[picks] ave_normal.data[picks] rtol 1e-08 atol 1e-16
def _find_python_traceback lines all_tb_lines []tb_lines []non_tb_lines []in_traceback Falsefor line in lines line to_string line if in_traceback tb_lines.append line if line.lstrip line in_traceback Falseif line.startswith 'subprocess.CalledProcessError' all_tb_lines + non_tb_linesall_tb_lines + tb_linestb_lines []non_tb_lines []elif line.startswith 'Traceback mostrecentcalllast ' tb_lines.append line in_traceback Trueelse non_tb_lines.append line if all_tb_lines return all_tb_lineselse return None
def critical_block_start registry xml_parent data cbs XML.SubElement xml_parent 'org.jvnet.hudson.plugins.exclusion.CriticalBlockStart' cbs.set 'plugin' 'Exclusion'
def test_scenario_matches_tags_excluding_fuzzywuzzy scenario Scenario.from_string SCENARIO1 original_string '@anothertag\n@another-tag\n' + SCENARIO1.strip assert not scenario.matches_tags ['-~anothertag']
def sdm_LT f return f[0]
def hostinterface_create hostid ip dns '' main 1 type 1 useip 1 port None **connection_args conn_args _login **connection_args if not port port INTERFACE_DEFAULT_PORTS[type]try if conn_args method 'hostinterface.create'params {'hostid' hostid 'ip' ip 'dns' dns 'main' main 'port' port 'type' type 'useip' useip}params _params_extend params **connection_args ret _query method params conn_args['url'] conn_args['auth'] return ret['result']['interfaceids']else raise KeyErrorexcept KeyError return ret
def load_locustfile path directory locustfile os.path.split path added_to_path Falseindex Noneif directory not in sys.path sys.path.insert 0 directory added_to_path Trueelse i sys.path.index directory if i ! 0 index isys.path.insert 0 directory del sys.path[ i + 1 ]imported __import__ os.path.splitext locustfile [0] if added_to_path del sys.path[0]if index is not None sys.path.insert index + 1 directory del sys.path[0]locusts dict filter is_locust vars imported .items return imported.__doc__ locusts
def s3_rheader_tabs r tabs None rheader_tabs S3ComponentTabs tabs return rheader_tabs.render r
def _recursive_dirname f while f yield f f dirname f yield u''
def pydot_from_networkx N from warnings import warnwarn 'pydot_from_networkxisreplacedbyto_pydot' DeprecationWarning return to_pydot N
@application.route '/event_click' def event_click try session_str urllib.unquote request.cookies.get 'reddit_session' '' user_id int session_str.split ' ' [0] except ValueError user_id Noneargs request.args.to_dict if user_id payload args.get 'data' .encode 'utf-8' try payload_json json.loads payload except ValueError passelse payload_json['user_id'] user_idargs['data'] json.dumps payload_json return _redirect_nocache '/event_redirect?%s' % urllib.urlencode args
def validate_int_or_None s if s u'None' s Noneif s is None return Nonetry return int s except ValueError raise ValueError u'Couldnotconvert"%s"toint' % s
def supply_item_entity_category row if hasattr row 'supply_item_entity' row row.supply_item_entityelse return Nonetry item_id row.item_idexcept AttributeError return Nonetable current.s3db.supply_itemquery table.id item_id record current.db query .select table.item_category_id limitby 0 1 .first if record return table.item_category_id.represent record.item_category_id else return current.messages['NONE']
def load_modules session modules_paths glob.glob '%s/modules/*/[a-z]*py' % config.weevely_path for module_path in modules_paths module_group module_filename module_path.split os.sep [ -2 ]module_name os.path.splitext module_filename [0]classname module_name.capitalize module __import__ 'modules.%s.%s' % module_group module_name fromlist ['*'] folder module_path.replace module_filename '_%s' % module_name module_class getattr module classname session '%s_%s' % module_group module_name folder loaded[ '%s_%s' % module_group module_name ] module_classtree_group loaded_tree.get module_group if not tree_group loaded_tree[module_group] []loaded_tree[module_group].append '%s_%s' % module_group module_name
def extract_tasks imported_vars new_style_tasks _Dict classic_tasks {}default_task Noneif 'new_style_tasks' not in state.env state.env.new_style_tasks Falsefor tup in imported_vars name obj tupif is_task_object obj state.env.new_style_tasks Trueif obj.name and obj.name ! 'undefined' new_style_tasks[obj.name] objelse obj.name namenew_style_tasks[name] objif obj.aliases is not None for alias in obj.aliases new_style_tasks[alias] objif obj.is_default default_task objelif is_classic_task tup classic_tasks[name] objelif is_task_module obj docs newstyle classic default load_tasks_from_module obj for task_name task in newstyle.items if name not in new_style_tasks new_style_tasks[name] _Dict new_style_tasks[name][task_name] taskif default is not None new_style_tasks[name].default defaultreturn new_style_tasks classic_tasks default_task
def get_app_access_token app_id app_secret args {'grant_type' 'client_credentials' 'client_id' app_id 'client_secret' app_secret}file urllib2.urlopen 'https //graph.facebook.com/oauth/access_token?' + urllib.urlencode args try result file.read .split ' ' [1]finally file.close return result
def _parse_quoted_string data start value u''qc data[start]pos start + 1 while pos < len data char data[pos]if char u'\\' if pos + 1 < len data value + data[ pos + 1 ]pos + 2else raise ParsingError u'Unexpectedendofdatawhileescaping {0} '.format _format_position data pos elif char u"'" or char u'"' and char qc return pos + 1 value else value + charpos + 1raise ParsingError u'Unexpectedendofunquotedstring startedat{0} !'.format _format_position data start
def zfill x width if type x type '' s xelse s repr x n len s if n > width return ssign ''if s[0] in '-' '+' sign s s[0] s[1 ] return sign + '0' * width - n + s
def fix_column_name val if val is not None try val str val except UnicodeEncodeError if six.PY2 raise ValueError u'ColumnnamesmustnotcontainUnicodecharactersonPython2' raisereturn val
def _unquote_filename filename return urllib.unquote filename
def prod a axis None dtype None out None keepdims False return a.prod axis dtype out keepdims
def random_discrete_dp num_states num_actions beta None k None scale 1 sparse False sa_pair False random_state None if sparse sa_pair TrueL num_states * num_actions random_state check_random_state random_state R scale * random_state.randn L Q _random_stochastic_matrix L num_states k k sparse sparse format 'csr' random_state random_state if beta is None beta random_state.random_sample if sa_pair s_indices a_indices sa_indices num_states num_actions else s_indices a_indices None None R.shape num_states num_actions Q.shape num_states num_actions num_states ddp DiscreteDP R Q beta s_indices a_indices return ddp
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def is_fp_closed obj try return obj.isclosed except AttributeError passtry return obj.closedexcept AttributeError passtry return obj.fp is None except AttributeError passraise ValueError 'Unabletodeterminewhetherfpisclosed.'
def set_console_screen_buffer_size x y fd 1 coord COORD coord.X xcoord.Y yhcon STDHANDLES[fd]rtn SetConsoleScreenBufferSize hcon coord return rtn
def get_parser description 'Runtoxenvironment s inallsub-packages.'parser argparse.ArgumentParser description description parser.add_argument '--tox-env' dest 'tox_env' help 'Thetoxenvironment s toruninsub-packages.' packages_help 'Optionallistofsub-packagestobetested.'parser.add_argument 'packages' nargs '*' default UNSET_SENTINEL help packages_help return parser
def addXIntersectionIndexesFromLoopY loop solidIndex xIntersectionIndexList y for pointIndex in xrange len loop pointFirst loop[pointIndex]pointSecond loop[ pointIndex + 1 % len loop ]xIntersection getXIntersectionIfExists pointFirst pointSecond y if xIntersection ! None xIntersectionIndexList.append XIntersectionIndex solidIndex xIntersection
def get_agent_settings ret dict sorted_types sorted _SERVICE_TYPES.items key lambda x - x[1] x[0] ret['services'] list ret['contact'] __salt__['reg.read_value'] _HKEY _AGENT_KEY 'sysContact' ['vdata']ret['location'] __salt__['reg.read_value'] _HKEY _AGENT_KEY 'sysLocation' ['vdata']current_bitmask __salt__['reg.read_value'] _HKEY _AGENT_KEY 'sysServices' ['vdata']if current_bitmask 0 ret['services'].append sorted_types[ -1 ][0] else for service bitmask in sorted_types if current_bitmask > 0 remaining_bitmask current_bitmask - bitmask if remaining_bitmask > 0 current_bitmask remaining_bitmaskret['services'].append service else breakret['services'] sorted ret['services'] return ret
def get_zookeeper zk_location_ips zookeeper_locations get_zk_locations_string zk_location_ips zookeeper zk.ZKTransaction host zookeeper_locations start_gc False return zookeeper
def wasLastResponseDBMSError threadData getCurrentThreadData return threadData.lastErrorPage and threadData.lastErrorPage[0] threadData.lastRequestUID
def get_service_type f return getattr f 'service_type' None
def test_config _ip.magic 'config'
def TXT host nameserver None dig ['dig' '+short' str host 'TXT']if nameserver is not None dig.append '@{0}'.format nameserver cmd __salt__['cmd.run_all'] dig python_shell False if cmd['retcode'] ! 0 log.warning "digreturnedexitcode'{0}'.Returningemptylistasfallback.".format cmd['retcode'] return []return [i for i in cmd['stdout'].split '\n' ]
def _build_localename localetuple language encoding localetupleif language is None language 'C'if encoding is None return languageelse return language + '.' + encoding
def GetSchema component parent componentwhile not isinstance parent XMLSchema parent parent._parent return parent
def has_url url return _cache.has_url url
def is_pointer ltyp return isinstance ltyp ir.PointerType
def make_yaml_patterns kw any 'keyword' [' |>|-|\\||\\[|\\]|[A-Za-z][\\w\\s\\-\\_]+ ? '] links any 'normal' ['# [^\\n]*'] comment any 'comment' ['#[^\\n]*'] number any 'number' ['\\b[+-]?[0-9]+[lL]?\\b' '\\b[+-]?0[xX][0-9A-Fa-f]+[lL]?\\b' '\\b[+-]?[0-9]+ ? \\.[0-9]+ ? ? [eE][+-]?[0-9]+ ?\\b'] sqstring " \\b[rRuU] ?'[^'\\\\\\n]* \\\\.[^'\\\\\\n]* *'?"dqstring ' \\b[rRuU] ?"[^"\\\\\\n]* \\\\.[^"\\\\\\n]* *"?'string any 'string' [sqstring dqstring] return '|'.join [kw string number links comment any 'SYNC' ['\\n'] ]
def get_comment_format commentstring vim.eval '&commentstring' if commentstring.endswith '%s' c commentstring[ -2 ]return c c c '' comments _parse_comments vim.eval '&comments' for c in comments if c[0] 'SINGLE_CHAR' return c[1 ]return comments[0][1 ]
def is_swapping loader_lock.acquire swapping swap_event.in_process loader_lock.release return swapping
def initialize_rnn_state state if isinstance state tf.nn.rnn_cell.LSTMStateTuple c state.c.eval h state.h.eval return c h else new_state state.eval return new_state
def run_node node updatehash taskid result dict result None traceback None taskid taskid try result[u'result'] node.run updatehash updatehash except etype eval etr sys.exc_info result[u'traceback'] format_exception etype eval etr result[u'result'] node.resultreturn result
def get_file_name type test platform None return '_'.join get_platform_string platform type.__module__ get_class_name type test + '.log'
def colors pass
def WithEvents disp user_event_class disp Dispatch disp if not disp.__class__.__dict__.get 'CLSID' try ti disp._oleobj_.GetTypeInfo disp_clsid ti.GetTypeAttr [0] tlb index ti.GetContainingTypeLib tla tlb.GetLibAttr gencache.EnsureModule tla[0] tla[1] tla[3] tla[4] bValidateFile 0 disp_class gencache.GetClassForProgID str disp_clsid except pythoncom.com_error raise TypeError 'ThisCOMobjectcannotautomatethemakepyprocess-pleaserunmakepymanuallyforthisobject' else disp_class disp.__class__clsid disp_class.CLSIDimport newevents_class getevents clsid if events_class is None raise ValueError 'ThisCOMobjectdoesnotsupportevents.' result_class new.classobj 'COMEventClass' events_class user_event_class {} instance result_class disp if hasattr user_event_class '__init__' user_event_class.__init__ instance return instance
def idz_reconid B idx proj B np.asfortranarray B if proj.size > 0 return _id.idz_reconid B idx proj else return B[ np.argsort idx ]
def sort seq gaps [x for x in range len seq // 2 0 -1 ]for gap in gaps for i in range gap len seq temp seq[i]j iwhile j > gap and seq[ j - gap ] > temp seq[j] seq[ j - gap ]j - gapseq[j] tempreturn seq
def _pipe_line_with_colons colwidths colaligns segments [_pipe_segment_with_colons a w for a w in zip colaligns colwidths ]return u'|' + u'|'.join segments + u'|'
def prepare_mock_wb_response node None provider 'github' files None folder True path '/' method httpretty.GET status_code 200 node nodefiles files or [] wb_url waterbutler_api_url_for node._id provider provider path path meta True default_file {u'contentType' None u'extra' {u'downloads' 0 u'version' 1} u'kind' u'file' u'modified' None u'name' u'NewFile' u'path' u'/NewFile' u'provider' provider u'size' None u'materialized' '/'}if len files data [dict default_file **each for each in files]else data [default_file]jsonapi_data []for datum in data jsonapi_data.append {'attributes' datum} if not folder jsonapi_data jsonapi_data[0]body json.dumps {u'data' jsonapi_data} httpretty.register_uri method wb_url body body status status_code content_type 'application/json'
@_docstring 'series' def search_series query '' limit None offset None strict False **fields return _do_mb_search 'series' query fields limit offset strict
def get_group_id *args **kargs raise _stub_error
def _condition_arg value if isinstance value float six.integer_types complex return valueif isinstance value np.ndarray and value.dtype.kind in [u'i' u'f' u'c'] return valuetry avalue np.array value assert avalue.dtype.kind in [u'i' u'f' u'c'] return avalueexcept ValueError AssertionError raise ValueError u'Valuenotscalarcompatibleorconvertibletoanint float orcomplexarray'
def _torf args sawT sawF Falsefor a in args if a is True if sawF returnsawT Trueelif a is False if sawT returnsawF Trueelse returnreturn sawT
def fix_IE_for_vary request response useragent request.META.get 'HTTP_USER_AGENT' '' .upper if 'MSIE' not in useragent and 'CHROMEFRAME' not in useragent return responsesafe_mime_types 'text/html' 'text/plain' 'text/sgml' if response['Content-Type'].split ';' [0] not in safe_mime_types try del response['Vary']except KeyError passreturn response
def remove_cookie_by_name cookiejar name domain None path None clearables []for cookie in cookiejar if cookie.name name if domain is None or domain cookie.domain if path is None or path cookie.path clearables.append cookie.domain cookie.path cookie.name for domain path name in clearables cookiejar.clear domain path name
def get_all_config try path os.path.expanduser '~' + os.sep + '.rainbow_config.json' data load_config path data.pop 'ONLY_LIST' None data.pop 'IGNORE_LIST' None data.pop 'FORMAT' None data.pop 'QUOTE_FORMAT' None data.pop 'NOTIFY_FORMAT' None return dataexcept return []
def libvlc_media_player_is_seekable p_mi f _Cfunctions.get 'libvlc_media_player_is_seekable' None or _Cfunction 'libvlc_media_player_is_seekable' 1 None ctypes.c_int MediaPlayer return f p_mi
def startViewer filename if filename try os.startfile filename except os.system 'open"%s"' % filename
def html_tree_equal received expected for attr in 'tag' 'attrib' 'text' 'tail' if getattr received attr ! getattr expected attr return Falseif len received ! len expected return Falseif any not html_tree_equal rec exp for rec exp in zip received expected return Falsereturn True
def signature fn import inspectif six.PY2 argspec inspect.getargspec fn args argspec.argsif len args > 0 args tuple args[1 ] if args[0] u'self' else args return args argspec.keywords signature inspect.signature fn args []keywords Nonefor arg in signature.parameters.values if arg.kind arg.VAR_KEYWORD keywords arg.nameelif arg.kind arg.VAR_POSITIONAL continueelse args.append arg.name return tuple args keywords
def get_grid grid_url raw False fid parse_grid_id_args None grid_url response v2.grids.content fid parsed_content response.json if raw return parsed_contentreturn Grid parsed_content fid
def all_weighers if CONF.least_cost_functions is not None or CONF.compute_fill_first_cost_fn_weight is not None LOG.deprecated _ 'least_costhasbeendeprecatedinfavoroftheRAMWeigher.' return least_cost.get_least_cost_weighers return HostWeightHandler .get_all_classes
def get_xsrf_token entity _AhAdminXsrfToken_.get_by_key_name _AhAdminXsrfToken_.XSRF_KEY_NAME if not entity randints [ '%08x' % random.randrange - 2 ** 31 2 ** 31 - 1 & 2 ** 32 - 1 for i in range 6 ]xsrf_token '_'.join randints entity _AhAdminXsrfToken_ key_name _AhAdminXsrfToken_.XSRF_KEY_NAME xsrf_token xsrf_token entity.put return entity.xsrf_token
def get_trim_footnote_ref_space settings if settings.trim_footnote_reference_space is None return hasattr settings 'footnote_references' and settings.footnote_references 'superscript' else return settings.trim_footnote_reference_space
def _quote_filename filename return urllib.quote filename
def get_preferred_output_encoding if hasattr locale u'LC_MESSAGES' return locale.getlocale locale.LC_MESSAGES [1] or locale.getdefaultlocale [1] or u'ascii' return locale.getdefaultlocale [1] or u'ascii'
@handle_response_format@treeio_login_required@module_admin_required def settings_edit request response_format 'html' if request.POST if 'cancel' not in request.POST form SettingsForm request.user.profile request.POST request.FILES if form.is_valid form.save return HttpResponseRedirect reverse 'core_settings_view' else return HttpResponseRedirect reverse 'core_settings_view' else form SettingsForm request.user.profile return render_to_response 'core/administration/settings_edit' {'form' form} context_instance RequestContext request response_format response_format
def ISNULL x return x None
def test_sigmoid_calibration exF np.array [5 -4 1.0] exY np.array [1 -1 -1 ] AB_lin_libsvm np.array [ -0.20261354391187855 0.6523631498001051] assert_array_almost_equal AB_lin_libsvm _sigmoid_calibration exF exY 3 lin_prob 1.0 / 1.0 + np.exp AB_lin_libsvm[0] * exF + AB_lin_libsvm[1] sk_prob _SigmoidCalibration .fit exF exY .predict exF assert_array_almost_equal lin_prob sk_prob 6 assert_raises ValueError _SigmoidCalibration .fit np.vstack exF exF exY
def post_begin for fn in post_configure fn options file_config global util fixtures engines exclusions assertions warnings profiling config testingfrom sqlalchemy import testingfrom sqlalchemy.testing import fixtures engines exclusions assertions warnings profiling configfrom sqlalchemy import util
def _get_version_from_git pre_version git_dir _get_git_directory if git_dir if pre_version try return _run_shell_command 'git--git-dir ' + git_dir + 'describe--exact-match' throw_on_error True .replace '-' '.' except Exception sha _run_shell_command 'git--git-dir ' + git_dir + 'log-n1--pretty format %h' return '%s.a%s.g%s' % pre_version _get_revno git_dir sha else return _run_shell_command 'git--git-dir ' + git_dir + 'describe--always' .replace '-' '.' return None
def binary_crossentropy y_true y_pred y_true tf.cast y_true tf.float32 y_pred logit tf.cast y_pred tf.float32 return tf.reduce_mean tf.nn.sigmoid_cross_entropy_with_logits y_pred y_true
def deserialize_usage_key usage_key_string course_key return UsageKey.from_string usage_key_string .replace course_key course_key
def users attrs None where None return _osquery_cmd table 'users' attrs attrs where where
def OR domains return combine OR_OPERATOR FALSE_DOMAIN TRUE_DOMAIN domains
def get_test_module_names module_list module_prefix 'test_' module_names [m for m in module_list if m.startswith module_prefix ]return module_names
def reduce_along_dim img dim weights indicies other_dim abs dim - 1 if other_dim 0 weights np.tile weights[np.newaxis np.newaxis] img.shape[other_dim] 1 1 3 out_img img[ indicies ] * weights out_img np.sum out_img axis 2 else weights np.tile weights[ np.newaxis np.newaxis] 1 1 img.shape[other_dim] 3 out_img img[indicies ] * weights out_img np.sum out_img axis 1 return out_img
def _event_on_first_init manager cls instrumenting_mapper manager.info.get _INSTRUMENTOR if instrumenting_mapper if Mapper._new_mappers configure_mappers
def isList l return hasattr l '__iter__' and not isString l or type l in types.ListType types.TupleType
def can_init if not sys.stdout.isatty return Falseif sys.flags.interactive return Falsemods sys.modules.keys for repl in ['IPython' 'bpython' 'dreampielib'] if repl in mods return Falsetry raise BaseExceptionexcept BaseException frame sys.exc_info [2].tb_framewhile frame if frame.f_code.co_filename '<stdin>' return Falseframe frame.f_backreturn True
def least_squares_fit x y beta correlation x y * standard_deviation y / standard_deviation x alpha mean y - beta * mean x return alpha beta
def roots_sh_chebyu n mu False x w m roots_chebyu n True x x + 1 / 2 m_us cephes.beta 1.5 1.5 w * m_us / m if mu return x w m_us else return x w
def introspect rebulk context None return Introspection rebulk context
def knapsack weights values W optimal_vals [0] * W + 1 for j in range 0 len weights for w in range W weights[j] - 1 -1 if optimal_vals[ w - weights[j] ] + values[j] > optimal_vals[w] optimal_vals[w] optimal_vals[ w - weights[j] ] + values[j] return optimal_vals[ -1 ]
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def _dtype_to_stata_type dtype if dtype.type np.string_ return chr dtype.itemsize elif dtype.type np.object_ return chr 244 elif dtype np.float64 return chr 255 elif dtype np.float32 return chr 254 elif dtype np.int64 return chr 253 elif dtype np.int32 return chr 252 elif dtype np.int8 or dtype np.int16 return chr 251 else raise ValueError 'Datatype%snotcurrentlyunderstood.Pleasereportanerrortothedevelopers.' % dtype
def parse_identifier source start throw True start pass_white source start end startif not end < len source if throw raise SyntaxError 'Missingidentifier!' return Noneif source[end] not in IDENTIFIER_START if throw raise SyntaxError 'Invalididentifierstart "%s"' % source[end] return Noneend + 1while end < len source and source[end] in IDENTIFIER_PART end + 1if not is_valid_lval source[start end] if throw raise SyntaxError 'Invalididentifiername "%s"' % source[start end] return Nonereturn source[start end] end
def shape_i var i fgraph None if fgraph is None and hasattr var 'fgraph' fgraph var.fgraphif fgraph and hasattr fgraph 'shape_feature' shape_feature fgraph.shape_featureshape_of shape_feature.shape_ofdef recur node if not node.outputs[0] in shape_of for inp in node.inputs if inp.owner recur inp.owner shape_feature.on_import fgraph node 'gof.ops.shape_i' if var not in shape_of recur var.owner return shape_of[var][i]return var.shape[i]
def get_preferred_environment_encoding return locale.getpreferredencoding or u'utf-8'
def _add_message_to_email_buffer author_id exploration_id thread_id message_id message_length old_status new_status thread feedback_models.FeedbackThreadModel.get_by_exp_and_thread_id exploration_id thread_id has_suggestion thread.has_suggestionfeedback_message_reference feedback_domain.FeedbackMessageReference exploration_id thread_id message_id batch_recipient_ids other_recipient_ids _get_all_recipient_ids exploration_id thread_id author_id if old_status ! new_status _send_feedback_thread_status_change_emails other_recipient_ids feedback_message_reference old_status new_status exploration_id has_suggestion if message_length > 0 _send_batch_emails batch_recipient_ids feedback_message_reference exploration_id has_suggestion _send_instant_emails other_recipient_ids feedback_message_reference exploration_id has_suggestion
def status_peers consul_url ret {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retfunction 'status/peers'ret _query consul_url consul_url function function return ret
def generateSimpleSequences nCoinc 10 seqLength [5 6 7] nSeq 100 coincList range nCoinc seqList []for i in xrange nSeq if max seqLength < nCoinc seqList.append random.sample coincList random.choice seqLength else len random.choice seqLength seq []for x in xrange len seq.append random.choice coincList seqList.append seq return seqList
def img_as_bool image force_copy False return convert image np.bool_ force_copy
def create_serial_port_spec client_factory if not CONF.vmware.serial_port_service_uri returnbacking client_factory.create 'ns0 VirtualSerialPortURIBackingInfo' backing.direction 'server'backing.serviceURI CONF.vmware.serial_port_service_uribacking.proxyURI CONF.vmware.serial_port_proxy_uriconnectable_spec client_factory.create 'ns0 VirtualDeviceConnectInfo' connectable_spec.startConnected Trueconnectable_spec.allowGuestControl Trueconnectable_spec.connected Trueserial_port client_factory.create 'ns0 VirtualSerialPort' serial_port.connectable connectable_specserial_port.backing backingserial_port.key -2 serial_port.yieldOnPoll Truedev_spec client_factory.create 'ns0 VirtualDeviceConfigSpec' dev_spec.operation 'add'dev_spec.device serial_portreturn dev_spec
def calculate_group_scores messages user_email now datetime.datetime.now message_ids_to_scores {}molecules_dict defaultdict set def get_message_list_weight message_ids return sum [message_ids_to_scores[m_id] for m_id in message_ids] for msg in messages participants _get_participants msg [user_email] if len participants > MIN_GROUP_SIZE molecules_dict[tuple participants ].add msg.id message_ids_to_scores[msg.id] _get_message_weight now msg.date if len molecules_dict > SOCIAL_MOLECULE_LIMIT return {}if len molecules_dict < SOCIAL_MOLECULE_EXPANSION_LIMIT _expand_molecule_pool molecules_dict molecules_list [ set emails set msgs for emails msgs in molecules_dict.iteritems if get_message_list_weight msgs > MIN_MESSAGE_COUNT ]molecules_list _subsume_molecules molecules_list get_message_list_weight molecules_list _combine_similar_molecules molecules_list return {' '.join sorted g get_message_list_weight m for g m in molecules_list}
def allow_add_attachment_by user if user.is_superuser or user.is_staff return Trueif user.has_perm 'attachments.add_attachment' return Trueif user.has_perm 'attachments.disallow_add_attachment' return Falsereturn True
def list_repos basedir None basedirs _normalize_basedir basedir repos {}log.debug 'Searchingforreposin%s' basedirs for bdir in basedirs if not os.path.exists bdir continuefor repofile in os.listdir bdir repopath '{0}/{1}'.format bdir repofile if not repofile.endswith '.repo' continuefilerepos _parse_repo_file repopath [1]for reponame in filerepos.keys repo filerepos[reponame]repo['file'] repopathrepos[reponame] reporeturn repos
def load_all_client_tests options local_namespace locals .copy global_namespace globals .copy all_tests []broken_tests []for test_base_dir in ['tests' 'site_tests'] testdir os.path.join os.environ['AUTODIR'] test_base_dir for test_name in os.listdir testdir client_test init_test options os.path.join testdir test_name if client_test all_tests.append client_test else broken_tests.append test_name if 'CUSTOM_DIR' in os.environ testdir os.environ['CUSTOM_DIR']for test_name in os.listdir testdir client_test init_test options os.path.join testdir test_name if client_test all_tests.append client_test else broken_tests.append test_name return all_tests broken_tests
def py_default type_name return {'double' '123.0' 'long' '123' 'integer' '123' 'string' "'string'" 'blob' "b'bytes'" 'boolean' 'True|False' 'list' '[...]' 'map' '{...}' 'structure' '{...}' 'timestamp' 'datetime 2015 1 1 '}.get type_name '...'
def HTTPS port 443 **kwargs return rule port **kwargs
def _validate_event_listeners option listeners if not isinstance listeners Sequence raise TypeError '%smustbealistortuple' % option for listener in listeners if not isinstance listener _EventListener raise TypeError 'Listenersfor%smustbeeitheraCommandListener ServerHeartbeatListener ServerListener orTopologyListener.' % option return listeners
def addXIntersectionsFromLoopForTable loop xIntersectionsTable width for pointIndex in xrange len loop pointBegin loop[pointIndex]pointEnd loop[ pointIndex + 1 % len loop ]if pointBegin.imag > pointEnd.imag pointOriginal pointBeginpointBegin pointEndpointEnd pointOriginalfillBegin int math.ceil pointBegin.imag / width fillEnd int math.ceil pointEnd.imag / width if fillEnd > fillBegin secondMinusFirstComplex pointEnd - pointBegin secondMinusFirstImaginaryOverReal secondMinusFirstComplex.real / secondMinusFirstComplex.imag beginRealMinusImaginary pointBegin.real - pointBegin.imag * secondMinusFirstImaginaryOverReal for fillLine in xrange fillBegin fillEnd y fillLine * width xIntersection y * secondMinusFirstImaginaryOverReal + beginRealMinusImaginary addElementToListTable xIntersection fillLine xIntersectionsTable
def decode_dbkey dbkey if ' ' in dbkey return dbkey.split ' ' else return None dbkey
def resolve_given_outfile_path path if path is None returnoutfile os.path.expanduser os.path.expandvars path if not os.access os.path.dirname os.path.abspath outfile os.W_OK raise ValueError 'Unabletowritetofile %s' % outfile return outfile
def sendmail smtphost from_addr to_addrs msg senderDomainName None port 25 if not hasattr msg 'read' msg StringIO str msg d defer.Deferred factory SMTPSenderFactory from_addr to_addrs msg d if senderDomainName is not None factory.domain senderDomainNamereactor.connectTCP smtphost port factory return d
def get_known_settings return _KNOWN_SETTINGS.values
def update_repository repo ctx_rev None commands.update get_configured_ui repo rev ctx_rev
def _latest_common_snapshot some others others_set set others for snapshot in reversed some if snapshot in others_set return snapshotreturn None
def scatter tensor devices chunk_sizes None dim 0 if chunk_sizes is None chunks tensor.chunk len devices dim else assert sum chunk_sizes tensor.size dim "givenchunksizesdon'tsumuptothetensor'ssize sum chunk_sizes {} butexpected{} ".format sum chunk_sizes tensor.size dim assert min chunk_sizes > 0 'gotanegativechunk_size'chunks [tensor.narrow dim start - size size for start size in zip _accumulate chunk_sizes chunk_sizes ]return tuple chunk.cuda gpu_id async chunk.is_contiguous for gpu_id chunk in zip devices chunks
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def qos_specs_disassociate context qos_specs_id type_id return IMPL.qos_specs_disassociate context qos_specs_id type_id
def get_config_var name return get_config_vars .get name
def _estimate_gaussian_covariances_tied resp X nk means reg_covar avg_X2 np.dot X.T X avg_means2 np.dot nk * means.T means covariance avg_X2 - avg_means2 covariance / nk.sum covariance.flat[ len covariance + 1 ] + reg_covarreturn covariance
def _preflight_check desired fromrepo **kwargs if 'pkg.check_db' not in __salt__ return {}ret {'suggest' {} 'no_suggest' []}pkginfo __salt__['pkg.check_db'] fromrepo fromrepo *list desired.keys **kwargs for pkgname in pkginfo if pkginfo[pkgname]['found'] is False if pkginfo[pkgname]['suggestions'] ret['suggest'][pkgname] pkginfo[pkgname]['suggestions']else ret['no_suggest'].append pkgname return ret
def readPin pinNumber global PORTreturn PORT.readPin pinNumber
def mappings_prepend_dev mappings for m in mappings virtual m['virtual']if is_swap_or_ephemeral virtual and not m['device'].startswith '/' m['device'] '/dev/' + m['device'] return mappings
def jvp v z n 1 if not isinstance n int or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n 0 return jv v z else return _bessel_diff_formula v z n jv -1
def submit_tags **kwargs query mbxml.make_tag_request **kwargs return _do_mb_post 'tag' query
def list_availability_zones call None ret {}params {'Action' 'DescribeZones' 'RegionId' get_location }items query params for zone in items['Zones']['Zone'] ret[zone['ZoneId']] {}for item in zone ret[zone['ZoneId']][item] str zone[item] return ret
def get_paragraphs amount start_with_lorem False paragraphs _GENERATOR.generate_paragraphs amount start_with_lorem return [p[ -1 ] for p in paragraphs]
def vb_machinestate_to_description machinestate return vb_machinestate_to_tuple machinestate [1]
@bdd.then bdd.parsers.parse 'thejavascriptmessage"{message}"shouldnotbelogged' def javascript_message_not_logged quteproc message quteproc.ensure_not_logged category 'js' function 'javaScriptConsoleMessage' message '[*]{}'.format message
def testDict suffix 'Test'trim len suffix fdict dict [ fname[ - trim ] f for fname f in inspect.getmembers modules[__name__] inspect.isfunction if fname.endswith suffix ] return fdict
def getMaximumByComplexPath path maximum complex -9.876543219876543e+17 -9.876543219876543e+17 for point in path maximum getMaximum maximum point return maximum
def update_module conn module remote_module conn.modules[module.__name__]local_file inspect.getsourcefile module remote_file inspect.getsourcefile remote_module upload_file conn local_filem remote_file reload remote_module
def _accumulate iterable fn lambda x y x + y it iter iterable try total next it except StopIteration return yield total for element in it total fn total element yield total
def _filter_names names names [n for n in names if n not in EXCLUDE_NAMES ]for pattern in EXCLUDE_PATTERNS names [n for n in names if not fnmatch.fnmatch n pattern and not n.endswith '.py' ]return names
def forget func *xs return Forget func *xs
def get_shell_embed_func shells None known_shells None if shells is None shells DEFAULT_PYTHON_SHELLS.keys if known_shells is None known_shells DEFAULT_PYTHON_SHELLS.copy for shell in shells if shell in known_shells try return known_shells[shell] except ImportError continue
def read_user_choice var_name options if not isinstance options list raise TypeErrorif not options raise ValueErrorchoice_map OrderedDict u'{}'.format i value for i value in enumerate options 1 choices choice_map.keys default u'1'choice_lines [u'{}-{}'.format *c for c in choice_map.items ]prompt u'\n'.join u'Select{} '.format var_name u'\n'.join choice_lines u'Choosefrom{}'.format u' '.join choices user_choice click.prompt prompt type click.Choice choices default default return choice_map[user_choice]
def with_metaclass meta *bases class metaclass meta __call__ type.__call____init__ type.__init__def __new__ cls name this_bases d if this_bases is None return type.__new__ cls name d return meta name bases d return metaclass 'DummyMetaClass' None {}
def url_test url location None status_code requests.codes.moved_permanently req_headers None req_kwargs None resp_headers None query None follow_redirects False final_status_code requests.codes.ok test_data {'url' url 'location' location 'status_code' status_code 'req_headers' req_headers 'req_kwargs' req_kwargs 'resp_headers' resp_headers 'query' query 'follow_redirects' follow_redirects 'final_status_code' final_status_code}expanded_urls list braceexpand url num_urls len expanded_urls if num_urls 1 return test_datatry location_pattern location.patterntest_data['location'] location_patternexcept AttributeError location_pattern Nonenew_urls []if location expanded_locations list braceexpand test_data['location'] num_locations len expanded_locations for i url in enumerate expanded_urls data test_data.copy data['url'] urlif location and num_urls num_locations if location_pattern is not None data['location'] re.compile expanded_locations[i] else data['location'] expanded_locations[i]new_urls.append data return new_urls
def dstack xs return Dstack *xs
def camelcase_to_spaces content camelcase_boundry ' ?< [a-z] [A-Z] | [A-Z] ?![A-Z]|$ 'content re.sub camelcase_boundry '\\1' content .strip return ''.join content.split '_' .title
def synchronize_iterables iterables out_list []iterable_items [ field iter fvals for field fvals in sorted iterables.items ]while True cur_dict {}for field iter_values in iterable_items try cur_dict[field] next iter_values except StopIteration passif cur_dict out_list.append cur_dict else breakreturn out_list
def _enabled_used_error ret ret['result'] Falseret['comment'] 'Service{0}usesnon-existentoption"enabled".' + 'Perhaps"enable"optionwasintended?' .format ret['name'] return ret
def first predicate it return next v for v in evaluate_promises it if predicate v if predicate is not None else v is not None None
def weekend_to_monday dt if dt.weekday 6 return dt + timedelta 1 elif dt.weekday 5 return dt + timedelta 2 return dt
def GenerateOutput target_list target_dicts data params if params['options'].generator_output raise NotImplementedError '--generator_outputnotimplementedforeclipse' user_config params.get 'generator_flags' {} .get 'config' None if user_config GenerateOutputForConfig target_list target_dicts data params user_config else config_names target_dicts[target_list[0]]['configurations'].keys for config_name in config_names GenerateOutputForConfig target_list target_dicts data params config_name
def vb_stop_vm name None timeout 10000 **kwargs vbox vb_get_box machine vbox.findMachine name log.info 'Stoppingmachine%s' name session _virtualboxManager.openMachineSession machine try console session.consoleprogress console.powerDown progress.waitForCompletion timeout finally _virtualboxManager.closeMachineSession session vb_wait_for_session_state session log.info 'Stoppedmachine%sisnow%s' name vb_machinestate_to_str machine.state return vb_xpcom_to_attribute_dict machine 'IMachine'
def do_migration dry False n_migrated 0for user in get_targets n_migrated + 1logger.info 'Clearingunclaimedrecordsfor{0!r}'.format user if not dry user.unclaimed_records {}user.save logger.info 'Migrated{0}records.'.format n_migrated return n_migrated
def tokenize_attribute iterable attribute sattr attribute.strip mattr r_attribute.match sattr if mattr atrv mattr.group 1 if r_comattrval.match atrv name type tokenize_single_comma atrv next_item next iterable elif r_wcomattrval.match atrv name type tokenize_single_wcomma atrv next_item next iterable else raise ValueError 'multilinenotsupportedyet' else raise ValueError 'Firstlineunparsable %s' % sattr if type 'relational' raise ValueError 'relationalattributesnotsupportedyet' return name type next_item
def spline_filter Iin lmbda 5.0 intype Iin.dtype.charhcol array [1.0 4.0 1.0] 'f' / 6.0 if intype in ['F' 'D'] Iin Iin.astype 'F' ckr cspline2d Iin.real lmbda cki cspline2d Iin.imag lmbda outr sepfir2d ckr hcol hcol outi sepfir2d cki hcol hcol out outr + 1j * outi .astype intype elif intype in ['f' 'd'] ckr cspline2d Iin lmbda out sepfir2d ckr hcol hcol out out.astype intype else raise TypeError 'InvaliddatatypeforIin' return out
def _make_args cmd opts os_opts separator u'-' flags None cmd_args None args [u'']flags flags or [] for k v in opts.items args.append u'--' + k.replace u'_' u'-' if v is not None args.append v for k v in os_opts.items args.append u'--os' + separator + k.replace u'_' separator if v is not None args.append v for flag in flags args.append u'--%s' % flag if cmd args.append cmd if cmd_args args.extend cmd_args return args
def get_active_history queue None items None if items is None items []if queue is None queue PostProcessor.do.get_queue for nzo in queue history build_history_info nzo item {} item['completed'] item['name'] item['nzb_name'] item['category'] item['pp'] item['script'] item['report'] item['url'] item['status'] item['nzo_id'] item['storage'] item['path'] item['script_log'] item['script_line'] item['download_time'] item['postproc_time'] item['stage_log'] item['downloaded'] item['completeness'] item['fail_message'] item['url_info'] item['bytes'] dummy dummy historyitem['action_line'] nzo.action_lineitem unpack_history_info item item['loaded'] nzo.pp_activeif item['bytes'] item['size'] format_bytes item['bytes'] else item['size'] ''for kw in item if isinstance item[kw] str item[kw] item[kw].decode 'utf-8' items.append item return items
def get_module_files src_directory blacklist files []for directory dirnames filenames in os.walk src_directory _handle_blacklist blacklist dirnames filenames if not '__init__.py' in filenames dirnames[ ] continuefor filename in filenames if _is_python_file filename src os.path.join directory filename files.append src return files
def test_pdbbreakpoint_op b tensor.fmatrix condition tensor.gt b.sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano.function [b] output mode mode_with_gpu topo f.maker.fgraph.toposort assert isinstance topo[ -2 ].op cuda.GpuElemwise assert topo[ -1 ].op cuda.host_from_gpu
@deprecated Version 'Twisted' 15 3 0 replacement 'twisted.web.template' def PRE text return '<pre>' + escape text + '</pre>'
def parse_date date_string assume_utc False as_utc True default None from dateutil.parser import parseif not date_string return UNDEFINED_DATEif default is None func datetime.utcnow if assume_utc else datetime.now default func .replace day 15 hour 0 minute 0 second 0 microsecond 0 tzinfo _utc_tz if assume_utc else _local_tz if iso_pat .match date_string is not None dt parse date_string default default else dt parse date_string default default dayfirst parse_date_day_first if dt.tzinfo is None dt dt.replace tzinfo _utc_tz if assume_utc else _local_tz return dt.astimezone _utc_tz if as_utc else _local_tz
def wsgiapp2 wrapped if wrapped is None raise ValueError 'wrappedcannotbeNone' def decorator context request return call_app_with_subpath_as_path_info request wrapped if getattr wrapped '__name__' None return wraps wrapped decorator return wraps wrapped '__module__' '__doc__' decorator
def _psed text before after limit flags atext textif limit limit re.compile limit comps text.split limit atext ''.join comps[1 ] count 1if 'g' in flags count 0flags flags.replace 'g' '' aflags 0for flag in flags aflags | RE_FLAG_TABLE[flag]before re.compile before flags aflags text re.sub before after atext count count return text
def bin_to_nibbles s return [hti[c] for c in encode_hex s ]
def _take_time iter secs album out []total_time 0.0for obj in iter length _length obj album if total_time + length < secs out.append obj total_time + lengthreturn out
def s3_datatable_truncate string maxlength 40 string s3_unicode string if string and len string > maxlength _class 'dt-truncate'return TAG[''] DIV SPAN _class 'ui-iconui-icon-zoomin' _style 'float right' string[ maxlength - 3 ] + '...' _class _class DIV SPAN _class 'ui-iconui-icon-zoomout' _style 'float right' string _style 'display none' _class _class else return string if string else ''
@datastore_rpc._positional 1 def NonTransactional _func None allow_existing True if _func is not None return NonTransactional _func def outer_wrapper func def inner_wrapper *args **kwds if not IsInTransaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError 'Functioncannotbecalledfromwithinatransaction.' txn_connection _PopConnection try return func *args **kwds finally _PushConnection txn_connection return inner_wrapperreturn outer_wrapper
def avail_projects call None if call 'action' raise SaltCloudException 'Theavail_projectsfunctionmustbecalledwith-for--function.' vm_ get_configured_provider manager packet.Manager auth_token vm_['token'] ret {}for project in manager.list_projects ret[project.name] project.__dict__return ret
def _fill_defaults context builder sig args defaults ty sig.return_typellty context.get_data_type ty args tuple args + tuple ir.Constant llty d for d in defaults[len args ] sig signature * ty * len args + 1 return sig args
def run_background_process cmd out_log None err_log None cwd None kwargs {'shell' True 'cwd' cwd}if out_log out_log_file open out_log 'w' kwargs['stdout'] out_log_fileif err_log err_log_file open err_log 'w' kwargs['stderr'] err_log_fileproc subprocess.Popen cmd **kwargs def exit_handler "\nSendSIGINTtotheprocess'schildren.Thisisimportant\nforrunningcommandsundercoverage ascoveragewillnot\nproducethecorrectartifactsifthechildprocessisn't\nkilledproperly.\n"p1_group psutil.Process proc.pid child_pids p1_group.get_children recursive True for child_pid in child_pids os.kill child_pid.pid signal.SIGINT proc.wait atexit.register exit_handler
def getMemoryLimit return None
def test_download_should_download_wheel_deps script data wheel_filename 'colander-0.9.9-py2.py3-none-any.whl'dep_filename 'translationstring-1.1.tar.gz'wheel_path os.path.join data.find_links wheel_filename result script.pip 'install' wheel_path '-d' '.' '--find-links' data.find_links '--no-index' expect_stderr True assert Path 'scratch' / wheel_filename in result.files_created assert Path 'scratch' / dep_filename in result.files_created
def spawnd path args pidfile None daemonize no_close True pidfile pidfile _os.execv path args
def YouCompleteMeInstance custom_options {} def Decorator test @functools.wraps test def Wrapper *args **kwargs ycm YouCompleteMe _MakeUserOptions custom_options _WaitUntilReady try test ycm *args **kwargs finally StopServer ycm return Wrapperreturn Decorator
def _maybe_slice grouped columns if isinstance grouped pd.core.groupby.DataFrameGroupBy if columns is not None if isinstance columns tuple list set pd.Index columns list columns return grouped[columns]return grouped
def make_indentation indent_size part u'' return indent_size * part
def get_public_projects user return Node.find_for_user user .filter is_public True is_deleted False .get_roots
def uncache_zipdir path from zipimport import _zip_directory_cache as zdc_uncache path zdc _uncache path sys.path_importer_cache
def _envpaths env_root env_name u'' shelldict {} sep shelldict[u'sep']return binpath_from_arg sep.join [env_root env_name] shelldict shelldict
def get_best_unit unit_a unit_b a DATETIME_UNITS[unit_a]b DATETIME_UNITS[unit_b]if a 14 return unit_bif b 14 return unit_aif b > a return unit_breturn unit_a
def _fsync_files filenames touched_directories set mode os.O_RDONLYif hasattr os 'O_BINARY' mode | os.O_BINARYfor filename in filenames fd os.open filename mode os.fsync fd os.close fd touched_directories.add os.path.dirname filename if hasattr os 'O_DIRECTORY' for dirname in touched_directories fd os.open dirname os.O_RDONLY | os.O_DIRECTORY os.fsync fd os.close fd
def compile_client if hasattr sys u'getwindowsversion' raise NotImplementedError else from distutils.ccompiler import new_compilercompiler new_compiler .compilercflags os.environ.get u'CFLAGS' str u'-O3' subprocess.check_call compiler + shlex.split cflags + [u'client/powerline.c' u'-o' u'scripts/powerline']
def cmd_get_spider_stats args opts stats jsonrpc_call opts 'stats' 'get_stats' args[0] for name value in stats.items print '%-40s%s' % name value
def redirectTo URL request if isinstance URL unicode raise TypeError 'UnicodeobjectnotallowedasURL' request.setHeader 'Content-Type' 'text/html;charset utf-8' request.redirect URL content '\n<html>\n<head>\n<metahttp-equiv "refresh"content "0;URL % url s">\n</head>\n<bodybgcolor "#FFFFFF"text "#000000">\n<ahref "% url s">clickhere</a>\n</body>\n</html>\n' % {'url' nativeString URL } if _PY3 content content.encode 'utf8' return content
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def query query_type 'list_nodes' client _get_client info client.query query_type return info
def parse_authorization_header value if not value returnvalue wsgi_to_bytes value try auth_type auth_info value.split None 1 auth_type auth_type.lower except ValueError returnif auth_type 'basic' try username password base64.b64decode auth_info .split ' ' 1 except Exception returnreturn Authorization 'basic' {'username' bytes_to_wsgi username 'password' bytes_to_wsgi password } elif auth_type 'digest' auth_map parse_dict_header auth_info for key in 'username' 'realm' 'nonce' 'uri' 'response' if key not in auth_map returnif 'qop' in auth_map if not auth_map.get 'nc' or not auth_map.get 'cnonce' returnreturn Authorization 'digest' auth_map
def logsumexp x axis None return LogSumExp axis x
def _fast_hmac key msg digest dig1 dig2 digest digest if len key > dig1.block_size key digest key .digest key + chr 0 * dig1.block_size - len key dig1.update key.translate _trans_36 dig1.update msg dig2.update key.translate _trans_5c dig2.update dig1.digest return dig2
def calcResponse HA1 HA2 algo pszNonce pszNonceCount pszCNonce pszQop m algorithms[algo] m.update HA1 m.update ' ' m.update pszNonce m.update ' ' if pszNonceCount and pszCNonce m.update pszNonceCount m.update ' ' m.update pszCNonce m.update ' ' m.update pszQop m.update ' ' m.update HA2 respHash hexlify m.digest return respHash
def get_processor_decline_html params payment_support_email configuration_helpers.get_value 'payment_support_email' settings.PAYMENT_SUPPORT_EMAIL msg _ 'Sorry!Ourpaymentprocessordidnotacceptyourpayment.Thedecisiontheyreturnedwas{decision_text} andthereasonwas{reason_text}.Youwerenotcharged.Pleasetryadifferentformofpayment.Contactuswithpayment-relatedquestionsat{email}.' formatted msg.format decision_text '<spanclass "decision">{}</span>'.format params['decision'] reason_text '<spanclass "reason">{code} {msg}</span>'.format code params['reasonCode'] msg REASONCODE_MAP[params['reasonCode']] email payment_support_email return '<pclass "error_msg">{}</p>'.format formatted
@register.inclusion_tag u'admin/includes/app_list.html' takes_context True def app_list context context[u'dashboard_app_list'] admin_app_list context[u'request'] return context
def recv_until sock suffix message sock.recv 4096 if not message raise EOFError 'socketclosed' while not message.endswith suffix data sock.recv 4096 if not data raise IOError 'received{!r}thensocketclosed'.format message message + datareturn message
def unicodise string encoding None errors 'replace' if not encoding encoding S3.Config.Config .encodingif type string unicode return stringdebug 'Unicodising%rusing%s' % string encoding try return unicode string encoding errors except UnicodeDecodeError raise UnicodeDecodeError 'Conversiontounicodefailed %r' % string
def filter_fasta input_seqs_f output_seqs_f seqs_to_keep negate False seqid_f None if seqid_f is None seqs_to_keep_lookup {}.fromkeys [seq_id.split [0] for seq_id in seqs_to_keep] if not negate def keep_seq seq_id return seq_id.split [0] in seqs_to_keep_lookup else def keep_seq seq_id return seq_id.split [0] not in seqs_to_keep_lookup elif not negate keep_seq seqid_felse keep_seq lambda x not seqid_f x for seq_id seq in parse_fasta input_seqs_f if keep_seq seq_id output_seqs_f.write '>%s\n%s\n' % seq_id seq output_seqs_f.close
def eat_descriptor descr array_dim 0while descr[0] '[' array_dim + 1descr descr[1 ]if descr[0] 'L' try end descr.find ';' except raise ParserError 'Notavaliddescriptorstring ' + descr type descr[1 end]descr descr[end ]else global code_to_type_nametry type code_to_type_name[descr[0]]except KeyError raise ParserError 'Notavaliddescriptorstring %s' % descr return type.replace '/' '.' + array_dim * '[]' descr[1 ]
def json2list jsonstr if jsonstr '' value_list []else if jsonstr[0] '[' value_list json2py jsonstr else value_list jsonstr.split ' ' if not isinstance value_list list value_list [value_list]return value_list
def dft n scale None if scale not in [None 'sqrtn' 'n'] raise ValueError "scalemustbeNone 'sqrtn' or'n';%risnotvalid." % scale omegas np.exp -2j * np.pi * np.arange n / n .reshape -1 1 m omegas ** np.arange n if scale 'sqrtn' m / math.sqrt n elif scale 'n' m / nreturn m
def consume n iterator if n is None collections.deque iterator maxlen 0 else next islice iterator n n None
def format_seconds total_seconds prefix '-' if total_seconds < 0 else '' hours rem divmod abs round total_seconds 3600 minutes seconds divmod rem 60 chunks []if hours chunks.append str hours min_format '{ 02}'else min_format '{}'chunks.append min_format.format minutes chunks.append '{ 02}'.format seconds return prefix + ' '.join chunks
def check_delete_headers request if 'x-delete-after' in request.headers try x_delete_after int request.headers['x-delete-after'] except ValueError raise HTTPBadRequest request request content_type 'text/plain' body 'Non-integerX-Delete-After' actual_del_time time.time + x_delete_after if actual_del_time < time.time raise HTTPBadRequest request request content_type 'text/plain' body 'X-Delete-Afterinpast' request.headers['x-delete-at'] utils.normalize_delete_at_timestamp actual_del_time if 'x-delete-at' in request.headers try x_delete_at int utils.normalize_delete_at_timestamp int request.headers['x-delete-at'] except ValueError raise HTTPBadRequest request request content_type 'text/plain' body 'Non-integerX-Delete-At' if x_delete_at < time.time raise HTTPBadRequest request request content_type 'text/plain' body 'X-Delete-Atinpast' return request
@with_setup prepare_stdout def test_output_with_failed_colorless_with_table runner Runner feature_name 'failed_table' verbosity 3 no_color True runner.run assert_stdout_lines_with_traceback u'\nFeature TableFail#tests/functional/output_features/failed_table/failed_table.feature 1\n\nScenario Seeitfail#tests/functional/output_features/failed_table/failed_table.feature 2\nGivenIhaveadumbstepthatpasses\u2665#tests/functional/output_features/failed_table/failed_table_steps.py 20\nAndthisonefails#tests/functional/output_features/failed_table/failed_table_steps.py 24\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line% call_line d in__call__\nret self.function self.step *args **kw \nFile"% step_file s" line25 intof\nassertFalse\nAssertionError\nThenthisonewillbeskipped#tests/functional/output_features/failed_table/failed_table_steps.py 28\nAndthisonewillbeskipped#tests/functional/output_features/failed_table/failed_table_steps.py 28\nAndthisonedoesnotevenhasdefinition#tests/functional/output_features/failed_table/failed_table.feature 12 undefined \n\n1feature 0passed \n1scenario 0passed \n5steps 1failed 2skipped 1undefined 1passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u\'Andthisonedoesnotevenhasdefinition\' \ndefand_this_one_does_not_even_has_definition step \nassertFalse \'Thisstepmustbeimplemented\'\n\nListoffailedscenarios \nScenario Seeitfail#tests/functional/output_features/failed_table/failed_table.feature 2\n\n' % {'lettuce_core_file' lettuce_path 'core.py' 'step_file' abspath lettuce_path '..' 'tests' 'functional' 'output_features' 'failed_table' 'failed_table_steps.py' 'call_line' call_line}
def test_resample x rng.normal 0 1 10 10 10 x_rs resample x 1 2 10 assert_equal x.shape 10 10 10 assert_equal x_rs.shape 10 10 5 x_2 x.swapaxes 0 1 x_2_rs resample x_2 1 2 10 assert_array_equal x_2_rs.swapaxes 0 1 x_rs x_3 x.swapaxes 0 2 x_3_rs resample x_3 1 2 10 0 assert_array_equal x_3_rs.swapaxes 0 2 x_rs assert_array_equal resample [0 0] 2 1 [0.0 0.0 0.0 0.0]
def get_major_minor_version version None version get_complete_version version return _get_version_string version[ 2]
def course_outline_initial_state locator_to_show course_structure def find_xblock_info xblock_info locator '\nFindsthexblockinfoforthespecifiedlocator.\n'if xblock_info['id'] locator return xblock_infochildren xblock_info['child_info']['children'] if xblock_info.get 'child_info' None else None if children for child_xblock_info in children result find_xblock_info child_xblock_info locator if result return resultreturn Nonedef collect_all_locators locators xblock_info '\nCollectallthelocatorsforanxblockanditschildren.\n'locators.append xblock_info['id'] children xblock_info['child_info']['children'] if xblock_info.get 'child_info' None else None if children for child_xblock_info in children collect_all_locators locators child_xblock_info selected_xblock_info find_xblock_info course_structure locator_to_show if not selected_xblock_info return Noneexpanded_locators []collect_all_locators expanded_locators selected_xblock_info return {'locator_to_show' locator_to_show 'expanded_locators' expanded_locators}
def test_fill Chart chart Chart fill True chart.add '_' [1 2 3] chart.add '?' [10 21 5] assert chart.render_pyquery
def _get_instructor_task_status task_id instructor_task get_updated_instructor_task task_id status get_status_from_instructor_task instructor_task if instructor_task is not None and instructor_task.task_state in STATES_WITH_STATUS succeeded message get_task_completion_info instructor_task status['message'] messagestatus['succeeded'] succeededreturn status
def _nearest_real_complex_idx fro to which assert which in 'real' 'complex' order np.argsort np.abs fro - to mask np.isreal fro[order] if which 'complex' mask ~ mask return order[np.where mask [0][0]]
def approx_equal a b epsilon EPSILON return abs a - b < epsilon
def instantiateShootErrback d defer.Deferred try 1 / 0 except d.errback d.addErrback lambda x None
def force_delete func path exc_info os.chmod path stat.S_IWRITE func path
@require_context@pick_context_manager_writerdef instance_remove_security_group context instance_uuid security_group_id model_query context models.SecurityGroupInstanceAssociation .filter_by instance_uuid instance_uuid .filter_by security_group_id security_group_id .soft_delete
def aggregate_metadata_delete context aggregate_id key IMPL.aggregate_metadata_delete context aggregate_id key
def start_time_service return __salt__['service.start'] 'w32time'
def _convert_to_float_if_possible s try ret float s except ValueError TypeError ret sreturn ret
def parse_mul_tree root mul_info is_mul root if mul_info is None neg_info is_neg root if neg_info is None return [False root]else neg sub_tree parse_mul_tree neg_info return [ not neg sub_tree]else return [False list map parse_mul_tree mul_info ]
def _authn_context_decl decl authn_auth None return factory saml.AuthnContext authn_context_decl decl authenticating_authority factory saml.AuthenticatingAuthority text authn_auth
def select_supported_python installed_pythons for python in installed_pythons if python[ -3 ] in SUPPORTED_PYTHON_VERS return python
def unpack_files key_list for key in key_list underscore key.find '_' if underscore < 0 filename key if underscore < 0 else key[1 ] else filename '{basename}.{ext}'.format basename key[ underscore + 1 ] ext key[ underscore] clear_metadata_to_file key filename
def vm_attach_nic name kwargs None call None if call ! 'action' raise SaltCloudSystemExit 'Thevm_attach_nicactionmustbecalledwith-aor--action.' if kwargs is None kwargs {}path kwargs.get 'path' None data kwargs.get 'data' None if data if path log.warning "Boththe'data'and'path'argumentswereprovided.'data'willtakeprecedence." elif path data salt.utils.fopen path mode 'r' .read else raise SaltCloudSystemExit "Thevm_attach_nicfunctionrequireseither'data'orafile'path'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] vm_id int get_vm_id kwargs {'name' name} response server.one.vm.attachnic auth vm_id data ret {'action' 'vm.attachnic' 'nic_attached' response[0] 'vm_id' response[1] 'error_code' response[2]}return ret
def _instantiate proxy bindings None if bindings is None bindings {}if isinstance proxy Proxy return _instantiate_proxy_tuple proxy bindings elif isinstance proxy dict return dict _instantiate k bindings _instantiate v bindings for k v in six.iteritems proxy elif isinstance proxy list return [_instantiate v bindings for v in proxy]elif isinstance proxy six.string_types return preprocess proxy else return proxy
def search_by lookup tgt_type 'compound' minion_id None expr_funcs dict inspect.getmembers sys.modules[__name__] predicate inspect.isfunction matches []for key target_list in lookup.items for target in target_list params target minion_id if minion_id else target if expr_funcs[tgt_type] *params matches.append key return matches or None
def test_hook_proxy testdir testdir.makepyfile **{'root/demo-0/test_foo1.py' 'deftest1 pass' 'root/demo-a/test_foo2.py' 'deftest1 pass' 'root/demo-a/conftest.py' '\ndefpytest_ignore_collect path config \nreturnTrue\n' 'root/demo-b/test_foo3.py' 'deftest1 pass' 'root/demo-c/test_foo4.py' 'deftest1 pass'} result testdir.runpytest result.stdout.fnmatch_lines ['*test_foo1.py*' '*test_foo3.py*' '*test_foo4.py*' '*3passed*']
def get_grouped_data form_data res {}for elem_data in form_data values res.setdefault elem_data['name'] [] if elem_data['type'] INPUT_TYPE_SELECT values.extend elem_data['values'] else values.append elem_data['value'] return res
def get_english_article word return 'a' + 'n' if word[0].lower in 'aeiou' else ''
def _get_user_via_basic_auth auth_header try creds binascii.a2b_base64 auth_header[len 'Basic' ] .split ' ' 1 except binascii.Error raise Response 400 'Malformed"Authorization"header' if len creds ! 2 raise Response 401 userid api_key credsif len userid 36 and '-' in userid user _get_user_via_api_key userid else try userid int userid except ValueError raise Response 401 user User.from_id userid if user.ANON or not constant_time_compare user.participant.api_key api_key raise Response 401 return user
def global_context request context {'WITH_WS4REDIS' hasattr settings 'WEBSOCKET_URL' }return context
def fmin_powell func x0 args xtol 0.0001 ftol 0.0001 maxiter None maxfun None full_output 0 disp 1 retall 0 callback None direc None opts {'xtol' xtol 'ftol' ftol 'maxiter' maxiter 'maxfev' maxfun 'disp' disp 'direc' direc 'return_all' retall}res _minimize_powell func x0 args callback callback **opts if full_output retlist res['x'] res['fun'] res['direc'] res['nit'] res['nfev'] res['status'] if retall retlist + res['allvecs'] return retlistelif retall return res['x'] res['allvecs'] else return res['x']
def install_hg path hook op.join path 'hgrc' if not op.isfile hook open hook 'w+' .close c ConfigParser c.readfp open hook 'r' if not c.has_section 'hooks' c.add_section 'hooks' if not c.has_option 'hooks' 'commit' c.set 'hooks' 'commit' 'python pylama.hooks.hg_hook' if not c.has_option 'hooks' 'qrefresh' c.set 'hooks' 'qrefresh' 'python pylama.hooks.hg_hook' c.write open hook 'w+'
def require_activities_to_be_public activity_references exploration_ids collection_ids activity_services.split_by_type activity_references activity_summaries_by_type [{'type' feconf.ACTIVITY_TYPE_EXPLORATION 'ids' exploration_ids 'summaries' exp_services.get_exploration_summaries_matching_ids exploration_ids } {'type' feconf.ACTIVITY_TYPE_COLLECTION 'ids' collection_ids 'summaries' collection_services.get_collection_summaries_matching_ids collection_ids }]for activities_info in activity_summaries_by_type for index summary in enumerate activities_info['summaries'] if summary is None raise Exception 'Cannotfeaturenon-existent%swithid%s' % activities_info['type'] activities_info['ids'][index] if summary.status rights_manager.ACTIVITY_STATUS_PRIVATE raise Exception 'Cannotfeatureprivate%swithid%s' % activities_info['type'] activities_info['ids'][index]
def create_api_service persistence_service cluster_state_service endpoint context_factory clock reactor api_root Resource user ConfigurationAPIUserV1 persistence_service cluster_state_service clock api_root.putChild 'v1' user.app.resource api_root._v1_user userreturn StreamServerEndpointService endpoint TLSMemoryBIOFactory context_factory False Site api_root
def ode_Riccati_special_minus2 eq func order match x func.args[0]f func.funcr match a2 b2 c2 d2 [r[r[s]] for s in 'a2b2c2d2'.split ]C1 get_numbered_constants eq num 1 mu sqrt 4 * d2 * b2 - a2 - c2 ** 2 return Eq f x a2 - c2 - mu * tan mu / 2 * a2 * log x + C1 / 2 * b2 * x
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def setuptools version MIN_SETUPTOOLS_VERSION python_cmd 'python' if not is_setuptools_installed python_cmd python_cmd install_setuptools python_cmd python_cmd
def capfirst value return value and value[0].upper + value[1 ]
def _get_certname config verb certname config.certnameif not certname disp zope.component.getUtility interfaces.IDisplay filenames storage.renewal_conf_files config choices [storage.lineagename_for_filename name for name in filenames]if not choices raise errors.Error 'Noexistingcertificatesfound.' code index disp.menu 'Whichcertificatewouldyouliketo{0}?'.format verb choices ok_label 'Select' flag '--cert-name' force_interactive True if code ! display_util.OK or not index in range 0 len choices raise errors.Error 'Userendedinteraction.' certname choices[index]return certname
def function_key_generator namespace fn to_str compat.string_type if namespace is None namespace '%s %s' % fn.__module__ fn.__name__ else namespace '%s %s|%s' % fn.__module__ fn.__name__ namespace args inspect.getargspec fn has_self args[0] and args[0][0] in 'self' 'cls' def generate_key *args **kw if kw raise ValueError "dogpile.cache'sdefaultkeycreationfunctiondoesnotacceptkeywordarguments." if has_self args args[1 ]return namespace + '|' + ''.join map to_str args return generate_key
def construct_snap_name volume if is_snapcopy_enabled volume return 'snap-as-vol-' + six.text_type volume.name_id else return 'tmp-snap-' + six.text_type volume.name_id
def uninstall pkg user None env None cmd ['ghc-pkgunregister']cmd.append '"{0}"'.format pkg result __salt__['cmd.run_all'] ''.join cmd runas user env env if result['retcode'] ! 0 raise CommandExecutionError result['stderr'] return result
def transform_series series force_list False vals series.valuesreturn transform_array vals force_list
def getFirstWordIndexReverse firstWord lines startIndex for lineIndex in xrange len lines - 1 startIndex - 1 -1 if firstWord getFirstWord getSplitLineBeforeBracketSemicolon lines[lineIndex] return lineIndexreturn -1
def _get_brew_tap_specific_commands brew_path_prefix commands []brew_taps_path brew_path_prefix + TAP_PATH for user in _get_directory_names_only brew_taps_path taps _get_directory_names_only brew_taps_path + '/%s' % user taps tap for tap in taps if tap.startswith 'homebrew-' for tap in taps tap_cmd_path brew_taps_path + TAP_CMD_PATH % user tap if os.path.isdir tap_cmd_path commands + name.replace 'brew-' '' .replace '.rb' '' for name in os.listdir tap_cmd_path if _is_brew_tap_cmd_naming name return commands
@utils.arg 'monitor' metavar '<monitor>' help 'IDofthemonitortodelete.' @utils.service_type 'monitor' def do_delete cs args monitor _find_monitor cs args.monitor monitor.delete
def validate_utf8 utfbytes return _validate_utf8 utfbytes
def _example_number_anywhere_for_type num_type for region_code in SUPPORTED_REGIONS example_numobj example_number_for_type region_code num_type if example_numobj is not None return example_numobjfor country_calling_code in COUNTRY_CODES_FOR_NON_GEO_REGIONS metadata PhoneMetadata.metadata_for_nongeo_region country_calling_code None desc _number_desc_for_type metadata num_type if desc.example_number is not None try return parse _PLUS_SIGN + unicod country_calling_code + desc.example_number UNKNOWN_REGION except NumberParseException passreturn None
def get_signin_vcode cookie codeString url ''.join [const.PASSPORT_BASE 'cgi-bin/genimage?' codeString] headers {'Cookie' cookie.header_output 'Referer' const.REFERER}req net.urlopen url headers headers if req return req.dataelse return None
def get_all ret _get_systemd_services ret.update set _get_sysv_services return sorted ret
def _dhcp_file dev kind fileutils.ensure_tree CONF.networks_path return os.path.abspath '%s/nova-%s.%s' % CONF.networks_path dev kind
def newline logger nb_blank_lines 1 formatter logging.Formatter fmt '' handler CustomStreamHandler formatter formatter logger.addHandler handler for i in xrange nb_blank_lines logger.info '' logger.removeHandler handler
def genslices n return product range - n n + 1 range - n n + 1 range - n n + 1
def next_ip ip ip2int lambda ipstr struct.unpack '!I' socket.inet_aton ipstr [0] int2ip lambda n socket.inet_ntoa struct.pack '!I' n return int2ip ip2int ip + 1
def tox registry xml_parent data pluginelement 'jenkins.plugins.shiningpanda.builders.ToxBuilder't XML.SubElement xml_parent pluginelement XML.SubElement t 'toxIni' .text data.get 'ini' 'tox.ini' XML.SubElement t 'recreate' .text str data.get 'recreate' False .lower pattern data.get 'toxenv-pattern' if pattern XML.SubElement t 'toxenvPattern' .text pattern
def test_scenario_has_repr scenario Scenario.from_string SCENARIO1 assert_equals repr scenario '<Scenario "Addingsomestudentstomyuniversitydatabase">'
def test_from_ndarray try from numpy import arrayexcept ImportError skip 'NumPymustbeavailabletotestcreatingmatricesfromndarrays' assert Matrix array [1 2 3] Matrix [1 2 3] assert Matrix array [[1 2 3]] Matrix [[1 2 3]] assert Matrix array [[1 2 3] [4 5 6]] Matrix [[1 2 3] [4 5 6]] assert Matrix array [x y z] Matrix [x y z] raises NotImplementedError lambda Matrix array [[[1 2] [3 4]] [[5 6] [7 8]]]
def _ToGypPath path if os.sep '\\' and os.altsep '/' return path.replace '\\' '/' return path
def _add_async_tag_url question_id return reverse 'questions.add_tag_async' kwargs {'question_id' question_id}
def _get_oid data position dummy0 dummy1 dummy2 end position + 12 return ObjectId data[position end] end
def _match_emr_step_log_path path log_type step_id None m _EMR_STEP_LOG_PATH_RE.match path if not m return Noneif m.group 'log_type' ! log_type return Noneif not step_id is None or m.group 'step_id' step_id return Nonereturn dict step_id m.group 'step_id' timestamp m.group 'timestamp'
def show_backrefs objs max_depth 3 extra_ignore filter None too_many 10 highlight None filename None extra_info None refcounts False shortnames True output None _show_graph objs max_depth max_depth extra_ignore extra_ignore filter filter too_many too_many highlight highlight edge_func gc.get_referrers swap_source_target False filename filename output output extra_info extra_info refcounts refcounts shortnames shortnames cull_func is_proper_module
def check_str_arg result func cargs dbl resultptr cargs[ -1 ]._objreturn dbl ptr.value.decode
def addNegativePeg derivation negatives x y negativePegRadius derivation.pegRadiusArealized + derivation.halfPegClearance inradius complex negativePegRadius negativePegRadius copyShallow derivation.elementNode.getCopyShallow start Vector3 x y derivation.height sides evaluate.getSidesMinimumThreeBasedOnPrecision copyShallow negativePegRadius cylinder.addCylinderOutputByEndStart 0.0 inradius negatives sides start derivation.topOverBottom
def free_physmem out sh 'free-b' lines out.split '\n' for line in lines if line.startswith 'Mem' total used free shared [int x for x in line.split [1 5]]nt collections.namedtuple 'free' 'totalusedfreesharedoutput' return nt total used free shared out raise ValueError "can'tfind'Mem'in'free'output \n%s" % '\n'.join lines
def assert_ok response msg_prefix u'' return assert_code response 200 msg_prefix msg_prefix
def store_parser_result package_dirpath parser_result tag copy copy_parser_result parser_result sto_filepath path.join package_dirpath PARSER_RESULT_STORE sto shelve_open sto_filepath sto[tag] copysto.close
def _append_params oauth_params params merged list params merged.extend oauth_params merged.sort key lambda i i[0].startswith 'oauth_' return merged
def _GetConfigFromKwargs kwargs convert_rpc False config_class datastore_rpc.Configuration if not kwargs return Nonerpc kwargs.pop 'rpc' None if rpc is not None if not isinstance rpc apiproxy_stub_map.UserRPC raise datastore_errors.BadArgumentError 'rpc argumentshouldbeNoneoraUserRPCinstance' if 'config' in kwargs raise datastore_errors.BadArgumentError 'Expectedrpc orconfig argumentbutnotboth' if not convert_rpc if kwargs raise datastore_errors.BadArgumentError 'Unexpectedkeywordarguments %s' % ' '.join kwargs return rpcread_policy getattr rpc 'read_policy' None kwargs['config'] datastore_rpc.Configuration deadline rpc.deadline read_policy read_policy config _GetConnection .config return config_class **kwargs
def unpack_groups hg_unbundle10_obj yield [chunk for chunk in unpack_chunks hg_unbundle10_obj ] yield [chunk for chunk in unpack_chunks hg_unbundle10_obj ] while True length struct.unpack '>l' readexactly hg_unbundle10_obj 4 if length < 4 breakfilename readexactly hg_unbundle10_obj length - 4 .encode 'string_escape' yield filename [chunk for chunk in unpack_chunks hg_unbundle10_obj ]
def ensure_has_elts x lineno None col_offset None if not has_elts x if not isinstance x Iterable x [x]lineno x[0].lineno if lineno is None else lineno col_offset x[0].col_offset if col_offset is None else col_offset x ast.Tuple elts x ctx ast.Load lineno lineno col_offset col_offset return x
def addNegativeSphere derivation negatives x radius Vector3 derivation.radiusPlusClearance derivation.radiusPlusClearance derivation.radiusPlusClearance sphereOutput sphere.getGeometryOutput derivation.elementNode.getCopyShallow radius euclidean.translateVector3Path matrix.getVertexes sphereOutput Vector3 x 0.0 derivation.demiheight negatives.append sphereOutput
def EnsureDispatch prog_id bForDemand 1 disp win32com.client.Dispatch prog_id if not disp.__dict__.get 'CLSID' try ti disp._oleobj_.GetTypeInfo disp_clsid ti.GetTypeAttr [0] tlb index ti.GetContainingTypeLib tla tlb.GetLibAttr mod EnsureModule tla[0] tla[1] tla[3] tla[4] bForDemand bForDemand GetModuleForCLSID disp_clsid import CLSIDToClassdisp_class CLSIDToClass.GetClass str disp_clsid disp disp_class disp._oleobj_ except pythoncom.com_error raise TypeError 'ThisCOMobjectcannotautomatethemakepyprocess-pleaserunmakepymanuallyforthisobject' return disp
def verify_crl crl cert if not salt.utils.which 'openssl' raise salt.exceptions.SaltInvocationError 'opensslbinarynotfoundinpath' crltext _text_or_file crl crltext get_pem_entry crltext pem_type 'X509CRL' crltempfile tempfile.NamedTemporaryFile crltempfile.write crltext crltempfile.flush certtext _text_or_file cert certtext get_pem_entry certtext pem_type 'CERTIFICATE' certtempfile tempfile.NamedTemporaryFile certtempfile.write certtext certtempfile.flush cmd 'opensslcrl-noout-in{0}-CAfile{1}'.format crltempfile.name certtempfile.name output __salt__['cmd.run_stderr'] cmd crltempfile.close certtempfile.close if 'verifyOK' in output return Trueelse return False
def showStaticWords firstPage secondPage infoMsg 'findingstaticwordsinlongestmatchingpartofdynamicpagecontent'logger.info infoMsg firstPage getFilteredPageContent firstPage secondPage getFilteredPageContent secondPage infoMsg 'staticwords 'if firstPage and secondPage match SequenceMatcher None firstPage secondPage .find_longest_match 0 len firstPage 0 len secondPage commonText firstPage[match[0] match[0] + match[2] ]commonWords getPageWordSet commonText else commonWords Noneif commonWords commonWords list commonWords commonWords.sort lambda a b cmp a.lower b.lower for word in commonWords if len word > 2 infoMsg + "'%s' " % word infoMsg infoMsg.rstrip ' ' else infoMsg + 'None'logger.info infoMsg
def _get_flow_for_token csrf_token flow_pickle session.pop _FLOW_KEY.format csrf_token None if flow_pickle is None return Noneelse return pickle.loads flow_pickle
@hook.command 'karma' 'k' def karma text db query db.execute select [karma_table] .where karma_table.c.nick_vote text.lower .fetchone if not query return 'Thatuserhasnokarma 'else return '{}has\x02{}\x02karma!'.format text query['up_karma'] - query['down_karma']
@XFAILdef test_conditionset_equality assert solveset Eq tan x y x ConditionSet x Eq tan x y S.Complexes
def write_cron_file_verbose user path if _check_instance_uid_match user or __grains__.get 'os_family' in 'Solaris' 'AIX' return __salt__['cmd.run_all'] _get_cron_cmdstr path runas user python_shell False else return __salt__['cmd.run_all'] _get_cron_cmdstr path user python_shell False
def _find_mapreduce_yaml start checked dir startwhile dir not in checked checked.add dir for mr_yaml_name in MR_YAML_NAMES yaml_path os.path.join dir mr_yaml_name if os.path.exists yaml_path return yaml_pathdir os.path.dirname dir return None
def skip_on_not_implemented only_if None def decorator fun @functools.wraps fun def wrapper *args **kwargs try return fun *args **kwargs except NotImplementedError if only_if is not None if not only_if raisemsg '%rwasskippedbecauseitraisedNotImplementedError' % fun.__name__ raise unittest.SkipTest msg return wrapperreturn decorator
def iterSourceCode paths for path in paths if os.path.isdir path for dirpath dirnames filenames in os.walk path for filename in filenames if filename.endswith '.py' yield os.path.join dirpath filename else yield path
def get_focus_python_shell widget QApplication.focusWidget from spyder.widgets.shell import PythonShellWidgetfrom spyder.widgets.externalshell.pythonshell import ExternalPythonShellif isinstance widget PythonShellWidget return widgetelif isinstance widget ExternalPythonShell return widget.shell
def request_host request url request.get_full_url host _rfc3986.urlsplit url [1]if host is None host request.get_header 'Host' '' host cut_port_re.sub '' host 1 return host.lower
def pkcs_mgf1 mgfSeed maskLen h if not _hashFuncParams.has_key h warning 'pkcs_mgf1 invalidhash %s provided' return NonehLen _hashFuncParams[h][0]hFunc _hashFuncParams[h][1]if maskLen > 2 ** 32 * hLen warning 'pkcs_mgf1 maskLen>2**32*hLen' return NoneT ''maxCounter math.ceil float maskLen / float hLen counter 0while counter < maxCounter C pkcs_i2osp counter 4 T + hFunc mgfSeed + C counter + 1return T[ maskLen]
def validate_children config if CONF_CHILDREN not in config _LOGGER.info 'NochildrenunderUniversalMediaPlayer %s ' config[CONF_NAME] config[CONF_CHILDREN] []elif not isinstance config[CONF_CHILDREN] list _LOGGER.warning 'UniversalMediaPlayer %s childrennotlistinconfig.Theywillbeignored.' config[CONF_NAME] config[CONF_CHILDREN] []
def run_spyder app options args main MainWindow options try main.setup except BaseException if main.console is not None try main.console.shell.exit_interpreter except BaseException passraisemain.show main.post_visible_setup if main.console main.console.shell.interpreter.namespace['spy'] Spy app app window main if args for a in args main.open_external_file a if sys.platform 'darwin' QCoreApplication.setAttribute Qt.AA_DontShowIconsInMenus True if running_in_mac_app app.sig_open_external_file.connect main.open_external_file app.focusChanged.connect main.change_last_focused_widget app.exec_ return main
def wmf_unwrap wmf_data verbose 0 w WMF verbose verbose w wmf_data if not w.has_raster_image raise ValueError 'NorasterimagefoundintheWMF' return w.to_png
def _get_pep8_violations report_dir Env.REPORT_DIR / 'pep8' report_dir.rmtree ignore_errors True report_dir.makedirs_p Env.METRICS_DIR.makedirs_p sh 'pep8.|tee{report_dir}/pep8.report-a'.format report_dir report_dir count violations_list _pep8_violations '{report_dir}/pep8.report'.format report_dir report_dir return count violations_list
def extras *p return reqs 'extras' *p
def processShape archivableClass xmlElement if xmlElement None returnarchivableObject evaluate.getArchivableObjectAddToParent archivableClass xmlElement matrix.setXMLElementDictionaryToOtherElementDictionary xmlElement xmlElement.object.matrix4X4 'matrix.' xmlElement xmlElement.getXMLProcessor .processChildren xmlElement
def delitem a b del a[b]
def resize_bitmap parent _bitmap target_height image wx.ImageFromBitmap _bitmap _width _height image.GetSize if _height < target_height return wx.StaticBitmap parent -1 wx.BitmapFromImage image ratio float _width / _height image image.Scale target_height * ratio target_height wx.IMAGE_QUALITY_HIGH return wx.StaticBitmap parent -1 wx.BitmapFromImage image
def instance_destroy context instance_uuid constraint None update_cells True rv IMPL.instance_destroy context instance_uuid constraint if update_cells try cells_rpcapi.CellsAPI .instance_destroy_at_top context rv except Exception LOG.exception _ 'Failedtonotifycellsofinstancedestroy' return rv
def folds documents [] K 10 **kwargs def chunks iterable n 10 a list iterable i 0j 0for m in xrange n j i + len a[m n] yield a[i j] i jk kwargs.get 'k' K d list chunks documents max k 2 for holdout in xrange k yield list chain * d[ holdout] + d[ holdout + 1 ] d[holdout]
def gpu_mem_free global cudaif cuda is None from theano.sandbox import cudareturn cuda.mem_info [0] / 1024.0 / 1024
def setup_events conf trait_plugin_mgr return NotificationEventsConverter conf declarative.load_definitions conf [] conf.event.definitions_cfg_file trait_plugin_mgr
def _connect user None password None host None port None database 'admin' authdb None if not user user __salt__['config.option'] 'mongodb.user' if not password password __salt__['config.option'] 'mongodb.password' if not host host __salt__['config.option'] 'mongodb.host' if not port port __salt__['config.option'] 'mongodb.port' if not authdb authdb databasetry conn pymongo.MongoClient host host port port mdb pymongo.database.Database conn database if user and password mdb.authenticate user password source authdb except pymongo.errors.PyMongoError log.error 'Errorconnectingtodatabase{0}'.format database return Falsereturn conn
def sm_backend_conf_get_by_sr context sr_uuid return IMPL.sm_backend_conf_get_by_sr context sr_uuid
def parse_volume_info connection_data volume_id connection_data['volume_id']target_portal connection_data['target_portal']target_host _get_target_host target_portal target_port _get_target_port target_portal target_iqn connection_data['target_iqn']LOG.debug ' vol_id number host port iqn %s %s %s %s ' volume_id target_host target_port target_iqn if volume_id is None or target_host is None or target_iqn is None raise StorageError _ 'Unabletoobtaintargetinformation% connection_data s' % locals volume_info {}volume_info['id'] volume_idvolume_info['target'] target_hostvolume_info['port'] target_portvolume_info['targetIQN'] target_iqnif 'auth_method' in connection_data and connection_data['auth_method'] 'CHAP' volume_info['chapuser'] connection_data['auth_username']volume_info['chappassword'] connection_data['auth_password']return volume_info
def log_page_hit request view_func level None if level is None level logging.INFOai AccessInfo request ai.log level app_re_match _MODULE_RE.match view_func.__module__ app app_re_match and app_re_match.group 0 or '-' ai.add_to_access_history app
def normalize_text_for_edit user text rich_text escape_html True if text is None return u''if not rich_text and is_rich_text_default_for_user user text djblets_markdown.markdown_escape text if escape_html text escape text return text
def connect_database url db _connect_database url db.copy lambda _connect_database url return db
def ranksums x y x y map np.asarray x y n1 len x n2 len y alldata np.concatenate x y ranked rankdata alldata x ranked[ n1]s np.sum x axis 0 expected n1 * n1 + n2 + 1 / 2.0 z s - expected / np.sqrt n1 * n2 * n1 + n2 + 1 / 12.0 prob 2 * distributions.norm.sf abs z return RanksumsResult z prob
def assert_mode_644 mode assert mode & stat.S_IROTH and mode & stat.S_IRGRP assert mode & stat.S_IWUSR and mode & stat.S_IRUSR and not mode & stat.S_IXUSR
def user_documentation text header section examples None if examples is None examples []def deco f f.user_documentation UserDocumentation text text examples pvector examples header header section section return freturn deco
def strip_plaintext_quote text found_quote Falselines text.strip .splitlines quote_start Nonefor i line in enumerate lines if line.startswith '>' found_quote Trueif quote_start is None quote_start ielse found_quote Falseif found_quote return '\n'.join lines[ quote_start - 1 ] else return text
def superimposition_matrix v0 v1 scale False usesvd True v0 numpy.array v0 dtype numpy.float64 copy False [ 3]v1 numpy.array v1 dtype numpy.float64 copy False [ 3]return affine_matrix_from_points v0 v1 shear False scale scale usesvd usesvd
def Residuals xs ys inter slope xs np.asarray xs ys np.asarray ys res ys - inter + slope * xs return res
def jupyter_notebook script_blocks work_notebook jupyter_notebook_skeleton add_code_cell work_notebook '%matplotlibinline' fill_notebook work_notebook script_blocks return work_notebook
def get_anonymous_user User get_user_model lookup {User.USERNAME_FIELD guardian_settings.ANONYMOUS_USER_NAME}return User.objects.get **lookup
def pyherion code imports list codebase list for line in code.split '\n' if not line.startswith '#' if 'import' in line imports.append line else codebase.append line key helpers.randomKey 32 cipherEnc AES.new key encrypted EncodeAES cipherEnc '\n'.join codebase b64var helpers.randomString 5 aesvar helpers.randomString 5 imports.append 'frombase64importb64decodeas%s' % b64var imports.append 'fromCrypto.CipherimportAESas%s' % aesvar random.shuffle imports crypted ';'.join imports + '\n' crypted + 'exec %s "%s" ' % b64var base64.b64encode 'exec %s.new "%s" .decrypt %s "%s" .rstrip \'{\' \n' % aesvar key b64var encrypted return crypted
def fix_divmod mod _DivmodFixer .visit mod
def inspect_container container status base_status.copy status['id'] containertry infos _get_container_infos container _valid status id_ container out infos except Exception _invalid status id_ container out traceback.format_exc comment 'Containerdoesnotexit {0}'.format container return status
def get_mongo_client host port 27017 def create_mongo_client try client MongoClient host host port port client.areyoualive.posts.insert {'ping' 1} return clientexcept PyMongoError return Falsed loop_until reactor create_mongo_client return d
def dist_in_site_packages dist return normalize_path dist_location dist .startswith normalize_path site_packages
def assert_timestamp_equal left right compare_nat_equal True msg '' if compare_nat_equal and left is pd.NaT and right is pd.NaT returnreturn pd.util.testing.assert_equal left right msg msg
def hello5 return HTML BODY H1 T 'HelloWorld' _style 'color red;' .xml
def getAttrStr attrs from xml.sax.saxutils import quoteattrs ''for attr value in attrs.items if not isinstance value basestring value str value elif isinstance value unicode value value.encode 'utf-8' s + '%s %s' % attr quoteattr value return s
def toSegments cwd path if path.startswith '/' segs []else segs cwd[ ]for s in path.split '/' if s '.' or s '' continueelif s '..' if segs segs.pop else raise InvalidPath cwd path elif '\x00' in s or '/' in s raise InvalidPath cwd path else segs.append s return segs
def jn_zeros n nt return jnyn_zeros n nt [0]
def _rate_limit_exceeded forbidden return any error['reason'] 'rateLimitExceeded' for error in forbidden._errors
def rgb_transpose array return np.transpose array 1 0 2
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def remount module mount_bin args msg ''cmd [mount_bin]if get_platform .lower .endswith 'bsd' cmd + ['-u']else cmd + ['-o' 'remount']if get_platform .lower 'openbsd' if module.params['fstab'] is not None module.fail_json msg 'OpenBSDdoesnotsupportalternatefstabfiles.DonotspecifythefstabparameterforOpenBSDhosts' else cmd + _set_fstab_args args['fstab'] cmd + [args['name']]out err ''try if get_platform .lower .endswith 'bsd' rc 1else rc out err module.run_command cmd except rc 1if rc ! 0 msg out + err if ismount args['name'] rc msg umount module args['name'] if rc 0 rc msg mount module args return rc msg
def encipher_kid_rsa msg key n e keyreturn msg * e % n
def is_escaped url if salt.utils.is_windows return Falsescheme urlparse url .schemeif not scheme return url.startswith '|' elif scheme 'salt' path saltenv parse url return path.startswith '|' else return False
def test_op_Implicit_inheritance a NewClass AreEqual int a 1002 AreEqual long a 1002 AreEqual NewClass.op_Implicit a 1002
def can_access_all_blocks requesting_user course_key return has_access requesting_user CourseStaffRole.ROLE course_key
def register_internal_trigger_types action_sensor_enabled cfg.CONF.action_sensor.enableregistered_trigger_types_db []for _ trigger_definitions in six.iteritems INTERNAL_TRIGGER_TYPES for trigger_definition in trigger_definitions LOG.debug 'Registeringinternaltrigger %s' trigger_definition['name'] is_action_trigger trigger_definition['name'] ACTION_SENSOR_TRIGGER['name'] if is_action_trigger and not action_sensor_enabled continuetry trigger_type_db _register_internal_trigger_type trigger_definition trigger_definition except Exception LOG.exception 'Failedregisteringinternaltrigger %s.' trigger_definition raiseelse registered_trigger_types_db.append trigger_type_db return registered_trigger_types_db
def closeDumper status msg '' if hasattr conf 'dumper' and hasattr conf.dumper 'finish' conf.dumper.finish status msg
def register_special_log_handler name_or_logger callback if isinstance name_or_logger string_types name name_or_loggerelse name name_or_logger.namespecial_logger_handlers[name] callback
def assert_disabled try assert Falseexcept AssertionError return Falseelse return True
def _CopyQueryToProtocolBuffer query params params.set_query query.encode 'utf-8'
def remove_prerequisite prereq_content_key milestones milestones_api.get_milestones '{usage_key}{qualifier}'.format usage_key prereq_content_key qualifier GATING_NAMESPACE_QUALIFIER for milestone in milestones milestones_api.remove_milestone milestone.get 'id'
def validate_encoding encoding try codecs.lookup encoding return Trueexcept LookupError return False
def extract_error_messages exception if isinstance exception DeserializationException return exception.args[0]if hasattr exception 'errors' return exception.errorsif hasattr exception 'message' return exception.messageif hasattr exception '__str__' return str exception return None
def read_mm_header fh byteorder dtype count return fh.read_record MM_HEADER byteorder byteorder
def get_props_cycled col prop fx lambda x x n len col.get_paths t_prop [fx x for x in prop]sliced islice cycle t_prop None n return list sliced
def runAsEffectiveUser euid egid function *args **kwargs uid gid os.geteuid os.getegid if uid euid and gid egid return function *args **kwargs else if uid ! 0 and uid ! euid or gid ! egid os.seteuid 0 if gid ! egid os.setegid egid if euid ! 0 and euid ! uid or gid ! egid os.seteuid euid try return function *args **kwargs finally if euid ! 0 and uid ! euid or gid ! egid os.seteuid 0 if gid ! egid os.setegid gid if uid ! 0 and uid ! euid or gid ! egid os.seteuid uid
def pyramid_reduce image downscale 2 sigma None order 1 mode 'reflect' cval 0 _check_factor downscale image img_as_float image rows image.shape[0]cols image.shape[1]out_rows math.ceil rows / float downscale out_cols math.ceil cols / float downscale if sigma is None sigma 2 * downscale / 6.0 smoothed _smooth image sigma mode cval out resize smoothed out_rows out_cols order order mode mode cval cval return out
def bzr_wc_target_exists_plain_no_force test 'bzr_wc_target_exists_plain_no_force'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric.api import runfrom fabtools.files import is_dirfrom fabtools import requirerun 'mkdir%s' % wt assert not is_dir path.join wt '.bzr' try require.bazaar.working_copy REMOTE_URL wt except SystemExit passelse assert False "working_copydidn'traiseexception"assert not is_dir path.join wt '.bzr'
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def _euler red x0 x1 y0 a A sympify x0 ._to_mpmath mp.prec B sympify x1 ._to_mpmath mp.prec y_0 [sympify i ._to_mpmath mp.prec for i in y0]h B - A f_0 y_0[1 ]f_0_n 0for i in range a f_0_n + sympify DMFsubs red[i] A mpm True ._to_mpmath mp.prec * y_0[i] f_0.append f_0_n sol []for i in range a sol.append y_0[i] + h * f_0[i] return sol
def cluster_get_all context is_up None get_services False services_summary False read_deleted 'no' name_match_level None **filters return IMPL.cluster_get_all context is_up get_services services_summary read_deleted name_match_level **filters
@register Tags.urls def check_url_namespaces_unique app_configs **kwargs if not getattr settings 'ROOT_URLCONF' None return []from django.urls import get_resolverresolver get_resolver all_namespaces _load_all_namespaces resolver counter Counter all_namespaces non_unique_namespaces [n for n count in counter.items if count > 1 ]errors []for namespace in non_unique_namespaces errors.append Warning "URLnamespace'{}'isn'tunique.YoumaynotbeabletoreverseallURLsinthisnamespace".format namespace id 'urls.W005' return errors
def getLocalDictionary attributesKey elementNode xmlProcessor elementNode.getXMLProcessor if len xmlProcessor.functions < 1 return Nonereturn xmlProcessor.functions[ -1 ].localDictionary
def format_float arg return '%f' % float arg .rstrip '0' .rstrip '.'
def path_not_found req resp **kwargs raise HTTPNotFound
@pytest.mark.parametrize 'fast_writer' [True False] def test_write_quoted_empty_field fast_writer t table.Table [['Hello' ''] ['' '']] dtype ['S10' 'S10'] out StringIO ascii.write t out fast_writer fast_writer assert out.getvalue .splitlines ['col0col1' 'Hello""' '""""'] out StringIO ascii.write t out fast_writer fast_writer delimiter ' ' assert out.getvalue .splitlines ['col0 col1' 'Hello ' ' ']
def _check_for_unsupported_ica_channels picks info if picks is None returnelif len picks 0 raise ValueError 'NochannelsprovidedtoICA' types _DATA_CH_TYPES_SPLIT + ['eog'] chs list set [channel_type info j for j in picks] check all [ ch in types for ch in chs] if not check raise ValueError 'Invalidchanneltype s passedforICA.\nOnlythefollowingchannelsaresupported{0}\nFollowingtypeswerepassed{1}\n'.format types chs
def process_python_symbol_data oedata symbol_list []for key in oedata val oedata[key]if val and key ! 'found_cell_separators' if val.is_class_or_function symbol_list.append key val.def_name val.fold_level val.get_token return sorted symbol_list
def _convert_exception e args 'exceptioninldapbackend {0}'.format repr e e if six.PY2 six.reraise LDAPError args sys.exc_info [2] else six.raise_from LDAPError *args e
def unhex s bits 0for c in s c bytes c if '0' < c < '9' i ord '0' elif 'a' < c < 'f' i ord 'a' - 10 elif 'A' < c < 'F' i ord 'A' - 10 else assert False 'non-hexdigit' + repr c bits bits * 16 + ord c - i return bits
def _translate_alias_to_requests alias_spec pci_aliases _get_alias_from_config pci_requests []for name count in [spec.split ' ' for spec in alias_spec.split ' ' ] name name.strip if name not in pci_aliases raise exception.PciRequestAliasNotDefined alias name else request objects.InstancePCIRequest count int count spec copy.deepcopy pci_aliases[name] alias_name name pci_requests.append request return pci_requests
def get_configured_provider return config.is_provider_configured __opts__ __active_provider_name__ or __virtualname__ 'user' 'password' 'url'
def clearCaches gc.collect
def choice_helper random_state a replace p size if a.ndim > 1 raise ValueError 'a.ndim %i mustbe0or1' % a.ndim if p.ndim 1 if p.size 0 p Noneelse raise ValueError 'p.ndim %i mustbe1' % p.ndim replace bool replace return random_state.choice a size replace p
def remove_mo_files for root dirs files in os.walk MO_DIR topdown False for f in files if not f.startswith DOMAIN os.remove os.path.join root f
def update_profilers_in_db profilers description 'NA' add_noncompliant False for profiler in profilers name os.path.basename profiler if name.endswith '.py' name name[ -3 ]if not profilers[profiler] if add_noncompliant doc descriptionelse logging.warn 'Skipping%s missingdocstring' profiler continueelse doc profilers[profiler]model models.Profiler.objects.get_or_create name name [0]model.description doc_log_or_execute repr model model.save
def get_collection_snapshots_metadata collection_id collection get_collection_by_id collection_id current_version collection.versionversion_nums range 1 current_version + 1 return collection_models.CollectionModel.get_snapshots_metadata collection_id version_nums
def FakeSetLocale category value None original_setlocale locale.setlocale if value not in None '' 'C' 'POSIX' raise locale.Error 'localeemulationonlysupports"C"locale' return original_setlocale category 'C'
def node_info conn __get_conn raw conn.getInfo info {'cpucores' raw[6] 'cpumhz' raw[3] 'cpumodel' str raw[0] 'cpus' raw[2] 'cputhreads' raw[7] 'numanodes' raw[4] 'phymemory' raw[1] 'sockets' raw[5]}return info
def date_from_quarter base_date ordinal year interval 3month_start interval * ordinal - 1 if month_start < 0 month_start 9month_end month_start + interval if month_start 0 month_start 1return [datetime year month_start 1 datetime year month_end calendar.monthrange year month_end [1] ]
def handle_com_error err None if err is None _ err _ sys.exc_info hresult_code hresult_name additional_info parameter_in_error err.argshresult_code signed_to_unsigned hresult_code exception_string [ '%s-%s' % hex hresult_code hresult_name ]scode Noneif additional_info wcode source_of_error error_description whlp_file whlp_context scode additional_infoscode signed_to_unsigned scode exception_string.append 'Errorin %s' % source_of_error exception_string.append '%s-%s' % hex scode error_description or '' .strip for error_code klass in WMI_EXCEPTIONS.items if error_code in hresult_code scode breakelse klass x_wmiraise klass com_error err
def convert_RatingProperty model prop kwargs kwargs['validators'].append validators.NumberRange min 0 max 100 return f.IntegerField **kwargs
def decompress data results []while data decomp BZ2Decompressor try res decomp.decompress data except OSError if results breakelse raiseresults.append res if not decomp.eof raise ValueError 'Compresseddataendedbeforetheend-of-streammarkerwasreached' data decomp.unused_datareturn ''.join results
def customize_compiler_for_nvcc self self.src_extensions.append '.cu' default_compiler_so self.compiler_sosuper self._compiledef _compile obj src ext cc_args extra_postargs pp_opts if os.path.splitext src [1] '.cu' self.set_executable 'compiler_so' CUDA['nvcc'] postargs extra_postargs['nvcc']else postargs extra_postargs['gcc']super obj src ext cc_args postargs pp_opts self.compiler_so default_compiler_soself._compile _compile
def get_template_from_request request obj None no_current_page False template Noneif len get_cms_setting 'TEMPLATES' 1 return get_cms_setting 'TEMPLATES' [0][0]if hasattr request 'POST' and 'template' in request.POST template request.POST['template']elif hasattr request 'GET' and 'template' in request.GET template request.GET['template']if not template and obj is not None template obj.get_template if not template and not no_current_page and hasattr request 'current_page' current_page request.current_pageif hasattr current_page 'get_template' template current_page.get_template if template is not None and template in dict get_cms_setting 'TEMPLATES' .keys if template constants.TEMPLATE_INHERITANCE_MAGIC and obj return obj.get_template return templatereturn get_cms_setting 'TEMPLATES' [0][0]
def region_codes_for_country_code country_code regions COUNTRY_CODE_TO_REGION_CODE.get country_code None if regions is None return else return regions
def _init_once path os.getenv 'LIBCLOUD_DEBUG' if path mode 'a'from libcloud.utils.py3 import PY3if path in ['/dev/stderr' '/dev/stdout'] and PY3 mode 'w'fo codecs.open path mode encoding 'utf8' enable_debug fo if have_paramiko paramiko.common.logging.basicConfig level paramiko.common.DEBUG
def list_monitor_data kwargs None call None if call ! 'function' raise SaltCloudSystemExit 'Thelist_monitor_datamustbecalledwith-for--function.' if not isinstance kwargs dict kwargs {}ret {}params {'Action' 'GetMonitorData' 'RegionId' get_location }if 'name' in kwargs params['InstanceId'] kwargs['name']items query params params monitorData items['MonitorData']for data in monitorData['InstanceMonitorData'] ret[data['InstanceId']] {}for item in data ret[data['InstanceId']][item] str data[item] return ret
def _active_mounts_freebsd ret for line in __salt__['cmd.run_stdout'] 'mount-p' .split '\n' comps re.sub '\\s+' '' line .split ret[comps[1]] {'device' comps[0] 'fstype' comps[2] 'opts' _resolve_user_group_names comps[3].split ' ' }return ret
def _search_software target search_results {}software dict _get_reg_software .items for key value in six.iteritems software if key is not None if target.lower in key.lower search_results[key] valuereturn search_results
def get_random_id from random import randomfrom time import timetry from hashlib import sha1 as shaexcept ImportError import shasha sha.newreturn sha '%s|%s' % random time .hexdigest
def get_non_private_exploration_summaries return _get_exploration_summaries_from_models exp_models.ExpSummaryModel.get_non_private
def _check_permission_clashing custom builtin ctype pool set builtin_codenames set p[0] for p in builtin for codename _name in custom if codename in pool raise CommandError u"Thepermissioncodename'%s'isduplicatedformodel'%s.%s'." % codename ctype.app_label ctype.model_class .__name__ elif codename in builtin_codenames raise CommandError u"Thepermissioncodename'%s'clasheswithabuiltinpermissionformodel'%s.%s'." % codename ctype.app_label ctype.model_class .__name__ pool.add codename
def parse_headers environ for cgi_var value in environ.iteritems if cgi_var in _parse_headers_special yield _parse_headers_special[cgi_var] value elif cgi_var.startswith 'HTTP_' yield cgi_var[5 ].title .replace '_' '-' value
def DefaultThrottle multiplier 1.0 layout dict [ name multiplier * limit for name limit in DEFAULT_LIMITS.iteritems ] return Throttle layout layout
def rejectionline n alpha 0.5 t np.arange n / float n frej t / t * 1 - alpha + alpha return frej
def sokalmichener u v u _validate_vector u v _validate_vector v if u.dtype bool ntt u & v .sum nff ~ u & ~ v .sum else ntt u * v .sum nff 1.0 - u * 1.0 - v .sum nft ntf _nbool_correspond_ft_tf u v return float 2.0 * ntf + nft / float ntt + nff + 2.0 * ntf + nft
def _get_mysql_error return sys.modules[__salt__['test.ping'].__module__].__context__.pop 'mysql.error' None
def build_ownership_map table key_from_row value_from_row rows sa.select table.c .execute .fetchall mappings {}for row in rows mappings.setdefault key_from_row row [] .append OwnershipPeriod pd.Timestamp row.start_date unit 'ns' tz 'utc' pd.Timestamp row.end_date unit 'ns' tz 'utc' row.sid value_from_row row return merge_ownership_periods mappings
def test_ast_unicode_strings def _compile_string s hy_s HyString s hy_s.start_line hy_s.end_line 0hy_s.start_column hy_s.end_column 0code hy_compile [hy_s] u'__main__' return code.body[0].value.sassert _compile_string u'test' u'test' assert _compile_string u'\u03b1\u03b2' u'\u03b1\u03b2' assert _compile_string u'\xc3\xa9' u'\xc3\xa9'
def kaiserord ripple width A abs ripple if A < 8 raise ValueError 'Requestedmaximumrippleattentuation%fistoosmallfortheKaiserformula.' % A beta kaiser_beta A numtaps A - 7.95 / 2.285 / np.pi * width + 1 return int ceil numtaps beta
def _asFilesystemText path encoding None if type path unicode return pathelse if encoding is None encoding sys.getfilesystemencoding return path.decode encoding
def compat_str s if isinstance s str return selif isinstance s bytes return s.decode 'utf-8' else return str s
def save filename None family 'ipv4' if _conf and not filename filename _conf family log.debug 'Savingrulesto{0}'.format filename parent_dir os.path.dirname filename if not os.path.isdir parent_dir os.makedirs parent_dir cmd '{0}-save'.format _iptables_cmd family ipt __salt__['cmd.run'] cmd if len _conf_save_filters > 0 ipt _regex_iptables_save ipt out __salt__['file.write'] filename ipt return out
def constructor_copy obj cls **kw names get_cls_kwargs cls kw.update k obj.__dict__[k] for k in names if k in obj.__dict__ return cls **kw
def guard_quota_dp scheduler.restart force True
def get_request_api_cpu_usage if apiproxy return apiproxy.GetRequestApiCpuUsage return 0
def _pre_yarn_history_unescape s return _PRE_YARN_HISTORY_ESCAPE_RE.sub '\\1' s
def _handle_old_style_images staging_path file_num 0for filename in 'snap.vhd' 'image.vhd' 'base.vhd' path os.path.join staging_path filename if os.path.exists path _rename path os.path.join staging_path '%d.vhd' % file_num file_num + 1
def parse_info response info {}response nativestr response def get_value value if ' ' not in value or ' ' not in value try if '.' in value return float value else return int value except ValueError return valueelse sub_dict {}for item in value.split ' ' k v item.rsplit ' ' 1 sub_dict[k] get_value v return sub_dictfor line in response.splitlines if line and not line.startswith '#' if line.find ' ' ! -1 key value line.split ' ' 1 info[key] get_value value else info.setdefault '__raw__' [] .append line return info
def get_changes_for_svn_txn repo_path txn_id changes subproc_check_output ['svnlook' 'changed' repo_path '-t' txn_id] for line in StringIO changes yield line[0] line[4 -1 ]
def oppositeFunction basef if isinstance basef FitnessEvaluator if isinstance basef FunctionEnvironment 'addedbyJPQ'if isinstance basef MultiObjectiveFunction res MultiObjectiveFunction else res FunctionEnvironment basef.xdim basef.xopt else res FitnessEvaluator res.f lambda x - basef.f x if not basef.desiredValue is None res.desiredValue - basef.desiredValue res.toBeMinimized not basef.toBeMinimized return reselse return lambda x - basef x
def jarque_bera x x np.asarray x n float x.size if n 0 raise ValueError 'Atleastoneobservationisrequired.' mu x.mean diffx x - mu skewness 1 / n * np.sum diffx ** 3 / 1 / n * np.sum diffx ** 2 ** 3 / 2.0 kurtosis 1 / n * np.sum diffx ** 4 / 1 / n * np.sum diffx ** 2 ** 2 jb_value n / 6 * skewness ** 2 + kurtosis - 3 ** 2 / 4 p 1 - distributions.chi2.cdf jb_value 2 return jb_value p
def get_context_first_object context context_lookups return get_context_first_matching_object context context_lookups [1]
def what filename res whathdr filename return res
def confirm title text informative_text ok_text icon None default True cancel_text None cancel_icon None msgbox QtWidgets.QMessageBox active_window msgbox.setWindowModality Qt.WindowModal msgbox.setWindowTitle title msgbox.setText text msgbox.setInformativeText informative_text icon icons.mkicon icon icons.ok ok msgbox.addButton ok_text QtWidgets.QMessageBox.ActionRole ok.setIcon icon cancel msgbox.addButton QtWidgets.QMessageBox.Cancel cancel_icon icons.mkicon cancel_icon icons.close cancel.setIcon cancel_icon if cancel_text cancel.setText cancel_text if default msgbox.setDefaultButton ok else msgbox.setDefaultButton cancel msgbox.exec_ return msgbox.clickedButton ok
def test_no_nans np.random.seed 1 image 0.5 + 1e-09 * np.random.normal size 20 20 template np.ones 6 6 template[ 3 ] 0result match_template image template assert not np.any np.isnan result
def test_scenario_matches_tags_excluding_when_scenario_has_no_tags scenario Scenario.from_string SCENARIO1 original_string SCENARIO1.strip assert scenario.matches_tags ['-nope' '-neither']
def parse_tag_namespaces tag_list namespaces {}for tag in tag_list ns ' ' in tag and '%s ' % tag.rsplit ' ' 1 [0] or '' if ns not in namespaces namespaces[ns] []namespaces[ns].append tag return namespaces
def _test_dir imputil.ImportManager .install path sys.path[ ]path.reverse for d in path sys.path.insert 0 DirectoryImporter d sys.path.insert 0 imputil.BuiltinImporter
def get_markdown_extensions return _markdown_extensions
def mergePathInfo layer coord extension z coord.zoomx coord.columny coord.rowreturn '/% layer s/% z d/% x d/% y d.% extension s' % locals
def check_media_permissions media user perm_type media_type media.__class__.__name__.lower perm_name 'gallery.%s_%s' % perm_type media_type if user ! media.creator and not user.has_perm perm_name raise PermissionDenied
def _compare_inverses_approx inv_1 inv_2 evoked rtol atol check_depth True if check_depth if inv_1['depth_prior'] is not None assert_array_almost_equal inv_1['depth_prior']['data'] inv_2['depth_prior']['data'] 5 else assert_true inv_2['depth_prior'] is None if inv_1['orient_prior'] is not None assert_array_almost_equal inv_1['orient_prior']['data'] inv_2['orient_prior']['data'] else assert_true inv_2['orient_prior'] is None assert_array_almost_equal inv_1['source_cov']['data'] inv_2['source_cov']['data'] assert_array_almost_equal np.abs inv_1['eigen_fields']['data'] np.abs inv_2['eigen_fields']['data'] 0 assert_array_almost_equal np.abs inv_1['eigen_leads']['data'] np.abs inv_2['eigen_leads']['data'] 0 stc_1 apply_inverse evoked inv_1 lambda2 'dSPM' stc_2 apply_inverse evoked inv_2 lambda2 'dSPM' assert_true stc_1.subject stc_2.subject assert_equal stc_1.times stc_2.times assert_allclose stc_1.data stc_2.data rtol rtol atol atol assert_true inv_1['units'] inv_2['units']
def getTokensEndLoc import inspectfstack inspect.stack try for f in fstack[2 ] if f[3] '_parseNoCache' endloc f[0].f_locals['loc']return endlocelse raise ParseFatalException 'incorrectusageofgetTokensEndLoc-mayonlybecalledfromwithinaparseaction' finally del fstack
def run_le_auto venv_dir base_url **kwargs env environ.copy d dict XDG_DATA_HOME venv_dir LE_AUTO_JSON_URL base_url + 'certbot/json' LE_AUTO_DIR_TEMPLATE base_url + '%s/' LE_AUTO_PUBLIC_KEY '-----BEGINPUBLICKEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsMoSzLYQ7E1sdSOkwelg\ntzKIh2qi3bpXuYtcfFC0XrvWig071NwIj+dZiT0OLZ2hPispEH0B7ISuuWg1ll7G\nhFW0VdbxL6JdGzS2ShNWkX9hE9z+j8VqwDPOBn3ZHm03qwpYkBDwQib3KqOdYbTT\nuUtJmmGcuk3a9Aq/sCT6DdfmTSdP5asdQYwIcaQreDrOosaS84DTWI3IU+UYJVgl\nLsIVPBuy9IcgHidUQ96hJnoPsDCWsHwX62495QKEarauyKQrJzFes0EY95orDM47\nZ5o/NDiQB11m91yNB0MmPYY9QSbnOA9j7IaaC97AwRLuwXY+/R2ablTcxurWou68\niQIDAQAB\n-----ENDPUBLICKEY-----' **kwargs env.update d return out_and_err join venv_dir 'letsencrypt-auto' + '--version' shell True env env
def clearNode node node.childNodes[ ] []
def dnn_pool img ws stride None mode 'max' pad None img gpu_contiguous img if stride is None stride 1 * len ws if pad is None pad 0 * len ws if mode 'sum' ret GpuDnnPool mode 'average_inc_pad' img ws stride pad context_name ret.type.context_namewindow_elem theano.tensor.prod ws .astype ret.dtype return as_gpuarray_variable ret * window_elem context_name return GpuDnnPool mode mode img ws stride pad
def get_spine_visible ax spine_key spine ax.spines[spine_key]ax_frame_on ax.get_frame_on spine_frame_like spine.is_frame_like if not spine.get_visible return Falseelif not spine._edgecolor[ -1 ] return Falseelif not ax_frame_on and spine_frame_like return Falseelif ax_frame_on and spine_frame_like return Trueelif not ax_frame_on and not spine_frame_like return Trueelse return False
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def get_fontconfig_fonts fontext u'ttf' fontext get_fontext_synonyms fontext return [fname for fname in _call_fc_list if os.path.splitext fname [1][1 ] in fontext ]
def parse_ml_headers headers attrs {}attrs['List-Archive'] headers.get 'List-Archive' attrs['List-Help'] headers.get 'List-Help' attrs['List-Id'] headers.get 'List-Id' attrs['List-Owner'] headers.get 'List-Owner' attrs['List-Post'] headers.get 'List-Post' attrs['List-Subscribe'] headers.get 'List-Subscribe' attrs['List-Unsubscribe'] headers.get 'List-Unsubscribe' return attrs
def send_session_accept_reject email session_name acceptance link message_settings MessageSettings.query.filter_by action SESSION_ACCEPT_REJECT .first if not message_settings or message_settings.mail_status 1 send_email to email action SESSION_ACCEPT_REJECT subject MAILS[SESSION_ACCEPT_REJECT]['subject'].format session_name session_name acceptance acceptance html MAILS[SESSION_ACCEPT_REJECT]['message'].format email str email session_name str session_name acceptance str acceptance link link
def number_connected_components G return len list connected_components G
def register linter linter.register_checker ExceptionsChecker linter
def Table *args **kwargs kwargs['mysql_character_set'] 'utf8'return sa.Table *args **kwargs
def _regex_from_encoded_pattern s if s.startswith '/' and s.rfind '/' ! 0 idx s.rfind '/' pattern flags_str s[1 idx] s[ idx + 1 ] flag_from_char {'i' re.IGNORECASE 'l' re.LOCALE 's' re.DOTALL 'm' re.MULTILINE 'u' re.UNICODE}flags 0for char in flags_str try flags | flag_from_char[char]except KeyError raise ValueError "unsupportedregexflag '%s'in'%s' mustbeoneof'%s' " % char s ''.join list flag_from_char.keys return re.compile s[1 idx] flags else return re.compile re.escape s
def await_gc obj rc for i in range 50 if grc obj < rc + 2 returntime.sleep 0.05
def add_server protocol None service_address None server_address None packet_forward_method 'dr' weight 1 **kwargs cmd '{0}-a{1}'.format __detect_os _build_cmd protocol protocol service_address service_address server_address server_address packet_forward_method packet_forward_method weight weight **kwargs out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] ret out['stderr'].strip else ret Truereturn ret
@gen.coroutinedef ListIdentities client obj_store user_id device_id request def _MakeIdentityDict ident i_dict {'identity' ident.key}if ident.authority is not None i_dict['authority'] ident.authorityreturn i_dictquery_expr 'identity.user_id %d' % user_id identities yield gen.Task Identity.IndexQuery client query_expr ['key' 'authority'] raise gen.Return {'identities' [_MakeIdentityDict ident for ident in identities]}
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def remove_users_in_conference id user users if checking_conference id and is_owner_user id user conferences get_memcached get_key 'conferences' for val in users del conferences[id]['users'][val]set_memcached get_key 'conferences' conferences return get_new_message_for_user user
def parsecodes codes len len filter filter range range if not codes return Nonel codes.split '+' if len l 1 return int l[0] 16 for i in range len l try l[i] int l[i] 16 except ValueError l[i] Nonel filter lambda x x is not None l if len l 1 return l[0]else return tuple l
def count_from_1 index collection return index + 1
def getFunctionsWithStringByFileName fileName searchString fileText archive.getFileText fileName functions []lines archive.getTextLines fileText for line in lines lineStripped line.strip if lineStripped.startswith 'def' and searchString in lineStripped if ' self ' not in lineStripped or lineStripped.count ' ' > 1 functions.append lineStripped[len 'def' ].strip functions.sort return functions
def Command char return CaselessPreservingLiteral char
def get_a_line src number global FILE_CACHEif src not in FILE_CACHE FILE_CACHE[src] []for line in open src 'r' FILE_CACHE[src].append line try return FILE_CACHE[src][ number - 1 ]except return ''
def _count_title_words value ret 0for word in iter_words value if word.value.istitle ret + 1return ret
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def render_report cr uid ids name data context None env api.Environment cr uid context or {} return env['ir.actions.report.xml'].render_report ids name data
def getGeometryOutputByArguments arguments elementNode return getGeometryOutput None elementNode
def lookup_cname domain try answer dns.resolver.query domain 'CNAME' .rrsetttl answer.ttlresult answer.items[0].to_text result result.rstrip '.' return ttl result except DNSException NXDOMAIN NoAnswer return 0 None
def get_website_users return frappe.db.sql u"selectcount * from`tabUser`\n DCTB DCTB whereenabled 1anduser_type 'WebsiteUser'" [0][0]
def call_xxdot context builder conjugate dtype n a_data b_data out_data fnty ir.FunctionType ir.IntType 32 [ll_char ll_char intp_t ll_void_p ll_void_p ll_void_p] fn builder.module.get_or_insert_function fnty name 'numba_xxdot' kind get_blas_kind dtype kind_val ir.Constant ll_char ord kind conjugate ir.Constant ll_char int conjugate res builder.call fn kind_val conjugate n builder.bitcast a_data ll_void_p builder.bitcast b_data ll_void_p builder.bitcast out_data ll_void_p check_blas_return context builder res
def test_slicing_on_instance_with_parameterless_model p2 Polynomial2D 1 c0_0 1 c1_0 2 c0_1 3 p1 Polynomial2D 1 c0_0 1 c1_0 2 c0_1 3 mapping Mapping 0 1 0 1 offx Shift -2 name u'x_translation' offy Shift -1 name u'y_translation' aff AffineTransformation2D matrix [[1 2] [3 4]] name u'rotation' model mapping | p1 & p2 | offx & offy | aff assert model.param_names u'c0_0_1' u'c1_0_1' u'c0_1_1' u'c0_0_2' u'c1_0_2' u'c0_1_2' u'offset_3' u'offset_4' u'matrix_5' u'translation_5' assert model 1 2 23.0 53.0 m model[3 ]assert m.param_names u'offset_3' u'offset_4' u'matrix_5' u'translation_5' assert m 1 2 1.0 1.0
def assert_deb_headers test_case expected_headers package_path output check_output ['dpkg' '--info' package_path.path] actual_headers parse_colon_dict output assert_dict_contains test_case expected_headers actual_headers 'MissingdpkgHeaders '
def rebulk_builder rebulk Rebulk rebulk.rebulk path rebulk.rebulk groups rebulk.rebulk episodes rebulk.rebulk container rebulk.rebulk format_ rebulk.rebulk video_codec rebulk.rebulk audio_codec rebulk.rebulk screen_size rebulk.rebulk website rebulk.rebulk date rebulk.rebulk title rebulk.rebulk episode_title rebulk.rebulk language rebulk.rebulk country rebulk.rebulk release_group rebulk.rebulk other rebulk.rebulk edition rebulk.rebulk cds rebulk.rebulk bonus rebulk.rebulk film rebulk.rebulk part rebulk.rebulk crc rebulk.rebulk processors rebulk.rebulk mimetype rebulk.rebulk type_ def customize_properties properties '\nCustomizedefaultrebulkproperties\n'count properties['count']del properties['count']properties['season_count'] countproperties['episode_count'] countreturn propertiesrebulk.customize_properties customize_propertiesreturn rebulk
def _test_jd2jcal import randomn 1000year [random.randint -4699 2200 for i in range n ]month [random.randint 1 12 for i in range n ]day [random.randint 1 28 for i in range n ]jd [jcal2jd y m d [1] for y m d in zip year month day ]x [jd2gcal MJD_0 i for i in jd]for i in range n assert x[i][0] year[i] assert x[i][1] month[i] assert x[i][2] day[i] assert x[i][3] < 1e-15
def modifier symbol def set_modifier func modifiers[symbol] funcreturn funcreturn set_modifier
def _attribute_matcher kwargs def match node if 'terminal' in kwargs kwa_copy kwargs.copy pattern kwa_copy.pop 'terminal' if pattern is not None and not hasattr node 'is_terminal' or node.is_terminal ! pattern return Falseelse kwa_copy kwargsfor key pattern in kwa_copy.items if not hasattr node key return Falsetarget getattr node key if isinstance pattern basestring return isinstance target basestring and re.match pattern + '$' target if isinstance pattern bool return pattern bool target if isinstance pattern int return pattern target if pattern is None return target is None raise TypeError 'invalidquerytype %s' % type pattern return Truereturn match
def test_ipv4_detect assert _is_ipv4_like '1.1.1.1' is True assert _is_ipv4_like '1.1.1.256' is True assert _is_ipv4_like '-1.1.1.1' is True assert _is_ipv4_like '1.1.1.hello' is False assert _is_ipv4_like 'hello' is False assert _is_ipv4_like '-1.1.1' is False assert _is_ipv4_like '-1.1.1.' is False
def _error_execute *args **kargs cmd args[1 -3 ] if args[0] 'raidcom' else args result _execute *args **kargs ret ERROR_EXECUTE_TABLE.get cmd return ret if ret else result
def apply_palette256 image return image.convert 'RGB' .convert 'P' palette Image.ADAPTIVE colors 256 dither Image.NONE
def parse_extra_info info if not info return infofinfos info.split ';' data_for_files {}for finfo in finfos items finfo.split '{' if len items 1 fname fake_sff_nameinfo items[0]else fname items[0]info items[1]info info.replace '}' '' data {}for item in info.split ' ' key value item.strip .split ' ' key key.strip value value.strip data[key] valuedata_for_files[fname] datareturn data_for_files
def t2b t clean b rws t if len clean % 2 1 raise ValueError 'Evennumberofcharactersexpected' return a2b_hex clean
def for_type typ func oldfunc _type_pprinters.get typ None if func is not None _type_pprinters[typ] funcreturn oldfunc
def compute_corr x y if len x 0 or len y 0 raise ValueError 'xoryhaszerolength' fast_dot _get_fast_dot X np.array x float Y np.array y float X - X.mean 0 Y - Y.mean 0 x_sd X.std 0 ddof 1 y_sd Y.std 0 ddof 1 [ None if X.shape Y.shape else Ellipsis ]return fast_dot X.T Y / float len X - 1 / x_sd * y_sd
def get_text_stream name encoding None errors 'strict' opener text_streams.get name if opener is None raise TypeError 'Unknownstandardstream%r' % name return opener encoding errors
def in_qtconsole try ip get_ipython front_end ip.config.get 'KernelApp' {} .get 'parent_appname' '' or ip.config.get 'IPKernelApp' {} .get 'parent_appname' '' if 'qtconsole' in front_end.lower return Trueexcept return Falsereturn False
def load_tasks_from_module imported imported_vars vars imported if '__all__' in imported_vars imported_vars [ name imported_vars[name] for name in imported_vars if name in imported_vars['__all__'] ]else imported_vars imported_vars.items new_style classic default extract_tasks imported_vars return imported.__doc__ new_style classic default
def escapedData data inAttribute if isinstance data unicode data data.encode 'utf-8' data data.replace '&' '&amp;' .replace '<' '&lt;' .replace '>' '&gt;' if inAttribute data data.replace '"' '&quot;' return data
def _is_same_origin websocket_origin host_scheme host_port host_policy if websocket_origin 'null' return Falseif not isinstance websocket_origin tuple or not len websocket_origin 3 raise ValueError "'websocket_origin'mustbea3-tuple" origin_scheme origin_host origin_port websocket_origintemplate '{scheme} //{host} {port}'origin_header template.format scheme origin_scheme host origin_host port origin_port for origin_pattern in host_policy if origin_pattern.match origin_header return Truereturn False
def elide_filename filename length elidestr '...'if length < len elidestr raise ValueError 'lengthmustbegreaterorequalto3' if len filename < length return filenamelength - len elidestr left length // 2 right length - left if right 0 return filename[ left] + elidestr else return filename[ left] + elidestr + filename[ - right ]
def check_requirements if sys.version_info < 3 3 and sys.version_info[ 2] ! 2 7 raise SystemExit 'PyInstallerrequiresatleastPython2.7or3.3+.' if is_win try from PyInstaller.utils.win32 import winutilspywintypes winutils.import_pywin32_module 'pywintypes' except ImportError raise SystemExit 'PyInstallercannotcheckforassemblydependencies.\nPleaseinstallPyWin32.\n\npipinstallpypiwin32\n'
def create_shadow_trigger trigger_type_db trigger_type_ref trigger_type_db.get_reference .refif trigger_type_db.parameters_schema LOG.debug 'SkipshadowtriggerforTriggerTypewithparameters%s.' trigger_type_ref return Nonetrigger {'name' trigger_type_db.name 'pack' trigger_type_db.pack 'type' trigger_type_ref 'parameters' {}}return create_or_update_trigger_db trigger
def create_container reactor control_service node_uuid name image volumes None timeout DEFAULT_TIMEOUT d control_service.create_container node_uuid name image volumes def wait_until_running container def container_matches container state return container.name state.name and container.node_uuid state.node_uuid and state.running d loop_until_state_found reactor control_service.list_containers_state partial container_matches container timeout def delete_container failure d control_service.delete_container container.name d.addCallback lambda _ignore failure return dd.addErrback delete_container return dd.addCallback wait_until_running return d
def normalize_headers response_headers strict True category {}for idx in range len response_headers key val response_headers[idx]head get_header key strict if not head newhead '-'.join [x.capitalize for x in key.replace '_' '-' .split '-' ] response_headers[idx] newhead val category[newhead] 4continueresponse_headers[idx] str head val category[str head ] head.sort_orderdef key_func item value item[0]return category[value] value response_headers.sort key key_func
def get_prosite_raw id cgi 'http //www.expasy.ch/cgi-bin/get-prosite-raw.pl' return _urlopen '%s?%s' % cgi id
def run_changed drain False min_size 500 limit 1000 sleep_time 10 use_safe_get False verbose False if use_safe_get CloudSearchUploader.use_safe_get Trueamqp.handle_items 'cloudsearch_changes' _run_changed min_size min_size limit limit drain drain sleep_time sleep_time verbose verbose
def _parseClientSSLOptions kwargs hostname kwargs.pop 'hostname' None clientCertificate _privateCertFromPaths kwargs.pop 'certKey' None kwargs.pop 'privateKey' None trustRoot _parseTrustRootPath kwargs.pop 'caCertsDir' None if hostname is not None configuration optionsForClientTLS _idnaText hostname trustRoot trustRoot clientCertificate clientCertificate else if clientCertificate is not None privateKeyOpenSSL clientCertificate.privateKey.originalcertificateOpenSSL clientCertificate.originalelse privateKeyOpenSSL NonecertificateOpenSSL Noneconfiguration CertificateOptions trustRoot trustRoot privateKey privateKeyOpenSSL certificate certificateOpenSSL kwargs['sslContextFactory'] configurationreturn kwargs
def set_rate_limiting rate_limit min_wait timedelta milliseconds 50 global RATE_LIMITglobal RATE_LIMIT_MIN_WAITglobal RATE_LIMIT_LAST_CALLRATE_LIMIT rate_limitif not rate_limit RATE_LIMIT_MIN_WAIT Noneelse RATE_LIMIT_MIN_WAIT min_waitRATE_LIMIT_LAST_CALL None
def attached_clients pl minimum 1 session_output get_tmux_output pl u'list-panes' u'-F' u'#{session_name}' if not session_output return Nonesession_name session_output.rstrip .split u'\n' [0]attached_clients_output get_tmux_output pl u'list-clients' u'-t' session_name attached_count len attached_clients_output.rstrip .split u'\n' return None if attached_count < minimum else str attached_count
def all_languages languages [ lang[0] _ lang[1] for lang in settings.ALL_LANGUAGES]return sorted languages key lambda lang lang[1]
def setattr_default obj name value if not hasattr obj name setattr obj name value
def cgsnapshot_get_all_by_group context group_id filters None return IMPL.cgsnapshot_get_all_by_group context group_id filters
def test_nm1_fit_sample_auto ratio 'auto'nm1 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS X_resampled y_resampled nm1.fit_sample X Y X_gt np.array [[0.91464286 1.61369212] [ -0.80809175 -1.09917302 ] [ -0.20497017 -0.26630228 ] [ -0.05903827 0.10947647] [0.03142011 0.12323596] [ -0.60413357 0.24628718] [0.50701028 -0.17636928 ] [0.4960075 0.86130762] [0.45713638 1.31069295]] y_gt np.array [0 0 0 1 1 1 2 2 2] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def make_ref_group info name position return RefGroup info name position case_flags make_case_flags info
def get_deployment_physnet_mtu return cfg.CONF.global_physnet_mtu
def get_template_attribute template_name attribute return getattr current_app.jinja_env.get_template template_name .module attribute
def splitattr url words url.split ';' return words[0] words[1 ]
def parse_yn00 lines results sequences for line in lines line_floats_res re.findall '-*\\d+\\.\\d+' line line_floats [float val for val in line_floats_res]row_res re.match '\\s+ \\d+ \\s+ \\d+ ' line if row_res is not None seq1 int row_res.group 1 seq2 int row_res.group 2 seq_name1 sequences[ seq1 - 1 ]seq_name2 sequences[ seq2 - 1 ]YN00 {}YN00['S'] line_floats[0]YN00['N'] line_floats[1]YN00['t'] line_floats[2]YN00['kappa'] line_floats[3]YN00['omega'] line_floats[4]YN00['dN'] line_floats[5]YN00['dNSE'] line_floats[6]YN00['dS'] line_floats[7]YN00['dSSE'] line_floats[8]results[seq_name1][seq_name2]['YN00'] YN00results[seq_name2][seq_name1]['YN00'] YN00seq_name1 Noneseq_name2 Nonereturn results
def setup app app.add_role 'rfc' rfclink return
def make_ifilesystemsnapshots_tests fixture class IFilesystemSnapshotsTests AsyncTestCase '\nTestsfor class `IFilesystemSnapshots`implementors.\n\nThesearefunctionaltestsifrunagainstrealfilesystems.\n'def test_interface self '\nThetestedobjectprovides class `IFilesystemSnapshots`.\n'fs_snapshots fixture self self.assertTrue verifyObject IFilesystemSnapshots fs_snapshots def test_created self '\nSnapshotscreatedwith``create ``arelistedinthatorderin\n``list ``.\n'fs_snapshots fixture self d fs_snapshots.create 'first' d.addCallback lambda _ fs_snapshots.create 'another' d.addCallback lambda _ fs_snapshots.list d.addCallback self.assertEqual ['first' 'another'] return dreturn IFilesystemSnapshotsTests
def tencode data key encode base64.b64encode salt_length 16 salt ''for n in range salt_length salt + chr random.randrange 256 data salt + crypt data sha1 key + salt .digest if encode data encode data return data
def populate_module_and_state trans workflow param_map allow_tool_state_corrections False module_injector None if module_injector is None module_injector WorkflowModuleInjector trans allow_tool_state_corrections for step in workflow.steps step_args param_map.get step.id {} step_errors module_injector.inject step step_args step_args if step_errors raise exceptions.MessageException step_errors err_data {step.order_index step_errors} if step.upgrade_messages if allow_tool_state_corrections log.debug 'Workflowstep"%i"hadupgrademessages %s' step.id step.upgrade_messages else raise exceptions.MessageException step.upgrade_messages err_data {step.order_index step.upgrade_messages}
def jupyter_info import nbconvertreturn dict nbconvert_version nbconvert.__version__
def test_ros_fit_single_class ros RandomOverSampler random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning ros.fit X y_single_class
def test_detect_nan nan_detected [False]def detect_nan i node fn for output in fn.outputs if numpy.isnan output[0] .any print '***NaNdetected***' theano.printing.debugprint node print 'Inputs %s' % [input[0] for input in fn.inputs] print 'Outputs %s' % [output[0] for output in fn.outputs] nan_detected[0] Truebreakx theano.tensor.dscalar 'x' f theano.function [x] [ theano.tensor.log x * x ] mode theano.compile.MonitorMode post_func detect_nan f 0 assert nan_detected[0]
def _to_matrix_vectorized M assert isinstance M tuple list assert all [isinstance item tuple list for item in M] c_vec np.asarray [len item for item in M] assert np.all c_vec - c_vec[0] 0 r len M c c_vec[0]M00 np.asarray M[0][0] dt M00.dtypesh [M00.shape[0] r c]M_ret np.empty sh dtype dt for irow in range r for icol in range c M_ret[ irow icol] np.asarray M[irow][icol] return M_ret
def VerifyMissingSources sources build_dir generator_flags gyp_to_ninja if int generator_flags.get 'msvs_error_on_missing_sources' 0 no_specials filter lambda x '$' not in x sources relative [os.path.join build_dir gyp_to_ninja s for s in no_specials]missing filter lambda x not os.path.exists x relative if missing cleaned_up [os.path.normpath x for x in missing]raise Exception 'Missinginputfiles \n%s' % '\n'.join cleaned_up
def no_backend test_func backend if settings.DATABASES[DEFAULT_DB_ALIAS]['ENGINE'].rsplit '.' [ -1 ] backend return pass_testelse return test_func
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def get_matplotlib_backend_module_names import_statement '\nimportos sys\n\n#Preservestdout.\nsys_stdout sys.stdout\n\ntry \n#Redirectoutputprintedbythisimportationto"/dev/null" preventing\n#suchoutputfrombeingerroneouslyinterpretedasanerror.\nwithopen os.devnull \'w\' asdev_null \nsys.stdout dev_null\n__import__ \'%s\' \n#IfthisisanImportError printthisexception\'smessagewithoutatraceback.\n#ImportErrormessagesarehuman-readableandrequirenoadditionalcontext.\nexceptImportErrorasexc \nsys.stdout sys_stdout\nprint exc \n#Else printthisexceptionprecededbyatraceback.traceback.print_exc \n#printstostderrratherthanstdoutandmustnotbecalledhere!\nexceptException \nsys.stdout sys_stdout\nimporttraceback\nprint traceback.format_exc \n'backend_names eval_statement 'importmatplotlib;print matplotlib.rcsetup.all_backends ' module_names []if not is_darwin and 'CocoaAgg' in backend_names backend_names.remove 'CocoaAgg' for backend_name in backend_names module_name 'matplotlib.backends.backend_%s' % backend_name.lower stdout exec_statement import_statement % module_name if not stdout module_names.append module_name logger.info 'Matplotlibbackend"%s" added' % backend_name else logger.info 'Matplotlibbackend"%s" ignored\n%s' % backend_name stdout return module_names
def _WrapEndMarker tree if isinstance tree pytree.Leaf and tree.type token.ENDMARKER return pytree.Node pygram.python_symbols.file_input [tree] return tree
def p_command_print p p[0] 'PRINT' p[2] p[3]
def _get_table_item doc name return doc.xpath '//th[contains text "%s" ]/following-sibling td' % name [0]
def addListsToRepositoryByFunction fileNameHelp getProfileDirectory repository repository.displayEntities []repository.executeTitle Nonerepository.fileNameHelp fileNameHelprepository.fileNameInput Nonerepository.lowerName fileNameHelp.split '.' [ -2 ]repository.baseName repository.lowerName + '.csv' repository.baseNameSynonym Nonerepository.capitalizedName getEachWordCapitalized repository.lowerName repository.getProfileDirectory getProfileDirectoryrepository.openLocalHelpPage HelpPage .getOpenFromDocumentationSubName repository.fileNameHelp repository.openWikiManualHelpPage Nonerepository.preferences []repository.repositoryDialog Nonerepository.saveListenerTable {}repository.title repository.capitalizedName + 'Settings' repository.menuEntities []repository.saveCloseTitle 'SaveandClose'repository.windowPosition WindowPosition .getFromValue repository '0+0' for setting in repository.preferences setting.repository repository
def _str2records filename rel recs []contents nltk.data.load u'corpora/chat80/%s' % filename format u'text' for line in contents.splitlines if line.startswith rel line re.sub rel + u'\\ ' u'' line line re.sub u'\\ \\.$' u'' line record line.split u' ' recs.append record return recs
@click.command u'setup-global-help' @click.option u'--mariadb_root_password' def setup_global_help mariadb_root_password None from frappe.installer import update_site_configfrappe.local.flags frappe._dict frappe.local.flags.in_setup_help Truefrappe.local.flags.in_install Truefrappe.local.lang u'en'frappe.local.conf frappe.get_site_config sites_path u'.' update_site_config u'global_help_setup' 1 site_config_path os.path.join u'.' u'common_site_config.json' if mariadb_root_password frappe.local.conf.root_password mariadb_root_passwordfrom frappe.utils.help import syncsync
def curve_keypair _check_version 3 2 'monitor' public ffi.new 'char[64]' private ffi.new 'char[64]' rc C.zmq_curve_keypair public private _check_rc rc return ffi.buffer public [ 40] ffi.buffer private [ 40]
def isroutine object return isbuiltin object or isfunction object or ismethod object or ismethoddescriptor object
def plot_day_summary_ohlc ax quotes ticksize 3 colorup u'k' colordown u'r' return _plot_day_summary ax quotes ticksize ticksize colorup colorup colordown colordown ochl False
def _validate_pad padtype padlen x axis ntaps if padtype not in ['even' 'odd' 'constant' None] raise ValueError "Unknownvalue'%s'giventopadtype.padtypemustbe'even' 'odd' 'constant' orNone." % padtype if padtype is None padlen 0if padlen is None edge ntaps * 3 else edge padlenif x.shape[axis] < edge raise ValueError 'Thelengthoftheinputvectorxmustbeatleastpadlen whichis%d.' % edge if padtype is not None and edge > 0 if padtype 'even' ext even_ext x edge axis axis elif padtype 'odd' ext odd_ext x edge axis axis else ext const_ext x edge axis axis else ext xreturn edge ext
def strcmp_const_time s1 s2 if len s1 ! len s2 return Falseresult 0for a b in zip s1 s2 result | ord a ^ ord b return result 0
def sum_squared X X_flat X.ravel order 'F' if np.isfortran X else 'C' return np.dot X_flat X_flat
def inside resource1 resource2 while resource1 is not None if resource1 is resource2 return Trueresource1 resource1.__parent__return False
def markdown_escape_field obj field_name if isinstance obj Model setattr obj field_name djblets_markdown.markdown_escape getattr obj field_name elif isinstance obj dict obj[field_name] djblets_markdown.markdown_escape obj[field_name] else raise TypeError u'Unexpectedtype%rpassedtomarkdown_escape_field' % obj
def ode_separable_reduced eq func order match x func.args[0]f func.funcy Dummy 'y' u match['u'].subs match['t'] y ycoeff 1 / y * match['power'] - u m1 {y 1 x -1 / x 'coeff' 1}m2 {y ycoeff x 1 'coeff' 1}r {'m1' m1 'm2' m2 'y' y 'hint' x ** match['power'] * f x }return ode_separable eq func order r
def test_ast_valid_for can_compile u' for[a2] printa '
def in_system_path filename fn sdk_normalize os.path.realpath filename if fn.startswith '/usr/local/' return Falseelif fn.startswith '/System/' or fn.startswith '/usr/' if fn in NOT_SYSTEM_FILES return Falsereturn Trueelse return False
def connect_cloudhsm aws_access_key_id None aws_secret_access_key None **kwargs from boto.cloudhsm.layer1 import CloudHSMConnectionreturn CloudHSMConnection aws_access_key_id aws_access_key_id aws_secret_access_key aws_secret_access_key **kwargs
def make_stem_cleaner stem if stem[ -1 ] 's' stem stem[ -1 ]if len stem > 2 return _memoized_stem_cleaner stem return nop
def split_filter_op expression left sep right expression.partition ' ' if sep try timeutils.parse_isotime expression op 'eq'threshold expressionexcept ValueError op leftthreshold rightelse op 'eq'threshold leftreturn op threshold
def get_default_verify_paths parts _ssl.get_default_verify_paths cafile os.environ.get parts[0] parts[1] capath os.environ.get parts[2] parts[3] return DefaultVerifyPaths cafile if os.path.isfile cafile else None capath if os.path.isdir capath else None *parts
def date_in_range date_range date debug True out Truefor item in date_range.split u' ' attribute comparison_operator value CLAUSE.match item.strip .groups if attribute in u'weekday' u'isoweekday' left getattr date attribute right int value elif attribute left getattr date attribute right int value else left dateright dateutil.parser.parse value if debug print u'<{0}{1}{2}>'.format left comparison_operator right out out and OPERATORS[comparison_operator] left right return out
def p_expression_opt_1 t pass
def hardware_events attrs None where None return _osquery_cmd table 'hardware_events' attrs attrs where where
def tenant_get tenant_id None name None profile None **connection_args kstone auth profile **connection_args ret {}if name for tenant in getattr kstone _TENANTS None .list if tenant.name name tenant_id tenant.idbreakif not tenant_id return {'Error' 'Unabletoresolvetenantid'}tenant getattr kstone _TENANTS None .get tenant_id ret[tenant.name] dict value getattr tenant value for value in dir tenant if not value.startswith '_' and isinstance getattr tenant value six.text_type dict bool str return ret
def sgd loss_or_grads params learning_rate grads get_or_compute_grads loss_or_grads params updates OrderedDict for param grad in zip params grads updates[param] param - learning_rate * grad return updates
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def _footer_social_links platform_name configuration_helpers.get_value 'platform_name' settings.PLATFORM_NAME links []for social_name in settings.SOCIAL_MEDIA_FOOTER_NAMES display settings.SOCIAL_MEDIA_FOOTER_DISPLAY.get social_name {} links.append {'name' social_name 'title' unicode display.get 'title' '' 'url' settings.SOCIAL_MEDIA_FOOTER_URLS.get social_name '#' 'icon-class' display.get 'icon' '' 'action' unicode display.get 'action' '' .format platform_name platform_name } return links
@route bp '/<store_id>/products' def products store_id return _stores.get_or_404 store_id .products
@check_is_trading@export_as_api@ExecutionContext.enforce_phase EXECUTION_PHASE.HANDLE_BAR EXECUTION_PHASE.SCHEDULED def order_target_value id_or_ins cash_amount style None order_book_id assure_order_book_id id_or_ins bar_dict ExecutionContext.get_current_bar_dict price bar_dict[order_book_id].closeposition get_simu_exchange .account.portfolio.positions[order_book_id]current_value position.quantity * price return order_value order_book_id cash_amount - current_value style
def _collect_tcl_tk_files hook_api _handle_broken_tcl_tk tcl_root tk_root _find_tcl_tk hook_api if not tcl_root logger.error 'Tcl/Tkimproperlyinstalledonthissystem.' return []if not os.path.isdir tcl_root logger.error 'Tcldatadirectory"%s"notfound.' tcl_root return []if not os.path.isdir tk_root logger.error 'Tkdatadirectory"%s"notfound.' tk_root return []tcltree Tree tcl_root prefix 'tcl' excludes ['demos' '*.lib' 'tclConfig.sh'] tktree Tree tk_root prefix 'tk' excludes ['demos' '*.lib' 'tkConfig.sh'] if is_darwin _warn_if_activetcl_or_teapot_installed tcl_root tcltree return tcltree + tktree
def test_column_filter def all_positive column if np.any column < 0 return Falsereturn Truet Table.read ['acd' '-27.00' '-25.01' '00.04' '13.05' '12.0-6' '11.07' '33.05' '3-2.06' '31.07'] format 'ascii' tg t.group_by 'a' c2 tg['c'].groups.filter all_positive assert len c2.groups 3 assert c2.groups[0].pformat ['c' '---' '7.0' '5.0'] assert c2.groups[1].pformat ['c' '---' '0.0'] assert c2.groups[2].pformat ['c' '---' '3.0' '2.0' '1.0']
def _div_nearest a b q r divmod a b return q + 2 * r + q & 1 > b
def s3_currency name 'currency' **attr settings current.deployment_settingsif 'label' not in attr attr['label'] current.T 'Currency' if 'default' not in attr attr['default'] settings.get_fin_currency_default if 'requires' not in attr currency_opts settings.get_fin_currencies attr['requires'] IS_IN_SET currency_opts.keys zero None if 'writable' not in attr attr['writable'] settings.get_fin_currency_writable f S3ReusableField name length 3 **attr return f
def call_with_appropriate fn kwargs args keyword signature fn if not keyword kwargs {key kwargs[key] for key in kwargs if key in args }return fn **kwargs
def combined_tensor_printing combined global _combined_printing_combined_printing combined
def use_plugin name kind None if kind is None kind plugin_store.keys else if not kind in plugin_provides[name] raise RuntimeError 'Plugin%sdoesnotsupport`%s`.' % name kind if kind 'imshow' kind [kind '_app_show']else kind [kind]_load name for k in kind if not k in plugin_store raise RuntimeError "'%s'isnotaknownpluginfunction." % k funcs plugin_store[k]funcs [ n f for n f in funcs if n name ] + [ n f for n f in funcs if n ! name ] plugin_store[k] funcs
def bmat block_lists row_blocks [hstack *blocks for blocks in block_lists]return vstack *row_blocks
def mvn_nloglike_obs x sigma sigmainv np.linalg.inv sigma cholsigmainv np.linalg.cholesky sigmainv .Tx_whitened np.dot cholsigmainv x logdetsigma np.log np.linalg.det sigma sigma2 1.0llike 0.5 * np.log sigma2 - 2.0 * np.log np.diagonal cholsigmainv + x_whitened ** 2 / sigma2 + np.log 2 * np.pi return llike
def _check_portname name if not isinstance name string_types or '/' not in name raise SaltInvocationError "Invalidportname'{0}' categoryrequired ".format name path os.path.join '/usr/ports' name if not os.path.isdir path raise SaltInvocationError "Path'{0}'doesnotexist".format path return path
def _obfuscate_inner var if isinstance var dict salt.utils.odict.OrderedDict return var.__class__ key _obfuscate_inner val for key val in six.iteritems var elif isinstance var list set tuple return type var _obfuscate_inner v for v in var else return '<{0}>'.format var.__class__.__name__
def check_force_season_folders pattern None multi None if pattern is None pattern sickbeard.NAMING_PATTERNvalid not validate_name pattern None file_only True if multi is not None valid valid or not validate_name pattern multi file_only True return valid
def get_descriptions nzo match name if nzo ep_name nzo.nzo_info.get 'episodename' else ep_name ''if not ep_name if match ep_name name[match.end ]else ep_name nameep_name ep_name.strip '_.' if ep_name.startswith '-' ep_name ep_name.strip '-_.' if '.' in ep_name and '' not in ep_name ep_name ep_name.replace '.' '' ep_name ep_name.replace '_' '' ep_name2 ep_name.replace '-' '-' .replace '' '.' ep_name3 ep_name.replace '' '_' return ep_name ep_name2 ep_name3
def get_domain cname False subreddit True no_www False domain g.domaindomain_prefix c.domain_prefix or g.domain_prefix site c.siteif not no_www and domain_prefix domain domain_prefix + '.' + domain if hasattr request 'port' and request.port domain + ' ' + str request.port if subreddit domain + site.path.rstrip '/' return domain
def archive_deleted_rows_for_table context tablename max_rows None return IMPL.archive_deleted_rows_for_table context tablename max_rows max_rows
def rs_or_single_client h client_context.host p client_context.port **kwargs return _mongo_client h p **kwargs
def gf_expand F p K if type F is tuple lc F Felse lc K.oneg [lc]for f k in F f gf_pow f k p K g gf_mul g f p K return g
def _extract_model_data model data []for i in range 0 model.rowCount cat_idx model.index i 0 row []for j in range 0 model.rowCount cat_idx row.append model.data cat_idx.child j 0 model.data cat_idx.child j 1 model.data cat_idx.child j 2 data.append row return data
def common_prefix *seqs if any not s for s in seqs return []elif len seqs 1 return seqs[0]i 0for i in range min len s for s in seqs if not all seqs[j][i] seqs[0][i] for j in range len seqs breakelse i + 1return seqs[0][ i]
def accumulate_dict_from_superclasses cls propname cachename '__cached_all' + propname if cachename not in cls.__dict__ d dict for c in inspect.getmro cls if issubclass c HasProps and hasattr c propname base getattr c propname for k v in base.items if k not in d d[k] vsetattr cls cachename d return cls.__dict__[cachename]
def has_permission job action username None if job.is_read_only return Falseif username is None username get_username if not username return Falseif not job.username return Truereturn username job.username
def allitems attr None doc '' def getter self if attr is None return self._itemsreturn [getattr frag attr for frag in self._items]return property fget getter doc doc
def _set_user_info_cookie email admin cookie_name _COOKIE_NAME cookie_value _create_cookie_data email admin cookie Cookie.SimpleCookie cookie[cookie_name] cookie_valuecookie[cookie_name]['path'] '/'return cookie[cookie_name].OutputString
def videos_index_json course return JsonResponse {'videos' _get_index_videos course } status 200
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def test_malformed_destinations monkeypatch monkeypatch.setenv 'WALE_SYSLOG_FACILITY' 'wat' out valid_facility log_help.get_syslog_facility assert not valid_facility assert out handlers.SysLogHandler.LOG_USER monkeypatch.setenv 'WALE_SYSLOG_FACILITY' 'local0 wat' out valid_facility log_help.get_syslog_facility assert not valid_facility assert out handlers.SysLogHandler.LOG_USER monkeypatch.setenv 'WALE_SYSLOG_FACILITY' ' ' out valid_facility log_help.get_syslog_facility assert not valid_facility assert out handlers.SysLogHandler.LOG_USER
def _generate_dispatch cls if '__visit_name__' in cls.__dict__ visit_name cls.__visit_name__if isinstance visit_name str getter operator.attrgetter 'visit_%s' % visit_name def _compiler_dispatch self visitor **kw try meth getter visitor except AttributeError raise exc.UnsupportedCompilationError visitor cls else return meth self **kw else def _compiler_dispatch self visitor **kw visit_attr 'visit_%s' % self.__visit_name__ try meth getattr visitor visit_attr except AttributeError raise exc.UnsupportedCompilationError visitor cls else return meth self **kw _compiler_dispatch.__doc__ 'Lookforanattributenamed"visit_"+self.__visit_name__\nonthevisitor andcallitwiththesamekwparams.\n'cls._compiler_dispatch _compiler_dispatch
def mangle_name name mode gitmode if stat.S_ISREG mode and not stat.S_ISREG gitmode assert stat.S_ISDIR gitmode return name + '.bup' elif name.endswith '.bup' or name[ -1 ].endswith '.bup' return name + '.bupl' else return name
def rs_fun p f *args _R p.ring R1 _x ring '_x' _R.domain h int args[ -1 ] args1 args[ -2 ] + _x h zm _R.zero_monomif zm in p x1 _x + p[zm] p1 p - p[zm] else x1 _xp1 pif isinstance f str q getattr x1 f *args1 else q f x1 *args1 a sorted q.items c [0] * h for x in a c[x[0][0]] x[1]p1 rs_series_from_list p1 c args[ -2 ] args[ -1 ] return p1
def idle_showwarning message category filename lineno file None line None if file is None file warning_streamtry file.write idle_formatwarning message category filename lineno line line file.write '>>>' except AttributeError IOError pass
def get_value val_name default None **kwargs if is_site_configuration_enabled configuration_value get_configuration_value val_name default default else configuration_value microsite.get_value val_name default default **kwargs try value dict default value.update configuration_value except TypeError ValueError AttributeError value configuration_valuereturn value
def _init_helptopic_completion log.completion.debug 'Initializinghelptopiccompletion.' model miscmodels.HelpCompletionModel _instances[usertypes.Completion.helptopic] model
def _auth_to_kv_pairs auth_string for item in _split_auth_string auth_string k v item.split ' ' 1 if v.startswith '"' and len v > 1 and v.endswith '"' v v[1 -1 ] yield k v
def update_state task_handle state result None if result is None result {}if not current_app.config.get 'CELERY_ALWAYS_EAGER' task_handle.update_state state state meta result
def plus_or_dot pieces if '+' in pieces.get 'closest-tag' '' return '.'return '+'
def getFontsDirectoryPath return archive.getFabmetheusUtilitiesPath 'fonts'
def compare a b if HAVE_COMPARE_DIGEST return hmac.compare_digest a b result len a ^ len b for i in xrange len b result | ord a[ i % len a ] ^ ord b[i] return result 0
def StartTcpServer context None identity None address None **kwargs framer ModbusSocketFramerserver ModbusTcpServer context framer identity address **kwargs server.serve_forever
def _build_request_data sample language_code None max_alternatives None profanity_filter None speech_context None if sample.content is not None audio {'content' _bytes_to_unicode b64encode _to_bytes sample.content }else audio {'uri' sample.source_uri}config {'encoding' sample.encoding 'sampleRate' sample.sample_rate}if language_code is not None config['languageCode'] language_codeif max_alternatives is not None config['maxAlternatives'] max_alternativesif profanity_filter is not None config['profanityFilter'] profanity_filterif speech_context is not None config['speechContext'] {'phrases' speech_context}data {'audio' audio 'config' config}return data
def sdm_add f g O K h dict f for monom c in g if monom in h coeff h[monom] + c if not coeff del h[monom]else h[monom] coeffelse h[monom] creturn sdm_from_dict h O
def _set obj attribute value obj.__dict__[attribute] value
def findOp node v OpFinder walk node v verbose 0 return v.op
def recent_changes request page max 1 request.args.get 'page' type int query RevisionedPage.query.order_by RevisionedPage.revision_id.desc return Response generate_template 'recent_changes.html' pagination Pagination query 20 page 'Special Recent_Changes'
def round_to_int number precision precision int precision rounded int number + precision / 2 // precision * precision return rounded
def assert_quantity_allclose actual desired rtol 1e-07 atol None **kwargs import numpy as npnp.testing.assert_allclose *_unquantify_allclose_arguments actual desired rtol atol **kwargs
def delete_vhost vhost runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user res __salt__['cmd.run_all'] [__context__['rabbitmqctl'] 'delete_vhost' vhost] runas runas python_shell False msg 'Deleted'return _format_response res msg
def str_replace arr pat repl n -1 case True flags 0 if not is_string_like repl or callable repl raise TypeError 'replmustbeastringorcallable' use_re not case or len pat > 1 or flags or callable repl if use_re if not case flags | re.IGNORECASEregex re.compile pat flags flags n n if n > 0 else 0 def f x return regex.sub repl x count n else f lambda x x.replace pat repl n return _na_map f arr
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def lscsum lx epsilon None lx numpy.asarray lx base lx.max if numpy.isinf base return baseif epsilon is not None and base < epsilon return epsilonx numpy.exp lx - base ssum x.sum result numpy.log ssum + base return result
def _candidate_tempdir_list dirlist []for envname in 'TMPDIR' 'TEMP' 'TMP' dirname _os.getenv envname if dirname dirlist.append dirname if _os.name 'nt' dirlist.extend ['c \\temp' 'c \\tmp' '\\temp' '\\tmp'] else dirlist.extend ['/tmp' '/var/tmp' '/usr/tmp'] try dirlist.append _os.getcwd except AttributeError OSError dirlist.append _os.curdir return dirlist
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def set_users users test False commit True return __salt__['net.load_template'] 'set_users' users users test test commit commit
def partialRelease a TpPd pd 6 b MessageType mesType 10 c ChannelDescription packet a / b / c return packet
def add_task queue_name url payload None **kws TaskQueue queue_name .add Task url payload **kws
def geo_distance a b a_y radians a.y b_y radians b.y delta_x radians a.x - b.x cos_x sin a_y * sin b_y + cos a_y * cos b_y * cos delta_x return acos cos_x * earth_radius_km
def to_valid_filename s valid_chars '-_. %s%s' % string.ascii_letters string.digits return ''.join c for c in s if c in valid_chars
@with_setup state.setup state.teardown def test_subunit_output_undefined_steps state.expect [Includes {'status' 'fail' 'details' Includes {'steps' ContentContains '?Whenthisteststepisundefined\n' } } Includes {'status' 'fail' 'details' Includes {'steps' ContentContains '?Whenthisteststepisundefined\n' } } ]runner Runner feature_name 'undefined_steps' enable_subunit True runner.run
def removeElementFromPixelListFromPoint element pixelDictionary point stepKey getStepKeyFromPoint point removeElementFromListTable element stepKey pixelDictionary
def pandas_dtype dtype if isinstance dtype DatetimeTZDtype return dtypeelif isinstance dtype PeriodDtype return dtypeelif isinstance dtype CategoricalDtype return dtypeelif isinstance dtype string_types try return DatetimeTZDtype.construct_from_string dtype except TypeError passif dtype.startswith 'period[' or dtype.startswith 'Period[' try return PeriodDtype.construct_from_string dtype except TypeError passtry return CategoricalDtype.construct_from_string dtype except TypeError passelif isinstance dtype ExtensionDtype return dtypereturn np.dtype dtype
def _serverFromStringLegacy reactor description default nameOrPlugin args kw _parseServer description None default if type nameOrPlugin is not str plugin nameOrPluginreturn plugin.parseStreamServer reactor *args **kw else name nameOrPluginargs args[ 1] + args[2 ] return _endpointServerFactories[name] reactor *args **kw
def rate_limit_argument_spec spec None arg_spec dict rate dict type 'int' rate_limit dict type 'int' if spec arg_spec.update spec return arg_spec
def check_api_key key url 'https //www.googleapis.com/youtube/v3/i18nLanguages'query {'part' 'snippet' 'fields' 'items/id' 'key' key}try urlopen url + '?' + urlencode query .read message "Thekey '" + key + "'willnowbeusedforAPIrequests." pafy.set_api_key Config.API_KEY.get return dict valid True message message except HTTPError message "Invalidkeyorquotaexceeded '" + key + "'" return dict valid False message message
def get_resolver_for_resource_type resource_type if resource_type ResourceType.RUNNER resolver_cls RunnerPermissionsResolverelif resource_type ResourceType.PACK resolver_cls PackPermissionsResolverelif resource_type ResourceType.SENSOR resolver_cls SensorPermissionsResolverelif resource_type ResourceType.ACTION resolver_cls ActionPermissionsResolverelif resource_type ResourceType.ACTION_ALIAS resolver_cls ActionAliasPermissionsResolverelif resource_type ResourceType.RULE resolver_cls RulePermissionsResolverelif resource_type ResourceType.EXECUTION resolver_cls ExecutionPermissionsResolverelif resource_type ResourceType.KEY_VALUE_PAIR resolver_cls KeyValuePermissionsResolverelif resource_type ResourceType.WEBHOOK resolver_cls WebhookPermissionsResolverelif resource_type ResourceType.API_KEY resolver_cls ApiKeyPermissionResolverelif resource_type ResourceType.RULE_ENFORCEMENT resolver_cls RuleEnforcementPermissionsResolverelse raise ValueError 'Unsupportedresource %s' % resource_type resolver_instance resolver_cls return resolver_instance
@with_setup reset def test_single_bundle b Bundle register 'foo' b assert _get b
def date value arg None from django.utils.dateformat import formatif not value return ''if arg is None arg settings.DATE_FORMATreturn format value arg
def set_vary_header response header_name varies response.headers.get 'Vary' '' varies [x.strip for x in varies.split ' ' if x.strip ]if header_name not in varies varies.append header_name response.headers['Vary'] ' '.join varies
@receiver post_init sender CourseCreator def post_init_callback sender **kwargs instance kwargs['instance']instance.orig_state instance.state
def xml_translate callback value if not value return valuetrans XMLTranslator callback 'xml' try root etree.fromstring encode value trans.process root return trans.get_done except etree.ParseError wrapped '<div>%s</div>' % encode value root etree.fromstring wrapped etree.HTMLParser encoding 'utf-8' trans.process root[0][0] return trans.get_done [5 -6 ]
def thunk_hook type value trace log_thunk_trace value __excepthook type value trace
def scan opts ret {}for root dirs files in os.walk opts['root'] for fn_ in files full os.path.join root fn_ if full.endswith '.py' ret.update mod_data opts full return ret
def calledback_url dispatch 'score_update' return dispatch
def run_grouped_correlation md_vals otu_arrays test test_choices pval_assignment_method permutations None test_fn test_choices[test]sample_sizes map len md_vals def _rho otu_vals md_vals return test_fn otu_vals md_vals rhos []for i in range len md_vals rhos.append apply_along_axis _rho 1 otu_arrays[i] md_vals[i] pvals []for i group_rhos in enumerate rhos pvals_i zeros len group_rhos for j rho in enumerate group_rhos pvals_i[j] assign_correlation_pval rho sample_sizes[i] pval_assignment_method permutations test_fn otu_arrays[i][j] md_vals[i] pvals.append array pvals_i fisher_pvals apply_along_axis fisher 0 array pvals fisher_rho_and_h apply_along_axis fisher_population_correlation 0 array rhos sample_sizes return rhos pvals fisher_pvals fisher_rho_and_h[0] fisher_rho_and_h[1]
def mean_squared_logarithmic_error y_true y_pred first_log tf.log tf.clip_by_value y_pred 1e-08 np.inf + 1.0 second_log tf.log tf.clip_by_value y_true 1e-08 np.inf + 1.0 return tf.reduce_mean tf.square first_log - second_log
def is_commentable_cohorted course_key commentable_id course courses.get_course_by_id course_key course_cohort_settings get_course_cohort_settings course_key if not course_cohort_settings.is_cohorted or get_team commentable_id ans Falseelif commentable_id in course.top_level_discussion_topic_ids or course_cohort_settings.always_cohort_inline_discussions is False ans commentable_id in course_cohort_settings.cohorted_discussions else ans Truelog.debug u'is_commentable_cohorted %s %s {%s}' course_key commentable_id ans return ans
def uniqueArrays vs resdic {}for v in vs resdic[xhash v ] vreturn list resdic.values
def default_handlers handlers [] return handlers + [ '/gist/ [^\\/]+/ ? [0-9]+|[0-9a-f]{20 } ' GistHandler '/gist/ [^\\/]+/ ? [0-9]+|[0-9a-f]{20 } / ? files/ ? .* ' GistHandler '/ [0-9]+|[0-9a-f]{20 } ' GistRedirectHandler '/ [0-9]+|[0-9a-f]{20 } / .* ' GistRedirectHandler '/gist/ [^\\/]+ /?' UserGistsHandler ]
def _have_socket_alg try s socket.socket socket.AF_ALG socket.SOCK_SEQPACKET 0 except AttributeError OSError return Falseelse s.close return True
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def collect_master_lb hosts message "\nSettinguphigh-availabilitymastersrequiresaloadbalancingsolution.\nPleaseprovidetheFQDNofahostthatwillbeconfiguredasaproxy.This\ncanbeeitheranexistingloadbalancerconfiguredtobalanceallmasterson\nport8443oranewhostthatwillhaveHAProxyinstalledonit.\n\nIfthehostprovidedisnotyetconfigured areferenceHAProxyload\nbalancerwillbeinstalled.It'simportanttonotethatwhiletherestofthe\nenvironmentwillbefault-tolerant thisreferenceloadbalancerwillnotbe.\nItcanbereplacedpost-installationwithaloadbalancerwiththesame\nhostname.\n"click.echo message host_props {}def validate_prompt_lb hostname hostname validate_prompt_hostname hostname for host in hosts if host.connect_to hostname and host.is_master or host.is_node raise click.BadParameter 'Cannotre-use"%s"asaloadbalancer pleasespecifyaseparatehost' % hostname return hostnamelb_hostname click.prompt 'EnterhostnameorIPaddress' value_proc validate_prompt_lb if lb_hostname host_props['connect_to'] lb_hostnameinstall_haproxy click.confirm 'ShouldthereferenceHAProxyloadbalancerbeinstalledonthishost?' host_props['preconfigured'] not install_haproxy host_props['roles'] ['master_lb']return Host **host_props else return None
@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_POSTdef mark_student_can_skip_entrance_exam request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id student_identifier request.POST.get 'unique_student_identifier' student get_student_from_identifier student_identifier __ created EntranceExamConfiguration.objects.get_or_create user student course_id course_id if created message _ 'Thisstudent %s willskiptheentranceexam.' % student_identifier else message _ 'Thisstudent %s isalreadyallowedtoskiptheentranceexam.' % student_identifier response_payload {'message' message}return JsonResponse response_payload
def DEFINE_flag flag flag_values FLAGS fv flag_valuesfv[flag.name] flagif isinstance flag_values FlagValues module module_name _GetCallingModuleObjectAndName flag_values._RegisterFlagByModule module_name flag flag_values._RegisterFlagByModuleId id module flag
def rtuFrameSize buffer byte_count_pos return struct.unpack '>B' buffer[byte_count_pos] [0] + byte_count_pos + 3
def get_openshift_version facts version Noneif 'common' in facts if 'version' in facts['common'] and facts['common']['version'] is not None return chomp_commit_offset facts['common']['version'] if os.path.isfile '/usr/bin/openshift' _ output _ module.run_command ['/usr/bin/openshift' 'version'] version parse_openshift_version output elif 'common' in facts and 'is_containerized' in facts['common'] version get_container_openshift_version facts if not version and os.path.isfile '/usr/local/bin/openshift' _ output _ module.run_command ['/usr/local/bin/openshift' 'version'] version parse_openshift_version output return chomp_commit_offset version
def identity_matrix return numpy.identity 4
def precompute config soups show_toc config.get u'show_toc' {} page {}pantsrefs precompute_pantsrefs soups for p soup in soups.items title get_title soup or p page[p] PrecomputedPageInfo title title show_toc show_toc.get p True return Precomputed page page pantsref pantsrefs
def _safe_id val utils.random_ascii for bad in '#;/?' val val.replace bad '' return val
def get_item_from_queue Q timeout 0.01 try item Q.get True timeout except Queue.Empty return Nonereturn item
def pbkdf2 password salt iterations digestMod hash passwordfor i in range iterations hash hmac.new salt hash digestMod .digest return hash
def _get_filter_query args query Q for arg in args if hasattr Message arg and args[arg] kwargs {str arg + '__id' long args[arg] }query query & Q **kwargs return query
def timedelta_to_days delta return delta.days + delta.seconds / 3600 * 24
@must_be_logged_indef user_choose_mailing_lists auth **kwargs user auth.userjson_data escape_html request.get_json if json_data for list_name subscribe in json_data.items if list_name settings.OSF_HELP_LIST update_osf_help_mails_subscription user user subscribe subscribe else update_mailchimp_subscription user list_name subscribe else raise HTTPError http.BAD_REQUEST data dict message_long "Mustprovideadictionaryoftheformat{'mailinglistname' Boolean}" user.save all_mailing_lists {}all_mailing_lists.update user.mailchimp_mailing_lists all_mailing_lists.update user.osf_mailing_lists return {'message' 'Successfullyupdatedmailinglists' 'result' all_mailing_lists} 200
def get_coding text for line in text.splitlines [ 2] try result CODING_RE.search to_text_string line except UnicodeDecodeError passelse if result codec result.group 1 if codec in CODECS return codecif is_binary_string text detector UniversalDetector for line in text.splitlines [ 2] detector.feed line if detector.done breakdetector.close return detector.result['encoding']return None
def _pval_from_histogram T H0 tail if tail not in [ -1 0 1] raise ValueError 'invalidtailparameter' if tail -1 pval np.array [np.sum H0 < t for t in T] elif tail 1 pval np.array [np.sum H0 > t for t in T] else pval np.array [np.sum abs H0 > abs t for t in T] pval pval + 1.0 / H0.size + 1.0 return pval
def resolve_iterator_class mode if isinstance mode six.string_types and mode not in _iteration_schemes raise ValueError 'unknowniterationmodestring %s' % mode elif mode in _iteration_schemes subset_iter_class _iteration_schemes[mode]else subset_iter_class modereturn subset_iter_class
def in6_getifaddr ret []i dnet.intf for int in i ifname int['name']v6 []if int.has_key 'alias_addrs' v6 int['alias_addrs']for a in v6 if a.type ! dnet.ADDR_TYPE_IP6 continuexx str a .split '/' [0]addr scapy.utils6.in6_ptop xx scope scapy.utils6.in6_getscope addr ret.append xx scope ifname return ret
def get_free_disk_bytes dirname if platform.system .lower .startswith 'win' free_bytes ctypes.c_ulonglong 0 ctypes.windll.kernel32.GetDiskFreeSpaceExW ctypes.c_wchar_p dirname None None ctypes.pointer free_bytes return free_bytes.valueelse st os.statvfs dirname return st.f_bavail * st.f_frsize
@local_optimizer [gemm_no_inplace] def local_gemm_to_gemv node if node.op gemm_no_inplace z a x y b node.inputsif z.broadcastable x.broadcastable True False r gemv_no_inplace z.dimshuffle 1 a y.T x.dimshuffle 1 b return [r.dimshuffle 'x' 0 ]if z.broadcastable y.broadcastable False True r gemv_no_inplace z.dimshuffle 0 a x y.dimshuffle 0 b return [r.dimshuffle 0 'x' ]
def ae_delete token_key import gdata.alt.app_enginekey_name ''.join 'gd_auth_token' token_key gdata.alt.app_engine.delete_token key_name
def merge_dict dic1 dic2 return dict dic1.items + dic2.items
def create_exception_cls name module parent None if not parent parent Exceptionreturn subclass_exception name parent module
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def scale_bem subject_to bem_name subject_from None scale None subjects_dir None subjects_dir subject_from scale nn_scale _scale_params subject_to subject_from scale subjects_dir src bem_fname.format subjects_dir subjects_dir subject subject_from name bem_name dst bem_fname.format subjects_dir subjects_dir subject subject_to name bem_name if os.path.exists dst raise IOError 'Filealredyexists %s' % dst surfs read_bem_surfaces src for surf in surfs surf['rr'] * scaleif nn_scale is not None surf['nn'] * nn_scalesurf['nn'] / np.sqrt np.sum surf['nn'] ** 2 1 [ np.newaxis]write_bem_surfaces dst surfs
def check_member_pool lb member pool_name if __opts__['load_balancers'].get lb None username password list __opts__['load_balancers'][lb].values else raise Exception 'Unabletofind`{0}`loadbalancer'.format lb F5 F5Mgmt lb username password return F5.check_member_pool member pool_name
def _reconstruct_object typ obj axes dtype try typ typ.typeexcept AttributeError passres_t np.result_type obj.dtype dtype if not isinstance typ partial and issubclass typ pd.core.generic.PandasObject return typ obj dtype res_t **axes if hasattr res_t 'type' and typ np.bool_ and res_t ! np.bool_ ret_value res_t.type obj else ret_value typ obj .astype res_t if len obj.shape 1 and len obj 1 if not isinstance ret_value np.ndarray ret_value np.array [ret_value] .astype res_t return ret_value
def attach_generated_user_stories queryset as_field 'generated_user_stories_attr' model queryset.modelsql 'SELECTjson_agg row_to_json t \nFROM \nSELECT\nuserstories_userstory.id \nuserstories_userstory.ref \nuserstories_userstory.subject\nFROMuserstories_userstory\nWHEREgenerated_from_issue_id {tbl}.id t'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def edge_betweenness_centrality G k None normalized True weight None seed None betweenness dict.fromkeys G 0.0 betweenness.update dict.fromkeys G.edges 0.0 if k is None nodes Gelse random.seed seed nodes random.sample G.nodes k for s in nodes if weight is None S P sigma _single_source_shortest_path_basic G s else S P sigma _single_source_dijkstra_path_basic G s weight betweenness _accumulate_edges betweenness S P sigma s for n in G del betweenness[n]betweenness _rescale_e betweenness len G normalized normalized directed G.is_directed return betweenness
def rshift a b return a >> b
def save_flavor_info metadata instance_type prefix '' for key in system_metadata_flavor_props.keys to_key '%sinstance_type_%s' % prefix key metadata[to_key] instance_type[key]extra_specs instance_type.get 'extra_specs' {} for extra_prefix in system_metadata_flavor_extra_props for key in extra_specs if key.startswith extra_prefix to_key '%sinstance_type_extra_%s' % prefix key metadata[to_key] extra_specs[key]return metadata
@np.deprecate message 'stats.f_valuedeprecatedinscipy0.17.0' def f_value ER EF dfR dfF return ER - EF / float dfR - dfF / EF / float dfF
def _init_readline if g.command_line returnif has_readline g.READLINE_FILE os.path.join paths.get_config_dir 'input_history' if os.path.exists g.READLINE_FILE readline.read_history_file g.READLINE_FILE dbg c.g + 'Readhistoryfile' + c.w
def unhex s bits 0for c in s c bytes c if '0' < c < '9' i ord '0' elif 'a' < c < 'f' i ord 'a' - 10 elif 'A' < c < 'F' i ord 'A' - 10 else assert False 'non-hexdigit' + repr c bits bits * 16 + ord c - i return bits
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _handle_interrupt exc original_exc hardfail False trace '' if hardfail if trace log.error trace raise original_excelse raise exc
def maxID db now intTime 1000 for tbl in 'cards' 'notes' now max now db.scalar 'selectmax id from%s' % tbl or 0 return now + 1
@with_setup prepare_stderr def test_feature_missing_scenarios filename syntax_feature_name 'feature_missing_scenarios' runner Runner filename assert_raises LettuceRunnerError runner.run assert_stderr_lines u'Syntaxerrorat %s\nFeaturesmusthavescenarios.\nPleaserefertothedocumentationavailableathttp //lettuce.itformoreinformation.\n' % filename
def concatenate_matrices *matrices M numpy.identity 4 for i in matrices M numpy.dot M i return M
def MakeHists live hist thinkstats2.Hist live.birthwgt_lb label 'birthwgt_lb' thinkplot.Hist hist thinkplot.Save root 'first_wgt_lb_hist' xlabel 'pounds' ylabel 'frequency' axis [ -1 14 0 3200] hist thinkstats2.Hist live.birthwgt_oz label 'birthwgt_oz' thinkplot.Hist hist thinkplot.Save root 'first_wgt_oz_hist' xlabel 'ounces' ylabel 'frequency' axis [ -1 16 0 1200] hist thinkstats2.Hist np.floor live.agepreg label 'agepreg' thinkplot.Hist hist thinkplot.Save root 'first_agepreg_hist' xlabel 'years' ylabel 'frequency' hist thinkstats2.Hist live.prglngth label 'prglngth' thinkplot.Hist hist thinkplot.Save root 'first_prglngth_hist' xlabel 'weeks' ylabel 'frequency' axis [ -1 53 0 5000]
def test_nested_mlp inner_mlp MLP layers [Linear 10 'h0' 0.1 Linear 10 'h1' 0.1 ] layer_name 'inner_mlp' outer_mlp MLP layers [CompositeLayer layer_name 'composite' layers [inner_mlp Linear 10 'h2' 0.1 ] ] nvis 10 X outer_mlp.get_input_space .make_theano_batch f theano.function [X] outer_mlp.fprop X f np.random.rand 5 10 .astype theano.config.floatX
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def test_dataset_validation_k_fold skip_if_no_sklearn mapping {'dataset_iterator' 'DatasetValidationKFold'}test_yaml test_yaml_dataset_iterator % mapping trainer yaml_parse.load test_yaml trainer.main_loop
def format_exception msg *args **kwargs tb traceback.extract_tb sys.exc_info [2] limit 1 if len tb > 0 filename lineno func text tb[0]else filename lineno func text u'<unknown>'return msg.format filename filename lineno lineno func func text text *args **kwargs
@taskdef linkcheck ctx build ctx builder 'linkcheck'
@check_login_required@valid_prefs_requireddef root request local_site_name None if request.user.is_authenticated url_name u'dashboard'else url_name u'all-review-requests'return HttpResponseRedirect local_site_reverse url_name local_site_name local_site_name
def _auto_create_specific_service_result_parser run utils.run result_parser _result_parsers[get_name_of_init run ]command_list [c for c in COMMANDS if c not in ['list' 'set_target'] ]return _ServiceResultParser result_parser command_list
def get_pending_reboot checks get_pending_update get_pending_file_rename get_pending_servermanager get_pending_component_servicing get_reboot_required_witnessed get_pending_computer_name get_pending_domain_join for check in checks if check return Truereturn False
def _structure msg fp None level 0 include_default False if fp is None fp sys.stdouttab '' * level * 4 print >>fp tab + msg.get_content_type if include_default print >>fp '[%s]' % msg.get_default_type else print >>fpif msg.is_multipart for subpart in msg.get_payload _structure subpart fp level + 1 include_default
def smartyPants text attr default_smartypants_attr language 'en' return ''.join [t for t in educate_tokens tokenize text attr language ]
def test_deep_bases_win_over_dependents dsk {'a' f 'b' 'c' 'd' 'b' f 'd' 'e' 'c' f 'd' 'd' 1 'e' 2}o order dsk assert o['d'] < o['e'] assert o['d'] < o['b'] or o['d'] < o['c']
def render_to_response *args **kwargs httpresponse_kwargs {'content_type' kwargs.pop 'content_type' None }mimetype kwargs.pop 'mimetype' None if mimetype warnings.warn 'Themimetypekeywordargumentisdeprecated usecontent_typeinstead' PendingDeprecationWarning stacklevel 2 httpresponse_kwargs['content_type'] mimetypereturn HttpResponse loader.render_to_string *args **kwargs **httpresponse_kwargs
def build_alpha_spans alpha_spans_str alpha_regexs spans []for elem in alpha_spans_str if elem in alpha_regexs spans.append re.compile alpha_regexs[elem] else bucket sorted [x for x in elem.lower if x.isalnum ] if bucket begin_index ASCII_DIGITS.index bucket[0] end_index ASCII_DIGITS.index bucket[ -1 ] else raise ui.UserError u"invalidrangedefinedforalphabucket'%s' noalphanumericcharacterfound" % elem spans.append re.compile '^[' + ASCII_DIGITS[begin_index end_index + 1 ] + ASCII_DIGITS[begin_index end_index + 1 ].upper + ']' return spans
def validate_config config del config[CONF_PLATFORM]if CONF_NAME not in config _LOGGER.error 'UniversalMediaPlayerconfigurationrequiresname' return Falsevalidate_children config validate_commands config validate_attributes config del_keys []for key in config if key not in [CONF_NAME CONF_CHILDREN CONF_COMMANDS CONF_ATTRS] _LOGGER.warning 'UniversalMediaPlayer %s unrecognizedparameter%s' config[CONF_NAME] key del_keys.append key for key in del_keys del config[key]return True
def _get_head_types pat if isinstance pat pytree.NodePattern pytree.LeafPattern if pat.type is None raise _EveryNodereturn set [pat.type] if isinstance pat pytree.NegatedPattern if pat.content return _get_head_types pat.content raise _EveryNodeif isinstance pat pytree.WildcardPattern r set for p in pat.content for x in p r.update _get_head_types x return rraise Exception "Ohno!Idon'tunderstandpattern%s" % pat
def _minpoly_rootof ex x p ex.exprp p.subs {ex.poly.gens[0] x} _ factors factor_list p x result _choose_factor factors x ex return result
def Triangular name a b c return rv name TriangularDistribution a b c
def read_uic_image_property fh size struct.unpack 'B' fh.read 1 [0]name struct.unpack '%is' % size fh.read size [0][ -1 ] flags prop struct.unpack '<IB' fh.read 5 if prop 1 value struct.unpack 'II' fh.read 8 value value[0] / value[1] else size struct.unpack 'B' fh.read 1 [0]value struct.unpack '%is' % size fh.read size [0]return dict name name flags flags value value
def configure_node cluster node certnkey dataset_backend_configuration provider logging_config None setup_action 'start'if provider 'managed' setup_action 'restart'return run_remotely username 'root' address node.address commands sequence [task_install_node_certificates cluster.certificates.cluster.certificate certnkey.certificate certnkey.key task_install_api_certificates cluster.certificates.user.certificate cluster.certificates.user.key task_enable_docker node.distribution if_firewall_available node.distribution open_firewall_for_docker_api node.distribution task_configure_flocker_agent control_node cluster.control_node.address dataset_backend cluster.dataset_backend dataset_backend_configuration dataset_backend_configuration logging_config logging_config task_enable_docker_plugin node.distribution task_enable_flocker_agent distribution node.distribution action setup_action ]
@np.deprecate message 'scipy.stats.fastsortisdeprecatedinscipy0.16.0' def fastsort a it np.argsort a as_ a[it]return as_ it
def maxzero x x np.asarray x cond1 x[ -1 ] < 0 cond2 x[1 ] > 0 allzeros np.nonzero cond1 & cond2 | x[1 ] 0 [0] + 1 if x[ -1 ] > 0 maxz max allzeros else maxz Nonereturn maxz allzeros
def list_cache_subnet_groups region None key None keyid None profile None return [g['CacheSubnetGroupName'] for g in describe_cache_subnet_groups None region key keyid profile ]
def prepend_path newpath oldpath if oldpath return newpath + ' ' + oldpath else return newpath
@login_required redirect False @json_view@non_atomic_requestsdef ajax request if 'q' not in request.GET raise http.Http404 data {'status' 0 'message' ''}email request.GET.get 'q' '' .strip if not email data.update message _ 'Anemailaddressisrequired.' return datauser UserProfile.objects.filter email email msg _ 'Auserwiththatemailaddressdoesnotexist.' if user data.update status 1 id user[0].id name user[0].name else data['message'] msgreturn escape_all data
def restore_ccx val ccx_id if isinstance val CourseLocator return CCXLocator.from_course_locator val ccx_id elif isinstance val BlockUsageLocator ccx_key restore_ccx val.course_key ccx_id val CCXBlockUsageLocator ccx_key val.block_type val.block_id for field_name in XMODULE_FIELDS_WITH_USAGE_KEYS if hasattr val field_name setattr val field_name restore_ccx getattr val field_name ccx_id if hasattr val 'children' val.children restore_ccx_collection val.children ccx_id return val
def ishow for manager in Gcf.get_all_fig_managers manager.show if show._needmain thread.start_new_thread Fltk_run_interactive show._needmain False
def is_shared_variable variable return isinstance variable SharedVariable and not isinstance variable RandomStateSharedVariable and not hasattr variable.tag 'is_rng'
def test_suggested_column_names_with_table_dot completer complete_event text u'SELECTusers.fromusers'position len u'SELECTusers.' result set completer.get_completions Document text text cursor_position position complete_event assert set result set testdata.columns u'users'
def needs_sgemv_fix info if uses_accelerate info return Trueelse return False
def scaled_zero mag sign 1 if type mag is tuple and len mag 4 and iszero mag scaled True return mag[0][0] + mag[1 ] elif isinstance mag SYMPY_INTS if sign not in [ -1 1] raise ValueError 'signmustbe+/-1' rv p mpf_shift fone mag -1 s 0 if sign 1 else 1 rv [s] + rv[1 ] return rv p else raise ValueError 'scaledzeroexpectsintorscaled_zerotuple.'
def restore_defaults top_level_logger logging.getLogger __name__.split '.' [0] top_level_logger.propagate Truetop_level_logger.setLevel logging.NOTSET while top_level_logger.handlers top_level_logger.handlers.pop
def demangle_name name mode if name.endswith '.bupl' return name[ -5 ] BUP_NORMAL elif name.endswith '.bup' return name[ -4 ] BUP_CHUNKED elif name.endswith '.bupm' return name[ -5 ] BUP_CHUNKED if stat.S_ISDIR mode else BUP_NORMAL else return name BUP_NORMAL
def menu_prompt model prompt '>' rows None header None theading None footer None force 0 content ''for x in header theading rows footer if isinstance x list for line in x content + line + '\n' elif isinstance x str content + x + '\n' g.content contentscreen.update choice input prompt if choice in model return model[choice]elif force return menu_prompt model prompt rows header theading footer force elif not choice.strip return False False else return False 'abort'
def test_parse_focus arg_str 'id_with_no_annotation'expected_output {'id' 'id_with_no_annotation' 'annotation' ''}actual_output screenshot._parse_focus arg_str assert_equal expected_output actual_output arg_str 'id_with_annotation|testannotation'expected_output {'id' 'id_with_annotation' 'annotation' 'testannotation'}actual_output screenshot._parse_focus arg_str assert_equal expected_output actual_output
def MaybeInvokeAuthentication datastore_stub apiproxy_stub_map.apiproxy.GetStub 'datastore_v3' if isinstance datastore_stub RemoteStub datastore_stub._server.Send datastore_stub._path payload None else raise ConfigurationError 'remote_apiisnotconfigured.'
def _BisectHashList ls left right value if right < left return Noneif left right return ls[left]middle left + right - left / 2 middleval ls[middle]start middleval.interval.startend middleval.interval.endif start < value < end return middlevalif value > end return _BisectHashList ls middle + 1 right value if value < start return _BisectHashList ls left middle - 1 value
def test_cache_call_signatures def check column call_name path None assert jedi.Script s 1 column path .call_signatures [0].name call_name s 'str int 'for i in range 3 check 8 'int' check 4 'str' for i in range 3 check 8 'int' 'boo' check 4 'str' 'boo'
def loadhook h def processor handler h return handler return processor
def set_errout fp import commandsif fp commands.ERR fpelse commands.ERR sys.stderr
def execute_directly request query query_server None design None on_success_url None on_success_params None **kwargs if design is not None authorized_get_design request design.id db dbms.get request.user query_server database query.query.get 'database' 'default' db.use database query_history db.execute_query query design watch_url reverse get_app_name request + ' watch_query_history' kwargs {'query_history_id' query_history.id} get_dict QueryDict None mutable True if on_success_url if callable on_success_url on_success_url on_success_url query_history get_dict['on_success_url'] on_success_urlif on_success_params get_dict.update on_success_params return format_preserving_redirect request watch_url get_dict
def test_exception_in_exception_handler exception_app request response sanic_endpoint_test exception_app uri '/error_in_error_handler_handler' assert response.status 500 assert response.body 'Anerroroccurredwhilehandlinganerror'
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def _non_reducing_slice slice_ kinds tuple list compat.string_types + [ABCSeries np.ndarray Index list] if isinstance slice_ kinds slice_ IndexSlice[ slice_]def pred part return isinstance part slice or is_list_like part if not is_list_like slice_ if not isinstance slice_ slice slice_ [[slice_]]else slice_ [slice_]else slice_ [ part if pred part else [part] for part in slice_]return tuple slice_
def test_module_is_active module get_pricing_module assert isinstance module CustomerGroupPricingModule
def gluechops string key n funcref message ''chops decode64chops string for cpart in chops mpart funcref cpart key n message + int2bytes mpart return message
def read_cz_lsm_time_stamps fh size count struct.unpack '<ii' fh.read 8 if size ! 8 + 8 * count raise ValueError 'lsm_time_stampsblockistooshort' return fh.read_array '<f8' count count
def scan_postfix_submission_line date log collector m re.match ' [A-Z0-9]+ client \\S+ sasl_method PLAIN sasl_username \\S+ ' log if m collector['activity-by-hour']['smtp-sends'][date.hour] + 1
def test_get_words_java expected_words ['Compilation' 'Execution' 'Hello' 'HelloWorld' 'Prints' 'String' 'System' 'World' 'args' 'class' 'java' 'javac' 'main' 'out' 'println' 'public' 'static' 'terminal' 'the' 'to' 'void' 'window']assert sorted expected_words sorted get_words_by_filename 'example.java' assert sorted expected_words sorted get_words_by_content 'example.java'
def mmInformation NetworkName_presence 0 NetworkName_presence1 0 TimeZone_presence 0 TimeZoneAndTime_presence 0 LsaIdentifier_presence 0 a TpPd pd 5 b MessageType mesType 50 packet a / b if NetworkName_presence is 1 c NetworkNameHdr ieiNN 67 eightBitNN 0 packet packet / c if NetworkName_presence1 is 1 d NetworkNameHdr ieiNN 69 eightBitNN 0 packet packet / d if TimeZone_presence is 1 e TimeZoneHdr ieiTZ 70 eightBitTZ 0 packet packet / e if TimeZoneAndTime_presence is 1 f TimeZoneAndTimeHdr ieiTZAT 71 eightBitTZAT 0 packet packet / f if LsaIdentifier_presence is 1 g LsaIdentifierHdr ieiLI 72 eightBitLI 0 packet packet / g return packet
@lru_cache 1 def _extract_containers_state deployment_state result []for node in deployment_state.nodes.itervalues applications if node.applications is not None applications node.applications.values for application in applications container container_configuration_response application node.uuid container[u'running'] application.runningresult.append container return result
def _label_clicked pos params labels params['ax'].yaxis.get_ticklabels offsets np.array params['offsets'] + params['offsets'][0] line_idx np.searchsorted offsets pos[1] text labels[line_idx].get_text if len text 0 returnif 'fig_selection' in params ch_idx _find_channel_idx text params _handle_topomap_bads text params else ch_idx [ params['ch_start'] + line_idx ]bads params['info']['bads']if text in bads while text in bads bads.remove text color vars params['lines'][line_idx] ['def_color']for idx in ch_idx params['ax_vscroll'].patches[idx].set_color color else bads.append text color params['bad_color']for idx in ch_idx params['ax_vscroll'].patches[idx].set_color color params['raw'].info['bads'] bads_plot_update_raw_proj params None
def make_auth_tkt_middleware app global_conf secret None cookie_name 'auth_tkt' secure False include_ip True logout_path None from paste.deploy.converters import asboolsecure asbool secure include_ip asbool include_ip if secret is None secret global_conf.get 'secret' if not secret raise ValueError "Youmustprovidea'secret' inglobalorlocalconfiguration " return AuthTKTMiddleware app secret cookie_name secure include_ip logout_path or None
def make_arrow pad if pad > 2 return '-' * pad - 2 + '>' elif pad 1 return '>'return ''
def eval_str expr from datetime import date datetimeif isinstance expr date datetime return repr expr return repr expr if isinstance expr _strtypes else str expr
def summarize text ratio 0.2 word_count None split False sentences _clean_text_by_sentences text if len sentences 0 logger.warning 'Inputtextisempty.' returnif len sentences 1 raise ValueError 'inputmusthavemorethanonesentence' if len sentences < INPUT_MIN_LENGTH logger.warning 'Inputtextisexpectedtohaveatleast' + str INPUT_MIN_LENGTH + 'sentences.' corpus _build_corpus sentences most_important_docs summarize_corpus corpus ratio ratio if word_count is None else 1 extracted_sentences _extract_important_sentences sentences corpus most_important_docs word_count extracted_sentences.sort key lambda s s.index return _format_results extracted_sentences split
def iterate obj opts stack deque [obj] while stack t stack.popleft yield t for c in t.get_children **opts stack.append c
def disk_block_size path return os.statvfs path .f_bsize
def function_namespace f args None m_args inspect.getargspec f [0]if len m_args and args if m_args[0] 'self' return '%s.%s.%s' % f.__module__ args[0].__class__.__name__ f.__name__ elif m_args[0] 'cls' return '%s.%s.%s' % f.__module__ args[0].__name__ f.__name__ if hasattr f 'im_func' return '%s.%s.%s' % f.__module__ f.im_class.__name__ f.__name__ elif hasattr f '__class__' return '%s.%s.%s' % f.__module__ f.__class__.__name__ f.__name__ else return '%s.%s' % f.__module__ f.__name__
def is_numeric_v_string_like a b is_a_array isinstance a np.ndarray is_b_array isinstance b np.ndarray is_a_numeric_array is_a_array and is_numeric_dtype a is_b_numeric_array is_b_array and is_numeric_dtype b is_a_string_array is_a_array and is_string_like_dtype a is_b_string_array is_b_array and is_string_like_dtype b is_a_scalar_string_like not is_a_array and is_string_like a is_b_scalar_string_like not is_b_array and is_string_like b return is_a_numeric_array and is_b_scalar_string_like or is_b_numeric_array and is_a_scalar_string_like or is_a_numeric_array and is_b_string_array or is_b_numeric_array and is_a_string_array
def timecall fn None immediate True timer time.time if fn is None def decorator fn return timecall fn immediate immediate timer timer return decoratorfp FuncTimer fn immediate immediate timer timer def new_fn *args **kw return fp *args **kw new_fn.__doc__ fn.__doc__new_fn.__name__ fn.__name__new_fn.__dict__ fn.__dict__new_fn.__module__ fn.__module__return new_fn
def process_summary article summary article._get_summary summary_parsed BeautifulSoup summary 'html.parser' math summary_parsed.find_all class_ 'math' if len math > 0 last_math_text math[ -1 ].get_text if len last_math_text > 3 and last_math_text[ -3 ] '...' content_parsed BeautifulSoup article._content 'html.parser' full_text content_parsed.find_all class_ 'math' [ len math - 1 ].get_text math[ -1 ].string '%s...' % full_text summary summary_parsed.decode article._summary "%s<scripttype 'text/javascript'>%s</script>" % summary process_summary.mathjax_script
def shift_time_events events ids tshift sfreq events events.copy for ii in ids events[ events[ 2] ii 0 ] + int tshift * sfreq return events
def resourcebase_post_save instance *args **kwargs if not instance.id returnResourceBase.objects.filter id instance.id .update thumbnail_url instance.get_thumbnail_url detail_url instance.get_absolute_url csw_insert_date datetime.datetime.now instance.set_missing_info for link in instance.link_set.all if link.name 'ExternalDocument' if link.resource.doc_url ! link.url link.delete elif urlsplit settings.SITEURL .hostname not in link.url link.delete
def symbol_gen sym_str n 0while True yield Symbol '%s_%d' % sym_str n n + 1
def event_return events opts _get_options {} opts['skip'] Truefor event in events log.trace 'Carbonreturnerreceivedevent {0}'.format event metric_base event['tag']saltdata event['data'].get 'data' _send saltdata metric_base opts
def set_effective_user uid None gid None uid uid and parse_uid uid gid gid and parse_gid gid if uid if not gid and pwd gid pwd.getpwuid uid .pw_gidsetegid gid seteuid uid else gid and setegid gid
@np.deprecate message 'scipy.special.sph_knisdeprecatedinscipy0.18.0.Usescipy.special.spherical_kninstead.Notethatthenewfunctionhasadifferentsignature.' def sph_kn n z if not isscalar n and isscalar z raise ValueError 'argumentsmustbescalars.' if n ! floor n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n < 1 n1 1else n1 nif iscomplex z or less z 0 nm In Inp kn knp specfun.csphik n1 z else nm kn knp specfun.sphk n1 z return kn[ n + 1 ] knp[ n + 1 ]
def run _task
def delete_documents_from_search_index collection_ids search_services.delete_documents_from_index collection_ids SEARCH_INDEX_COLLECTIONS
def decodeBase58 string alphabet ALPHABET base len alphabet num 0try for char in string num * basenum + alphabet.index char except return 0return num
def env_purge_doc app env docname if docname in env.bokeh_plot_files del env.bokeh_plot_files[docname]
def get_course_position course_module urlargs {'course_id' unicode course_module.id }chapter get_current_child course_module min_depth 1 if chapter is None log.debug 'Nochapterfoundwhenloadingcurrentpositionincourse' return Noneurlargs['chapter'] chapter.url_nameif course_module.position is not None return {'display_name' chapter.display_name_with_default_escaped 'url' reverse 'courseware_chapter' kwargs urlargs }section get_current_child chapter min_depth 1 if section is None log.debug 'Nosectionfoundwhenloadingcurrentpositionincourse' return Noneurlargs['section'] section.url_namereturn {'display_name' section.display_name_with_default_escaped 'url' reverse 'courseware_section' kwargs urlargs }
def onFini INFO_MSG 'onFini '
def get_role_policy role_name policy_name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile try _policy conn.get_role_policy role_name policy_name _policy _policy.get_role_policy_response.policy_document_policy _unquote _policy _policy json.loads _policy object_pairs_hook odict.OrderedDict return _policyexcept boto.exception.BotoServerError return {}
def check_update github_slug current_version prereleases False releases get_valid_releases github_slug prereleases wf .logger.info u'{0}releasesfor{1}'.format len releases github_slug if not len releases raise ValueError u'Novalidreleasesfor{0}'.format github_slug latest_release releases[0]vr Version latest_release[u'version'] vl Version current_version wf .logger.debug u'Latest {0!r}Installed {1!r}'.format vr vl if vr > vl wf .cache_data u'__workflow_update_status' {u'version' latest_release[u'version'] u'download_url' latest_release[u'download_url'] u'available' True} return Truewf .cache_data u'__workflow_update_status' {u'available' False} return False
def coerce_types **kwargs def _coerce types return coerce *types return preprocess **valmap _coerce kwargs
def attachment_specs_delete context attachment_id key return IMPL.attachment_specs_delete context attachment_id key
def _load_lexers module_name mod __import__ module_name None None ['__all__'] for lexer_name in mod.__all__ cls getattr mod lexer_name _lexer_cache[cls.name] cls
def translate_attributes op server_dict operation_kwargs auto_disk_config_raw server_dict.pop API_DISK_CONFIG None if auto_disk_config_raw is not None auto_disk_config disk_config_from_api auto_disk_config_raw operation_kwargs['auto_disk_config'] auto_disk_configif API_ACCESS_V4 in server_dict operation_kwargs['access_ip_v4'] server_dict.pop API_ACCESS_V4 if API_ACCESS_V6 in server_dict operation_kwargs['access_ip_v6'] server_dict.pop API_ACCESS_V6 if 'preserve_ephemeral' in server_dict and op REBUILD preserve strutils.bool_from_string server_dict.pop 'preserve_ephemeral' strict True operation_kwargs['preserve_ephemeral'] preserveif 'personality' in server_dict if op REBUILD operation_kwargs['files_to_inject'] get_injected_files server_dict.pop 'personality' if op CREATE operation_kwargs['injected_files'] get_injected_files server_dict.pop 'personality' []
def s3_cleanup bucket session region 'us-west-2'client session.create_client 's3' region_name region try client.head_bucket Bucket bucket except ClientError returnresponse client.list_objects Bucket bucket contents response.get 'Contents' {} keys [content['Key'] for content in contents]for key in keys client.delete_object Bucket bucket Key key client.delete_bucket Bucket bucket
def confirm title text informative_text ok_text icon None default True cancel_text None cancel_icon None msgbox QtWidgets.QMessageBox active_window msgbox.setWindowModality Qt.WindowModal msgbox.setWindowTitle title msgbox.setText text msgbox.setInformativeText informative_text icon icons.mkicon icon icons.ok ok msgbox.addButton ok_text QtWidgets.QMessageBox.ActionRole ok.setIcon icon cancel msgbox.addButton QtWidgets.QMessageBox.Cancel cancel_icon icons.mkicon cancel_icon icons.close cancel.setIcon cancel_icon if cancel_text cancel.setText cancel_text if default msgbox.setDefaultButton ok else msgbox.setDefaultButton cancel msgbox.exec_ return msgbox.clickedButton ok
def ParseInteger text is_signed False is_long False try result int text 0 except ValueError raise ValueError "Couldn'tparseinteger %s" % text checker _INTEGER_CHECKERS[ 2 * int is_long + int is_signed ]checker.CheckValue result return result
@app.template_filter 'as_timezone' def as_timezone dt tzname if tzname and timezone tzname return dt.astimezone timezone tzname return dt
def call_alert *args **kwargs res dict devices _get_lights for dev_id in 'id' not in kwargs and sorted devices.keys or _get_devices kwargs res[dev_id] _set dev_id {'alert' kwargs.get 'on' True and 'lselect' or 'none' } return res
def _overrideFunc v t return 'OVERRIDDEN'
def list_images provider 'all' client _get_client images client.list_images provider return images
def imtext from .ansiext import AnsiExtensionmd Markdown output_format 'imtext' extensions [ExtraExtension AnsiExtension ] md.stripTopLevelTags Falsereturn md
def expect warn_type message for filter in _warnings.filters if filter[0] 'ignore' and issubclass warn_type filter[2] returnEXPECTED.append ' ' + warn_type.__name__ + ' ' + message + '\n'
def test_nvcc_cast var theano.tensor.fvector f theano.function [var] -1.0 * var > 0 mode mode_with_gpu if not numpy.allclose f [ -1 0 1] [0 0 -1 ] raise Exception 'TheversionofnvccthatTheanodetectedonyoursystemhasabugduringconversionfromintegerstofloatingpoint.InstallingCUDA7.0 ormorerecent shouldfixtheproblem.'
def _generate_path_between_rules old_rules new_rules old_by_chain _get_rules_by_chain old_rules new_by_chain _get_rules_by_chain new_rules old_chains new_chains set old_by_chain.keys set new_by_chain.keys statements [ ' %s-[0 0]' % c for c in sorted new_chains - old_chains ]sg_chains []other_chains []for chain in sorted old_chains | new_chains if '-sg-' in chain sg_chains.append chain else other_chains.append chain for chain in other_chains + sg_chains statements + _generate_chain_diff_iptables_commands chain old_by_chain[chain] new_by_chain[chain] for chain in sorted old_chains - new_chains statements + [ '-X%s' % chain ]return statements
def get_info app env account container None swift_source None env.setdefault 'swift.infocache' {} if container path '/v1/%s/%s' % account container path_env env.copy path_env['PATH_INFO'] pathreturn get_container_info path_env app swift_source swift_source else path '/v1/%s' % account path_env env.copy path_env['PATH_INFO'] pathreturn get_account_info path_env app swift_source swift_source
def abstract func def wrapper *__args **__kw raise NotImplementedError 'Missingrequired%s method' % func.__name__ wrapper.__name__ func.__name__wrapper.__dict__ func.__dict__wrapper.__doc__ func.__doc__return wrapper
def get_latest_gce_image_for_distribution distribution compute return GCE_DISTRIBUTION_TO_IMAGE_MAP[distribution].get_active_image compute ['selfLink']
def trigger hass event value1 None value2 None value3 None data {ATTR_EVENT event ATTR_VALUE1 value1 ATTR_VALUE2 value2 ATTR_VALUE3 value3}hass.services.call DOMAIN SERVICE_TRIGGER data
def _size_fmt num try num int num if num < 1024 return '{0}bytes'.format num num / 1024.0for unit in 'KiB' 'MiB' 'GiB' 'TiB' 'PiB' if num < 1024.0 return '{0 3.1f}{1}'.format num unit num / 1024.0except Exception log.error "Unabletoformatfilesizefor'{0}'".format num return 'unknown'
def run_dummy_heroku_worker sandbox _imminent_shutdown_delay sys.stderr open os.path.join sandbox u'stderr.log' u'w' class TestHerokuWorker HerokuWorker imminent_shutdown_delay _imminent_shutdown_delaydef perform_job self job queue create_file os.path.join sandbox u'started' for i in range 20 time.sleep 0.1 create_file os.path.join sandbox u'finished' w TestHerokuWorker Queue u'dummy' w.main_work_horse None None
def latency_echo url count poll copy ctx zmq.Context s ctx.socket zmq.REP if poll p zmq.Poller p.register s s.bind url block zmq.NOBLOCK if poll else 0 for i in range count if poll res p.poll msg s.recv block copy copy if poll res p.poll s.send msg block copy copy msg s.recv assert msg 'done' s.close ctx.term
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def decode_from_s3 string errors 'replace' if type string unicode return stringtry return unicode string 'UTF-8' errors except UnicodeDecodeError raise UnicodeDecodeError 'Conversiontounicodefailed %r' % string
@then u'itshouldpasswith' def step_it_should_pass_with context assert context.text is not None 'ENSURE multilinetextisprovided.'step_command_output_should_contain context assert_that context.command_result.returncode equal_to 0 context.command_result.output
def FromString s more_formatters lambda x None _constructor None f StringIO.StringIO s return FromFile f more_formatters more_formatters _constructor _constructor
def test_replace_column_qtable a [1 2 3] * u.m b [4 5 6]t table.QTable [a b] names ['a' 'b'] ta t['a']tb t['b']ta.info.meta {'aa' [0 1 2 3 4]}ta.info.format '%f't.replace_column 'a' a.to 'cm' assert np.all t['a'] ta assert t['a'] is not ta assert t['b'] is tb assert t.colnames ['a' 'b'] assert t['a'].info.meta is None assert t['a'].info.format is None
@frappe.whitelist def get_start_end_dates payroll_frequency start_date None company None if payroll_frequency u'Monthly' or payroll_frequency u'Bimonthly' or payroll_frequency u'' fiscal_year get_fiscal_year start_date company company [0]month u'%02d' % getdate start_date .month m get_month_details fiscal_year month if payroll_frequency u'Bimonthly' if getdate start_date .day < 15 start_date m[u'month_start_date']end_date m[u'month_mid_end_date']else start_date m[u'month_mid_start_date']end_date m[u'month_end_date']else start_date m[u'month_start_date']end_date m[u'month_end_date']if payroll_frequency u'Weekly' end_date add_days start_date 6 if payroll_frequency u'Fortnightly' end_date add_days start_date 13 if payroll_frequency u'Daily' end_date start_datereturn frappe._dict {u'start_date' start_date u'end_date' end_date}
def from_openid_response openid_response issued int time.time sreg_resp sreg.SRegResponse.fromSuccessResponse openid_response or [] ax_resp ax.FetchResponse.fromSuccessResponse openid_response ax_args {}if ax_resp is not None ax_args ax_resp.getExtensionArgs ax_resp.parseExtensionArgs ax_args ax_args ax_resp.datareturn OpenID openid_response.identity_url issued openid_response.signed_fields dict sreg_resp ax_args
@with_setup step_runner_environ def test_steps_that_match_groups_and_named_groups_takes_just_named_as_params @step ' he|she getsa ?P<what>\\w+ ' def given_action_named step what assert_equals what 'caipirinha' f Feature.from_string FEATURE6 feature_result f.run scenario_result feature_result.scenario_results[0]assert_equals len scenario_result.steps_passed 1 assert_equals scenario_result.total_steps 1
def make_rpm_version flocker_version parsed_version parse_version flocker_version installable parsed_version.installable_releaseif is_pre_release installable release ['0' 'rc' parsed_version.pre_release]elif is_weekly_release installable release ['0' 'dev' parsed_version.weekly_release]else release ['1']if parsed_version.commit_count is not None release + [parsed_version.commit_count 'g' + parsed_version.commit_hash ]if parsed_version.dirty release.append 'dirty' return RPMVersion version parsed_version.release release '.'.join release
def xthreaded func return threaded_factory func False
def read_forward_solution_meg *args **kwargs fwd read_forward_solution *args **kwargs fwd pick_types_forward fwd meg True eeg False return fwd
def test_strf_index ea ea.rules[0]['index'] 'logstash-%Y.%m.%d'ea.rules[0]['use_strftime_index'] Truestart ts_to_dt '2015-01-02T12 34 45Z' end ts_to_dt '2015-01-02T16 15 14Z' assert ea.get_index ea.rules[0] start end 'logstash-2015.01.02' end ts_to_dt '2015-01-03T01 02 03Z' assert ea.get_index ea.rules[0] start end 'logstash-2015.01.02 logstash-2015.01.03' assert ea.get_index ea.rules[0] 'logstash-*' ea.rules[0]['index'] 'logstash-%Y.%m'assert ea.get_index ea.rules[0] 'logstash-*' ea.rules[0]['index'] 'logstash-%Y.%m-stuff'assert ea.get_index ea.rules[0] 'logstash-*-stuff'
def get_ip_port_afi host_and_port_str host_and_port_str host_and_port_str.strip if host_and_port_str.startswith '[' af socket.AF_INET6 host rest host_and_port_str[1 ].split ']' if rest port int rest[1 ] else port DEFAULT_KAFKA_PORTreturn host port af elif ' ' not in host_and_port_str af _address_family host_and_port_str return host_and_port_str DEFAULT_KAFKA_PORT af else try socket.inet_pton socket.AF_INET6 host_and_port_str return host_and_port_str DEFAULT_KAFKA_PORT socket.AF_INET6 except AttributeError log.warning 'socket.inet_ptonnotavailableonthisplatform.consider`pipinstallwin_inet_pton`' passexcept ValueError socket.error pass host port host_and_port_str.rsplit ' ' 1 port int port af _address_family host return host port af
def get_access_token_uncached scopes deadline None service_account_id None rpc create_rpc deadline make_get_access_token_call rpc scopes service_account_id service_account_id rpc.wait return rpc.get_result
def list_nodes_select call None return salt.utils.cloud.list_nodes_select list_nodes_full 'function' __opts__['query.selection'] call
def T3 ds count timeperiod - 2 ** 31 vfactor -4e+37 return call_talib_with_ds ds count talib.T3 timeperiod vfactor
def select_directory paths if not paths return core.getcwd for path in paths if core.isdir path return pathreturn os.path.dirname paths[0]
def resource def prep r if r.interactive if r.method in 'create' 'update' table r.tablelocation_id get_vars.get ' location ' None if location_id field table.location_idfield.default location_idfield.readable field.writable Falseorganisation_id get_vars.get ' organisation ' None if organisation_id field table.organisation_idfield.default organisation_idfield.readable field.writable Falsereturn Trues3.prep prepreturn s3_rest_controller
def can_do_meijer a1 a2 b1 b2 numeric True from sympy import unpolarify expandr hyperexpand meijerg a1 a2 b1 b2 z if r.has meijerg return Falser unpolarify expand r force True power_base True power_exp False mul False log False multinomial False basic False if not numeric return Truerepl {}for n a in enumerate meijerg a1 a2 b1 b2 z .free_symbols - {z} repl[a] randcplx n return tn meijerg a1 a2 b1 b2 z .subs repl r.subs repl z
def _keystone_client context version 3 0 auth_plugin identity.Token auth_url CONF.keystone_authtoken.auth_uri token context.auth_token project_id context.project_id client_session ka_loading.session.Session .load_from_options auth auth_plugin insecure CONF.keystone_authtoken.insecure cacert CONF.keystone_authtoken.cafile key CONF.keystone_authtoken.keyfile cert CONF.keystone_authtoken.certfile return client.Client auth_url CONF.keystone_authtoken.auth_uri session client_session version version
def l2_projection f basis lim r 0for b in basis r + l2_inner_product f b lim * b return r
def is_ip_addr value if not isinstance value string_type raise VdtTypeError value value value.strip try dottedQuadToNum value except ValueError raise VdtValueError value return value
def getAreaLoopAbsolute loop return abs getAreaLoop loop
def has_isoread return has_userland_tool 'iso-read'
def set_unittest_reportflags flags global _unittest_reportflagsif flags & REPORTING_FLAGS ! flags raise ValueError 'Onlyreportingflagsallowed' flags old _unittest_reportflags_unittest_reportflags flagsreturn old
def enforce_shopping_cart_enabled func def func_wrapper *args **kwargs '\nWrapperfunctionthatdoestheenforcementthat\ntheshoppingcartfeatureisenabled\n'if not is_shopping_cart_enabled raise Http404return func *args **kwargs return func_wrapper
def key_subtitles subtitle video languages services order key ''for sort_item in order if sort_item LANGUAGE_INDEX key + '{0 03d}'.format len languages - languages.index subtitle.language - 1 key + '{0 01d}'.format subtitle.language languages[languages.index subtitle.language ] elif sort_item SERVICE_INDEX key + '{0 02d}'.format len services - services.index subtitle.service - 1 elif sort_item SERVICE_CONFIDENCE key + '{0 04d}'.format int subtitle.confidence * 1000 elif sort_item MATCHING_CONFIDENCE confidence 0if subtitle.release confidence matching_confidence video subtitle key + '{0 04d}'.format int confidence * 1000 return int key
def cut_after node levels removed if levels 0 removed.extend node.children node.children []else removed_local []for child in node.children if child.visible cut_after child levels - 1 removed else removed_local.append child for removed_child in removed_local node.children.remove removed_child removed.extend removed_local
def mul_shapes lh_shape rh_shape if lh_shape 1 1 return rh_shapeelif rh_shape 1 1 return lh_shapeelse if lh_shape[1] ! rh_shape[0] raise ValueError 'Incompatibledimensions%s%s' % lh_shape rh_shape return lh_shape[0] rh_shape[1]
def constructor_args class_ *args **kwargs argspec inspect.getargspec _constructor class_ return argspec_args argspec True *args **kwargs
def validate_arguments func args kwargs drop_extra True parser _parse_signature func args kwargs missing extra extra_positional parser args kwargs [ 5]if missing raise ArgumentValidationError tuple missing elif extra or extra_positional and not drop_extra raise ArgumentValidationError None extra extra_positional return tuple args kwargs
def test_install_from_local_directory_with_symlinks_to_directories script data to_install data.packages.join 'symlinks' result script.pip 'install' to_install expect_error False pkg_folder script.site_packages / 'symlinks' egg_info_folder script.site_packages / 'symlinks-0.1.dev0-py%s.egg-info' % pyversion assert pkg_folder in result.files_created str result.stdout assert egg_info_folder in result.files_created str result
def _get_gpg_exec gpg_exec salt.utils.which 'gpg' if gpg_exec return gpg_execelse raise SaltRenderError 'GPGunavailable'
def iternext_impl func def wrapper context builder sig args pair_type sig.return_typepairobj context.make_helper builder pair_type func context builder sig args _IternextResult context builder pairobj return impl_ret_borrowed context builder pair_type pairobj._getvalue return wrapper
def serializeObject object_ return base64pickle object_
def potential_energy *body pe_sys S 0 for e in body if isinstance e RigidBody Particle pe_sys + e.potential_energyelse raise TypeError '*bodymusthaveonlyParticleorRigidBody' return pe_sys
def deepcopy x try return _deepcopy_dispatch[type x ] x except KeyError raise Error 'Unsupportedtype%sfordeepcopy.Usecopy.deepcopy' + 'orexpandsimple_copysupport.' % type x
def get_bban_from_iban iban return normalize_iban iban [4 ]
def xml_add_items data try xml ''.join [xml_item item for item in data[config.ITEMS]] except xml xml_dict data return xml
def vsplit ary indices_or_sections if ary.ndim < 1 raise ValueError 'Cannotvsplitanarraywithlessthan2dimensions' return split ary indices_or_sections 0
def subtest_nocleanup function def wrapped self *args **kwds self._cleanup Falseself.decored result function self *args **kwds return resultwrapped.func_name function.func_namereturn wrapped
def entry_from_named_pair register_pairs key results register_pairs.get 'results' if results is None raise RuntimeError "Thedictargumentdoesnothavea'results'entry.Mustnothavebeencreatedusing'register'inaloop" for result in results item result.get 'item' if item is not None name item.get 'name' if name key return result['content']raise RuntimeError 'Therewasnoentryfoundinthedictthathadanitemwithanamethatmatched{}'.format key
def service_location return s3_rest_controller
def get_dims x if isinstance x float or isinstance x int return []elif isinstance x tf.Tensor or isinstance x tf.Variable return x.get_shape .as_list elif isinstance x np.ndarray return list x.shape elif isinstance x RandomVariable return x.get_batch_shape .as_list else raise NotImplementedError
def _pmap_model klass record {u'category' u'map' u'fields' {u'key' sorted fqpn cls for cls in klass._checked_key_types u'value' sorted fqpn cls for cls in klass._checked_value_types }}further_classes set for cls in klass._checked_key_types + klass._checked_value_types further_classes.add cls return record further_classes
def finish_common_config encoding common_config encoding encoding.lower default_top_theme get_default_theme encoding.startswith u'utf' or encoding.startswith u'ucs' common_config common_config.copy common_config.setdefault u'default_top_theme' default_top_theme common_config.setdefault u'paths' [] common_config.setdefault u'watcher' u'auto' common_config.setdefault u'log_level' u'WARNING' common_config.setdefault u'log_format' u'% asctime s % levelname s % message s' common_config.setdefault u'term_truecolor' False common_config.setdefault u'term_escape_style' u'auto' common_config.setdefault u'ambiwidth' 1 common_config.setdefault u'additional_escapes' None common_config.setdefault u'reload_config' True common_config.setdefault u'interval' None common_config.setdefault u'log_file' [None] if not isinstance common_config[u'log_file'] list common_config[u'log_file'] [common_config[u'log_file']]common_config[u'paths'] [os.path.expanduser path for path in common_config[u'paths']]return common_config
def migrate_up manager if db_utils.auth_tables_exist manager management.setup_environ settings from django.contrib.contenttypes import management as content_managementfrom django.contrib.auth import management as auth_managementfrom django.db import models as db_modelscontent_management.update_all_contenttypes for app in db_models.get_apps auth_management.create_permissions app None 2 manager.execute_script migration_059.UP_SQL
def www_authenticate realm key algorithm 'MD5' nonce None qop qop_auth stale False if qop not in valid_qops raise ValueError "Unsupportedvalueforqop '%s'" % qop if algorithm not in valid_algorithms raise ValueError "Unsupportedvalueforalgorithm '%s'" % algorithm if nonce is None nonce synthesize_nonce realm key s 'Digestrealm "%s" nonce "%s" algorithm "%s" qop "%s"' % realm nonce algorithm qop if stale s + ' stale "true"'return s
def p_unary_expression_3 t pass
def get_configuration_errors return cache.get u'configuration-errors' []
def get_needs_reboot return salt.utils.win_update.needs_reboot
def set_virt_pxe_boot self num try inum int num if inum 0 or inum 1 self.virt_pxe_boot inumreturnraise CX _ "invalidvirt_pxe_bootvalue %s valuemustbeeither'0' disabled or'1' enabled " % inum except raise CX _ "invalidvirt_pxe_bootvalue %s valuemustbeeither'0' disabled or'1' enabled " % num
def check_slug list_name try owner slug list_name.split '/' if slug.startswith '@' slug slug[1 ]return owner slug except printNicely light_magenta 'Listnameshouldfollow"@owner/list_name"format.' raise Exception 'Wronglistname'
def search_reverse prog chars col m prog.search chars if not m return Nonefound None i j m.span while i < col and j < col found mif i j j j + 1 m prog.search chars j if not m break i j m.span return found
def get_project request project skip_acl False project get_object_or_404 Project slug project if not skip_acl project.check_acl request return project
def migration_get_unconfirmed_by_dest_compute context confirm_window dest_compute return IMPL.migration_get_unconfirmed_by_dest_compute context confirm_window dest_compute
def _merge_hash option opt_str value parser if not parser.values.hashes parser.values.hashes {}try algo digest value.split ' ' 1 except ValueError parser.error 'Argumentsto%smustbeahashnamefollowedbyavalue like--hash sha256 abcde...' % opt_str if algo not in STRONG_HASHES parser.error 'Allowedhashalgorithmsfor%sare%s.' % opt_str ' '.join STRONG_HASHES parser.values.hashes.setdefault algo [] .append digest
def addparentstofks rels fks for j in rels son index fks j[1] parent index fks j[0] fks[son][2] fks[son][2].replace 'models.Model' parent if parent not in fks[son][0] fks[son][0].append parent
@memoize 'traffic_last_modified' time 60 * 10 def get_traffic_last_modified try return Session.query SitewidePageviews.date .order_by desc SitewidePageviews.date .limit 1 .one .dateexcept NoResultFound return datetime.datetime.min
def getconn obj if not isproxy obj raise TypeError '`obj`isnotaNetProxy' return _get_conn obj
def teardown_module if os.path.isdir SCIKIT_LEARN_DATA shutil.rmtree SCIKIT_LEARN_DATA if os.path.isdir SCIKIT_LEARN_EMPTY_DATA shutil.rmtree SCIKIT_LEARN_EMPTY_DATA
def make_increasing_candle open high low close dates **kwargs increase_x increase_y _Candlestick open high low close dates **kwargs .get_candle_increase if 'line' in kwargs kwargs.setdefault 'fillcolor' kwargs['line']['color'] else kwargs.setdefault 'fillcolor' _DEFAULT_INCREASING_COLOR if 'name' in kwargs kwargs.setdefault 'showlegend' True else kwargs.setdefault 'showlegend' False kwargs.setdefault 'name' 'Increasing' kwargs.setdefault 'line' dict color _DEFAULT_INCREASING_COLOR candle_incr_data dict type 'box' x increase_x y increase_y whiskerwidth 0 boxpoints False **kwargs return [candle_incr_data]
def libvlc_media_player_set_android_context p_mi p_jvm p_awindow_handler f _Cfunctions.get 'libvlc_media_player_set_android_context' None or _Cfunction 'libvlc_media_player_set_android_context' 1 1 1 None None MediaPlayer ctypes.c_void_p ctypes.c_void_p return f p_mi p_jvm p_awindow_handler
def events request if not test_user_authenticated request return login request next '/cobbler_web/events' expired True events remote.get_events events2 []for id in events.keys ttime name state read_by events[id]events2.append [id time.asctime time.localtime ttime name state] def sorter a b return cmp a[0] b[0] events2.sort sorter t get_template 'events.tmpl' html t.render RequestContext request {'results' events2 'version' remote.extended_version request.session['token'] ['version'] 'username' username} return HttpResponse html
def getLocalAttributeValueString key valueString augmentedStatements '+ - * / % ** '.split for augmentedStatement in augmentedStatements if valueString.startswith augmentedStatement return key + augmentedStatement[ -1 ] + valueString[len augmentedStatement ] return valueString
def check_entrance_exam_problems_for_rescoring exam_key problems get_problems_in_section exam_key .values if any not hasattr problem 'module_class' or not hasattr problem.module_class 'rescore_problem' for problem in problems msg _ 'Notallproblemsinentranceexamsupportre-scoring.' raise NotImplementedError msg
def test_sharedmethod_reuse_on_subclasses class AMeta type def foo cls return cls.xsix.add_metaclass AMeta class A object x 3def __init__ self x self.x x@sharedmethoddef foo self return self.xa1 A 1 a2 A 2 assert a1.foo 1 assert a2.foo 2 assert A.foo 3 class B A x 5assert B.foo 5
def get_setter_methods_from_fields item fields setters {}for elem in fields name elem[0].replace '*' '' setters[name] getattr item 'set_%s' % name if item.COLLECTION_TYPE 'system' setters['modify_interface'] getattr item 'modify_interface' setters['delete_interface'] getattr item 'delete_interface' setters['rename_interface'] getattr item 'rename_interface' return setters
def locattr accessing_obj accessed_obj *args **kwargs if hasattr accessing_obj 'obj' accessing_obj accessing_obj.objif hasattr accessing_obj 'location' return attr accessing_obj.location accessed_obj *args **kwargs
def getVector3Path complexPath z 0.0 vector3Path []for complexPoint in complexPath vector3Path.append Vector3 complexPoint.real complexPoint.imag z return vector3Path
def csm_indptr csm return csm_properties csm [2]
def maybe_expression s if not isinstance s string_types return Falseops ExprVisitor.binary_ops + ExprVisitor.unary_ops + ' ' return any op in s for op in ops
def corner_harris image method 'k' k 0.05 eps 1e-06 sigma 1 Axx Axy Ayy structure_tensor image sigma detA Axx * Ayy - Axy ** 2 traceA Axx + Ayy if method 'k' response detA - k * traceA ** 2 else response 2 * detA / traceA + eps return response
def get_repr obj constructor False **attrs cls qualname obj.__class__ parts []items sorted attrs.items for name val in items parts.append '{} {!r}'.format name val if constructor return '{} {} '.format cls ' '.join parts elif parts return '<{}{}>'.format cls ''.join parts else return '<{}>'.format cls
def test_prewitt_v_zeros result filters.prewitt_v np.zeros 10 10 np.ones 10 10 bool assert_allclose result 0
def libvlc_vlm_add_broadcast p_instance psz_name psz_input psz_output i_options ppsz_options b_enabled b_loop f _Cfunctions.get 'libvlc_vlm_add_broadcast' None or _Cfunction 'libvlc_vlm_add_broadcast' 1 1 1 1 1 1 1 1 None ctypes.c_int Instance ctypes.c_char_p ctypes.c_char_p ctypes.c_char_p ctypes.c_int ListPOINTER ctypes.c_char_p ctypes.c_int ctypes.c_int return f p_instance psz_name psz_input psz_output i_options ppsz_options b_enabled b_loop
def find_locustfile locustfile names [locustfile]if not names[0].endswith '.py' names + [ names[0] + '.py' ]if os.path.dirname names[0] for name in names expanded os.path.expanduser name if os.path.exists expanded if name.endswith '.py' or _is_package expanded return os.path.abspath expanded else path '.'while os.path.split os.path.abspath path [1] for name in names joined os.path.join path name if os.path.exists joined if name.endswith '.py' or _is_package joined return os.path.abspath joined path os.path.join '..' path
@block_user_agents@login_required@permission_required 'wiki.delete_document' @check_readonly@process_document_pathdef delete_document request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug prevent document.children.exists first_revision document.revisions.all [0]if request.method 'POST' form DocumentDeletionForm data request.POST if form.is_valid DocumentDeletionLog.objects.create locale document.locale slug document.slug user request.user reason form.cleaned_data['reason'] document.delete return redirect document else form DocumentDeletionForm context {'document' document 'form' form 'request' request 'revision' first_revision 'prevent' prevent}return render request 'wiki/confirm_document_delete.html' context
def test_relative_requirements_file script data url path_to_url os.path.join data.root 'packages' '..' 'packages' 'FSPkg' + '#egg FSPkg' script.scratch_path.join 'file-egg-req.txt' .write textwrap.dedent '%s\n' % url result script.pip 'install' '-vvv' '-r' script.scratch_path / 'file-egg-req.txt' assert script.site_packages / 'FSPkg-0.1.dev0-py%s.egg-info' % pyversion in result.files_created str result assert script.site_packages / 'fspkg' in result.files_created str result.stdout
def lookupCanonicalName name timeout None return getResolver .lookupCanonicalName name timeout
def send_mail sender_email recipient_email subject plaintext_body html_body bcc_admin False if not feconf.MAILGUN_API_KEY raise Exception 'MailgunAPIkeyisnotavailable.' if not feconf.MAILGUN_DOMAIN_NAME raise Exception 'Mailgundomainnameisnotset.' mailgun_domain_name 'https //api.mailgun.net/v3/%s/messages' % feconf.MAILGUN_DOMAIN_NAME if not feconf.CAN_SEND_EMAILS raise Exception 'Thisappcannotsendemailstousers.' data {'from' sender_email 'to' recipient_email 'subject' subject 'text' plaintext_body 'html' html_body}if bcc_admin data['bcc'] feconf.ADMIN_EMAIL_ADDRESSrequests.post mailgun_domain_name auth 'api' feconf.MAILGUN_API_KEY data data
def test_get_new_command assert get_new_command Command u'ps-ef|\xa0grepfoo' 'ps-ef|grepfoo'
def load_scores_wiggle fname chrom_buffer_size 3 scores_by_chrom dict try for chrom pos val in bx.wiggle.Reader UCSCOutWrapper open fname if chrom not in scores_by_chrom if chrom_buffer_size scores_by_chrom[chrom] BinnedArray chrom_buffer_size - 1else scores_by_chrom[chrom] PositionalScoresOnDisk scores_by_chrom[chrom][pos] valexcept UCSCLimitException print 'EncounteredmessagefromUCSC "Reachedoutputlimitof100000datavalues" sobeawareyourdatawastruncated.' except IndexError stop_err 'Dataerror oneormorecolumndatavaluesismissingin"%s"' % fname except ValueError stop_err 'Dataerror invaliddatatypeforoneormorevaluesin"%s".' % fname return scores_by_chrom
def contextwin l win assert win % 2 1 assert win > 1 l list l lpadded win // 2 * [ -1 ] + l + win // 2 * [ -1 ] out [lpadded[i i + win ] for i in range len l ]assert len out len l return out
def test_cylinder md create_cylinder 10 20 radius [10 10] radii np.sqrt md.get_vertices [ 2] ** 2 .sum axis 1 assert_allclose radii np.ones_like radii * 10
def use_library name version if name not in PACKAGES raise ValueError '%sisnotasupportedpackage' % name versions PACKAGES[name][1].keys if version not in versions raise ValueError '%sisnotasupportedversionfor%s;supportedversionsare%s' % version name versions if USING_SDK CheckInstalledLibrary name version else InstallLibrary name version explicit True
def outer_atomic using None savepoint True read_committed False name None if callable using return OuterAtomic DEFAULT_DB_ALIAS savepoint read_committed using else return OuterAtomic using savepoint read_committed name
def set_score user_id usage_key score max_score student_module created StudentModule.objects.get_or_create student_id user_id module_state_key usage_key course_id usage_key.course_key defaults {'grade' score 'max_grade' max_score} if not created student_module.grade scorestudent_module.max_grade max_scorestudent_module.save return student_module.modified
def getExtensions extensions []if not sys.platform.startswith 'java' for dir in os.listdir 'twisted' + [''] topfiles os.path.join 'twisted' dir 'topfiles' if os.path.isdir topfiles ns {}setup_py os.path.join topfiles 'setup.py' execfile setup_py ns ns if 'extensions' in ns extensions.extend ns['extensions'] return extensions
def Document docx None docx _default_docx_path if docx is None else docx document_part Package.open docx .main_document_partif document_part.content_type ! CT.WML_DOCUMENT_MAIN tmpl "file'%s'isnotaWordfile contenttypeis'%s'"raise ValueError tmpl % docx document_part.content_type return document_part.document
def volume_type_qos_disassociate context qos_specs_id type_id return IMPL.volume_type_qos_disassociate context qos_specs_id type_id
def get_aggregate_function name _create_function_dict return _function_dict[name]
def imp_type_for_filename filename for type_data in imp.get_suffixes extension type_data[0]if filename.endswith extension return type_datareturn None
def strip_proto url return re.sub '^[^ /]+ //' '' url
def maven_builder registry xml_parent data maven XML.SubElement xml_parent 'org.jfrog.hudson.maven3.Maven3Builder' mapping [ 'name' 'mavenName' None 'goals' 'goals' None 'pom' 'rootPom' 'pom.xml' 'maven-opts' 'mavenOpts' '' ]convert_mapping_to_xml maven data mapping fail_required True
def _restore_plugin_configs config renewalparams if renewalparams['authenticator'] 'webroot' _restore_webroot_config config renewalparams plugin_prefixes []else plugin_prefixes [renewalparams['authenticator']]if renewalparams.get 'installer' None is not None plugin_prefixes.append renewalparams['installer'] for plugin_prefix in set plugin_prefixes plugin_prefix plugin_prefix.replace '-' '_' for config_item config_value in six.iteritems renewalparams if config_item.startswith plugin_prefix + '_' and not cli.set_by_cli config_item if config_value in 'None' 'True' 'False' setattr config.namespace config_item eval config_value else cast cli.argparse_type config_item setattr config.namespace config_item cast config_value
def expression_ok expression expression_ok Truefields expression.split for f in fields try if f.endswith ' 2' f f[ -2 ]if mavutil.evaluate_expression f mestate.status.msgs is None expression_ok Falseexcept Exception expression_ok Falsebreakreturn expression_ok
def s3_str s if type s is str return selse return s3_unicode s .encode 'utf-8' 'strict'
def test_create_wedge_text polar_cats text_data build_wedge_text_source polar_cats assert isinstance text_data ColumnDataSource assert all col in text_data.column_names for col in ['x' 'y' 'text' 'text_angle'] is True
def test_mod x y fscalars 'xy' fn gof.DualLinker .accept gof.FunctionGraph [x y] [ x % y ] .make_function for a b in 0 1 1 1 0 -1 1 -1 -1 -1 1 2 -1 2 1 -2 -1 -2 5 3 -5 3 5 -3 -5 -3 assert fn a b a % b a
def is_non_string_sequence obj return not isinstance obj six.string_types and isinstance obj Sequence
def p_initializer_list_2 t pass
@task base BaseInstructorTask routing_key settings.GRADES_DOWNLOAD_ROUTING_KEY def calculate_problem_responses_csv entry_id xmodule_instance_args action_name ugettext_noop 'generated' task_fn partial upload_problem_responses_csv xmodule_instance_args return run_main_task entry_id task_fn action_name
def guess_vfs_zfs_arc_max if HW_PHYSMEM_GB > 200 and TRUENAS return int max min int HW_PHYSMEM * 0.92 HW_PHYSMEM - USERLAND_RESERVED_MEM + KERNEL_RESERVED_MEM MIN_ZFS_RESERVED_MEM else return int max min int HW_PHYSMEM * 0.9 HW_PHYSMEM - USERLAND_RESERVED_MEM + KERNEL_RESERVED_MEM MIN_ZFS_RESERVED_MEM
def rot_axis1 theta ct cos theta st sin theta lil 1 0 0 0 ct st 0 - st ct return Matrix lil
def _raises_invalid_signature **kwargs return Raises MatchesException InvalidSignature Equals InvalidSignature **kwargs
def boxcox_normplot x la lb plot None N 80 x np.asarray x if x.size 0 return xif lb < la raise ValueError '`lb`hastobelargerthan`la`.' lmbdas np.linspace la lb num N ppcc lmbdas * 0.0 for i val in enumerate lmbdas z boxcox x lmbda val _ r2 probplot z dist 'norm' fit True ppcc[i] r2[ -1 ]if plot is not None plot.plot lmbdas ppcc 'x' _add_axis_labels_title plot xlabel '$\\lambda$' ylabel 'ProbPlotCorr.Coef.' title 'Box-CoxNormalityPlot' return lmbdas ppcc
def numa_fit_instance_to_host host_topology instance_topology limits None pci_requests None pci_stats None if not host_topology and instance_topology LOG.debug 'RequirebothahostandinstanceNUMAtopologytofitinstanceonhost.' returnelif len host_topology < len instance_topology LOG.debug 'TherearenotenoughNUMAnodesonthesystemtoscheduletheinstancecorrectly.Required % required s actual % actual s' {'required' len instance_topology 'actual' len host_topology } returnfor host_cell_perm in itertools.permutations host_topology.cells len instance_topology cells []for host_cell instance_cell in zip host_cell_perm instance_topology.cells try got_cell _numa_fit_instance_cell host_cell instance_cell limits except exception.MemoryPageSizeNotSupported breakif got_cell is None breakcells.append got_cell if len cells ! len host_cell_perm continueif not pci_requests or pci_stats is not None and pci_stats.support_requests pci_requests cells return objects.InstanceNUMATopology cells cells
@FileSystem.in_directory current_directory 'django' 'celeries' def test_failfast status output run_scenario **{'--failfast' None} the output .should.contain 'Thisoneispresent' the output .should.contain 'Celeriesbeforeall' the output .should.contain 'Celeriesbeforeharvest' the output .should.contain "Celeriesbeforefeature'Testthedjangoappleaves'" the output .should.contain "Celeriesbeforescenario'Thisoneispresent'" the output .should.contain "Celeriesbeforestep'GivenIsayfoobar'" the output .should.contain "Celeriesafterstep'GivenIsayfoobar'" the output .should.contain "Celeriesbeforestep'Thenitfails'" the output .should.contain "Celeriesafterstep'Thenitfails'" the output .should.contain "Celeriesafterscenario'Thisoneispresent'" the output .should.contain "Celeriesafterfeature'Testthedjangoappleaves'" the output .should.contain 'Celeriesafterharvest' the output .should.contain 'Celeriesafterall' the output .should_not.contain 'Thisoneisnevercalled'
def time_a_while_ago days 0 seconds 0 microseconds 0 milliseconds 0 minutes 0 hours 0 weeks 0 delta timedelta days seconds microseconds milliseconds minutes hours weeks return datetime.utcnow - delta
def quopri_decode input errors 'strict' assert errors 'strict' f StringIO str input g StringIO quopri.decode f g output g.getvalue return output len input
def validate_host_mapping host_mapping schema {'$schema' 'http //json-schema.org/draft-04/schema#' 'type' 'object' 'additionalProperties' 'true'}v Draft4Validator schema format_checker FormatChecker v.validate host_mapping
def get_lang_from_http_header request supported accept request.META.get 'HTTP_ACCEPT_LANGUAGE' '' for accept_lang __ in trans_real.parse_accept_lang_header accept if accept_lang '*' return Nonenormalized data.normalize_code data.simplify_to_common accept_lang if normalized in ['en-us' 'en'] return Noneif normalized in supported return normalizedfor lang in supported.keys if normalized data.normalize_code lang return langreturn None
def compare_elements a b if a is None a []if b is None b []return set a set b
def create_url_helper base_url base_url base_url.rstrip '/' def url_for path '' if path path '/' + path.strip '/' return base_url + path return url_for
def check_flow_information evaluator flow search_name pos if not settings.dynamic_flow_information return Noneresult set if flow.is_scope try names reversed flow.names_dict[search_name.value] except KeyError AttributeError names []for name in names ass name.get_parent_until tree.AssertStmt if isinstance ass tree.AssertStmt and pos is not None and ass.start_pos < pos result _check_isinstance_type evaluator ass.assertion search_name if result breakif isinstance flow tree.IfStmt tree.WhileStmt potential_ifs [c for c in flow.children[1 4] if c ! ' ' ]for if_test in reversed potential_ifs if search_name.start_pos > if_test.end_pos return _check_isinstance_type evaluator if_test search_name return result
def tree_post_save_handler sender instance **kwargs instance.get_descendants include_self True .update _ct_inventory None
def restore_long_table_names for table in metadata.tables.values table.name table._original_namedel table._original_name
def new_bookmark_collection user Collection apps.get_model 'osf.Collection' existing_bookmark_collection Collection.find Q 'is_bookmark_collection' 'eq' True & Q 'creator' 'eq' user if existing_bookmark_collection.count > 0 raise NodeStateError 'Usersmayonlyhaveonebookmarkcollection' collection Collection title 'Bookmarks' creator user is_bookmark_collection True collection.save return collection
def _ReferenceFromReference reference new_reference entity_pb.Reference new_reference.CopyFrom reference return new_reference
def make_extension trigger None default_name None priority None invoke_before_training False finalizer None if trigger is None trigger Extension.triggerif priority is None priority Extension.prioritydef decorator ext ext.trigger triggerext.default_name default_name or ext.__name__ ext.priority priorityext.invoke_before_training invoke_before_trainingext.finalize finalizerreturn extreturn decorator
def oc_cmd_mock cmd oadm False output False output_type 'json' input_data None version 'ocv3.4.0.39\nkubernetesv1.4.0+776c994\nfeatures Basic-AuthGSSAPIKerberosSPNEGO\n\nServerhttps //internal.api.opstest.openshift.com\nopenshiftv3.4.0.39\nkubernetesv1.4.0+776c994\n'if 'version' in cmd return {'stderr' None 'stdout' version 'returncode' 0 'results' version 'cmd' cmd}
def isList l return hasattr l '__iter__' and not isString l or type l in types.ListType types.TupleType
def test_text_elide_none mocker qtbot label TextBase qtbot.add_widget label label.setText '' mocker.patch 'qutebrowser.mainwindow.statusbar.textbase.TextBase.fontMetrics' label._update_elided_text 20 assert not label.fontMetrics.called
def set_external_opts_defaults cors.set_defaults allow_headers ['X-Auth-Token' 'X-Openstack-Request-Id' 'X-Subject-Token' 'X-Project-Id' 'X-Project-Name' 'X-Project-Domain-Id' 'X-Project-Domain-Name' 'X-Domain-Id' 'X-Domain-Name'] expose_headers ['X-Auth-Token' 'X-Openstack-Request-Id' 'X-Subject-Token'] allow_methods ['GET' 'PUT' 'POST' 'DELETE' 'PATCH'] profiler.set_defaults CONF enabled False trace_sqlalchemy False opts cache._opts.list_opts for opt_list in opts if opt_list[0] 'cache' for o in opt_list[1] if o.name 'enabled' o.default True
def PCO_option_dispatcher s option ord s[0] cls PCO_OPTION_CLASSES.get option Raw return cls s
def zip_format request context {'title' 'ZippedSourceInstruction'}template 'general/zip.html'return render request template context
def get_git_revision repopath try git programs.find_program 'git' assert git is not None and osp.isdir osp.join repopath '.git' commit programs.run_program git ['rev-parse' '--short' 'HEAD'] cwd repopath .communicate commit commit[0].strip if PY3 commit commit.decode sys.getdefaultencoding branches programs.run_program git ['branch'] cwd repopath .communicate branches branches[0]if PY3 branches branches.decode sys.getdefaultencoding branches branches.split '\n' active_branch [b for b in branches if b.startswith '*' ]if len active_branch ! 1 branch Noneelse branch active_branch[0].split None 1 [1]return commit branch except subprocess.CalledProcessError AssertionError AttributeError return None None
def splitport host global _portprogif _portprog is None import re_portprog re.compile '^ .* [0-9]+ $' match _portprog.match host if match return match.group 1 2 return host None
def p_command_def p p[0] 'FUNC' p[2] p[4] p[7]
def hierarchical_cuboids dimensions required None default_only False cuboids combined_cuboids dimensions required result []for cuboid in cuboids result + list combined_levels cuboid default_only return result
def block_devices attrs None where None return _osquery_cmd table 'block_devices' attrs attrs where where
def SwallowArgs func @functools.wraps func def Decorator arg *unused_args return func arg return Decorator
def get_sample_func model layer_to_state x theano_rng MRG_RandomStreams 2012 + 9 + 18 if x > 0 sampling_updates model.get_sampling_updates layer_to_state theano_rng layer_to_clamp {model.visible_layer True} num_steps x t1 time.time sample_func function [] updates sampling_updates t2 time.time print 'Clampedsamplingfunctioncompilationtook' t2 - t1 sample_func sampling_updates model.get_sampling_updates layer_to_state theano_rng assert layer_to_state[model.visible_layer] in sampling_updates t1 time.time sample_func function [] updates sampling_updates t2 time.time print 'Samplingfunctioncompilationtook' t2 - t1 return sample_func
def get_ident return -1
def assert_has_n_columns output n sep ' DCTB ' n int n first_line get_first_line output assert first_line is not None 'Wasexpectingoutputwith%dcolumns butoutputwasempty.' % n assert len first_line.split sep n 'Outputdoesnothave%dcolumns.' % n
def filter_stack graph head filters visited removes orphans set [head] set set stack deque [ head head ] get_data graph.node_dataget_edges graph.out_edgesget_tail graph.tailwhile stack last_good node stack.pop data get_data node if data is not None for filtfunc in filters if not filtfunc data removes.add node breakelse last_good nodefor edge in get_edges node tail get_tail edge if last_good is not node orphans.add last_good tail if tail not in visited visited.add tail stack.append last_good tail orphans [ last_good tail for last_good tail in orphans if tail not in removes ]return visited removes orphans
def vowel_consonant_pairs w max None m 0for i ch in enumerate w if is_vowel ch and i < len w - 1 and is_consonant w[ i + 1 ] m + 1if m max breakreturn m
def create_snapshot_body indices ignore_unavailable False include_global_state True partial False if not indices logger.error 'Noindicesprovided.' return Falsebody {'ignore_unavailable' ignore_unavailable 'include_global_state' include_global_state 'partial' partial}if indices '_all' body['indices'] indiceselse body['indices'] to_csv indices return body
def _open_library config dbpath util.bytestring_path config['library'].as_filename try lib library.Library dbpath config['directory'].as_filename get_path_formats get_replacements lib.get_item 0 except sqlite3.OperationalError sqlite3.DatabaseError log.debug u'{}' traceback.format_exc raise UserError u'databasefile{0}couldnotbeopened'.format util.displayable_path dbpath log.debug u'librarydatabase {0}\nlibrarydirectory {1}' util.displayable_path lib.path util.displayable_path lib.directory return lib
def set_useragent app version contact None global _useragent _clientif not app or not version raise ValueError 'Appandversioncannotbeempty' if contact is not None _useragent '%s/%spython-musicbrainzngs/%s %s ' % app version _version contact else _useragent '%s/%spython-musicbrainzngs/%s' % app version _version _client '%s-%s' % app version _log.debug 'setuser-agentto%s' % _useragent
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def resource_mapping return {'OS Heat ResourceChain' ResourceChain}
def split filenames format_string shards parsed_formats parser.parse format_string sizes [files.stat filename .st_size for filename in filenames]size_per_shard float sum sizes / shards if not size_per_shard returnif parsed_formats[0].can_split return _deep_split filenames size_per_shard parsed_formats else return _shallow_split filenames size_per_shard parsed_formats sizes
@require_http_methods ['POST'] def password_change_request_handler request limiter BadRequestRateLimiter if limiter.is_rate_limit_exceeded request AUDIT_LOG.warning 'Passwordresetratelimitexceeded' return HttpResponseForbidden user request.useremail user.email if user.is_authenticated else request.POST.get 'email' if email try request_password_change email request.get_host request.is_secure user user if user.is_authenticated else User.objects.get email email destroy_oauth_tokens user except UserNotFound AUDIT_LOG.info 'Invalidpasswordresetattempt' limiter.tick_bad_request_counter request return HttpResponse status 200 else return HttpResponseBadRequest _ 'Noemailaddressprovided.'
def override_timeout timeout action retval timeoutif action in ['forcemerge' 'snapshot' 'sync_flush'] if timeout 30 if action in ['forcemerge' 'snapshot'] retval 21600elif action 'sync_flush' retval 180logger.debug 'Overridingdefaultconnectiontimeoutfor{0}action.Newtimeout {1}'.format action.upper timeout return retval
def bump_cache_for_shop_product shop_product from shuup.core.models import ShopProductbump_cache_for_item shop_product bump_cache_for_item shop_product.product q Q q | Q product__variation_parent_id shop_product.product if shop_product.product.variation_parent q | Q product_id shop_product.product.variation_parent.id for child in ShopProduct.objects.filter q .select_related 'product' bump_cache_for_item child bump_cache_for_item child.product if shop_product.product.is_package_child for package_parent in shop_product.product.get_all_package_parents for sp in ShopProduct.objects.filter product_id package_parent.id bump_cache_for_item sp bump_cache_for_item sp.product
def symptom_caching_enabled_without_a_backend return CONF.cache.enabled and CONF.cache.backend 'dogpile.cache.null'
def get_value_from_json json_dict sensor_type group tool if group in json_dict if sensor_type in json_dict[group] if sensor_type 'target' and json_dict[sensor_type] is None return 0else return json_dict[group][sensor_type]elif tool is not None if sensor_type in json_dict[group][tool] return json_dict[group][tool][sensor_type]
def _TagSize field_number return _VarintSize wire_format.PackTag field_number 0
def modpath_from_file filename extrapath None base splitext abspath filename [0]if extrapath is not None for path_ in extrapath path abspath path_ if path and base[ len path ] path submodpath [pkg for pkg in base[len path ].split os.sep if pkg]if _check_init path submodpath[ -1 ] return extrapath[path_].split '.' + submodpath for path in sys.path path abspath path if path and base.startswith path modpath [pkg for pkg in base[len path ].split os.sep if pkg]if _check_init path modpath[ -1 ] return modpathraise ImportError 'Unabletofindmodulefor%sin%s' % filename ' \n'.join sys.path
def expand_log expr deep True force False return sympify expr .expand deep deep log True mul False power_exp False power_base False multinomial False basic False force force
def acl_represent acl options values []for o in options.keys if o 0 and acl 0 values.append '%s' % options[o][0] elif acl and acl & o o values.append '%s' % options[o][0] else values.append '_' return ''.join values
@blueprint.route '/sources/<source>/resources' def list_resources_by_source source return _list_resources source source project acl.get_limited_to_project flask.request.headers
def test_multiclass_fit_sample y Y.copy y[5] 2y[6] 2rus RandomUnderSampler random_state RND_SEED X_resampled y_resampled rus.fit_sample X y count_y_res Counter y_resampled assert_equal count_y_res[0] 2 assert_equal count_y_res[1] 2 assert_equal count_y_res[2] 2
def description_of file name 'stdin' u UniversalDetector for line in file u.feed line u.close result u.resultif result['encoding'] return '%s %swithconfidence%s' % name result['encoding'] result['confidence'] else return '%s noresult' % name
def scale s dtype None assert len s 3 return np.array np.diag np.concatenate [s 1.0 ] dtype
def rvm_env registry xml_parent data rpo XML.SubElement xml_parent 'ruby-proxy-object' ro_class 'Jenkins Plugin Proxies BuildWrapper'ro XML.SubElement rpo 'ruby-object' {'ruby-class' ro_class 'pluginid' 'rvm'} o XML.SubElement ro 'object' {'ruby-class' 'RvmWrapper' 'pluginid' 'rvm'} XML.SubElement o 'impl' {'pluginid' 'rvm' 'ruby-class' 'String'} .text data['implementation']XML.SubElement ro 'pluginid' {'pluginid' 'rvm' 'ruby-class' 'String'} .text 'rvm'
def _surface_constraint rd surf min_dist_to_inner_skull dist _compute_nearest surf['rr'] rd[np.newaxis ] return_dists True [1][0]if _points_outside_surface rd[np.newaxis ] surf 1 [0] dist * -1.0 dist - min_dist_to_inner_skullreturn dist
def make_pony app global_conf return PonyMiddleware app
def _root_notice msg *args **kwargs if len logging.root.handlers 0 logging.basicConfig logging.root.notice msg *args **kwargs
def runTests vm tests None pre '' post '' prompt Prompt uninstallNtpd False if uninstallNtpd removeNtpd vm vm.expect prompt if Branch checkOutBranch vm branch Branch vm.expect prompt if not tests tests []if pre log '*Runningcommand' pre vm.sendline pre vm.expect prompt testfns testDict if tests log '*Runningtests' for test in tests if test not in testfns raise Exception 'Unknowntest ' + test log '*Runningtest' test fn testfns[test]fn vm vm.expect prompt if post log '*Runningpost-testcommand' post vm.sendline post vm.expect prompt
def subscribe_with_data mailchimp list_id user_data format_entry lambda e {name_to_tag k v for k v in e.iteritems } formated_data list format_entry e for e in user_data for batch in chunk formated_data SUBSCRIBE_BATCH_SIZE result mailchimp.listBatchSubscribe id list_id batch batch double_optin False update_existing True log.debug 'Added %sErroron %s' result['add_count'] result['error_count']
def group_backend_by_type items key lambda x x from social_auth.backends import get_backends BaseOAuth BaseOAuth2result defaultdict list backends get_backends for item in items backend backends[key item ]if issubclass backend BaseOAuth2 result['oauth2'].append item elif issubclass backend BaseOAuth result['oauth'].append item return dict result
def get_i3_connection global connif not conn try import i3ipcexcept ImportError import i3 as connelse conn i3ipc.Connection return conn
def get_updated_instructor_task task_id try instructor_task InstructorTask.objects.get task_id task_id except InstructorTask.DoesNotExist log.warning 'queryforInstructorTaskstatusfailed task_id %s notfound' task_id return Noneif instructor_task.task_state not in READY_STATES result AsyncResult task_id _update_instructor_task instructor_task result return instructor_task
@require_POSTdef join_group request url group get_object_or_404 Group url url profile_to_add request.user.userprofileif group.has_member profile_to_add messages.error request _ 'Youarealreadyinthisgroup.' elif group.has_pending_member profile_to_add messages.error request _ 'Yourrequesttojointhisgroupisstillpending.' elif group.accepting_new_members 'no' messages.error request _ 'Thisgroupisnotacceptingrequeststojoin.' else if group.accepting_new_members 'yes' status GroupMembership.MEMBERmessages.info request _ 'Youhavebeenaddedtothisgroup.' if group.terms status GroupMembership.PENDING_TERMSelif group.accepting_new_members 'by_request' status GroupMembership.PENDINGmessages.info request _ 'Yourmembershiprequesthasbeensenttothegroupcurator s .' group.add_member profile_to_add status status return redirect reverse 'groups show_group' args [group.url]
def mulrowcol row col K result K.zerofor i in range len row result + row[i] * col[i] return result
def _exception_pprint obj p cycle name getattr obj.__class__ '__qualname__' obj.__class__.__name__ if obj.__class__.__module__ not in 'exceptions' 'builtins' name '%s.%s' % obj.__class__.__module__ name step len name + 1 p.begin_group step name + ' ' for idx arg in enumerate getattr obj 'args' if idx p.text ' ' p.breakable p.pretty arg p.end_group step ' '
def _coerce_scalar_to_timedelta_type r unit 'ns' box True errors 'raise' try result tslib.convert_to_timedelta64 r unit except ValueError if errors 'raise' raiseelif errors 'ignore' return rresult pd.NaTif box result tslib.Timedelta result return result
def test_pl_fancy o nikola.utils.slugify u'Za\u017c\xf3\u0142\u0107g\u0119\u015bl\u0105ja\u017a\u0144!-123.456' lang u'pl' assert o u'zazolc-gesla-jazn-123456' assert isinstance o nikola.utils.unicode_str
def detect_periodical toc log None if toc.count < 1 or not toc[0].klass u'periodical' return Falsefor node in toc.iterdescendants if node.depth 1 and node.klass ! u'article' if log is not None log.debug u'Notaperiodical Deepestnodedoesnothaveclass "article"' return Falseif node.depth 2 and node.klass ! u'section' if log is not None log.debug u'Notaperiodical Seconddeepestnodedoesnothaveclass "section"' return Falseif node.depth 3 and node.klass ! u'periodical' if log is not None log.debug u'Notaperiodical Thirddeepestnodedoesnothaveclass "periodical"' return Falseif node.depth > 3 if log is not None log.debug u'Notaperiodical Hasnodesofdepth>3' return Falsereturn True
def getSkeinforgePath subName '' return getJoinedPath getFabmetheusPath 'skeinforge_application' subName
def uri_reference uri encoding 'utf-8' return URIReference.from_string uri encoding
@not_implemented_for 'directed' def connected_component_subgraphs G copy True for c in connected_components G if copy yield G.subgraph c .copy else yield G.subgraph c
def get_templates dirs templates set for root in dirs for dirpath dirnames filenames in os.walk root for f in filenames if len [True for e in TEMPLATE_EXTENSIONS if f.endswith e ] > 0 t make_template_info os.path.join dirpath f dirs t.all_templates templatestemplates.add t return templates
def deprecated version replacement None def deprecationDecorator function '\nDecoratorthatmarksC{function}asdeprecated.\n'warningString getDeprecationWarningString function version None replacement @wraps function def deprecatedFunction *args **kwargs warn warningString DeprecationWarning stacklevel 2 return function *args **kwargs _appendToDocstring deprecatedFunction _getDeprecationDocstring version replacement deprecatedFunction.deprecatedVersion versionreturn deprecatedFunctionreturn deprecationDecorator
def p_command_if_bad2 p p[0] 'INVALIDLINENUMBERINTHEN'
def quota_class_get_defaults context return IMPL.quota_class_get_defaults context
def __methodDict cls _dict baseList list cls.__bases__ baseList.reverse for _super in baseList __methodDict _super _dict for key value in cls.__dict__.items if type value types.FunctionType _dict[key] value
def nll_loss input target weight None size_average True return _functions.thnn.NLLLoss size_average weight weight input target
def _TestUpdateFollower tester user_cookie request_dict user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict actual_dict tester.SendRequest 'update_follower' user_cookie request_dict op_dict tester._DeriveNotificationOpDict user_id device_id request_dict _ValidateUpdateFollower tester user_cookie op_dict request_dict['follower'] tester._CompareResponseDicts 'update_follower' user_id request_dict {} actual_dict return actual_dict
def hue1_to_hue2_data_migration jd_list JobDesign.objects.all for jd in jd_list if jd.type 'jar' job_design_migration_for_jar jd elif jd.type 'streaming' job_design_migration_for_streaming jd else LOG.warn "UnknownJobDesigntype'%s'intheoldtable.Rowid %s" % jd.type jd.id
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def get_interval return 10
def demean x axis 0 return detrend_mean x axis axis
def recurse *cls def wrap f def wrapped_f tlist for sgroup in tlist.get_sublists if not isinstance sgroup cls wrapped_f sgroup f tlist return wrapped_freturn wrap
def turan_graph n r if not 1 < r < n raise nx.NetworkXError 'Mustsatisfy1< r< n' partitions [ n // r ] * r - n % r + [ n // r + 1 ] * n % r G complete_multipartite_graph *partitions G.name 'turan_graph {} {} '.format n r return G
def addNestedRingBeginning distanceFeedRate loop z distanceFeedRate.addLine ' <nestedRing> ' distanceFeedRate.addLine ' <boundaryPerimeter> ' for point in loop pointVector3 Vector3 point.real point.imag z distanceFeedRate.addLine distanceFeedRate.getBoundaryLine pointVector3
def add_pool_member lb name port pool_name if __opts__['load_balancers'].get lb None username password list __opts__['load_balancers'][lb].values else raise Exception 'Unabletofind`{0}`loadbalancer'.format lb F5 F5Mgmt lb username password F5.add_pool_member name port pool_name return True
def check_workers workers worker_sockets log_fh None for worker sock in zip workers worker_sockets try sock.send '' except error if log_fh log_fh.write 'FATALERROR\nWorker%snotalive.Aborting\n' % worker stop_workers worker_sockets log_fh return Falsereturn True
def is_any_marketing_link_set names return any is_marketing_link_set name for name in names
def _tokenize description empty _matchingString u'' description colon _matchingString u' ' description equals _matchingString u' ' description backslash _matchingString u'\\' description current emptyops colon + equals nextOps {colon colon + equals equals colon}iterdesc iter iterbytes description for n in iterdesc if n in iterbytes ops yield _STRING current yield _OP n current emptyops nextOps[n]elif n backslash current + next iterdesc else current + n yield _STRING current
def _repr_pprint obj p cycle output repr obj for idx output_line in enumerate output.splitlines if idx p.break_ p.text output_line
def total_by_codename cls codenames codenames tup codenames q Session.query cls.codename sum cls.pageview_count .filter cls.interval 'hour' .filter cls.codename.in_ codenames .group_by cls.codename return list q
def test_only_major_dots_no_labels line Line show_only_major_dots True line.add 'test' range 12 q line.render_pyquery assert len q '.dots' 12
def trade events strategy portfolio execution heartbeat while True try event events.get False except queue.Empty passelse if event is not None if event.type 'TICK' logger.info 'Receivednewtickevent %s' event strategy.calculate_signals event portfolio.update_portfolio event elif event.type 'SIGNAL' logger.info 'Receivednewsignalevent %s' event portfolio.execute_signal event elif event.type 'ORDER' logger.info 'Receivedneworderevent %s' event execution.execute_order event time.sleep heartbeat
def _clone_vdi session vdi_to_clone_ref vdi_ref session.call_xenapi 'VDI.clone' vdi_to_clone_ref LOG.debug 'ClonedVDI% vdi_ref sfromVDI% vdi_to_clone_ref s' {'vdi_ref' vdi_ref 'vdi_to_clone_ref' vdi_to_clone_ref} return vdi_ref
def format_err_msg_and_raise operation_type component error_message error_code formated_err_msg _ 'Error Failedto% operation_type s% component s' % {'operation_type' operation_type 'component' component} if error_message.startswith '"\'' and error_message.endswith '\'"' error_message error_message[2 len error_message - 2 ]formated_err_msg formated_err_msg + '\nReason ' + error_message raise CoprHdError error_code formated_err_msg
@apply_to_text_filedef typogrify_sans_widont data if typo is None req_missing ['typogrify'] 'usethetypogrify_sans_widontfilter' data _normalize_html data data typo.amp data data typo.smartypants data data typo.initial_quotes data return data
def itruediv a b a / breturn a
def test_disarmed nikola.utils.USE_SLUGIFY Falseo nikola.utils.slugify u'Za\u017c\xf3\u0142\u0107g\u0119\u015bl\u0105ja\u017a\u0144!-123.456' lang u'pl' assert o u'Za\u017c\xf3\u0142\u0107g\u0119\u015bl\u0105ja\u017a\u0144!-123.456' assert isinstance o nikola.utils.unicode_str nikola.utils.USE_SLUGIFY True
def make_option_group group parser option_group OptionGroup parser group['name'] for option in group['options'] option_group.add_option option return option_group
def quota_class_update_resource context resource new_resource return IMPL.quota_class_update_resource context resource new_resource
def rating_post_save instance *args **kwargs ResourceBase.objects.filter id instance.object_id .update rating instance.rating
def test_allknn_init allknn AllKNN random_state RND_SEED assert_equal allknn.n_neighbors 3 assert_equal allknn.kind_sel 'all' assert_equal allknn.n_jobs -1 assert_equal allknn.random_state RND_SEED
def test_position_angle_directly from ..angle_utilities import position_angleresult position_angle 10.0 20.0 10.0 20.0 assert result.unit is u.radian assert result.value 0.0
@pytest.mark.usefixtures 'clean_system' 'remove_additional_dirs' def test_cookiecutter_no_input_return_project_dir project_dir main.cookiecutter 'tests/fake-repo-pre' no_input True assert project_dir os.path.abspath 'fake-project'
def guess_path pth if os.path.isabs pth return pthelse return os.path.expanduser os.path.join '~' pth
def maintenance_mode_exempt view_func view_func.maintenance_mode_exempt Truereturn view_func
def words count common True word_list list COMMON_WORDS if common else [] c len word_list if count > c count - cwhile count > 0 c min count len WORDS count - cword_list + random.sample WORDS c else word_list word_list[ count]return ''.join word_list
def _bench_skipper condition skip_message def decorator func if isinstance condition bool and condition or not isinstance condition bool and condition wrapper unittest.skip '[{}]skipped {}\n'.format _get_bench_name func skip_message func else @wraps func def wrapper *args **kwargs func *args **kwargs return wrapperreturn decorator
def get_courseware_with_tabs course_id course get_course_by_id course_id chapters [chapter for chapter in course.get_children if not chapter.hide_from_toc ]courseware [{'chapter_name' c.display_name_with_default_escaped 'sections' [{'section_name' s.display_name_with_default_escaped 'clickable_tab_count' len s.get_children if type s seq_module.SequenceDescriptor else 0 'tabs' [{'children_count' len t.get_children if type t vertical_block.VerticalBlock else 0 'class' t.__class__.__name__} for t in s.get_children ]} for s in c.get_children if not s.hide_from_toc ]} for c in chapters]return courseware
def toLux raw return np.power 10 raw * LOG_LUX_RATIO
def system_resolvers system None if system is None if stem.util.system.is_gentoo system 'Gentoo'else system platform.system if system 'Windows' resolvers [Resolver.NETSTAT_WINDOWS]elif system in 'Darwin' 'OpenBSD' resolvers [Resolver.LSOF]elif system 'FreeBSD' resolvers [Resolver.BSD_SOCKSTAT Resolver.BSD_PROCSTAT Resolver.LSOF]else resolvers [Resolver.NETSTAT Resolver.SOCKSTAT Resolver.LSOF Resolver.SS]resolvers [r for r in resolvers if stem.util.system.is_available RESOLVER_COMMAND[r] ]if stem.util.proc.is_available and os.access '/proc/net/tcp' os.R_OK and os.access '/proc/net/udp' os.R_OK resolvers [Resolver.PROC] + resolvers return resolvers
@step u'thedirectory"{directory}"doesnotexist' def step_directory_named_does_not_exist context directory step_the_directory_should_not_exist context directory
def _get_jinja_error_line tb_data try return _get_jinja_error_slug tb_data [1]except IndexError passreturn None
def _running_on_ci env_vars ['CI' 'BUILD_NUMBER']return any var in os.environ for var in env_vars
def _to_forward_dict fwd names fwd_grad None coord_frame FIFF.FIFFV_COORD_HEAD source_ori FIFF.FIFFV_MNE_FREE_ORI assert names is not None if len fwd 0 return Nonesol dict data fwd.T nrow fwd.shape[1] ncol fwd.shape[0] row_names names col_names [] fwd Forward sol sol source_ori source_ori nsource sol['ncol'] coord_frame coord_frame sol_grad None nchan sol['nrow'] _orig_source_ori source_ori _orig_sol sol['data'].copy _orig_sol_grad None if fwd_grad is not None sol_grad dict data fwd_grad.T nrow fwd_grad.shape[1] ncol fwd_grad.shape[0] row_names names col_names [] fwd.update dict sol_grad sol_grad _orig_sol_grad sol_grad['data'].copy return fwd
def split_hosts hosts default_port DEFAULT_PORT nodes []for entity in hosts.split ' ' if not entity raise ConfigurationError 'Emptyhost orextracommainhostlist .' port default_portif entity.endswith '.sock' port Nonenodes.append parse_host entity port return nodes
def cmd_save args child multiprocessing.Process target save_process args [mestate.last_graph] child.start
def uptime_seconds uptime_list years uptime_list[0]weeks uptime_list[1]days uptime_list[2]hours uptime_list[3]minutes uptime_list[4]days years * 365 + weeks * 7 + days minutes days * 24 * 60 + hours * 60 + minutes seconds minutes * 60 return seconds
def clean_link link_text return link_text.strip ' DCTB \r\n\'"'
def save_tiled_raster_images tiled_img filename if tiled_img.ndim 2 ensure_Image img Image.fromarray tiled_img 'L' elif tiled_img.ndim 3 ensure_Image img Image.fromarray tiled_img 'RGBA' else raise TypeError 'badndim' tiled_img img.save filename return img
def _image_member_format member_ref return {'id' member_ref['id'] 'image_id' member_ref['image_id'] 'member' member_ref['member'] 'can_share' member_ref['can_share'] 'status' member_ref['status'] 'created_at' member_ref['created_at'] 'updated_at' member_ref['updated_at']}
def generate_random_asset_md course_key CourseKey.from_string 'org/course/run' asset_key course_key.make_asset_key asset_type filename curr_version prev_version versions return AssetMetadata asset_key pathname pathname internal_name str [filename for __ in xrange 10 ] locked locked contenttype contenttype thumbnail filename fields fields curr_version curr_version prev_version prev_version edited_by user_id edited_by_email 'staff@edx.org' edited_on date_and_time created_by user_id created_by_email 'staff@edx.org' created_on date_and_time
def read_named_ranges xml_source workbook named_ranges []root fromstring xml_source names_root root.find QName 'http //schemas.openxmlformats.org/spreadsheetml/2006/main' 'definedNames' .text if names_root is not None for name_node in names_root.getchildren range_name name_node.get 'name' if name_node.get 'hidden' '0' '1' continuevalid Truefor discarded_range in DISCARDED_RANGES if discarded_range in range_name valid Falsefor bad_range in BUGGY_NAMED_RANGES if bad_range in name_node.text valid Falseif valid destinations split_named_range name_node.text new_destinations []for worksheet cells_range in destinations worksheet workbook.get_sheet_by_name worksheet if worksheet new_destinations.append worksheet cells_range named_range NamedRange range_name new_destinations named_ranges.append named_range return named_ranges
def _get_dir_path sibling py_file __file__.replace '.pyc' '.py' dir_paths [os.path.abspath os.path.dirname os.path.realpath py_file os.path.abspath os.path.dirname py_file ]for dir_path in dir_paths sibling_path os.path.join dir_path sibling if os.path.exists sibling_path return dir_pathraise ValueError 'Couldnotdeterminedirectorythatcontainsboth thisfileand%s.' % sibling
def latest_release_tag git_tags subprocess.check_output ['git' 'tag' '-l'] stderr subprocess.STDOUT .split release_tags [tag for tag in git_tags if tag.startswith 'ckan-' ]release_tags.sort if release_tags return release_tags[ -1 ]else return 'COULD_NOT_DETECT_VERSION_NUMBER'
def remove_logrotate app_name app_logrotate_script '{0}/appscale-{1}'.format LOGROTATE_CONFIG_DIR app_name logging.debug 'Removingscript {}'.format app_logrotate_script try os.remove app_logrotate_script except OSError logging.error 'Errordeleting{0}'.format app_logrotate_script return Falsereturn True
def cmd_reverse_lookup command_name for key value in miss_cmds.items if value.upper command_name.upper return keyreturn 0
def getVector3ByPrefixes elementNode prefixes vector3 for prefix in prefixes vector3 getVector3ByPrefix vector3 elementNode prefix return vector3
def fuzzy_search query elements key lambda x x rank True seq 3 R match_rank query [key el for el in elements] seq seq out [ el R[i] for i el in enumerate elements if R[i] is not None ]return [el[0] for el in sorted out key lambda el el[1] ]
def _resolve_args cls *args **kwargs attrs cls._argumentsattrset set attrs if not set kwargs < attrset raise TypeError '%sgotunknownkeywords %s' % cls.__name__ ' '.join set kwargs - attrset if len args > len attrs raise TypeError '%stakes3positionalargumentsbut%dweregiven' % cls.__name__ len args attributes OrderedDict zip attrs repeat None to_add dict zip attrs args attributes.update to_add added set to_add for key value in kwargs.items if key in added raise TypeError '%sgotmultiplevaluesforargument%r' % cls.__name__ key attributes[key] valueadded.add key return attributes
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def unlisted_addons_reviewer_required f @login_required@functools.wraps f def wrapper request *args **kw if acl.check_unlisted_addons_reviewer request return f request *args **kw raise PermissionDeniedreturn wrapper
def convert_fontsize length unit base_font_size 16.0 dpi 96.0 if unit u'px' return length / base_font_size pt_to_px dpi / 72.0 pt_to_rem pt_to_px / base_font_size return length * length_factors.get unit 1 * pt_to_rem
def set_extra_environ key value def decorator func def wrapper *args **kwargs app _get_test_app app.get '/' extra_environ {key value} try return_value func *args **kwargs finally app.get '/' extra_environ {key ''} return return_valuereturn nose.tools.make_decorator func wrapper return decorator
def aggregated_indicator return s3_rest_controller
def guestbook_key guestbook_name DEFAULT_GUESTBOOK_NAME return ndb.Key 'Guestbook' guestbook_name
def readPlistFromString data return readPlist StringIO data
def _higher_function_scope node current nodewhile current.parent and not isinstance current.parent nodes.Function current current.parentif current and current.parent return current.parent
def abort_action session task raise importer.ImportAbort
def monkeypatch_property cls def decorator func setattr cls func.__name__ property func return funcreturn decorator
def getSerialPorts if sys.platform 'darwin' ports ['/dev/tty.USA*' '/dev/tty.Key*' '/dev/tty.modem*' '/dev/cu.usbmodem*' '/dev/tty.usbserial*']elif sys.platform.startswith 'linux' ports ['/dev/ttyACM?' '/dev/ttyUSB?' '/dev/ttyS?']elif sys.platform 'cygwin' ports ['/dev/ttyS?']elif sys.platform 'win32' return imap 'COM{0}'.format xrange 11 else logging.error "Wedon'tsupportserialportson{0}yet!".format sys.platform return []return chain.from_iterable imap glob.iglob ports
def addPluginsToMenu directoryPath menu pluginFileNames for pluginFileName in pluginFileNames ToolDialog .addPluginToMenu menu os.path.join directoryPath pluginFileName
def chunkyreader f count None if count ! None while count > 0 b f.read min count 65536 if not b raise IOError 'EOFwith%dbytesremaining' % count yield b count - len b else while 1 b f.read 65536 if not b break yield b
def GetIndexes **kwargs return GetIndexesAsync **kwargs .get_result
def _rotate_polygon lon lat lon0 lat0 polygon UnitSphericalRepresentation lon lon lat lat m1 rotation_matrix - 0.5 * np.pi * u.radian - lat0 axis 'y' m2 rotation_matrix - lon0 axis 'z' transform_matrix matrix_product m2 m1 polygon polygon.to_cartesian polygon polygon.transform transform_matrix polygon UnitSphericalRepresentation.from_cartesian polygon return polygon.lon polygon.lat
def _determine_host data omit '' host ''bestmem 0for hv_ comps in six.iteritems data if hv_ omit continueif not isinstance comps dict continueif comps.get 'freemem' 0 > bestmem bestmem comps['freemem']host hv_return host
def _matchReportKeys reportKeyREs [] allReportKeys [] matchingReportKeys []for keyRE in reportKeyREs matchObj re.compile keyRE found Falsefor keyName in allReportKeys match matchObj.match keyName if match and match.end len keyName matchingReportKeys.append keyName found Trueif not found raise _BadKeyError keyRE return matchingReportKeys
def set_epsilon_closure state_set result {}for state1 in state_set for state2 in epsilon_closure state1 result[state2] 1return result
def urlencoded_processor entity cherrypy._cpreqbody.process_urlencoded entity cherrypy.serving.request.unserialized_data entity.paramscherrypy.serving.request.raw_body ''
def get_api_query service table_id return service.data .ga .get ids table_id start_date '2012-01-01' end_date '2012-01-15' metrics 'ga visits' dimensions 'ga source ga keyword' sort '-ga visits' filters 'ga medium organic' start_index '1' max_results '25'
def get_payment_provider_portals app None user None provider_portals []if app q dict addon app elif user q dict payment_account__user user else raise ValueError 'userorappisrequired' for acct in AddonPaymentAccount.objects.filter **q .select_related 'payment_account' provider get_provider id acct.payment_account.provider portal_url provider.get_portal_url acct.addon.app_slug if portal_url provider_portals.append {'provider' provider 'app' acct.addon 'portal_url' portal_url 'payment_account' acct.payment_account} return provider_portals
def generate_paragraphs amount start_with_lorem False return _GENERATOR.generate_paragraphs amount start_with_lorem
def enableCache if not isinstance _entityCache LRUCache _entityCache _LRUCache size
def infer_layout val if sys.version_info > 3 return 'C' if val.c_contiguous else 'F' if val.f_contiguous else 'A' if val.ndim 1 and val.strides[0] val.itemsize return 'C'return 'A'
def prop_set prop value extra_args None cibfile None return item_create item 'property' item_id '{0} {1}'.format prop value item_type None create 'set' extra_args extra_args cibfile cibfile
def sync_user_email_addresses user from .models import EmailAddressemail user_email user if email and not EmailAddress.objects.filter user user email__iexact email .exists if app_settings.UNIQUE_EMAIL and EmailAddress.objects.filter email__iexact email .exists returnEmailAddress.objects.create user user email email primary False verified False
def create_method_not_allowed allowed_methods def method_not_allowed req resp **kwargs 'Raise405HTTPMethodNotAllowederror'raise HTTPMethodNotAllowed allowed_methods return method_not_allowed
def FileSize APP_PATH return round float os.path.getsize APP_PATH / 1024 * 1024 2
def _host_dhcp_opts vif_id None gateway None values []if vif_id is not None values.append _host_dhcp_network vif_id values.append '3' if gateway values.append '%s' % gateway return ' '.join values
def opts if __opts__.get 'grain_opts' False or isinstance __pillar__ dict and __pillar__.get 'grain_opts' False return __opts__return {}
def locate_library candidates find_library ctypes.util.find_library if find_library is None find_library ctypes.util.find_libraryuse_dll_workaround sys.platform 'win32' and find_library is ctypes.util.find_library for candidate in candidates if use_dll_workaround candidate + '.dll'libname find_library candidate if libname return libnamereturn None
def dotted_from_fs_path fs_path sys_path if os.path.basename fs_path .startswith '__init__.' fs_path os.path.dirname fs_path path ''for s in sys_path if fs_path.startswith s and len path < len s path smodule_path fs_path[len path ].lstrip os.path.sep .lstrip '/' return _path_re.sub '' module_path .replace os.path.sep '.' .replace '/' '.'
def update_support_forum_contributors_metric day None if day start end dayelse latest_metric _get_latest_metric SUPPORT_FORUM_CONTRIBUTORS_METRIC_CODE if latest_metric is not None start latest_metric.end + timedelta days 1 else start date 2011 1 1 end date.today - timedelta days 1 day startwhile day < end thirty_days_back day - timedelta days 30 contributors Answer.objects.exclude creator F 'question__creator' .filter created__gte thirty_days_back created__lt day .values 'creator' .annotate count Count 'creator' .filter count__gte 10 count contributors.count metric_kind MetricKind.objects.get code SUPPORT_FORUM_CONTRIBUTORS_METRIC_CODE Metric.objects.create kind metric_kind start thirty_days_back end day value count day day + timedelta days 1
def convert_language_code_format lang_code for_django True if not lang_code return lang_codelang_code lang_code.lower code_parts re.split '-|_' lang_code if len code_parts > 1 assert len code_parts 2 'code_partswas {0}'.format code_parts code_parts[1] code_parts[1].upper if for_django lang_code '_'.join code_parts else lang_code '-'.join code_parts return lang_code
def print_commands commands status_update_callback logger close_logger_on_success True logger.write 'Printingcommandsonly.\n\n' for c in commands for e in c status_update_callback '#%s' % e[0] print '%s' % e[1] logger.write '#%scommand\n%s\n\n' % e
def liberal_is_HDN text if IPV4_RE.search text return Falsereturn True
def filterprotected *filters def _filterprotected f @functools.wraps f def wrapper self context **kwargs if not context['is_admin'] action 'identity %s' % f.__name__ creds _build_policy_check_credentials self action context kwargs target dict if len filters > 0 for filter in filters if filter in context['query_string'] target[filter] context['query_string'][filter]LOG.debug _ 'RBAC Addingqueryfilterparams %s ' % ' '.join [ '%s %s' % filter target[filter] for filter in target] for key in kwargs target[key] kwargs[key]self.policy_api.enforce context creds action flatten target LOG.debug _ 'RBAC Authorizationgranted' else LOG.warning _ 'RBAC Bypassingauthorization' return f self context filters **kwargs return wrapperreturn _filterprotected
def convert_to_octal file_name return oct os.stat file_name [stat.ST_MODE] [ -3 ]
def _require_sender_id_is_valid intent sender_id if intent not in SENDER_VALIDATORS raise Exception 'Invalidemailintentstring %s' % intent elif not SENDER_VALIDATORS[intent] sender_id logging.error "Invalidsender_id%sforemailwithintent'%s'" % sender_id intent raise Exception "Invalidsender_idforemailwithintent'%s'" % intent
def _doc_parms cls axis_descr '{%s}' % ' '.join ['{0} {1} '.format a i for i a in enumerate cls._AXIS_ORDERS ] name cls._constructor_sliced.__name__ if cls._AXIS_LEN > 1 else 'scalar' name2 cls.__name__return axis_descr name name2
def set_device request device u'' response redirect add_cache_bypass next_url request or u'/' set_cookie response u'mezzanine-device' device 60 * 60 * 24 * 365 return response
def get_pgraster_srid data if data is None returnreturn unpack 'i' data[106 114] [0]
def filter_aln_by_otus aln prefs filtered_seqs []removed_seqs []for j in range aln.sequence_count remove Falsealn_name aln[j].idstripped_aln_name aln_name.split '' [0].split '_' if len stripped_aln_name > 1 new_aln_name ''.join stripped_aln_name[ -1 ] else new_aln_name stripped_aln_name[0]for sample_id in prefs if prefs[sample_id] new_aln_name remove Trueif remove removed_seqs.append aln_name str aln[aln_name] else filtered_seqs.append aln_name str aln[aln_name] return filtered_seqs removed_seqs
def convert_db_channel_to_json channel include_rel_score False res_json {'id' channel[0] 'dispersy_cid' channel[1].encode 'hex' 'name' channel[2] 'description' channel[3] 'votes' channel[5] 'torrents' channel[4] 'spam' channel[6] 'modified' channel[8] 'subscribed' channel[7] VOTE_SUBSCRIBE }if include_rel_score res_json['relevance_score'] channel[9]return res_json
def opengl_arrays_modules statement 'importOpenGL;print OpenGL.__path__[0] 'opengl_mod_path exec_statement statement arrays_mod_path os.path.join opengl_mod_path 'arrays' files glob.glob arrays_mod_path + '/*.py' modules []for f in files mod os.path.splitext os.path.basename f [0]if mod '__init__' continuemodules.append 'OpenGL.arrays.' + mod return modules
def floating_ip_bulk_destroy context ips return IMPL.floating_ip_bulk_destroy context ips
def take_sorted outname inname blockdims index axis 0 sizes blockdims[axis]index_lists partition_by_size sizes sorted index where_index [i for i il in enumerate index_lists if il]index_lists [il for il in index_lists if il]dims [range len bd for bd in blockdims]indims list dims indims[axis] list range len where_index keys list product [outname] *indims outdims list dims outdims[axis] where_indexslices [ [colon] * len bd for bd in blockdims]slices[axis] index_listsslices list product *slices inkeys list product [inname] *outdims values [ getitem inkey slc for inkey slc in zip inkeys slices ]blockdims2 list blockdims blockdims2[axis] tuple map len index_lists return tuple blockdims2 dict zip keys values
def reverse x axes if isinstance axes int axes [axes]slices [ slice None None -1 if i in axes else slice None None None for i in range x.ndim ]return x[slices]
def Assign target source if not isinstance target list target [target]if not isinstance source list source.prefix u''source [source]return Node syms.atom target + [Leaf token.EQUAL u' ' prefix u'' ] + source
def BuildClonePostBody file_tuples file_list []for tup in file_tuples path tup[1]tup tup[2 ]file_list.append TUPLE_DELIMITER.join [path] + list tup return LIST_DELIMITER.join file_list
def _has_wiki_staff_access user wiki_slug modstore course_keys modstore.get_courses_for_wiki wiki_slug if wiki_slug.endswith '_' and slug_is_numerical wiki_slug[ -1 ] course_keys.extend modstore.get_courses_for_wiki wiki_slug[ -1 ] for course_key in course_keys course modstore.get_course course_key if courseware.access.has_access user 'staff' course course_key return Truereturn False
def _filepath_to_path filepath return filepath.path
@evalcontextfilterdef do_urlize eval_ctx value trim_url_limit None nofollow False target None rel None policies eval_ctx.environment.policiesrel set rel or '' .split or [] if nofollow rel.add 'nofollow' rel.update policies['urlize.rel'] or '' .split if target is None target policies['urlize.target']rel ''.join sorted rel or None rv urlize value trim_url_limit rel rel target target if eval_ctx.autoescape rv Markup rv return rv
def get_latest_downloadable_repository_metadata trans repository encoded_repository_id trans.security.encode_id repository.id repo hg_util.get_repo_for_repository trans.app repository repository repo_path None create False tip_ctx str repo.changectx repo.changelog.tip repository_metadata Nonetry repository_metadata metadata_util.get_repository_metadata_by_changeset_revision trans.app encoded_repository_id tip_ctx if repository_metadata is not None and repository_metadata.downloadable return repository_metadatareturn Noneexcept latest_downloadable_revision metadata_util.get_previous_metadata_changeset_revision repository repo tip_ctx downloadable True if latest_downloadable_revision hg_util.INITIAL_CHANGELOG_HASH return Nonerepository_metadata metadata_util.get_repository_metadata_by_changeset_revision trans.app encoded_repository_id latest_downloadable_revision if repository_metadata is not None and repository_metadata.downloadable return repository_metadatareturn None
def saxify element_or_tree content_handler return ElementTreeProducer element_or_tree content_handler .saxify
def migration_get_by_instance_and_status context instance_uuid status return IMPL.migration_get_by_instance_and_status context instance_uuid status
def is_prime n if n < 1 return Falsefor i in range 2 int math.sqrt n + 1 if n % i 0 return Falsereturn True
@deprecated u'2.1' def alltrue seq if not len seq return Falsefor val in seq if not val return Falsereturn True
def oauth2decorator_from_clientsecrets filename scope message None return OAuth2DecoratorFromClientSecrets filename scope message
def array_split ary indices_or_sections axis 0 ndim ary.ndimif - ndim > axis or ndim < axis raise IndexError 'Axisexceedsndim' axis % ndimsize ary.shape[axis]if numpy.isscalar indices_or_sections each_size size - 1 // indices_or_sections + 1 indices [ i * each_size for i in six.moves.range 1 indices_or_sections ]else indices indices_or_sectionsif len indices 0 return [ary]skip slice None * axis ret []i 0for index in indices ret.append ary[ skip + slice i index ] i indexret.append ary[ skip + slice i size ] return ret
def _decode_rrq_wrq packet packet_buff offset file_name idx _get_string packet_buff offset packet['file_name'] file_name_decode_options packet packet_buff idx return packet
def prob_quantize_cdf_old binsx binsy cdf binsx np.asarray binsx binsy np.asarray binsy nx len binsx - 1 ny len binsy - 1 probs np.nan * np.ones nx ny for xind in range 1 nx + 1 for yind in range 1 ny + 1 upper binsx[xind] binsy[yind] lower binsx[ xind - 1 ] binsy[ yind - 1 ] probs[ xind - 1 yind - 1 ] prob_bv_rectangle lower upper cdf assert not np.isnan probs .any return probs
def _listFriends fs sep ' ' lock True getLastMessage False p PyFred 'ch.xtin.skypingalfred.find' False for f in fs img imgtype _getAvatar f[0] p.addItem 'skypename_' + f[0] f[0] + sep f[0] + ' ' + f[1] + ' ' if f[1] else ' ' + f[2] + ' ' if f[2] else '' _getLastMessageFormated f[0] if getLastMessage else '' not lock f[0] + sep img imgtype if len p._items 0 p.addItem 'skypename_notfound' 'skypeupdate' 'NoSkypefriendfound ' + tg 'Maybetryupdatingyourfriends?Hitentertodoso!' True return p.toXML
def Concatenate sep u' ' def step ctxt value if value is not None ctxt.append value def finalize ctxt if not ctxt return Nonereturn sep.join ctxt return [] step finalize
def related_revisions_link obj link '%s?%s' % reverse 'admin wiki_revision_changelist' args [] 'document__exact %s' % obj.id count obj.revisions.count what count 1 and 'revision' or 'revisions' return '<ahref "%s">%s&nbsp;%s</a>' % link count what
def compare_dirs dir1 dir2 dc filecmp.dircmp dir1 dir2 if len dc.funny_files > 0 or len dc.left_only > 0 or len dc.right_only > 0 or len dc.diff_files > 0 dc.report return Falseelse for subdir in dc.common_dirs if not compare_dirs dir1 + '\\' + subdir dir2 + '\\' + subdir return Falsereturn True
def delta_seconds before after delta after - before return datetime.timedelta.total_seconds delta
def item_endpoint **lookup resource _resource response Nonemethod request.methodif method in 'GET' 'HEAD' response getitem resource **lookup elif method 'PATCH' response patch resource **lookup elif method 'PUT' response put resource **lookup elif method 'DELETE' response deleteitem resource **lookup elif method 'OPTIONS' send_response resource response else abort 405 return send_response resource response
def _is_valid_args func args kwargs if func not in signatures return Nonesigs signatures[func]return any check_valid sig args kwargs for sig in sigs
def create_api_key import timetry from hashlib import md5except ImportError from md5 import md5import randomt str time.time r str random.random m md5 t m.update r return m.hexdigest
def _api_qstatus name output kwargs if output 'json' keyword ''else keyword 'queue'return report output keyword keyword data qstatus_data
def handle_extra_payload payload api_model if type payload ! dict return payloaddata payload.copy for key in payload if key not in api_model del data[key]elif isinstance api_model[key] fields.Nested data[key] handle_extra_payload data[key] api_model[key].model elif isinstance api_model[key] fields.List temp []for _ in payload[key] temp.append handle_extra_payload _ api_model[key].container data[key] tempreturn data
def getBodyStructure msg extended False return _getMessageStructure msg .encode extended
def check_mod_enabled mod if mod.endswith '.load' or mod.endswith '.conf' mod_file modelse mod_file '{0}.load'.format mod return os.path.islink '/etc/apache2/mods-enabled/{0}'.format mod_file
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
def find predicate seq for element in seq if predicate element return elementreturn None
def isStackingAvailable retVal Falseif PAYLOAD.TECHNIQUE.STACKED in kb.injection.data retVal Trueelse for technique in getPublicTypeMembers PAYLOAD.TECHNIQUE True _ getTechniqueData technique if _ and 'stacked' in _['title'].lower retVal Truebreakreturn retVal
def normjoin *path_parts return os.path.normpath os.path.normcase os.path.join *path_parts
def parse_course_and_usage_keys course_id usage_id course_key CourseKey.from_string course_id usage_id unquote_slashes usage_id usage_key UsageKey.from_string usage_id .map_into_course course_key return course_key usage_key
def gf_quo f g p K df gf_degree f dg gf_degree g if not g raise ZeroDivisionError 'polynomialdivision' elif df < dg return []inv K.invert g[0] p h dq dr f[ ] df - dg dg - 1 for i in range 0 dq + 1 coeff h[i]for j in range max 0 dg - i min df - i dr + 1 coeff - h[ i + j - dg ] * g[ dg - j ] h[i] coeff * inv % p return h[ dq + 1 ]
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def magic_set obj def decorator func is_class isinstance obj six.class_types args varargs varkw defaults inspect.getargspec func if not args or args[0] not in 'self' 'cls' 'klass' if is_class replacement staticmethod func else replacement funcelif args[0] 'self' if is_class replacement funcelse def replacement *args **kw return func obj *args **kw try replacement.__name__ func.__name__except passelif is_class replacement classmethod func else def replacement *args **kw return func obj.__class__ *args **kw try replacement.__name__ func.__name__except passsetattr obj func.__name__ replacement return replacementreturn decorator
def open_cover hass entity_id None data {ATTR_ENTITY_ID entity_id} if entity_id else None hass.services.call DOMAIN SERVICE_OPEN_COVER data
def info return _nodetool 'info'
def savepoint using None if using is None using DEFAULT_DB_ALIASconnection connections[using]thread_ident thread.get_ident if thread_ident in savepoint_state and using in savepoint_state[thread_ident] savepoint_state[thread_ident][using].append None else savepoint_state.setdefault thread_ident {} savepoint_state[thread_ident][using] [None]tid str thread_ident .replace '-' '' sid 's%s_x%d' % tid len savepoint_state[thread_ident][using] connection._savepoint sid return sid
def pem_managed name text backup False **kwargs file_args kwargs _get_file_args name **kwargs file_args['contents'] __salt__['x509.get_pem_entry'] text text return __states__['file.managed'] **file_args
@not_implemented_for 'directed' 'multigraph' def is_strongly_regular G return is_distance_regular G and diameter G 2
def decode encoding None default_encoding 'utf-8' body cherrypy.request.bodyif encoding is not None if not isinstance encoding list encoding [encoding]body.attempt_charsets encodingelif default_encoding if not isinstance default_encoding list default_encoding [default_encoding]body.attempt_charsets body.attempt_charsets + default_encoding
def _instance_to_allocations_dict instance is_bfv compute_utils.is_volume_backed_instance instance._context instance disk 0 if is_bfv else instance.flavor.root_gb + instance.flavor.swap + instance.flavor.ephemeral_gb alloc_dict {MEMORY_MB instance.flavor.memory_mb VCPU instance.flavor.vcpus DISK_GB disk}return {key val for key val in alloc_dict.items if val}
def dup_spherical_bessel_fn n K seq [[K.one] [K.one K.zero]]for i in range 2 n + 1 a dup_mul_ground dup_lshift seq[ -1 ] 1 K K 2 * i - 1 K seq.append dup_sub a seq[ -2 ] K return dup_lshift seq[n] 1 K
def quopri_decode input errors 'strict' assert errors 'strict' f StringIO str input g StringIO quopri.decode f g output g.getvalue return output len input
def _get_related_models m related_models [subclass for subclass in m.__subclasses__ if issubclass subclass models.Model ]related_fields_models set for f in m._meta.get_fields include_parents True include_hidden True if f.is_relation and f.related_model is not None and not isinstance f.related_model str related_fields_models.add f.model related_models.append f.related_model opts m._metaif opts.proxy and m in related_fields_models related_models.append opts.concrete_model return related_models
def encode_problem_and_student_input usage_key student None assert isinstance usage_key UsageKey if student is not None task_input {'problem_url' usage_key.to_deprecated_string 'student' student.username}task_key_stub '{student}_{problem}'.format student student.id problem usage_key.to_deprecated_string else task_input {'problem_url' usage_key.to_deprecated_string }task_key_stub '_{problem}'.format problem usage_key.to_deprecated_string task_key hashlib.md5 task_key_stub .hexdigest return task_input task_key
def dashboard_mark_activities_old context data_dict _check_access 'dashboard_mark_activities_old' context data_dict model context['model']user_id model.User.get context['user'] .idmodel.Dashboard.get user_id .activity_stream_last_viewed datetime.datetime.utcnow if not context.get 'defer_commit' model.repo.commit
def test_local_abstractconv_gemm image tensor.ftensor4 W tensor.ftensor4 conv tensor.nnet.conv2d image W input_shape 1 32 32 32 filter_shape 32 32 3 3 border_mode 'half' f theano.function [image W] [conv] mode mode_with_gpu f numpy.random.rand 1 32 32 32 .astype 'float32' numpy.random.rand 32 32 3 3 .astype 'float32'
def host_topology_and_format_from_host host was_json Falsetry host_numa_topology host.get 'numa_topology' except AttributeError host_numa_topology host.numa_topologyif host_numa_topology is not None and isinstance host_numa_topology six.string_types was_json Truehost_numa_topology objects.NUMATopology.obj_from_db_obj host_numa_topology return host_numa_topology was_json
def validate_id_birthday gd fix_coordination_number_day True today datetime.date.today day int gd['day'] if fix_coordination_number_day and day > 60 day - 60if gd['century'] is None current_year today.yearyear int today.strftime '%Y' - int today.strftime '%y' + int gd['year'] if '%s%s%02d' % gd['year'] gd['month'] day > today.strftime '%y%m%d' year - 100if gd['sign'] '+' year - 100else year int gd['century'] + gd['year'] if year < 1800 raise ValueErrorbirth_day datetime.date year int gd['month'] day if birth_day > today raise ValueErrorreturn birth_day
def _first_and_last_element arr if isinstance arr np.ndarray or hasattr arr 'data' data arr.data if sparse.issparse arr else arr return data.flat[0] data.flat[ -1 ] else return arr[ 0 0 ] arr[ -1 -1 ]
def tryit rule def try_rl expr try return rule expr except Exception return exprreturn try_rl
def wrap_draft item item.is_draft item.location.revision MongoRevisionKey.draft item.location item.location.replace revision MongoRevisionKey.published return item
def check_key user key enc comment options config '.ssh/authorized_keys' cache_keys None if cache_keys is None cache_keys []enc _refine_enc enc current auth_keys user config nline _format_auth_line key enc comment options if key in current cline _format_auth_line key current[key]['enc'] current[key]['comment'] current[key]['options'] if cline ! nline return 'update'else return 'add'return 'exists'
def generate_search_qs term match 'term' videoDuration 'any' after None aliases dict views 'viewCount' qs {'q' term 'maxResults' 50 'safeSearch' 'none' 'order' aliases.get config.ORDER.get config.ORDER.get 'part' 'id snippet' 'type' 'video' 'videoDuration' videoDuration 'key' config.API_KEY.get}if after after after.lower qs['publishedAfter'] '%sZ' % datetime.utcnow - timedelta days DAYS[after] .isoformat if after in DAYS.keys else '%s%s' % after 'T00 00 00Z' * len after 10 if match 'related' qs['relatedToVideoId'] termdel qs['q']if config.SEARCH_MUSIC.get qs['videoCategoryId'] 10return qs
def parse_cookie value if not value return Nonereturn value
def docopt doc argv None help True version None options_first False if argv is None argv sys.argv[1 ]DocoptExit.usage printable_usage doc options parse_defaults doc pattern parse_pattern formal_usage DocoptExit.usage options argv parse_argv TokenStream argv DocoptExit list options options_first pattern_options set pattern.flat Option for ao in pattern.flat AnyOptions doc_options parse_defaults doc ao.children list set doc_options - pattern_options extras help version argv doc matched left collected pattern.fix .match argv if matched and left [] return Dict a.name a.value for a in pattern.flat + collected raise DocoptExit
def _init_tk_type global _tk_typeif platform 'darwin' root tkinter.Tk ws root.tk.call 'tk' 'windowingsystem' if 'x11' in ws _tk_type 'xquartz'elif 'aqua' not in ws _tk_type 'other'elif 'AppKit' in root.tk.call 'winfo' 'server' '.' _tk_type 'cocoa'else _tk_type 'carbon'root.destroy else _tk_type 'other'
def test_feature_max_length_on_feature_name feature Feature.from_string FEATURE3 assert_equals feature.max_length 78
def dmp_sub_term f c i u K if not u return dup_add_term f - c i K v u - 1 if dmp_zero_p c v return fn len f m n - i - 1 if i n - 1 return dmp_strip [dmp_sub f[0] c v K ] + f[1 ] u elif i > n return [dmp_neg c v K ] + dmp_zeros i - n v K + f else return f[ m] + [dmp_sub f[m] c v K ] + f[ m + 1 ]
def norm0255 arr arr arr.copy arr - arr.min arr * 255.0 / arr.max + 1e-10 arr np.array arr 'uint8' return arr
def clear_property zone key return _property 'clear' zone key None
def getHalfSimplifiedPath path radius remainder if len path < 2 return pathchannelRadius radius * 0.01 simplified [path[0]]for pointIndex in xrange 1 len path - 1 point path[pointIndex]if pointIndex % 2 remainder simplified.append point elif not isWithinChannel channelRadius pointIndex path simplified.append point simplified.append path[ -1 ] return simplified
def _get_userprofile_from_registry user sid profile_dir __salt__['reg.read_value'] 'HKEY_LOCAL_MACHINE' u'SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\ProfileList\\{0}'.format sid 'ProfileImagePath' ['vdata']log.debug u'user{0}withsid {2}profileislocatedat"{1}"'.format user profile_dir sid return profile_dir
def Assign target source if not isinstance target list target [target]if not isinstance source list source.prefix u''source [source]return Node syms.atom target + [Leaf token.EQUAL u' ' prefix u'' ] + source
def user_data_dir appname None appauthor None version None roaming False if system 'win32' if appauthor is None appauthor appnameconst roaming and 'CSIDL_APPDATA' or 'CSIDL_LOCAL_APPDATA' path os.path.normpath _get_win_folder const if appname if appauthor is not False path os.path.join path appauthor appname else path os.path.join path appname elif system 'darwin' path os.path.expanduser '~/Library/ApplicationSupport/' if appname path os.path.join path appname else path os.getenv 'XDG_DATA_HOME' os.path.expanduser '~/.local/share' if appname path os.path.join path appname if appname and version path os.path.join path version return path
def pw_affine fromim toim fp tp tri im toim.copy is_color len fromim.shape 3 im_t zeros im.shape 'uint8' for t in tri H homography.Haffine_from_points tp[ t] fp[ t] if is_color for col in range fromim.shape[2] im_t[ col] ndimage.affine_transform fromim[ col] H[ 2 2] H[ 0 2 ] H[ 1 2 ] im.shape[ 2] else im_t ndimage.affine_transform fromim H[ 2 2] H[ 0 2 ] H[ 1 2 ] im.shape[ 2] alpha alpha_for_triangle tp[ t] im.shape[0] im.shape[1] im[ alpha > 0 ] im_t[ alpha > 0 ]return im
def noop_node lineno return ExprStmt Const 0 .set_lineno lineno
@login_required@ensure_csrf_cookie@check_feature_enabled feature_name 'ENTRANCE_EXAMS' def entrance_exam request course_key_string course_key CourseKey.from_string course_key_string if not has_course_author_access request.user course_key return HttpResponse status 403 if request.method 'GET' return _get_entrance_exam request course_key elif request.method 'POST' response_format request.POST.get 'format' 'html' http_accept request.META.get 'http_accept' if response_format 'json' or 'application/json' in http_accept ee_min_score request.POST.get 'entrance_exam_minimum_score_pct' None entrance_exam_minimum_score_pct _get_default_entrance_exam_minimum_pct if ee_min_score ! '' and ee_min_score is not None entrance_exam_minimum_score_pct float ee_min_score return create_entrance_exam request course_key entrance_exam_minimum_score_pct return HttpResponse status 400 elif request.method 'DELETE' return delete_entrance_exam request course_key else return HttpResponse status 405
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def disable_insecure_serializers allowed ['json'] for name in registry._decoders registry.disable name if allowed is not None for name in allowed registry.enable name
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def get_tests_for python_name def _extract_ids t if isinstance t TestSuite result pset for sub_tests in t result result | _extract_ids sub_tests return resultelse return pset [t.id ] loader TestLoader tests loader.loadByName python_name recurse True return _extract_ids tests
@requires_csrf_tokendef page_not_found request template_name '404.html' try template loader.get_template template_name content_type Noneexcept TemplateDoesNotExist template Template '<h1>NotFound</h1><p>TherequestedURL{{request_path}}wasnotfoundonthisserver.</p>' content_type 'text/html'body template.render RequestContext request {'request_path' request.path} return http.HttpResponseNotFound body content_type content_type
def euclidean_distance u v diff u - v return sqrt numpy.dot diff diff
def list_to_string inlist endsep 'and' addquote False if not endsep endsep ' 'else endsep '' + endsep if not inlist return ''if addquote if len inlist 1 return '"%s"' % inlist[0] return ' '.join '"%s"' % v for v in inlist[ -1 ] + '%s%s' % endsep '"%s"' % inlist[ -1 ] else if len inlist 1 return str inlist[0] return ' '.join str v for v in inlist[ -1 ] + '%s%s' % endsep inlist[ -1 ]
def maybe_list l scalars Mapping string_t return l if l is None or is_list l scalars else [l]
def destroy_oauth_tokens user dop_access_token.objects.filter user user.id .delete dop_refresh_token.objects.filter user user.id .delete dot_access_token.objects.filter user user.id .delete dot_refresh_token.objects.filter user user.id .delete
def translation_matrix direction M numpy.identity 4 M[ 3 3] direction[ 3]return M
def get_info app env account container None swift_source None env.setdefault 'swift.infocache' {} if container path '/v1/%s/%s' % account container path_env env.copy path_env['PATH_INFO'] pathreturn get_container_info path_env app swift_source swift_source else path '/v1/%s' % account path_env env.copy path_env['PATH_INFO'] pathreturn get_account_info path_env app swift_source swift_source
def instantiate_descriptor **field_data system get_test_descriptor_system course_key SlashSeparatedCourseKey 'org' 'course' 'run' usage_key course_key.make_usage_key 'html' 'SampleHtml' return system.construct_xblock_from_class HtmlDescriptor scope_ids ScopeIds None None usage_key usage_key field_data DictFieldData field_data
def opt_in msg_hash email removed Email.handler.opt_in msg_hash if email and removed _system_email email '' Email.Kind.OPTIN return email removed
def iddr_svd A k A np.asfortranarray A U V S ier _id.iddr_svd A k if ier raise _RETCODE_ERRORreturn U V S
def _validate_int name value limits strip '%' comment ''try if isinstance value string_types value value.strip '' + strip value int value except TypeError ValueError comment + '{0}mustbeaninteger'.format name else if len limits 2 if value < limits[0] or value > limits[1] comment + '{0}mustbeintherange[{1[0]} {1[1]}]'.format name limits return value comment
def pull_from_email_account email_account email_account frappe.get_doc u'EmailAccount' email_account email_account.receive
def affinity_locality_predicate write_affinity_str affinity_str write_affinity_str.strip if not affinity_str return Nonematchers []pieces [s.strip for s in affinity_str.split ' ' ]for piece in pieces match re.match 'r \\d+ ? z \\d+ ?$' piece if match region zone match.groups region int region zone int zone if zone else None matcher {'region' region}if zone is not None matcher['zone'] zonematchers.append matcher else raise ValueError 'Invalidwrite-affinityvalue %r' % affinity_str def is_local ring_node for matcher in matchers if matcher['region'] ring_node['region'] and 'zone' not in matcher or matcher['zone'] ring_node['zone'] return Truereturn Falsereturn is_local
def train_autoencoder hidden_units training_data autoencoder_training_data [ x x for x _ in training_data]net Network [784 hidden_units 784] net.SGD autoencoder_training_data 6 10 0.01 0.05 return net
def wildcards2patterns wildcards return [re.compile '^' + wc.replace '.' '\\.' .replace '*' '.*' + '$' for wc in wildcards]
def CorrelatedNormalGenerator mu sigma rho for x in CorrelatedGenerator rho yield x * sigma + mu
def _raise_unknown_type element_type element_name raise InvalidBSON "DetectedunknownBSONtype%rforfieldname'%s'.Areyouusingthelatestdriverversion?" % element_type element_name
def is_device_memory obj return getattr obj '__cuda_memory__' False
def SubPlot plot_number rows None cols None rows rows or SUBPLOT_ROWS cols cols or SUBPLOT_COLS pyplot.subplot rows cols plot_number
def _solve_discrete_lyapunov_bilinear a q eye np.eye a.shape[0] aH a.conj .transpose aHI_inv inv aH + eye b np.dot aH - eye aHI_inv c 2 * np.dot np.dot inv a + eye q aHI_inv return solve_lyapunov b.conj .transpose - c
def xen_mem_use name global connvm_mem 0for id in conn.listDomainsID dom conn.lookupByID id info dom.info vm_mem vm_mem + info[2] return vm_mem
def CAN_CHANGE_PERMISSIONS article user return _is_staff_for_article article user
def pci_device_get_by_addr context node_id dev_addr return IMPL.pci_device_get_by_addr context node_id dev_addr
@utils.arg 'id' metavar '<id>' help _ 'IDoftheagent-build.' @utils.arg 'version' metavar '<version>' help _ 'Version.' @utils.arg 'url' metavar '<url>' help _ 'URL' @utils.arg 'md5hash' metavar '<md5hash>' help _ 'MD5hash.' def do_agent_modify cs args result cs.agents.update args.id args.version args.url args.md5hash utils.print_dict result.to_dict
def describe_object o FunctionType types.FunctionType MethodType types.MethodType InstanceType types.InstanceType sl []if isinstance o FunctionType try sl.append "<type'function'%s>" % str o.func_name except passelif isinstance o MethodType try sl.append "<type'method'%s>" % str o.im_func.func_name except passelif isinstance o InstanceType try sl.append "<type'instance'%s>" % str o.__class__.__name__ except passelse sl.append str type o try sl.append str len o except passreturn ''.join sl
def test_get_debug_values_exc prev_value config.compute_test_valuetry config.compute_test_value 'raise'x T.vector try for x_val in op.get_debug_values x assert Falseraised Falseexcept AttributeError raised Trueassert raisedfinally config.compute_test_value prev_value
def application_init args update False setup_environment process_args args app new_application args model new_model app args.repo prompt args.prompt settings args.settings if update model.update_status cfg gitcfg.current return ApplicationContext args app cfg model
def do_merge pr_url pr session response session.put pr_url + '/merge' data json.dumps dict sha pr['head']['sha'] if response.status_code ! 200 print 'PRfailedtomerge {}'.format response.json ['message'] return Falseelse print '{}at{}'.format response.json ['message'] response.json ['sha'] del_resp delete_branch pr session if del_resp.status_code ! 204 print 'Branchdeletionfailed {}'.format del_resp.content return Falseprint 'Branchdeleted' return True
def admin_url model url object_id None opts model._metaurl u'admin %s_%s_%s' % opts.app_label opts.object_name.lower url args if object_id is not None args object_id return reverse url args args
def short_group_names groups groups groups.split ' ' short_group_list []if helpers.set_up_anidb_connection for groupName in groups try group sickbeard.ADBA_CONNECTION.group gname groupName except AniDBCommandTimeoutError logger.log u'TimeoutwhileloadinggroupfromAniDB.Tryingnextgroup' logger.DEBUG except Exception logger.log u'FailedwhileloadinggroupfromAniDB.Tryingnextgroup' logger.DEBUG else for line in group.datalines if line['shortname'] short_group_list.append line['shortname'] elif groupName not in short_group_list short_group_list.append groupName else short_group_list groupsreturn short_group_list
def instance_test_and_set context instance_uuid attr ok_states new_state return IMPL.instance_test_and_set context instance_uuid attr ok_states new_state
def for_user user recs recommend_for_user user return 'Foruser{user} wholikes{liked} werecommend{recs}.'.format user user liked ' '.join brandsfor.get user ['nothing'] recs ' '.join recs
def match_host host pattern if ' ' in host host host_port host.rsplit ' ' 1 else host_port Noneif ' ' in pattern pattern pattern_port pattern.rsplit ' ' 1 if pattern_port '*' pattern_port Noneelse pattern_port Noneif pattern_port is not None and host_port ! pattern_port return Falsehost host.split '.' pattern pattern.split '.' if len pattern > len host return Falsefor h p in zip host pattern if h p or p '*' continueelse return Falsereturn True
def _all_traverse self result []result.append self for child in self.children result.extend child._all_traverse return result
def _patch_wrapper old new try new.__name__ old.__name__new.__module__ old.__module__new.__doc__ old.__doc__new.__dict__ old.__dict__except Exception passreturn new
def demo_bottom_cbar fig grid AxesGrid fig 121 nrows_ncols 2 2 axes_pad 0.1 share_all True label_mode '1' cbar_location 'bottom' cbar_mode 'edge' cbar_pad 0.25 cbar_size '15%' direction 'column' Z extent get_demo_image cmaps [plt.get_cmap 'autumn' plt.get_cmap 'summer' ]for i in range 4 im grid[i].imshow Z extent extent interpolation 'nearest' cmap cmaps[ i // 2 ] if i % 2 cbar grid.cbar_axes[ i // 2 ].colorbar im for cax in grid.cbar_axes cax.toggle_label True cax.axis[cax.orientation].set_label 'Bar' grid.axes_llc.set_xticks [ -2 0 2] grid.axes_llc.set_yticks [ -2 0 2]
def celery_settings request capital re.compile '^[A-Z]' settings [key for key in dir current_app.conf if capital.match key ]sorted_settings [{'key' key 'value' '*****' if 'password' in key.lower else getattr current_app.conf key } for key in sorted settings ]return render_to_response 'kadmin/settings.html' {'settings' sorted_settings 'title' 'CelerySettings'} RequestContext request {}
def rescale data_matrix means stdevs scale data_matrix def rescaled i j if stdevs[j] > 0 return data_matrix[i][j] - means[j] / stdevs[j] else return data_matrix[i][j] num_rows num_cols shape data_matrix return make_matrix num_rows num_cols rescaled
def keepOriginalText s startLoc t try endloc getTokensEndLoc except ParseException raise ParseFatalException 'incorrectusageofkeepOriginalText-mayonlybecalledasaparseaction' del t[ ]t + ParseResults s[startLoc endloc] return t
def get_disk_timeout scheme None return _get_powercfg_minute_values scheme 'SUB_DISK' 'DISKIDLE' 'Turnoffharddiskafter'
def get_calendar_info hass calendar calendar_info DEVICE_SCHEMA {CONF_CAL_ID calendar['id'] CONF_ENTITIES [{CONF_TRACK calendar['track'] CONF_NAME calendar['summary'] CONF_DEVICE_ID generate_entity_id '{}' calendar['summary'] hass hass }]} return calendar_info
def assert_true_instance logical_line if asse_trueinst_re.match logical_line yield 0 'G316 assertTrue isinstance a b sentencesnotallowed'
def _convert_to_example filename image_buffer label text height width colorspace 'RGB'channels 3image_format 'JPEG'example tf.train.Example features tf.train.Features feature {'image/height' _int64_feature height 'image/width' _int64_feature width 'image/colorspace' _bytes_feature tf.compat.as_bytes colorspace 'image/channels' _int64_feature channels 'image/class/label' _int64_feature label 'image/class/text' _bytes_feature tf.compat.as_bytes text 'image/format' _bytes_feature tf.compat.as_bytes image_format 'image/filename' _bytes_feature tf.compat.as_bytes os.path.basename filename 'image/encoded' _bytes_feature tf.compat.as_bytes image_buffer } return example
def partition lst f save_keys False d collections.OrderedDict for l in lst c f l s d.setdefault c [] s.append l if save_keys return delse return d.values
def _merge_and_sort_errors errors key_to_error {}for error in errors key _time_sort_key error key_to_error.setdefault key {} key_to_error[key].update error def sort_key key_and_error key error key_and_errorreturn key[0] bool error.get 'task_error' key[1 ] return [error for key error in sorted key_to_error.items key sort_key reverse True ]
def corr_nearest corr threshold 1e-15 n_fact 100 k_vars corr.shape[0]if k_vars ! corr.shape[1] raise ValueError 'matrixisnotsquare' diff np.zeros corr.shape x_new corr.copy diag_idx np.arange k_vars for ii in range int len corr * n_fact x_adj x_new - diff x_psd clipped clip_evals x_adj value threshold if not clipped x_new x_psdbreakdiff x_psd - x_adj x_new x_psd.copy x_new[ diag_idx diag_idx ] 1else import warningswarnings.warn iteration_limit_doc IterationLimitWarning return x_new
def bind_row_anchor_column column_name def decorator method @functools.wraps method def wrapper table row cell row.cells[column_name]action_element cell.find_element by.By.CSS_SELECTOR 'td.%s>a' % NORMAL_COLUMN_CLASS return method table action_element row return wrapperreturn decorator
def _find_predicates expr if not isinstance expr BooleanFunction return {expr}return set .union * _find_predicates i for i in expr.args
def getRMS data def _rms data 'Audioloudness/power asrms;~2xfasterthanstd \n'if len data.shape > 1 return np.std data axis 1 return np.std data if isinstance data basestring if not os.path.isfile data raise ValueError 'getRMS couldnotfindfile%s' % data _junk data wavfile.read data data_tr np.transpose data data data_tr / 32768.0 elif not isinstance data np.ndarray data np.array data .astype np.float return _rms data
def _validate_min_score min_score if min_score message _ '% min_score sisnotavalidgradepercentage' % {'min_score' min_score} try min_score int min_score except ValueError raise GatingValidationError message if min_score < 0 or min_score > 100 raise GatingValidationError message
def strict_eq x y __tracebackhide__ Trueassert x y assert issubclass type x type y or issubclass type y type x if isinstance x dict and isinstance y dict x sorted x.items y sorted y.items elif isinstance x set and isinstance y set x sorted x y sorted y assert repr x repr y
def _zconfint_generic mean std_mean alpha alternative if alternative in ['two-sided' '2-sided' '2s'] zcrit stats.norm.ppf 1 - alpha / 2.0 lower mean - zcrit * std_mean upper mean + zcrit * std_mean elif alternative in ['larger' 'l'] zcrit stats.norm.ppf alpha lower mean + zcrit * std_mean upper np.infelif alternative in ['smaller' 's'] zcrit stats.norm.ppf 1 - alpha lower - np.inf upper mean + zcrit * std_mean else raise ValueError 'invalidalternative' return lower upper
def start_response_app environ start_response raise ValueError 'hi'
def get_more_info_for_log more_info []site getattr frappe.local u'site' None if site more_info.append u'Site {0}'.format site form_dict getattr frappe.local u'form_dict' None if form_dict more_info.append u'FormDict {0}'.format frappe.as_json form_dict if more_info more_info more_info + [u''] return u'\n'.join more_info
def _prod_vectorized M1 M2 sh1 M1.shapesh2 M2.shapeassert len sh1 > 2 assert len sh2 > 2 assert sh1[ -1 ] sh2[ -2 ] ndim1 len sh1 t1_index list xrange ndim1 - 2 + [ ndim1 - 1 ndim1 - 2 ] return np.sum np.transpose M1 t1_index [... np.newaxis] * M2[... np.newaxis ] -3
def to_base85 x islong False size 10 if islong else 5 rems ''for i in xrange size rems b85chars[ x % 85 ] + rems x // 85return rems
def torrent_availability seeds leeches return seeds * 2 + leeches
def get_table_description cursor table_name cursor.execute 'SELECT*FROM%sLIMIT1' % quote_name table_name return cursor.description
def pages_to_list items objs []while True try page items.next for item in page objs.append item except GeneratorExit breakreturn objs
def replace name repl full_match False ret {'name' name 'result' False 'changes' {} 'comment' ''}if full_match is False search '^.*{0}.*$'.format name else search namematches __salt__['nxos.cmd'] 'find' search if not matches ret['result'] Trueret['comment'] 'Nothingfoundtoreplace'return retif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configswillbechanged'ret['changes']['old'] matchesret['changes']['new'] [re.sub name repl match for match in matches]return retret['changes'] __salt__['nxos.cmd'] 'replace' name repl full_match full_match matches __salt__['nxos.cmd'] 'find' search if matches ret['result'] Falseret['comment'] 'Failedtoreplaceallinstancesof"{0}"'.format name else ret['result'] Trueret['comment'] 'Successfullyreplacedallinstancesof"{0}"with"{1}"'.format name repl return ret
def install_build_utils apt_install BUILD_UTILS_PKGS
def _netstat_sunos log.warning 'Userandprogramnot yet supportedonSunOS' ret []for addr_family in 'inet' 'inet6' cmd 'netstat-f{0}-Ptcp-an|tail-n+5'.format addr_family out __salt__['cmd.run'] cmd python_shell True for line in out.splitlines comps line.split ret.append {'proto' 'tcp6' if addr_family 'inet6' else 'tcp' 'recv-q' comps[5] 'send-q' comps[4] 'local-address' comps[0] 'remote-address' comps[1] 'state' comps[6]} cmd 'netstat-f{0}-Pudp-an|tail-n+5'.format addr_family out __salt__['cmd.run'] cmd python_shell True for line in out.splitlines comps line.split ret.append {'proto' 'udp6' if addr_family 'inet6' else 'udp' 'local-address' comps[0] 'remote-address' comps[1] if len comps > 2 else '' } return ret
def get_page_classes warn u'get_page_classesisdeprecatedinReviewBoard3.0andwillberemoved;iteratethroughAccountPage.registryinstead.' DeprecationWarning return iter AccountPage.registry
def parse_media_range range type subtype params parse_mime_type range try if not 0 < float params['q'] < 1 raise ValueErrorexcept KeyError ValueError params['q'] '1'return type subtype params
def _CopyMetadataToProtocolBuffer index spec_pb spec_pb.set_name index.name.encode 'utf-8' spec_pb.set_namespace index.namespace.encode 'utf-8' if index._source ! Index.SEARCH spec_pb.set_source _SOURCES_TO_PB_MAP.get index._source
def short_platform r None p None if r is None r platform.release if p is None p platform.platform sp r.split '-' if len sp < 2 return pkernel_version sp[0].split '.' if len kernel_version < 2 return psp[0] '.'.join kernel_version[ 2] rest sp[1].split '.' while len rest if rest[0].isdigit del rest[0]else breaksp[1] '.'.join rest sr '-'.join sp p p.replace r sr return p
def make_filesystem device block_device options []if block_device and not device.isBlockDevice raise Exception '{}isnotablockdevicebutitwasexpectedtobe'.format device.path elif device.isBlockDevice and not block_device raise Exception '{}isablockdevicebutitwasnotexpectedtobe'.format device.path if not block_device options.extend ['-F'] command ['mkfs'] + options + ['-t' 'ext4' device.path] run_process command
def set_auth auth key _auth_registry_key request None request request or webapp2.get_request request.registry[key] auth
def _merge_extra_filerefs *args ret []for arg in args if isinstance arg string_types if arg ret.extend arg.split ' ' elif isinstance arg list if arg ret.extend arg return ' '.join ret
def get url conn urlopen url resp conn.read conn.close return resp
def _check_arguments kwargs release deprecated_name right_name None if deprecated_name in kwargs if right_name if right_name in kwargs msg _LW "The'% old s'argumentisdeprecatedin% release sanditsusemayresultinerrorsinfuturereleases.As'% new s'isprovided the'% old s'argumentwillbeignored." % {'old' deprecated_name 'release' release 'new' right_name} kwargs.pop deprecated_name else msg _LW "The'% old s'argumentisdeprecatedin% release sanditsusemayresultinerrorsinfuturereleases.Use'% right s'instead." % {'old' deprecated_name 'release' release 'right' right_name} kwargs[right_name] kwargs.pop deprecated_name else msg _LW "The'% old s'argumentisdeprecatedin% release sanditsusemayresultinerrorsinfuturereleases." % {'old' deprecated_name 'release' release} kwargs.pop deprecated_name warnings.warn msg
def _discover_test_modules package_dir def is_unittest_module path file_name os.path.basename path return file_name.startswith UNITTEST_FILE_PREFIX names get_module_names package_dir package_dir should_include is_unittest_module if len names < 1 raise Exception 'Nounit-testmodulesfound--\nin%s' % package_dir return names
def skip_unless_internalhash test ok sys.hash_info.algorithm in {'fnv' 'siphash24'} msg 'RequiresSipHash24orFNV'return test if ok else unittest.skip msg test
def get_comment_header line m re.match '^ [\\t]*#* ' line if m is None return ''return m.group 1
def dbg_signal sig args return '{} {} '.format signal_name sig format_args args
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def add_ssh_public_key name filename add_ssh_public_keys name [filename]
def mkalias src dst relative None srcfsr File.FSRef src dstdir dstname os.path.split dst if not dstdir dstdir os.curdirdstdirfsr File.FSRef dstdir if relative relativefsr File.FSRef relative alias File.FSNewAlias relativefsr srcfsr else alias srcfsr.FSNewAliasMinimal dstfsr dstfss Res.FSCreateResourceFile dstdirfsr unicode dstname File.FSGetResourceForkName h Res.FSOpenResourceFile dstfsr File.FSGetResourceForkName 3 resource Res.Resource alias.data resource.AddResource 'alis' 0 '' Res.CloseResFile h dstfinfo dstfss.FSpGetFInfo dstfinfo.Flags dstfinfo.Flags | 32768 dstfss.FSpSetFInfo dstfinfo
@transaction.non_atomic_requests@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def spoc_gradebook request course_id course_key CourseKey.from_string course_id course get_course_with_access request.user 'staff' course_key depth None student_info page get_grade_book_page request course course_key return render_to_response 'courseware/gradebook.html' {'page' page 'page_url' reverse 'spoc_gradebook' kwargs {'course_id' unicode course_key } 'students' student_info 'course' course 'course_id' course_key 'staff_access' True 'ordered_grades' sorted course.grade_cutoffs.items key lambda i i[1] reverse True }
def _decode_file path fp open path 'r' txt fp.readline m re.search '#encoding[ \\s]+ \\S+ ' txt if m and m.group 1 encoding m.group 1 else encoding 'latin-1'source fp.read fp.close try return source.decode encoding except return ''
def getNewDerivation elementNode return GridDerivation elementNode
@given u'afilenamed"{filename}"with' def step_a_file_named_filename_with context filename step_a_file_named_filename_and_encoding_with context filename 'UTF-8' if filename.endswith '.feature' command_util.ensure_context_attribute_exists context 'features' [] context.features.append filename
def get_pack_base_path pack_name if not pack_name return Nonepacks_base_paths get_packs_base_paths for packs_base_path in packs_base_paths pack_base_path os.path.join packs_base_path quote_unix pack_name pack_base_path os.path.abspath pack_base_path if os.path.isdir pack_base_path return pack_base_pathpack_base_path os.path.join packs_base_paths[0] quote_unix pack_name pack_base_path os.path.abspath pack_base_path return pack_base_path
def test_same_max_and_relative_values_sparktext chart Line chart.add '_' [0 0 0 0 0] assert chart.render_sparktext u '\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81' chart2 Line chart2.add '_' [1 1 1 1 1] assert chart2.render_sparktext relative_to 1 u '\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81\xe2\x96\x81'
def test_choose_port_returns_a_port_number app OnionShare app.choose_port assert 1024 < app.port < 65535
def test_greaterthan value other return value > other
@register.filter name 'currency' def currency value currency None try value D value except TypeError InvalidOperation return u''kwargs {'currency' currency if currency else settings.OSCAR_DEFAULT_CURRENCY 'format' getattr settings 'OSCAR_CURRENCY_FORMAT' None 'locale' to_locale get_language or settings.LANGUAGE_CODE }return format_currency value **kwargs
def _check_means means n_components n_features means check_array means dtype [np.float64 np.float32] ensure_2d False _check_shape means n_components n_features 'means' return means
@collect_authdef auth_login auth campaign request.args.get 'campaign' next_url request.args.get 'next' data login_and_register_handler auth login True campaign campaign next_url next_url if data['status_code'] http.FOUND return redirect data['next_url']
def LocateOptionalFileName fileName searchPaths None try return LocateFileName fileName searchPaths except KeyboardInterrupt return None
def _expires name cert_file _cert_file name 'cert' if 'tls.cert_info' in __salt__ expiry __salt__['tls.cert_info'] cert_file ['not_after']else openssl_cmd 'opensslx509-in{0}-noout-enddate'.format cert_file strptime_sux_cmd 'date--date "$ {0}|cut-d -f2 "+%s'.format openssl_cmd expiry float __salt__['cmd.shell'] strptime_sux_cmd output_loglevel 'quiet' return datetime.datetime.fromtimestamp expiry
def _freedman_diaconis_bins a a np.asarray a h 2 * iqr a / len a ** 1 / 3 if h 0 return int np.sqrt a.size else return int np.ceil a.max - a.min / h
def get_manager_class rdbms_type klass RDBMS_REGISTRY.get rdbms_type None if klass is None logging.info 'There\'snodatabasemanagerspecificfor"%s"' rdbms_type klass DummyDatabaseManagerreturn klass
def test_hsl_to_rgb_part_8 assert hsl_to_rgb 60 20 50 153 153 102 assert hsl_to_rgb 60 60 50 204 204 51 assert hsl_to_rgb 60 100 50 255 255 0
def extract_from_dict data path value datatry for key in path value value[key]return valueexcept KeyError IndexError TypeError return ''
def get_contact_objects current_user contact objects dict CONTACT_OBJECTS for key in objects if hasattr contact key manager getattr contact key try manager manager.filter status__hidden False except passobjects[key]['objects'] Object.filter_permitted current_user manager return objects
def _depth_first_select rectangles min_area j None None for i _ u v s t _ _ _ _ in enumerate rectangles area s - u * t - v if min_area is None or area < min_area min_area j area i return rectangles.pop j
def getval filename keyword *args **kwargs if 'do_not_scale_image_data' not in kwargs kwargs['do_not_scale_image_data'] Truehdr getheader filename *args **kwargs return hdr[keyword]
def getSVGByLoopLayers addLayerTemplateToSVG carving loopLayers if len loopLayers < 1 return ''decimalPlacesCarried max 0 2 - int math.floor math.log10 carving.layerThickness svgWriter SVGWriter addLayerTemplateToSVG carving.getCarveCornerMaximum carving.getCarveCornerMinimum decimalPlacesCarried carving.getCarveLayerThickness return svgWriter.getReplacedSVGTemplate carving.fileName loopLayers 'basic' carving.getFabmetheusXML
def version_exclude_prerelease versions output []for version in versions if SemVer semver_compat version .prerelease is not None continueoutput.append version return output
@needs 'pavelib.prereqs.install_prereqs' 'pavelib.utils.test.utils.clean_reports_dir' @cmdopts [ 'failed' 'f' 'Runonlyfailedtests' 'fail-fast' 'x' 'Runonlyfailedtests' make_option '-c' '--cov-args' default '' help 'addsasargstocoverageforthetestrun' make_option '--verbose' action 'store_const' const 2 dest 'verbosity' make_option '-q' '--quiet' action 'store_const' const 0 dest 'verbosity' make_option '-v' '--verbosity' action 'count' dest 'verbosity' default 1 make_option '--disable-migrations' action 'store_true' dest 'disable_migrations' help "Createtablesdirectlyfromapps'models.CanalsobeusedbyexportingDISABLE_MIGRATIONS 1." 'cov_args ' None 'deprecatedinfavorofcov-args' make_option '-e' '--extra_args' default '' help 'deprecated passextraoptionsdirectlyinthepavercommandline' 'fail_fast' None 'deprecatedinfavoroffail-fast' ] @PassthroughTask@timeddef test_python options passthrough_options python_suite suites.PythonTestSuite 'PythonTests' passthrough_options passthrough_options **options.test_python python_suite.run
def _check_version actver version cmp_op try if cmp_op '>' return LooseVersion actver > LooseVersion version elif cmp_op '> ' return LooseVersion actver > LooseVersion version elif cmp_op ' ' return LooseVersion actver LooseVersion version elif cmp_op '<' return LooseVersion actver < LooseVersion version else return Falseexcept TypeError return True
def output string_ context.output + str string_
def assertIs first second msg '' a b first second assert a is b '%s %risnot%r' % msg.format a b a b
def dup_revert f n K g [K.revert dup_TC f K ]h [K.one K.zero K.zero]N int _ceil _log n 2 for i in range 1 N + 1 a dup_mul_ground g K 2 K b dup_mul f dup_sqr g K K g dup_rem dup_sub a b K h K h dup_lshift h dup_degree h K return g
def _exclude_home path_list home os.path.expanduser '~' for p in path_list if not p.startswith home yield p
def get_open_threads exploration_id has_suggestion threads get_threads exploration_id open_threads []for thread in threads if thread.has_suggestion has_suggestion and thread.status feedback_models.STATUS_CHOICES_OPEN open_threads.append thread return open_threads
def test_clrtype_metaclass_characteristics class T type 'Thisisourowntype'def __clrtype__ self return type.__clrtype__ self class X object __metaclass__ TAreEqual X.__class__ T AreEqual X.__metaclass__ X.__class__ AreEqual X.__class__.__base__ type AreEqual X.__class__.__bases__ type AreEqual X.__class__.__doc__ 'Thisisourowntype' x X Assert isinstance x X Assert not isinstance x T Assert not issubclass X T AreEqual x.__class__ X AreEqual x.__metaclass__ T
def get_name_of_init run utils.run global _init_nametry return _init_nameexcept NameError AttributeError _init_name _get_name_of_init run return _init_name
def create_catalog_by_name name T 'general' result util.callm 'catalog/create' {} POST True data {'name' name 'type' T} result result['response']return Catalog result['id'] **dict k result[k] for k in 'name' 'type'
def _check_call *args **kwargs kwargs['stderr'] open devnull 'w' return check_call *args **kwargs
def cov_cluster results group use_correction True xu hessian_inv _get_sandwich_arrays results cov_type 'clu' if not hasattr group 'dtype' or group.dtype ! np.dtype 'int' clusters group np.unique group return_inverse True else clusters np.unique group scale S_crosssection xu group nobs k_params xu.shapen_groups len clusters cov_c _HCCM2 hessian_inv scale if use_correction cov_c * n_groups / n_groups - 1.0 * nobs - 1.0 / float nobs - k_params return cov_c
def S_ISBLK mode return S_IFMT mode S_IFBLK
def Match pattern s if pattern not in _regexp_compile_cache _regexp_compile_cache[pattern] sre_compile.compile pattern return _regexp_compile_cache[pattern].match s
@login_required redirect False @json_view@non_atomic_requestsdef ajax request if 'q' not in request.GET raise http.Http404 data {'status' 0 'message' ''}email request.GET.get 'q' '' .strip if not email data.update message _ 'Anemailaddressisrequired.' return datauser UserProfile.objects.filter email email msg _ 'Auserwiththatemailaddressdoesnotexist.' if user data.update status 1 id user[0].id name user[0].name else data['message'] msgreturn escape_all data
def hr_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'hrm' 'human_resource'
def warn msg stacklevel 3 if isinstance msg compat.string_types warnings.warn msg exc.SAWarning stacklevel stacklevel else warnings.warn msg stacklevel stacklevel
@hook.commanddef spalbum text params {'q' text.strip }request requests.get 'http //ws.spotify.com/search/1/album.json' params params if request.status_code ! requests.codes.ok return 'Couldnotgetalbuminformation {}'.format request.status_code data request.json try _type _id data['albums'][0]['href'].split ' ' [1 ]except IndexError return 'Couldnotfindalbum.'url web.try_shorten gateway.format _type _id return '\x02{}\x02by\x02{}\x02-{}'.format data['albums'][0]['name'] data['albums'][0]['artists'][0]['name'] url
def _walk_vdi_chain session vdi_uuid scan_default_sr session while True vdi_ref session.call_xenapi 'VDI.get_by_uuid' vdi_uuid vdi_rec session.call_xenapi 'VDI.get_record' vdi_ref yield vdi_rec parent_uuid _get_vhd_parent_uuid session vdi_ref if not parent_uuid breakvdi_uuid parent_uuid
def tracked_files *args out git.ls_files u'--' z True *args [STDOUT]if out return sorted out[ -1 ].split u'\x00' else return []
def get_group_id_for_comments_service request course_key commentable_id None if commentable_id is None or is_commentable_cohorted course_key commentable_id if request.method 'GET' requested_group_id request.GET.get 'group_id' elif request.method 'POST' requested_group_id request.POST.get 'group_id' if has_permission request.user 'see_all_cohorts' course_key if not requested_group_id return Nonetry group_id int requested_group_id get_cohort_by_id course_key group_id except CourseUserGroup.DoesNotExist raise ValueErrorelse group_id get_cohort_id request.user course_key return group_idelse return None
def getLocalIP retVal Nonetry s socket.socket socket.AF_INET socket.SOCK_STREAM s.connect conf.hostname conf.port retVal _ s.getsockname s.close except debugMsg 'therewasanerrorinopeningsocket'debugMsg + "connectiontoward'%s'" % conf.hostname logger.debug debugMsg return retVal
def user_list profile None **connection_args kstone auth profile **connection_args ret {}for user in kstone.users.list ret[user.name] dict value getattr user value None for value in dir user if not value.startswith '_' and isinstance getattr user value None six.text_type dict bool str tenant_id getattr user 'tenantId' None if tenant_id ret[user.name]['tenant_id'] tenant_idreturn ret
def match_file filename exclude base_name os.path.basename filename if base_name.startswith u'.' return Falsefor pattern in exclude if fnmatch.fnmatch base_name pattern return Falseif fnmatch.fnmatch filename pattern return Falseif not os.path.isdir filename and not is_python_file filename return Falsereturn True
def solc_arguments libraries None combined 'bin abi' optimize True extra_args None args ['--combined-json' combined '--add-std']if optimize args.append '--optimize' if extra_args try args.extend shlex.split extra_args except args.extend extra_args if libraries is not None and len libraries addresses ['{name} {address}'.format name name address address.decode 'utf8' for name address in libraries.items ]args.extend ['--libraries' ' '.join addresses ] return args
def _inherit_from context uri calling_uri if uri is None return Nonetemplate _lookup_template context uri calling_uri self_ns context['self']ih self_nswhile ih.inherits is not None ih ih.inheritslclcontext context.locals_ {'next' ih} ih.inherits TemplateNamespace 'self %s' % template.uri lclcontext template template populate_self False context._data['parent'] lclcontext._data['local'] ih.inheritscallable_ getattr template.module '_mako_inherit' None if callable_ is not None ret callable_ template lclcontext if ret return retgen_ns getattr template.module '_mako_generate_namespaces' None if gen_ns is not None gen_ns context return template.callable_ lclcontext
def _pg_is_older_ext_ver a b return a < b
def dup_ff_prs_gcd f g K result _dup_ff_trivial_gcd f g K if result is not None return resulth dup_subresultants f g K [ -1 ]h dup_monic h K cff dup_quo f h K cfg dup_quo g h K return h cff cfg
def _af_invert a inv_form [0] * len a for i ai in enumerate a inv_form[ai] ireturn inv_form
def test_get_index_urls_locations finder PackageFinder [] ['file //index1/' 'file //index2'] session PipSession locations finder._get_index_urls_locations InstallRequirement.from_line 'Complex_Name' .name assert locations ['file //index1/complex-name/' 'file //index2/complex-name/']
def member_roles_list context data_dict group_type data_dict.get 'group_type' 'organization' roles_list authz.roles_list if group_type 'group' roles_list [role for role in roles_list if role['value'] ! 'editor' ]_check_access 'member_roles_list' context data_dict return roles_list
def separate_interface_data ospf_data ospf_data re.split ' .+isup lineprotocolisup ' ospf_data ospf_data.pop 0 ospf_list []while True if len ospf_data > 2 intf ospf_data.pop 0 section ospf_data.pop 0 ospf_string intf + section ospf_list.append ospf_string else breakreturn ospf_list
def enableConcurrencyChecks maxConcurrency raiseException True global g_max_concurrency g_max_concurrency_raise_exceptionassert maxConcurrency > 0 g_max_concurrency maxConcurrencyg_max_concurrency_raise_exception raiseExceptionreturn
def format_signature signature terms {'\n' '' '[source]' '' u'\xb6' ''}return replace_all signature terms
def path_for_script script return path.join current_directory script
def fill_notebook work_notebook script_blocks for blabel bcontent in script_blocks if blabel 'code' add_code_cell work_notebook bcontent else add_markdown_cell work_notebook text2string bcontent
def check_dbl result func cargs if result ! 1 return Nonereturn last_arg_byref cargs
def encode_path p if not isinstance p unicode raise TypeError u'Canonlyencodeunicode not{}'.format type p return p.encode _FILESYSTEM_ENCODING
def package_create_default_resource_views context data_dict dataset_dict _get_or_bust data_dict 'package' _check_access 'package_create_default_resource_views' context data_dict create_datastore_views paste.deploy.converters.asbool data_dict.get 'create_datastore_views' False return ckan.lib.datapreview.add_views_to_dataset_resources context dataset_dict view_types [] create_datastore_views create_datastore_views
def getPluginsDirectoryPath return archive.getAbsoluteFolderPath os.path.dirname __file__ os.path.join 'skeinforge_plugins' 'analyze_plugins'
def dup_factor_list_include f K coeff factors dup_factor_list f K if not factors return [ dup_strip [coeff] 1 ]else g dup_mul_ground factors[0][0] coeff K return [ g factors[0][1] ] + factors[1 ]
def get_indexes cursor table_name raise NotImplementedError
def current_request_has_associated_site_theme request get_current_request site_theme getattr request 'site_theme' None return bool site_theme and site_theme.id
def list2numpy l dtype object from numpy import emptya empty len l dtype for i s in enumerate l a[i] sreturn a
def test_add_column mixin_cols attrs 'name' 'unit' 'dtype' 'format' 'description' 'meta' m mixin_cols['m']assert m.info.name is None t QTable [m] names ['a'] assert m.info.name is None t['new'] massert m.info.name is None m.info.name 'm'm.info.format '{0}'m.info.description 'd'm.info.meta {'a' 1}t QTable [m] t['m2'] mm.info.name 'm3't.add_columns [m] copy True m.info.name 'm4't.add_columns [m] copy False for name in 'm2' 'm3' 'm4' assert_table_name_col_equal t 'm' t[name] for attr in attrs if attr ! 'name' assert getattr t['m'].info attr getattr t[name].info attr
def returns model downgrade None upgrade None return attrsetter '_returns' model downgrade upgrade
def subs task key val if not istask task try if type task is type key and task key return valexcept Exception passif isinstance task list return [subs x key val for x in task]return tasknewargs []for arg in task[1 ] if istask arg arg subs arg key val elif isinstance arg list arg [subs x key val for x in arg]elif type arg is type key and arg key arg valnewargs.append arg return task[ 1] + tuple newargs
def event name ret {'name' name 'changes' {} 'comment' '' 'result' False}for event in __events__ if salt.utils.expr_match event['tag'] name ret['result'] Truereturn ret
def compile_args args kwargs sep prefix processed_args []encode encode_to_py3bytes_or_py2strfor arg in args if isinstance arg list tuple if isinstance arg GlobResults and not arg arg [arg.path]for sub_arg in arg processed_args.append encode sub_arg elif isinstance arg dict processed_args + aggregate_keywords arg sep prefix raw True else processed_args.append encode arg processed_args + aggregate_keywords kwargs sep prefix return processed_args
def LogInit logging.debug 'InitializingLoggingsubsystem.' if flags.FLAGS.verbose config_lib.CONFIG.AddContext 'DebugContext' 'Thiscontextistoallowverboseanddebugoutputfromthebinary.' logger logging.getLogger memory_handlers [m for m in logger.handlers if m.__class__.__name__ 'PreLoggingMemoryHandler' ]logger.handlers list GetLogHandlers SetLogLevels for handler in memory_handlers for record in handler.buffer logger.handle record
def single_param schema ret multi_params schema ret['maxItems'] 1return ret
@image_comparison baseline_images [u'EventCollection_plot__set_lineoffset'] def test__EventCollection__set_lineoffset splt coll props generate_EventCollection_plot new_lineoffset -5.0 coll.set_lineoffset new_lineoffset assert_equal new_lineoffset coll.get_lineoffset check_segments coll props[u'positions'] props[u'linelength'] new_lineoffset props[u'orientation'] splt.set_title u'EventCollection set_lineoffset' splt.set_ylim -6 -4
def getGeometryOutput derivation xmlElement if derivation None derivation ShaftDerivation derivation.setToXMLElement xmlElement shaftPath getShaftPath derivation.depthBottom derivation.depthTop derivation.radius derivation.sides return lineation.getGeometryOutputByLoop lineation.SideLoop shaftPath xmlElement
def apply_vagrant_workaround if os.environ.get 'USER' None 'vagrant' del os.link
def scheduled_resume global __PAUSE_ENDif __PAUSE_END is None sabnzbd.unpause_all
def parse_spec text tokens text.split ' ' specs []for token in tokens if ' ' not in token token + ' 1' sizespec weight token.split ' ' weight float weight units {'m' 1 'g' 1 << 10 't' 1 << 20 'p' 1 << 30 }unit units.get sizespec[ -1 ].lower None if not unit size float sizespec unit 1else size float sizespec[ -1 ] spec PartitionSpec int size * unit weight specs.append spec return specs
def get_spacing_matrix size spacing offset val_arr []row_arr []col_arr []for var_row in range size[1] val_arr.append 1.0 row_arr.append spacing * var_row + offset col_arr.append var_row mat sp.coo_matrix val_arr row_arr col_arr size .tocsc return lu.create_const mat size sparse True
def do_translate message translation_function global _defaulteol_message message and message.replace str u'\r\n' str u'\n' .replace str u'\r' str u'\n' or None t getattr _active u'value' None if t is not None result getattr t translation_function eol_message else if _default is None from django.conf import settings_default translation settings.LANGUAGE_CODE result getattr _default translation_function eol_message if isinstance message SafeData return mark_safe result return result
def account_check f def wrapper self *args **kwargs for arg in args if isinstance arg PaymentAccount and arg.provider ! self.provider raise ValueError 'Wrongaccount{0}! {1}'.format arg.provider self.provider return f self *args **kwargs return wrapper
def list_nodes_full call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodes_fullfunctionmustbecalledwith-for--function.' return get_resources_vms includeConfig True
def prepare_multi_upload_segments yield FakeWalSegment '0' * 8 * 3 explicit True for i in range 1 5 yield FakeWalSegment str i * 8 * 3 explicit False
def gen_salt length if length < 0 raise ValueError 'Saltlengthmustbepositive' return ''.join _sys_rng.choice SALT_CHARS for _ in range_type length
def is_html ct_headers url allow_xhtml False if not ct_headers ext os.path.splitext _rfc3986.urlsplit url [2] [1]html_exts ['.htm' '.html']if allow_xhtml html_exts + ['.xhtml']return ext in html_exts ct split_header_words ct_headers [0][0][0]html_types ['text/html']if allow_xhtml html_types + ['text/xhtml' 'text/xml' 'application/xml' 'application/xhtml+xml']return ct in html_types
def get_valid_column_name field if not REGEX_VALID_TB_FLD.match field if re.match '^[0-9]' field numbers ['Zero' 'One' 'Two' 'Three' 'Four' 'Five' 'Six' 'Seven' 'Eight' 'Nine']field numbers[int field[0] ] + field[1 ] field INVALID_CHARS.sub '_' field return field
def normalize_paragraph text line_len 80 indent '' text _NORM_SPACES_RGX.sub '' text line_len line_len - len indent lines []while text aline text splittext text.strip line_len lines.append indent + aline return linesep.join lines
def skip_if_command_unavailable cmd from matplotlib.compat.subprocess import check_outputtry check_output cmd except return skipif True reason u'missingcommand %s' % cmd[0] return lambda f f
def _flip_fiducials idx_points_nm idx_points_nm[[1 2]] idx_points_nm[[2 1]]return idx_points_nm
def _list_libraries request lib_info [{'display_name' lib.display_name 'library_key' unicode lib.location.library_key } for lib in modulestore .get_libraries if has_studio_read_access request.user lib.location.library_key ]return JsonResponse lib_info
def _trace_S s j b S_cosets for h in S_cosets[b] if s[h[b]] j return hreturn None
def group_type_access_get_all context type_id return IMPL.group_type_access_get_all context type_id
def equalize_hist image nbins 256 mask None if mask is not None mask np.array mask dtype bool cdf bin_centers cumulative_distribution image[mask] nbins else cdf bin_centers cumulative_distribution image nbins out np.interp image.flat bin_centers cdf return out.reshape image.shape
def cache_set key value timeout None refreshed False if timeout is None timeout settings.CACHE_MIDDLEWARE_SECONDSrefresh_time timeout + time real_timeout timeout + settings.CACHE_SET_DELAY_SECONDS packed value refresh_time refreshed return cache.set _hashed_key key packed real_timeout
def extract_digest_key_date digest_s3_key return digest_s3_key[ -24 -8 ]
def get_vagrant_config result local 'vagrantssh-config' capture True conf {}for line in iter result.splitlines parts line.split conf[parts[0]] ''.join parts[1 ] return conf
def vg_check vg_name cmd 'vgdisplay%s' % vg_name try utils.run cmd logging.debug 'Providedvolumegroupexists %s' vg_name return Trueexcept error.CmdError return False
def _initialize_issue_counts review_request if review_request.pk is None return 0issue_counts fetch_issue_counts review_request review_request.issue_open_count issue_counts[BaseComment.OPEN]review_request.issue_resolved_count issue_counts[BaseComment.RESOLVED]review_request.issue_dropped_count issue_counts[BaseComment.DROPPED]review_request.save update_fields [u'issue_open_count' u'issue_resolved_count' u'issue_dropped_count'] return None
def _py_WX28_convert_agg_to_wx_image agg bbox if bbox is None image wx.EmptyImage int agg.width int agg.height image.SetData agg.tostring_rgb return imageelse return wx.ImageFromBitmap _WX28_clipped_agg_as_bitmap agg bbox
def top_last_month cls key ids None num None cur_month datetime.date.today .replace day 1 last_month decrement_month cur_month q Session.query cls .filter cls.date last_month .filter cls.interval 'month' .order_by desc cls.date desc cls.pageview_count if ids q q.filter getattr cls key .in_ ids else num num or 55 q q.limit num return [ getattr r key r.unique_count r.pageview_count for r in q.all ]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def from_nested_tuple sequence sensible_relabeling False def _make_tree sequence 'Recursivelycreatesatreefromthegivensequenceofnested\ntuples.\n\nThisfunctionemploysthe func `~networkx.tree.join`function\ntorecursivelyjoinsubtreesintoalargertree.\n\n'if len sequence 0 return nx.empty_graph 1 return nx.tree.join [ _make_tree child 0 for child in sequence] T _make_tree sequence if sensible_relabeling bfs_nodes chain [0] v for u v in nx.bfs_edges T 0 labels {v i for i v in enumerate bfs_nodes }T nx.relabel_nodes T labels return T
def assert_case_equal case actual desired assert actual desired '\nTest%rfailed.\nactual %s\ndesired %s\n' % case actual desired
def volume_get context volume_id return IMPL.volume_get context volume_id
def force_copy src dest if os.path.isfile dest os.remove dest if os.path.isdir dest dest os.path.join dest os.path.basename src shutil.copyfile src dest return dest
def migration_get_all_unconfirmed context confirm_window return IMPL.migration_get_all_unconfirmed context confirm_window
def latex_preview math_expr variables functions case_sensitive False if math_expr.strip '' return ''latex_interpreter ParseAugmenter math_expr case_sensitive latex_interpreter.parse_algebra variables functions add_defaults variables functions case_sensitive if case_sensitive casify lambda x x else casify lambda x x.lower render_actions {'number' render_number 'variable' variable_closure variables casify 'function' function_closure functions casify 'atom' render_atom 'power' render_power 'parallel' render_parallel 'product' render_product 'sum' render_sum}backslash '\\'wrap_escaped_strings lambda s LatexRendered s.replace backslash backslash * 2 output latex_interpreter.reduce_tree render_actions terminal_converter wrap_escaped_strings return output.latex
def collection_backup_all location backup_name None **kwargs for collection_name in collection_list **kwargs if backup_name is not None backup_name '&name {backup}.{collection}'.format backup backup_name collection collection_name else backup_name ''_query '{collection}/replication?command BACKUP&location {location}{backup_name}&wt json'.format collection collection_name backup_name backup_name location location **kwargs
def login_url login_view next_url None next_field 'next' base expand_login_view login_view if next_url is None return baseparts list urlparse base md url_decode parts[4] md[next_field] make_next_param base next_url parts[4] url_encode md sort True return urlunparse parts
@requires_version 'scipy' '0.12' def test_plot_psd_epochs import matplotlib.pyplot as pltepochs _get_epochs epochs.plot_psd assert_raises RuntimeError epochs.plot_psd_topomap bands [ 0 0.01 'foo' ] epochs.plot_psd_topomap plt.close 'all'
def cg_has_cgsnapshot_filter return IMPL.cg_has_cgsnapshot_filter
def WriteIncludePaths out eclipse_langs include_dirs out.write '<sectionname "org.eclipse.cdt.internal.ui.wizards.settingswizards.IncludePaths">\n' out.write '<languagename "holderforlibrarysettings"></language>\n' for lang in eclipse_langs out.write '<languagename "%s">\n' % lang for include_dir in include_dirs out.write '<includepathworkspace_path "false">%s</includepath>\n' % include_dir out.write '</language>\n' out.write '</section>\n'
def _parse_timestamp_and_interval keyword content line '%s%s' % keyword content content_match _timestamp_re.match content if not content_match raise ValueError 'Malformed%sline %s' % keyword line timestamp_str interval remainder content_match.groups if remainder remainder remainder[1 ]if not interval.isdigit raise ValueError "%sline'sintervalwasn'tanumber %s" % keyword line try timestamp stem.util.str_tools._parse_timestamp timestamp_str return timestamp int interval remainder except ValueError raise ValueError "%sline'stimestampwasn'tparsable %s" % keyword line
def test_hsl_to_rgb_part_0 assert hsl_to_rgb 0 100 50 255 0 0 assert hsl_to_rgb 60 100 50 255 255 0 assert hsl_to_rgb 120 100 50 0 255 0 assert hsl_to_rgb 180 100 50 0 255 255 assert hsl_to_rgb 240 100 50 0 0 255 assert hsl_to_rgb 300 100 50 255 0 255
def kernel_extensions attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'kernel_extensions' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def test_no_truncate_crval w wcs.WCS naxis 3 w.wcs.crval [50 50 212345678000.0]w.wcs.cdelt [0.001 0.001 100000000.0]w.wcs.ctype [u'RA---TAN' u'DEC--TAN' u'FREQ']w.wcs.set header w.to_header for ii in range 3 assert header[u'CRVAL{0}'.format ii + 1 ] w.wcs.crval[ii] assert header[u'CDELT{0}'.format ii + 1 ] w.wcs.cdelt[ii]
def get_running_instructor_tasks course_id instructor_tasks InstructorTask.objects.filter course_id course_id for state in READY_STATES instructor_tasks instructor_tasks.exclude task_state state return instructor_tasks.order_by '-id'
def make_matrix return T.matrix
def _cgi_FieldStorage__repr__patch self if self.file return 'FieldStorage %r %r ' % self.name self.filename return 'FieldStorage %r %r %r ' % self.name self.filename self.value
def compute_dict_measures ntwk iflogger.info u'Computingmeasureswhichreturnadictionary ' measures {}iflogger.info u'...Computingrichclubcoefficient...' measures[u'rich_club_coef'] nx.rich_club_coefficient ntwk return measures
def configInputQueue def captureInput iqueue while True c getch if c u'\x03' or c u'\x04' log.debug u'Breakreceived \\x{0 02X} '.format ord c iqueue.put c breaklog.debug u"InputChar'{}'received".format c if c ! u'\r' else u'\\r' iqueue.put c input_queue queue.Queue input_thread threading.Thread target lambda captureInput input_queue input_thread.daemon Trueinput_thread.start return input_queue input_thread
@dog_stats_api.timed 'status.service.celery.ping' def celery_ping _ start time.time result delayed_ping.apply_async 'ping' 0.1 task_id result.idtry value result.get timeout 4.0 success Trueexcept TimeoutError value Nonesuccess Falseoutput {'success' success 'task_id' task_id 'value' value 'time' time.time - start }return HttpResponse json.dumps output indent 4 content_type 'application/json'
def getHalfwave pitchRadius teeth return pitchRadius * math.pi / float teeth
def File fd filename None mimetype None from warnings import warnwarn DeprecationWarning 'werkzeug.test.Fileisdeprecated usetheEnvironBuilderorFileStorageinstead' return FileStorage fd filename filename content_type mimetype
def new data None return SHA224Hash .new data
def test_lex_exception try tokenize ' foo' assert True is False except PrematureEndOfInput passtry tokenize '{foobar' assert True is False except PrematureEndOfInput passtry tokenize ' defnfoo[bar]' assert True is False except PrematureEndOfInput passtry tokenize ' foo"bar' assert True is False except PrematureEndOfInput pass
def get_recommendation_tree data recommendation_tree {}for subtopic in data recommendation_tree[str subtopic ] []related_subtopics data[subtopic]['related_subtopics']for rel_subtopic in related_subtopics if rel_subtopic exercises get_topic_contents topic_id rel_subtopic kinds ['Exercise'] for ex in exercises recommendation_tree[str subtopic ].append ex['id'] return recommendation_tree
def dbunserialize data db_obj None return from_pickle do_unpickle data db_obj db_obj
def inplace_optimizer f dh_handler dh.DestroyHandlerrequirements lambda fgraph fgraph.attach_feature dh_handler rval FromFunctionOptimizer f requirements rval.__name__ f.__name__return rval
def nspfxmap *nspfxs return dict pfx nsmap[pfx] for pfx in nspfxs
def truncate_day dt measure days dt.toordinal days days // measure * measure return date.fromordinal days
def getLoopLength polygon polygonLength 0.0for pointIndex in xrange len polygon point polygon[pointIndex]secondPoint polygon[ pointIndex + 1 % len polygon ]polygonLength + abs point - secondPoint return polygonLength
def get_module_for_descriptor user request descriptor field_data_cache course_key position None wrap_xmodule_display True grade_bucket_type None static_asset_path '' disable_staff_debug_info False course None track_function make_track_function request xqueue_callback_url_prefix get_xqueue_callback_url_prefix request user_location getattr request 'session' {} .get 'country_code' student_kvs DjangoKeyValueStore field_data_cache if is_masquerading_as_specific_student user course_key student_kvs MasqueradingKeyValueStore student_kvs request.session student_data KvsFieldData student_kvs return get_module_for_descriptor_internal user user descriptor descriptor student_data student_data course_id course_key track_function track_function xqueue_callback_url_prefix xqueue_callback_url_prefix position position wrap_xmodule_display wrap_xmodule_display grade_bucket_type grade_bucket_type static_asset_path static_asset_path user_location user_location request_token xblock_request_token request disable_staff_debug_info disable_staff_debug_info course course
def get_tensor_parents_placeholders tensor placeholders_list []if tensor.op.type 'Placeholder' placeholders_list.append tensor if tensor.op for t in tensor.op.inputs if not 'read 0' in t.name placeholders_list + get_tensor_parents_placeholders t return list set placeholders_list
def _ll_nb1 y X beta alph ll _ll_nbp y X beta alph Q 1 return ll
def send_catch_log_deferred signal Any sender Anonymous *arguments **named def logerror failure recv if dont_log is None or not isinstance failure.value dont_log log.err failure 'Errorcaughtonsignalhandler %s' % recv spider spider return failuredont_log named.pop 'dont_log' None spider named.get 'spider' None dfds []for receiver in liveReceivers getAllReceivers sender signal d maybeDeferred robustApply receiver signal signal sender sender *arguments **named d.addErrback logerror receiver d.addBoth lambda result receiver result dfds.append d d DeferredList dfds d.addCallback lambda out [x[1] for x in out] return d
def test_null_str AreEqual str RudeObjectOverride '' AreEqual RudeObjectOverride .__str__ '' AreEqual RudeObjectOverride .ToString None Assert repr RudeObjectOverride .startswith '<IronPythonTest.RudeObjectOverrideobjectat'
def validate_positive_float_or_zero option value if value 0 or value '0' return 0return validate_positive_float option value
def _warn_missing_microversion_header header_name LOG.warning _LW 'YourrequestwasprocessedbyaNovaAPIwhichdoesnotsupportmicroversions %sheaderismissingfromresponse .Warning Responsemaybeincorrect.' header_name
@receiver post_save sender CourseUserGroup def _cohort_added sender **kwargs instance kwargs['instance']if kwargs['created'] and instance.group_type CourseUserGroup.COHORT tracker.emit 'edx.cohort.created' {'cohort_id' instance.id 'cohort_name' instance.name}
def nearest_intersection line0 line1 Pa Pb intersection_dist nearest_intersection_points line0 line1 if Pa is not None nPoint Pa - Pb return Pb + nPoint * 0.5 intersection_dist else return None None
def resource_data_get context resource_id key result resource_data_get_by_key context resource_id key if result.redact return crypt.decrypt result.decrypt_method result.value return result.value
def test_skycoord_representation c coordinates.SkyCoord [0] [1] [0] representation 'cartesian' t Table [c] assert t.pformat ['col0' 'None None None' '--------------' '0.0 1.0 0.0'] c coordinates.SkyCoord [0] [1] [0] unit 'm' representation 'cartesian' t Table [c] assert t.pformat ['col0' 'm m m' '-----------' '0.0 1.0 0.0'] t['col0'].representation 'unitspherical'assert t.pformat ['col0' 'deg deg' '--------' '90.0 0.0'] t['col0'].representation 'cylindrical'assert t.pformat ['col0' 'm deg m' '------------' '1.0 90.0 0.0']
def _find_monitor_type cs vtype return utils.find_resource cs.monitor_types vtype
def is_unique conn table field rows query conn "\nSELECTinformation_schema.constraint_column_usage.column_name\nFROMinformation_schema.table_constraints\nNATURALJOINinformation_schema.constraint_column_usage\nWHEREinformation_schema.table_constraints.table_name %s\nANDinformation_schema.constraint_column_usage.column_name %s\nANDinformation_schema.table_constraints.constraint_type 'UNIQUE'\n;" table field['column_name'] return rows and True or False
def parse_ipv6_literal_host entity default_port if entity.find ']' -1 raise ValueError "anIPv6addressliteralmustbeenclosedin'['and']'accordingtoRFC2732." i entity.find '] ' if i -1 return entity[1 -1 ] default_port return entity[1 i] entity[ i + 2 ]
def test_show script result script.pip 'show' 'pip' lines result.stdout.splitlines assert len lines 9 assert 'Name pip' in lines assert 'Version %s' % __version__ in lines assert any line.startswith 'Location ' for line in lines assert 'Requires ' in lines
def brand return s3_rest_controller 'supply' 'brand'
def _upload_folder cf folder container ttl None headers None total_bytes 0for root dirs files in os.walk folder for fname in files full_path os.path.join root fname obj_name os.path.relpath full_path folder obj_size os.path.getsize full_path cf.upload_file container full_path obj_name obj_name return_none True ttl ttl headers headers total_bytes + obj_sizereturn total_bytes
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def encrypt_bigfile infile outfile pub_key if not isinstance pub_key key.PublicKey raise TypeError 'Publickeyrequired butgot%r' % pub_key key_bytes common.bit_size pub_key.n // 8 blocksize key_bytes - 11 outfile.write byte varblock.VARBLOCK_VERSION for block in varblock.yield_fixedblocks infile blocksize crypto pkcs1.encrypt block pub_key varblock.write_varint outfile len crypto outfile.write crypto
def _print_char code additional_info None sys.stdout.write 'U+%04X%s' % code _character_name code if additional_info is not None sys.stdout.write ' DCTB ' + additional_info sys.stdout.write '\n'
def _FormatEta eta_usec eta datetime.datetime.fromtimestamp eta_usec / 1000000 return eta.strftime '%Y/%m/%d%H %M %S'
def is_decreasing f interval S.Reals symbol None f sympify f free_sym f.free_symbolsif symbol is None if len free_sym > 1 raise NotImplementedError 'is_decreasinghasnotyetbeenimplementedforallmultivariateexpressions' elif len free_sym 0 return Truesymbol free_sym.pop df f.diff symbol df_nonpos_interval solveset df < 0 symbol domain S.Reals return interval.is_subset df_nonpos_interval
def _MakeCronListIntoYaml cron_list statements ['cron ']for cron in cron_list statements + cron.ToYaml return '\n'.join statements + '\n'
def addXIntersectionsFromLoopForTable loop xIntersectionsTable width for pointIndex in xrange len loop pointBegin loop[pointIndex]pointEnd loop[ pointIndex + 1 % len loop ]if pointBegin.imag > pointEnd.imag pointOriginal pointBeginpointBegin pointEndpointEnd pointOriginalfillBegin int math.ceil pointBegin.imag / width fillEnd int math.ceil pointEnd.imag / width if fillEnd > fillBegin secondMinusFirstComplex pointEnd - pointBegin secondMinusFirstImaginaryOverReal secondMinusFirstComplex.real / secondMinusFirstComplex.imag beginRealMinusImaginary pointBegin.real - pointBegin.imag * secondMinusFirstImaginaryOverReal for fillLine in xrange fillBegin fillEnd y fillLine * width xIntersection y * secondMinusFirstImaginaryOverReal + beginRealMinusImaginary addElementToListTable xIntersection fillLine xIntersectionsTable
def trimboth data proportiontocut 0.2 inclusive True True axis None return trimr data limits proportiontocut proportiontocut inclusive inclusive axis axis
def memoize_property storage def decorator method name method.__name__def wrapper self if name not in storage storage[name] method self return storage[name]return property update_wrapper wrapper method return decorator
def redirect_to_referrer request default return redirect safe_referrer request default
def custom_404 request template_name '404.html' context {'legacy_path' legacy_path request.path 'download_path' reverse 'download download' 'doc_path' reverse 'documentation' 'pypi_path' PYPI_URL}response render request template_name context response['Cache-Control'] 'max-age 300'response.status_code 404return response
def _urlnode_render_replacement self context args [arg.resolve context for arg in self.args]try app webapp.WSGIApplication.active_instancehandler app.get_registered_handler_by_name self.view_name return handler.get_url implicit_args True *args except webapp.NoUrlFoundError return ''
def load_session filename return loads read filename binary False
def simple_paginate request queryset per_page 20 p paginator.SimplePaginator queryset per_page page p.page request.GET.get 'page' 1 page.url build_paged_url request return page
def link_or_copy src dst if os.path.isdir dst dst os.path.join dst os.path.basename src link_errno link src dst if link_errno errno.EEXIST if os.stat src .st_ino os.stat dst .st_ino returnnew_dst dst + '-temp-%04X' % random.randint 1 16 ** 4 try link_or_copy src new_dst except try os.remove new_dst except OSError passraiseos.rename new_dst dst elif link_errno ! 0 shutil.copy src dst
def record_absent name zone type data profile zones libcloud_dns_module.list_zones profile try matching_zone [z for z in zones if z.domain zone ][0]except IndexError return state_result False 'Zonecouldnotbefound' records libcloud_dns_module.list_records matching_zone.id profile matching_records [record for record in records if record.name name and record.type type and record.data data ]if len matching_records > 0 result []for record in matching_records result.append libcloud_dns_module.delete_record matching_zone.id record.id profile return state_result all result 'Removed{0}records'.format len result else return state_result True 'Recordsalreadyabsent'
def HT_DCPERIOD ds count return call_talib_with_ds ds count talib.HT_DCPERIOD
def _parse_iso_timestamp entry if not isinstance entry str str_type raise ValueError 'parse_iso_timestamp inputmustbeastr gota%s' % type entry if '.' in entry timestamp_str microseconds entry.split '.' else timestamp_str microseconds entry '000000' if len microseconds ! 6 or not microseconds.isdigit raise ValueError "timestamp'smicrosecondsshouldbesixdigits" if timestamp_str[10] 'T' timestamp_str timestamp_str[ 10] + '' + timestamp_str[11 ] else raise ValueError "timestampdidn'tcontaindelimeter'T'betweendateandtime" timestamp _parse_timestamp timestamp_str return timestamp + datetime.timedelta microseconds int microseconds
def _salt_cloud_force_ascii exc if not isinstance exc UnicodeEncodeError UnicodeTranslateError raise TypeError "Can'thandle{0}".format exc unicode_trans {u'\xa0' u'' u'\u2013' u'-'}if exc.object[exc.start exc.end] in unicode_trans return unicode_trans[exc.object[exc.start exc.end]] exc.end raise exc
@with_setup prepare_stdout def test_output_level_2_fail runner Runner feature_name 'failed_table' verbosity 2 runner.run assert_stdout_lines_with_traceback 'Seeitfail...FAILED\n\n\n<Step "Andthisonefails">\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line% call_line d in__call__\nret self.function self.step *args **kw \nFile"% step_file s" line25 intof\nassertFalse\nAssertionError\n\n1feature 0passed \n1scenario 0passed \n5steps 1failed 2skipped 1undefined 1passed \n\nListoffailedscenarios \nScenario Seeitfail#tests/functional/output_features/failed_table/failed_table.feature 2\n\n' % {'lettuce_core_file' lettuce_path 'core.py' 'step_file' abspath lettuce_path '..' 'tests' 'functional' 'output_features' 'failed_table' 'failed_table_steps.py' 'call_line' call_line}
def qcut x q labels None retbins False precision 3 duplicates 'raise' x_is_series series_index name x _preprocess_for_cut x x dtype _coerce_to_type x if is_integer q quantiles np.linspace 0 1 q + 1 else quantiles qbins algos.quantile x quantiles fac bins _bins_to_cuts x bins labels labels precision precision include_lowest True dtype dtype duplicates duplicates return _postprocess_for_cut fac bins retbins x_is_series series_index name
def best_docstring param1 param2 return None
def dup_quo_ground f c K if not c raise ZeroDivisionError 'polynomialdivision' if not f return fif K.has_Field return [K.quo cf c for cf in f]else return [ cf // c for cf in f]
def _is_int string try int string return Trueexcept ValueError return False
def _icrs_to_fk5_matrix eta0 -19.9 / 3600000.0 xi0 9.1 / 3600000.0 da0 -22.9 / 3600000.0 m1 rotation_matrix - eta0 u'x' m2 rotation_matrix xi0 u'y' m3 rotation_matrix da0 u'z' return matrix_product m1 m2 m3
def oauth_dance app_name consumer_key consumer_secret token_filename None open_browser True print "Hithere!We'regonnagetyouallsetuptouse%s." % app_name twitter Twitter auth OAuth '' '' consumer_key consumer_secret format '' api_version None oauth_token oauth_token_secret parse_oauth_tokens twitter.oauth.request_token oauth_callback 'oob' oauth_url 'https //api.twitter.com/oauth/authorize?oauth_token ' + oauth_token oauth_verifier get_oauth_pin oauth_url open_browser twitter Twitter auth OAuth oauth_token oauth_token_secret consumer_key consumer_secret format '' api_version None oauth_token oauth_token_secret parse_oauth_tokens twitter.oauth.access_token oauth_verifier oauth_verifier if token_filename write_token_file token_filename oauth_token oauth_token_secret print print "That'sit!Yourauthorizationkeyshavebeenwrittento%s." % token_filename return oauth_token oauth_token_secret
def _date_lookup_for_field field date if isinstance field models.DateTimeField date_range datetime.datetime.combine date datetime.time.min datetime.datetime.combine date datetime.time.max return { '%s__range' % field.name date_range}else return {field.name date}
def adduser group name cmd 'dscl.-merge/Groups/{0}GroupMembership{1}'.format group name return __salt__['cmd.retcode'] cmd 0
def _import_migrated_vhds session instance chain_label disk_type vdi_label imported_vhds session.call_plugin_serialized 'migration.py' 'move_vhds_into_sr' instance_uuid chain_label sr_path get_sr_path session uuid_stack _make_uuid_stack scan_default_sr session vdi_uuid imported_vhds['root']['uuid']vdi_ref session.call_xenapi 'VDI.get_by_uuid' vdi_uuid _set_vdi_info session vdi_ref disk_type vdi_label disk_type instance return {'uuid' vdi_uuid 'ref' vdi_ref}
def conf_test return __salt__['config.option'] 'test.foo'
def HasClass clsid return clsid in mapCLSIDToClass
def dirname path current_dir u'' while u'//' in path path path.replace u'//' u'/' path_dirname path.rsplit u'/' 1 [0]if path_dirname path return current_dirreturn path.rsplit u'/' 1 [0]
def decodeGenerator params return GenericBatchGenerator
def async_runner timeout async_factory _AsyncRunner.make_factory timeout timeout.total_seconds suppress_twisted_logging False store_twisted_logs False return retry_flaky async_factory
def get_updater name None if not name name settings.ASSETS_UPDATERtry return {None update_never False update_never 'never' update_never 'timestamp' update_by_timestamp 'hash' update_by_hash 'interval' update_by_interval 'always' update_always}[name]except KeyError raise ValueError 'Updater"%s"isnotvalid.' % name
def create_simple_binding jboss_config binding_name value profile None log.debug ' MODULEFUNCTION jboss7.create_simple_binding binding_name %s value %s profile %s' binding_name value profile operation '/subsystem naming/binding "{binding_name}" add binding-type simple value "{value}" '.format binding_name binding_name value __escape_binding_value value if profile is not None operation '/profile "{profile}"'.format profile profile + operation return __salt__['jboss7_cli.run_operation'] jboss_config operation
def starts_with_path path prefix if sabnzbd.WIN32 return clip_path path .lower .startswith prefix.lower elif sabnzbd.DARWIN return path.lower .startswith prefix.lower else return path.startswith prefix
def plot_MCMC_trace ax xdata ydata trace scatter False **kwargs xbins ybins sigma compute_sigma_level trace[0] trace[1] ax.contour xbins ybins sigma.T levels [0.683 0.955] **kwargs if scatter ax.plot trace[0] trace[1] ' k' alpha 0.1 ax.set_xlabel '$\\alpha$' ax.set_ylabel '$\\beta$'
def fix_error_editor self filename linenum column msg warnings.warn '\n`fix_error_editor`ispendingdeprecationasofIPython5.0andwillberemoved\ninfutureversions.Itappearstobeusedonlyforautomaticallyfixingsyntax\nerrorthathasbeenbrokenforafewyearsandhasthusbeenremoved.Ifyou\nhappendtousethisfunctionandstillneeditpleasemakeyourvoiceheardon\nthemailinglistipython-dev@scipy.org orontheGitHubIssuetracker \nhttps //github.com/ipython/ipython/issues/9649' UserWarning def vim_quickfix_file t tempfile.NamedTemporaryFile t.write '%s %d %d %s\n' % filename linenum column msg t.flush return tif os.path.basename self.editor ! 'vim' self.hooks.editor filename linenum returnt vim_quickfix_file try if os.system 'vim--cmd"seterrorformat %f %l %c %m"-q' + t.name raise TryNext finally t.close
def _url_to_origin url if url.lower 'null' return 'null'res urllib.parse.urlsplit url scheme res.scheme.lower if scheme 'file' return 'null'host res.hostnameport res.portif port is None try port {'https' 443 'http' 80}[scheme]except KeyError port Noneif not host raise ValueError "NohostpartinOrigin'{}'".format url return scheme host port
def _cert_details cert_pointer data_pointer Nonetry data_pointer Security.SecCertificateCopyData cert_pointer der_cert CFHelpers.cf_data_to_bytes data_pointer cert_hash hashlib.sha1 der_cert .digest return der_cert cert_hash finally if data_pointer is not None CoreFoundation.CFRelease data_pointer
def getKeysA prefix '' keysA []for row in xrange 4 for column in xrange 4 key getKeyA row column prefix keysA.append key return keysA
def attach_is_fan queryset user as_field 'is_fan_attr' model queryset.modelif user is None or user.is_anonymous sql 'SELECTfalse'else sql "\nSELECTCOUNT likes_like.id >0\nFROMlikes_like\nINNERJOINdjango_content_typeONlikes_like.content_type_id django_content_type.id\nWHEREdjango_content_type.model 'project'AND\ndjango_content_type.app_label 'projects'AND\nlikes_like.user_id {user_id}AND\nlikes_like.object_id {tbl}.id\n"sql sql.format tbl model._meta.db_table user_id user.id queryset queryset.extra select {as_field sql} return queryset
def _get_menu_class_for_instance menu_class instance attrs {'instance' instance}class_name menu_class.__name__meta_class type menu_class return meta_class class_name menu_class attrs
def natural_pk_mti_test format self child_1 Child.objects.create parent_data '1' child_data '1' child_2 Child.objects.create parent_data '2' child_data '2' string_data serializers.serialize format [child_1.parent_ptr child_2.parent_ptr child_2 child_1] use_natural_foreign_keys True use_natural_primary_keys True child_1.delete child_2.delete for obj in serializers.deserialize format string_data obj.save children Child.objects.all self.assertEqual len children 2 for child in children self.assertEqual child.child_data child.parent_data
def total_seconds delta if sys.version_info[ 2] ! 2 6 return delta.total_seconds day_in_seconds delta.days * 24 * 3600.0 micro_in_seconds delta.microseconds / 10.0 ** 6 return day_in_seconds + delta.seconds + micro_in_seconds
def get_money_supply rdint vs.random request Request vs.MACRO_URL % vs.P_TYPE['http'] vs.DOMAINS['sina'] rdint vs.MACRO_TYPE[2] 1 600 rdint text urlopen request timeout 10 .read text text.decode 'gbk' regSym re.compile '\\ count .*? \\}' datastr regSym.findall text datastr datastr[0]datastr datastr.split 'data ' [1]js json.loads datastr df pd.DataFrame js columns vs.MONEY_SUPPLY_COLS for i in df.columns df[i] df[i].apply lambda x np.where x is None '--' x return df
def stonith_create stonith_id stonith_device_type stonith_device_options None cibfile None return item_create item 'stonith' item_id stonith_id item_type stonith_device_type extra_args stonith_device_options cibfile cibfile
def get_jid jid ret {}for returner_ in __opts__[CONFIG_KEY] ret.update _mminion .returners['{0}.get_jid'.format returner_ ] jid return ret
def plot_results src res figure nbr_results len res for i in range nbr_results imname src.get_filename res[i] subplot 1 nbr_results i + 1 imshow array Image.open imname axis 'off' show
def get_permalink_path self try first_permalink_id self.get_permalink_ids_iter .next except StopIteration return Nonereturn '/{settings[PERMALINK_PATH]}/{first_permalink}'.format settings self.settings first_permalink first_permalink_id
@log_calldef metadef_object_get_all context namespace_name namespace metadef_namespace_get context namespace_name objects []_check_namespace_visibility context namespace namespace_name for object in DATA['metadef_objects'] if object['namespace_id'] namespace['id'] objects.append object return objects
def test_trailing_spaces_in_row_definition table '\n#comment withblanklineabove \n \nCol1Col2Col3\n \n33.4foo\n14.5bar\n \n'reader ascii.get_reader Reader ascii.RST dat reader.read table assert_equal dat.colnames ['Col1' 'Col2' 'Col3'] assert_equal dat[0][2] 'foo' assert_equal dat[1][0] 1
def event name ret {'name' name 'changes' {} 'comment' '' 'result' False}for event in __events__ if salt.utils.expr_match event['tag'] name ret['result'] Truereturn ret
def catch_errors_app application environ start_response error_callback_app ok_callback None catch Exception try app_iter application environ start_response except catch return error_callback_app environ start_response sys.exc_info if type app_iter in list tuple if ok_callback is not None ok_callback return app_iterelse return _wrap_app_iter_app environ start_response app_iter error_callback_app ok_callback catch catch
def is_debug return _debug
def _can_access_descriptor_with_start_date user descriptor course_key return check_start_date user descriptor.days_early_for_beta descriptor.start course_key
def assert_mail_count count msg None from django.core import mailif msg is None msg u' '.join [e.subject for e in mail.outbox] msg u'%d! %d%s' % len mail.outbox count msg assert_equals len mail.outbox count msg
def arg_type *args **kwargs ret {'args' [] 'kwargs' {}}for argument in args ret['args'].append str type argument for key val in six.iteritems kwargs ret['kwargs'][key] str type val return ret
def _check_preload inst if inst.preload is False raise RuntimeError 'ModifyingdataofInstanceisonlysupportedwhenpreloadingisused.Usepreload True orstring intheconstructor.'
def _instrument_class cls if cls.__module__ '__builtin__' raise sa_exc.ArgumentError 'Cannotinstrumentabuilt-intype.Useasubclass evenatrivialone.' roles methods _locate_roles_and_methods cls _setup_canned_roles cls roles methods _assert_required_roles cls roles methods _set_collection_attributes cls roles methods
def filter_otu_table_to_n_samples otu_table n if not 0 < n < len otu_table.ids raise ValueError 'Numberofsamplestofiltermustbebetween0andthenumberofsamples.' return otu_table.subsample n axis 'sample' by_id True
def gprsSuspensionRequest a TpPd pd 6 b MessageType c Tlli d RoutingAreaIdentification e SuspensionCause packet a / b / c / d / e return packet
def load_frame url skiprows return pd.read_csv url skiprows skiprows skipinitialspace True na_values ['Bankholiday' 'Notavailable'] parse_dates ['Date'] index_col 'Date' .dropna how 'all' .tz_localize 'UTC' .rename columns COLUMN_NAMES
def _validate_project project parent if parent is None if project is None raise ValueError 'AKeymusthaveaprojectset.' return project
def valid_api_version version global VALID_API_VERSIONSif not isinstance VALID_API_VERSIONS list VALID_API_VERSIONS [str VALID_API_VERSIONS ]return version in VALID_API_VERSIONS
def test_import_path_seperator AssertError ImportError __import__ 'iptest\\warning_util' __import__ 'iptest.warning_util'
def rs_series_inversion p x prec R p.ringif p R.zero raise ZeroDivisionErrorzm R.zero_monomindex R.gens.index x m min p key lambda k k[index] [index]if m p mul_xin p index - m prec prec + m if zm not in p raise NotImplementedError 'Noconstantterminseries' if _has_constant_term p - p[zm] x raise NotImplementedError 'p-p[0]mustnothaveaconstanttermintheseriesvariables' r _series_inversion1 p x prec if m ! 0 r mul_xin r index - m return r
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def power G k if k < 0 raise ValueError 'kmustbeapositiveinteger' H nx.Graph for n in G seen {}level 1nextlevel G[n]while nextlevel thislevel nextlevelnextlevel {}for v in thislevel if v n continueif v not in seen seen[v] levelnextlevel.update G[v] if k < level breaklevel + 1H.add_edges_from n nbr for nbr in seen return H
def fast_urandom16 urandom [] locker threading.RLock try return urandom.pop except IndexError try locker.acquire ur os.urandom 16 * 1024 urandom + [ur[i i + 16 ] for i in xrange 16 1024 * 16 16 ]return ur[0 16]finally locker.release
def next_tag el el el.getnext while el.tag 'br' el el.getnext return el
@pytest.yield_fixture autouse True def imp_env xonsh_execer load_builtins execer xonsh_execer builtins.__xonsh_env__ Env {'PATH' [] 'PATHEXT' []} yield unload_builtins
def get_application_id return app_identity.get_application_id
def except_token source start token throw True start pass_white source start if start < len source and source[start] token return start + 1 if throw raise SyntaxError 'Missingtoken.Expected%s' % token return None
@contextlib.contextmanagerdef temporary_mutation obj **kwargs def is_dict_like thing return hasattr thing 'has_key' def get thing attr default if is_dict_like thing return thing.get attr default else return getattr thing attr default def set_value thing attr val if is_dict_like thing thing[attr] valelse setattr thing attr val def delete thing attr if is_dict_like thing del thing[attr]else delattr thing attr NOT_PRESENT object old_values {}for attr new_value in kwargs.items old_values[attr] get obj attr NOT_PRESENT set_value obj attr new_value try yield finally for attr old_value in old_values.items if old_value is NOT_PRESENT delete obj attr else set_value obj attr old_value
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@protocol.commands.add u'command_list_end' list_command False def command_list_end context if not context.dispatcher.command_list_receiving raise exceptions.MpdUnknownCommand command u'command_list_end' context.dispatcher.command_list_receiving False command_list context.dispatcher.command_list context.dispatcher.command_list [] command_list_ok context.dispatcher.command_list_ok context.dispatcher.command_list_ok False command_list_response []for index command in enumerate command_list response context.dispatcher.handle_request command current_command_list_index index command_list_response.extend response if command_list_response and command_list_response[ -1 ].startswith u'ACK' return command_list_responseif command_list_ok command_list_response.append u'list_OK' return command_list_response
def _check_rel element if 'rel' not in element return Truemust_have {'stylesheet' 'icon'}rels [rel.lower for rel in element['rel'].split '' ]return any rel in rels for rel in must_have
def _bytes_feature value return tf.train.Feature bytes_list tf.train.BytesList value [value]
@step 'Idonotseethechanges' @step 'Iseethesetdates' def i_see_the_set_dates _step verify_date_or_time COURSE_START_DATE_CSS '12/20/2013' verify_date_or_time COURSE_END_DATE_CSS '12/26/2013' verify_date_or_time ENROLLMENT_START_DATE_CSS '12/01/2013' verify_date_or_time ENROLLMENT_END_DATE_CSS '12/10/2013' verify_date_or_time COURSE_START_TIME_CSS DUMMY_TIME verify_date_or_time COURSE_END_TIME_CSS DEFAULT_TIME verify_date_or_time ENROLLMENT_START_TIME_CSS DEFAULT_TIME verify_date_or_time ENROLLMENT_END_TIME_CSS DUMMY_TIME
def getnameinfo sockaddr flags return get_hub .resolver.getnameinfo sockaddr flags
def decode_base32_to_hex base32_string bin_form base64.b32decode base32_string return binascii.hexlify bin_form
def verify_list mailchimp list_id course_id lists mailchimp.lists filters {'list_id' list_id} ['data']if len lists ! 1 log.error 'incorrectlistid' return Falselist_name lists[0]['name']log.debug 'listname %s' list_name parts course_id.replace '_' '' .replace '/' '' .split count sum 1 for p in parts if p in list_name if count < 3 log.info course_id log.info list_name log.error 'course_iddoesnotmatchlistname' return Falsereturn True
def ceph_version return ceph_cfg.ceph_version
def record_user_has_seen_notifications user_id last_seen_msecs subscriptions_model user_models.UserSubscriptionsModel.get user_id strict False if not subscriptions_model subscriptions_model user_models.UserSubscriptionsModel id user_id subscriptions_model.last_checked datetime.datetime.utcfromtimestamp last_seen_msecs / 1000.0 subscriptions_model.put
def _ScrubUpdateViewpoint op_args _ScrubForClass Viewpoint op_args['vp_dict']
def get_localizer language 'English' languages dict English EnglishGetter Greek GreekGetter return languages[language]
def create_uninitialized_tensor_descriptor desc Descriptor cudnn.createTensorDescriptor cudnn.destroyTensorDescriptor return desc
def merge_cache_under_settings destination setting key_prefix list_ False default {} if not list_ else [] existing destination.settings.get setting value get_cache key_prefix + '.' + setting default if value if existing if list_ base dict zip value [None] * len value for val in existing if val in base continuevalue.append val else value.update existing destination.settings[setting] value
def get_terminal_size def ioctl_GWINSZ fd try import fcntlimport termiosimport structcr struct.unpack 'hh' fcntl.ioctl fd termios.TIOCGWINSZ '1234' except return Noneif cr 0 0 return Nonereturn crcr ioctl_GWINSZ 0 or ioctl_GWINSZ 1 or ioctl_GWINSZ 2 if not cr try fd os.open os.ctermid os.O_RDONLY cr ioctl_GWINSZ fd os.close fd except passif not cr cr os.environ.get 'LINES' 25 os.environ.get 'COLUMNS' 80 return int cr[1] int cr[0]
def add_milestone milestone_data if not settings.FEATURES.get 'MILESTONES_APP' return Nonereturn milestones_api.add_milestone milestone_data
def convert_to_RGB_255 colors rgb_components []for component in colors rounded_num decimal.Decimal str component * 255.0 .quantize decimal.Decimal '1' rounding decimal.ROUND_HALF_EVEN rounded_num int rounded_num rgb_components.append rounded_num return rgb_components[0] rgb_components[1] rgb_components[2]
def importETree etree_in_c Nonetry import xml.etree.cElementTree as etree_in_cexcept ImportError try import xml.etree.ElementTree as etreeexcept ImportError try import cElementTree as etree_in_cexcept ImportError try import elementtree.ElementTree as etreeexcept ImportError message CRITICAL 'FailedtoimportElementTree' sys.exit 1 if etree_in_c and etree_in_c.VERSION < '1.0' message CRITICAL 'ForcElementTreeversion1.0orhigherisrequired.' sys.exit 1 elif etree_in_c return etree_in_celif etree.VERSION < '1.1' message CRITICAL 'ForElementTreeversion1.1orhigherisrequired' sys.exit 1 else return etree
@environmentfilterdef do_attr environment obj name try name str name except UnicodeError passelse try value getattr obj name except AttributeError passelse if environment.sandboxed and not environment.is_safe_attribute obj name value return environment.unsafe_undefined obj name return valuereturn environment.undefined obj obj name name
def validate_clip_with_axis axis args kwargs if isinstance axis ndarray args axis + args axis Nonevalidate_clip args kwargs return axis
def delete_flavor_info metadata *prefixes for key in system_metadata_flavor_props.keys for prefix in prefixes to_key '%sinstance_type_%s' % prefix key del metadata[to_key]for key in list metadata.keys for prefix in prefixes if key.startswith '%sinstance_type_extra_' % prefix del metadata[key]return metadata
def initMultiprocessing if not queue returnfor handler in logger.handlers[ ] logger.removeHandler handler queue_handler QueueHandler queue queue_handler.setLevel logging.DEBUG logger.addHandler queue_handler threading.current_thread .name multiprocessing.current_process .name
def expand_reqs fpath absfpath os.path.abspath fpath output expand_reqs_helper absfpath set return sorted set output
def test_read_twoline_ReST table '\n \nCol1Col2\n \n1.2"hello"\n2.4\'sworlds\n \n'dat ascii.read table Reader ascii.FixedWidthTwoLine header_start 1 position_line 2 data_end -1 assert_equal dat.dtype.names 'Col1' 'Col2' assert_almost_equal dat[1][0] 2.4 assert_equal dat[0][1] '"hello"' assert_equal dat[1][1] "'sworlds"
def imp_find_module name path None names name.split '.' if path is not None if isinstance path str unicode path [os.path.realpath path ]for name in names result imp.find_module name path if result[0] is not None result[0].close path [result[1]]return result
def _CheckInteger value name zero_ok True upper_bound None datastore_types.ValidateInteger value name ValueError empty_ok True zero_ok zero_ok if upper_bound is not None and value > upper_bound raise ValueError '%s %dmustbe< %d' % name value upper_bound return value
def gaussian x mean stddev tmp -0.5 * sum x - mean / stddev ** 2 return np.exp tmp / np.power 2.0 * np.pi 0.5 * len x * stddev
@require_POST@login_required@permitteddef create_sub_comment request course_id comment_id if is_comment_too_deep parent cc.Comment comment_id return JsonError _ 'Commentleveltoodeep' return _create_comment request CourseKey.from_string course_id parent_id comment_id
def locationUpdatingReject a TpPd pd 5 b MessageType mesType 4 c RejectCause packet a / b / c return packet
def collect_attributes attributes *containers collected []if attributes collected + attributesfor container in containers if container collected + container.all_attributesreturn collected
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def apiNew user passwd return DeliciousAPI user user passwd passwd
def _safe_html s return cgi.escape s quote 1 .replace "'" '&#39;'
def test_set_format_shares_subfmt t Time '+02000-02-03' format 'fits' out_subfmt 'date_hms' precision 5 tc t.copy t.format 'isot'assert t.precision 5 assert t.out_subfmt 'date_hms' assert t.value '2000-02-03T00 00 00.00000' t.format 'fits'assert t.value tc.value assert t.precision 5
def connectNetToMs Facility_presence 0 ProgressIndicator_presence 0 ConnectedNumber_presence 0 ConnectedSubaddress_presence 0 UserUser_presence 0 a TpPd pd 3 b MessageType mesType 7 packet a / b if Facility_presence is 1 c FacilityHdr ieiF 28 eightBitF 0 packet packet / c if ProgressIndicator_presence is 1 d ProgressIndicatorHdr ieiPI 30 eightBitPI 0 packet packet / d if ConnectedNumber_presence is 1 e ConnectedNumberHdr ieiCN 76 eightBitCN 0 packet packet / e if ConnectedSubaddress_presence is 1 f ConnectedSubaddressHdr ieiCS 77 eightBitCS 0 packet packet / f if UserUser_presence is 1 g UserUserHdr ieiUU 127 eightBitUU 0 packet packet / g return packet
def compatible_channels source_channel sink_channel source_type name_lookup source_channel.type sink_type name_lookup sink_channel.type ret issubclass source_type sink_type if source_channel.dynamic ret ret or issubclass sink_type source_type return ret
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def get_global_notification_type global_subscription user for notification_type in constants.NOTIFICATION_TYPES if getattr global_subscription notification_type .filter id user.id .exists return notification_type
def temp_directory prefix _create_trashcan_dir return _create_trashcan_subdir prefix
def format_block block nlspaces 0 import relines str block .split '\n' while lines and not lines[0] del lines[0]while lines and not lines[ -1 ] del lines[ -1 ]ws re.match '\\s*' lines[0] .group 0 if ws lines map lambda x x.replace ws '' 1 lines while lines and not lines[0] del lines[0]while lines and not lines[ -1 ] del lines[ -1 ]flines [ '%s%s' % '' * nlspaces line for line in lines]return '\n'.join flines + '\n'
def copy_cache cache if cache is None return Noneelif type cache is dict return {}return LRUCache cache.capacity
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def array_repr arr max_line_width None precision None suppress_small None return numpy.array_repr cupy.asnumpy arr max_line_width precision suppress_small
def aggregate_metadata_get context aggregate_id return IMPL.aggregate_metadata_get context aggregate_id
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def gis_hierarchy_editable level id country current.gis.get_parent_country id s3db current.s3dbtable s3db.gis_hierarchyfieldname 'edit_%s' % level query table.uuid 'SITE_DEFAULT' if country query | table.location_id country limitby 0 2 else limitby 0 1 rows current.db query .select table[fieldname] table.uuid limitby limitby cache s3db.cache if len rows > 1 filter lambda row row.uuid 'SITE_DEFAULT' rows.exclude filter row rows.first editable row[fieldname]return editable
def raw_seconds_short string match re.match '^ \\d+ [0-5]\\d $' string if not match raise ValueError u'StringnotinM SSformat' minutes seconds map int match.groups return float minutes * 60 + seconds
def unregister_email_hook signal handler assert signal in review_request_published review_request_closed review_published reply_published u'Invalidsignal%r' % signal _hooks[signal].discard handler
def get_field_parts model field_name parts field_name.split LOOKUP_SEP opts model._metafields []for name in parts try field opts.get_field name except FieldDoesNotExist return Nonefields.append field if isinstance field RelatedField opts remote_model field ._metaelif isinstance field ForeignObjectRel opts field.related_model._metareturn fields
def avail_sizes response list_common_lookups kwargs {'lookup' 'server.ram'} ret {}for item in response['list'] name item['name']ret[name] itemreturn ret
def _get_plugin plugin_name plugin_list plugin Nonefor plug in plugin_list if plug[u'name'] plugin_name plugin plugbreakreturn plugin
def empty_urlconf request t Template EMPTY_URLCONF_TEMPLATE name 'EmptyURLConftemplate' c Context {'project_name' settings.SETTINGS_MODULE.split '.' [0]} return HttpResponseNotFound t.render c mimetype 'text/html'
def _mark_method_skipped meth reason @functools.wraps meth def wrapper *args **kwargs raise testtools.testcase.TestSkipped reason return wrapper
def keyring_present **kwargs return ceph_cfg.keyring_present **kwargs
def create_index_types evaluator index if index ' ' return set [Slice evaluator None None None ] elif tree.is_node index 'subscript' result []for el in index.children if el ' ' if not result result.append None elif tree.is_node el 'sliceop' if len el.children 2 result.append el.children[1] else result.append el result + [None] * 3 - len result return set [Slice evaluator *result ] return evaluator.eval_element index
@dispatch Expr MongoQuery def post_compute e q scope None scope {'$project' toolz.merge {'_id' 0} dict col 1 for col in e.fields }q q.append scope if not e.dshape.shape result get_result q.coll.aggregate list q.query [0]if isscalar e.dshape.measure return result[e._name]else return get e.fields result dicts get_result q.coll.aggregate list q.query if isscalar e.dshape.measure return list pluck e.fields[0] dicts default None else return list pluck e.fields dicts default None
def widget_toggle request collapsed request.GET.get u'collapse' None widget request.GET.get u'widget' None if widget and collapsed siteconfig SiteConfiguration.objects.get_current widget_settings siteconfig.get u'widget_settings' {} widget_settings[widget] collapsedsiteconfig.set u'widget_settings' widget_settings siteconfig.save return HttpResponse u''
def p_direct_declarator_4 t pass
def format_help_entry title help_text aliases None suggested None string _SEP + '\n' if title string + '{CHelpfor{w%s{n' % title if aliases string + '{C aliases %s{C {n' % '{C {n'.join '{w%s{n' % ali for ali in aliases if help_text string + '\n%s' % dedent help_text.rstrip if suggested string + '\n\n{CSuggested {n'string + '%s' % fill '{C {n'.join '{w%s{n' % sug for sug in suggested string.strip string + '\n' + _SEP return string
def miscs_update_idxs_vals miscs idxs vals assert_all_vals_used True idxs_map None if idxs_map is None idxs_map {}assert set idxs.keys set vals.keys misc_by_id dict [ m['tid'] m for m in miscs] for m in miscs m['idxs'] dict [ key [] for key in idxs] m['vals'] dict [ key [] for key in idxs] for key in idxs assert len idxs[key] len vals[key] for tid val in zip idxs[key] vals[key] tid idxs_map.get tid tid if assert_all_vals_used or tid in misc_by_id misc_by_id[tid]['idxs'][key] [tid]misc_by_id[tid]['vals'][key] [val]return miscs
def get_versions cfg get_config verbose cfg.verbosetry return git_versions_from_keywords get_keywords cfg.tag_prefix verbose except NotThisMethod passtry root os.path.realpath __file__ for i in cfg.versionfile_source.split '/' root os.path.dirname root except NameError return {'version' '0+unknown' 'full-revisionid' None 'dirty' None 'error' 'unabletofindrootofsourcetree' 'date' None}try pieces git_pieces_from_vcs cfg.tag_prefix root verbose return render pieces cfg.style except NotThisMethod passtry if cfg.parentdir_prefix return versions_from_parentdir cfg.parentdir_prefix root verbose except NotThisMethod passreturn {'version' '0+unknown' 'full-revisionid' None 'dirty' None 'error' 'unabletocomputeversion' 'date' None}
def _copy_entries arr return [c.copy for c in arr]
def p_numlist p if len p > 2 p[0] p[1]p[0].append p[3] else p[0] [p[1]]
def strip_accents_ascii s nkfd_form unicodedata.normalize u'NFKD' s return nkfd_form.encode u'ASCII' u'ignore' .decode u'ASCII'
def dmp_add_ground f c u K return dmp_add_term f dmp_ground c u - 1 0 u K
def roundrobin *iterables pending len iterables nexts cycle iter it .next for it in iterables while pending try for next in nexts yield next except StopIteration pending - 1nexts cycle islice nexts pending
def clean_filename filename split_fname filename.rsplit '.' 1 split_fname[0] FILENAME_TOKENreturn '.'.join split_fname
def format_status status github jenkins statusreturn u'{} {} {} '.format github['context'] jenkins.value github['target_url']
def _gen_rules_port_min port_min top_bit rules []mask top_bit - 1 while True if port_min & mask 0 rules.append _hex_format port_min mask breaktop_bit >> 1mask >> 1if port_min & top_bit 0 rules.append _hex_format port_min & ~ mask | top_bit mask return rules
def _select_helper args kwargs if len args > 1 raise TypeError 'selectacceptsatmostONEpositionalargument.' if len args > 0 and len kwargs > 0 raise TypeError 'selectacceptsEITHERapositionalargument ORkeywordarguments notboth .' if len args 0 and len kwargs 0 raise TypeError 'selectrequiresEITHERapositionalargument ORkeywordarguments.' if args arg args[0]if isinstance arg dict selector argelif isinstance arg string_types selector dict name arg elif issubclass arg Model selector {'type' arg}else raise RuntimeError 'Selectormustbeadictionary stringorplotobject.' else selector kwargsreturn selector
def Comma return Leaf token.COMMA ' '
def etag_request_processor page request class DummyResponse dict u'\nThisisadummyclasswithenoughbehaviourofHttpResponsesowe\ncanusetheconditiondecoratorwithouttoomuchpain.\n'def has_header page what return Falsedef dummy_response_handler *args **kwargs return DummyResponse def etagger request page *args **kwargs etag page.etag request return etagdef lastmodifier request page *args **kwargs lm page.last_modified return lmfrom django.views.decorators.http import conditionrsp condition etag_func etagger last_modified_func lastmodifier dummy_response_handler request page if not isinstance rsp DummyResponse return rsp
def _inclusiveNamespacePrefixes node context unsuppressedPrefixes inclusive []if node.prefix usedPrefixes [ 'xmlns %s' % node.prefix ]else usedPrefixes ['xmlns']for a in _attrs node if a.nodeName.startswith 'xmlns' or not a.prefix continueusedPrefixes.append 'xmlns %s' % a.prefix unused_namespace_dict {}for attr in context n attr.nodeNameif n in unsuppressedPrefixes inclusive.append attr elif n.startswith 'xmlns ' and n[6 ] in unsuppressedPrefixes inclusive.append attr elif n.startswith 'xmlns' and n[5 ] in unsuppressedPrefixes inclusive.append attr elif attr.nodeName in usedPrefixes inclusive.append attr elif n.startswith 'xmlns ' unused_namespace_dict[n] attr.valuereturn inclusive unused_namespace_dict
def in6_ifaceidtomac ifaceid try ifaceid inet_pton socket.AF_INET6 ' ' + ifaceid [8 16]except return Noneif ifaceid[3 5] ! '\xff\xfe' return Nonefirst struct.unpack 'B' ifaceid[ 1] [0]ulbit 2 * [1 '-' 0][ first & 2 ] first struct.pack 'B' first & 253 | ulbit oui first + ifaceid[1 3] end ifaceid[5 ]l map lambda x '%.02x' % struct.unpack 'B' x [0] list oui + end return ' '.join l
def interpret_in_shape xshape if isinstance xshape int np.integer return xshape 1 elif len xshape 2 return xshapeelse return np.prod xshape 1
def Donut data label 'index' values None color None agg None hover_tool True hover_text None plot_height 400 plot_width 400 xgrid False ygrid False **kw kw['label'] labelkw['values'] valueskw['color'] colorkw['xgrid'] xgridkw['ygrid'] ygridkw['plot_height'] plot_heightkw['plot_width'] plot_widthif agg is not None kw['agg'] aggchart create_and_build DonutBuilder data **kw chart.left[0].visible Falsechart.below[0].visible False values agg derive_aggregation dim_cols label agg_col values agg agg if hover_tool tooltip build_agg_tooltip hover_text hover_text aggregated_col values agg_text agg chart.add_tools HoverTool tooltips [tooltip] return chart
def idd_reconid B idx proj B np.asfortranarray B if proj.size > 0 return _id.idd_reconid B idx proj else return B[ np.argsort idx ]
def check_multinomial_samples value expected_shape expected_mean tol assert value.shape expected_shape assert is_binary value assert np.all value.sum axis 1 1 mean value.mean axis 0 max_error np.abs mean - expected_mean .max if max_error > tol print 'Actualmean ' print mean print 'Expectedmean ' print expected_mean print 'Maximalerror ' max_error raise ValueError "Samplesdon'tseemtohavetherightmean."
def is_carrier_specific numobj region_codes region_codes_for_country_code numobj.country_code region_code _region_code_for_short_number_from_region_list numobj region_codes national_number national_significant_number numobj metadata PhoneMetadata.short_metadata_for_region region_code return metadata is not None and _is_number_matching_desc national_number metadata.carrier_specific
def sanitize_hostname hostname if six.PY3 hostname hostname.encode 'latin-1' 'ignore' hostname hostname.decode 'latin-1' elif isinstance hostname six.text_type hostname hostname.encode 'latin-1' 'ignore' hostname re.sub '[_]' '-' hostname hostname re.sub '[^\\w.-]+' '' hostname hostname hostname.lower hostname hostname.strip '.-' return hostname
def test_scenario_matches_tags_excluding scenario Scenario.from_string SCENARIO1 original_string SCENARIO1.strip tags ['anothertag' 'another-tag'] assert not scenario.matches_tags ['-anothertag'] assert scenario.matches_tags ['-foobar']
def destroy_vm session instance vm_ref try session.VM.destroy vm_ref except session.XenAPI.Failure LOG.exception _LE 'DestroyVMfailed' returnLOG.debug 'VMdestroyed' instance instance
def _pick_data_channels info exclude 'bads' with_ref_meg True return pick_types info ref_meg with_ref_meg include [] exclude exclude selection None **_PICK_TYPES_DATA_DICT
def Nonfunction *args return None
def test_disconnect_one timer func mock.Mock timer.timeout.connect func timer.timeout.disconnect func timer.timeout.emit assert not func.called
def _add_new_ide_controller_helper ide_controller_label controller_key bus_number if controller_key is None controller_key randint -200 250 ide_spec vim.vm.device.VirtualDeviceSpec ide_spec.device vim.vm.device.VirtualIDEController ide_spec.operation vim.vm.device.VirtualDeviceSpec.Operation.addide_spec.device.key controller_keyide_spec.device.busNumber bus_numberide_spec.device.deviceInfo vim.Description ide_spec.device.deviceInfo.label ide_controller_labelide_spec.device.deviceInfo.summary ide_controller_labelreturn ide_spec
def copy_monitordir host tmp_dir host.get_tmp_dir host.send_file MONITORDIR tmp_dir return os.path.join tmp_dir 'monitors'
def db_setup_with_retry db_name db_host db_port username None password None ensure_indexes True ssl False ssl_keyfile None ssl_certfile None ssl_cert_reqs None ssl_ca_certs None ssl_match_hostname True retrying_obj retrying.Retrying retry_on_exception _retry_if_connection_error wait_exponential_multiplier cfg.CONF.database.connection_retry_backoff_mul * 1000 wait_exponential_max cfg.CONF.database.connection_retry_backoff_max_s * 1000 stop_max_delay cfg.CONF.database.connection_retry_max_delay_m * 60 * 1000 return retrying_obj.call db_setup db_name db_host db_port username username password password ensure_indexes ensure_indexes ssl ssl ssl_keyfile ssl_keyfile ssl_certfile ssl_certfile ssl_cert_reqs ssl_cert_reqs ssl_ca_certs ssl_ca_certs ssl_match_hostname ssl_match_hostname
def print_info_content summary_info fout None rep_record 0 fout fout or sys.stdout if not summary_info.ic_vector summary_info.information_content rep_sequence summary_info.alignment[rep_record].seqfor pos ic in enumerate summary_info.ic_vector fout.write '%d%s%.3f\n' % pos rep_sequence[pos] ic
def get_portaudio_version_text return pa.get_version_text
def benchmarkNFunc iter ns def decorator func for n in ns benchmarkFuncs.append func n iter return funcreturn decorator
def format_tb tb limit None return format_list extract_tb tb limit
def source_attributes domain return string_attributes domain
def generate_involutions n idx list range n for p in permutations idx for i in idx if p[p[i]] ! i breakelse yield p
def __standardize_result status message data None debug_msg None result {'status' status 'message' message}if data is not None result['return'] dataif debug_msg is not None and debug result['debug'] debug_msgreturn result
def autostartup for app in settings.INSTALLED_APPS try mod import_module app + '.startup' except ImportError continueif hasattr mod 'run' mod.run
def CheckFlowAuthorizedLabels token flow_name flow_cls flow.GRRFlow.GetPlugin flow_name if flow_cls.AUTHORIZED_LABELS return CheckUserForLabels token.username flow_cls.AUTHORIZED_LABELS token token else return True
def fetch_lyricswiki artist title url LYRICSWIKI_URL_PATTERN % _lw_encode artist _lw_encode title html fetch_url url if not html returnlyrics extract_text_in html u"<divclass 'lyricbox'>" if lyrics and 'Unfortunately wearenotlicensed' not in lyrics return lyrics
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def recipients_to_addresses recipients review_request_id None addresses set for recipient in recipients assert isinstance recipient User or isinstance recipient Group if isinstance recipient User addresses.add build_email_address_for_user recipient else addresses.update get_email_addresses_for_group recipient review_request_id return addresses
def assert_deb_content test_case expected_paths package_path output_dir FilePath test_case.mktemp output_dir.makedirs check_output ['dpkg' '--extract' package_path.path output_dir.path] actual_paths set for f in output_dir.walk if f.isdir continueactual_paths.add FilePath '/' .descendant f.segmentsFrom output_dir test_case.assertEqual set expected_paths.difference actual_paths
def isFirstBestMatch result sickrage.srCore.srLogger.debug u'Checkingifweshouldarchiveourfirstbestqualitymatchforepisode' + result.name show_obj result.episodes[0].show any_qualities best_qualities Quality.splitQuality show_obj.quality if best_qualities and show_obj.archive_firstmatch and result.quality in best_qualities return Truereturn False
def task_flake8 yield {'name' os.path.join os.getcwd 'nikola' 'actions' ['flake8nikola/']}
def iterlen items try return len items except TypeError for i x in enumerate items count ireturn count + 1
def prepare_adagrad_test dataset_type 'arange' model_type 'random' cost SumOfCosts [SumOfOneHalfParamsSquared 0.0 DummyCost ] model DummyModel shapes lr_scalers scales init_type model_type if dataset_type 'arange' dataset ArangeDataset 1 elif dataset_type 'zeros' X np.zeros 1 1 X[ 0] np.arange 1 dataset DenseDesignMatrix X else raise ValueError 'Unknownvaluefordataset_type %s' dataset_type sgd SGD cost cost learning_rate learning_rate learning_rule AdaGrad batch_size 1 sgd.setup model model dataset dataset state {}for param in model.get_params param_shape param.get_value .shapestate[param] {}state[param]['sg2'] np.zeros param_shape return cost model dataset sgd state
def asinh x np import_module 'numpy' if isinstance x int float return interval np.arcsinh x elif isinstance x interval start np.arcsinh x.start end np.arcsinh x.end return interval start end is_valid x.is_valid else return NotImplementedError
def zdt2 individual g 1.0 + 9.0 * sum individual[1 ] / len individual - 1 f1 individual[0]f2 g * 1 - f1 / g ** 2 return f1 f2
def load_repo client path None index 'git' path dirname dirname abspath __file__ if path is None else path repo_name basename path repo git.Repo path create_git_index client index client.create index index doc_type 'repos' id repo_name body {} ignore 409 for ok result in streaming_bulk client parse_commits repo.refs.master.commit repo_name index index doc_type 'commits' chunk_size 50 action result result.popitem doc_id '/%s/commits/%s' % index result['_id'] if not ok print 'Failedto%sdocument%s %r' % action doc_id result else print doc_id
def delete_firewall_rule firewall_rule profile None conn _auth profile return conn.delete_firewall_rule firewall_rule
def rbm_ais_pk_free_energy rbmA_params rbmB_params beta v_sample def rbm_fe rbm_params v b weights visbias hidbias rbm_paramsvis_term b * tensor.dot v visbias hid_act b * tensor.dot v weights + hidbias fe - vis_term - tensor.sum tensor.log 1 + tensor.exp hid_act axis 1 return fefe_a rbm_fe rbmA_params v_sample 1 - beta fe_b rbm_fe rbmB_params v_sample beta return fe_a + fe_b
def new_repo path qtutils.opendir_dialog N_ u'NewRepository...' core.getcwd if not path return Noneif git.is_git_worktree path or git.is_git_dir path return path status out err core.run_command [u'git' u'init' path] if status 0 return pathelse title N_ u'ErrorCreatingRepository' msg N_ u'"% command s"returnedexitstatus% status d' % dict command u'gitinit%s' % path status status details N_ u'Output \n%s' % out if err details + u'\n\n'details + N_ u'Errors %s' % err qtutils.critical title msg details return None
def get_http_url method host path headers if method ! None and path ! None if host ! '' and not re.match ' http s ? // ?' + host path http_url_req method + '' + host + path else http_url_req method + '' + path http_url_req url_filter http_url_req return http_url_req
def applySparseFilter kerns kshp nkern images imgshp step 1 1 bias None mode 'valid' if numpy.size imgshp 2 imgshp 1 + imgshp indices indptr spmat_shape sptype outshp kmap convolution_indices.sparse_eval imgshp kshp nkern step mode sparsew theano.sparse.CSM sptype kmap kerns indices indptr spmat_shape output sparse.structured_dot sparsew images.T .Tif bias is not None output + biasreturn output numpy.hstack nkern outshp
def _can_show_deleted context if hasattr context 'show_deleted' return context.show_deletedif not hasattr context 'get' return Falsereturn context.get 'deleted' False
def finder pl initialize vim.command u'ruby$powerline.commandt_set_active_finder' return [{u'highlight_groups' [u'commandt finder'] u'contents' vim.eval u'g powerline_commandt_reply' .replace u'CommandT ' u'' .replace u'Finder ' u'' }]
def InitNetwork input_pattern model_spec mode 'eval' initial_learning_rate 5e-05 final_learning_rate 5e-05 halflife 1600000 optimizer_type 'Adam' num_preprocess_threads 1 reader None model VGSLImageModel mode model_spec initial_learning_rate final_learning_rate halflife left_bracket model_spec.find '[' right_bracket model_spec.rfind ']' if left_bracket < 0 or right_bracket < 0 raise ValueError 'Failedtofind[]inmodelspec!' model_spec input_spec model_spec[ left_bracket]layer_spec model_spec[left_bracket right_bracket + 1 ]output_spec model_spec[ right_bracket + 1 ]model.Build input_pattern input_spec layer_spec output_spec optimizer_type num_preprocess_threads reader return model
def _save_user_contributions user_contributions user_contributions.validate user_models.UserContributionsModel id user_contributions.user_id created_exploration_ids user_contributions.created_exploration_ids edited_exploration_ids user_contributions.edited_exploration_ids .put
def _default_callback_unzip afile fi nfiles if fi > 0 and fi % round nfiles / 10 0 pct_done round 100.0 * fi + 1.0 / nfiles sys.stdout.write '%d%%' % pct_done sys.stdout.flush if not is_windows and os.path.splitext afile [1] in system_specific_scripts or afile.endswith 'manage.py' sys.stdout.write ' DCTB Changingpermsonscript%s\n' % afile
def test_sample_wrong_X sm SMOTEENN random_state RND_SEED sm.fit X Y assert_raises RuntimeError sm.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def SHORTER fragment return len fragment
def min_weight graph src dst n default {'weight' np.inf}w1 graph[n].get src default ['weight']w2 graph[n].get dst default ['weight']return {'weight' min w1 w2 }
def sort_q_values header_val if not header_val return []def item x e r x.partition u';' [ 2] p v r.partition u' ' [ 2]q 1.0if p u'q' and v try q max 0.0 min 1.0 float v.strip except Exception passreturn e.strip q return tuple map itemgetter 0 sorted map item parse_http_list header_val key itemgetter 1 reverse True
def _ShardName name number return _SuffixName name str number
def get_compiler compiler **compiler_attrs if compiler is None or isinstance compiler str cc ccompiler.new_compiler compiler compiler customize_compiler cc if cc.compiler_type 'mingw32' customize_mingw cc else cc compilerfor name val in compiler_attrs.items setattr cc name val return cc
def jsbuild_prompt print BOKEHJS_BUILD_PROMPT mapping {'1' True '2' False}value input 'Choice?' while value not in mapping print "Input'%s'notunderstood.Validchoices 1 2\n" % value value input 'Choice?' return mapping[value]
def attach_total_points queryset as_field 'total_points_attr' model queryset.modelsql 'SELECTSUM projects_points.value \nFROMuserstories_rolepoints\nINNERJOINprojects_pointsONuserstories_rolepoints.points_id projects_points.id\nWHEREuserstories_rolepoints.user_story_id {tbl}.id'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def libvlc_video_get_track p_mi f _Cfunctions.get 'libvlc_video_get_track' None or _Cfunction 'libvlc_video_get_track' 1 None ctypes.c_int MediaPlayer return f p_mi
def instance_name instance return getattr instance 'OS-EXT-SRV-ATTR instance_name' None
def _annotated_unpack_infer stmt context None if isinstance stmt List Tuple for elt in stmt.elts inferred safe_infer elt if inferred and inferred is not YES yield elt inferred returnfor infered in stmt.infer context if infered is YES continue yield stmt infered
def survey_getTemplateFromSeries series_id s3db current.s3dbstable s3db.survey_seriesttable s3db.survey_templatequery stable.id series_id & ttable.id stable.template_id row current.db query .select ttable.ALL limitby 0 1 .first return row
def frac_in f t **kwargs cancel kwargs.pop 'cancel' False if type f is tuple fa fd ff fa.as_expr / fd.as_expr fa fd f.as_expr .as_numer_denom fa fd fa.as_poly t **kwargs fd.as_poly t **kwargs if cancel fa fd fa.cancel fd include True if fa is None or fd is None raise ValueError 'Couldnotturn%sintoafractionin%s.' % f t return fa fd
def rotate_reverse lst dist n len lst sublist_reverse lst 0 dist - 1 sublist_reverse lst dist n - 1 sublist_reverse lst 0 n - 1
def join_host_strings user host port None if port template '%s@[%s] %s' if host.count ' ' > 1 else '%s@%s %s' return template % user host port else return '%s@%s' % user host
def _objective mle precision_ alpha p precision_.shape[0]cost -2.0 * log_likelihood mle precision_ + p * np.log 2 * np.pi cost + alpha * np.abs precision_ .sum - np.abs np.diag precision_ .sum return cost
def testing_suite unittest_suite unittest.TestSuite test_loader unittest.TestLoader test_loader.testMethodPrefix 'test_'tests [TestPSW]for test in tests cur_suite test_loader.loadTestsFromTestCase test unittest_suite.addTest cur_suite doctest_suite doctest.DocTestSuite psw big_suite unittest.TestSuite unittest_suite doctest_suite return big_suite
def gen_arg_access_qual_md fn mod fn.moduleconsts [lc.MetaDataString.get mod 'none' ] * len fn.args name lc.MetaDataString.get mod 'kernel_arg_access_qual' return lc.MetaData.get mod [name] + consts
@commands u'announce' @example u'.announceSomeimportantmessagehere' def announce bot trigger if not trigger.admin bot.reply u"Sorry Ican'tletyoudothat" returnfor channel in bot.channels bot.msg channel u'[ANNOUNCEMENT]%s' % trigger.group 2 bot.reply u'Announcecomplete.'
def set_fw_rules subprocess.call 'iptables-tnat-APREROUTING-ptcp--dport80-jDNAT--to-destination%s %s' % NETWORK_GW_IP PORT shell True subprocess.call 'iptables-tnat-APREROUTING-pudp--dport53-jDNAT--to-destination%s %s' % NETWORK_GW_IP 53 shell True subprocess.call 'iptables-tnat-APREROUTING-ptcp--dport53-jDNAT--to-destination%s %s' % NETWORK_GW_IP 53 shell True subprocess.call 'iptables-tnat-APREROUTING-ptcp--dport443-jDNAT--to-destination%s %s' % NETWORK_GW_IP SSL_PORT shell True
def install_numpy_scipy chdir SRC_DIR apt_command 'build-deppython-numpy' apt_command 'build-deppython-scipy' run_command 'pipinstall-d.numpy' run_command 'tarxvzfnumpy*.tar.gz' run_command "sed-i's/returnNone#/pass#/'numpy*/numpy/core/setup.py" run_command 'cdnumpy*&&pythonsetup.pyinstall' run_command 'pipinstallscipy'
def bayesian_info_criterion log_likelihood n_params n_samples return n_params * np.log n_samples - 2.0 * log_likelihood
def to_entity_json entity entity_sentiment entity_frequency json_doc {}avg_sentiment float entity_sentiment / float entity_frequency json_doc['wiki_url'] entityjson_doc['name'] get_wiki_title entity json_doc['sentiment'] float '%.3f' % entity_sentiment json_doc['avg_sentiment'] float '%.3f' % avg_sentiment return json.dumps json_doc
def p_ref_type p ref_type thrift_stack[ -1 ]for name in p[1].split '.' ref_type getattr ref_type name None if ref_type is None raise ThriftParserError 'Notypefound %r atline%d' % p[1] p.lineno 1 if hasattr ref_type '_ttype' p[0] getattr ref_type '_ttype' ref_type else p[0] ref_type
def load_resource name try if is_ST3 return sublime.load_resource 'Packages/MarkdownPreview/{0}'.format name else filename os.path.join sublime.packages_path INSTALLED_DIRECTORY os.path.normpath name return load_utf8 filename except print "Errorwhileload_resource '%s' " % name traceback.print_exc return ''
def prevent_recursion default def decorator func name '_calling_%s_' % func.__name__ def newfunc self *args **kwds if getattr self name False return default setattr self name True try return func self *args **kwds finally setattr self name False return newfuncreturn decorator
def _find_backup cs backup return utils.find_resource cs.backups backup
def collect_replies conn channel queue *args **kwargs no_ack kwargs.setdefault 'no_ack' True received Falsetry for body message in itermessages conn channel queue *args **kwargs if not no_ack message.ack received True yield body finally if received channel.after_reply_message_received queue.name
def AppLogInit logging.debug 'InitializingApplicationLogger.' return GrrApplicationLogger
def _colspec dataset_width spec 'l'for _ in range 1 dataset_width spec + 'r'return spec
def mlinspace a b nums order 'C' a numpy.array a dtype 'float64' b numpy.array b dtype 'float64' nums numpy.array nums dtype 'int64' nodes [numpy.linspace a[i] b[i] nums[i] for i in range len nums ]return cartesian nodes order order
def intToID idnum rid ''while idnum > 0 idnum - 1rid chr idnum % 26 + ord 'a' + rid idnum int idnum / 26 return rid
def _read_page_header file_obj tin TFileTransport file_obj pin TCompactProtocolFactory .get_protocol tin page_header parquet_thrift.PageHeader page_header.read pin return page_header
@log_calldef metadef_object_get_all context namespace_name namespace metadef_namespace_get context namespace_name objects []_check_namespace_visibility context namespace namespace_name for object in DATA['metadef_objects'] if object['namespace_id'] namespace['id'] objects.append object return objects
def NormalProbabilityPlot sample fit_color '0.8' **options xs ys NormalProbability sample mean var MeanVar sample std math.sqrt var fit FitLine xs mean std thinkplot.Plot color fit_color label 'model' *fit xs ys NormalProbability sample thinkplot.Plot xs ys **options
def delete_router router profile None conn _auth profile return conn.delete_router router
def _set_cache_version version from django.core.cache import cachecache.set CMS_PAGE_CACHE_VERSION_KEY version get_cms_setting 'CACHE_DURATIONS' ['content']
def isPrime N false_positive_prob 1e-06 randfunc None if _fastmath is not None return _fastmath.isPrime long N false_positive_prob randfunc if N < 3 or N & 1 0 return N 2 for p in sieve_base if N p return 1if N % p 0 return 0rounds int math.ceil - math.log false_positive_prob / math.log 4 return _rabinMillerTest N rounds randfunc
def mpl_runner safe_execfile def mpl_execfile fname *where **kw 'matplotlib-awarewrapperaroundsafe_execfile.\n\nItsinterfaceisidenticaltothatofthe func `execfile`builtin.\n\nThisisultimatelyacalltoexecfile butwrappedinsafetiesto\nproperlyhandleinteractiverendering.'import matplotlibimport matplotlib.pyplot as pltis_interactive matplotlib.rcParams['interactive']matplotlib.interactive False safe_execfile fname *where **kw matplotlib.interactive is_interactive if plt.draw_if_interactive.called plt.draw plt.draw_if_interactive.called Falsetry da plt.draw_allexcept AttributeError passelse da return mpl_execfile
def delete_vlanid vlan_id LOG.debug _ 'delete_vlanid called' session db.get_session try vlanid session.query network_models_v2.VlanID .filter_by vlan_id vlan_id .one session.delete vlanid session.flush return vlanidexcept exc.NoResultFound pass
def PrintUsage message sys.stderr.write _USAGE if message sys.exit '\nFATALERROR ' + message else sys.exit 0
def parse_exponent source start if not source[start] in {'e' 'E'} if source[start] in IDENTIFIER_PART raise SyntaxError 'Invalidnumberliteral!' return startstart + 1if source[start] in {'-' '+'} start + 1FOUND Falsewhile source[start] in NUMS FOUND Truestart + 1if not FOUND or source[start] in IDENTIFIER_PART raise SyntaxError 'Invalidnumberliteral!' return start
def seq2str2 sequence if not sequence return '[]'return '[%s]' % '|'.join unic item for item in sequence
def ok_ pred msg None msg msg or '%r! True' % pred assert pred msg
def make_service_dict name service_dict working_dir filename None resolver config.ServiceExtendsResolver config.ServiceConfig working_dir working_dir filename filename name name config service_dict config.ConfigFile filename filename config {} environment Environment.from_env_file working_dir return config.process_service resolver.run
def from_units val val str val .strip .upper if val '-1' return valm RE_UNITS.search val if m if m.group 2 val float m.group 1 unit m.group 2 n 0while unit ! TAB_UNITS[n] val val * 1024.0 n n + 1 else val m.group 1 try return float val except return 0.0else return 0.0
def deduplicate_countries country dup_country regions dup_country.region_set.all if regions.exists regions.update country country cities dup_country.city_set.all if cities.exists cities.update country country users dup_country.userprofile_set.all if users.exists users.update geo_country country dup_country.delete
def get_file filename return os.path.join TEST_DIR filename
def build_narrow_filter narrow check_supported_events_narrow_filter narrow def narrow_filter event message event['message']flags event['flags']for element in narrow operator element[0]operand element[1]if operator 'stream' if message['type'] ! 'stream' return Falseif operand.lower ! message['display_recipient'].lower return Falseelif operator 'topic' if message['type'] ! 'stream' return Falseif operand.lower ! message['subject'].lower return Falseelif operator 'sender' if operand.lower ! message['sender_email'].lower return Falseelif operator 'is' and operand 'private' if message['type'] ! 'private' return Falseelif operator 'is' and operand in ['starred'] if operand not in flags return Falseelif operator 'is' and operand in ['alerted' 'mentioned'] if 'mentioned' not in flags return Falsereturn Truereturn narrow_filter
def force_drop_names *names from . import configfrom sqlalchemy import inspect@decoratordef go fn *args **kw try return fn *args **kw finally drop_all_tables config.db inspect config.db include_names names return go
def print_to_tty string open '/dev/tty' 'w' .write string + '\n'
def set_global_registry registry entry_point_group '_default' global __GLOBAL_REGISTRYlog.debug "'set_global_registry '-settingregistry." __GLOBAL_REGISTRY[entry_point_group] registry
def _check_pandas_installed try import pandas as pdreturn pdexcept ImportError raise RuntimeError 'ForthismethodtoworkthePandaslibraryisrequired.'
def check_call *popenargs **kwargs retcode call *popenargs **kwargs if retcode cmd kwargs.get 'args' if cmd is None cmd popenargs[0]raise CalledProcessError retcode cmd return 0
def ECDF values x np.array values copy True x.sort x.shape np.product x.shape axis 0 n x.shape[0]y np.arange n + 1.0 / n return StepFunction x y
def test_cc_fit_invalid_ratio ratio 1.0 / 10000.0 cc ClusterCentroids ratio ratio random_state RND_SEED assert_raises RuntimeError cc.fit X Y
def add_build_arguments parser parser.add_argument '--involucro-path' dest 'involucro_path' default None help 'Pathtoinvolucro ifnotsetwilllookinworkingdirectoryandonPATH .' parser.add_argument '--force-rebuild' dest 'force_rebuild' action 'store_true' help 'Rebuildpackageevenifalreadypublished.' parser.add_argument '--dry-run' dest 'dry_run' action 'store_true' help 'Justprintcommandsinsteadofexecutingthem.' parser.add_argument '-n' '--namespace' dest 'namespace' default 'mulled' help 'quay.ionamespace.' parser.add_argument '-r' '--repository_template' dest 'repository_template' default DEFAULT_REPOSITORY_TEMPLATE help 'Dockerrepositorytargetforpublication onlyquay.ioorcompat.APIiscurrentlysupported .' parser.add_argument '-c' '--channel' dest 'channel' default DEFAULT_CHANNEL help 'Targetcondachannel' parser.add_argument '--extra-channels' dest 'extra_channels' default ' '.join DEFAULT_EXTRA_CHANNELS help 'Dependentcondachannels.'
def check_min_healthy_instances min_healthy healthy ec2_utils.GetELBInstancesByHealth env.region node_types [env.nodetype] num_healthy len healthy['InService'] assert num_healthy > min_healthy 'NotenoughbackendswithhealthyELBstatus %dvs%d ' % num_healthy min_healthy
def _simple_cmd cmd app url 'http //localhost 8080/manager' timeout 180 try opts {'path' app 'version' ls url [app]['version']}return '\n'.join _wget cmd opts url timeout timeout ['msg'] except Exception return 'FAIL-Nocontextexistsforpath{0}'.format app
def num_plurals catalog message if not message.pluralizable if not isinstance message.string basestring raise TranslationError 'Foundpluralformsfornon-pluralizablemessage' returnelif catalog is None returnmsgstrs message.stringif not isinstance msgstrs list tuple msgstrs msgstrs if len msgstrs ! catalog.num_plurals raise TranslationError 'Wrongnumberofpluralforms expected%d ' % catalog.num_plurals
def get_file_items path raise_not_found False ignore_empty_lines True import frappe.utilscontent read_file path raise_not_found raise_not_found if content content frappe.utils.strip content return [p.strip for p in content.splitlines if not ignore_empty_lines or p.strip and not p.startswith u'#' ]else return []
def _cleanupConnections senderkey signal try receivers connections[senderkey][signal]except passelse if not receivers try signals connections[senderkey]except KeyError passelse del signals[signal]if not signals _removeSender senderkey
def page_missing request page_name revision_requested protected False return Response generate_template 'page_missing.html' page_name page_name revision_requested revision_requested protected protected status 404
def new data None return SHA224Hash .new data
def group_sums_dummy x group_dummy if data_util._is_using_ndarray_type group_dummy None return np.dot x.T group_dummy else return x.T * group_dummy
def _add_billed_ops_to_map billed_ops_map billed_ops_list for billed_op in billed_ops_list if billed_op.op not in billed_ops_map update_me datamodel_pb.BilledOpProto update_me.set_op billed_op.op update_me.set_num_ops 0 billed_ops_map[billed_op.op ] update_meupdate_me billed_ops_map[billed_op.op ]update_me.set_num_ops update_me.num_ops + billed_op.num_ops
def _validate_webroot webroot_path if not os.path.isdir webroot_path raise errors.PluginError webroot_path + 'doesnotexistorisnotadirectory' return os.path.abspath webroot_path
def tanh X return np.tanh X out X
def corner_peaks image min_distance 1 threshold_abs None threshold_rel 0.1 exclude_border True indices True num_peaks np.inf footprint None labels None peaks peak_local_max image min_distance min_distance threshold_abs threshold_abs threshold_rel threshold_rel exclude_border exclude_border indices False num_peaks num_peaks footprint footprint labels labels if min_distance > 0 coords np.transpose peaks.nonzero for r c in coords if peaks[ r c ] peaks[ r - min_distance r + min_distance + 1 c - min_distance c + min_distance + 1 ] Falsepeaks[ r c ] Trueif indices is True return np.transpose peaks.nonzero else return peaks
def _get_xunit_setup_teardown holder attr_name param_obj None param_obj param_obj if param_obj is not None else holder result _get_xunit_func holder attr_name if result is not None arg_count result.__code__.co_argcountif inspect.ismethod result arg_count - 1if arg_count return lambda result param_obj else return result
def umc_module_for_add module container_dn superordinate None mod module_by_name module position position_base_dn position.setDn container_dn obj mod.object config uldap position superordinate superordinate obj.open return obj
def update_or_create model event_id **kwargs was_created Falseinstance db.session.query model .filter_by event_id event_id .first if instance db.session.query model .filter_by event_id event_id .update kwargs else was_created Trueinstance model event_id event_id **kwargs db.session.add instance db.session.commit return instance was_created
def routingAreaUpdateComplete ReceiveNpduNumbersList_presence 0 a TpPd pd 3 b MessageType mesType 10 packet a / b if ReceiveNpduNumbersList_presence is 1 c ReceiveNpduNumbersList ieiRNNL 38 packet packet / c return packet
def department mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepif not auth.s3_has_role ADMIN s3.filter auth.filter_by_root_org s3db.hrm_department output s3_rest_controller return output
def _fileToMatrix file_name if 1 < 3 lres []for line in open file_name 'r' .readlines if len line > 0 and line[0] not in '%' '#' lres.append list map float line.split res lreselse fil open file_name 'r' fil.readline lineToRow lambda line list map float line.split res list map lineToRow fil.readlines fil.close while res ! [] and res[0] [] del res[0]return resprint 'couldnotreadfile' + file_name
def __read_docker_compose path if os.path.isfile os.path.join path dc_filename is False return __standardize_result False 'Pathdoesnotexistordocker-compose.ymlisnotpresent' None None f salt.utils.fopen os.path.join path dc_filename 'r' result {'docker-compose.yml' ''}if f for line in f result['docker-compose.yml'] + linef.close else return __standardize_result False 'Couldnotreaddocker-compose.ymlfile.' None None return __standardize_result True 'Readingcontentofdocker-compose.ymlfile' result None
@with_setup prepare_stdout registry.clear def test_xunit_output_with_different_filename called []def assert_correct_xml filename content called.append True assert_xsd_valid filename content assert_equals filename 'custom_filename.xml' old xunit_output.wrt_outputxunit_output.wrt_output assert_correct_xmlrunner Runner feature_name 'error_traceback' enable_xunit True xunit_filename 'custom_filename.xml' runner.run assert_equals 1 len called 'Functionnotcalled' xunit_output.wrt_output old
def combine_vars a b if C.DEFAULT_HASH_BEHAVIOUR 'merge' return merge_hash a b else _validate_mutable_mappings a b result a.copy result.update b return result
def test_find_module_4 nt.assert_is_none mp.find_module None
def make_axis_dummies frame axis 'minor' transform None numbers {'major' 0 'minor' 1}num numbers.get axis axis items frame.index.levels[num]labels frame.index.labels[num]if transform is not None mapped_items items.map transform labels items _factorize_from_iterable mapped_items.take labels values np.eye len items dtype float values values.take labels axis 0 return DataFrame values columns items index frame.index
@api_versions.wraps '2.0' '2.32' @utils.arg '--matching' metavar '<hostname>' default None help _ 'Listhypervisorsmatchingthegiven<hostname>.' def do_hypervisor_list cs args _do_hypervisor_list cs matching args.matching
def group_table_indices table key_vars exclude_unknown False groups defaultdict list for i inst in enumerate table key [ inst.id if a INSTANCEID else i if a INDEX else inst[a] for a in key_vars]if exclude_unknown and any math.isnan k for k in key continuekey tuple [str k for k in key] groups[key].append i return groups
def p_command_next_bad p p[0] 'MALFORMEDNEXT'
def _path_is_abs path if path is None return Truetry return os.path.isabs path except AttributeError return False
def getRemainingEdgeTable edges vertexes z remainingEdgeTable {}if len edges > 0 if edges[0].zMinimum None for edge in edges edge.zMinimum min vertexes[edge.vertexIndexes[0]].z vertexes[edge.vertexIndexes[1]].z edge.zMaximum max vertexes[edge.vertexIndexes[0]].z vertexes[edge.vertexIndexes[1]].z for edgeIndex in xrange len edges edge edges[edgeIndex]if edge.zMinimum < z and edge.zMaximum > z remainingEdgeTable[edgeIndex] edgereturn remainingEdgeTable
def _rearrange_args l if len l 1 return lx list l[ -1 ] x.extend l[0 -1 ] return Mul *x .args
def volume_type_create context values projects None return IMPL.volume_type_create context values projects
@permission_required 'users.add_userban' def ban_user_and_cleanup request username user get_object_or_404 User username username user_ban UserBan.objects.filter user user is_active True date_three_days_ago datetime.now .date - timedelta days 3 revisions user.created_revisions.prefetch_related 'document' revisions revisions.defer 'content' 'summary' .order_by '-id' revisions revisions.filter created__gte date_three_days_ago revisions_not_spam revisions.filter akismet_submissions None return render request 'users/ban_user_and_cleanup.html' {'detail_user' user 'user_banned' user_ban 'revisions' revisions 'revisions_not_spam' revisions_not_spam 'on_ban_page' True}
def get_mapping_data_by_usernames usernames return [{'username' username 'remote_id' 'remote_' + username } for username in usernames]
@bdd.then bdd.parsers.parse 'thejsononthepageshouldbe \n{text}' def check_contents_json quteproc text content quteproc.get_content .strip expected json.loads text actual json.loads content assert actual expected
def test_keep_duplicates testdir a testdir.mkdir 'a' fh a.join 'test_a.py' fh.write _pytest._code.Source '\nimportpytest\ndeftest_real \npass\n' result testdir.runpytest '--keep-duplicates' a.strpath a.strpath result.stdout.fnmatch_lines ['*collected2item*']
def ParseFile file base_uri *args **kwds return _ParseFileEx file base_uri *args **kwds [1 ]
def addVertexes geometryOutput vertexes if geometryOutput.__class__ list for element in geometryOutput addVertexes element vertexes returnif geometryOutput.__class__ dict for geometryOutputKey in geometryOutput.keys if geometryOutputKey 'vertex' vertexes + geometryOutput[geometryOutputKey]else addVertexes geometryOutput[geometryOutputKey] vertexes
def isString s try return isinstance s unicode or isinstance s basestring except NameError return isinstance s str
def printError failure domainname failure.trap error.DNSNameError sys.stderr.write 'ERROR domainnamenotfound%r\n' % domainname
def individual_billed_ops_to_str self return billed_ops_to_str self.billed_ops_list
def intfOptions net Mininet autoStaticArp True net.addController 'c0' h1 net.addHost 'h1' h2 net.addHost 'h2' s1 net.addSwitch 's1' link1 net.addLink h1 s1 cls TCLink net.addLink h2 s1 net.start net.pingAll info '\n***Configuringoneintfwithbandwidthof5Mb\n' link1.intf1.config bw 5 info '\n***Runningiperftotest\n' net.iperf info '\n***Configuringoneintfwithlossof50%\n' link1.intf1.config loss 50 info '\n' net.iperf h1 h2 l4Type 'UDP' info '\n***Configuringoneintfwithdelayof15ms\n' link1.intf1.config delay '15ms' info '\n***Runapingtoconfirmdelay\n' net.pingPairFull info '\n***Donetesting\n' net.stop
def to_decimal x try return D x except TypeError return D '%0.54f' % x
def strategy_largest_first G colors return sorted G key G.degree reverse True
def _generate_site_navigation pages_config url_context use_dir_urls True nav_items []pages []previous Nonefor config_line in pages_config for page_or_header in _follow config_line url_context use_dir_urls if isinstance page_or_header Header if page_or_header.is_top_level nav_items.append page_or_header elif isinstance page_or_header Page if page_or_header.is_top_level nav_items.append page_or_header pages.append page_or_header if previous page_or_header.previous_page previousprevious.next_page page_or_headerprevious page_or_headerif len pages 0 raise exceptions.ConfigurationError u'Nopagesfoundinthepagesconfig.Removeitentirelytoenableautomaticpagediscovery.' return nav_items pages
def datastore_make_public context data_dict if 'id' in data_dict data_dict['resource_id'] data_dict['id']res_id _get_or_bust data_dict 'resource_id' data_dict['connection_url'] config['ckan.datastore.write_url']if not _resource_exists context data_dict raise p.toolkit.ObjectNotFound p.toolkit._ u'Resource"{0}"wasnotfound.'.format res_id p.toolkit.check_access 'datastore_change_permissions' context data_dict db.make_public context data_dict
def ebAuthentication failure proto username password failure.trap imap4.NoSupportedAuthentication return proto.prompt 'Nosecureauthenticationavailable.Logininsecurely? y/N ' .addCallback cbInsecureLogin proto username password
def test_undefined value return isinstance value Undefined
def _to_seconds timestr timestr timestr.upper if 'H' in timestr seconds int timestr.replace 'H' '' * 3600 elif 'D' in timestr seconds int timestr.replace 'D' '' * 86400 elif 'W' in timestr seconds 604800else try seconds int timestr except ValueError seconds 604800if seconds > 604800 seconds 604800return seconds
def http_auth_required realm def decorator fn @wraps fn def wrapper *args **kwargs if _check_http_auth return fn *args **kwargs if _security._unauthorized_callback return _security._unauthorized_callback else r _security.default_http_auth_realm if callable realm else realm h {'WWW-Authenticate' 'Basicrealm "%s"' % r }return _get_unauthorized_response headers h return wrapperif callable realm return decorator realm return decorator
def include_dirs_from_path include_dirs []for p in os.environ['PATH'].split os.path.pathsep if p.endswith '/' p p[ -1 ]if p.endswith 'bin' include_dirs.append p[ -3 ] + 'include' return include_dirs
def ngettext singular plural number global _default _activet _active.get currentThread None if t is not None return t.ngettext singular plural number if _default is None from django.conf import settings_default translation settings.LANGUAGE_CODE return _default.ngettext singular plural number
def _require_tp language project from pootle_translationproject.models import create_translation_projectreturn create_translation_project language project
def embed_album log album maxwidth None quiet False compare_threshold 0 ifempty False imagepath album.artpathif not imagepath log.info u'Noalbumartpresentfor{0}' album returnif not os.path.isfile syspath imagepath log.info u'Albumartnotfoundat{0}for{1}' displayable_path imagepath album returnif maxwidth imagepath resize_image log imagepath maxwidth log.info u'Embeddingalbumartinto{0}' album for item in album.items embed_item log item imagepath maxwidth None compare_threshold ifempty as_album True
def argToBool x if isinstance x six.string_types if x.lower in u'0' u'false' u'f' u'no' u'n' u'off' return Falseelif x.lower in u'1' u'true' u't' u'yes' u'y' u'on' return Trueraise ValueError u'failedtocastasboolean' return bool x
def list_nat_rules module driver network_domain try return driver.ex_list_nat_rules network_domain except DimensionDataAPIException e get_exception module.fail_json msg 'FailedtolistNATrules %s' % e.message
def is_bind_mounted module linux_mounts dest src None fstype None is_mounted Falseif get_platform 'Linux' and linux_mounts is not None if src is None if dest in linux_mounts is_mounted Trueelif dest in linux_mounts and linux_mounts[dest]['src'] src is_mounted Trueelse bin_path module.get_bin_path 'mount' required True cmd '%s-l' % bin_path rc out err module.run_command cmd mounts []if len out mounts to_native out .strip .split '\n' for mnt in mounts arguments mnt.split if arguments[0] src or src is None and arguments[2] dest and arguments[4] fstype or fstype is None is_mounted Trueif is_mounted breakreturn is_mounted
def model_fields model db_session None only None exclude None field_args None converter None if not hasattr model u'_sa_class_manager' raise TypeError u'modelmustbeasqlalchemymappedmodel' mapper model._sa_class_manager.mapperconverter converter or ModelConverter field_args field_args or {} properties p.key p for p in mapper.iterate_properties if only properties x for x in properties if x[0] in only elif exclude properties x for x in properties if x[0] not in exclude field_dict {}for name prop in properties field converter.convert model mapper prop field_args.get name db_session if field is not None field_dict[name] fieldreturn field_dict
def _time_last_active cluster_summary steps timestamps []for key in 'creationdatetime' 'readydatetime' value getattr cluster_summary.status.timeline key None if value timestamps.append value for step in steps for key in 'creationdatetime' 'startdatetime' 'enddatetime' value getattr step.status.timeline key None if value timestamps.append value last_timestamp max timestamps return iso8601_to_datetime last_timestamp
def from_bundle_ingest_dirname cs return pd.Timestamp cs.replace ';' ' '
def extract_http_basic_credentials request authorization request.headers.get 'Authorization' if not authorization return Nonetry authmeth auth authorization.split '' 1 except ValueError return Noneif authmeth.lower ! 'basic' return Nonetry authbytes b64decode auth.strip except TypeError binascii.Error return Nonetry auth authbytes.decode 'utf-8' except UnicodeDecodeError auth authbytes.decode 'latin-1' try username password auth.split ' ' 1 except ValueError return Nonereturn HTTPBasicCredentials username password
def isCarbonAquaTk root global _carbonaquatkif _carbonaquatk is None _carbonaquatk runningAsOSXApp and 'aqua' in root.tk.call 'tk' 'windowingsystem' and 'AppKit' not in root.tk.call 'winfo' 'server' '.' return _carbonaquatk
def test_escaped value return hasattr value '__html__'
def cyclic_metasploit length None sets None sets sets or [string.ascii_uppercase string.ascii_lowercase string.digits] out []for ndx c in enumerate metasploit_pattern sets if length ! None and ndx > length breakelse out.append c out ''.join out if len out < length log.error "Can'tcreateapatternoflength%iwithsetsoflengths%s.Maximumpatternlengthis%i." % length map len sets len out return ''.join out
@must_be_contributor_or_publicdef get_pointed auth node **kwargs return {'pointed' [serialize_pointer each auth for each in node.pointed if not get_pointer_parent each .is_collection ]}
def list_nodes_full call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodes_fullfunctionmustbecalledwith-for--function.' return get_resources_vms includeConfig True
def get_tu source lang 'c' all_warnings False flags [] args list flags name 't.c'if lang 'cpp' name 't.cpp'args.append '-std c++11' elif lang 'objc' name 't.m'elif lang ! 'c' raise Exception 'Unknownlanguage %s' % lang if all_warnings args + ['-Wall' '-Wextra']return TranslationUnit.from_source name args unsaved_files [ name source ]
def xml_add_meta data xml ''meta []if data.get config.META ordered_meta OrderedDict sorted data[config.META].items for name value in ordered_meta.items meta.append '<%s>%d</%s>' % name value name if meta xml '<%s>%s</%s>' % config.META ''.join meta config.META return xml
def cholesky a lower False l u _cholesky a if lower return lelse return u
def convertPermanences sourceSP destSP numColumns sourceSP.getNumColumns numInputs sourceSP.getNumInputs for i in xrange numColumns potential numpy.zeros numInputs .astype uintType sourceSP.getPotential i potential destSP.setPotential i potential perm numpy.zeros numInputs .astype realType sourceSP.getPermanence i perm destSP.setPermanence i perm
def _add_kernel_to_bootloader bootloader base_args tag args image initrd bootloader.remove_kernel tag if base_args if args args '%s%s' % base_args args else args base_argsbootloader.add_kernel path image title tag initrd initrd args args
def tgrep_nodes pattern trees search_leaves True if isinstance pattern binary_type text_type pattern tgrep_compile pattern for tree in trees try if search_leaves positions tree.treepositions else positions treepositions_no_leaves tree yield [tree[position] for position in positions if pattern tree[position] ] except AttributeError yield []
def find_again text return _setup text .find_again text
def p_struct_declarator_1 t pass
def skip_because **kwargs def actual_decoration obj skip_method _get_skip_method obj bugs kwargs.get 'bugs' if bugs and isinstance bugs collections.Iterable for bug in bugs if not bug.isdigit raise ValueError 'bugmustbeavalidbugnumber' obj skip_method obj 'SkippeduntilBugs %sareresolved.' % ' '.join [bug for bug in bugs] return objreturn actual_decoration
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def _get_index passed_id None if passed_id index_matcher re.search '.*?/? \\d+ $' passed_id if index_matcher return int index_matcher.group 1 return 0
def image_get_resized_images base64_source return_big False return_medium True return_small True big_name 'image' medium_name 'image_medium' small_name 'image_small' avoid_resize_big True avoid_resize_medium False avoid_resize_small False return_dict dict if return_big return_dict[big_name] image_resize_image_big base64_source avoid_if_small avoid_resize_big if return_medium return_dict[medium_name] image_resize_image_medium base64_source avoid_if_small avoid_resize_medium if return_small return_dict[small_name] image_resize_image_small base64_source avoid_if_small avoid_resize_small return return_dict
def setup_module self try use_plugin 'simpleitk' except ImportError pass
def stream_decompress iterator mode 'gzip' if mode not in ['gzip' 'deflate'] raise ValueError 'stream_decompressmodemustbegzipordeflate' zlib_mode 16 + zlib.MAX_WBITS if mode 'gzip' else - zlib.MAX_WBITS dec zlib.decompressobj zlib_mode try for chunk in iterator rv dec.decompress chunk if rv yield rv except zlib.error yield chunk for chunk in iterator yield chunk else buf dec.decompress bytes rv buf + dec.flush if rv yield rv
def getAudio parent encode True r Recorder mb QMessageBox parent restoreGeom mb 'audioRecorder' mb.setWindowTitle 'Anki' mb.setIconPixmap QPixmap ' /icons/media-record.png' but QPushButton _ 'Stop' but.setIcon QIcon ' /icons/media-playback-stop.png' mb.addButton but QMessageBox.RejectRole t time.time r.start QApplication.instance .processEvents while not mb.clickedButton txt _ 'Recording...<br>Time %0.1f' mb.setText txt % time.time - t mb.show QApplication.instance .processEvents saveGeom mb 'audioRecorder' while time.time - t < 1 time.sleep 0.1 r.stop r.postprocess encode return r.file
def test_app environ start_response req Request environ populate_request False if req.args.get 'resource' 'logo' response logoelse response Response render_testapp req mimetype 'text/html' return response environ start_response
def _instance_get_all_uuids_by_host context host uuids []for tuple in model_query context models.Instance models.Instance.uuid read_deleted 'no' .filter_by host host .all uuids.append tuple[0] return uuids
def restore_important_follower_config dict_ global include_tags exclude_tagsinclude_tags.update dict_['memoized_config']['include_tags'] exclude_tags.update dict_['memoized_config']['exclude_tags']
def npath path return path
@_replaceIf _PY3 getattr os 'fsdecode' None def _fsdecode x if isinstance x unicode return xreturn x.decode sys.getfilesystemencoding
def _getGitShaString dist None sha None shaStr 'n/a'if dist is not None proc subprocess.Popen 'gitrev-parse--shortHEAD' stdout subprocess.PIPE stderr subprocess.PIPE cwd '.' shell True repo_commit _ proc.communicate del procif repo_commit shaStr repo_commit.strip else shaStr 'n/a'return shaStr
def synchronized_with_prefix lock_file_prefix return functools.partial synchronized lock_file_prefix lock_file_prefix
def ctc_decode y_pred input_length greedy True beam_width 100 top_paths 1 y_pred tf.log tf.transpose y_pred perm [1 0 2] + 1e-08 input_length tf.to_int32 input_length if greedy decoded log_prob ctc.ctc_greedy_decoder inputs y_pred sequence_length input_length else decoded log_prob ctc.ctc_beam_search_decoder inputs y_pred sequence_length input_length beam_width beam_width top_paths top_paths decoded_dense [tf.sparse_to_dense st.indices st.shape st.values default_value -1 for st in decoded]return decoded_dense log_prob
def keyring_auth_list **kwargs return ceph_cfg.keyring_auth_list **kwargs
def chworkphone name workphone return _update_gecos name 'workphone' workphone
def instance_system_metadata_update context instance_uuid metadata delete IMPL.instance_system_metadata_update context instance_uuid metadata delete
def dir_list load if 'env' in load salt.utils.warn_until 'Oxygen' "Parameter'env'hasbeendetectedintheargumentlist.Thisparameterisnolongerusedandhasbeenreplacedby'saltenv'asofSalt2016.11.0.ThiswarningwillberemovedinSaltOxygen." load.pop 'env' ret []if 'saltenv' not in load return retsaltenv load['saltenv']metadata _init if not metadata or saltenv not in metadata return retfor dirs in six.itervalues _find_dirs metadata[saltenv] dirs _trim_env_off_path dirs saltenv trim_slash True ret + [_f for _f in dirs if _f]return ret
def active extended False ret {}if __grains__['os'] 'FreeBSD' _active_mounts_freebsd ret elif __grains__['kernel'] 'SunOS' _active_mounts_solaris ret elif __grains__['os'] 'OpenBSD' _active_mounts_openbsd ret elif __grains__['os'] in ['MacOS' 'Darwin'] _active_mounts_darwin ret elif extended try _active_mountinfo ret except CommandExecutionError _active_mounts ret else _active_mounts ret return ret
def safe_hasattr obj attr try getattr obj attr return Trueexcept return False
def _ConvertBuiltinsToIncludes included_from app_include state runtime includes_list []if app_include.builtins builtins_list appinfo.BuiltinHandler.ListToTuples app_include.builtins for builtin_name on_or_off in builtins_list if not on_or_off continueyaml_path builtins.get_yaml_path builtin_name runtime if on_or_off 'on' includes_list.append yaml_path elif on_or_off 'off' if yaml_path in state.includes logging.warning '%salreadyincludedby%sbutlaterdisabledby%s' yaml_path state.includes[yaml_path] included_from state.excludes[yaml_path] included_fromelse logging.error 'InvalidstateforAppIncludeobjectloadedfrom%s;builtinsdirective"%s %s"ignored.' included_from builtin_name on_or_off return includes_list
@blueprint.route '/<job_id>.json' methods ['GET'] @blueprint.route '/<job_id>' methods ['GET'] def show job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' related_jobs scheduler.get_related_jobs job if request_wants_json return flask.jsonify job.json_dict True elif isinstance job model_images.ImageClassificationModelJob return model_images.classification.views.show job related_jobs related_jobs elif isinstance job model_images.GenericImageModelJob return model_images.generic.views.show job related_jobs related_jobs else raise werkzeug.exceptions.BadRequest 'Invalidjobtype'
@must_have_addon SHORT_NAME 'node' @must_be_addon_authorizer SHORT_NAME def googledrive_folder_list node_addon **kwargs path request.args.get 'path' '' folder_id request.args.get 'folder_id' 'root' return node_addon.get_folders folder_path path folder_id folder_id
def create_response status_code 200 headers None response requests.Response response.status_code status_codeif headers response.headers headersreturn response
def cast x typ return Cast typ x
def delete_container reactor control_service container def container_removed expected '\nCheckwhetheracontainerhasbeenremoved deletedandstopped .\n\n paramContainerStateexpected Acontainerstatetomatchagainstthe\nresultsof``list_containers_state``.\n returnDeferred[Optional[ContainerState]] ``None``ifthe\n``expected``containerisfound or``expected``ifitisnot\nfound.\n'd control_service.list_containers_state def container_matches inspecting expected return expected.name inspecting.name and expected.node_uuid inspecting.node_uuid and inspecting.running def no_running_match existing_state for state in existing_state if container_matches state expected return Nonereturn expectedd.addCallback no_running_match return dd control_service.delete_container container.name def loop_until_container_removed _ignore return loop_until reactor partial container_removed container d.addCallback loop_until_container_removed return d
def _unabc cls msg "{}isn'timplemented" def make_dummy_method ab_name 'Afunctiontomakethedummymethod tocloseoverab_name.'def dummy_method self *args **kwargs 'Themethodprovidedforallmissingabstractmethods.'raise NotImplementedError msg.format ab_name return dummy_methodfor ab_name in cls.__abstractmethods__ setattr cls ab_name make_dummy_method ab_name cls.__abstractmethods__ return cls
def dataEncrypt data password keyLength 32 hashIterations 10000 from .py3AES import encryptDatafrom .py3PBKDF2 import hashPasswordTuple digestname iterations salt hash hashPasswordTuple password iterations hashIterations key hash[ keyLength]try cipher encryptData key data except ValueError return '' False return CryptoMarker.encode + Delimiter.encode .join [digestname.encode str iterations .encode base64.b64encode salt base64.b64encode cipher ] True
def _resolve_document request docid permission 'base.change_resourcebase' msg _PERMISSION_MSG_GENERIC **kwargs return resolve_object request Document {'pk' docid} permission permission permission_msg msg **kwargs
def CheckSection CFG sec try CFG[sec]return Trueexcept CFG[sec] {}return False
def multipath_list cmd 'multipath-l'return __salt__['cmd.run'] cmd .splitlines
def write fd data return WriteEvent fd data
def custom_model *args **kwargs fit_deriv kwargs.get u'fit_deriv' None if len args 1 and six.callable args[0] return _custom_model_wrapper args[0] fit_deriv fit_deriv elif not args return functools.partial _custom_model_wrapper fit_deriv fit_deriv else raise TypeError u'{0}takesatmostonepositionalargument thecallable/functiontobeturnedintoamodel.Whenusedasadecoratoritshouldbepassedkeywordargumentsonly ifany .'.format __name__
def _group tlist cls match valid_prev lambda t True valid_next lambda t True post None extend True recurse True tidx_offset 0 pidx prev_ None None for idx token in enumerate list tlist tidx idx - tidx_offset if token.is_whitespace continueif recurse and token.is_group and not isinstance token cls _group token cls match valid_prev valid_next post extend if match token nidx next_ tlist.token_next tidx if valid_prev prev_ and valid_next next_ from_idx to_idx post tlist pidx tidx nidx grp tlist.group_tokens cls from_idx to_idx extend extend tidx_offset + to_idx - from_idx pidx prev_ from_idx grp continue pidx prev_ tidx token
def shining_panda registry xml_parent data shining_panda_plugin XML.SubElement xml_parent 'jenkins.plugins.shiningpanda.publishers.CoveragePublisher' if 'html-reports-directory' in data XML.SubElement shining_panda_plugin 'htmlDir' .text str data['html-reports-directory']
def p_expr_variable p p[0] 'VAR' p[1]
def do_round value precision 0 method 'common' if not method in 'common' 'ceil' 'floor' raise FilterArgumentError 'methodmustbecommon ceilorfloor' if precision < 0 raise FilterArgumentError 'precisionmustbeapostiveintegerorzero.' if method 'common' return round value precision func getattr math method if precision return func value * 10 * precision / 10 * precision else return func value
def rm_id isid new new def ident_remove expr 'Removeidentities'ids list map isid expr.args if sum ids 0 return exprelif sum ids ! len ids return new expr.__class__ *[arg for arg x in zip expr.args ids if not x ] else return new expr.__class__ expr.args[0] return ident_remove
def cartesian nodes order 'C' nodes [numpy.array e for e in nodes]shapes [e.shape[0] for e in nodes]dtype nodes[0].dtypen len nodes l numpy.prod shapes out numpy.zeros l n dtype dtype if order 'C' repetitions numpy.cumprod [1] + shapes[ -1 ] else shapes.reverse sh [1] + shapes[ -1 ] repetitions numpy.cumprod sh repetitions repetitions.tolist repetitions.reverse for i in range n _repeat_1d nodes[i] repetitions[i] out[ i] return out
def smartsplit code strings []pos 0while pos < len code if code[pos] '"' word ''pos + 1while pos < len code if code[pos] '"' breakif code[pos] '\\' word + '\\'pos + 1word + code[pos]pos + 1strings.append '"%s"' % word pos + 1return strings
def gidFromString gidString try return int gidString except ValueError if grp is None raisereturn grp.getgrnam gidString [2]
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def command from fabtools.require.deb import package as require_deb_packagefrom fabtools.require.rpm import package as require_rpm_packagefrom fabtools.require.portage import package as require_portage_packagefrom fabtools.system import distrib_familyres run 'bzr--version' quiet True if res.failed family distrib_family if family 'debian' require_deb_package 'bzr' elif family 'gentoo' require_portage_package 'bzr' elif family 'redhat' require_rpm_package 'bzr' else raise UnsupportedFamily supported ['debian' 'redhat' 'gentoo']
def parse_openid_response request current_url request.build_absolute_uri consumer make_consumer request return consumer.complete dict request.REQUEST.items current_url
def _find_longest_prefix_match tree bin_X hash_size left_masks right_masks hi np.empty_like bin_X dtype np.intp hi.fill hash_size lo np.zeros_like bin_X dtype np.intp res np.empty_like bin_X dtype np.intp left_idx right_idx _find_matching_indices tree bin_X left_masks[hi] right_masks[hi] found right_idx > left_idx res[found] lo[found] hash_sizer np.arange bin_X.shape[0] kept r[ lo < hi ]while kept.shape[0] mid lo.take kept + hi.take kept // 2 left_idx right_idx _find_matching_indices tree bin_X.take kept left_masks[mid] right_masks[mid] found right_idx > left_idx mid_found mid[found]lo[kept[found]] mid_found + 1 res[kept[found]] mid_foundhi[kept[ ~ found ]] mid[ ~ found ]kept r[ lo < hi ]return res
def get_initial_contact request initial {}if request.user.is_authenticated initial[u'name'] request.user.first_nameinitial[u'email'] request.user.emailreturn initial
def get_notifications_for_modules config notification_count return get_notifications_for u'for_module' config notification_count
def ExpectingFunctionArgs clean_lines linenum line clean_lines.elided[linenum]return Match '^\\s*MOCK_ CONST_ ?METHOD\\d+ _T ?\\ ' line or linenum > 2 and Match '^\\s*MOCK_ ? CONST_ ?METHOD\\d+ ? _T ?\\ ? \\S+ ?\\s*$' clean_lines.elided[ linenum - 1 ] or Match '^\\s*MOCK_ ? CONST_ ?METHOD\\d+ ? _T ?\\ \\s*$' clean_lines.elided[ linenum - 2 ] or Search '\\bstd m?function\\s*\\<\\s*$' clean_lines.elided[ linenum - 1 ]
def _as_floats im1 im2 float_type np.result_type im1.dtype im2.dtype np.float32 if im1.dtype ! float_type im1 im1.astype float_type if im2.dtype ! float_type im2 im2.astype float_type return im1 im2
def worker_activated name workers None profile 'default' if workers is None workers []return _bulk_state 'modjk.bulk_activate' name workers profile
def task_enable_docker_plugin distribution if is_systemd_distribution distribution return sequence [run_from_args ['systemctl' 'enable' 'flocker-docker-plugin'] run_from_args ['systemctl' START 'flocker-docker-plugin'] run_from_args ['systemctl' START 'docker'] ] elif is_ubuntu distribution return sequence [run_from_args ['service' 'flocker-docker-plugin' 'restart'] run_from_args ['service' 'docker' 'restart'] ] else raise DistributionNotSupported distribution distribution
def is_ssh_url url if '@' in url and ' //' not in url return Truefor scheme in 'ssh //' 'git+ssh //' 'ssh+git //' if url.startswith scheme return Truereturn False
def compile_uri_template template if not isinstance template six.string_types raise TypeError 'uri_templateisnotastring' if not template.startswith '/' raise ValueError "uri_templatemuststartwith'/'" if '//' in template raise ValueError "uri_templatemaynotcontain'//'" if template ! '/' and template.endswith '/' template template[ -1 ]expression_pattern '{ [a-zA-Z]\\w* }'fields set re.findall expression_pattern template escaped re.sub '[\\.\\ \\ \\[\\]\\?\\*\\+\\^\\|]' '\\\\\\g<0>' template pattern re.sub expression_pattern ' ?P<\\1>[^/]+ ' escaped pattern '\\A' + pattern + '\\Z' return fields re.compile pattern re.IGNORECASE
def transform_ipynb_uri uri uri_rewrite_list for reg rewrite in uri_rewrite_list matches re.match reg uri if matches return rewrite.format *matches.groups if '?' in uri uri query uri.split '?' 1 uri '%s/%s' % uri quote '?' + query return uri
def _check_numpy_unicode_bug labels if np_version[ 3] < 1 7 0 and labels.dtype.kind 'U' raise RuntimeError 'NumPy<1.7.0doesnotimplementsearchsortedonunicodedatacorrectly.PleaseupgradeNumPytouseLabelEncoderwithunicodeinputs.'
@_docker_clientdef info return _client_wrapper 'info'
@pytest.mark.parametrize 'parallel' [True False] def test_delimiter parallel read_basic text '\nCOL1COL2COL3\n1A-1\n2B-2\n'expected Table [[1 2] ['A' 'B'] [ -1 -2 ]] names 'COL1' 'COL2' 'COL3' for sep in ' DCTB #;' table read_basic text.replace '' sep delimiter sep parallel parallel assert_table_equal table expected
def coord_distance lat1 lon1 lat2 lon2 lon1 lat1 lon2 lat2 map math.radians [lon1 lat1 lon2 lat2] dlon lon2 - lon1 dlat lat2 - lat1 a math.sin dlat / 2 ** 2 + math.cos lat1 * math.cos lat2 * math.sin dlon / 2 ** 2 c 2 * math.asin math.sqrt a km 6367 * c return km
def get_perms_for_model cls if isinstance cls basestring app_label model_name cls.split u'.' model apps.get_model app_label model_name else model clsctype get_content_type model return Permission.objects.filter content_type ctype
def DatastoreTypeToTransforms property_type import_transform export_transform TYPE_TO_TRANSFORM_MAP.get property_type None None transform []if import_transform transform.append 'import_transform %s\n' % import_transform if export_transform transform.append 'export_transform %s\n' % export_transform return ''.join transform
def colorize image hue saturation 1 hsv color.rgb2hsv image hsv[ 1] saturationhsv[ 0] huereturn color.hsv2rgb hsv
def user_can_delete_review request review is_editor acl.check_reviewer request is_author review.addon.has_author request.user return review.user_id request.user.id or not is_author and is_editor or acl.action_allowed request 'Users' 'Edit' or acl.action_allowed request 'Apps' 'ModerateReview'
def get_num_workers if CONF.workers is None return processutils.get_worker_count return CONF.workers
def _getTerminalCharset try charset locale.getpreferredencoding if charset return charsetexcept locale.Error AttributeError passtry charset locale.nl_langinfo locale.CODESET if charset return charsetexcept locale.Error AttributeError passif hasattr sys.stdout 'encoding' and sys.stdout.encoding return sys.stdout.encodingreturn 'ASCII'
def custom_analyze_title4kwd title yearNote outline title title.strip if not title return {}if yearNote yearNote '%s ' % yearNote.split '' [0] title title + '' + yearNote retDict analyze_title title if outline retDict['plotoutline'] outlinereturn retDict
def barrier *args **kargs raise _stub_error
def example2_build_horizontal_exit x y **kwargs if kwargs['iteration'] 0 returnwest_room kwargs['room_dict'][ x - 1 y ]east_room kwargs['room_dict'][ x + 1 y ]west create_object exits.Exit key 'east' aliases ['e'] location west_room destination east_room east create_object exits.Exit key 'west' aliases ['w'] location east_room destination west_room kwargs['caller'].msg 'Connected ' + west_room.key + '&' + east_room.key
def _fib num if num < 2 return numreturn _fib num - 1 + _fib num - 2
def removeXMLFile xmlFilePath if archive.getEndsWithList xmlFilePath ['_interpret.xml'] os.remove xmlFilePath print 'removeGeneratedFilesdeleted' + xmlFilePath
def get_uuid return str time.time
def soap_fault message None actor None code None detail None _string _actor _code _detail Noneif message _string soapenv.Fault_faultstring text message if actor _actor soapenv.Fault_faultactor text actor if code _code soapenv.Fault_faultcode text code if detail _detail soapenv.Fault_detail text detail fault soapenv.Fault faultcode _code faultstring _string faultactor _actor detail _detail return '%s' % fault
def _get_nics vm_ nics []if 'public_lan' in vm_ firewall_rules []lan_id set_public_lan int vm_['public_lan'] if 'public_firewall_rules' in vm_ firewall_rules _get_firewall_rules vm_['public_firewall_rules'] nics.append NIC lan lan_id name 'public' firewall_rules firewall_rules if 'private_lan' in vm_ firewall_rules []if 'private_firewall_rules' in vm_ firewall_rules _get_firewall_rules vm_['private_firewall_rules'] nic NIC lan int vm_['private_lan'] name 'private' firewall_rules firewall_rules if 'nat' in vm_ nic.nat vm_['nat']nics.append nic return nics
def _image_member_update context memb_ref values session None _drop_protected_attrs models.ImageMember values values['deleted'] Falsevalues.setdefault 'can_share' False memb_ref.update values memb_ref.save session session return memb_ref
@_api_version 1.21 @_client_version '1.5.0' def networks names None ids None response _client_wrapper 'networks' names names ids ids _clear_context return response
def getFlattenedNestedRings nestedRings flattenedNestedRings []for nestedRing in nestedRings nestedRing.addFlattenedNestedRings flattenedNestedRings return flattenedNestedRings
def write_metadata_pil file metadata from PIL import Image PngImagePluginim Image.open file meta PngImagePlugin.PngInfo for k v in metadata.items meta.add_text k v 0 im.save file 'PNG' pnginfo meta return True
def remove_repeating substr s index s.find substr if index > 0 return u''.join [s[ index + len substr ] s[ index + len substr ].replace substr u'' ] return s
def album_field_getters funcs {}for plugin in find_plugins if plugin.album_template_fields funcs.update plugin.album_template_fields return funcs
def libvlc_media_list_media p_ml f _Cfunctions.get 'libvlc_media_list_media' None or _Cfunction 'libvlc_media_list_media' 1 class_result Media ctypes.c_void_p MediaList return f p_ml
def find_guests names path None ret {}names names.split ' ' for data in _list_iter path path host stat next six.iteritems data for state in stat for name in stat[state] if name in names if host in ret ret[host].append name else ret[host] [name]return ret
def get_all_processes_pids h CreateToolhelp32Snapshot parents {}pe Process32First h while pe if pe.th32ParentProcessID parents[pe.th32ProcessID] pe.th32ParentProcessIDpe Process32Next h pe return parents
def service_get_all_by_binary context binary include_disabled False return IMPL.service_get_all_by_binary context binary include_disabled include_disabled
def test_pytables x np.ones 2 3 y np.ones 2 ds DenseDesignMatrixPyTables X x y y it ds.iterator mode 'sequential' batch_size 1 it.next
def _normalize_index df index if not isinstance df DataFrame return indexelif isinstance index list return [_normalize_index df col for col in index]elif isinstance index Series and index.name in df.columns and index._name df[index.name]._name return index.nameelif isinstance index DataFrame and set index.columns .issubset df.columns and index._name df[index.columns]._name return list index.columns else return index
def prefix_unit unit prefixes from sympy.physics.unitsystems.units import Unitprefixed_units []for prefix in prefixes prefixed_units.append Unit unit abbrev unit.abbrev prefix prefixes[prefix] return prefixed_units
def handle_405 environ start_response _methods util.wsgi_path_item environ '_methods' headers {}if _methods headers['allow'] str _methods raise webob.exc.HTTPMethodNotAllowed _ 'Themethodspecifiedisnotallowedforthisresource.' headers headers json_formatter util.json_error_formatter
def _normalize_server_settings **settings ret dict settings salt.utils.clean_kwargs **settings for setting in settings if isinstance settings[setting] dict _LOG.debug 'Fixingvalue %s' settings[setting] value_from_key next six.iterkeys settings[setting] ret[setting] '{{{0}}}'.format value_from_key else ret[setting] settings[setting]return ret
def vech A length A.shape[1]vechvec []for i in range length b iwhile b < length vechvec.append A[ b i ] b b + 1 vechvec np.asarray vechvec return vechvec
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
@register.inclusion_tag 'zinnia/tags/dummy.html' takes_context True def get_similar_entries context number 5 template 'zinnia/tags/entries_similar.html' entry context.get 'entry' if not entry return {'template' template 'entries' []}vectors EntryPublishedVectorBuilder entries vectors.get_related entry number return {'template' template 'entries' entries}
def get_about_info vim return vim.service_content.about
def handle_extends tail line_index if tail return 'extends' [p.strip for p in tail.split ' ' ] else return 'error' "'extends'withoutfiletypes" line_index
@handle_response_formatdef user_denied request message '' response_format 'html' response render_to_response 'core/user_denied' {'message' message} context_instance RequestContext request response_format response_format return response
def device_array_like ary stream 0 return device_array shape ary.shape dtype ary.dtype strides ary.strides stream stream
def codestr2rst codestr code_directive '..code-block python\n\n'indented_block ' DCTB ' + codestr.replace '\n' '\n DCTB ' return code_directive + indented_block
def toggle_images event if event.key ! 't' returnb1 im1.get_visible b2 im2.get_visible im1.set_visible not b1 im2.set_visible not b2 plt.draw
def check_partial sig args kwargs num_pos_only func keyword_exclude sigspec sigif len args < num_pos_only pad None * num_pos_only - len args args args + pad if keyword_exclude kwargs dict kwargs for item in keyword_exclude kwargs.pop item None return is_partial_args func args kwargs sigspec
def getSplitLineBeforeBracketSemicolon line bracketSemicolonIndex min line.find ';' line.find ' ' if bracketSemicolonIndex < 0 return line.split return line[ bracketSemicolonIndex].split
def _parse_number stream rv ''while stream.peek and stream.peek in string.digits rv + next stream return int rv
def make_action app_factory hostname 'localhost' port 5000 threaded False processes 1 stream None sort_by 'time' 'calls' restrictions def action hostname 'h' hostname port 'p' port threaded threaded processes processes 'Startanewdevelopmentserver.'from werkzeug.serving import run_simpleapp ProfilerMiddleware app_factory stream sort_by restrictions run_simple hostname port app False None threaded processes return action
def broken_send *args **kwargs raise SMTPException 'Failuremockedbylettuce'
def list_objects service_instance vim_object properties None if properties is None properties ['name']items []item_list get_mors_with_properties service_instance vim_object properties for item in item_list items.append item['name'] return items
def _get_entities_custom_fields entities custom_fields set for entity in entities fields dir entity for field in fields if not field.startswith '_' custom_fields.add field for skip_field in ['PartitionKey' 'RowKey' 'Timestamp' 'etag'] custom_fields.discard skip_field return custom_fields
def has_controller_permissions doc ptype user None if not user user frappe.session.usermethods frappe.get_hooks u'has_permission' .get doc.doctype [] if not methods return Nonefor method in methods controller_permission frappe.call frappe.get_attr method doc doc ptype ptype user user if controller_permission is not None return controller_permissionreturn None
def format_te_prefs prefs_dict sample_coloring prefs_dict['sample_coloring']lines []for k in sample_coloring for t in sample_coloring[k]['colors'] if isinstance t tuple lines.append ''.join [ str i + ' ' for i in t[1]] + '\n' if isinstance t str lines.append t + ' ' + ''.join [ str i + ' ' for i in data_color_hsv[sample_coloring[k]['colors'][t]]] + '\n' lines.append '>default' + k + ' ' + k + '\n' return lines
def steps steps_class if hasattr steps_class '__init__' _init_ getattr steps_class '__init__' def init self *args **kwargs _init_ self *args **kwargs STEP_REGISTRY.load_steps self else def init self *args **kwargs STEP_REGISTRY.load_steps self setattr steps_class '__init__' init return steps_class
@logic.validate logic.schema.default_autocomplete_schema def format_autocomplete context data_dict model context['model']session context['session']_check_access 'format_autocomplete' context data_dict q data_dict['q']limit data_dict.get 'limit' 5 like_q u'%' + q + u'%' query session.query model.Resource.format _func.count model.Resource.format .label 'total' .filter _and_ model.Resource.state 'active' .filter model.Resource.format.ilike like_q .group_by model.Resource.format .order_by 'totalDESC' .limit limit return [resource.format.lower for resource in query]
def filter_errors errors select None ignore None **params select select or [] ignore ignore or [] for e in errors for s in select if e.number.startswith s yield e breakelse for s in ignore if e.number.startswith s breakelse yield e
def test_urljoin base 'https //www.evernote.com/'assert urljoin base base assert urljoin base '/foo/bar' 'baz/blah' base + 'foo/bar/baz/blah' assert urljoin base '/foo/' '/bar/' '/baz/' base + 'foo/bar/baz/' assert urljoin base '/foo//' '//bar/' base + 'foo/bar/' assert urljoin base '/foo//' '//bar/?q a' base + 'foo/bar/?q a' assert urljoin base 'foo//' '//bar/?q a' base + 'foo/bar/?q a' assert urljoin base 'foo//////' base + 'foo/' assert urljoin base 'foo' 'bar/baz' 'blah' base + 'foo/bar/baz/blah' assert urljoin base 'foo/' 'bar' 'baz/' base + 'foo/bar/baz/' assert urljoin '' '' '/////foo' '/foo'
def errFail *cmd **kwargs out err ret errRun *cmd **kwargs if ret raise Exception 'errFail %sfailedwithreturncode%s %s' % cmd ret err return out err ret
def attach_lb kwargs None call None if call ! 'function' raise SaltCloudSystemExit 'Theattach_lbfunctionmustbecalledwith-for--function.' if not kwargs or 'name' not in kwargs log.error 'Aload-balancernamemustbespecified.' return Falseif 'member' not in kwargs log.error 'Anodenamenamemustbespecified.' return Falseconn get_conn node conn.ex_get_node kwargs['member'] lb_conn get_lb_conn conn lb lb_conn.get_balancer kwargs['name'] __utils__['cloud.fire_event'] 'event' 'attachload_balancer' 'salt/cloud/loadbalancer/attaching' args kwargs sock_dir __opts__['sock_dir'] transport __opts__['transport'] result lb_conn.balancer_attach_compute_node lb node __utils__['cloud.fire_event'] 'event' 'attachedload_balancer' 'salt/cloud/loadbalancer/attached' args kwargs sock_dir __opts__['sock_dir'] transport __opts__['transport'] return _expand_item result
def last_access_time path return os.stat path [stat.ST_ATIME]
def hasattr_recursive item attr_key if '.' in attr_key attr_key last_key attr_key.rsplit '.' 1 item getattr_recursive item attr_key None if item is None return Falseattr_key last_keytry if isinstance item dict return item.__contains__ attr_key else return hasattr item attr_key except KeyError AttributeError return Falsereturn True
def no_log_warn logical_line if logical_line.startswith 'LOG.warn ' yield 0 'Heat301UseLOG.warning ratherthanLOG.warn '
def fix_IE_for_vary request response useragent request.META.get 'HTTP_USER_AGENT' '' .upper if 'MSIE' not in useragent and 'CHROMEFRAME' not in useragent return responsesafe_mime_types 'text/html' 'text/plain' 'text/sgml' if response['Content-Type'].split ';' [0] not in safe_mime_types try del response['Vary']except KeyError passreturn response
def _descendants node try treepos node.treepositions except AttributeError return []return [node[x] for x in treepos[1 ]]
def pairwise iterable it iter iterable try first next it except StopIteration returnfor second in it yield first second first second
def mccp_compress protocol data if hasattr protocol 'zlib' return protocol.zlib.compress data + protocol.zlib.flush FLUSH return data
def lowercase_keys_recursively subject lowercased dict for key val in subject.iteritems if isinstance val dict val lowercase_keys_recursively val lowercased[key.lower ] valreturn lowercased
def color_to_hex color if color is None or colorConverter.to_rgba color [3] 0 return 'none'else rgb colorConverter.to_rgb color return '#{0 02X}{1 02X}{2 02X}'.format * int 255 * c for c in rgb
def restricted_content f @functools.wraps f def wrapper request *args **kw from olympia.access import aclif acl.action_allowed request '*' '*' or not acl.action_allowed request 'Restricted' 'UGC' return f request *args **kw else raise PermissionDeniedreturn wrapper
def make_list value return list value
def compute_md5_v1 get_deps_dict import hashlibreturn _compute_hash_v1 get_deps_dict hashlib.md5
def silhouette_score X labels metric 'euclidean' sample_size None random_state None **kwds if sample_size is not None X labels check_X_y X labels accept_sparse ['csc' 'csr'] random_state check_random_state random_state indices random_state.permutation X.shape[0] [ sample_size]if metric 'precomputed' X labels X[indices].T[indices].T labels[indices] else X labels X[indices] labels[indices] return np.mean silhouette_samples X labels metric metric **kwds
def int_to_bin_list value width None m width or 6 return value & 1 << np.arange m > 0 .astype int
def oldQuietRun *cmd if len cmd 1 cmd cmd[0]if isinstance cmd str cmd cmd.split '' popen Popen cmd stdout PIPE stderr STDOUT out ''readable poll readable.register popen.stdout while True while readable.poll data popen.stdout.read 1024 if len data 0 breakout + datapopen.poll if popen.returncode is not None breakreturn out
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def send_global_velocity velocity_x velocity_y velocity_z duration msg vehicle.message_factory.set_position_target_global_int_encode 0 0 0 mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT_INT 4039 0 0 0 velocity_x velocity_y velocity_z 0 0 0 0 0 for x in range 0 duration vehicle.send_mavlink msg time.sleep 1
def test_pip_show_is_short script result script.pip 'show' 'pip' lines result.stdout.splitlines assert len lines < 10
def norm_weight nin nout None scale 0.01 ortho True if nout is None nout ninif nout nin and ortho W ortho_weight nin else W scale * numpy.random.randn nin nout return W.astype 'float32'
def assert_choicetext_values course problem_type choices expected_values all_choices ['choiceinput_0bc' 'choiceinput_1bc']all_inputs ['choiceinput_0_numtolerance_input_0' 'choiceinput_1_numtolerance_input_0']for this_choice in all_choices element world.css_find inputfield course problem_type choice this_choice if this_choice in choices assert element.checkedelse assert not element.checked for name expected in zip all_inputs expected_values element world.css_find inputfield course problem_type name assert element.value.strip expected
def numbered_symbols prefix 'x' cls None start 0 exclude [] *args **assumptions exclude set exclude or [] if cls is None from sympy import Symbolcls Symbolwhile True name '%s%s' % prefix start s cls name *args **assumptions if s not in exclude yield s start + 1
def lbp_cmp f g if sig_cmp Sign f Sign g Polyn f .ring.order -1 return -1 if Sign f Sign g if Num f > Num g return -1 return 1
def _list_availability_zones vm_ None ret {}params {'Action' 'DescribeAvailabilityZones' 'Filter.0.Name' 'region-name' 'Filter.0.Value.0' get_location vm_ }result aws.query params location get_location vm_ provider get_provider opts __opts__ sigver '4' for zone in result ret[zone['zoneName']] zone['zoneState']return ret
def _get_dns_services subnet services []if not subnet.get 'dns' return servicesreturn [{'type' 'dns' 'address' ip.get 'address' } for ip in subnet['dns']]
def set_default_credentials aws_access_key_id aws_secret_access_key DEFAULT_CREDENTIALS.update {'aws_access_key_id' aws_access_key_id 'aws_secret_access_key' aws_secret_access_key}
def configure_remote_put remote_url app_id extra_headers None if not app_id or not remote_url raise ConfigurationError 'app_idandremote_urlrequired' original_datastore_stub apiproxy_stub_map.apiproxy.GetStub 'datastore_v3' if isinstance original_datastore_stub DatastorePutStub logging.info 'Stubisalreadyconfigured.Hopefullyinamatchingfashion.' returndatastore_stub DatastorePutStub remote_url app_id extra_headers original_datastore_stub apiproxy_stub_map.apiproxy.RegisterStub 'datastore_v3' datastore_stub
def sign_in username api_key **kwargs kwargs.update username username api_key api_key for key in kwargs if key not in CREDENTIALS_KEYS and key not in CONFIG_KEYS raise exceptions.PlotlyError '{}isnotavalidconfigorcredentialskey'.format key for key in CREDENTIALS_KEYS if key in kwargs if not isinstance kwargs[key] CREDENTIALS_KEYS[key] raise exceptions.PlotlyError "{}mustbeoftype'{}'".format key CREDENTIALS_KEYS[key] _session['credentials'][key] kwargs[key]for key in CONFIG_KEYS if key in kwargs if not isinstance kwargs[key] CONFIG_KEYS[key] raise exceptions.PlotlyError "{}mustbeoftype'{}'".format key CONFIG_KEYS[key] _session['config'][key] kwargs.get key for key in PLOT_OPTIONS if key in kwargs if not isinstance kwargs[key] CONFIG_KEYS[key] raise exceptions.PlotlyError "{}mustbeoftype'{}'".format key CONFIG_KEYS[key] _session['plot_options'][key] kwargs.get key
def strip_newsgroup_footer text lines text.strip .split '\n' for line_num in range len lines - 1 -1 -1 line lines[line_num]if line.strip .strip '-' '' breakif line_num > 0 return '\n'.join lines[ line_num] else return text
def get_most_recent_exercises user exercises_by_user ExerciseLog.objects.filter user user .order_by '-latest_activity_timestamp' .values_list 'exercise_id' flat True return exercises_by_user
def send_flag_exploration_email exploration_title exploration_id reporter_id report_text email_subject 'Explorationflaggedbyuser "%s"' % exploration_title email_body_template 'HelloModerator <br>%shasflaggedexploration"%s"onthefollowinggrounds <br>%s.<br>Youcanmodifytheexplorationbyclicking<ahref "https //www.oppia.org/create/%s">here</a>.<br><br>Thanks!<br>-TheOppiaTeam<br><br>%s'if not feconf.CAN_SEND_EMAILS log_new_error 'Thisappcannotsendemailstousers.' returnemail_body email_body_template % user_services.get_user_settings reporter_id .username exploration_title report_text exploration_id EMAIL_FOOTER.value recipient_list config_domain.MODERATOR_IDS.valuefor recipient_id in recipient_list _send_email recipient_id feconf.SYSTEM_COMMITTER_ID feconf.EMAIL_INTENT_REPORT_BAD_CONTENT email_subject email_body feconf.NOREPLY_EMAIL_ADDRESS
def all_methods obj temp []for name in dir obj func getattr obj name if callable func temp.append name return temp
def cdataescape s if isinstance s unicode s s.encode 'utf-8' parts s.split ']]>' return ']]]]><![CDATA[>'.join parts
def get_build_exe_options opts freeze.get_build_exe_options skip_html True opts['includes'] + pytest.freeze_includes opts['includes'] + ['unittest.mock' 'PyQt5.QtTest' 'hypothesis' 'bs4' 'httpbin' 'jinja2.ext' 'cheroot' 'pstats' 'queue']httpbin_dir os.path.dirname httpbin.__file__ opts['include_files'] + [ 'tests/end2end/data' 'end2end/data' os.path.join httpbin_dir 'templates' 'end2end/templates' ]opts['packages'].append 'qutebrowser' return opts
def replaceAcronyms text def parseDirections text words {'N' 'north' 'S' 'south' 'E' 'east' 'W' 'west'}output [words[w] for w in list text ]return ''.join output acronyms re.findall '\\b [NESW]+ \\b' text for w in acronyms text text.replace w parseDirections w text re.sub ' \\b\\d+ F \\b ' '\\g<1>Fahrenheit\\g<2>' text text re.sub ' \\b mph \\b ' '\\g<1>milesperhour\\g<2>' text text re.sub ' \\b in\\.' '\\g<1>inches' text return text
def _get_devices params if 'id' not in params raise CommandExecutionError 'ParameterIDisrequired.' return type params['id'] int and [params['id']] or [int dev for dev in params['id'].split ' ' ]
def parse_ldd_output output expr_linux re.compile '\\s ?P<lib>\\S?/\\S+ \\s+\\ ?P<addr>0x.+ \\ ' expr_openbsd re.compile '^\\s+ ?P<addr>[0-9a-f]+ \\s+[0-9a-f]+\\s+\\S+\\s+[01]\\s+[0-9]+\\s+[0-9]+\\s+ ?P<lib>\\S+ $' libs {}for s in output.split '\n' match expr_linux.search s or expr_openbsd.search s if not match continue lib addr match.group 'lib' match.group 'addr' libs[lib] int addr 16 return libs
def attach_server host port cert None key None chain None if sabnzbd.cfg.ipv6_hosting or ' 1' not in host http_server cherrypy._cpserver.Server http_server.bind_addr host port if cert and key http_server.ssl_provider 'builtin'http_server.ssl_certificate certhttp_server.ssl_private_key keyhttp_server.ssl_certificate_chain chainhttp_server.subscribe
def nest_paths paths nested []for path in paths if os.path.sep not in path nested.append path continue directory _ os.path.split path parts directory.split os.path.sep branch nestedfor part in parts part dirname_to_title part branch find_or_create_node branch part branch.append path return nested
def commit_item return s3_rest_controller
def url_add_parameters url params if params fragments list urlparse url value parse_qs fragments[4] value.update params fragments[4] urlencode value url urlunparse fragments return url
def p_varlist p if len p > 2 p[0] p[1]p[0].append p[3] else p[0] [p[1]]
def arg_of_softmax Y_hat assert hasattr Y_hat 'owner' owner Y_hat.ownerassert owner is not None op owner.opif isinstance op Print assert len owner.inputs 1 Y_hat owner.inputsowner Y_hat.ownerop owner.opif not isinstance op T.nnet.Softmax raise ValueError 'ExpectedY_hattobetheoutputofasoftmax butitappearstobetheoutputof' + str op + 'oftype' + str type op z owner.inputsassert z.ndim 2 return z
def find_if predicate seq for x in seq if predicate x return x
def endpoint_list profile None **connection_args kstone auth profile **connection_args ret {}for endpoint in kstone.endpoints.list ret[endpoint.id] dict value getattr endpoint value for value in dir endpoint if not value.startswith '_' and isinstance getattr endpoint value six.text_type dict bool str return ret
@pytest.mark.skipif u'notHAS_SCIPY' def test_subpixel_gauss_1D gauss_1D Gaussian1D 1 0 0.1 values discretize_model gauss_1D -1 2 mode u'integrate' factor 100 assert_allclose values.sum np.sqrt 2 * np.pi * 0.1 atol 1e-05
def strip_entities value return re.sub '& ? \\w+|#\\d+ ;' '' force_unicode value
def fixed_ip_get_by_network_host context network_uuid host return IMPL.fixed_ip_get_by_network_host context network_uuid host
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def _get_heads_file_path config return os.path.join _get_root_versions_dir config HEADS_FILENAME
def markdown_escape text warnings.warn u'reviewboard.reviews.markdown_utils.markdown_escapeisdeprecated.Pleaseusedjblets.markdown.markdown_escape.' DeprecationWarning return djblets_markdown.markdown_escape text
def SetOutputFileName filename None SetOutputFile if filename SetOutputFile open filename 'w' 1
def propagate_attributes old_function new_function if hasattr old_function 'return_type' new_function.func_name old_function.func_namenew_function.return_type old_function.return_typenew_function.arg_types old_function.arg_typesif hasattr old_function 'CustomAttributeBuilders' new_function.CustomAttributeBuilders old_function.CustomAttributeBuildersif hasattr old_function 'CustomAttributeBuilders' new_function.DllImportAttributeDecorator old_function.DllImportAttributeDecorator
@step 'Icreatelogrecordswith' def step_I_create_logrecords_with_table context assert context.table 'REQUIRE context.table'context.table.require_columns ['category' 'level' 'message'] for row in context.table.rows category row['category']if category '__ROOT__' category Nonelevel LogLevel.parse_type row['level'] message row['message']make_log_record category level message
def simple_conv_specs s simple_conv_specs_re re.compile '\\%\\w' return simple_conv_specs_re.findall s
def run_python_script package None module None args [] p_args [] assert module is not None assert isinstance args tuple list and isinstance p_args tuple list path python_script_exists package module run_program sys.executable p_args + [path] + args
def uncouple expr jn None jcoupling_list None a expr.atoms SpinState for state in a expr expr.subs state _uncouple state jn jcoupling_list return expr
def _convert_time date_str time_str for fmt in '%d/%m/%Y' '%d-%b-%Y' '%a %b%d %Y' try date strptime date_str fmt except ValueError passelse breakelse raise RuntimeError 'Illegaldate %s.\nIfthelanguageofthedatedoesnotcorrespondtoyourlocalmachine\'slanguagetrytosetthelocaletothelanguageofthedatestring \nlocale.setlocale locale.LC_ALL "en_US" ' % date_str for fmt in '%H %M %S' '%H %M' try time strptime time_str fmt except ValueError passelse breakelse raise RuntimeError 'Illegaltime %s' % time_str res timegm date.tm_year date.tm_mon date.tm_mday time.tm_hour time.tm_min time.tm_sec date.tm_wday date.tm_yday date.tm_isdst return res
def get_default_extension return rawData.Visualization
def cost_of_flow G flowDict weight 'weight' return sum flowDict[u][v] * d.get weight 0 for u v d in G.edges data True
def parse_rst text default_reference_context thing_being_parsed None link_base '../..' overrides {'doctitle_xform' True 'inital_header_level' 3 'default_reference_context' default_reference_context 'link_base' link_base}if thing_being_parsed thing_being_parsed '<%s>' % thing_being_parsed parts docutils.core.publish_parts text source_path thing_being_parsed destination_path None writer_name 'html' settings_overrides overrides return parts['fragment']
@not_implemented_for 'directed' def enumerate_all_cliques G index {}nbrs {}for u in G index[u] len index nbrs[u] {v for v in G[u] if v not in index }queue deque [u] sorted nbrs[u] key index.__getitem__ for u in G while queue base cnbrs map list queue.popleft yield base for i u in enumerate cnbrs queue.append chain base [u] filter nbrs[u].__contains__ islice cnbrs i + 1 None
def uninstall pkg user None env None cmd ['ghc-pkgunregister']cmd.append '"{0}"'.format pkg result __salt__['cmd.run_all'] ''.join cmd runas user env env if result['retcode'] ! 0 raise CommandExecutionError result['stderr'] return result
def run_in_executor f @wraps f def new_f self *args **kwargs if self.is_shutdown returntry future self.executor.submit f self *args **kwargs future.add_done_callback _future_completed except Exception log.exception 'Failedtosubmittasktoexecutor' return new_f
def get_datapath app dpid assert isinstance dpid numbers.Integral return app.send_request event.GetDatapathRequest dpid dpid
def get_access_path key parts path []for is_attribute specifier in parts if is_attribute path.append '.{}'.format specifier else path.append '[{!r}]'.format specifier return str key + ''.join path
@add_handler 'plainlog' def qute_plainlog url if log.ram_handler is None text 'Logoutputwasdisabled.'else try level urllib.parse.parse_qs url.query ['level'][0]except KeyError level 'vdebug'text log.ram_handler.dump_log html False level level html jinja.render 'pre.html' title 'log' content text return 'text/html' html
def distances_along_curve X X np.diff X axis 0 return vector_lengths X axis 1
def package pkg_name repos None yes None options None if not is_installed pkg_name install pkg_name repos yes options
def format_heading level text underlining [' ' '-' '~'][ level - 1 ] * len text return '%s\n%s\n\n' % text underlining
def brightness x gamma 1 gain 1 is_random False if is_random gamma np.random.uniform 1 - gamma 1 + gamma x exposure.adjust_gamma x gamma gain return x
def find_alternating_4_cycle G for u v in G.edges for w in G.nodes if not G.has_edge u w and u ! w for x in G.neighbors w if not G.has_edge v x and v ! x return [u v w x]return False
def _datetime_to_pb_timestamp when ms_value _microseconds_from_datetime when seconds micros divmod ms_value 10 ** 6 nanos micros * 10 ** 3 return timestamp_pb2.Timestamp seconds seconds nanos nanos
def check_enum enum name None valid None name name or 'enum' res Noneif isinstance enum int if hasattr enum 'name' and enum.name.startswith 'GL_' res enum.name[3 ].lower elif isinstance enum string_types res enum.lower if res is None raise ValueError 'Couldnotdeterminestringrepresenatationforenum%r' % enum elif valid and res not in valid raise ValueError 'Valueof%smustbeoneof%r not%r' % name valid enum return res
def permanent location to location falcon.HTTP_301
def _register_mimetype_handlers **kwargs from reviewboard.attachments.mimetypes import ImageMimetype MarkDownMimetype MimetypeHandler register_mimetype_handler ReStructuredTextMimetype TextMimetyperegister_mimetype_handler ImageMimetype register_mimetype_handler MarkDownMimetype register_mimetype_handler MimetypeHandler register_mimetype_handler ReStructuredTextMimetype register_mimetype_handler TextMimetype
def encryptDES s iv helpers.randomKey 8 key helpers.randomKey 8 desmain DES.new key DES.MODE_CFB iv encrypted desmain.encrypt s return encrypted key iv
def median_absolute_error y_true y_pred y_type y_true y_pred _ _check_reg_targets y_true y_pred 'uniform_average' if y_type 'continuous-multioutput' raise ValueError 'Multioutputnotsupportedinmedian_absolute_error' return np.median np.abs y_pred - y_true
def _special_sparse_dot W H X if sp.issparse X ii jj X.nonzero dot_vals np.multiply W[ii ] H.T[jj ] .sum axis 1 WH sp.coo_matrix dot_vals ii jj shape X.shape return WH.tocsr else return fast_dot W H
def find_free_ports start_port end_port count address 'localhost' ports []i start_portwhile i < end_port and count > 0 if is_port_free i address ports.append i count - 1i + 1return ports
def get_purchase_endpoint return get_processor_config .get 'PURCHASE_ENDPOINT' ''
def validate_category value if value not in settings.NODE_CATEGORY_MAP.keys raise ValidationValueError 'Invalidvalueforcategory.' return True
def randomizeParameterValue value retVal valuevalue re.sub '%[0-9a-fA-F]{2}' '' value for match in re.finditer '[A-Z]+' value retVal retVal.replace match.group randomStr len match.group .upper for match in re.finditer '[a-z]+' value retVal retVal.replace match.group randomStr len match.group .lower for match in re.finditer '[0-9]+' value retVal retVal.replace match.group str randomInt len match.group return retVal
def RegisterPyComCategory regCat _cat_registrar regCat.RegisterCategories [ CATID_PythonCOMServer 1033 'PythonCOMServer' ]
def get_attribute_statistics layer_name field logger.debug 'Derivingaggregatestatisticsforattribute%s' field if not ogc_server_settings.WPS_ENABLED return Nonetry return wps_execute_layer_attribute_statistics layer_name field except Exception logger.exception 'Errorgeneratinglayeraggregatestatistics'
@np.deprecate message 'scipy.special.sph_inisdeprecatedinscipy0.18.0.Usescipy.special.spherical_ininstead.Notethatthenewfunctionhasadifferentsignature.' def sph_in n z if not isscalar n and isscalar z raise ValueError 'argumentsmustbescalars.' if n ! floor n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n < 1 n1 1else n1 nif iscomplex z nm In Inp kn knp specfun.csphik n1 z else nm In Inp specfun.sphi n1 z return In[ n + 1 ] Inp[ n + 1 ]
def enable name **kwargs cmd '/usr/sbin/svcadmenable{0}'.format name return not __salt__['cmd.retcode'] cmd python_shell False
def prop_has_value name prop value extra_args None cibname None return _item_present name name item 'property' item_id '{0} {1}'.format prop value item_type None create 'set' extra_args extra_args cibname cibname
def test_custom_context assert ask Q.integer x is None local_context AssumptionsContext local_context.add Q.integer x assert ask Q.integer x context local_context is True assert ask Q.integer x is None
def norm_weight nin nout None scale 0.01 ortho True if nout is None nout ninif nout nin and ortho W ortho_weight nin else W scale * numpy.random.randn nin nout return W.astype 'float32'
def instance_tag_delete context instance_uuid tag return IMPL.instance_tag_delete context instance_uuid tag
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def sitemap request sitemaps section None maps urls [] [] if section is not None if section not in sitemaps raise Http404 'Nositemapavailableforsection %r' % section maps.append sitemaps[section] else maps sitemaps.values page request.GET.get 'p' 1 current_site get_current_site request for site in maps try if callable site urls.extend site .get_urls page page site current_site else urls.extend site.get_urls page page site current_site except EmptyPage raise Http404 'Page%sempty' % page except PageNotAnInteger raise Http404 "Nopage'%s'" % page xml smart_str loader.render_to_string 'gis/sitemaps/geo_sitemap.xml' {'urlset' urls} return HttpResponse xml mimetype 'application/xml'
def get_doc_permissions doc verbose False user None if not user user frappe.session.userif frappe.is_table doc.doctype return {u'read' 1 u'write' 1}meta frappe.get_meta doc.doctype role_permissions copy.deepcopy get_role_permissions meta user user verbose verbose if not cint meta.is_submittable role_permissions[u'submit'] 0if not cint meta.allow_import role_permissions[u'import'] 0if role_permissions.get u'apply_user_permissions' for ptype in role_permissions if role_permissions[u'apply_user_permissions'].get ptype and not user_has_permission doc verbose verbose user user user_permission_doctypes role_permissions.get u'user_permission_doctypes' {} .get ptype or [] role_permissions[ptype] 0if doc.owner frappe.session.user role_permissions.update role_permissions.if_owner update_share_permissions role_permissions doc user return role_permissions
def updatevmx_path global VMX_PATHVMX_PATH []
def _has_git try subprocess.check_call ['git' '--version'] stdout subprocess.DEVNULL stderr subprocess.DEVNULL except OSError subprocess.CalledProcessError return Falseelse return True
def check_password_hash pwhash password if pwhash.count '$' < 2 return False method salt hashval pwhash.split '$' 2 return safe_str_cmp _hash_internal method salt password hashval
def test_parallel_predict clf1 LogisticRegression random_state 123 clf2 RandomForestClassifier random_state 123 clf3 GaussianNB X np.array [[ -1.1 -1.5 ] [ -1.2 -1.4 ] [ -3.4 -2.2 ] [1.1 1.2]] y np.array [1 1 2 2] eclf1 VotingClassifier estimators [ 'lr' clf1 'rf' clf2 'gnb' clf3 ] voting 'soft' n_jobs 1 .fit X y eclf2 VotingClassifier estimators [ 'lr' clf1 'rf' clf2 'gnb' clf3 ] voting 'soft' n_jobs 2 .fit X y assert_array_equal eclf1.predict X eclf2.predict X assert_array_equal eclf1.predict_proba X eclf2.predict_proba X
def task_status request task_id result AsyncResult task_id state retval result.state result.result response_data {u'id' task_id u'status' state u'result' retval}if state in states.EXCEPTION_STATES traceback result.tracebackresponse_data.update {u'result' safe_repr retval u'exc' get_full_cls_name retval.__class__ u'traceback' traceback} return JsonResponse {u'task' response_data}
def metadata_accept rule '-ptcp-mtcp--dport%s%s-jACCEPT' % CONF.metadata_port _iptables_dest CONF.metadata_host if netaddr.IPAddress CONF.metadata_host .version 4 iptables_manager.ipv4['filter'].add_rule 'INPUT' rule else iptables_manager.ipv6['filter'].add_rule 'INPUT' rule iptables_manager.apply
def setup_daemon_context_fixtures testcase testcase.mock_tracker scaffold.MockTracker setup_streams_fixtures testcase setup_pidfile_fixtures testcase testcase.mock_pidfile_path tempfile.mktemp testcase.mock_pidlockfile scaffold.Mock 'pidlockfile.PIDLockFile' tracker testcase.mock_tracker testcase.mock_pidlockfile.path testcase.mock_pidfile_pathscaffold.mock 'daemon.daemon.is_detach_process_context_required' returns True tracker testcase.mock_tracker scaffold.mock 'daemon.daemon.make_default_signal_map' returns object tracker testcase.mock_tracker scaffold.mock 'os.getuid' returns object tracker testcase.mock_tracker scaffold.mock 'os.getgid' returns object tracker testcase.mock_tracker testcase.daemon_context_args dict stdin testcase.stream_files_by_name['stdin'] stdout testcase.stream_files_by_name['stdout'] stderr testcase.stream_files_by_name['stderr'] testcase.test_instance daemon.DaemonContext **testcase.daemon_context_args
def psi_n n x m omega n x m omega map S [n x m omega] nu m * omega / hbar C nu / pi ** S 1 / 4 * sqrt 1 / 2 ** n * factorial n return C * exp - nu * x ** 2 / 2 * hermite n sqrt nu * x
def reset_url_prefixer global _locals_locals threading.local
def queue_mail to_addr mail send_at user **context new_mail QueuedMail user user to_addr to_addr send_at send_at email_type mail['template'] data context new_mail.save return new_mail
def get_all_user_subscriptions user NotificationSubscription apps.get_model 'osf.NotificationSubscription' for notification_type in constants.NOTIFICATION_TYPES query NotificationSubscription.find Q notification_type 'eq' user.pk for subscription in query yield subscription
def get_pl_from_json pldata try items pldata['items']except KeyError items []results []for item in items snippet item['snippet']results.append dict link item['id'] size item['contentDetails']['itemCount'] title snippet['title'] author snippet['channelTitle'] created snippet['publishedAt'] updated snippet['publishedAt'] description snippet['description'] return results
def run_suite *test_classes loader unittest.TestLoader suite unittest.TestSuite for test_class in test_classes tests loader.loadTestsFromTestCase test_class suite.addTests tests if suite is not None unittest.TextTestRunner verbosity 2 .run suite return
def setIcon filePath icnsPath dirPath os.path.normpath os.path.dirname __file__ toolPath os.path.join dirPath 'seticon.app/Contents/MacOS/seticon' if not os.path.exists toolPath or os.stat toolPath .st_mtime < os.stat dirPath + '/seticon.m' .st_mtime appPath os.path.join dirPath 'seticon.app/Contents/MacOS' if not os.path.exists appPath os.makedirs appPath runCommand 'cc-o%s%s/seticon.m-frameworkCocoa' % shellQuote toolPath shellQuote dirPath runCommand '%s%s%s' % shellQuote os.path.abspath toolPath shellQuote icnsPath shellQuote filePath
def _numa_get_pagesize_constraints flavor image_meta def check_and_return_pages_size request if request 'any' return MEMPAGES_ANYelif request 'large' return MEMPAGES_LARGEelif request 'small' return MEMPAGES_SMALLelse try request int request except ValueError try request strutils.string_to_bytes request return_int True / units.Ki except ValueError request 0if request < 0 raise exception.MemoryPageSizeInvalid pagesize request return request flavor_request image_request _get_flavor_image_meta 'mem_page_size' flavor image_meta if not flavor_request and image_request raise exception.MemoryPageSizeForbidden pagesize image_request against '<empty>' if not flavor_request return Nonepagesize check_and_return_pages_size flavor_request if image_request and pagesize in MEMPAGES_ANY MEMPAGES_LARGE return check_and_return_pages_size image_request elif image_request raise exception.MemoryPageSizeForbidden pagesize image_request against flavor_request return pagesize
def prettydict d keys sorted list d.keys key get_max_denom reverse True result ''for tup in keys children sorted d[tup] key get_max_denom reverse False result + prettytuple tup + '\n' for child in children result + '' + prettytuple child + '\n' return result
def date_sorted_sources *sources sorted_stream heapq.merge * _decorate_source s for s in sources for _ message in sorted_stream yield message
def tree2semi_rel tree from nltk.tree import Treesemi_rels []semi_rel [[] None]for dtr in tree if not isinstance dtr Tree semi_rel[0].append dtr else semi_rel[1] dtrsemi_rels.append semi_rel semi_rel [[] None]return semi_rels
def _get_legen x n_coeff 100 return legendre.legvander x n_coeff - 1
def test_vi_cursor_movements feed partial _feed_cli_with_input editing_mode EditingMode.VI result cli feed u'\x1b\n' assert result.text u'' assert cli.editing_mode EditingMode.VI result cli feed u'hello\x1bhaX\n' assert result.text u'hellXo' result cli feed u'hello\x1bIX\n' assert result.text u'Xhello' result cli feed u'hello\x1bIX\n' assert result.text u'Xhello' result cli feed u'hello\x1b2hiX\n' assert result.text u'heXllo' result cli feed u'hello\x1b2h2liX\n' assert result.text u'hellXo' result cli feed u'hello\x08\x08\n' assert result.text u'hel' result cli feed u'hello\x08\x08\n' assert result.text u'hel' result cli feed u'hello\x1b2hD\n' assert result.text u'he' result cli feed u'hello\x1b2hrX\n' assert result.text u'heXlo'
def test_stratified_dataset_validation_k_fold skip_if_no_sklearn mapping {'dataset_iterator' 'StratifiedDatasetValidationKFold'}test_yaml test_yaml_dataset_iterator % mapping trainer yaml_parse.load test_yaml trainer.main_loop
def bw_scott x kernel None A _select_sigma x n len x return 1.059 * A * n ** -0.2
@memoize for_each_device True def elementwise in_params out_params operation name **kwargs check_cuda_available return cupy.ElementwiseKernel in_params out_params operation name **kwargs
def ce actual predicted return sum [1.0 for x y in zip actual predicted if x ! y ] / len actual
@pick_context_manager_writerdef compute_node_delete context compute_id result model_query context models.ComputeNode .filter_by id compute_id .soft_delete synchronize_session False if not result raise exception.ComputeHostNotFound host compute_id
def _topo_closed events ax lines fill for line in lines ax.lines.remove line[0] ax.collections.remove fill ax.get_figure .canvas.draw
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def im_resize maxwidth path_in path_out None path_out path_out or temp_file_for path_in log.debug u'artresizer ImageMagickresizing{0}to{1}' util.displayable_path path_in util.displayable_path path_out try util.command_output ['convert' util.syspath path_in prefix False '-resize' '{0}x^>'.format maxwidth util.syspath path_out prefix False ] except subprocess.CalledProcessError log.warning u'artresizer IMconvertfailedfor{0}' util.displayable_path path_in return path_inreturn path_out
def get_mpkg_ids mpkg mpkg _quote mpkg package_infos []base_path os.path.dirname mpkg cmd 'find{0}-name*.pkg'.format base_path out __salt__['cmd.run'] cmd python_shell True pkg_files out.split '\n' for p in pkg_files package_infos.extend get_pkg_id p return package_infos
def _get_pyo_codes fmt '' dtype 'int16' file_out '' if not fmt dot_ext os.path.splitext file_out [1]fmt dot_ext.lower .strip '.' if fmt in pyo_formats.keys file_fmt pyo_formats[fmt]else msg 'format`{0}`notsupported'.format file_out raise PyoFormatException msg if fmt in ['sd2' 'flac'] ok_dfmt {'int16' 0 'int24' 1}else ok_dfmt pyo_dtypeif dtype in ok_dfmt.keys data_fmt pyo_dtype[dtype]else msg 'dataformat`{0}`notsupportedfor`{1}`'.format dtype file_out raise PyoFormatException msg return file_fmt data_fmt
def accumulate_values_into_parents accounts accounts_by_name period_list accumulated_values for d in reversed accounts if d.parent_account for period in period_list accounts_by_name[d.parent_account][period.key] accounts_by_name[d.parent_account].get period.key 0.0 + d.get period.key 0.0 accounts_by_name[d.parent_account][u'opening_balance'] accounts_by_name[d.parent_account].get u'opening_balance' 0.0 + d.get u'opening_balance' 0.0
@permission_required [ 'AccountLookup' 'View' ] def user_activity request user_id user get_object_or_404 UserProfile pk user_id products purchase_list request user is_admin acl.action_allowed request 'Users' 'Edit' user_items ActivityLog.objects.for_user user .exclude action__in mkt.LOG_HIDE_DEVELOPER admin_items ActivityLog.objects.for_user user .filter action__in mkt.LOG_HIDE_DEVELOPER mkt.log mkt.LOG.ADMIN_VIEWED_LOG request.user user user return render request 'lookup/user_activity.html' {'pager' products 'account' user 'is_admin' is_admin 'single' bool None 'user_items' user_items 'admin_items' admin_items 'show_link' False}
def iso_to_datetime_tuple iso return iso8601.parse_date iso
def getLazyLogger name 'unknown' version 'unknown' return LazyAdapter name version
def _parse_request_range range_header unit _ value range_header.partition ' ' unit value unit.strip value.strip if unit ! 'bytes' return None start_b _ end_b value.partition '-' try start _int_or_none start_b end _int_or_none end_b except ValueError return Noneif end is not None if start is None if end ! 0 start - end end Noneelse end + 1return start end
def print_metric line metric timestamp if not line['svname'] returnvalue line[metric]if not value value 0print 'haproxy.%s%i%ssource %scluster %s' % METRIC_NAMES[metric] timestamp value line['svname'] line['pxname']
def and_ a b return a & b
def sortHeaderNames headerNames headers [a.strip for a in headerNames.split ' ' if a.strip ]headers.sort return ' '.join headers
def _dispatch table action user obj if action in table result table[action] debug '%suser%s object%s action%s' 'ALLOWED' if result else 'DENIED' user obj.location.to_deprecated_string if isinstance obj XBlock else str obj action return resultraise ValueError u"Unknownactionforobjecttype'{0}' '{1}'".format type obj action
def event_search_location value query locations list value.split ' ' queries []for i in locations response requests.get 'https //maps.googleapis.com/maps/api/geocode/json?address ' + unicode i .json if response['results'] lng float response['results'][0]['geometry']['location']['lng'] lat float response['results'][0]['geometry']['location']['lat'] queries.append get_query_close_area lng lat queries.append func.lower Event.searchable_location_name .contains i.lower queries.append func.lower Event.location_name .contains i.lower return query.filter or_ *queries
def utcstr ts None assert ts is None or isinstance ts datetime if ts is None ts datetime.utcnow return u'{0}Z'.format ts.strftime u'%Y-%m-%dT%H %M %S.%f' [ -3 ]
def eigvals a b None overwrite_a False check_finite True homogeneous_eigvals False return eig a b b left 0 right 0 overwrite_a overwrite_a check_finite check_finite homogeneous_eigvals homogeneous_eigvals
def shared_floatx_zeros shape **kwargs return shared_floatx numpy.zeros shape **kwargs
def fit_model k features labels return k features.copy labels.copy
def set_hwclock clock return False
def autolevel image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._autolevel image selem out out mask mask shift_x shift_x shift_y shift_y
def apns_send_message registration_id alert **kwargs return _apns_send registration_id alert **kwargs
def setup_py_test nose.main addplugins [NoseSQLAlchemy ] argv ['runner']
def safe_key key key_prefix version key cleaned_string key key_prefix cleaned_string key_prefix version cleaned_string version combined ' '.join [key_prefix version key] if len combined > 250 combined fasthash combined return combined
def is_older_than before seconds if isinstance before basestring before parse_strtime before .replace tzinfo None return utcnow - before > datetime.timedelta seconds seconds
def attach_severities queryset as_field 'severities_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json projects_severity \nORDERBYprojects_severity.order\n \nFROMprojects_severity\nWHEREprojects_severity.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def _check_type value types description application_name if not isinstance value types raise ConfigurationError u"Application'{application_name}'hasaconfigerror.{description};gottype'{type}'.".format application_name application_name description description type type value .__name__
def extract_fields tweet fields out []for field in fields try _add_field_to_out tweet field out except TypeError raise RuntimeError 'Fatalerrorwhenextractingfields.Cannotfindfield' field return out
def _central_crop image_list crop_height crop_width outputs []for image in image_list image_height tf.shape image [0]image_width tf.shape image [1]offset_height image_height - crop_height / 2 offset_width image_width - crop_width / 2 outputs.append _crop image offset_height offset_width crop_height crop_width return outputs
def topological_ordering digr_ori if not digr_ori.DIRECTED raise Exception '%sisnotadirectedgraph' % digr digr deepcopy digr_ori ordering []n len digr.nodes while n > 0 sink_node find_sink_node digr ordering.append sink_node n digr.del_node sink_node n - 1return ordering
def test_qdatastream_status_count values vars QDataStream .values status_vals [e for e in values if isinstance e QDataStream.Status ]assert len status_vals 4
def _check_cb cb_ if cb_ is not None if hasattr cb_ '__call__' return cb_else log.error 'log_callbackisnotcallable ignoring' return lambda x x
def _extract_id_token id_token if type id_token bytes segments id_token.split '.' else segments id_token.split u'.' if len segments ! 3 raise VerifyJwtTokenError 'Wrongnumberofsegmentsintoken {0}'.format id_token return json.loads _helpers._from_bytes _helpers._urlsafe_b64decode segments[1]
def get_new_collection_id return collection_models.CollectionModel.get_new_id ''
def get_currency_precision currency cache_key u'currency_precision ' + currency precision cache.get cache_key if precision is None currency_obj Currency.objects.filter code currency .first precision decimal.Decimal u'0.1' ** currency_obj.decimal_places if currency_obj else None cache.set cache_key precision return precision
def cost w return 0.5 * sum y - h w np.array x ** 2 for x y in zip INPUTS OUTPUTS
def compute_P x X n x.shape[1]if X.shape[1] ! n raise ValueError "Numberofpointsdon'tmatch." M zeros 3 * n 12 + n for i in range n M[ 3 * i 0 4] X[ i]M[ 3 * i + 1 4 8] X[ i]M[ 3 * i + 2 8 12] X[ i]M[ 3 * i 3 * i + 3 i + 12 ] - x[ i] U S V linalg.svd M return V[ -1 12].reshape 3 4
def Init global INIT_RANif INIT_RAN returnif hasattr local 'stats' stats.STATS local.stats.StatsCollector else stats.STATS stats.StatsCollector syslog_logger logging.getLogger 'TempLogger' if os.path.exists '/dev/log' handler logging.handlers.SysLogHandler address '/dev/log' else handler logging.handlers.SysLogHandler syslog_logger.addHandler handler try config_lib.SetPlatformArchContext config_lib.ParseConfigCommandLine except config_lib.Error syslog_logger.exception 'Diedduringconfiginitialization' raiselog.ServerLoggingStartupInit registry.Init if not config_lib.CONFIG.ContextApplied 'ConfigUpdaterContext' if not config_lib.CONFIG.Get 'Server.initialized' raise RuntimeError 'Confignotinitialized run"grr_config_updaterinitialize".Iftheserverisalreadyconfigured add"Server.initialized True"toyourconfig.' INIT_RAN True
def dictConfig config dictConfigClass config .configure
def _compare_term minterm term for i x in enumerate term if x ! 3 and x ! minterm[i] return Falsereturn True
def qspline1d signal lamb 0.0 if lamb ! 0.0 raise ValueError 'Smoothingquadraticsplinesnotsupportedyet.' else return _quadratic_coeff signal
def _if_configuration_matches original @wraps original def render_if_matches self request **route_arguments if request.requestHeaders.hasHeader IF_MATCHES_HEADER tag get_configuration_tag self if_matches request.requestHeaders.getRawHeaders IF_MATCHES_HEADER if tag not in if_matches request.setResponseCode PRECONDITION_FAILED request.responseHeaders.setRawHeaders 'content-type' ['application/json'] return dumps {'description' "Tagdoesn'tmatch.Required %s current %s" % if_matches[0] tag } return original self request **route_arguments return render_if_matches
@click.command 'http_timeout' @click.argument 'seconds' type int def config_http_timeout seconds update_config {'http_timeout' seconds}
def _split_optional_netmask address addr str address .split '/' if len addr > 2 raise AddressValueError "Onlyone'/'permittedin%r" % address return addr
def make_attrgetter environment attribute if not isinstance attribute string_types or '.' not in attribute and not attribute.isdigit return lambda x environment.getitem x attribute attribute attribute.split '.' def attrgetter item for part in attribute if part.isdigit part int part item environment.getitem item part return itemreturn attrgetter
def import_repo_to_dir name temp_dir tempfile.mkdtemp export_path os.path.join _REPOS_DATA_DIR name temp_repo_dir os.path.join temp_dir name export_file open export_path 'rb' run_git_or_fail ['init' '--quiet' '--bare' temp_repo_dir] run_git_or_fail ['fast-import'] input export_file.read cwd temp_repo_dir export_file.close return temp_repo_dir
def format_decimal number format None return get_i18n .format_decimal number format
def check_empty_fields_before_bounds header mapping_data warnings desc_field 'Description'correction 1primer_field 'LinkerPrimerSequence'try desc_field_ix header.index desc_field + correction primer_field_ix header.index primer_field + correction except ValueError return warningsfor curr_row in range len mapping_data for curr_col in range primer_field_ix desc_field_ix curr_field mapping_data[curr_row][curr_col].replace '\n' '' if not curr_field warnings.append 'Emptydatafield' + '%sfound DCTB %d %d' % mapping_data[curr_row][curr_col].replace '\n' '' curr_row + correction curr_col return warnings
def insort_right a x lo 0 hi None if lo < 0 raise ValueError 'lomustbenon-negative' if hi is None hi len a while lo < hi mid lo + hi // 2 if x < a[mid] hi midelse lo mid + 1 a.insert lo x
def _union_items baselist comparelist return list set baselist | set comparelist
def create_python_app_env public_ip app_name env_vars {}env_vars['MY_IP_ADDRESS'] public_ipenv_vars['APPNAME'] app_nameenv_vars['GOMAXPROCS'] appscale_info.get_num_cpus env_vars['APPSCALE_HOME'] constants.APPSCALE_HOMEenv_vars['PYTHON_LIB'] '{0}/AppServer/'.format constants.APPSCALE_HOME return env_vars
def update_package_site new_url config_file parse_config ['config_file']__salt__['file.sed'] config_file 'PACKAGESITE.*' 'PACKAGESITE DCTB {0}'.format new_url return True
def _cast value schema_type if schema_type 'string' if type value type '' or type value type u'' return valueelse return str value elif schema_type 'integer' return str int value elif schema_type 'number' return str float value elif schema_type 'boolean' return str bool value .lower elif type value type '' or type value type u'' return valueelse return str value
def unquote_slashes text return re.sub ' ;;|;_ ' _unquote_slashes text
def truncate_file filename open filename 'w' .close
def _rehash shell __salt__['environ.get'] 'SHELL' if shell.split '/' [ -1 ] in 'csh' 'tcsh' __salt__['cmd.run'] 'rehash' output_loglevel 'trace'
def test_in value seq return value in seq
def swapcached mem_info meminfo for line in mem_info swaped re.search 'SwapCached \\s+ \\d+ \\w+' line if swaped return swaped.group 1 return 0
def rgb2short r g b dist lambda s d s[0] - d[0] ** 2 + s[1] - d[1] ** 2 + s[2] - d[2] ** 2 ary [hex_to_rgb hex for hex in RGB2SHORT_DICT]m min ary key partial dist r g b return RGB2SHORT_DICT[rgb_to_hex m ]
def _create_png figure canvas matplotlib.backends.backend_agg.FigureCanvasAgg figure canvas.draw size canvas.get_renderer .get_canvas_width_height image_as_string canvas.tostring_rgb image PIL.Image.fromstring 'RGB' size image_as_string 'raw' 'RGB' 0 1 image_background PIL.Image.new image.mode image.size figure.get_facecolor non_whitespace PIL.ImageChops.difference image image_background bounding_box non_whitespace.getbbox image image.crop bounding_box image_data StringIO.StringIO image.save image_data format 'PNG' return image_data.getvalue bounding_box
def read_all filter_ [] dir_ rospkg.get_test_results_dir root_result Result 'ros' 0 0 0 if not os.path.exists dir_ return root_resultfor d in os.listdir dir_ if filter_ and not d in filter_ continuesubdir os.path.join dir_ d if os.path.isdir subdir for filename in os.listdir subdir if filename.endswith '.xml' filename os.path.join subdir filename result read filename os.path.basename subdir root_result.accumulate result return root_result
def index_alt s3_redirect_default URL f 'mission' args 'summary'
def osquery_extensions attrs None where None return _osquery_cmd table 'osquery_extensions' attrs attrs where where
def call_command_async cmd *args **kwargs is_osx sys.platform 'darwin' in_proc kwargs.pop 'in_proc' not is_osx if in_proc return call_command_threaded cmd *args **kwargs else if hasattr sys 'pyrun' if settings.IS_SOURCE and 'kalite_dir' not in kwargs kwargs['kalite_dir'] settings.SOURCE_DIRif 'wait' not in kwargs kwargs['wait'] Falsereturn call_outside_command_with_output cmd *args **kwargs return call_command_subprocess cmd *args **kwargs
def ones shape dtype None if not isinstance shape list tuple TensorVariable shape [shape]if dtype is None dtype config.floatXreturn alloc numpy.array 1 dtype dtype *shape
def _list_from_layouttuple tk ltuple ltuple tk.splitlist ltuple res []indx 0while indx < len ltuple name ltuple[indx]opts {}res.append name opts indx + 1while indx < len ltuple opt val ltuple[indx indx + 2 ]if not opt.startswith '-' breakopt opt[1 ]indx + 2if opt 'children' val _list_from_layouttuple tk val opts[opt] valreturn res
def update_counters rex node_info None db None def wrapper func @functools.wraps func def wrapped *args **kwargs ret func *args **kwargs page build_page rex kwargs update_counter page node_info db return retreturn wrappedreturn wrapper
@step STEP_PREFIX + ' ? an? ? [A-Z][a-z0-9_]* shouldbepresent' + 'inthedatabase' def models_exist_generic step model model get_model model try func _MODEL_EXISTS[model]except KeyError func curry models_exist model func step
def make_migrations base_dir try manage os.path.join base_dir 'manage.py' args ['python' manage 'makemigrations']subprocess.call args args ['python' manage 'makemigrations' 'StaticAnalyzer']subprocess.call args except PrintException '[ERROR]CannotMakeMigrations'
def labeller n symbol 'q' return [ '%s_%d' % symbol n - i - 1 for i in range n ]
def _multi_send method context topic msg timeout None envelope False _msg_id None conf CONFLOG.debug _ '% msg s' % {'msg' ''.join map pformat topic msg } queues _get_matchmaker .queues topic LOG.debug _ 'Sendingmessage s to %s' queues if len queues 0 LOG.warn _ 'Nomatchmakerresults.Notcasting.' raise rpc_common.Timeout _ 'Nomatchfrommatchmaker.' for queue in queues _topic ip_addr queue_addr 'tcp //%s %s' % ip_addr conf.rpc_zmq_port if method.__name__ '_cast' eventlet.spawn_n method _addr context _topic msg timeout envelope _msg_id returnreturn method _addr context _topic msg timeout envelope
def nova_except_format_assert logical_line if logical_line.startswith 'self.assertRaises Exception' yield 1 'N202 assertRaisesExceptiontoobroad'
def version_tag names version.NAMES.strip assert names[0] ' ' assert names[ -1 ] ' ' names names[1 -1 ]l [n.strip for n in names.split ' ' ]for n in l if n.startswith 'tag ' and version_rx.match n[5 ] return n[5 ]return 'unknown-%s' % version.COMMIT[ 7]
def ec2_error req request_id code message LOG.error _ '% code s % message s' % locals resp webob.Response resp.status 400resp.headers['Content-Type'] 'text/xml'resp.body str '<?xmlversion "1.0"?>\n<Response><Errors><Error><Code>%s</Code><Message>%s</Message></Error></Errors><RequestID>%s</RequestID></Response>' % utils.xhtml_escape utils.utf8 code utils.xhtml_escape utils.utf8 message utils.xhtml_escape utils.utf8 request_id return resp
def DEFINE_integer_list name default help CONFIG.AddOption type_info.List name name default default description help validator type_info.Integer
def getIndexedCellLoopsFromIndexedGrid grid indexedCellLoops []for rowIndex in xrange len grid - 1 rowBottom grid[rowIndex]rowTop grid[ rowIndex + 1 ]for columnIndex in xrange len rowBottom - 1 columnIndexEnd columnIndex + 1 indexedConvex []indexedConvex.append rowBottom[columnIndex] indexedConvex.append rowBottom[ columnIndex + 1 ] indexedConvex.append rowTop[ columnIndex + 1 ] indexedConvex.append rowTop[columnIndex] indexedCellLoops.append indexedConvex return indexedCellLoops
def get_cap_alert_addresses_opts T current.Tgtable current.s3db.pr_grouprows current.db gtable.deleted ! True .select gtable.id gtable.name return [ row.id s3_str T row.name for row in rows]
def InlineLegend chart show Falselabels []label_positions []for series in chart.data if series.label is None labels.append '' else labels.append series.label show Truelabel_positions.append series.data[ -1 ] if show chart.right.min chart.left.minchart.right.max chart.left.maxchart.right.labels labelschart.right.label_positions label_positionschart._show_legend False
def cleanup_stubs pass
def import_object_ns name_space import_str *args **kwargs import_value '%s.%s' % name_space import_str try return import_class import_value *args **kwargs except ImportError return import_class import_str *args **kwargs
def proportions_chisquare_allpairs count nobs multitest_method 'hs' all_pairs lzip *np.triu_indices len count 1 pvals [proportions_chisquare count[list pair ] nobs[list pair ] [1] for pair in all_pairs]return AllPairsResults pvals all_pairs multitest_method multitest_method
def pretty expr **settings pp PrettyPrinter settings use_unicode pp._settings['use_unicode']uflag pretty_use_unicode use_unicode try return pp.doprint expr finally pretty_use_unicode uflag
def read_git_file path result Noneif path and is_git_file path header u'gitdir 'data core.read path .strip if data.startswith header result data[len header ]return result
def get_fields node return dict iter_fields node
def ode_linear_coefficients eq func order match return ode_1st_homogeneous_coeff_best eq func order match
def only_if_subclass meth @wraps meth def test_only_subclass self *args **kwds 'Notethatthismethodneedstostartwithtest_inorderfornose\ntorunit!'for base_klass in self.__class__.__bases__ if meth.__name__ in dir base_klass and base_klass.__name__ ! self.__class__.__name__ return meth self *args **kwds returnreturn test_only_subclass
def layers n m def bump a x 1 / 0.1 + np.random.random y 2 * np.random.random - 0.5 z 10 / 0.1 + np.random.random for i in range m w i / float m - y * z a[i] + x * np.exp - w * w a np.zeros m n for i in range n for j in range 5 bump a[ i] return a
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def error xml try ET.XML xml except ET.ParseError return sys.exc_value
def click_and_wait_for_id_to_appear context elem_click elem_wait wait_time MAX_WAIT_TIME elem_click.click return id_shown_with_wait context elem_wait wait_time wait_time
def transform_crap code ind code.rfind '?' if ind -1 return codesep code.find ' ' ind if sep -1 raise SyntaxError 'Invalid? syntax probablymissing" " ' beg max code.rfind ' ' 0 ind code.find '?' 0 ind + 1 end code.find ' ' sep + 1 end len code if end -1 else end formula ' ' + code[ ind + 1 sep] + 'if' + code[beg ind] + 'else' + code[ sep + 1 end] + ' ' return transform_crap code[ beg] + formula + code[end ]
def permutationFilter perm return True
def partial_max a raise NotImplementedError 'TODO implementthisfunction.'
def reject_fairness experiment num_heads len [flip for flip in experiment if flip] return num_heads < 469 or num_heads > 531
def remove_nexusport_binding port_id vlan_id switch_ip instance_id LOG.debug _ 'remove_nexusport_binding called' session db.get_session try binding session.query nexus_models_v2.NexusPortBinding .filter_by vlan_id vlan_id .filter_by switch_ip switch_ip .filter_by port_id port_id .filter_by instance_id instance_id .all for bind in binding session.delete bind session.flush return bindingexcept exc.NoResultFound pass
def read_comments ws xml_source root fromstring xml_source authors _get_author_list root comment_nodes safe_iterator root '{%s}comment' % SHEET_MAIN_NS for node in comment_nodes author authors[int node.attrib['authorId'] ]cell node.attrib['ref']text_node node.find '{%s}text' % SHEET_MAIN_NS substrs []for run in text_node.findall '{%s}r' % SHEET_MAIN_NS runtext ''.join [t.text for t in run.findall '{%s}t' % SHEET_MAIN_NS ] substrs.append runtext comment_text ''.join substrs comment Comment comment_text author ws.cell coordinate cell .comment comment
def insert_read_more_link instance if type instance ! contents.Article returnSUMMARY_MAX_LENGTH instance.settings.get 'SUMMARY_MAX_LENGTH' READ_MORE_LINK instance.settings.get 'READ_MORE_LINK' None READ_MORE_LINK_FORMAT instance.settings.get 'READ_MORE_LINK_FORMAT' '<aclass "read-more"href "/{url}">{text}</a>' if not SUMMARY_MAX_LENGTH and READ_MORE_LINK and READ_MORE_LINK_FORMAT returnif hasattr instance '_summary' and instance._summary summary instance._summaryelse summary truncate_html_words instance.content SUMMARY_MAX_LENGTH if summary ! instance.content read_more_link READ_MORE_LINK_FORMAT.format url instance.url text READ_MORE_LINK instance._summary insert_into_last_element summary read_more_link
def SimpleParser fieldname schema **kwargs from whoosh.qparser import pluginspins [plugins.WhitespacePlugin plugins.PlusMinusPlugin plugins.PhrasePlugin]return QueryParser fieldname schema plugins pins **kwargs
def getPointsByVerticalDictionary width xIntersectionsDictionary points []xIntersectionsDictionaryKeys xIntersectionsDictionary.keys xIntersectionsDictionaryKeys.sort for xIntersectionsDictionaryKey in xIntersectionsDictionaryKeys for xIntersection in xIntersectionsDictionary[xIntersectionsDictionaryKey] points.append complex xIntersectionsDictionaryKey * width xIntersection return points
def rotation x rg 20 is_random False row_index 0 col_index 1 channel_index 2 fill_mode 'nearest' cval 0.0 if is_random theta np.pi / 180 * np.random.uniform - rg rg else theta np.pi / 180 * rg rotation_matrix np.array [[np.cos theta - np.sin theta 0] [np.sin theta np.cos theta 0] [0 0 1]] h w x.shape[row_index] x.shape[col_index] transform_matrix transform_matrix_offset_center rotation_matrix h w x apply_transform x transform_matrix channel_index fill_mode cval return x
def make_segments x y points np.array [x y] .T.reshape -1 1 2 segments np.concatenate [points[ -1 ] points[1 ]] axis 1 return segments
@lower_constant types.UniTuple @lower_constant types.NamedUniTuple def unituple_constant context builder ty pyval consts [context.get_constant_generic builder ty.dtype v for v in pyval]return ir.ArrayType consts[0].type len consts consts
def experimental api_name if not chainer.disable_experimental_feature_warning warnings.warn '{}isexperimental.Theinterfacecanchangeinthefuture.'.format api_name FutureWarning
def secondary_clustering sff_file mapping bestscores log_fh threshold 4.5 verbose False if len bestscores 0 return flowgrams header lazy_parse_sff_handle open sff_file counter 0for f in flowgrams id score bestscores[f.Name]if score < threshold counter + 1mapping[id].extend mapping[f.Name] mapping[id].append f.Name del mapping[f.Name]if verbose log_fh.write 'Secondaryclusteringremoved%dflowgrams\n' % counter
def available_attrs fn if six.PY3 return WRAPPER_ASSIGNMENTSelse return tuple a for a in WRAPPER_ASSIGNMENTS if hasattr fn a
def id return _distro.id
def find_undeclared nodes names visitor UndeclaredNameVisitor names try for node in nodes visitor.visit node except VisitorExit passreturn visitor.undeclared
def home_dir if IS_WINDOWS_PLATFORM return os.environ.get 'USERPROFILE' '' else return os.path.expanduser '~'
def _get_nibbles char try x y hex ord char [2 ]except x '0'y hex ord char [2 ]return x y
def get_openshift_secret_key token os.getenv 'OPENSHIFT_SECRET_TOKEN' if token is not None return tokenname os.getenv 'OPENSHIFT_APP_NAME' uuid os.getenv 'OPENSHIFT_APP_UUID' if name is not None and uuid is not None nameuuid '-'.join name uuid return hashlib.sha256 nameuuid.encode 'utf-8' .hexdigest sys.stderr.write 'OPENSHIFTWARNING Usingdefaultvaluesforsecurevariables ' + 'pleasesetOPENSHIFT_SECRET_TOKEN!' raise ValueError 'Nokeyavailable'
def use_step_matcher name global current_matchercurrent_matcher matcher_mapping[name]
def will_expire_soon expiry soon timeutils.utcnow + datetime.timedelta seconds 30 return expiry < soon
def proxy_rewriter condition rewrite def _proxy_rewriter criteria criteria integral criteria integrand symbol integralargs criteria + list integral if condition *args rewritten rewrite *args if rewritten ! integrand return RewriteRule rewritten integral_steps rewritten symbol integrand symbol return _proxy_rewriter
def build_property_spec client_factory type 'VirtualMachine' properties_to_collect None all_properties False if not properties_to_collect properties_to_collect ['name']property_spec client_factory.create 'ns0 PropertySpec' property_spec.all all_propertiesproperty_spec.pathSet properties_to_collectproperty_spec.type typereturn property_spec
def test_db ip.db['__unittest_'] 12nt.assert_equal ip.db['__unittest_'] 12 del ip.db['__unittest_']assert '__unittest_' not in ip.db
def path_to_url2 path path os.path.normpath os.path.abspath path drive path os.path.splitdrive path filepath path.split os.path.sep url '/'.join [urllib.quote part for part in filepath] if not drive url url.lstrip '/' return 'file ///' + drive + url
def _filter source try varname re.search 'eval\\ \\w+\\ \\w+\\ \\w+ \\ \\ \\ ;' source .group 1 reverse re.search "var+%s*\\ *' .* ';" % varname source .group 1 except AttributeError raise UnpackingError 'MalformedMyObfuscatedata.' try return base64.b64decode reverse[ -1 ].encode 'utf8' .decode 'utf8' except TypeError raise UnpackingError 'MyObfuscatepayloadisnotbase64-encoded.'
def FormatArguments *args **kwargs def _FormatArg arg return FormatLogArgument arg args [_FormatArg arg for arg in args]kwargs {key _FormatArg value for key value in kwargs.items }return ' args %s kwargs %s ' % args kwargs
def get_available_colours ret ''for colours in IRC_COLOUR_DICT ret + colours + ' ' return ret[ -2 ]
def index_alt s3_redirect_default URL f 'mission' args 'summary'
def unpublish desc type port properties None add_hostname True server start_server service create_service desc type port properties add_hostname server.unregisterService service if server.countRegisteredServices 0 stop_server
def set_palette palette n_colors None desat None color_codes False colors palettes.color_palette palette n_colors desat if mpl_ge_150 from cycler import cyclercyl cycler 'color' colors mpl.rcParams['axes.prop_cycle'] cylelse mpl.rcParams['axes.color_cycle'] list colors mpl.rcParams['patch.facecolor'] colors[0]if color_codes palettes.set_color_codes palette
def has_parent basepath obj try return any cls for cls in obj.__class__.mro if basepath '%s.%s' % cls.__module__ cls.__name__ except TypeError AttributeError return False
def moduleProvides *interfaces frame sys._getframe 1 locals frame.f_localsif locals is not frame.f_globals or '__name__' not in locals raise TypeError 'moduleProvidescanonlybeusedfromamoduledefinition.' if '__provides__' in locals raise TypeError 'moduleProvidescanonlybeusedonceinamoduledefinition.' locals['__provides__'] Provides ModuleType *_normalizeargs interfaces
def multigroup pvals groups exact True keep_all True alpha 0.05 pvals pd.Series pvals if not set pvals.unique < set [False True] raise ValueError 'theseriesshouldbebinary' if hasattr pvals.index 'is_unique' and not pvals.index.is_unique raise ValueError 'serieswithduplicatedindexisnotaccepted' results {'pvals' {} 'increase' {} '_in_sign' {} '_in_non' {} '_out_sign' {} '_out_non' {}}for group_name group_list in iteritems groups res _test_group pvals group_name group_list exact results['pvals'][group_name] res[0]results['increase'][group_name] res[1]results['_in_sign'][group_name] res[2][0]results['_in_non'][group_name] res[2][1]results['_out_sign'][group_name] res[2][2]results['_out_non'][group_name] res[2][3]result_df sort_values pd.DataFrame results 'pvals' if not keep_all result_df result_df[result_df.increase]smt stats.multipletestscorrected smt result_df['pvals'] method 'fdr_bh' alpha alpha [1]result_df['adj_pvals'] correctedreturn result_df
def has_key key store load return key in store
def collect_quantum_ports bridges root_helper ports []for bridge in bridges ovs ovs_lib.OVSBridge bridge root_helper ports + [port.port_name for port in ovs.get_vif_ports ]return ports
def _yule_walker X order 1 assert X.ndim 2 denom X.shape[ -1 ] - np.arange order + 1 r np.zeros order + 1 np.float64 for di d in enumerate X d - d.mean r[0] + np.dot d d for k in range 1 order + 1 r[k] + np.dot d[0 - k ] d[k ] r / denom * len X rho linalg.solve linalg.toeplitz r[ -1 ] r[1 ] sigmasq r[0] - r[1 ] * rho .sum return rho np.sqrt sigmasq
def _get_headnode_dict fixer_list head_nodes collections.defaultdict list every []for fixer in fixer_list if fixer.pattern try heads _get_head_types fixer.pattern except _EveryNode every.append fixer else for node_type in heads head_nodes[node_type].append fixer elif fixer._accept_type is not None head_nodes[fixer._accept_type].append fixer else every.append fixer for node_type in chain pygram.python_grammar.symbol2number.itervalues pygram.python_grammar.tokens head_nodes[node_type].extend every return dict head_nodes
def keyboard_role name rawtext text lineno inliner options {} content [] new_element nodes.literal rawtext text new_element.set_class 'kbd' return [new_element] []
def pkg_commit_hash pkg_path pth os.path.join pkg_path COMMIT_INFO_FNAME if not os.path.isfile pth raise IOError u'Missingcommitinfofile%s' % pth cfg_parser ConfigParser cfg_parser.read pth archive_subst cfg_parser.get u'commithash' u'archive_subst_hash' if not archive_subst.startswith u'$Format' return u'archivesubstitution' archive_subst install_subst cfg_parser.get u'commithash' u'install_hash' if install_subst ! u'' return u'installation' install_subst proc subprocess.Popen u'gitrev-parse--shortHEAD' stdout subprocess.PIPE stderr subprocess.PIPE cwd pkg_path shell True repo_commit _ proc.communicate if repo_commit if PY3 repo_commit repo_commit.decode return u'repository' repo_commit.strip return u' nonefound ' u'<notfound>'
def supported_fixes yield u'E101' docstring_summary reindent.__doc__ instance FixPEP8 filename None options None contents u'' for attribute in dir instance code re.match u'fix_ [ew][0-9][0-9][0-9] ' attribute if code yield code.group 1 .upper re.sub u'\\s+' u'' docstring_summary getattr instance attribute .__doc__ for code function in sorted global_fixes yield code.upper + 4 - len code * u'' re.sub u'\\s+' u'' docstring_summary function.__doc__ for code in sorted CODE_TO_2TO3 yield code.upper + 4 - len code * u'' re.sub u'\\s+' u'' docstring_summary fix_2to3.__doc__
def memory_index indices t memlen itemsize ndim shape strides offset tp offsetfor i in range ndim p + strides[i] * indices[i] return p
def cs_int func func.argtypes [CS_PTR POINTER c_uint ]func.restype c_intfunc.errcheck check_cs_getreturn func
def _Repr class_instance ordered_dictionary return u'search.%s %s ' % class_instance.__class__.__name__ ' '.join [ '%s %r' % key value for key value in ordered_dictionary if value is not None and value ! [] ]
def _infer_return_type *args return_type Nonefor arg in args if arg is None continueif isinstance arg bytes if return_type is str raise TypeError "Can'tmixbytesandnon-bytesinpathcomponents." return_type byteselse if return_type is bytes raise TypeError "Can'tmixbytesandnon-bytesinpathcomponents." return_type strif return_type is None return strreturn return_type
def roots_chebyu n mu False m int n if n < 1 or n ! m raise ValueError 'nmustbeapositiveinteger.' t np.arange m 0 -1 * pi / m + 1 x np.cos t w pi * np.sin t ** 2 / m + 1 if mu return x w pi / 2 else return x w
def _element_in_child_template root e return any x.typeid.startswith 'bind template' for x in root.path_to e
def generate_gexf G encoding 'utf-8' prettyprint True version '1.1draft' writer GEXFWriter encoding encoding prettyprint prettyprint version version writer.add_graph G for line in str writer .splitlines yield line
def CopyReversedLines instream outstream blocksize 2 ** 16 line_count 0instream.seek 0 2 last_block instream.tell // blocksize spillover ''for iblock in xrange last_block + 1 -1 -1 instream.seek iblock * blocksize data instream.read blocksize lines data.splitlines True lines[ -1 ] ''.join lines[ -1 ] + [spillover] .splitlines True if lines and not lines[ -1 ].endswith '\n' lines[ -1 ] + '\n'lines.reverse if lines and iblock > 0 spillover lines.pop if lines line_count + len lines data ''.join lines .replace '\x00' '\n DCTB ' outstream.write data return line_count
def create_new_user_confirmation user_address id_chars string.ascii_letters + string.digits rand random.SystemRandom random_id ''.join [rand.choice id_chars for i in range 42 ] record UserConfirmationRecord user_address user_address id random_id record.put return 'https //{}/user/confirm?code {}'.format socket.getfqdn socket.gethostname random_id
def generate_lane_mask aln entropy_threshold if entropy_threshold 0.0 result ['1'] * aln.sequence_length else entropies aln.position_entropies nan_on_non_standard_chars False entropy_cutoff np.percentile entropies 1 - entropy_threshold * 100.0 interpolation 'nearest' result []for entropy in entropies if entropy > entropy_cutoff result.append '0' else result.append '1' return ''.join result
def _error_detail data item err item['errorDetail']if 'code' in err msg '{1} {2}'.format item['errorDetail']['code'] item['errorDetail']['message'] else msg item['errorDetail']['message']data.append msg
def loop_until reactor predicate steps None if steps is None steps repeat 0.1 steps iter steps action LOOP_UNTIL_ACTION predicate predicate d action.run DeferredContext maybeDeferred action.run predicate def loop result if not result LOOP_UNTIL_ITERATION_MESSAGE result result .write try delay steps.next except StopIteration raise LoopExceeded predicate result d deferLater reactor delay action.run predicate d.addCallback partial action.run loop return daction.addSuccessFields result result return resultd.addCallback loop return d.addActionFinish
@login_required@permission_required_or_403 'forums_forum.post_delete_forum' Forum 'slug__iexact' 'forum_slug' def delete_post request forum_slug thread_id post_id forum get_object_or_404 Forum slug forum_slug thread get_object_or_404 Thread pk thread_id forum forum post get_object_or_404 Post pk post_id thread thread if request.method 'GET' return render request 'forums/confirm_post_delete.html' {'forum' forum 'thread' thread 'post' post} log.warning 'User%sisdeletingpostwithid %s' % request.user post.id post.delete statsd.incr 'forums.delete_post' try Thread.objects.get pk thread_id goto reverse 'forums.posts' args [forum_slug thread_id] except Thread.DoesNotExist goto reverse 'forums.threads' args [forum_slug] return HttpResponseRedirect goto
@blueprint.route '/sources/<source>/users' def list_users_by_source source return _list_users source source
def parse_content_type content_type if content_type is not None and ';' in content_type return parse_header content_type return content_type empty.dict
def _is_minimal_bsgs base gens base1 []sgs1 gens[ ]size gens[0].sizefor i in range size if not all h._array_form[i] i for h in sgs1 base1.append i sgs1 [h for h in sgs1 if h._array_form[i] i ]return base1 base
@utils.arg 'hypervisor' metavar '<hypervisor>' help _ 'NameorIDofthehypervisortoshowthedetailsof.' @utils.arg '--wrap' dest 'wrap' metavar '<integer>' default 40 help _ 'Wraptheoutputtoaspecifiedlength.Defaultis40or0todisable' def do_hypervisor_show cs args hyper _find_hypervisor cs args.hypervisor utils.print_dict utils.flatten_dict hyper.to_dict wrap int args.wrap
def extract_test_sentences string comment_chars '#%;' encoding None if encoding is not None string string.decode encoding sentences []for sentence in string.split '\n' if sentence '' or sentence[0] in comment_chars continuesplit_info sentence.split ' ' 1 result Noneif len split_info 2 if split_info[0] in ['True' 'true' 'False' 'false'] result split_info[0] in ['True' 'true'] sentence split_info[1]else result int split_info[0] sentence split_info[1]tokens sentence.split if tokens [] continuesentences + [ tokens result ]return sentences
def check_for_obj_leakage f *args **kwargs f gc.collect gc.collect gc.collect f gc.collect gc.collect gc.collect r1 gc.get_objects f gc.collect gc.collect gc.collect r2 gc.get_objects d2 dict [ id x x for x in r2] del d2[id r1 ]for o in r1 if id o in d2 del d2[id o ]return len r2 - len r1 - 1 d2
def parse_gcs_uri uri components urlparse uri if components.scheme ! 'gs' or '/' not in components.path raise ValueError 'InvalidGCSURI %s' % uri return components.netloc components.path[1 ]
def encipher_elgamal i key seed None p r e keyif i < 0 or i > p raise ValueError 'Message %s shouldbeinrange %s ' % i p randrange _randrange seed a randrange 2 p return pow r a p i * pow e a p % p
def signalcommand func def inner self *args **kwargs pre_command.send self.__class__ args args kwargs kwargs ret func self *args **kwargs post_command.send self.__class__ args args kwargs kwargs outcome ret return retreturn inner
def parse_keqv_list l encoded_list [u.encode 'utf-8' for u in l]encoded_parsed urllib2.parse_keqv_list encoded_list return dict k.decode 'utf-8' v.decode 'utf-8' for k v in encoded_parsed.items
def _pretty_fulltext_sentences sents outstr u''outstr + u'full-textdocument {0.ID} {0.name} \n\n'.format sents outstr + u'[corpid]{0.corpid}\n[corpname]{0.corpname}\n[description]{0.description}\n[URL]{0.URL}\n\n'.format sents outstr + u'[sentence]\n'.format sents for i sent in enumerate sents.sentence outstr + u'[{0}]{1}\n'.format i sent.text outstr + u'\n'return outstr
def _sample_even_odd W_list b_list samples beta odd True for i in xrange odd len samples 2 samples[i] sample_hi_given samples i W_list b_list beta
def arbitrary_address family if family 'AF_INET' return 'localhost' 0 elif family 'AF_UNIX' return tempfile.mktemp prefix 'listener-' dir util.get_temp_dir elif family 'AF_PIPE' return tempfile.mktemp prefix '\\\\.\\pipe\\pyc-%d-%d-' % os.getpid next _mmap_counter dir '' else raise ValueError 'unrecognizedfamily'
def encode_short_string pieces value encoded_value as_bytes value length len encoded_value if length > 255 raise exceptions.ShortStringTooLong encoded_value pieces.append struct.pack 'B' length pieces.append encoded_value return 1 + length
def safe_loads arg try loaded json.loads arg except TypeError ValueError loaded argreturn loaded
def combine_types x y if isinstance x Unknown return yif isinstance y Unknown return xif isinstance x Any return xif isinstance y Any return yif isinstance x Union return combine_either x y if isinstance y Union return combine_either y x if x y return xreturn simplify_either [x] [y]
def hex2rgb255 hexColor if hexColor[0] '#' hexColor hexColor[1 ]elif hexColor[0 2].lower '0x' hexColor hexColor[2 ]if len hexColor 3 hexColor hexColor[0] + '0' + hexColor[1] + '0' + hexColor[2] + '0' rgb int hexColor[0 2] 16 int hexColor[2 4] 16 int hexColor[4 6] 16 return rgb
def gray rc u'image' cmap u'gray' im gci if im is not None im.set_cmap cm.gray
def GenBankIterator handle return GenBankScanner debug 0 .parse_records handle
def _country_level_time_zones_for_number numobj cc str numobj.country_code for prefix_len in range TIMEZONE_LONGEST_PREFIX 0 -1 prefix cc[ 1 + prefix_len ]if prefix in TIMEZONE_DATA return TIMEZONE_DATA[prefix]return _UNKNOWN_TIME_ZONE_LIST
def edition rebulk Rebulk .regex_defaults flags re.IGNORECASE abbreviations [dash] .string_defaults ignore_case True rebulk.defaults name 'edition' validator seps_surround rebulk.regex 'collector' 'collector-edition' 'edition-collector' value 'CollectorEdition' rebulk.regex 'special-edition' 'edition-special' value 'SpecialEdition' conflict_solver lambda match other other if other.name 'episode_details' and other.value 'Special' else '__default__' rebulk.regex 'criterion-edition' 'edition-criterion' value 'CriterionEdition' rebulk.regex 'deluxe' 'deluxe-edition' 'edition-deluxe' value 'DeluxeEdition' rebulk.regex "director'?s?-cut" "director'?s?-cut-edition" "edition-director'?s?-cut" value "Director'scut" return rebulk
def _check_roundtrip montage fname assert_equal montage.coord_frame 'head' montage.save fname montage_read read_dig_montage fif fname assert_equal str montage str montage_read for kind in 'elp' 'hsp' 'nasion' 'lpa' 'rpa' assert_allclose getattr montage kind getattr montage_read kind err_msg kind assert_equal montage_read.coord_frame 'head'
def _find_collections root packages []for dirname subdirs files in os.walk root for filename in files if filename.endswith u'.xml' xmlfile os.path.join dirname filename yield ElementTree.parse xmlfile .getroot
def common_mocks f def _common_inner_inner1 inst *args **kwargs @mock.patch 'subprocess.Popen' spec True @mock.patch 'eventlet.sleep' spec True @mock.patch 'time.time' spec True @mock.patch 'cinder.backup.drivers.ceph.rbd' @mock.patch 'cinder.backup.drivers.ceph.rados' def _common_inner_inner2 mock_rados mock_rbd mock_time mock_sleep mock_popen mock_time.side_effect inst.time_incmock_popen.side_effect Exceptioninst.mock_rados mock_radosinst.mock_rbd mock_rbdinst.mock_rbd.ImageBusy MockImageBusyExceptioninst.mock_rbd.ImageNotFound MockImageNotFoundExceptioninst.service.rbd inst.mock_rbdinst.service.rados inst.mock_radosreturn f inst *args **kwargs return _common_inner_inner2 return _common_inner_inner1
def libvlc_media_player_get_chapter_count_for_title p_mi i_title f _Cfunctions.get 'libvlc_media_player_get_chapter_count_for_title' None or _Cfunction 'libvlc_media_player_get_chapter_count_for_title' 1 1 None ctypes.c_int MediaPlayer ctypes.c_int return f p_mi i_title
def _get_win_adapter_name_and_ip_address mac_address network_adapters _get_windows_network_adapters return _get_adapter_name_and_ip_address network_adapters mac_address
def cloudstack_displayname vm_ return config.get_cloud_config_value 'cloudstack_displayname' vm_ __opts__ search_global True
def rs_is_puiseux p x index p.ring.gens.index x for k in p if k[index] ! int k[index] return Trueif k[index] < 0 raise ValueError 'Theseriesisnotregularin%s' % x return False
def cached_query model filter_fn filter_identity def cached_query_decorator fn def cached_query_wrapper *args assert fn.__name__.startswith 'get_' row_key_components [fn.__name__[len 'get_' ]]if len args > 0 if isinstance args[0] Thing args list args args[0] args[0]._idif isinstance args[0] int long serialized to36 args[0] else serialized str args[0] row_key_components.append serialized row_key_components.extend str x for x in args[1 ] row_key '.'.join row_key_components query fn *args query_sort query._sorttry is_precomputed query.precomputedexcept AttributeError is_precomputed _is_query_precomputed query return CachedQuery model row_key query_sort filter_fn is_precomputed return cached_query_wrapperreturn cached_query_decorator
def _PrepareSpecialProperties entity_proto is_load for i in xrange entity_proto.property_size - 1 -1 -1 if _SPECIAL_PROPERTY_MAP.has_key entity_proto.property i .name del entity_proto.property_list [i]for is_visible is_stored property_func in _SPECIAL_PROPERTY_MAP.values if is_load should_process is_visibleelse should_process is_storedif should_process special_property property_func entity_proto if special_property entity_proto.property_list .append special_property
def split_content_type c_type delim ';'ps c_type.split delim tup dict [ k.lower .strip v for k v in [p.split ' ' 1 for p in ps[1 ]]] return tup
def test_scenario_post_email feature Feature.from_string FEATURE21 scenario1 scenario2 feature.scenariosscenario1.tags.should.be.emptyscenario2.tags.should.equal ['tag']
def confirm_email_token_status token return get_token_status token 'confirm' 'CONFIRM_EMAIL'
def removeDynamicContent page if page for item in kb.dynamicMarkings prefix suffix itemif prefix is None and suffix is None continueelif prefix is None page re.sub ' ?s ^.+%s' % re.escape suffix suffix.replace '\\' '\\\\' page elif suffix is None page re.sub ' ?s %s.+$' % re.escape prefix prefix.replace '\\' '\\\\' page else page re.sub ' ?s %s.+%s' % re.escape prefix re.escape suffix '%s%s' % prefix.replace '\\' '\\\\' suffix.replace '\\' '\\\\' page return page
def _isCategory fieldType if fieldType 'string' return Trueif fieldType 'int' or fieldType 'float' return False
def _build_template_params params_str i 0params {}for item in params_str param __ value item.partition ' ' if value params[param] valueelse i i + 1 params[str i ] paramreturn params
def includes_cls fields first_field Noneif len fields if isinstance fields[0] six.string_types first_field fields[0]elif isinstance fields[0] list tuple and len fields[0] first_field fields[0][0]return first_field '_cls'
def test_record_bad output StringIO recorder Record file_object output replay False num_lines 10for i in xrange num_lines recorder.handle_line str i + '\n' output_value output.getvalue output StringIO output_value playback_checker Record file_object output replay True for i in xrange num_lines // 2 playback_checker.handle_line str i + '\n' try playback_checker.handle_line '0\n' except MismatchError returnraise AssertionError 'Failedtodetectmismatchbetweenrecordedsequenceandrepetitionofit.'
def equate point returnValue point.setToVector3 evaluate.getVector3ByDictionaryListValue returnValue point
def migrate_node_facts facts params {'common' 'dns_ip'}if 'node' not in facts facts['node'] {}for role in params.keys if role in facts for param in params[role] if param in facts[role] facts['node'][param] facts[role].pop param return facts
def GetModuleForTypelib typelibCLSID lcid major minor modName GetGeneratedFileName typelibCLSID lcid major minor mod _GetModule modName if '_in_gencache_' not in mod.__dict__ AddModuleToCache typelibCLSID lcid major minor assert '_in_gencache_' in mod.__dict__ return mod
def _psql_cmd *args **kwargs user host port maintenance_db password _connection_defaults kwargs.get 'user' kwargs.get 'host' kwargs.get 'port' kwargs.get 'maintenance_db' kwargs.get 'password' _PSQL_BIN _find_pg_binary 'psql' cmd [_PSQL_BIN '--no-align' '--no-readline' '--no-psqlrc' '--no-password']if user cmd + ['--username' user]if host cmd + ['--host' host]if port cmd + ['--port' str port ]if not maintenance_db maintenance_db 'postgres'cmd.extend ['--dbname' maintenance_db] cmd.extend args return cmd
def decode_fvwi byts flag_size 4 arg consumed decint bytes byts val arg >> flag_size flags 0for i in xrange flag_size flags | arg & 1 << i return val flags consumed
@pytest.mark.parametrize u'collection' [[u'user_action' u'user'] [u'user_group' u'user'] [u'user_group' u'user_action']] def test_should_break_ties_using_lexical_order completer collection text u'user'matches completer.find_matches text collection assert matches[1].priority > matches[0].priority
def get_exploration_recommendations exp_id recommendations_model recommendations_models.ExplorationRecommendationsModel.get exp_id strict False if recommendations_model is None return []else return recommendations_model.recommended_exploration_ids
def test_stockwell_check_input for last_dim in 127 128 data np.zeros 2 10 last_dim x_in n_fft zero_pad _check_input_st data None assert_equal x_in.shape 2 10 128 assert_equal n_fft 128 assert_equal zero_pad 128 - last_dim
def parse_logging rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--host' dest 'host' action 'store' parser.add_argument '--port' dest 'port' action 'store' parser.add_argument '--level' dest 'level' action 'store' choices ['debug' 'info' 'warning' 'error' 'critical'] args clean_args vars parser.parse_args rules parser Nonereturn args
def DER_cert_to_PEM_cert der_cert_bytes if hasattr base64 'standard_b64encode' f base64.standard_b64encode der_cert_bytes return PEM_HEADER + '\n' + textwrap.fill f 64 + '\n' + PEM_FOOTER + '\n' else return PEM_HEADER + '\n' + base64.encodestring der_cert_bytes + PEM_FOOTER + '\n'
def check_stack_complete cnxt stack current_traversal sender_id deps is_update roots set deps.roots if sender_id is_update not in roots returndef mark_complete stack_id data stack.mark_complete sender_key sender_id is_update sync_point.sync cnxt stack.id current_traversal True mark_complete roots {sender_key None}
def getComplexByMultiplierPrefix elementNode multiplier prefix valueComplex if multiplier 0.0 return valueComplexoldMultipliedValueComplex valueComplex * multiplier complexByPrefix getComplexByPrefix elementNode prefix oldMultipliedValueComplex if complexByPrefix oldMultipliedValueComplex return valueComplexreturn complexByPrefix / multiplier
def _get_chart_ajax request chart_id None div_id None 'Reportsindexpage'options json.dumps {'chart' {'renderTo' div_id 'defaultSeriesType' 'line'} 'title' {'text' 'AlexsQuestforMooshoo'} 'xAxis' {'categories' ['Apples' 'Bananas' 'Oranges']} 'yAxis' {'title' {'text' 'Howdy'}} 'series' [{'name' 'hi' 'data' 50} {'name' 'h0' 'data' 60} {'name' 'hi' 'data' 50} {'name' 'h0' 'data' 10} {'name' 'hi' 'data' 80} {'name' 'h0' 'data' 40} {'name' 'hi' 'data' 50} {'name' 'h0' 'data' 26} {'name' 'hi' 'data' 50} {'name' 'h0' 'data' 20} {'name' 'hi' 'data' 30} {'name' 'h0' 'data' 80} {'name' 'hi' 'data' 50}]} return HttpResponse options content_type settings.HARDTREE_RESPONSE_FORMATS['json']
def get_filesystem name 'default' if name not in FS_CACHE FS_CACHE[name] _make_fs name return FS_CACHE[name]
def getframeinfo frame context 1 if istraceback frame lineno frame.tb_linenoframe frame.tb_frameelse lineno frame.f_linenoif not isframe frame raise TypeError 'argisnotaframeortracebackobject' filename getsourcefile frame or getfile frame if context > 0 start lineno - 1 - context // 2 try lines lnum findsource frame except IOError lines index Noneelse start max start 1 start max 0 min start len lines - context lines lines[start start + context ]index lineno - 1 - start else lines index Nonereturn Traceback filename lineno frame.f_code.co_name lines index
def k_core G k None core_number None def k_filter v k c return c[v] > k return _core_subgraph G k_filter k core_number
def add_tag_trace thing user_line None if user_line is None user_line config.traceback.limitif user_line -1 user_line Noneskips ['theano/tensor/' 'theano\\tensor\\' 'theano/compile/' 'theano\\compile\\' 'theano/gof/' 'theano\\gof\\' 'theano/scalar/basic.py' 'theano\\scalar\\basic.py' 'theano/sandbox/' 'theano\\sandbox\\' 'theano/scan_module/' 'theano\\scan_module\\' 'theano/sparse/' 'theano\\sparse\\' 'theano/typed_list/' 'theano\\typed_list\\']if config.traceback.compile_limit > 0 skips []tr simple_extract_stack limit user_line skips skips if tr thing.tag.trace [tr]else thing.tag.trace trreturn thing
def EncodePOSIXShellArgument argument if not isinstance argument str argument str argument if _quote.search argument quote '"'else quote ''encoded quote + re.sub _escape '\\\\\\1' argument + quote return encoded
def _read_uint16 f return np.uint16 struct.unpack '>H' f.read 4 [2 4] [0]
def attach_cd session vm_ref vdi_ref userdevice vbd_ref create_vbd session vm_ref None userdevice vbd_type 'cd' read_only True bootable True empty True unpluggable False session.call_xenapi 'VBD.insert' vbd_ref vdi_ref return vbd_ref
def metadef_tag_get context namespace_name name session None session session or get_session return metadef_tag_api.get context namespace_name name session
def assert_soon condition message None max_tries 60 if not wait_for condition max_tries max_tries raise AssertionError message or ''
def change_music new_music repeat False if music and new_music is not current_music if new_music new_playlist PlayList [new_music] repeat repeat else new_playlist Nonechange_playlist new_playlist
def log_dir init if sys.platform 'darwin' name str QCoreApplication.applicationName logdir os.path.join os.path.expanduser '~/Library/Logs' name else logdir data_dir if not os.path.exists logdir os.makedirs logdir return logdir
def str2tuple s sep '/' loc s.rfind sep if loc > 0 return s[ loc] s[ loc + len sep ].upper else return s None
def test_format_pep8 pep8_checker StyleGuide files_to_check []for path in list_files '.py' rel_path os.path.relpath path pylearn2.__path__[0] if rel_path in whitelist_pep8 continueelse files_to_check.append path report pep8_checker.check_files files_to_check if report.total_errors > 0 raise AssertionError 'PEP8Formatnotrespected'
def randslice_from_slicelen slicelen listlen maxstart listlen - slicelen start randrange maxstart + 1 maxstep listlen - start // slicelen if slicelen else 1 step randrange 1 maxstep + 1 stop start + slicelen * step s slice start stop step _ _ _ control slice_indices s listlen if control ! slicelen raise RuntimeErrorreturn s
def road_stats estate None return get_stats estate estate stack 'road'
def _missing_count album return album.albumtotal or 0 - len album.items
def get_bufsize iface if __grains__['kernel'] 'Linux' if os.path.exists '/sbin/ethtool' return _get_bufsize_linux iface return {}
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def toint number if isinstance number float if number > 1 number round number 0 else number round math.ceil number 0 return int number
def create_keytab name keytab enctypes None ret {}krb_cmd 'ktadd-k{0}'.format keytab if enctypes krb_cmd + '-e{0}'.format enctypes krb_cmd + '{0}'.format name cmd __execute_kadmin krb_cmd if cmd['retcode'] ! 0 or cmd['stderr'] ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retreturn True
def get_symmetric_group_sgs n antisym False if n 1 return [] [_af_new list range 3 ] gens [Permutation n - 1 i i + 1 ._array_form for i in range n - 1 ]if antisym 0 gens [ x + [n n + 1 ] for x in gens]else gens [ x + [ n + 1 n] for x in gens]base list range n - 1 return base [_af_new h for h in gens]
def build_environment request response session store_current True environment dict _base_environment_ if not request.env request.env Storage response.models_to_run ['^\\w+\\.py$' '^%s/\\w+\\.py$' % request.controller '^%s/%s/\\w+\\.py$' % request.controller request.function ]t environment['T'] translator os.path.join request.folder 'languages' request.env.http_accept_language c environment['cache'] Cache request if store_current current.globalenv environmentcurrent.request requestcurrent.response responsecurrent.session sessioncurrent.T tcurrent.cache cif is_jython global __builtins____builtins__ mybuiltin environment['request'] requestenvironment['response'] responseenvironment['session'] sessionenvironment['local_import'] lambda name reload False app request.application local_import_aux name reload app BaseAdapter.set_folder pjoin request.folder 'databases' custom_import_install return environment
def buy_data return {}
def format_subject subject return subject.replace '\n' '\\n' .replace '\r' '\\r'
def isotime at None subsecond False if not at at timeutils.utcnow st at.strftime _ISO8601_TIME_FORMAT if not subsecond else _ISO8601_TIME_FORMAT_SUBSECOND tz at.tzinfo.tzname None if at.tzinfo else 'UTC' st + 'Z' if tz 'UTC' else tz return st
def basic_tokenizer sentence words []for space_separated_fragment in sentence.strip .split words.extend _WORD_SPLIT.split space_separated_fragment return [w for w in words if w]
def maybe_evaluate obj try return obj.__maybe_evaluate__ except AttributeError return obj
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def chuang_f1 individual total 0if individual[ -1 ] 0 for i in xrange 0 len individual - 1 4 total + inv_trap individual[i i + 4 ] else for i in xrange 0 len individual - 1 4 total + trap individual[i i + 4 ] return total
def poi_type return s3_rest_controller
def remove_refct_pairs bb didsomething Truewhile didsomething didsomething Falseincrefs {}decrefs {}for inst in bb.instructions if isinstance inst lc.CallOrInvokeInstruction fname inst.called_function.nameif fname 'Py_IncRef' arg inst.operands[0]increfs[arg] instelif fname 'Py_DecRef' arg inst.operands[0]decrefs[arg] instfor val in increfs.keys if val in decrefs increfs[val].erase_from_parent decrefs[val].erase_from_parent didsomething True
def get_ipdir ipdir pjoin os.path.dirname __file__ os.pardir ipdir os.path.abspath ipdir cd ipdir if not os.path.isdir 'IPython' and os.path.isfile 'setup.py' raise SystemExit 'Invalidipythondirectory %s' % ipdir return ipdir
def validate_filter filter return filter in CONF.filter_scheduler.enabled_filters
def add_tenant_user_role request tenant_id user_id role_id return keystoneclient request admin True .roles.add_user_role user_id role_id tenant_id
def demo print_times True print_grammar False print_trees True trace 2 sent 'IsawJohnwithadogwithmycookie' numparses 5 import sys timefrom nltk.parse.chart import demo_grammargrammar demo_grammar if print_grammar print '*Grammar' print grammar print '*Sentence ' print sent tokens sent.split print tokens print earley EarleyChartParser grammar trace trace t time.clock chart earley.chart_parse tokens parses list chart.parses grammar.start t time.clock - t if numparses assert len parses numparses 'Notallparsesfound'if print_trees for tree in parses print tree else print 'Nrtrees ' len parses if print_times print 'Time ' t
def in6_getha prefix r in6_and inet_pton socket.AF_INET6 prefix in6_cidr2mask 64 r in6_or r inet_pton socket.AF_INET6 ' fdff ffff ffff fffe' return inet_ntop socket.AF_INET6 r
def RandomSum dists total sum dist.Random for dist in dists return total
def sdm_monomial_mul M X return M[0] + monomial_mul X M[1 ]
def sql_flush style connection only_django False reset_sequences True allow_cascade False if only_django tables connection.introspection.django_table_names only_existing True include_views False else tables connection.introspection.table_names include_views False seqs connection.introspection.sequence_list if reset_sequences else statements connection.ops.sql_flush style tables seqs allow_cascade return statements
def validate_is_mapping option value if not isinstance value collections.Mapping raise TypeError '%smustbeaninstanceofdict bson.son.SON orothertypethatinheritsfromcollections.Mapping' % option
def get_cwd p subprocess.Popen ['pwd'] stdout subprocess.PIPE shell True return p.communicate [0].strip
def echo_instancemethod klass method write sys.stdout.write mname method_name method never_echo '__str__' '__repr__' if mname in never_echo passelif is_classmethod method klass setattr klass mname classmethod echo method.__func__ write else setattr klass mname echo method write
def subArray data offset shape stride data data[offset ]shape tuple shape stride tuple stride extraShape data.shape[1 ]for i in range len shape mask slice None * i + slice None shape[i] * stride[i] newShape shape[ i + 1 ]if i < len shape - 1 newShape + stride[i] newShape + extraShapedata data[mask]data data.reshape newShape return data
def image_member_delete context memb_id session None session session or get_session member_ref _image_member_get context memb_id session _image_member_delete context member_ref session
def dup_primitive f K if not f return K.zero f cont dup_content f K if K.is_one cont return cont f else return cont dup_quo_ground f cont K
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def handler_url block handler_name suffix '' query '' thirdparty False view_name 'xblock_handler'if handler_name func getattr block.__class__ handler_name None if not func raise ValueError '{!r}isnotafunctionname'.format handler_name if thirdparty view_name 'xblock_handler_noauth'url reverse view_name kwargs {'course_id' unicode block.location.course_key 'usage_id' quote_slashes unicode block.scope_ids.usage_id .encode 'utf-8' 'handler' handler_name 'suffix' suffix} if not suffix url url.rstrip '/' if query url + '?' + query if thirdparty scheme 'https' if settings.HTTPS 'on' else 'http' url '{scheme} //{host}{path}'.format scheme scheme host settings.SITE_NAME path url return url
def _add_billed_op_to_trace trace num_ops op if num_ops billed_op trace.add_billed_ops billed_op.set_num_ops num_ops billed_op.set_op op
def format_acl_v1 groups None referrers None header_name None groups referrers groups or [] referrers or [] referrers [ '.r %s' % r for r in referrers]result ' '.join groups + referrers return clean_acl header_name result if header_name else result
def get_labels_url return '{base_url}/{owner}/{repo}/labels'.format **API_PARAMS
def require_jinja2 test_func test_func skipIf jinja2 is None 'thistestrequiresjinja2' test_func test_func override_settings TEMPLATES [{'BACKEND' 'django.template.backends.django.DjangoTemplates' 'APP_DIRS' True} {'BACKEND' 'django.template.backends.jinja2.Jinja2' 'APP_DIRS' True 'OPTIONS' {'keep_trailing_newline' True}}] test_func return test_func
def sort_otu_table_by_mapping_field otu_table_data mapping_file_data sort_field sort_f natsort mapping_data header_data comments mapping_file_datamapping_field_index header_data.index sort_field sorted_sample_ids [ e[mapping_field_index] e[0] for e in mapping_data]sorted_sample_ids sort_f sorted_sample_ids sorted_sample_ids [e[1] for e in sorted_sample_ids]return sort_otu_table otu_table_data sorted_sample_ids
def _HasIOSTarget targets for target_dict in targets.values for config in target_dict['configurations'].values if config.get 'xcode_settings' {} .get 'IPHONEOS_DEPLOYMENT_TARGET' return Truereturn False
def get_cup_metric name for metric in cup_metrics if metric.__name__.lower name.lower return metricraise AttributeError
def time_to_datetime x if isinstance x time return datetime.combine date 1970 1 1 x return x
def onReadyForShutDown INFO_MSG 'onReadyForShutDown ' return True
def get_factory return random.choice [DogFactory CatFactory]
def cumNorm xx sd thresh chance 0.5 xx numpy.asarray xx y special.erf xx - thresh / numpy.sqrt 2 * sd + 1 * 0.5 y y * 1 - chance + chance return y
def register linter linter.register_checker ExceptionsChecker linter
def intword value try value int value except TypeError ValueError return valueif value < 1000000 return valueif value < 1000000000 new_value value / 1000000.0 return ungettext '% value .1fmillion' '% value .1fmillion' new_value % {'value' new_value} if value < 1000000000000 new_value value / 1000000000.0 return ungettext '% value .1fbillion' '% value .1fbillion' new_value % {'value' new_value} if value < 1000000000000000 new_value value / 1000000000000.0 return ungettext '% value .1ftrillion' '% value .1ftrillion' new_value % {'value' new_value} return value
def is_valid_lval t if not is_internal t and is_lval t and t not in RESERVED_NAMES return Truereturn False
def ubuntu module release module.params['release']stream module.params['stream']store module.params['store']arch module.params['arch']region module.params['region']virt module.params['virt']url get_ubuntu_url release stream req get_url module url reader csv.reader req delimiter ' DCTB ' try ami aki ari tag serial lookup_ubuntu_ami reader release stream store arch region virt module.exit_json changed False ami ami aki aki ari ari tag tag serial serial except KeyError module.fail_json msg 'NomatchingAMIfound'
def _ensure_decoded s if isinstance s np.bytes_ bytes s s.decode pd.get_option 'display.encoding' return s
def test_add_array_odd_shape large_test_array np.zeros 11 11 small_test_array np.ones 5 5 large_test_array_ref large_test_array.copy large_test_array_ref[3 8 3 8] + small_test_arrayadded_array add_array large_test_array small_test_array 5 5 assert np.all added_array large_test_array_ref
def remote_args remote local_branch u'' remote_branch u'' ff_only False force False no_ff False tags False rebase False pull False push False set_upstream False args [remote]what refspec_arg local_branch remote_branch pull push if what args.append what kwargs {u'verbose' True}if pull if rebase kwargs[u'rebase'] Trueelif ff_only kwargs[u'ff_only'] Trueelif no_ff kwargs[u'no_ff'] Trueelif force kwargs[u'force'] Trueif push and set_upstream kwargs[u'set_upstream'] Trueif tags kwargs[u'tags'] Truereturn args kwargs
def s3_get_extension request None if request is None request current.requestextension request.extensionif request.function 'ticket' and request.controller 'admin' extension 'html'elif 'format' in request.get_vars ext request.get_vars.formatif isinstance ext list ext ext[ -1 ]extension ext.lower or extension else ext Nonefor arg in request.args[ -1 ] if '.' in arg ext arg.rsplit '.' 1 [1].lower breakif ext extension extreturn extension
def cors_enabled origin methods ['GET'] def decorator f @wraps f def decorated_func request *args **kwargs if request.method 'OPTIONS' if 'HTTP_ACCESS_CONTROL_REQUEST_METHOD' in request.META and 'HTTP_ACCESS_CONTROL_REQUEST_HEADERS' in request.META response http.HttpResponse response['Access-Control-Allow-Methods'] ' '.join methods response['Access-Control-Allow-Headers'] request.META['HTTP_ACCESS_CONTROL_REQUEST_HEADERS']else return http.HttpResponseBadRequest elif request.method in methods response f request *args **kwargs else return http.HttpResponseBadRequest response['Access-Control-Allow-Origin'] originreturn responsereturn decorated_funcreturn decorator
def national_significant_number numobj national_number U_EMPTY_STRINGif numobj.italian_leading_zero num_zeros numobj.number_of_leading_zerosif num_zeros is None num_zeros 1national_number U_ZERO * num_zeros national_number + str numobj.national_number return national_number
def list_commands docstring format_ if format_ 'short' return _task_names state.commands result []if docstring trailer '\n' if not docstring.endswith '\n' else '' result.append docstring + trailer header COMMANDS_HEADERif format_ 'nested' header + NESTED_REMINDERresult.append header + ' \n' c _normal_list if format_ 'normal' else _nested_list state.commands result.extend c return result
def get_child_nodes node return list iter_child_nodes node
def str_pad arr width side 'left' fillchar '' if not isinstance fillchar compat.string_types msg 'fillcharmustbeacharacter not{0}'raise TypeError msg.format type fillchar .__name__ if len fillchar ! 1 raise TypeError 'fillcharmustbeacharacter notstr' if not is_integer width msg 'widthmustbeofintegertype not{0}'raise TypeError msg.format type width .__name__ if side 'left' f lambda x x.rjust width fillchar elif side 'right' f lambda x x.ljust width fillchar elif side 'both' f lambda x x.center width fillchar else raise ValueError 'Invalidside' return _na_map f arr
def compute_q_noisy_max counts noise_eps winner np.argmax counts counts_normalized noise_eps * counts - counts[winner] counts_rest np.array [counts_normalized[i] for i in xrange len counts if i ! winner ] q 0.0for c in counts_rest gap - c q + gap + 2.0 / 4.0 * math.exp gap return min q 1.0 - 1.0 / len counts
def _third_party_login_url backend_name auth_entry redirect_url None params [ 'auth_entry' auth_entry ]if redirect_url params.append 'next' redirect_url return u'{url}?{params}'.format url reverse 'social begin' kwargs {'backend' backend_name} params urllib.urlencode params
def m_assign llst rlst lslices rslices if atomp rlst return rlstrlst [m_assign l r lslices[1 ] rslices[1 ] for l r in zip llst[lslices[0]] rlst[rslices[0]] ]llst[lslices[0]] rlstreturn llst
def DACrange n return numpy.arange 0.0 256.0 255.0 / n - 1 .astype numpy.uint8
def diff_expression tracked gitcmds.tracked_branch current gitcmds.current_branch if tracked and current ref tracked + u'..' + current else ref u'origin/master..'difftool.diff_expression qtutils.active_window ref
def in_list list_possible_values def validate key data errors context if not data[key] in list_possible_values raise Invalid '"{0}"isnotavalidparameter'.format data[key] return validate
def _do_mb_post path body return _mb_request path 'POST' AUTH_YES True body body
def newey_west m max_lags nobs df nw_overlap False Xeps np.dot m.T m for lag in range 1 max_lags + 1 auto_cov np.dot m[ - lag ].T m[lag ] weight lag / max_lags + 1 if nw_overlap weight 0bb auto_cov + auto_cov.T dd 1 - weight * bb Xeps + ddXeps * nobs / nobs - df if nw_overlap and not is_psd Xeps new_max_lags int np.ceil max_lags * 1.5 return newey_west m new_max_lags nobs df return Xeps
def load_qiime_config qiime_config_filepaths []qiime_project_dir get_qiime_project_dir qiime_config_filepaths.append qiime_project_dir + '/qiime/support_files/qiime_config' qiime_config_env_filepath getenv 'QIIME_CONFIG_FP' if qiime_config_env_filepath qiime_config_filepaths.append qiime_config_env_filepath home_dir getenv 'HOME' if home_dir qiime_config_home_filepath home_dir + '/.qiime_config' qiime_config_filepaths.append qiime_config_home_filepath qiime_config_files []for qiime_config_filepath in qiime_config_filepaths if exists qiime_config_filepath qiime_config_files.append open qiime_config_filepath qiime_config parse_qiime_config_files qiime_config_files qiime_config['pick_otus_reference_seqs_fp'] qiime_config['pick_otus_reference_seqs_fp'] or get_reference_sequences qiime_config['pynast_template_alignment_fp'] qiime_config['pynast_template_alignment_fp'] or get_template_alignment qiime_config['assign_taxonomy_reference_seqs_fp'] qiime_config['assign_taxonomy_reference_seqs_fp'] or get_reference_sequences qiime_config['assign_taxonomy_id_to_taxonomy_fp'] qiime_config['assign_taxonomy_id_to_taxonomy_fp'] or get_reference_taxonomy temp_dir qiime_config['temp_dir'] or tempfile.gettempdir if not temp_dir.endswith os.sep temp_dir + os.sepqiime_config['temp_dir'] temp_dirreturn qiime_config
def process_multipart_form_data entity process_multipart entity kept_parts []for part in entity.parts if part.name is None kept_parts.append part else if part.filename is None value part.fullvalue else value partif part.name in entity.params if not isinstance entity.params[part.name] list entity.params[part.name] [entity.params[part.name]]entity.params[part.name].append value else entity.params[part.name] valueentity.parts kept_parts
def rpartition s t i s.rfind t if i ! -1 return s[ i] s[ i + len t ] return '' s
def parse_args parser argparse.ArgumentParser parser.add_argument '--profile-tool' metavar 'TOOL' action 'store' choices ['kcachegrind' 'snakeviz' 'gprof2dot' 'none'] default 'snakeviz' help 'Thetooltousetoviewtheprofilingdata' parser.add_argument '--profile-file' metavar 'FILE' action 'store' help 'Thefilenametousewith--profile-tool none' return parser.parse_known_args
def requote_uri uri return quote unquote_unreserved uri safe "!#$%&' *+ / ; ?@[]~"
def fudge_headers response stats if not stats add_never_cache_headers response else seven_days 60 * 60 * 24 * 7 patch_cache_control response max_age seven_days
def shuffleArray inArray shuffleAxis -1 seed None if seed is not None numpy.random.seed seed inArray numpy.array inArray 'O' rndArray numpy.random.random inArray.shape newIndices numpy.argsort rndArray shuffleAxis return numpy.take inArray newIndices
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def matrix_eye n **options format options.get 'format' 'sympy' if format 'sympy' return eye n elif format 'numpy' return _numpy_eye n elif format 'scipy.sparse' return _scipy_sparse_eye n raise NotImplementedError 'Invalidformat %r' % format
def get_fake_volume return {'id' '114774fb-e15a-4fae-8ee2-c9723e3645ef' 'size' 1 'volume_name' 'lun1' 'host' 'hostname@backend#DDP' 'os_type' 'linux' 'provider_location' 'lun1' 'name_id' '114774fb-e15a-4fae-8ee2-c9723e3645ef' 'provider_auth' 'providerab' 'project_id' 'project' 'display_name' None 'display_description' 'lun1' 'volume_type_id' None 'migration_status' None 'attach_status' fields.VolumeAttachStatus.DETACHED}
def validate_email trans email user None check_dup True message ''if user and user.email email return messageif not VALID_EMAIL_RE.match email message 'Theformatoftheemailaddressisnotcorrect.'elif len email > EMAIL_MAX_LEN message 'Emailaddresscannotbemorethan%dcharactersinlength.' % EMAIL_MAX_LEN elif check_dup and trans.sa_session.query trans.app.model.User .filter_by email email .first message 'Userwiththatemailalreadyexists.'elif trans.app.config.blacklist_content is not None domain email.split '@' [1]if len domain.split '.' > 2 domain '.'.join domain.split '.' [ -2 ] if domain in trans.app.config.blacklist_content message 'Pleaseenteryourpermanentemailaddress.'return message
def cpu_times user nice system idle irq cext.cpu_times return scputimes user nice system idle irq
def _parse_key key splt key.split '\\' hive splt.pop 0 key '\\'.join splt return hive key
def do_flash message category None if config_value 'FLASH_MESSAGES' flash message category
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def _patch_objects layout_attribute_paths []for node path in utils.node_generator GRAPH_REFERENCE if any [ key in path for key in GRAPH_REFERENCE['defs']['metaKeys']] continueif path and path[ -1 ] 'layoutAttributes' layout_attribute_paths.append path for trace_name in TRACE_NAMES OBJECTS[trace_name] {'meta_paths' [ 'traces' trace_name ] 'attribute_paths' [ 'traces' trace_name 'attributes' ] 'additional_attributes' {}}OBJECTS['layout'] {'meta_paths' [ 'layout' ] 'attribute_paths' layout_attribute_paths 'additional_attributes' {}}figure_attributes {'layout' {'role' 'object'} 'data' {'role' 'object' '_isLinkedToArray' True} 'frames' {'role' 'object' '_isLinkedToArray' True}}OBJECTS['figure'] {'meta_paths' [] 'attribute_paths' [] 'additional_attributes' figure_attributes}
def _htmlentity_transform entity_with_semicolon entity entity_with_semicolon[ -1 ]if entity in compat_html_entities.name2codepoint return compat_chr compat_html_entities.name2codepoint[entity] if entity_with_semicolon in compat_html_entities_html5 return compat_html_entities_html5[entity_with_semicolon]mobj re.match u'# x[0-9a-fA-F]+|[0-9]+ ' entity if mobj is not None numstr mobj.group 1 if numstr.startswith u'x' base 16numstr u'0%s' % numstr else base 10try return compat_chr int numstr base except ValueError passreturn u'&%s;' % entity
def _escape_json_for_js json_dumps_string json_dumps_string json_dumps_string.replace '&' '\\u0026' json_dumps_string json_dumps_string.replace '>' '\\u003e' json_dumps_string json_dumps_string.replace '<' '\\u003c' return json_dumps_string
def create_mig gce params changed Falsereturn_data []actions_filter ['CREATING']mig gce.ex_create_instancegroupmanager name params['name'] size params['size'] template params['template'] zone params['zone'] if mig changed Truereturn_data _get_instance_list mig filter_list actions_filter return changed return_data
def test_cache_deactivated_metadata_file config_stub tmpdir config_stub.data {'storage' {'cache-size' 1024} 'general' {'private-browsing' True}}disk_cache cache.DiskCache str tmpdir assert disk_cache.fileMetaData 'foo' QNetworkCacheMetaData
def global_config append None **kwargs duplicated_source_action kwargs.get 'duplicated_source_action' if duplicated_source_action not in __DUPLICATED_SOURCE_ACTION_VALUES console.error_exit 'Invalidglobal_config.duplicated_source_actionvalue canonlybein%s' % __DUPLICATED_SOURCE_ACTION_VALUES blade_config.update_config 'global_config' append kwargs
def _get_quote_indices line escaped indices quote_index [] -1 for _ in range 2 quote_index line.find '"' quote_index + 1 if escaped while quote_index > 1 and line[ quote_index - 1 ] '\\' quote_index line.find '"' quote_index + 1 indices.append quote_index return tuple indices
def hcluster features distfcn L2dist distances {}node [ClusterLeafNode array f id i for i f in enumerate features ]while len node > 1 closest float 'Inf' for ni nj in combinations node 2 if ni nj not in distances distances[ ni nj ] distfcn ni.vec nj.vec d distances[ ni nj ]if d < closest closest dlowestpair ni nj ni nj lowestpairnew_vec ni.vec + nj.vec / 2.0 new_node ClusterNode new_vec left ni right nj distance closest node.remove ni node.remove nj node.append new_node return node[0]
def libvlc_chapter_descriptions_release p_chapters i_count f _Cfunctions.get 'libvlc_chapter_descriptions_release' None or _Cfunction 'libvlc_chapter_descriptions_release' 1 1 None None ctypes.POINTER ChapterDescription ctypes.c_uint return f p_chapters i_count
@register u'end-of-line' def end_of_line event buff event.current_bufferbuff.cursor_position + buff.document.get_end_of_line_position
def test_main2 import tempfiletempdir tempfile.mkdtemp arglist '--data-dir%s-e2--iter-num 1-v-v--tensorboard-verbose 1train5000' % tempdir arglist arglist.split '' tf.reset_default_graph ts2s CommandLine arglist arglist wfn ts2s.weights_output_fnassert os.path.exists wfn arglist '-i%spredict1234567890' % wfn arglist arglist.split '' tf.reset_default_graph ts2s CommandLine arglist arglist assert len ts2s.prediction_results[0][0] 10 os.system 'rm-rf%s' % tempdir
def stop_cassandra db_ips keyname logging.info 'StoppingCassandra...' for ip in db_ips stop_service_cmd STOP_SERVICE_SCRIPT + CASSANDRA_WATCH_NAME try utils.ssh ip keyname stop_service_cmd except subprocess.CalledProcessError logging.error 'UnabletostopCassandraon{}'.format ip
def get_cache_durations return getattr settings 'CMS_CACHE_DURATIONS' {'menus' 60 * 60 'content' 60 'permissions' 60 * 60 }
def quote c assert isinstance c bytes and len c 1 c ord c return ESCAPE + bytes HEX[ c // 16 ] HEX[ c % 16 ]
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def in_idle import sysreturn sys.stdin.__class__.__name__ in 'PyShell' 'RPCProxy'
@manager.option '-a' '--accounts' dest 'accounts' type unicode default u'all' def run_change_reporter accounts account_names _parse_accounts accounts sm_run_change_reporter account_names
def ParseStatusRewriter response location_value response.headers.getheader 'location' status_value response.headers.getheader 'status' if status_value response_status status_valuedel response.headers['status']elif location_value response_status '%dRedirecting' % httplib.FOUND else return responsestatus_parts response_status.split '' 1 response.status_code response.status_message status_parts + [''] [ 2]try response.status_code int response.status_code except ValueError response.status_code 500response.body cStringIO.StringIO 'Error Invalid"status"headervaluereturned.'
def keyfilter predicate d factory dict rv factory for k v in iteritems d if predicate k rv[k] vreturn rv
def get_check_class agentConfig check_name from config import get_os get_checks_places get_valid_check_classosname get_os checks_places get_checks_places osname agentConfig for check_path_builder in checks_places check_path check_path_builder check_name if not os.path.exists check_path continue check_is_valid check_class load_failure get_valid_check_class check_name check_path if check_is_valid return check_classlog.warning 'Failedtoloadthecheckclassfor%s.' % check_name return None
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
@task def assets ctx dev False watch False if os.getcwd ! HERE os.chdir HERE npm 'npminstall'if not dev npm + '--production'ctx.run npm echo True bower_install ctx webpack ctx clean False watch watch dev dev
def _mock_view_index model category_idx child_idx qtbot view QTreeView qtbot.add_widget view view.setModel model idx model.indexFromItem model.item category_idx .child child_idx view.setCurrentIndex idx return view
def check_mount root drive if not urllib.parse.quote_plus drive drive return Falsepath os.path.join root drive return utils.ismount path
def resnet_v2_152 inputs num_classes None is_training True global_pool True output_stride None reuse None scope 'resnet_v2_152' blocks [resnet_utils.Block 'block1' bottleneck [ 256 64 1 ] * 2 + [ 256 64 2 ] resnet_utils.Block 'block2' bottleneck [ 512 128 1 ] * 7 + [ 512 128 2 ] resnet_utils.Block 'block3' bottleneck [ 1024 256 1 ] * 35 + [ 1024 256 2 ] resnet_utils.Block 'block4' bottleneck [ 2048 512 1 ] * 3 ]return resnet_v2 inputs blocks num_classes is_training is_training global_pool global_pool output_stride output_stride include_root_block True reuse reuse scope scope
@receiver models.signals.post_save sender SkippedReverification @receiver models.signals.post_delete sender SkippedReverification def invalidate_skipped_verification_cache sender instance **kwargs cache_key SkippedReverification.cache_key_name instance.user.id unicode instance.course_id cache.delete cache_key
def gen_keys nbits p q find_p_q nbits e d calculate_keys p q nbits return p q e d
@LiquidTags.register 'graphviz' def graphviz_parser preprocessor tag markup m DOT_BLOCK_RE.search markup if m code m.group 'code' program m.group 'program' .strip output run_graphviz program code return '<spanclass "graphviz"style "text-align center;"><imgsrc "data image/png;base64 %s"></span>' % base64.b64encode output .decode 'utf-8' else raise ValueError 'Errorprocessinginput.Expectedsyntax {0}'.format SYNTAX
@register.tag u'filter' def do_filter parser token _ rest token.contents.split None 1 filter_expr parser.compile_filter u'var|%s' % rest for func unused in filter_expr.filters if getattr func u'_decorated_function' func .__name__ in u'escape' u'safe' raise TemplateSyntaxError u'"filter%s"isnotpermitted.Usethe"autoescape"taginstead.' % func.__name__ nodelist parser.parse u'endfilter' parser.delete_first_token return FilterNode filter_expr nodelist
@pytest.fixturedef remove_fake_project_dir request def fin_remove_fake_project_dir if os.path.isdir 'fake-project' utils.rmtree 'fake-project' request.addfinalizer fin_remove_fake_project_dir
@add_handler 'version' @add_handler 'verizon' def qute_version _url html jinja.render 'version.html' title 'Versioninfo' version version.version copyright qutebrowser.__copyright__ return 'text/html' html
def _log_error_and_abort ret obj ret['result'] Falseret['abort'] Trueif 'error' in obj ret['comment'] '{0}'.format obj.get 'error' return ret
def mrjob_pythonpath return os.path.abspath os.path.join os.path.dirname mrjob.__file__ '..'
def cm2pix cm monitor if not isinstance monitor monitors.Monitor msg 'cm2pixrequiresamonitors.Monitorobjectasthesecondargumentbutreceived%s'raise ValueError msg % str type monitor scrWidthCm monitor.getWidth scrSizePix monitor.getSizePix if scrSizePix is None msg 'Monitor%shasnoknownsizeinpixels SEEMONITORCENTER 'raise ValueError msg % monitor.name if scrWidthCm is None msg 'Monitor%shasnoknownwidthincm SEEMONITORCENTER 'raise ValueError msg % monitor.name return cm * scrSizePix[0] / float scrWidthCm
def getDistanceToPlaneSegment segmentBegin segmentEnd point segmentDifference segmentEnd - segmentBegin pointMinusSegmentBegin point - segmentBegin beginPlaneDot getDotProduct pointMinusSegmentBegin segmentDifference if beginPlaneDot < 0.0 return abs point - segmentBegin * abs point - segmentBegin differencePlaneDot getDotProduct segmentDifference segmentDifference if differencePlaneDot < beginPlaneDot return abs point - segmentEnd * abs point - segmentEnd intercept beginPlaneDot / differencePlaneDot interceptPerpendicular segmentBegin + segmentDifference * intercept return abs point - interceptPerpendicular * abs point - interceptPerpendicular
def _clean_string str regex ' ^[^a-zA-Z\\._]+ | [^a-zA-Z\\._0-9]+ ' replace '_' regex re.compile regex if str[0].isdigit str replace + str return regex.sub replace str
def _isfile_side_effect path return {'/tmp/foo.tar.gz' True '/tmp/out' False '/usr/bin/tar' True '/bin/tar' True '/tmp/test_extracted_tar' False}[path]
def addLineAndNewlineIfNecessary line output output.write line if len line < 1 returnif not line.endswith '\n' output.write '\n'
def getGeometryOutputByArguments arguments elementNode return getGeometryOutput None elementNode
def truncate_reverse_primer fasta_fp mapping_fp output_dir '.' truncate_option 'truncate_only' primer_mismatches 2 reverse_primers get_rev_primer_seqs open mapping_fp 'U' output_fp log_fp get_output_filepaths output_dir fasta_fp log_data truncate_rev_primers open fasta_fp 'U' open output_fp 'w' reverse_primers truncate_option primer_mismatches log_data['fasta_fp'] fasta_fplog_data['mapping_fp'] mapping_fplog_data['truncate_option'] truncate_optionlog_data['primer_mismatches'] primer_mismatcheswrite_log_file log_data open log_fp 'w'
@themes.command 'new' @click.argument 'theme_identifier' callback check_cookiecutter @click.option '--template' '-t' type click.STRING default 'https //github.com/sh4nks/cookiecutter-flaskbb-theme' help 'Pathtoacookiecuttertemplateortoavalidgitrepo.' def new_theme theme_identifier template from cookiecutter.main import cookiecutterout_dir os.path.join current_app.root_path 'themes' click.secho '[+]Creatingnewtheme{}'.format theme_identifier fg 'cyan' cookiecutter template output_dir out_dir click.secho '[+]Done.Createdin{}'.format out_dir fg 'green' bold True
def list_genres kwargs {}result util.callm '%s/%s' % 'artist' 'list_genres' kwargs return result['response']['genres']
def _multi_permission_mask mode compose lambda f g lambda *args **kwargs g f *args **kwargs return functools.reduce compose map _permission_mask mode.split u' '
def _validate_deletion lineedit bridge method text deleted rest lineedit.set_aug_text text method assert bridge._deleted[lineedit] deleted assert lineedit.aug_text rest lineedit.clear bridge.rl_yank assert lineedit.aug_text deleted + '|'
def _array_to_file_like arr fileobj if len arr 0 returnif arr.flags.contiguous try fileobj.write arr.data except TypeError passelse returnif hasattr np 'nditer' for item in np.nditer arr fileobj.write item.tostring else byteorder arr.dtype.byteorderif sys.byteorder 'little' and byteorder '>' or sys.byteorder 'big' and byteorder '<' for item in arr.flat fileobj.write item.byteswap .tostring else for item in arr.flat fileobj.write item.tostring
def pkcs_emsa_pkcs1_v1_5_encode M emLen h hLen _hashFuncParams[h][0]hFunc _hashFuncParams[h][1]H hFunc M hLeadingDigestInfo _hashFuncParams[h][2]T hLeadingDigestInfo + H tLen len T if emLen < tLen + 11 warning 'pkcs_emsa_pkcs1_v1_5_encode intendedencodedmessagelengthtooshort' return NonePS '\xff' * emLen - tLen - 3 EM '\x00' + '\x01' + PS + '\x00' + T return EM
def multi_constructor_obj loader tag_suffix node yaml_src yaml.serialize node construct_mapping node mapping loader.construct_mapping node assert hasattr mapping 'keys' assert hasattr mapping 'values' for key in mapping.keys if not isinstance key six.string_types message 'Receivednonstringobject %s askeyinmapping.' % str key raise TypeError message if '.' not in tag_suffix callable eval tag_suffix else callable try_to_import tag_suffix rval Proxy callable callable yaml_src yaml_src positionals keywords mapping return rval
def get_harris_points harrisim min_dist 10 threshold 0.1 corner_threshold harrisim.max * threshold harrisim_t harrisim > corner_threshold * 1 coords array harrisim_t.nonzero .Tcandidate_values [harrisim[ c[0] c[1] ] for c in coords]index argsort candidate_values allowed_locations zeros harrisim.shape allowed_locations[min_dist - min_dist min_dist - min_dist ] 1filtered_coords []for i in index if allowed_locations[ coords[ i 0 ] coords[ i 1 ] ] 1 filtered_coords.append coords[i] allowed_locations[ coords[ i 0 ] - min_dist coords[ i 0 ] + min_dist coords[ i 1 ] - min_dist coords[ i 1 ] + min_dist ] 0return filtered_coords
def parse_percent percent_input percent_input percent_input.rstrip u'%' try return float percent_input except ValueError raise ValueError u"shouldbeinformat'0-x%'"
def get_module_attribute module_name attr_name attr_value_if_undefined '! ABadCafe@ D15ea5e#*DeadBeef$&Fee1Dead%^'attr_value exec_statement '\nimport%sasm\nprint getattr m %r %r \n' % module_name attr_name attr_value_if_undefined if attr_value attr_value_if_undefined raise AttributeError 'Module%rhasnoattribute%r' % module_name attr_name else return attr_value
def _validate_encode_value value do_pickle flags 0stored_value valueif isinstance value str passelif isinstance value unicode stored_value value.encode 'utf-8' flags | TYPE_UNICODEelif isinstance value bool stored_value str int value flags | TYPE_BOOLelif isinstance value int stored_value str value flags | TYPE_INTelif isinstance value long stored_value str value flags | TYPE_LONGelse stored_value do_pickle value flags | TYPE_PICKLEDif len stored_value > MAX_VALUE_SIZE raise ValueError 'Valuesmaynotbemorethan%dbytesinlength;received%dbytes' % MAX_VALUE_SIZE len stored_value return stored_value flags
@not_implemented_for 'directed' def laplacian_matrix G nodelist None weight 'weight' import scipy.sparseif nodelist is None nodelist list G A nx.to_scipy_sparse_matrix G nodelist nodelist weight weight format 'csr' n m A.shapediags A.sum axis 1 D scipy.sparse.spdiags diags.flatten [0] m n format 'csr' return D - A
def remove_suffix string suffix if suffix and string.endswith suffix return string[ - len suffix ]else return string
def find predicate seq for element in seq if predicate element return elementreturn None
def get_platform_string current None if current None import syscurrent sys.platformif current.startswith 'win' or current.startswith 'linux' return 'nat'if current.startswith 'cli' return 'cli'return 'non'
def parse_region region if isinstance region type and issubclass region regions.REGION return regionif str region .isdigit return regions.REGIONS_CHOICES_ID_DICT[int region ]else region_by_slug regions.REGION_LOOKUP.get region if region_by_slug is not None return region_by_slugregion_lower region.lower for region in regions.ALL_REGIONS if unicode region.name .lower region_lower return region
def attach_ dev None cache uuid if not cache log.error 'Nocachetoattach{0}to'.format dev return Falseif dev is None res {}for dev data in status alldevs True .items if 'cache' in data res[dev] attach_ dev if len res return reselse return Nonebcache uuid dev if bcache if bcache cache log.info '{0}isalreadyattachedtobcache{1} doingnothing'.format dev cache return Noneelif not detach dev return Falselog.debug 'Attaching{0}tobcache{1}'.format dev cache if not _bcsys dev 'attach' cache 'error' 'Errorattaching{0}tobcache{1}'.format dev cache return Falsereturn _wait lambda uuid dev cache 'error' '{0}receivedattachtobcache{1} butdidnotcomply'.format dev cache
def conditional_update context model values expected_values filters include_deleted 'no' project_only False order None return IMPL.conditional_update context model values expected_values filters include_deleted project_only order
def run_cmd cmd shell False args shlex.split cmd try sp subprocess.Popen args shell shell stdout subprocess.PIPE stderr subprocess.PIPE close_fds True except OSError raise Exception 'OSerrorrunningcommand%s' % cmd output err sp.communicate rc sp.returncodeif rc ! 0 raise Exception 'Commandreturnreturncode%s error %s' % rc err return output
def getobjdir obj return [item for item in dir obj if is_text_string item ]
def test_exclusive_environment_markers eq26 InstallRequirement.from_line "Django> 1.6.10 <1.7;python_version '2.6'" ne26 InstallRequirement.from_line "Django> 1.6.10 <1.8;python_version! '2.6'" req_set RequirementSet '' '' '' session PipSession req_set.add_requirement eq26 req_set.add_requirement ne26 assert req_set.has_requirement 'Django'
def _GetLibraries spec libraries spec.get 'libraries' [] found OrderedSet unique_libraries_list []for entry in reversed libraries library re.sub '^\\-l' '' entry if not os.path.splitext library [1] library + '.lib'if library not in found found.add library unique_libraries_list.append library unique_libraries_list.reverse return unique_libraries_list
def image_show id None name None profile None g_client _auth profile ret {}if name for image in g_client.images.list if image.name name id image.idcontinueif not id return {'result' False 'comment' "UnabletoresolveimageIDforname'{0}'".format name }try image g_client.images.get id except exc.HTTPNotFound return {'result' False 'comment' 'NoimagewithID{0}'.format id }pformat pprint.PrettyPrinter indent 4 .pformatlog.debug 'Propertiesofimage{0} \n{1}'.format image.name pformat image schema image_schema profile profile if len schema.keys 1 schema schema['image']for key in schema.keys if key in image ret[key] image[key]return ret
def make_api_method func @functools.wraps func def wrapper *args **kwargs args[0]._extra_params kwargs.pop 'extra_params' None result func *args **kwargs try del args[0]._extra_paramsexcept AttributeError passreturn resultreturn wrapper
def unpackbyte b ret struct.unpack 'B' b return ret
def make_temp_file_copies file_paths for file_path in file_paths temp_file_path get_temp_file_path file_path shutil.copyfile file_path temp_file_path
def string_at ptr size -1 return _string_at ptr size
def abspath path if not isabs path path join os.getcwd path return normpath path
def get_resource_from_path path resource Falsefor adpath in ad_paths adpath os.path.join adpath '' if os.path.commonprefix [adpath path] adpath resource path.replace adpath '' 1 breakif resource relative resource.split os.path.sep if not relative[0] relative.pop 0 module relative.pop 0 return module '/'.join relative os.path.sep.join relative return None
def parse_form_data environ stream_factory None charset 'utf-8' errors 'replace' max_form_memory_size None max_content_length None cls None silent True return FormDataParser stream_factory charset errors max_form_memory_size max_content_length cls silent .parse_from_environ environ
def mindtouch_file_redirect request file_id filename attachment get_object_or_404 Attachment mindtouch_attachment_id file_id return redirect attachment.get_file_url permanent True
def betweenness_centrality G k None normalized True weight None endpoints False seed None betweenness dict.fromkeys G 0.0 if k is None nodes Gelse random.seed seed nodes random.sample G.nodes k for s in nodes if weight is None S P sigma _single_source_shortest_path_basic G s else S P sigma _single_source_dijkstra_path_basic G s weight if endpoints betweenness _accumulate_endpoints betweenness S P sigma s else betweenness _accumulate_basic betweenness S P sigma s betweenness _rescale betweenness len G normalized normalized directed G.is_directed k k return betweenness
def open_help chapter '' try current_branch get_current_branch except git.exc.InvalidGitRepositoryError current_branch 'latest'else if current_branch in DETACHED_HEAD 'master' current_branch 'latest'help_url DOC_ROOT_FMT % current_branch if chapter help_url + DOC_ROUTER.get chapter.lower '' webbrowser.open help_url
def convert_files_to_filenames answers new_answers dict for answer_id in answers.keys answer answers[answer_id]if is_list_of_files answer new_answers[answer_id] [f.name for f in answer]else new_answers[answer_id] answers[answer_id]return new_answers
def _get_tri_dist p q p0 q0 a b c dist return np.sqrt p - p0 * p - p0 * a + q - q0 * q - q0 * b + p - p0 * q - q0 * c + dist * dist
def GetCalendar client obj_store user_id device_id request callback def _OnQueryUser user calendars request['calendars']response {'calendars' []}for cal in calendars if cal['calendar_id'] 'holidays' cal_data Calendar.GetHolidaysByLocale user.locale else cal_data Calendar.GetCalendar cal['calendar_id'] response['calendars'].append {'calendar_id' cal_data.calendar_id 'year' cal['year'] 'events' cal_data.GetEvents year cal['year'] } logging.info 'GETCALENDAR user %d device %d %dcalendars eventcounts %s' % user_id device_id len calendars dict [ c['calendar_id'] len c['events'] for c in response['calendars']] callback response User.Query client user_id None _OnQueryUser
def is_path_to_egg path return get_path_to_egg path is not None
def set_shortcut context name keystr CONF.set 'shortcuts' '%s/%s' % context name keystr
def get_next_timezone_transition zone None dt None zone get_timezone zone dt _get_datetime dt .replace tzinfo None if not hasattr zone '_utc_transition_times' raise TypeError 'GiventimezonedoesnothaveUTCtransitiontimes.Thiscanhappenbecausetheoperatingsystemfallbacklocaltimezoneisusedoracustomtimezoneobject' try idx max 0 bisect_right zone._utc_transition_times dt old_trans zone._transition_info[ idx - 1 ]new_trans zone._transition_info[idx]old_tz zone._tzinfos[old_trans]new_tz zone._tzinfos[new_trans]except LookupError ValueError return Nonereturn TimezoneTransition activates zone._utc_transition_times[idx] from_tzinfo old_tz to_tzinfo new_tz reference_date dt
def file_list *packages errors []ret []cmd ['pacman' '-Ql']if len packages > 0 and os.path.exists packages[0] packages list packages cmd.extend '-r' packages.pop 0 cmd.extend packages out __salt__['cmd.run'] cmd output_loglevel 'trace' python_shell False for line in salt.utils.itertools.split out '\n' if line.startswith 'error' errors.append line else comps line.split ret.append ''.join comps[1 ] return {'errors' errors 'files' ret}
def generateIBP customers alpha 10 reducedprop 1.0 _lambda alpha * sum 1.0 / array list range 1 customers + 1 alpha / reducedpropmaxdishes int _lambda + sqrt _lambda * 2 + 1 res zeros customers maxdishes dtype bool stickprops beta alpha 1 maxdishes currentstick 1.0dishesskipped 0for i nu in enumerate stickprops currentstick * nudishestaken rand customers < currentstick * reducedprop if sum dishestaken > 0 res[ i - dishesskipped ] dishestakenelse dishesskipped + 1return res[ maxdishes - dishesskipped ]
def random_password_generator characters string.letters + string.digits pwd_size constants.PASSWORD_SIZEreturn ''.join random.choice characters for x in range pwd_size
def clean_orphaned_instances xenapi orphaned_instances for vm_ref vm_rec instance in orphaned_instances if CONF.verbose print 'CLEANINGINSTANCE %s ' % instance.name cleanup_instance xenapi instance vm_ref vm_rec
def gen_data p batch_size BATCH_SIZE data in_text return_target True x np.zeros batch_size SEQ_LENGTH vocab_size y np.zeros batch_size for n in range batch_size ptr nfor i in range SEQ_LENGTH x[ n i char_to_ix[data[ p + ptr + i ]] ] 1.0if return_target y[n] char_to_ix[data[ p + ptr + SEQ_LENGTH ]]return x np.array y dtype 'int32'
def _pshell_json cmd cwd None cmd 'Import-ModuleServerManager;{0}'.format cmd if 'convertto-json' not in cmd.lower cmd '{0}|ConvertTo-Json'.format cmd log.debug 'PowerShell {0}'.format cmd ret __salt__['cmd.shell'] cmd shell 'powershell' cwd cwd try ret json.loads ret strict False except ValueError log.debug 'Jsonnotreturned' return ret
def _string_as_base_36 string total 0for c power in zip string[ -1 ] _powers_of_36 if 48 < ord c < 57 val ord c - 22 elif 65 < ord c < 90 val ord c - 65 elif 97 < ord c < 122 val ord c - 97 else val 0total + val * power return total
def generate_rolls num_rolls cur_state 'F'roll_seq MutableSeq '' DiceRollAlphabet state_seq MutableSeq '' DiceTypeAlphabet for roll in range num_rolls state_seq.append cur_state chance_num random.random new_roll _loaded_dice_roll chance_num cur_state roll_seq.append new_roll chance_num random.random if cur_state 'F' if chance_num < 0.05 cur_state 'L'elif cur_state 'L' if chance_num < 0.1 cur_state 'F'return roll_seq.toseq state_seq.toseq
def export_book databook return yaml.safe_dump databook._package ordered False
@app.route '/patch' methods 'PATCH' def view_patch return jsonify get_dict 'url' 'args' 'form' 'data' 'origin' 'headers' 'files' 'json'
def mavg x y window x y map _plot_friendly [x y] x_is_date _isdate x.iloc[0] if x_is_date x np.array [i.toordinal for i in x] std_err pd.rolling_std y window y pd.rolling_mean y window y1 y - std_err y2 y + std_err if x_is_date x [Timestamp.fromordinal int i for i in x]return x y y1 y2
def create_extra_classes classes {}for platform caps in EXTRA_PLATFORMS.items name '{}_{}'.format platform SeleniumTests.__name__ classdict dict SeleniumTests.__dict__ classdict.update {'caps' caps} classes[name] type name SeleniumTests classdict globals .update classes
def dsa_urlopen *args **kwargs timeout setting 'SOCIAL_AUTH_URLOPEN_TIMEOUT' if timeout and 'timeout' not in kwargs kwargs['timeout'] timeoutreturn urlopen *args **kwargs
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def run _task
def service_get_by_host_and_binary context host binary return IMPL.service_get_by_host_and_binary context host binary
def p_expr_list t pass
def load_basic_system_bindings registry Registry suspend_supported Condition lambda cli suspend_to_background_supported @registry.add_binding Keys.ControlZ filter suspend_supported def _ event u'\nSuspendprocesstobackground.\n'event.cli.suspend_to_background return registry
def savepoint_commit sid using None get_connection using .savepoint_commit sid
def get_kind_from_entity_key entity_key tokens entity_key.split KEY_DELIMITER return tokens[2].split ' ' [0]
def ignore_warnings obj None category Warning if callable obj return _IgnoreWarnings category category obj else return _IgnoreWarnings category category
def _encode_maxkey name dummy0 dummy1 dummy2 return '\x7f' + name
def get_secret_token platform version global_version GLOBAL_TOKEN_VERSION token_identifier '{global_version} {platform} {version}'.format global_version global_version platform platform version version global_secret g.secrets['request_signature_secret']return versioned_hmac global_secret token_identifier global_version
def configure_context_processors app @app.context_processordef inject_flaskbb_config 'Injectsthe``flaskbb_config``configvariableintothe\ntemplates.\n'return dict flaskbb_config flaskbb_config
def read_string_table xml_source root fromstring text xml_source nodes safe_iterator root '{%s}si' % SHEET_MAIN_NS strings get_string node for node in nodes return IndexedList strings
def get_datastore session cluster datastore_regex None storage_policy None allowed_ds_types ALL_SUPPORTED_DS_TYPES datastore_ret session._call_method vutil 'get_object_property' cluster 'datastore' if not datastore_ret raise exception.DatastoreNotFound data_store_mors datastore_ret.ManagedObjectReferencedata_stores session._call_method vim_util 'get_properties_for_a_collection_of_objects' 'Datastore' data_store_mors ['summary.type' 'summary.name' 'summary.capacity' 'summary.freeSpace' 'summary.accessible' 'summary.maintenanceMode'] best_match Nonewhile data_stores best_match _select_datastore session data_stores best_match datastore_regex storage_policy allowed_ds_types data_stores session._call_method vutil 'continue_retrieval' data_stores if best_match return best_matchif storage_policy raise exception.DatastoreNotFound _ 'Storagepolicy%sdidnotmatchanydatastores' % storage_policy elif datastore_regex raise exception.DatastoreNotFound _ 'Datastoreregex%sdidnotmatchanydatastores' % datastore_regex.pattern else raise exception.DatastoreNotFound
def validate_id_is_docker_compatible value match re.match u'^[a-z0-9-]+$' value if not match raise ValidationError u'AppIDscanonlycontain[a-z0-9-].'
def validate_appname_or_none option value if value is None return valuevalidate_string option value if len value.encode 'utf-8' > 128 raise ValueError '%smustbe< 128bytes' % option return value
def select_from_attribute attribute_value path def get_path_component collection key if not isinstance collection collections.Mapping collections.Sequence raise TypeError _ "Can'ttraverseattributepath" if not isinstance key six.string_types int raise TypeError _ 'Pathcomponentsinattributesmustbestrings' return collection[key]try return six.moves.reduce get_path_component path attribute_value except KeyError IndexError TypeError return None
def _filter_hypervisor_macs instance ports hypervisor_macs if not hypervisor_macs return Noneavailable_macs set hypervisor_macs if not ports return available_macsfor port in ports.values mac port['mac_address']if mac not in hypervisor_macs LOG.debug 'Port% port smacaddress% mac sisnotinthesetofhypervisormacs % hyper_macs s.Novawilloverwritethiswithanewmacaddress.' {'port' port['id'] 'mac' mac 'hyper_macs' hypervisor_macs} instance instance else available_macs.discard mac return available_macs
def _pianobar_exists pianobar_exe shutil.which 'pianobar' if pianobar_exe return Trueelse _LOGGER.warning 'ThePandoracomponentdependsonthePianobarclient whichcannotbefound.Pleaseinstallusinginstructionsathttps //home-assistant.io/components/media_player.pandora/' return False
def metadef_property_count context namespace_name session None session session or get_session return metadef_property_api.count context namespace_name session
def owner_required f None require_owner True def decorator func @functools.wraps func def wrapper request username slug *args **kw collection get_collection request username slug if acl.check_collection_ownership request collection require_owner require_owner return func request collection username slug *args **kw else raise PermissionDeniedreturn wrapperreturn decorator f if f else decorator
def get_login_ip raw_ips file_io.read constants.LOGIN_IP_LOC ips raw_ips.split '\n' return ips[0]
def is_votable origin filepath fileobj *args **kwargs from . import is_votableif origin u'read' if fileobj is not None try result is_votable fileobj finally fileobj.seek 0 return resultelif filepath is not None return is_votable filepath elif isinstance args[0] VOTableFile VOTable return Trueelse return Falseelse return False
@with_setup prepare_stdout def test_output_level_1_error runner Runner feature_name 'error_traceback' verbosity 1 runner.run assert_stdout_lines_with_traceback '.E\n\n<Step "Givenmystepthatblowsaexception">\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line% call_line d in__call__\nret self.function self.step *args **kw \nFile"% step_file s" line10 ingiven_my_step_that_blows_a_exception\nraiseRuntimeError\nRuntimeError\n\n1feature 0passed \n2scenarios 1passed \n2steps 1failed 1passed \n\nListoffailedscenarios \nScenario ItshouldraiseanexceptiondifferentofAssertionError#tests/functional/output_features/error_traceback/error_traceback.feature 5\n\n' % {'lettuce_core_file' lettuce_path 'core.py' 'step_file' abspath lettuce_path '..' 'tests' 'functional' 'output_features' 'error_traceback' 'error_traceback_steps.py' 'call_line' call_line}
def deterministicReactorThreads worker doer createMemoryWorker class CFT object def callFromThread self f *a **k worker.do lambda f *a **k return CFT doer
def test_rgb_to_hsl_part_9 assert rgb_to_hsl 102 153 102 120 20 50 assert rgb_to_hsl 51 204 51 120 60 50 assert rgb_to_hsl 0 255 0 120 100 50
def immediateAssignmentExtended StartingTime_presence 0 a L2PseudoLength b TpPd pd 6 c MessageType mesType 57 d PageModeAndSpareHalfOctets f ChannelDescription g RequestReference h TimingAdvance i MobileAllocation packet a / b / c / d / f / g / h / i if StartingTime_presence is 1 j StartingTimeHdr ieiST 124 eightBitST 0 packet packet / j k IaxRestOctets packet packet / k return packet
def hello_plugin return u'HelloWorld thisisservedfromanextension'
def correlate_eye_world eye_timestamps world_timestamps e_ts eye_timestampsw_ts list world_timestamps eye_frames_by_timestamp dict zip e_ts range len e_ts eye_timestamps_by_world_index [[] for i in world_timestamps]frame_idx 0try current_e_ts e_ts.pop 0 except logger.warning 'Noeyetimestampsfound.' return eye_timestamps_by_world_indexwhile e_ts try t_between_frames w_ts[frame_idx] + w_ts[ frame_idx + 1 ] / 2.0 except IndexError breakif current_e_ts < t_between_frames eye_timestamps_by_world_index[frame_idx].append current_e_ts current_e_ts e_ts.pop 0 else frame_idx + 1idx 0eye_world_frame_map []for candidate world_ts in zip eye_timestamps_by_world_index w_ts if not candidate e_past_ts get_past_timestamp idx eye_timestamps_by_world_index e_future_ts get_future_timestamp idx eye_timestamps_by_world_index eye_world_frame_map.append eye_frames_by_timestamp[get_nearest_timestamp e_past_ts e_future_ts world_ts ] else eye_world_frame_map.append eye_frames_by_timestamp[eye_timestamps_by_world_index[idx][ -1 ]] idx + 1return eye_world_frame_map
def parse_auth entries raise_on_error False conf {}for registry entry in six.iteritems entries if not isinstance entry dict log.debug 'Configentryforkey{0}isnotauthconfig'.format registry if raise_on_error raise errors.InvalidConfigFile 'Invalidconfigurationforregistry{0}'.format registry return {}if 'identitytoken' in entry log.debug 'FoundanIdentityTokenentryforregistry{0}'.format registry conf[registry] {'IdentityToken' entry['identitytoken']}continueif 'auth' not in entry log.debug 'Authdatafor{0}isabsent.Clientmightbeusingacredentialsstoreinstead.' conf[registry] {}continue username password decode_auth entry['auth'] log.debug 'Foundentry registry {0} username {1} '.format repr registry repr username conf[registry] {'username' username 'password' password 'email' entry.get 'email' 'serveraddress' registry}return conf
def _iter_relative_dirs dirname if not dirname dirname os.curdirtry files_or_dirs os.listdir dirname except os.error returnfor file_or_dir in files_or_dirs yield file_or_dir path os.path.join dirname file_or_dir for sub_file_or_dir in _iter_relative_dirs path yield os.path.join file_or_dir sub_file_or_dir
@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_GETdef look_up_registration_code request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id code request.GET.get 'registration_code' course get_course_by_id course_key depth 0 try registration_code CourseRegistrationCode.objects.get code code except CourseRegistrationCode.DoesNotExist return JsonResponse {'is_registration_code_exists' False 'is_registration_code_valid' False 'is_registration_code_redeemed' False 'message' _ 'Theenrollmentcode {code} wasnotfoundforthe{course_name}course.' .format code code course_name course.display_name } status 400 reg_code_already_redeemed RegistrationCodeRedemption.is_registration_code_redeemed code registration_code_detail_url reverse 'registration_code_details' kwargs {'course_id' unicode course_id } return JsonResponse {'is_registration_code_exists' True 'is_registration_code_valid' registration_code.is_valid 'is_registration_code_redeemed' reg_code_already_redeemed 'registration_code_detail_url' registration_code_detail_url}
def to_int_repr clauses symbols symbols dict list zip symbols list range 1 len symbols + 1 def append_symbol arg symbols if arg.func is Not return - symbols[arg.args[0]] else return symbols[arg]return [set append_symbol arg symbols for arg in Or.make_args c for c in clauses]
def print_numa_stats numafiles for numafilename in numafiles numafile open numafilename node_id int numafile.name[ numafile.name.find '/node/node' + 10 -9 ] ts int time.time stats dict line.split for line in numafile.read .splitlines for stat tag in 'numa_hit' 'hit' 'numa_miss' 'miss' print 'sys.numa.zoneallocs%d%snode %dtype %s' % ts stats[stat] node_id tag print 'sys.numa.foreign_allocs%d%snode %d' % ts stats['numa_foreign'] node_id for stat tag in 'local_node' 'local' 'other_node' 'remote' print 'sys.numa.allocation%d%snode %dtype %s' % ts stats[stat] node_id tag print 'sys.numa.interleave%d%snode %dtype hit' % ts stats['interleave_hit'] node_id numafile.close
def parse_block_scalar_empty_line IndentTokenClass ContentTokenClass def callback lexer match context text match.group if context.block_scalar_indent is None or len text < context.block_scalar_indent if text yield match.start IndentTokenClass text else indentation text[ context.block_scalar_indent]content text[context.block_scalar_indent ] yield match.start IndentTokenClass indentation yield match.start + context.block_scalar_indent ContentTokenClass content context.pos match.end return callback
def test_status_bar backup views._status_bar_viewsviews._status_bar_views []c make_logged_in_client views.register_status_bar_view lambda _ HttpResponse 'foo' status 200 views.register_status_bar_view lambda _ HttpResponse 'bar' views.register_status_bar_view lambda _ None def f r raise Exception views.register_status_bar_view f response c.get '/desktop/status_bar' assert_equal 'foobar' response.content views._status_bar_views backup
def get_html_img scene byte_array QByteArray filename QBuffer byte_array filename.open QIODevice.WriteOnly PngFormat.write filename scene img_encoded byte_array.toBase64 .data .decode 'utf-8' return "<imgsrc 'data image/png;base64 %s'/>" % img_encoded
def generate_dependency_paths name packages_dir os.path.join st_dir u'Packages' dependency_dir os.path.join packages_dir name ver u'st%s' % st_version plat sublime.platform arch sublime.arch return {'all' os.path.join dependency_dir 'all' 'ver' os.path.join dependency_dir ver 'plat' os.path.join dependency_dir u'%s_%s' % ver plat 'arch' os.path.join dependency_dir u'%s_%s_%s' % ver plat arch }
def conv_input_length output_length filter_size border_mode stride if output_length is None return Noneassert border_mode in {'same' 'valid' 'full'} if border_mode 'same' pad filter_size // 2 elif border_mode 'valid' pad 0elif border_mode 'full' pad filter_size - 1 return output_length - 1 * stride - 2 * pad + filter_size
def int_to_base36 i digits u'0123456789abcdefghijklmnopqrstuvwxyz'factor 0if i < 0 raise ValueError u'Negativebase36conversioninput.' if six.PY2 if not isinstance i six.integer_types raise TypeError u'Non-integerbase36conversioninput.' if i > sys.maxint raise ValueError u'Base36conversioninputtoolarge.' while True factor + 1if i < 36 ** factor factor - 1breakbase36 []while factor > 0 j 36 ** factor base36.append digits[ i // j ] i i % j factor - 1return u''.join base36
def exp msg t None obj None root.log msg level EXP t t obj obj
def check_is_right name lhs rhs _split_left_right name if lhs.endswith u'/2' return Trueelif rhs.startswith u'2 ' return Trueelif rhs.endswith u'/2' return Truereturn False
def validate_plugin plugin if plugin not in plugin_manager.all_plugins.keys raise FlaskBBCLIError 'Plugin{}notfound.'.format plugin fg 'red' return True
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def pol2cart theta radius units 'deg' if units in 'deg' 'degs' theta theta * numpy.pi / 180.0 xx radius * numpy.cos theta yy radius * numpy.sin theta return xx yy
@pytest.mark.parametrize units_attr_args [x for x in units_attr_sets if x[0] in u'spherical' u'unitspherical' ] def test_galactic_spherical_two_components repr_name unit1 unit2 unit3 cls2 attr1 attr2 attr3 representation c1 c2 c3 sc Galactic 1000 * c1 * u.Unit unit1 / 1000 cls2 c2 unit unit2 representation representation assert_quantities_allclose sc c1 * unit1 c2 * unit2 attr1 attr2 sc Galactic c1 * unit1 c2 * unit2 representation representation assert_quantities_allclose sc c1 * unit1 c2 * unit2 attr1 attr2 kwargs {attr1 c1 * unit1 attr2 c2 * unit2 }sc Galactic representation representation **kwargs assert_quantities_allclose sc c1 * unit1 c2 * unit2 attr1 attr2
@step 'Iwillanswerallpromptswith" [^"]* "' def i_answer_prompts_with step prompt world.browser.execute_script 'window.prompt function {return%s;}' % prompt
def is_course_in_block_structure_cache course_key store course_usage_key store.make_course_usage_key course_key return BlockStructureCache get_cache .get course_usage_key is not None
def _is_int string try int string return Trueexcept ValueError return False
def referrer_allowed referrer referrer_acl allow Falseif referrer_acl rhost urlparse referrer or '' .hostname or 'unknown' for mhost in referrer_acl if mhost[0] '-' mhost mhost[1 ]if mhost rhost or mhost[0] '.' and rhost.endswith mhost allow Falseelif mhost '*' or mhost rhost or mhost[0] '.' and rhost.endswith mhost allow Truereturn allow
def test_topic_move_same_forum topic assert not topic.move topic.forum
def isWithinChannel channelRadius pointIndex loop point loop[pointIndex]behindSegmentComplex loop[ pointIndex + len loop - 1 % len loop ] - point behindSegmentComplexLength abs behindSegmentComplex if behindSegmentComplexLength < channelRadius return TrueaheadSegmentComplex loop[ pointIndex + 1 % len loop ] - point aheadSegmentComplexLength abs aheadSegmentComplex if aheadSegmentComplexLength < channelRadius return TruebehindSegmentComplex / behindSegmentComplexLengthaheadSegmentComplex / aheadSegmentComplexLengthabsoluteZ getDotProductPlusOne aheadSegmentComplex behindSegmentComplex if behindSegmentComplexLength * absoluteZ < channelRadius return Truereturn aheadSegmentComplexLength * absoluteZ < channelRadius
def __newobj_ex__ cls args kwargs return cls.__new__ cls *args **kwargs
def volunteer_cluster return s3_rest_controller
def message_detail request slug topic_id message_id template_name 'groups/messages/message_detail.html' group get_object_or_404 Group slug slug is_active True topic get_object_or_404 GroupTopic pk topic_id is_active True message get_object_or_404 GroupMessage pk message_id is_active True return render request template_name {'group' group 'topic' topic 'message' message}
def get_file_mode path return stat.S_IMODE os.stat path .st_mode
def get_key_value_store name kvs_region None global KEY_VALUE_STORE_REGISTRY_register_backends key_value_store KEY_VALUE_STORE_REGISTRY.get name if key_value_store is None if kvs_region is None kvs_region region.make_region name name key_value_store KeyValueStore kvs_region KEY_VALUE_STORE_REGISTRY[name] key_value_storereturn key_value_store
def matching_dict_to_set matching return set map frozenset matching.items
def gf_Qmatrix f p K n r gf_degree f int p q [K.one] + [K.zero] * n - 1 Q [list q ] + [[]] * n - 1 for i in range 1 n - 1 * r + 1 qq c [ - q[ -1 ] * f[ -1 ] % p ] q[ -1 ] for j in range 1 n qq.append q[ j - 1 ] - c * f[ - j - 1 ] % p if not i % r Q[ i // r ] list qq q qqreturn Q
def generate_resource_file target source env src_path str source[0] new_src_path str target[0] cmd 'xxd-i%s|sed-e"s/^unsignedchar/constcharRESOURCE_/g"-e"s/^unsignedint/constunsignedintRESOURCE_/g">%s' % src_path new_src_path p subprocess.Popen cmd env {} stdout subprocess.PIPE stderr subprocess.PIPE shell True universal_newlines True stdout stderr p.communicate if p.returncode or stderr error 'failedtogenerateresourcefile'if stderr error error + ' ' + stderr console.error_exit error return p.returncode
def safe_email email if EMAIL_REGEX.match email is not None return not email.startswith '.' and '..' not in email else logger.warning 'Invalidemailaddress %s.' email return False
def generate_all_aliases fieldfile include_global all_options aliases.all fieldfile include_global include_global if all_options thumbnailer get_thumbnailer fieldfile for key options in six.iteritems all_options options['ALIAS'] keythumbnailer.get_thumbnail options
def compute_first_bit a bits np.bitwise_and.outer a 1 << np.arange 32 bits bits.cumsum axis 1 .astype np.bool return 33 - bits.sum axis 1
def handle_del request basket line_id **kwargs return {u'ok' basket.delete_line int line_id }
def get_music *names **kwds prefix kwds.pop 'prefix' 'music' return resource_path prefix *names
def set_pipeline_timeout strategy user *args **kwargs if strategy.request and not user strategy.request.session.set_expiry strategy.setting 'PIPELINE_TIMEOUT' 600
@_docstring 'discid' def get_releases_by_discid id includes [] toc None cdstubs True media_format None params _check_filter_and_make_params 'discid' includes release_status [] release_type [] if toc params['toc'] tocif not cdstubs params['cdstubs'] 'no'if media_format params['media-format'] media_formatreturn _do_mb_query 'discid' id includes params
def digitsrep n b 10 if n < 0 return [0]dlist []while n > 0 dlist [ n % b ] + dlist n n // b return dlist
def network_get context network_id project_only 'allow_none' return IMPL.network_get context network_id project_only project_only
def rslices_ndim ndim shape iterations 5 for _ in range iterations yield tuple rslice shape[n] for n in range ndim for _ in range iterations yield tuple rslice shape[n] allow_empty True for n in range ndim yield tuple slice 0 1 0 for _ in range ndim
def parse_ignoredisk rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--drives' dest 'drives' action 'store' parser.add_argument '--only-use' dest 'only-use' action 'store' parser.add_argument '--interactive' dest 'interactive' action 'store_true' args clean_args vars parser.parse_args rules parser Nonereturn args
def R1 w m RE_R1.search w if m return w[m.end ]return ''
def maybe_utf8 value if isinstance value unicode return value.encode 'utf-8' return value
def format_arg_value arg_val arg val arg_valreturn '%s %r' % arg val
def Dispatcher env resp page util.shift_path_info env if page in DISPATCH return DISPATCH[page] env resp else status '404NotFound'headers [ 'Content-type' 'text/plain' ]resp status headers return [ 'NotFound ' + page ]
def sentence_iterator corpus_iterator current_sentence []for l in corpus_iterator if l None None if current_sentence yield current_sentence current_sentence []else sys.stderr.write 'WARNING Gotemptyinputfile/stream.\n' raise StopIterationelse current_sentence.append l if current_sentence yield current_sentence
def bind_lineedit model hint u'' class BoundLineEdit CompletionLineEdit def __init__ self hint hint parent None CompletionLineEdit.__init__ self model hint hint parent parent return BoundLineEdit
def export_patches revs summaries gitcmds.log_helper to_export select_commits N_ u'ExportPatches' revs summaries if not to_export returncmds.do cmds.FormatPatch reversed to_export reversed revs
def bucket_upload_fileobj self Fileobj Key ExtraArgs None Callback None Config None return self.meta.client.upload_fileobj Fileobj Fileobj Bucket self.name Key Key ExtraArgs ExtraArgs Callback Callback Config Config
def http_log_resp resp body if not pyrax.get_http_debug returnlog logging.getLogger 'pyrax' log.debug 'RESP %s\n%s' resp resp.headers if body log.debug 'RESPBODY %s' body
def user_by_anonymous_id uid if uid is None return Nonetry return User.objects.get anonymoususerid__anonymous_user_id uid except ObjectDoesNotExist return None
def setlocale category locale None if locale and type locale is not type '' locale normalize _build_localename locale return _setlocale category locale
def _embed_standard_shell namespace {} banner '' import codetry import readlineexcept ImportError passelse import rlcompleterreadline.parse_and_bind 'tab complete' @wraps _embed_standard_shell def wrapper namespace namespace banner '' code.interact banner banner local namespace return wrapper
def ensure_dir_exists directory if dir if not os.path.isdir directory os.makedirs directory
def randslice qs limit exclude None cnt qs.count if exclude is not None limit + 1rand 0 if limit > cnt else random.randint 0 cnt - limit slice_ list qs[rand rand + limit ] if exclude is not None slice_ [o for o in slice_ if o.pk ! exclude ][ limit - 1 ]return slice_
@register u'delete-char' def delete_char event deleted event.current_buffer.delete count event.arg if not deleted event.cli.output.bell
def get_param_list layer_list plist []for l in layer_list ptuple l.get_params plist.extend ptuple if isinstance ptuple list else plist.append ptuple return plist
def select_element cache selector element selector.elementif not element or element u'*' for elem in cache.itertag yield elem else for elem in cache.element_map[ascii_lower element ] yield elem
def mpl_image_to_rgba mpl_image image mpl_image.get_array if image.ndim 2 input_range mpl_image.norm.vmin mpl_image.norm.vmax image rescale_intensity image in_range input_range image mpl_image.cmap img_as_float image elif image.ndim 3 and image.shape[2] 3 image np.dstack image np.ones_like image return img_as_float image
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def mul a b return a * b
def getNextLinkText hypertextFiles nextIndex nextFileName 'contents.html'if nextIndex < len hypertextFiles nextFileName hypertextFiles[nextIndex]return '<ahref "%s">Next</a>' % nextFileName
def _init_non_posix vars vars['LIBDEST'] get_path 'stdlib' vars['BINLIBDEST'] get_path 'platstdlib' vars['INCLUDEPY'] get_path 'include' vars['SO'] '.pyd'vars['EXE'] '.exe'vars['VERSION'] _PY_VERSION_SHORT_NO_DOTvars['BINDIR'] os.path.dirname _safe_realpath sys.executable
def _error_msg_network option expected msg 'Invalidnetworksetting--Setting {0} Expected [{1}]'return msg.format option '|'.join expected
def get_display_name username if len username > 40 return '%s...%s' % username[ 20].strip username[ -15 ].strip return username
def pos_tag_sents sentences tagset None lang 'eng' tagger _get_tagger lang return [_pos_tag sent tagset tagger for sent in sentences]
@on_valid 'file/dynamic' def file data response **kwargs if hasattr data 'read' name data getattr data 'name' '' data elif os.path.isfile data name data data open data 'rb' else response.content_type 'text/plain'response.status HTTP_NOT_FOUNDreturn 'Filenotfound!'response.content_type mimetypes.guess_type name None [0] or 'application/octet-stream' return data
def rangename3d book ref3d coords ref3d.coordsreturn '%s!%s' % sheetrange book *coords[ 2] rangename2d *coords[2 6]
def prevent_indexing func @wraps func def _added_header request *args **kwargs response func request *args **kwargs response['X-Robots-Tag'] 'noindex'return responsereturn _added_header
def test_lambda_list_keywords_kwargs can_compile u' fn x&kwargskw listxkw ' cant_compile u' fn x&kwargsxs&kwargsys listxxsys ' can_compile u' fn &optionalx&kwargskw listxkw '
def GetRootKey return win32con.HKEY_LOCAL_MACHINE
def gettz_db_metadata if len _CLASS_ZONE_INSTANCE 0 _CLASS_ZONE_INSTANCE.append ZoneInfoFile getzoneinfofile_stream return _CLASS_ZONE_INSTANCE[0].metadata
def clean_text_by_word text deacc True text_without_acronyms replace_with_separator text '' [AB_ACRONYM_LETTERS] original_words list tokenize text_without_acronyms to_lower True deacc deacc filtered_words [join_words word_list '' for word_list in preprocess_documents original_words ]if HAS_PATTERN tags tag join_words original_words else tags Noneunits merge_syntactic_units original_words filtered_words tags return dict unit.text unit for unit in units
def _cache_key_to_dir cachedir func argument_hash parts [cachedir]if isinstance func _basestring parts.append func else parts.append _get_func_fullname func if argument_hash is not None parts.append argument_hash return os.path.join *parts
@register_specialize@register_stabilize@register_canonicalize@register_useless@gof.local_optimizer [T.alloc] def local_useless_alloc node op node.opif not isinstance op Alloc return Falseinput node.inputs[0]output node.outputs[0]if input.type output.type return [input]
def init mpstate return CmdlongModule mpstate
def win_shutdown try import win32securityimport win32apiimport ntsecurityconflags ntsecuritycon.TOKEN_ADJUST_PRIVILEGES | ntsecuritycon.TOKEN_QUERY htoken win32security.OpenProcessToken win32api.GetCurrentProcess flags id_ win32security.LookupPrivilegeValue None ntsecuritycon.SE_SHUTDOWN_NAME newPrivileges [ id_ ntsecuritycon.SE_PRIVILEGE_ENABLED ]win32security.AdjustTokenPrivileges htoken 0 newPrivileges win32api.InitiateSystemShutdown '' '' 30 1 0 finally os._exit 0
def xml_findtext xpath return all xml_find xpath getattr 'text'
def image_present name ret {'name' name 'changes' {} 'result' None 'comment' ''}if name in __salt__['imgadm.list'] ret['result'] Trueret['comment'] 'image{0}ispresent'.format name else available_images __salt__['imgadm.avail'] if name in available_images if __opts__['test'] ret['result'] Trueelse __salt__['imgadm.import'] name ret['result'] name in __salt__['imgadm.list'] ret['comment'] 'image{0}installed'.format name ret['changes'][name] available_images[name]else ret['result'] Falseret['comment'] 'image{0}doesnotexists'.format name return ret
def resolve_relative_url url environ cur_url construct_url environ with_query_string False return urlparse.urljoin cur_url url
def tupleRemoveItem tup index l list tup return tuple l[ index] + l[ index + 1 ]
def fg1eu x return x + 0.5 * np.exp -50 * x - 0.5 ** 2
@pytest.fixture scope u'function' def remove_additional_folders request def fin_remove_additional_folders if os.path.exists u'tests/test-pyhooks/inputpyhooks' utils.rmtree u'tests/test-pyhooks/inputpyhooks' if os.path.exists u'inputpyhooks' utils.rmtree u'inputpyhooks' if os.path.exists u'tests/test-shellhooks' utils.rmtree u'tests/test-shellhooks' request.addfinalizer fin_remove_additional_folders
def refresher name refreshers CompletionRefresher.refreshers def wrapper wrapped refreshers[name] wrappedreturn wrappedreturn wrapper
def generate_map map name 'url_map' map.update rules []converters []for rule in map.iter_rules trace [{'is_dynamic' is_dynamic 'data' data} for is_dynamic data in rule._trace]rule_converters {}for key converter in rule._converters.iteritems js_func js_to_url_function converter try index converters.index js_func except ValueError converters.append js_func index len converters - 1 rule_converters[key] indexrules.append {u'endpoint' rule.endpoint u'arguments' list rule.arguments u'converters' rule_converters u'trace' trace u'defaults' rule.defaults} return render_template name_parts name and name.split '.' or [] rules dumps rules converters converters
def _validate_locale locale if locale and locale not in settings.SUMO_LANGUAGES raise Http404return locale
def check_for_x_over_absX numerators denominators for den in list denominators if den.owner and den.owner.op T.abs_ and den.owner.inputs[0] in numerators if den.owner.inputs[0].type.dtype.startswith 'complex' passelse denominators.remove den numerators.remove den.owner.inputs[0] numerators.append T.sgn den.owner.inputs[0] return numerators denominators
def posify_index shape ind if isinstance ind tuple return tuple map posify_index shape ind if isinstance ind int long if ind < 0 return ind + shape else return indif isinstance ind list return [ i + shape if i < 0 else i for i in ind]return ind
def get_identity identity if isinstance identity AnonymousUser identity get_anonymous_user if isinstance identity get_user_model return identity None elif isinstance identity Group return None identity raise NotUserNorGroup u'User/AnonymousUserorGroupinstanceisrequired got%s ' % identity
def package pkg_name repos None yes None options None if not is_installed pkg_name install pkg_name repos yes options
def execute_salt_restart_task return __salt__['task.run'] name 'restart-salt-minion'
@profiler.trace@memoized_with_request list_extensions 1 def extension_supported extension_name extensions for extension in extensions if extension.name extension_name return Truereturn False
@pytest.mark.parametrize u'testframe' totest_frames def test_gcrs_altaz_sunish testframe sun get_sun testframe.obstime assert sun.frame.name u'gcrs' assert EARTHECC - 1 * u.au < sun.distance.to u.au < EARTHECC + 1 * u.au sunaa sun.transform_to testframe assert EARTHECC - 1 * u.au < sunaa.distance.to u.au < EARTHECC + 1 * u.au
def decrypt_dtc_code code dtc []current codefor i in range 0 3 if len current < 4 raise 'TriedtodecodebadDTC %s' % code tc obd_sensors.hex_to_int current[0] tc tc >> 2 if tc 0 type 'P'elif tc 1 type 'C'elif tc 2 type 'B'elif tc 3 type 'U'else raise tcdig1 str obd_sensors.hex_to_int current[0] & 3 dig2 str obd_sensors.hex_to_int current[1] dig3 str obd_sensors.hex_to_int current[2] dig4 str obd_sensors.hex_to_int current[3] dtc.append type + dig1 + dig2 + dig3 + dig4 current current[4 ]return dtc
def instanceproperty fget None fset None fdel None doc None classval None if fget is None return partial instanceproperty fset fset fdel fdel doc doc classval classval return InstanceProperty fget fget fset fset fdel fdel doc doc classval classval
def _vote_or_unvote request course_id obj value 'up' undo_vote False course_key CourseKey.from_string course_id course get_course_with_access request.user 'load' course_key user cc.User.from_django_user request.user if undo_vote user.unvote obj else user.vote obj value track_voted_event request course obj value undo_vote return JsonResponse prepare_content obj.to_dict course_key
def chordal_cycle_graph p create_using None if create_using is None create_using nx.MultiGraph elif create_using.is_directed or not create_using.is_multigraph msg '`create_using`mustbeanundirectedmultigraph.'raise nx.NetworkXError msg G create_usingG.clear for x in range p left x - 1 % p right x + 1 % p chord pow x p - 2 p if x > 0 else 0 for y in left right chord G.add_edge x y G.graph['name'] 'chordal_cycle_graph {0} '.format p return G
def delete_logged_in_cookies response for cookie_name in [settings.EDXMKTG_LOGGED_IN_COOKIE_NAME settings.EDXMKTG_USER_INFO_COOKIE_NAME] response.delete_cookie cookie_name.encode u'utf-8' path u'/' domain settings.SESSION_COOKIE_DOMAIN return response
def block_device_mapping_create context values return IMPL.block_device_mapping_create context values
def _GetScatterProperty entity_proto hash_obj _MD5_FUNC for element in entity_proto.key .path .element_list if element.has_name hash_obj.update element.name elif element.has_id hash_obj.update str element.id hash_bytes hash_obj.digest [0 2] hash_int struct.unpack 'H' hash_bytes if hash_int > _SCATTER_PROPORTION return Nonescatter_property entity_pb.Property scatter_property.set_name '__scatter__' scatter_property.set_meaning entity_pb.Property.BYTESTRING scatter_property.set_multiple False property_value scatter_property.mutable_value property_value.set_stringvalue hash_bytes return scatter_property
def GenerateURL callback object_store S3ObjectStore 'photos-viewfinder-co' upload_url object_store.GenerateUploadUrl options.options.key logging.info 'PUTURL %s' % upload_url logging.info 'GETURL %s' % object_store.GenerateUrl options.options.key callback
def _avoid_invalidating_lineage config lineage original_server latest_cert OpenSSL.crypto.load_certificate OpenSSL.crypto.FILETYPE_PEM open lineage.cert .read now_valid 'fake' not in repr latest_cert.get_issuer .lower if util.is_staging config.server if not util.is_staging original_server or now_valid if not config.break_my_certs names ' '.join lineage.names raise errors.Error "You'veaskedtorenew/replaceaseeminglyvalidcertificatewithatestcertificate domains {0} .Wewillnotdothatunlessyouusethe--break-my-certsflag!".format names
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def parse_mapping fileobj filename None extractors {}method_map []options_map {}parser RawConfigParser parser._sections odict parser._sections parser.readfp fileobj filename for section in parser.sections if section 'extractors' extractors dict parser.items section else method pattern [part.strip for part in section.split ' ' 1 ]method_map.append pattern method options_map[pattern] dict parser.items section if extractors for idx pattern method in enumerate method_map if method in extractors method extractors[method]method_map[idx] pattern method return method_map options_map
def get_mock_dir *subdirs **kwargs environ kwargs.get 'environ' or os.environ path os.path.join environ['MOCK_HADOOP_TMP'] *subdirs if not os.path.exists path os.makedirs os.path.abspath path return path
def pretty_unicode string if isinstance string six.text_type return stringtry return string.decode 'utf8' except UnicodeDecodeError return string.decode 'Latin-1' .encode 'unicode_escape' .decode 'utf8'
def list_public_ips kwargs None call None if kwargs is None kwargs {}args {}if 'state' in kwargs if kwargs['state'] 'assigned' args['ip.state'] 'Assigned'else args['ip.state'] 'Unassigned'else args['ip.state'] 'Unassigned'args['ip.type'] 'Public'response _query 'grid' 'ip/list' args args ret {}for item in response['list'] name item['ip']ret[name] itemreturn ret
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def test_build_model arguments g Expression.fromstring 'allx.man x ' alist [Expression.fromstring a for a in ['man John ' 'man Socrates ' 'man Bill ' 'somex. - x John &man x &sees John x ' 'somex. - x Bill &man x ' 'allx.somey. man x ->gives Socrates x y ']]m MaceCommand g assumptions alist m.build_model spacer print 'AssumptionsandGoal' spacer for a in alist print '%s' % a print '|-%s %s\n' % g decode_result m.build_model spacer print 'Valuation' spacer print m.valuation '\n'
def assemble name devices test_mode False **kwargs opts []for key in kwargs if not key.startswith '__' opts.append '--{0}'.format key if kwargs[key] is not True opts.append kwargs[key] if isinstance devices str devices devices.split ' ' cmd ['mdadm' '-A' name '-v'] + opts + devices if test_mode is True return cmdelif test_mode is False return __salt__['cmd.run'] cmd python_shell False
def test_sobel_vertical i j np.mgrid[ -5 6 -5 6]image j > 0 .astype float result filters.sobel image * np.sqrt 2 j[ np.abs i 5 ] 10000assert np.all result[ j 0 ] 1 assert np.all result[ np.abs j > 1 ] 0
def quopri_encode input errors 'strict' assert errors 'strict' f StringIO str input g StringIO quopri.encode f g quotetabs True output g.getvalue return output len input
def test_regression_3998 time Time u'2012-01-0100 00 00' assert time.isscalarsun get_sun time assert sun.isscalarassert sun.obstime is time
def get_instance_metadata version 'latest' url 'http //169.254.169.254' data 'meta-data/' timeout None num_retries 5 try metadata_url _build_instance_metadata_url url version data return _get_instance_metadata metadata_url num_retries num_retries timeout timeout except urllib.error.URLError boto.log.exception 'Exceptioncaughtwhentryingtoretrieveinstancemetadatafor %s' data return None
def run_on_executor fn @functools.wraps fn def wrapper self *args **kwargs callback kwargs.pop 'callback' None future self.executor.submit fn self *args **kwargs if callback self.io_loop.add_future future lambda future callback future.result return futurereturn wrapper
def standard_deviation input labels None index None return numpy.sqrt variance input labels index
def drop_stray_directories apps schema_editor Directory apps.get_model u'pootle_app.Directory' TP apps.get_model u'pootle_translationproject.TranslationProject' Language apps.get_model u'pootle_language.Language' dirs Directory.objects.exclude pootle_path u'/' .exclude pootle_path__startswith u'/goals/' .exclude pootle_path__startswith u'/projects/' language_codes Language.objects.values_list u'code' flat True for directory in dirs directory_path_parts directory.pootle_path.split u'/' if len directory_path_parts < 4 continuedirectory_lang_code directory_path_parts[1]if directory_lang_code in language_codes tp_path u'/'.join directory_path_parts[ 3] + [u''] has_tp TP.objects.filter pootle_path tp_path .exists if not has_tp Directory.objects.filter pootle_path__startswith directory.pootle_path .delete
@depends HAS_ESX_CLI def get_firewall_status host username password protocol None port None esxi_hosts None cmd 'networkfirewallrulesetlist'ret {}if esxi_hosts if not isinstance esxi_hosts list raise CommandExecutionError "'esxi_hosts'mustbealist." for esxi_host in esxi_hosts response salt.utils.vmware.esxcli host username password cmd protocol protocol port port esxi_host esxi_host if response['retcode'] ! 0 ret.update {esxi_host {'Error' response['stdout'] 'success' False 'rulesets' None}} else ret.update {esxi_host _format_firewall_stdout response } else response salt.utils.vmware.esxcli host username password cmd protocol protocol port port if response['retcode'] ! 0 ret.update {host {'Error' response['stdout'] 'success' False 'rulesets' None}} else ret.update {host _format_firewall_stdout response } return ret
def visualize profiling_data converter CalltreeConverter profiling_data converter.visualize
def _get_args_for_reloading rv [sys.executable]py_script sys.argv[0]if os.name 'nt' and not os.path.exists py_script and os.path.exists py_script + '.exe' py_script + '.exe'rv.append py_script rv.extend sys.argv[1 ] return rv
@cuda.jitdef gpu_single_block_sum arr out temp cuda.shared.array gpu_block_sum_max_blockdim dtype float32 tid cuda.threadIdx.xblksz cuda.blockDim.xtemp[tid] 0for i in range tid arr.size blksz temp[tid] + arr[i]cuda.syncthreads if tid 0 for i in range 1 blksz temp[0] + temp[i]out[0] temp[0]
@given u'anemptyfilenamed"{filename}"' def step_an_empty_file_named_filename context filename assert not os.path.isabs filename command_util.ensure_workdir_exists context filename2 os.path.join context.workdir filename pathutil.create_textfile_with_contents filename2 ''
def test_hosts_in_role_dict @roles 'r1' def command passeq_hosts command ['a' 'b'] env {'roledefs' dict_roles}
def indicesFromString indsString try inds int round float indsString return [inds]except Exception passtry inds sliceFromString indsString return indsexcept Exception passtry inds list eval indsString return indsexcept Exception pass
def _make_edges_3d n_x n_y n_z 1 vertices np.arange n_x * n_y * n_z .reshape n_x n_y n_z edges_deep np.vstack vertices[ -1 ].ravel vertices[ 1 ].ravel edges_right np.vstack vertices[ -1 ].ravel vertices[ 1 ].ravel edges_down np.vstack vertices[ -1 ].ravel vertices[1 ].ravel edges np.hstack edges_deep edges_right edges_down return edges
def modifyComplete LowLayerCompatibility_presence 0 HighLayerCompatibility_presence 0 ReverseCallSetupDirection_presence 0 a TpPd pd 3 b MessageType mesType 31 c BearerCapability packet a / b / c if LowLayerCompatibility_presence is 1 d LowLayerCompatibilityHdr ieiLLC 124 eightBitLLC 0 packet packet / d if HighLayerCompatibility_presence is 1 e HighLayerCompatibilityHdr ieiHLC 125 eightBitHLC 0 packet packet / e if ReverseCallSetupDirection_presence is 1 f ReverseCallSetupDirection ieiRCSD 163 packet packet / f return packet
def get_scene_exceptions indexer_id season -1 exceptionsList []if indexer_id not in exceptionsCache or season not in exceptionsCache[indexer_id] cache_db_con db.DBConnection 'cache.db' exceptions cache_db_con.select 'SELECTshow_nameFROMscene_exceptionsWHEREindexer_id ?andseason ?' [indexer_id season] if exceptions exceptionsList list {cur_exception['show_name'] for cur_exception in exceptions} if indexer_id not in exceptionsCache exceptionsCache[indexer_id] {}exceptionsCache[indexer_id][season] exceptionsListelse exceptionsList exceptionsCache[indexer_id][season]if season ! -1 and not exceptionsList exceptionsList + get_scene_exceptions indexer_id season -1 return list {exception for exception in exceptionsList}
def test_record_mode_good output StringIO recorder Record file_object output replay False record_mode RecordMode recorder i iscalar f function [i] i mode record_mode name 'f' num_lines 10for i in xrange num_lines recorder.handle_line str i + '\n' f i output_value output.getvalue output StringIO output_value playback_checker Record file_object output replay True playback_mode RecordMode playback_checker i iscalar f function [i] i mode playback_mode name 'f' for i in xrange num_lines playback_checker.handle_line str i + '\n' f i
def constrain_stationary_univariate unconstrained n unconstrained.shape[0]y np.zeros n n dtype unconstrained.dtype r unconstrained / 1 + unconstrained ** 2 ** 0.5 for k in range n for i in range k y[ k i ] y[ k - 1 i ] + r[k] * y[ k - 1 k - i - 1 ] y[ k k ] r[k]return - y[ n - 1 ]
def test_ncr_fit ncr NeighbourhoodCleaningRule random_state RND_SEED ncr.fit X Y assert_equal ncr.min_c_ 0 assert_equal ncr.maj_c_ 2 assert_equal ncr.stats_c_[0] 2 assert_equal ncr.stats_c_[1] 6 assert_equal ncr.stats_c_[2] 7
def find_program basename names [basename]if os.name 'nt' extensions '.exe' '.bat' '.cmd' if not basename.endswith extensions names [ basename + ext for ext in extensions] + [basename] for name in names path is_program_installed name if path return path
def is_existing_language language_code try get_babel_locale language_code except UnknownLocaleError ValueError '\nCatcherrorswithbabellocaleparsing\n\nForexamplelanguage`bew`raises`UnknownLocaleError`\nand`ValueError`isbeingraisediflanguage_codeis\nanemptystring.\n'return Falsereturn True
def _mro cls if isinstance cls type return cls.__mro__else mro [cls]for base in cls.__bases__ mro.extend _mro base return mro
def _HandleCommonPrefix first_handler second_handler common_prefix stripped_first_handler SimpleHandler first_handler.pattern[len common_prefix ] first_handler.properties stripped_second_handler SimpleHandler second_handler.pattern[len common_prefix ] second_handler.properties stripped_handlers _IntersectTwoHandlers stripped_first_handler stripped_second_handler handlers set for stripped_handler in stripped_handlers handlers.add SimpleHandler common_prefix + stripped_handler.pattern stripped_handler.properties return handlers
def is_extension_module filename return os.path.splitext filename [1].lower in '.so' '.pyd'
def new_loncapa_problem xml problem_id '1' capa_system None seed 723 use_capa_render_template False render_template capa_render_template if use_capa_render_template else None return LoncapaProblem xml id problem_id seed seed capa_system capa_system or test_capa_system render_template capa_module mock_capa_module
def show_version_info about False import osimport sysimport twistedimport djangoreturn VERSION_INFO.format version EVENNIA_VERSION about ABOUT_INFO if about else '' os os.name python sys.version.split [0] twisted twisted.version.short django django.get_version
def _to_secs delta return delta.days * 86400.0 + delta.seconds + delta.microseconds / 1000000.0
def EvalExponentialPdf x lam return lam * math.exp - lam * x
def _data response return response.data
def get_limit_conn_shared_memory import psutiltotal_vm psutil.virtual_memory .total / 1024 * 1024 return int 0.02 * total_vm
def get_milestones repo_name None profile 'github' state 'open' sort 'due_on' direction 'asc' output 'min' per_page None org_name _get_config_value profile 'org_name' if repo_name is None repo_name _get_config_value profile 'repo_name' action '/'.join ['repos' org_name repo_name] args {}if per_page args['per_page'] per_pageif state and state ! 'open' args['state'] stateif sort and sort ! 'due_on' args['sort'] sortif direction and direction ! 'asc' args['direction'] directionret {}milestones _query profile action action command 'milestones' args args for milestone in milestones milestone_id milestone.get 'id' if output 'full' ret[milestone_id] milestoneelse milestone.pop 'creator' milestone.pop 'html_url' milestone.pop 'labels_url' ret[milestone_id] milestonereturn ret
@jit nopython True cache True def pivoting tableau pivot pivot_row nrows ncols tableau.shapepivot_elt tableau[ pivot_row pivot ]for j in range ncols tableau[ pivot_row j ] / pivot_eltfor i in range nrows if i pivot_row continuemultiplier tableau[ i pivot ]if multiplier 0 continuefor j in range ncols tableau[ i j ] - tableau[ pivot_row j ] * multiplier return tableau
def region_style_loss style_image target_image style_mask target_mask assert 3 K.ndim style_image K.ndim target_image assert 2 K.ndim style_mask K.ndim target_mask if K.image_dim_ordering 'th' masked_style style_image * style_mask masked_target target_image * target_mask nb_channels K.shape style_image [0]else masked_style K.permute_dimensions style_image 2 0 1 * style_mask masked_target K.permute_dimensions target_image 2 0 1 * target_mask nb_channels K.shape style_image [ -1 ]s gram_matrix masked_style / K.mean style_mask / nb_channels c gram_matrix masked_target / K.mean target_mask / nb_channels return K.mean K.square s - c
def Memoize func @wraps func def wrapper *args if args not in dg['cache'] dg['cache'][args] func *args return dg['cache'][args]return wrapper
def tool_proxy tool_path ensure_cwltool_available tool to_cwl_tool_object tool_path return tool
def mask_missing arr values_to_mask if not isinstance values_to_mask list np.ndarray values_to_mask [values_to_mask]try values_to_mask np.array values_to_mask dtype arr.dtype except Exception values_to_mask np.array values_to_mask dtype object na_mask isnull values_to_mask nonna values_to_mask[ ~ na_mask ]mask Nonefor x in nonna if mask is None if is_numeric_v_string_like arr x mask Falseelse mask arr x if is_scalar mask mask np.zeros arr.shape dtype bool elif is_numeric_v_string_like arr x mask | Falseelse mask | arr x if na_mask.any if mask is None mask isnull arr else mask | isnull arr return mask
def pass_bracket source start bracket ' ' e bracket_split source[start ] [bracket] False try cand e.next except StopIteration return None None if not cand.strip try res e.next return res start + len cand + len res except StopIteration return None None elif cand[ -1 ] bracket[1] return cand start + len cand else return None None
def parse_code code var_factory **kwargs block CodeBlock defdict collections.defaultdict var_factory defdict.update kwargs indent -1 code code.strip for line in code.splitlines length len line line line.lstrip spaces length - len line if spaces if indent < 0 indent spaceslevel 1else level spaces // indent else level 0if line.startswith '$' and line.count '$' 1 name line[1 ]if name in kwargs and isinstance kwargs[name] CodeBlock kwargs[name].write_into block level continueblock.write_line string.Template line .substitute defdict level return block dict defdict
def _reorder_unifrac_res_one_sample unifrac_res sample_names_in_desired_order sample_names sample_names_in_desired_orderunifrac_dist_arry unifrac_res[0]unifrac_sample_names unifrac_res[1]unifrac_sample_names_idx dict [ n i for i n in enumerate unifrac_sample_names ] if list unifrac_sample_names list sample_names dist_arry unifrac_dist_arryelse dist_arry np.zeros len sample_names for i sam_i in enumerate sample_names if sam_i not in unifrac_sample_names_idx dist_arry[i] 1.0else unifrac_i unifrac_sample_names_idx[sam_i]dist_arry[i] unifrac_dist_arry[unifrac_i]return dist_arry
def size_string raw_text size MAX_DISPLAY_SIZE if raw_text and len raw_text > size large_str '\nFilecontentstruncatedbecausefilesizeislargerthanmaximumviewingsizeof%s\n' % nice_size size raw_text '%s%s' % raw_text[0 size] large_str return raw_text or ''
def error_exit msg code 1 error msg sys.exit code
def _antidivisors n for d in _divisors n y 2 * d if n > y and n % y yield y for d in _divisors 2 * n - 1 if n > d > 2 and n % d yield d for d in _divisors 2 * n + 1 if n > d > 2 and n % d yield d
def general_config_get config config_get_patterns config_validation kodi_set default **kwargs results []for line in config[ -1 ] if not line.strip continueif line.strip .startswith '#' continueif '#' in line line line[ line.index '#' ]for pair in config_get_patterns matched re.search pair['identify'] line re.IGNORECASE if matched raw_value re.search pair['extract'] line re.IGNORECASE if raw_value result config_validation raw_value.group 1 if result is not None results.append result kodi_setting kodi_set results if kodi_setting is None kodi_setting retrieve_default **default return kodi_setting
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def test_sip_hst test_file get_pkg_data_filename os.path.join u'data' u'hst_sip.hdr' hdr fits.Header.fromtextfile test_file crpix1 hdr[u'CRPIX1']crpix2 hdr[u'CRPIX2']wobj wcs.WCS hdr a_pars dict **hdr[u'A_*'] b_pars dict **hdr[u'B_*'] a_order a_pars.pop u'A_ORDER' b_order b_pars.pop u'B_ORDER' sip SIP [crpix1 crpix2] a_order b_order a_pars b_pars coords [1 1]rel_coords [ 1 - crpix1 1 - crpix2 ]astwcs_result wobj.sip_pix2foc [coords] 1 [0] - rel_coords assert_allclose sip 1 1 astwcs_result
def is_installed return get_binstar is not None
def are_variants uri other_uri if uri.get_domain ! other_uri.get_domain return Falseif uri.get_path ! other_uri.get_path return Falseif not uri.has_query_string and not other_uri.has_query_string return Trueif uri.has_query_string and other_uri.has_query_string dc uri.querystringodc other_uri.querystringif dc.keys ! odc.keys return Falsefor vself vother in izip_longest chain *dc.values chain *odc.values fillvalue None if None in vself vother or vself.isdigit ! vother.isdigit return Falsereturn Truereturn False
def int_to_string x assert x > 0 if x 0 return b '\x00' result []while x ordinal x & 255 result.append int2byte ordinal x >> 8result.reverse return b '' .join result
def hqic_sigma sigma2 nobs df_modelwc islog False if not islog sigma2 np.log sigma2 return sigma2 + hqic 0 nobs df_modelwc / nobs
def _kernel kernel_spec if isinstance kernel_spec int return [kernel_spec kernel_spec]elif len kernel_spec 1 return [kernel_spec[0] kernel_spec[0]]else assert len kernel_spec 2 return kernel_spec
def nvram attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'nvram' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def show_reconstructions m model_path model load_model model_path m x input 'usetestset? y/n ' dataset load_dataset model.dataset_yaml_src x vis_batch dataset.get_batch_topo m pv init_viewer dataset rows cols vis_batch batch model.visible_layer.space.make_theano_batch reconstruction model.reconstruct batch recons_func function [batch] reconstruction if hasattr model.visible_layer 'beta' beta model.visible_layer.beta.get_value print 'beta ' beta.min beta.mean beta.max while True update_viewer dataset batch rows cols pv recons_func vis_batch pv.show print 'Displayingreconstructions. qtoquit ENTER showmore ' while True x input if x 'q' quit if x '' x 1breakelse print 'Invalidinput tryagain' vis_batch dataset.get_batch_topo m
def add_error_codes new_codes for code message in new_codes.iteritems error_list[code] _ message errors[code] code
def rooms socketio flask.current_app.extensions['socketio']return socketio.server.rooms flask.request.sid namespace flask.request.namespace
def _get_legen_lut_fast x lut block None n_interp lut.shape[0] - 1.0 mm x * n_interp / 2.0 mm + 0.5 * n_interp idx np.round mm .astype int if block is None vals lut[idx]else vals lut[idx block]return vals
def django_boolean_icon field_val alt_text None title None BOOLEAN_MAPPING {True u'yes' False u'no' None u'unknown'}alt_text alt_text or BOOLEAN_MAPPING[field_val] if title is not None title u'title "%s"' % title else title u''icon_url static u'feincms/img/icon-%s.gif' % BOOLEAN_MAPPING[field_val] return mark_safe u'<imgsrc "%s"alt "%s"%s/>' % icon_url alt_text title
def macColonHex mac return _colonHex mac 6
def _sysv_services _services []output __salt__['cmd.run'] ['chkconfig' '--list'] python_shell False for line in output.splitlines comps line.split try if comps[1].startswith '0 ' _services.append comps[0] except IndexError continuereturn [x for x in _services if _service_is_sysv x ]
def normalize_to_string host_string return join_host_strings *normalize host_string
def _get_recarray_field array key field np.recarray.field array key if field.dtype.char in 'S' 'U' and not isinstance field chararray.chararray field field.view chararray.chararray return field
def decode_task_payload task body task['body']if not body return {}decoded base64.b64decode body result {}for name value in cgi.parse_qs decoded .items if len value 1 result[name] value[0]else result[name] valuereturn util.HugeTask.decode_payload result
@gof.local_optimizer [csm_grad None ] def local_csm_grad_c node if node.op csm_grad None return [csm_grad_c *node.inputs ]return False
def cherry_pick revs summaries gitcmds.log_helper all True commits select_commits N_ u'Cherry-PickCommit' revs summaries multiselect False if not commits returncmds.do cmds.CherryPick commits
def generate_helper_script pkg_manager_cmd os_packages pip_cmd failed_deps temp_dir tempfile.gettempdir script_path os.path.join temp_dir SCRIPT_NAME script_file file script_path 'w' script_file.write '#!/bin/bash\n' if os_packages missing_pkgs ''.join os_packages script_file.write '%s%s\n' % pkg_manager_cmd missing_pkgs if failed_deps script_file.write '\n' if running_in_virtualenv script_file.write '#Runwithoutsudotoinstallinsidevenv\n' not_git_pkgs [fdep for fdep in failed_deps if not fdep.is_git ]git_pkgs [fdep.git_src for fdep in failed_deps if fdep.is_git]if not_git_pkgs cmd generate_pip_install_non_git pip_cmd not_git_pkgs script_file.write '%s\n' % cmd if git_pkgs for missing_git_pkg in git_pkgs cmd generate_pip_install_git pip_cmd missing_git_pkg script_file.write '%s\n' % cmd os.chmod script_path 493 script_file.close return script_path
def restart name return __salt__['service.run'] name 'restart'
def plt_show show True **kwargs import matplotlibimport matplotlib.pyplot as pltif show and matplotlib.get_backend ! 'agg' plt.show **kwargs
def _determine_error_message remainder match BAD_QUOTED_PARAM_RE.match remainder if match if match.group 1 return u'Spaceexpectedafterclosing\'"\''else return u'Missingclosing\'"\''return u'Invalidunquotedcharacter'
def format_list lst locale DEFAULT_LOCALE locale Locale.parse locale if not lst return ''if len lst 1 return lst[0]if len lst 2 return locale.list_patterns['2'].format *lst result locale.list_patterns['start'].format lst[0] lst[1] for elem in lst[2 -1 ] result locale.list_patterns['middle'].format result elem result locale.list_patterns['end'].format result lst[ -1 ] return result
def makeConnections app if web.proxies is None web.setupProxy if web.proxies 0 returnif app.prefs.connections['allowUsageStats'] sendUsageStats if app.prefs.connections['checkForUpdates'] app._latestAvailableVersion getLatestVersionInfo
def parse_event_payload event if 'event' in event and isinstance event['event'] basestring event event.copy try event['event'] json.loads event['event'] except ValueError passreturn event
def cg_simp e if isinstance e Add return _cg_simp_add e elif isinstance e Sum return _cg_simp_sum e elif isinstance e Mul return Mul *[cg_simp arg for arg in e.args] elif isinstance e Pow return Pow cg_simp e.base e.exp else return e
@inspect_command def active_queues state if state.consumer.task_consumer return [dict queue.as_dict recurse True for queue in state.consumer.task_consumer.queues]return []
def notify_about_server_group_update context event_suffix sg_payload notifier rpc.get_notifier service 'servergroup' notifier.info context 'servergroup.%s' % event_suffix sg_payload
@register.filter def oneline value return value.replace '\n' ''
def _check_and_install_python ret python default False user None ret _python_installed ret python user user if not ret['result'] if __salt__['pyenv.install_python'] python runas user ret['result'] Trueret['changes'][python] 'Installed'ret['comment'] 'Successfullyinstalledpython'ret['default'] defaultelse ret['result'] Falseret['comment'] 'Couldnotinstallpython.'return retif default __salt__['pyenv.default'] python runas user return ret
def prepare_lookup_value key value if key.endswith '__in' value value.split ' ' if key.endswith '__isnull' and type value str if value.lower in '' 'false' value Falseelse value Truereturn value
def get_strategy_name return 'store_type'
def resolve_ipv6 name flags 0 waiter Waiter core.dns_resolve_ipv6 name flags waiter.switch_args result _type ttl addrs waiter.get if result ! core.DNS_ERR_NONE raise DNSError result return ttl addrs
def api_github_v1 user_profile event payload branches stream **kwargs commit_stream streamissue_stream 'issues'return api_github_v2 user_profile event payload branches stream commit_stream issue_stream **kwargs
def compare_dicts old None new None ret {}for key in set new or {} .union old or {} if key not in old ret[key] {'old' '' 'new' new[key]}elif key not in new ret[key] {'new' '' 'old' old[key]}elif new[key] ! old[key] ret[key] {'old' old[key] 'new' new[key]}return ret
def PutSecret secret secret_value GetSecretsManagerForSecret secret .PutSecret secret secret_value
def p_struct_declaration_list_2 t pass
def roots_sh_jacobi n p1 q1 mu False if p1 - q1 < -1 or q1 < 0 raise ValueError ' p-q mustbegreaterthan-1 andqmustbegreaterthan0.' x w m roots_jacobi n p1 - q1 q1 - 1 True x x + 1 / 2 scale 2.0 ** p1 w / scalem / scaleif mu return x w m else return x w
def _get_indent_length line result 0for char in line if char '' result + 1elif char ' DCTB ' result + _TAB_LENGTHelse breakreturn result
def get_course_date_blocks course user block_classes CourseEndDate CourseStartDate TodaysDate VerificationDeadlineDate VerifiedUpgradeDeadlineDate blocks cls course user for cls in block_classes def block_key_fn block "\nIftheblock'sdateisNone returnthemaximumdatetimeinorder\ntoforceittotheendofthelistofdisplayedblocks.\n"if block.date is None return datetime.max.replace tzinfo pytz.UTC return block.datereturn sorted b for b in blocks if b.is_enabled key block_key_fn
def check_bc_duplicates header mapping_data errors has_barcodes True variable_len_barcodes False added_demultiplex_field None if has_barcodes and not variable_len_barcodes and not added_demultiplex_field errors check_fixed_len_bcs_dups header mapping_data errors if has_barcodes and variable_len_barcodes and not added_demultiplex_field errors check_variable_len_bcs_dups header mapping_data errors if added_demultiplex_field errors check_added_demultiplex_dups header mapping_data errors has_barcodes added_demultiplex_field if not has_barcodes and not added_demultiplex_field if len mapping_data ! 1 errors.append 'Ifnobarcodesarepresent andthe' + "added_demultiplex_fieldoptionisn'tused onlyasingle" + 'SampleIDcanbepresent. DCTB -1 -1' return errors
def read_cz_lsm_info fh byteorder dtype count assert byteorder '<' magic_number structure_size struct.unpack '<II' fh.read 8 if magic_number not in 50350412 67127628 raise ValueError 'notavalidCS_LSM_INFOstructure' fh.seek -8 1 if structure_size < numpy.dtype CZ_LSM_INFO .itemsize cz_lsm_info []size 0for name dtype in CZ_LSM_INFO size + numpy.dtype dtype .itemsizeif size > structure_size breakcz_lsm_info.append name dtype else cz_lsm_info CZ_LSM_INFOreturn fh.read_record cz_lsm_info byteorder byteorder
def module_suite module classnames None if classnames return unittest.TestLoader .loadTestsFromNames classnames module elif hasattr module 'suite' return module.suite else return unittest.TestLoader .loadTestsFromModule module
def educateSingleBackticks str str re.sub '`' '&#8216;' str str re.sub "'" '&#8217;' str return str
def write_table_votable input output table_id None overwrite False tabledata_format None if input.has_mixin_columns mixin_names [name for name col in input.columns.items if not isinstance col input.ColumnClass ]raise ValueError u'cannotwritetablewithmixincolumn s {0}toVOTable'.format mixin_names if isinstance output six.string_types and os.path.exists output if overwrite os.remove output else raise IOError u'Fileexists {0}'.format output table_file from_table input table_id table_id table_file.to_xml output tabledata_format tabledata_format
def is_site_configuration_enabled configuration get_current_site_configuration if configuration return configuration.enabledreturn False
def _trim_zeros str_floats na_rep 'NaN' trimmed str_floatsdef _cond values non_na [x for x in values if x ! na_rep ]return len non_na > 0 and all [x.endswith '0' for x in non_na] and not any [ 'e' in x or 'E' in x for x in non_na] while _cond trimmed trimmed [ x[ -1 ] if x ! na_rep else x for x in trimmed]return [ x + '0' if x.endswith '.' and x ! na_rep else x for x in trimmed]
def make_local_path s return s.replace '/' os.sep
def matches_patterns path patterns None if patterns is None patterns []for pattern in patterns if fnmatch.fnmatchcase path pattern return Truereturn False
def add_application_with_volume node_state manifestation list node_state.manifestations.values [0]return node_state.set 'applications' {Application name u'myapplication' image DockerImage.from_string u'image' volume AttachedVolume manifestation manifestation mountpoint FilePath '/data' }
def he_uniform shape name None dim_ordering 'th' fan_in fan_out get_fans shape dim_ordering dim_ordering s np.sqrt 6.0 / fan_in return uniform shape s name name
def _write_data writer data data data.replace '&' '&amp;' .replace '<' '&lt;' data data.replace '"' '&quot;' .replace '>' '&gt;' writer.write data
def get_valid_user user None if user is None theuser get_default_user elif isinstance user basestring theuser get_user_model .objects.get username user elif user user.get_anonymous raise GeoNodeException 'Theuseruploadingfilesmustnotbeanonymous' else theuser userassert isinstance theuser get_user_model return theuser
def check_if_vlan_interface_exists session vlan_interface cluster None host_mor vm_util.get_host_ref session cluster physical_nics_ret session._call_method vim_util 'get_dynamic_property' host_mor 'HostSystem' 'config.network.pnic' if not physical_nics_ret return Falsephysical_nics physical_nics_ret.PhysicalNicfor pnic in physical_nics if vlan_interface pnic.device return Truereturn False
def parse_gff_attributes attr_str attributes_list attr_str.split ';' attributes {}for name_value_pair in attributes_list pair name_value_pair.strip .split '' if len pair 1 pair name_value_pair.strip .split ' ' if len pair 1 continueif pair '' continuename pair[0].strip if name '' continuevalue pair[1].strip '"' attributes[name] valueif len attributes 0 attributes['group'] attr_strreturn attributes
def open_repo_in_new_window dirname qtutils.opendir_dialog N_ u'OpenGitRepository...' main.model .getcwd if not dirname returncmds.do cmds.OpenNewRepo dirname
def Odds p if p 1 return float 'inf' return p / 1 - p
def service_stop name r salt.utils.http.query DETAILS['url'] + 'service/stop/' + name decode_type 'json' decode True return r['dict']
def convert_jobsub_design jobsub_design action get_root_action jobsub_design if action is None return Noneif action.action_type OozieMapreduceAction.ACTION_TYPE action _convert_jobsub_mapreduce_action action elif action.action_type OozieStreamingAction.ACTION_TYPE action _convert_jobsub_streaming_action action elif action.action_type OozieJavaAction.ACTION_TYPE action _convert_jobsub_java_action action else return Noneaction.name jobsub_design.nameaction.description jobsub_design.descriptionreturn action
def test_custom_completion_error ip get_ipython class A object passip.user_ns['a'] A @complete_object.when_type A def complete_A a existing_completions raise TypeError 'thisshouldbesilenced' ip.complete 'a.'
def _get_rc_timezone s matplotlib.rcParams[u'timezone']if s u'UTC' return UTCimport pytzreturn pytz.timezone s
@deprecated Version 'Twisted' 16 0 0 def addSlash request return _addSlash request
def save_obj base_mapper states uowtransaction single False if not single and not base_mapper.batch for state in _sort_states states save_obj base_mapper [state] uowtransaction single True return states_to_insert states_to_update _organize_states_for_save base_mapper states uowtransaction cached_connections _cached_connection_dict base_mapper for table mapper in base_mapper._sorted_tables.items insert _collect_insert_commands base_mapper uowtransaction table states_to_insert update _collect_update_commands base_mapper uowtransaction table states_to_update if update _emit_update_statements base_mapper uowtransaction cached_connections mapper table update if insert _emit_insert_statements base_mapper uowtransaction cached_connections mapper table insert _finalize_insert_update_commands base_mapper uowtransaction states_to_insert states_to_update
def _engineServicesRunning process subprocess.Popen ['ps' 'aux'] stdout subprocess.PIPE stdout process.communicate [0]result process.returncodeif result ! 0 raise RuntimeError 'Unabletocheckforrunningclientjobmanager' running Falsefor line in stdout.split '\n' if 'python' in line and 'clientjobmanager.client_job_manager' in line running Truebreakreturn running
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request.method ! 'POST' return redirect document.get_edit_url if not allow_add_attachment_by request.user raise PermissionDeniedform AttachmentRevisionForm data request.POST files request.FILES if form.is_valid revision form.save commit False revision.creator request.userattachment Attachment.objects.create title revision.title revision.attachment attachmentrevision.save attachment.attach document request.user revision return redirect document.get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment.html' context
def get_report_list module is_standard u'No' reports frappe.get_list u'Report' fields [u'name' u'ref_doctype' u'report_type'] filters {u'is_standard' is_standard u'disabled' 0 u'module' module} order_by u'name' out []for r in reports out.append {u'type' u'report' u'doctype' r.ref_doctype u'is_query_report' 1 if r.report_type in u'QueryReport' u'ScriptReport' else 0 u'label' _ r.name u'name' r.name} return out
def getDataProvider dataset assert dataset in ['flickr8k' 'flickr30k' 'coco'] 'dataset%sunknown' % dataset return BasicDataProvider dataset
def test_pickle_multidimensional_column protocol a np.zeros 3 2 c Column a name 'a' cs pickle.dumps c cp pickle.loads cs assert np.all c cp assert c.shape cp.shape assert cp.attrs_equal c assert repr c repr cp
def get_scanner hass config info config[DOMAIN]host info.get CONF_HOST username info.get CONF_USERNAME password info.get CONF_PASSWORD port info.get CONF_PORT scanner NetgearDeviceScanner host username password port return scanner if scanner.success_init else None
def CacheStats formatted_results kinds_and_sizes dict kind['kind_name'] kind['total_bytes'] for kind in formatted_results memcache.set KINDS_AND_SIZES_VAR kinds_and_sizes namespace MEMCACHE_NAMESPACE
def _get_entrance_exam request course_key course modulestore .get_course course_key if course is None return HttpResponse status 400 if not course.entrance_exam_id return HttpResponse status 404 try exam_key UsageKey.from_string course.entrance_exam_id except InvalidKeyError return HttpResponse status 404 try exam_descriptor modulestore .get_item exam_key return HttpResponse dump_js_escaped_json {'locator' unicode exam_descriptor.location } status 200 content_type 'application/json' except ItemNotFoundError return HttpResponse status 404
def ImgtIterator handle return _ImgtScanner debug 0 .parse_records handle
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
def split_template_path template pieces []for piece in template.split '/' if path.sep in piece or path.altsep and path.altsep in piece or piece path.pardir raise TemplateNotFound template elif piece and piece ! '.' pieces.append piece return pieces
def detach_volume name None kwargs None instance_id None call None if call ! 'action' raise SaltCloudSystemExit 'Thedetach_volumeactionmustbecalledwith-aor--action.' if not kwargs kwargs {}if 'volume_id' not in kwargs log.error 'Avolume_idisrequired.' return Falseparams {'Action' 'DetachVolume' 'VolumeId' kwargs['volume_id']}data aws.query params return_url True location get_location provider get_provider opts __opts__ sigver '4' return data
def _check_orphans_no_tips cursor orphans_with_tips cursor.all '\nWITHvalid_tipsAS SELECT*FROMcurrent_tipsWHEREamount>0 \nSELECTusername\nFROM SELECTtipperASusernameFROMvalid_tips\nUNION\nSELECTtippeeASusernameFROMvalid_tips foo\nWHERENOTEXISTS SELECT1FROMelsewhereWHEREparticipant username \n' assert len orphans_with_tips 0 orphans_with_tips
def _is_safe_size n n int n if n 0 return Truefor c in 3 5 while n % c 0 n // creturn not n & n - 1
def header_decode s s s.replace '_' '' return re.sub ' [a-fA-F0-9]{2}' _unquote_match s flags re.ASCII
def name_from_path path collection path path.strip '/' + '/' start collection.path + '/' if not path.startswith start raise ValueError "'%s'doesn'tstartwith'%s'" % path start return path[len start ].rstrip '/'
def _sc_encode gain peak peak * 32768.0g1 int min round 10 ** gain / -10 * 1000 65534 g2 int min round 10 ** gain / -10 * 2500 65534 uk 0values g1 g1 g2 g2 uk uk int peak int peak uk uk return u'%08X' * 10 % values
def onLoginCallbackFromDB loginName accountName errorno datas INFO_MSG 'onLoginCallbackFromDB loginName %s accountName %s errorno %s' % loginName accountName errorno
def newRecoveryHeader self if self['flags/extend'].value yield filesizeHandler UInt32 self 'body_size' 'Sizeoftheunknownbodyfollowing' self.body_size self['body_size'].value yield textHandler UInt32 self 'unknown[]' 'Unknownfield probably0' hexadecimal yield String self 'signature' 7 "Signature normally'**ACE**'" yield textHandler UInt32 self 'relative_start' "Offset crc16's ofthisblockinthefile" hexadecimal yield textHandler UInt32 self 'unknown[]' 'Unknownfield probably0' hexadecimal
def _sysv_delete name if not _service_is_chkconfig name return Falsecmd '/sbin/chkconfig--del{0}'.format name return not __salt__['cmd.retcode'] cmd
def database dburl None **params if not dburl and not params dburl os.environ['DATABASE_URL']if dburl params dburl2dict dburl dbn params.pop 'dbn' if dbn in _databases return _databases[dbn] **params else raise UnknownDB dbn
def get_store_from_uri context uri loc None scheme uri[0 uri.find '/' - 1 ]store get_store_from_scheme context scheme loc return store
def _sort_distributions plot_data plot_labels plot_colors sort_type if sort_type 'median' sort_key lambda item np.median item[0] elif sort_type 'alphabetical' sort_key lambda item item[1] else raise ValueError "Invalidsorttype'%s'." % sort_type return zip *sorted zip plot_data plot_labels plot_colors key sort_key
def check_status status if status 'REQUEST_DENIED' return 'ThegeocodeAPIisoffintheGoogleDevelopersConsole.'elif status 'ZERO_RESULTS' return 'Noresultsfound.'elif status 'OVER_QUERY_LIMIT' return 'ThegeocodeAPIquotahasrunout.'elif status 'UNKNOWN_ERROR' return 'UnknownError.'elif status 'INVALID_REQUEST' return 'InvalidRequest.'elif status 'OK' return None
def Ids2Words ids_list vocab assert isinstance ids_list list '%sisnotalist' % ids_list return [vocab.IdToWord i for i in ids_list]
@deprecated 'UseTimedeltaWin64fieldtype' def durationWin64 field assert hasattr field 'value' and hasattr field 'size' assert field.size 64 delta doDurationWin64 field.value return humanDuration delta
def is_path_browsable app path repository_id is_admin False if is_admin and is_path_within_dependency_dir app path return Truereturn is_path_within_repo app path repository_id
def history_add paths state _open_state if HISTORY_KEY not in state state[HISTORY_KEY] set state[HISTORY_KEY].add tuple paths _save_state state
def _get_old_package_revision_license_ids migrate_engine old_ids {}select_licenses 'SELECTid license_idFROMpackage_revision;'q migrate_engine.execute select_licenses for id license_id in q old_ids[id] license_idreturn old_ids
def vulnerability_rheader r tabs [] if r.representation ! 'html' return Nonerecord r.recordif record is None return Nonetable r.tableresourcename r.nameT current.Tif resourcename 'risk' tabs [ T 'BasicDetails' None T 'Tags' 'tag' ]rheader_tabs s3_rheader_tabs r tabs rheader DIV TABLE TR TH '%s ' % table.name.label record.name rheader_tabs return rheader
def define_servers global CFGtry for server in CFG['servers'] svr CFG['servers'][server]s ConfigServer server.replace '{' '[' .replace '}' ']' svr if s.fillserver s.priority.set 1 s.fillserver.set False except KeyError pass
def java_binary name main_class srcs [] deps [] resources [] source_encoding None warnings None exclusions [] **kwargs target JavaBinary name srcs deps resources source_encoding warnings main_class exclusions kwargs blade.blade.register_target target
def basePre base a b base.calledBasePre base.calledBasePre + 1
def set_hidden_list hidden_list user None if isinstance hidden_list basestring hidden_list json.loads hidden_list for module_name in hidden_list set_hidden module_name user 1 for module_name in list set get_all_icons - set hidden_list set_hidden module_name user 0 if user clear_desktop_icons_cache else frappe.clear_cache
def connect_discussion_signals post_save.connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PS_COUNT_DISCUSSIONS pre_delete.connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PD_COUNT_DISCUSSIONS comment_was_flagged.connect count_discussions_handler sender comment_model dispatch_uid COMMENT_WF_COUNT_DISCUSSIONS comment_was_posted.connect count_comments_handler sender comment_model dispatch_uid COMMENT_WP_COUNT_COMMENTS pingback_was_posted.connect count_pingbacks_handler sender comment_model dispatch_uid PINGBACK_WF_COUNT_PINGBACKS trackback_was_posted.connect count_trackbacks_handler sender comment_model dispatch_uid TRACKBACK_WF_COUNT_TRACKBACKS
def satisfiable expr algorithm 'dpll2' all_models False expr to_cnf expr if algorithm 'dpll' from sympy.logic.algorithms.dpll import dpll_satisfiablereturn dpll_satisfiable expr elif algorithm 'dpll2' from sympy.logic.algorithms.dpll2 import dpll_satisfiablereturn dpll_satisfiable expr all_models raise NotImplementedError
def _lltrace selector def traced cls *args **kwargs ret selector cls *args **kwargs if TRACED_OIDS is not None _trace_selector cls selector args ret return rettraced.__name__ selector.__name__traced.__doc__ selector.__doc__return traced
def _cmpTop a b what 'top250rank' av int a[1].get what bv int b[1].get what if av bv return 0return -1 1 [ av > bv ]
def thetagrids *args **kwargs ax gca if not isinstance ax PolarAxes raise RuntimeError 'rgridsonlydefinedforpolaraxes' if len args 0 lines ax.xaxis.get_ticklines labels ax.xaxis.get_ticklabels else lines labels ax.set_thetagrids *args **kwargs draw_if_interactive return silent_list 'Line2Dthetagridline' lines silent_list 'Textthetagridlabel' labels
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def test_import_vispy_util modnames loaded_vispy_modules 'vispy.util' 2 assert_equal modnames set _min_modules
def task_install_docker distribution if is_centos_or_rhel distribution update 'yum--assumeyesupdate&&'else update ''return retry_effect_with_timeout run command '[[-e/usr/bin/docker]]||{' + update + 'curlhttps //get.docker.com/>/tmp/install-docker.sh&&sh/tmp/install-docker.sh;}' timeout 5.0 * 60.0
def parseFragmentString string context namespaces True if namespaces builder FragmentBuilderNS context else builder FragmentBuilder context return builder.parseString string
def p_dimitem_single p p[0] p[1] eval p[3] 0
def rootname filename if os.path.sep not in filename return ''else file_root _ filename.split os.path.sep 1 return file_root
def no_minc return not check_minc
def connect_ec2containerservice aws_access_key_id None aws_secret_access_key None **kwargs from boto.ec2containerservice.layer1 import EC2ContainerServiceConnectionreturn EC2ContainerServiceConnection aws_access_key_id aws_access_key_id aws_secret_access_key aws_secret_access_key **kwargs
def endswith string def ends_with value validate text value if not value.endswith string raise ValueError "'{0}'doesnotendwith'{1}'".format value string return Truereturn ends_with
def smoothed_sens counts noise_eps l beta k 0smoothed_sensitivity sens_at_k counts noise_eps l k while k < max counts k + 1sensitivity_at_k sens_at_k counts noise_eps l k smoothed_sensitivity max smoothed_sensitivity math.exp - beta * k * sensitivity_at_k if sensitivity_at_k 0.0 breakreturn smoothed_sensitivity
def about_dialog view AboutView qtutils.active_window view.show return view
def _NewSchemaFromPb field_type_pb_list field_types {}for field_type_pb in field_type_pb_list for field_type in field_type_pb.type_list public_type _FIELD_TYPE_MAP[field_type]name _DecodeUTF8 field_type_pb.name if name in field_types field_types[name].append public_type else field_types[name] [public_type]return field_types
def systemInformationType7 a L2PseudoLength l2pLength 1 b TpPd pd 6 c MessageType mesType 55 d Si7RestOctets packet a / b / c / d return packet
def plot_image_and_patch ax prng size 20 20 values prng.random_sample size size ax.imshow values interpolation 'none' c plt.Circle 5 5 radius 5 label 'patch' ax.add_patch c ax.set_xticks [] ax.set_yticks []
def send query query json.loads query if query.get '_color' query['data'] json.dumps {'xy' xy_color query['_color'] } conn httplib.HTTPConnection query.get 'host' conn.request query.get 'method' query.get 'url' query.get 'data'
def _canonical_type name if name 'int' return 'int256'if name 'uint' return 'uint256'if name 'fixed' return 'fixed128x128'if name 'ufixed' return 'ufixed128x128'if name.startswith 'int[' return 'int256' + name[3 ] if name.startswith 'uint[' return 'uint256' + name[4 ] if name.startswith 'fixed[' return 'fixed128x128' + name[5 ] if name.startswith 'ufixed[' return 'ufixed128x128' + name[6 ] return name
def generic_cdp_parser pattern cdp cdp cdp.split '\n' for line in cdp re_pattern re.search pattern line if re_pattern return_val re_pattern.group 1 return return_val.strip return ''
def dt_data row_list None add_header False config current.test_configbrowser config.browsercell browser.find_element_by_id 'table-container' text cell.textparts text.splitlines records []cnt 0lastrow ''header ''for row in parts if row.startswith 'Detail' header lastrowrow row[8 ]if row_list None or cnt in row_list records.append row cnt + 1else lastrow rowif add_header return [header] + records return records
def make_testdata_filename mission_type filename return os.path.join os.path.dirname __file__ '..' mission_type 'testdata' filename
def extract request response None ids []cookie_name settings.OSCAR_RECENTLY_VIEWED_COOKIE_NAMEif cookie_name in request.COOKIES try ids json.loads request.COOKIES[cookie_name] except ValueError if response response.delete_cookie cookie_name else if not isinstance ids list ids []return ids
def bnot value width None if width is None width context.bitsmask 1 << width - 1 return mask ^ value
def get_original mod_name item_name if isinstance item_name string_types return _get_original mod_name [item_name] [0]else return _get_original mod_name item_name
def addCube elementNode faces inradius vertexes square [complex - inradius.x - inradius.y complex inradius.x - inradius.y complex inradius.x inradius.y complex - inradius.x inradius.y ]bottomTopSquare triangle_mesh.getAddIndexedLoops square vertexes [ - inradius.z inradius.z] triangle_mesh.addPillarByLoops faces bottomTopSquare
def _rgb x y z rgb np.array [x y z] .Trgb - rgb.min 0 rgb / rgb.max 0 return rgb
def format_image_notification image return {'id' image.image_id 'name' image.name 'status' image.status 'created_at' timeutils.isotime image.created_at 'updated_at' timeutils.isotime image.updated_at 'min_disk' image.min_disk 'min_ram' image.min_ram 'protected' image.protected 'checksum' image.checksum 'owner' image.owner 'disk_format' image.disk_format 'container_format' image.container_format 'size' image.size 'is_public' image.visibility 'public' 'properties' dict image.extra_properties 'tags' list image.tags 'deleted' False 'deleted_at' None}
@app.route '/' @app.route '/home' def home_view return render_template 'index.html' title 'HomePage' year datetime.now .year
def await_results program timeout_seconds 2 countdown timeout_seconds * 10 while program.poll is None and countdown > 0 time.sleep 0.1 countdown - 1if countdown 0 program.kill raise TimeoutFailure '<programtimedout>'
def nodesplit name parts name.split NODENAME_SEP 1 if len parts 1 return None parts[0] return parts
def xpath elem path return elem.xpath path namespaces NS
def volume_type_access_remove context type_id project_id return IMPL.volume_type_access_remove context type_id project_id
@require_chanmsg u'.setsfwisonlypermittedinchannels' @commands u'setsafeforwork' u'setsfw' @example u'.setsfwtrue' @example u'.setsfwfalse' def update_channel bot trigger if bot.privileges[trigger.sender][trigger.nick] < OP returnelse param u'true'if trigger.group 2 and trigger.group 3 param trigger.group 3 .strip .lower sfw param u'true' bot.db.set_channel_value trigger.sender u'sfw' sfw if sfw bot.reply u'Gotit.%sisnowflaggedasSFW.' % trigger.sender else bot.reply u'Gotit.%sisnowflaggedasNSFW.' % trigger.sender
def fullrank X r None if r is None r np_matrix_rank X V D U L.svd X full_matrices 0 order np.argsort D order order[ -1 ]value []for i in range r value.append V[ order[i]] return np.asarray np.transpose value .astype np.float64
def get_docs fileName source open fileName .read basename os.path.basename os.path.splitext fileName [0] ast parser.suite source return ModuleInfo ast.totuple basename
def typed_list conversion_func return lambda setting [conversion_func StringConverter elem for elem in setting]
def askopenfiles mode 'r' **options files askopenfilenames **options if files ofiles []for filename in files ofiles.append open filename mode files ofilesreturn files
def _wait_for_volume_state_change operation volume update _get_ebs_volume_state timeout VOLUME_STATE_CHANGE_TIMEOUT time.sleep 5.0 start_time time.time poll_until lambda _reached_end_state operation volume update time.time - start_time timeout itertools.repeat 1
def rand_string min max int_gen random.randintstring_length int_gen min max return ''.join [chr int_gen ord '' ord '~' for __ in range string_length ]
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
def nltkdemo18plus return nltkdemo18 + [Template Word [ -1 ] Pos [1] Template Pos [ -1 ] Word [1] Template Word [ -1 ] Word [0] Pos [1] Template Pos [ -1 ] Word [0] Word [1] Template Pos [ -1 ] Word [0] Pos [1] ]
def get_telemetry_data request indent None admin_user User.objects.first data_dict {'daily_data' get_daily_data now 'apps' settings.INSTALLED_APPS 'debug' settings.DEBUG 'host' request.get_host if request else None 'key' get_installation_key 'machine' platform.machine 'admin_user' admin_user.email if admin_user else None 'last_login' admin_user.last_login if admin_user else None 'platform' platform.platform 'python_version' sys.version 'shuup_version' shuup.__version__}return safe_json data_dict indent
def add_items fs_items_set db_items create_or_resurrect_db_item parent items []new_items []db_items_set set db_items items_to_delete db_items_set - fs_items_set items_to_create fs_items_set - db_items_set for name in items_to_delete db_items[name].makeobsolete for name in db_items_set - items_to_delete items.append db_items[name] for name in items_to_create item create_or_resurrect_db_item name items.append item new_items.append item try item.save except Exception logging.exception 'Errorwhileadding%s' item return items new_items
def instructor_task_status request output {}task_id request.GET.get 'task_id' or request.POST.get 'task_id' tasks request.GET.get 'task_ids[]' or request.POST.get 'task_ids[]' if task_id output _get_instructor_task_status task_id elif tasks for task_id in tasks task_output _get_instructor_task_status task_id if task_output is not None output[task_id] task_outputreturn HttpResponse json.dumps output indent 4
def speed_limits client place_ids params [ 'placeId' place_id for place_id in convert.as_list place_ids ]return client._get '/v1/speedLimits' params base_url _ROADS_BASE_URL accepts_clientid False extract_body _roads_extract ['speedLimits']
def assertNotIn first second msg '' a b first second assert a not in b '%s %risin%r' % msg.format a b a b
def qos_specs_associations_get context qos_specs_id return IMPL.qos_specs_associations_get context qos_specs_id
def render_and_scrub markdown return Markup.escape render markdown .striptags
def format_datetime datetime None format None rebase True return get_i18n .format_datetime datetime format rebase
def IndexDefinitionToProto app_id index_definition proto entity_pb.CompositeIndex proto.set_app_id app_id proto.set_id 0 proto.set_state entity_pb.CompositeIndex.WRITE_ONLY definition_proto proto.mutable_definition definition_proto.set_entity_type index_definition.kind definition_proto.set_ancestor index_definition.ancestor if index_definition.properties is not None is_geo any x.mode 'geospatial' for x in index_definition.properties for prop in index_definition.properties prop_proto definition_proto.add_property prop_proto.set_name prop.name if prop.mode 'geospatial' prop_proto.set_mode entity_pb.Index_Property.GEOSPATIAL elif is_geo passelif prop.IsAscending prop_proto.set_direction entity_pb.Index_Property.ASCENDING else prop_proto.set_direction entity_pb.Index_Property.DESCENDING return proto
def get_valid_completed_exploration_ids user_id collection completed_exploration_ids get_completed_exploration_ids user_id collection.id return [exp_id for exp_id in completed_exploration_ids if collection.get_node exp_id ]
def setup_database_via_manager engine settings.DATABASES['default']['ENGINE']rdbms_type database_manager.engine_to_rdbms_type engine manager database_manager.get_manager_from_config rdbms_type rdbms_type manager.create_instance manager.grant_privileges
def test_keypoints_censure_moon_image_dob detector CENSURE detector.detect img expected_keypoints np.array [[21 497] [36 46] [119 350] [185 177] [287 250] [357 239] [463 116] [464 132] [467 260]] expected_scales np.array [3 4 4 2 2 3 2 2 2] assert_array_equal expected_keypoints detector.keypoints assert_array_equal expected_scales detector.scales
def rsync_upload excludes [u'*.pyc' u'*.pyo' u'*.db' u'.DS_Store' u'.coverage' u'local_settings.py' u'/static' u'/.git' u'/.hg']local_dir os.getcwd + os.sep return rsync_project remote_dir env.proj_path local_dir local_dir exclude excludes
def make_service options def make_stub 'Helperfunctionformakingastubtotalktoservice.'credentials_path options.get 'credentials_path' None http httplib2.Http http apiclient.http.set_user_agent http 'SpinnakerStackdriverAgent/0.001' if credentials_path logging.info 'UsingStackdriverCredentialsfrom"%s"' credentials_path credentials ServiceAccountCredentials.from_json_keyfile_name credentials_path scopes StackdriverMetricsService.WRITE_SCOPE else logging.info 'UsingStackdriverCredentialsfromapplicationdefault.' credentials GoogleCredentials.get_application_default http credentials.authorize http return apiclient.discovery.build 'monitoring' 'v3' http http return StackdriverMetricsService make_stub options
def inputhook_wx2 context try app wx.GetApp if app is not None assert wx.Thread_IsMain elr EventLoopRunner elr.Run time 10 input_is_ready context.input_is_ready except KeyboardInterrupt passreturn 0
def mail_admins_contact request subject message context sender LOGGER.info u'contactformfrom%s' sender if not settings.ADMINS messages.error request _ u'Messagecouldnotbesenttoadministrator!' LOGGER.error u'ADMINSnotconfigured cannotsendmessage!' returnmail EmailMultiAlternatives u'%s%s' % settings.EMAIL_SUBJECT_PREFIX subject % context message % context to [a[1] for a in settings.ADMINS] headers {u'Reply-To' sender} mail.send fail_silently False messages.success request _ u'Messagehasbeensenttoadministrator.'
def __version client versions {9 'CMC' 8 'iDRAC6' 10 'iDRAC6' 11 'iDRAC6' 16 'iDRAC7' 17 'iDRAC7'}if isinstance client paramiko.SSHClient stdin stdout stderr client.exec_command 'racadmgetconfig-gidRacInfo' for i in stdout.readlines if i[2 ].startswith 'idRacType' return versions.get int i[2 ].split ' ' [1] None return None
def get_power_command power_type if power_type power_path1 '/sbin/fence_%s' % power_type power_path2 '/usr/sbin/fence_%s' % power_type for power_path in power_path1 power_path2 if os.path.isfile power_path and os.access power_path os.X_OK return power_pathreturn None
def init mpstate return CmdlongModule mpstate
@task def push_course_update_task course_key_string course_subscription_id course_display_name from .push_notification import send_push_course_updatesend_push_course_update course_key_string course_subscription_id course_display_name
def is_text_file filename try return not is_binary filename except OSError IOError return False
@FileSystem.in_directory current_directory 'django' 'brocolis' def test_harvest_uses_test_runner status out run_scenario 'leaves' 'disabled' assert_equals status 0 out assert 'Customtestrunnerenabled.' in out
def apply_acoustid_metadata task session for item in task.imported_items if item.path in _fingerprints item.acoustid_fingerprint _fingerprints[item.path]if item.path in _acoustids item.acoustid_id _acoustids[item.path]
def test_recursive_FileLinks td mkdtemp tf NamedTemporaryFile dir td subtd mkdtemp dir td subtf NamedTemporaryFile dir subtd fl display.FileLinks td actual str fl actual actual.split '\n' nt.assert_equal len actual 4 actual fl display.FileLinks td recursive False actual str fl actual actual.split '\n' nt.assert_equal len actual 2 actual
def create_program_action parent text name icon None nt_name None if is_text_string icon icon get_icon icon if os.name 'nt' and nt_name is not None name nt_namepath programs.find_program name if path is not None return create_action parent text icon icon triggered lambda programs.run_program name
def enabled name **kwargs ret {'name' name 'result' True 'changes' {} 'comment' []}current_schedule __salt__['schedule.list'] show_all True return_yaml False if name in current_schedule if 'test' in __opts__ and __opts__['test'] kwargs['test'] Trueresult __salt__['schedule.enable_job'] name **kwargs ret['comment'].append result['comment'] else result __salt__['schedule.enable_job'] name **kwargs if not result['result'] ret['result'] result['result']ret['comment'] result['comment']return retelse ret['comment'].append 'Enabledjob{0}fromschedule'.format name else ret['comment'].append 'Job{0}notpresentinschedule'.format name ret['comment'] '\n'.join ret['comment'] return ret
def get_certificate_footer_context data dict terms_of_service_and_honor_code branding_api.get_tos_and_honor_code_url if terms_of_service_and_honor_code ! branding_api.EMPTY_URL data.update {'company_tos_url' terms_of_service_and_honor_code} privacy_policy branding_api.get_privacy_url if privacy_policy ! branding_api.EMPTY_URL data.update {'company_privacy_url' privacy_policy} about branding_api.get_about_url if about ! branding_api.EMPTY_URL data.update {'company_about_url' about} return data
def get_data_for_unfinished_jobs unfinished_job_models job_models.JobModel.get_all_unfinished_jobs NUM_JOBS_IN_DASHBOARD_LIMIT return [_get_job_dict_from_job_model model for model in unfinished_job_models]
def my_kernel X Y M np.array [[2 0] [0 1.0]] return np.dot np.dot X M Y.T
def _get_error_details data default_code None if isinstance data list ret [_get_error_details item default_code for item in data]if isinstance data ReturnList return ReturnList ret serializer data.serializer return retelif isinstance data dict ret {key _get_error_details value default_code for key value in data.items }if isinstance data ReturnDict return ReturnDict ret serializer data.serializer return rettext force_text data code getattr data u'code' default_code return ErrorDetail text code
def get_comment_form parser token return CommentFormNode.handle_token parser token
def _validate_name name name str name name_length len name regex re.compile '^[a-zA-Z0-9][A-Za-z0-9_-]*[a-zA-Z0-9]$' if name_length < 3 or name_length > 48 ret Falseelif not re.match regex name ret Falseelse ret Trueif ret is False log.warning 'ALinodelabelmayonlycontainASCIIlettersornumbers dashes andunderscores mustbeginandendwithlettersornumbers andbeatleastthreecharactersinlength.' return ret
def destroy_namespace conf namespace force False try ip ip_lib.IPWrapper namespace namespace if force kill_dhcp conf namespace if ip.netns.exists namespace try kill_listen_processes namespace except PidsInNamespaceException LOG.error _LE 'Notallprocesseswerekilledin%s' namespace for device in ip.get_devices exclude_loopback True unplug_device conf device ip.garbage_collect_namespace except Exception LOG.exception _LE 'Errorunabletodestroynamespace %s' namespace
def ensure_local_plotly_files if check_file_permissions for fn in [CREDENTIALS_FILE CONFIG_FILE] utils.ensure_file_exists fn contents utils.load_json_dict fn for key val in list FILE_CONTENT[fn].items if key not in contents contents[key] valcontents_keys list contents.keys for key in contents_keys if key not in FILE_CONTENT[fn] del contents[key]utils.save_json_dict fn contents else warnings.warn "Lookslikeyoudon'thave'read-write'permissiontoyour'home' '~' directoryortoour'~/.plotly'directory.Thatmeansplotly'spythonapican'tsetuplocalconfigurationfiles.Noproblemthough!You'lljusthavetosign-inusing'plotly.plotly.sign_in '.Forhelpwiththat 'help plotly.plotly.sign_in '.\nQuestions?Visitcommunity.plot.lyorupgradetoaProplanfor1-1help https //goo.gl/1YUVu9"
def null_applicable_aside_types block return []
def _merge_map key values partial proto file_service_pb.KeyValues proto.set_key key proto.value_list .extend values proto.set_partial partial yield proto.Encode
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
def project_activity_year_options db current.dbtable current.s3db.project_activityquery table.deleted False min_field table.date.min start_date_min db query .select min_field orderby min_field limitby 0 1 .first [min_field]if start_date_min start_year start_date_min.yearelse start_year Nonemax_field table.end_date.max end_date_max db query .select max_field orderby max_field limitby 0 1 .first [max_field]if end_date_max end_year end_date_max.yearelse end_year Noneif not start_year or not end_year return {start_year start_year} or {end_year end_year} years {}for year in xrange start_year end_year + 1 years[year] yearreturn years
def read_dict filename return getcfs 'lang ' + filename filename lambda read_dict_aux filename
def replaceWith replStr def _replFunc *args return [replStr]return _replFunc
def _generate_java_test_coverage_flag env env_dict env.Dictionary jacoco_agent env_dict.get 'JACOCOAGENT' if jacoco_agent jacoco_agent os.path.abspath jacoco_agent target_under_test_package env_dict.get 'JAVATARGETUNDERTESTPKG' if target_under_test_package options []options.append 'includes %s' % ' '.join [ p + '.*' for p in target_under_test_package if p] options.append 'output file' return '-javaagent %s %s' % jacoco_agent ' '.join options return ''
def sample_count value len_uris len value if len_uris 1 return 'ten'if len_uris > 10 return 'ten'else return human_number len_uris
def insort_left a x lo 0 hi None if lo < 0 raise ValueError 'lomustbenon-negative' if hi is None hi len a while lo < hi mid lo + hi // 2 if a[mid] < x lo mid + 1 else hi mida.insert lo x
def pushed name tag 'latest' insecure_registry False image_name _get_image_name name tag if __opts__['test'] comment 'Image{0}willbepushed'.format image_name return _ret_status name name comment comment push __salt__['docker.push']returned push name tag tag insecure_registry insecure_registry log.debug 'Returned ' + str returned if returned['status'] changes {name {'Rev' returned['id']}}else changes {}return _ret_status returned name changes changes
def init_rttable rt_table interface if rt_table in ['local' 'main' 'default'] return stdout _ run settings.ip 'route' 'list' 'dev' interface for line in stdout.split '\n' args ['route' 'add'] + [x for x in line.split '' if x] args + ['dev' interface 'table' rt_table]run settings.ip *args
def volume_type_get_by_name context name return IMPL.volume_type_get_by_name context name
def survey_getPriorityQuestionForSeries series_id template_rec survey_getTemplateFromSeries series_id if template_rec ! None priority_question_code template_rec['priority_qstn']question survey_getQuestionFromCode priority_question_code series_id return questionelse return None
def pop_from_stack_section args if len args 0 return ''parts []for idx in xrange len args parts.append 'self->arg%d self->arguments_stack[self->deeplevel "arg%d"];\n DCTB self->arguments_stack[self->deeplevel "arg%d"] 0;' % idx idx idx parts.append '--self->deeplevel;' return '\n DCTB ' + '\n DCTB '.join parts
def _SkipFixed32 buffer pos end pos + 4if pos > end raise _DecodeError 'Truncatedmessage.' return pos
@register u'transpose-chars' def transpose_chars event b event.current_bufferp b.cursor_positionif p 0 returnelif p len b.text or b.text[p] u'\n' b.swap_characters_before_cursor else b.cursor_position + b.document.get_cursor_right_position b.swap_characters_before_cursor
def _setup_scenario_switches logger config hass scenario config.get CONF_SCENARIO if scenario for _ entity_info in scenario.items if entity_info[scsgate.CONF_SCS_ID] in scsgate.SCSGATE.devices continuename entity_info[CONF_NAME]scs_id entity_info[scsgate.CONF_SCS_ID]logger.info 'Adding%sscsgate.scenario_switch' name switch SCSGateScenarioSwitch name name scs_id scs_id logger logger hass hass scsgate.SCSGATE.add_device switch
def bfs_successors G source parent sourcechildren []for p c in bfs_edges G source if p parent children.append c continue yield parent children children [c]parent p yield parent children
def warning_priority def prep r if r.representation 'json' list_fields ['id' 'priority_rank' 'color_code' 'severity' 'certainty' 'urgency' 'event_type_id' 'event_code' 'name']s3db.configure 'cap_warning_priority' list_fields list_fields return Trues3.prep prepreturn s3_rest_controller
def _insert_header network_str incomings outgoings line_1 deque [] if incomings line_1.append 'In-->' line_1.append 'Layer' if outgoings line_1.append '-->Out' line_1.append 'Description' line_2 deque [] if incomings line_2.append '-------' line_2.append '-----' if outgoings line_2.append '-------' line_2.append '-----------' network_str.appendleft line_2 network_str.appendleft line_1 return network_str
def _unixdll_getnode _uuid_generate_time _buffer return UUID bytes _buffer.raw .node
def instance_get_all context columns_to_join None return IMPL.instance_get_all context columns_to_join columns_to_join
def depth_first_search node visit lambda node False traversable lambda node edge True _visited None stop visit node _visited _visited or {} _visited[node.id] Truefor n in node.links if stop return Trueif traversable node node.links.edge n is False continueif not n.id in _visited stop depth_first_search n visit traversable _visited return stop
def get_wanna_help_queue_from_session session ret []for project_id in session.get PROJECTS_TO_HELP_OUT_KEY [] try project mysite.search.models.Project.objects.get id project_id except mysite.search.models.Project.DoesNotExist continueret.append project ret list set ret return ret
def find_current_module depth 1 finddiff False frm inspect.currentframe for i in range depth frm frm.f_backif frm is None return Noneif finddiff currmod inspect.getmodule frm if finddiff is True diffmods [currmod]else diffmods []for fd in finddiff if inspect.ismodule fd diffmods.append fd elif isinstance fd six.string_types diffmods.append __import__ fd elif fd is True diffmods.append currmod else raise ValueError u'invalidentryinfinddiff' while frm frmb frm.f_backmodb inspect.getmodule frmb if modb not in diffmods return modbfrm frmbelse return inspect.getmodule frm
def CloseExpression clean_lines linenum pos line clean_lines.elided[linenum]startchar line[pos]if startchar not in ' {[<' return line clean_lines.NumLines -1 if startchar ' ' endchar ' 'if startchar '[' endchar ']'if startchar '{' endchar '}'if startchar '<' endchar '>' end_pos num_open FindEndOfExpressionInLine line pos 0 startchar endchar if end_pos > -1 return line linenum end_pos while linenum < clean_lines.NumLines - 1 linenum + 1line clean_lines.elided[linenum] end_pos num_open FindEndOfExpressionInLine line 0 num_open startchar endchar if end_pos > -1 return line linenum end_pos return line clean_lines.NumLines -1
def get_store_from_location uri loc location.get_location_from_uri uri return loc.store_name
def addOrbitsIfLarge distanceFeedRate loop orbitalFeedRatePerSecond temperatureChangeTime z if orbitsAreLarge loop temperatureChangeTime addOrbits distanceFeedRate loop orbitalFeedRatePerSecond temperatureChangeTime z
def stop_service service_name os_cmd ['/usr/bin/openstack-service' 'stop' service_name]return __salt__['cmd.retcode'] os_cmd 0
def alarm_keypress_handler service entity_ids service.data.get ATTR_ENTITY_ID keypress service.data.get ATTR_KEYPRESS _target_devices [device for device in DEVICES if device.entity_id in entity_ids ]for device in _target_devices EnvisalinkAlarm.alarm_keypress device keypress
def _is_url_dns urlstr url qurl_from_user_input urlstr assert url.isValid if utils.raises ValueError ipaddress.ip_address urlstr and not QHostAddress urlstr .isNull log.url.debug 'BogusIPURL->False' return Falsehost url.host if not host log.url.debug 'URLhasnohost->False' return Falselog.url.debug 'DoingDNSrequestfor{}'.format host info QHostInfo.fromName host return not info.error
def drk_org_rheader r tabs [] if r.representation ! 'html' return Nonefrom s3 import s3_rheader_resource S3ResourceHeader tablename record s3_rheader_resource r if tablename ! r.tablename resource current.s3db.resource tablename id record.id else resource r.resourcerheader Nonerheader_fields []if record T current.Tif tablename 'org_facility' if not tabs tabs [ T 'BasicDetails' None ]rheader_fields [['name' 'email'] ['organisation_id' 'phone1'] ['location_id' 'phone2']]rheader S3ResourceHeader rheader_fields tabs r table resource.table record record return rheader
def p_function_definition_1 t pass
def get_current_theme request None if _current_theme_class is not _not_set if _current_theme_class return _current_theme_class return Nonevalue cache.get THEME_CACHE_KEY if value return valueif request and hasattr request '_current_xtheme' return request._current_xthemetheme _get_current_theme if request request._current_xtheme themecache.set THEME_CACHE_KEY theme return theme
@hello.get permission NO_PERMISSION_REQUIRED def get_hello request settings request.registry.settingsproject_name settings['project_name']project_version settings['project_version']data dict project_name project_name project_version project_version http_api_version settings['http_api_version'] project_docs settings['project_docs'] url request.route_url hello.name eos get_eos request if eos data['eos'] eosdata['settings'] {}public_settings request.registry.public_settingsfor setting in list public_settings data['settings'][setting] settings[setting]if Authenticated in request.effective_principals data['user'] request.get_user_info data['capabilities'] request.registry.api_capabilitiesreturn data
def parse_http_list u encoded_str u.encode 'utf-8' encoded_list urllib2.parse_http_list encoded_str return [s.decode 'utf-8' for s in encoded_list]
def walk top topdown True followlinks False names os.listdir top dirs nondirs [] [] for name in names if path.isdir path.join top name dirs.append name else nondirs.append name if topdown yield top dirs nondirs for name in dirs fullpath path.join top name if followlinks or not path.islink fullpath for x in walk fullpath topdown followlinks yield x if not topdown yield top dirs nondirs
def _extract_instance_info instances ret {}for instance in instances if isinstance instance['instancesSet']['item'] list for item in instance['instancesSet']['item'] name _extract_name_tag item ret[name] itemret[name]['name'] nameret[name].update dict id item['instanceId'] image item['imageId'] size item['instanceType'] state item['instanceState']['name'] private_ips item.get 'privateIpAddress' [] public_ips item.get 'ipAddress' [] else item instance['instancesSet']['item']name _extract_name_tag item ret[name] itemret[name]['name'] nameret[name].update dict id item['instanceId'] image item['imageId'] size item['instanceType'] state item['instanceState']['name'] private_ips item.get 'privateIpAddress' [] public_ips item.get 'ipAddress' [] return ret
def prexsync_create_container_stat_table self conn put_timestamp None if put_timestamp is None put_timestamp normalize_timestamp 0 conn.executescript "\nCREATETABLEcontainer_stat \naccountTEXT \ncontainerTEXT \ncreated_atTEXT \nput_timestampTEXTDEFAULT'0' \ndelete_timestampTEXTDEFAULT'0' \nobject_countINTEGER \nbytes_usedINTEGER \nreported_put_timestampTEXTDEFAULT'0' \nreported_delete_timestampTEXTDEFAULT'0' \nreported_object_countINTEGERDEFAULT0 \nreported_bytes_usedINTEGERDEFAULT0 \nhashTEXTdefault'00000000000000000000000000000000' \nidTEXT \nstatusTEXTDEFAULT'' \nstatus_changed_atTEXTDEFAULT'0' \nmetadataTEXTDEFAULT''\n ;\n\nINSERTINTOcontainer_stat object_count bytes_used \nVALUES 0 0 ;\n" conn.execute '\nUPDATEcontainer_stat\nSETaccount ? container ? created_at ? id ? \nput_timestamp ?\n' self.account self.container normalize_timestamp time str uuid4 put_timestamp
@step 'Ihavenotsentanyemails' def mail_not_sent step return mail_sent_count step 0
def find_words string trie _boundary_re re.compile '[%s]+' % re.escape DEFAULT_BOUNDARY_CHARS results []start 0while start < len string keys match_all string[start ] trie for key in keys l len key if start + l len string or _boundary_re.match string[ start + l ] results.append key start start + l m _boundary_re.search string start if m is None breakstart m.end return results
def sanitize_hostname hostname if six.PY3 hostname hostname.encode 'latin-1' 'ignore' hostname hostname.decode 'latin-1' elif isinstance hostname six.text_type hostname hostname.encode 'latin-1' 'ignore' hostname re.sub '[_]' '-' hostname hostname re.sub '[^\\w.-]+' '' hostname hostname hostname.lower hostname hostname.strip '.-' return hostname
def parse_query_string query_string keep_blank_values True encoding 'utf-8' if image_map_pattern.match query_string pm query_string.split ' ' pm {'x' int pm[0] 'y' int pm[1] }else pm _parse_qs query_string keep_blank_values encoding encoding return pm
def printException exctype value traceback print ''.join formatException exctype value traceback skip 1
@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_POSTdef mark_student_can_skip_entrance_exam request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id student_identifier request.POST.get 'unique_student_identifier' student get_student_from_identifier student_identifier __ created EntranceExamConfiguration.objects.get_or_create user student course_id course_id if created message _ 'Thisstudent %s willskiptheentranceexam.' % student_identifier else message _ 'Thisstudent %s isalreadyallowedtoskiptheentranceexam.' % student_identifier response_payload {'message' message}return JsonResponse response_payload
def mangle_type typ if typ in N2C typename N2C[typ]else typename str typ return mangle_type_c typename
def endpoint_absent name profile None **connection_args ret {'name' name 'changes' {} 'result' True 'comment' 'Endpointforservice"{0}"isalreadyabsent'.format name }endpoint __salt__['keystone.endpoint_get'] name profile profile **connection_args if not endpoint return retelse if __opts__.get 'test' ret['result'] Noneret['comment'] 'Endpointforservice"{0}"willbedeleted'.format name return ret__salt__['keystone.endpoint_delete'] name profile profile **connection_args ret['comment'] 'Endpointforservice"{0}"hasbeendeleted'.format name ret['changes']['endpoint'] 'Deleted'return ret
def validate_metadata map_fp gradient_variable metadata parse_mapping_file map_fp if not gradient_variable in metadata[1] raise Exception 'Header%snotfoundinmetadataheaders ' % gradient_variable + ' '.join metadata[1] column_ix metadata[1].index gradient_variable gradient zip *metadata[0] [column_ix]for i in xrange len gradient try float gradient[i] except ValueError if gradient[i] ! 'NA' raise Exception 'Non-numericvalue%sfoundinmetadatagradientcolumn ' % gradient[i] + ' '.join gradient
def _plot results metrics formats title x_ticks x_label format_markers 'x' '|' 'o' '+' metric_colors 'c' 'm' 'y' 'k' 'g' 'r' 'b' fig plt.figure 'scikit-learnmultilabelmetricsbenchmarks' plt.title title ax fig.add_subplot 111 for i metric in enumerate metrics for j format in enumerate formats ax.plot x_ticks results[ i j ].flat label '{} {}'.format metric format marker format_markers[j] color metric_colors[ i % len metric_colors ] ax.set_xlabel x_label ax.set_ylabel 'Time s ' ax.legend plt.show
def get_enrolled_students course_id objects UserProfile.objectscourse_key CourseKey.from_string course_id students objects.filter user__courseenrollment__course_id course_key user__courseenrollment__is_active True return students
def mysql_encode t return 'CHAR %s ' % ' '.join str ord c for c in t
def zk_service_name ip_address keyname key_file '{}/{}.key'.format KEY_DIRECTORY keyname ssh_cmd ['ssh' '-i' key_file ip_address 'ls{}'.format SERVICES_DIR ]response subprocess.check_output ssh_cmd init_files response.split for init_file in init_files if 'zookeeper' in init_file return init_fileraise OSError 'UnabletofindZooKeeperon{}'.format ip_address
def wait objects None timeout None count None if objects is None return get_hub .join timeout timeout result []if count is None return list iwait objects timeout for obj in iwait objects objects timeout timeout result.append obj count - 1if count < 0 breakreturn result
def erfinv x a 0.147 lnx log 1 - x * x part1 2 / a * pi + lnx / 2 part2 lnx / a sgn 1 if x > 0 else -1 return sgn * sqrt sqrt part1 * part1 - part2 - part1
def impulse2 system X0 None T None N None **kwargs if isinstance system lti sys system._as_ss elif isinstance system dlti raise AttributeError 'impulse2canonlybeusedwithcontinuous-timesystems.' else sys lti *system ._as_ss B sys.Bif B.shape[ -1 ] ! 1 raise ValueError 'impulse2 requiresasingle-inputsystem.' B B.squeeze if X0 is None X0 zeros_like B if N is None N 100if T is None T _default_response_times sys.A N ic B + X0 Tr Yr Xr lsim2 sys T T X0 ic **kwargs return Tr Yr
def learn_cache_key request response cache_timeout None key_prefix None cache None if key_prefix is None key_prefix settings.CACHE_MIDDLEWARE_KEY_PREFIXif cache_timeout is None cache_timeout settings.CACHE_MIDDLEWARE_SECONDScache_key _generate_cache_header_key key_prefix request if cache is None cache get_cache settings.CACHE_MIDDLEWARE_ALIAS if response.has_header u'Vary' is_accept_language_redundant settings.USE_I18N or settings.USE_L10N headerlist []for header in cc_delim_re.split response[u'Vary'] header header.upper .replace u'-' u'_' if header u'ACCEPT_LANGUAGE' and is_accept_language_redundant continueheaderlist.append u'HTTP_' + header headerlist.sort cache.set cache_key headerlist cache_timeout return _generate_cache_key request request.method headerlist key_prefix else cache.set cache_key [] cache_timeout return _generate_cache_key request request.method [] key_prefix
def get_field_setup_query query model column_name if not hasattr model column_name rel_model getattr model column_name.split '.' [0] .mapper.class_query query.join rel_model return query getattr rel_model column_name.split '.' [1] else return query getattr model column_name
def load_plugin_names settings seen set def generate_name path maxsplit 0 splits None if splits is None splits len path.split '.' - 1 name '.'.join path.split '.' splits - maxsplit [ -1 ].rsplit '.' maxsplit if name not in seen or maxsplit > splits seen.add name return namereturn generate_name path maxsplit + 1 splits if settings['PLUGINS'] return [generate_name path for path in settings['PLUGINS']]else return ['Annotations']
def tokenizeJsonEntry json_dict return set find_words.findall ''.join word.lower for word in json_dict.values
def _HandleWildcardCases first_handler second_handler merged_handlers set if len first_handler.pattern < 1 or len second_handler.pattern < 1 return merged_handlersif first_handler.pattern[ -1 ] second_handler.pattern[0] ! '*' '*' return merged_handlersfirst_no_star first_handler.pattern[ -1 ]merged_handlers.add SimpleHandler first_no_star + second_handler.pattern if second_handler.MatchesString first_no_star merged_handlers.add SimpleHandler first_no_star return merged_handlers
def test_paginated_url url '%s?%s' % reverse 'search' 'q bookmarks&page 2' request RequestFactory .get url queryset [{} {}]paginated paginate request queryset eq_ paginated.url request.build_absolute_uri request.path + '?q bookmarks'
def _get_course_enrollment_domain course_id course modulestore .get_course course_id if course is None return Nonereturn course.enrollment_domain
def get_filename_from_path path dirpath filename ntpath.split path return filename if filename else ntpath.basename dirpath
@hsa.jit device True def shuf_device_inclusive_scan data temp tid hsa.get_local_id 0 lane tid & _WARPSIZE - 1 warpid tid >> 6 warp_scan_res shuf_wave_inclusive_scan data hsa.barrier if lane _WARPSIZE - 1 temp[warpid] warp_scan_reshsa.barrier if warpid 0 shuf_wave_inclusive_scan temp[lane] hsa.barrier blocksum 0if warpid > 0 blocksum temp[ warpid - 1 ]return warp_scan_res + blocksum
def dist_location dist egg_link egg_link_path dist if egg_link return egg_linkreturn dist.location
def test_scenario_outline1_ptbr_from_string ptbr Language 'pt-br' scenario Scenario.from_string SCENARIO_OUTLINE1 language ptbr assert_equals scenario.name 'Cadastrarumalunonobancodedados' assert_equals scenario.outlines [{'nome' u'Gabriel' u'idade' '22'} {'nome' u'Jo\xe3o' u'idade' '30'}]
def get_rdm_create_spec client_factory device adapter_type 'lsiLogic' disk_type 'rdmp' create_vmdk_spec client_factory.create 'ns0 DeviceBackedVirtualDiskSpec' create_vmdk_spec.adapterType adapter_typecreate_vmdk_spec.diskType disk_typecreate_vmdk_spec.device devicereturn create_vmdk_spec
def test_feature_first_scenario_tags_extraction feature Feature.from_string FEATURE23 assert that feature.scenarios[0].tags .deep_equals ['onetag' 'another' '$%^&even-weird_chars']
def strswapmid data return ''.join arrswapmid data
def _windows_long_path_name short_path if not isinstance short_path six.text_type short_path short_path.decode _fsencoding import ctypesbuf ctypes.create_unicode_buffer 260 get_long_path_name_w ctypes.windll.kernel32.GetLongPathNameWreturn_value get_long_path_name_w short_path buf 260 if return_value 0 or return_value > 260 return short_pathelse long_path buf.valueif len long_path > 1 and long_path[1] ' ' long_path long_path[0].upper + long_path[1 ] return long_path
def paths_equal paths_1 paths_2 if len paths_1 ! len paths_2 return Falsefor path_1 path_2 in zip paths_1 paths_2 if len path_1 ! len path_2 return Falsefor path_item_1 path_item_2 in zip path_1 path_2 if path_item_1.display_name ! path_item_2.display_name return Falseusage_key_1 path_item_1.usage_key.replace course_key modulestore .fill_in_run path_item_1.usage_key.course_key usage_key_2 path_item_1.usage_key.replace course_key modulestore .fill_in_run path_item_2.usage_key.course_key if usage_key_1 ! usage_key_2 return Falsereturn True
def get_network_with_the_name session network_name 'vmnet0' cluster None vm_networks session._call_method vim_util 'get_object_properties' None cluster 'ClusterComputeResource' ['network'] while vm_networks if vm_networks.objects network_obj _get_network_obj session vm_networks.objects network_name if network_obj session._call_method vutil 'cancel_retrieval' vm_networks return network_objvm_networks session._call_method vutil 'continue_retrieval' vm_networks LOG.debug 'Network%snotfoundoncluster!' network_name
@log_calldef metadef_object_get_all context namespace_name namespace metadef_namespace_get context namespace_name objects []_check_namespace_visibility context namespace namespace_name for object in DATA['metadef_objects'] if object['namespace_id'] namespace['id'] objects.append object return objects
def _check_all_skipped test import doctestall_skipped all x.options.get doctest.SKIP False for x in test.examples if all_skipped pytest.skip 'alltestsskippedby+SKIPoption'
def _render_jinja2 recipe_dir try import jinja2except ImportError raise Exception 'Failedtoimportjinja2forevaluatingCondarecipetemplates.' loaders [jinja2.FileSystemLoader recipe_dir ]env jinja2.Environment loader jinja2.ChoiceLoader loaders template env.get_or_select_template 'meta.yaml' return template.render environment env
def read_int s start_position m _READ_INT_RE.match s start_position if not m raise ReadError 'integer' start_position return int m.group m.end
@register.filter u'slice' is_safe True def slice_filter value arg try bits []for x in arg.split u' ' if len x 0 bits.append None else bits.append int x return value[slice *bits ]except ValueError TypeError return value
def list_security_groups profile None conn _auth profile return conn.list_security_groups
def create_l2_gw_service cluster tenant_id display_name devices tags [{'tag' tenant_id 'scope' 'os_tid'}]gateways [{'transport_node_uuid' device['id'] 'device_id' device['interface_name'] 'type' 'L2Gateway'} for device in devices]gwservice_obj {'display_name' _check_and_truncate_name display_name 'tags' tags 'gateways' gateways 'type' 'L2GatewayServiceConfig'}try return json.loads do_single_request 'POST' _build_uri_path GWSERVICE_RESOURCE json.dumps gwservice_obj cluster cluster except NvpApiClient.NvpApiException LOG.exception _ 'AnexceptionoccuredwhilecommunicatingwiththeNVPcontrollerforcluster %s' cluster.name raise
@allow_unvouched@never_cachedef confirm_delete request return render request 'phonebook/confirm_delete.html'
def MakeJoint pmf1 pmf2 joint Joint for v1 p1 in pmf1.Items for v2 p2 in pmf2.Items joint.Set v1 v2 p1 * p2 return joint
def format_exception msg *args **kwargs tb traceback.extract_tb sys.exc_info [2] limit 1 if len tb > 0 filename lineno func text tb[0]else filename lineno func text u'<unknown>'return msg.format filename filename lineno lineno func func text text *args **kwargs
def get_deprecated_tense removal_version future_tense u'willbe' past_tense u'was' return future_tense if Version removal_version > PANTS_SEMVER else past_tense
def discover_files base_path sub_path '' ext '' trim_base_path False file_list []for root dirs files in walk path.join base_path sub_path if trim_base_path root path.relpath root base_path file_list.extend [path.join root file_name for file_name in files if file_name.endswith ext ] return sorted file_list
def _plot_ci_band ax x ci color err_kws **kwargs low high ciif 'alpha' not in err_kws err_kws['alpha'] 0.2ax.fill_between x low high facecolor color **err_kws
def _simplified_pairs terms simplified_terms []todo list range len terms for i ti in enumerate terms[ -1 ] for j_i tj in enumerate terms[ i + 1 ] index _check_pair ti tj if index ! -1 todo[i] todo[ j_i + i + 1 ] Nonenewterm ti[ ]newterm[index] 3if newterm not in simplified_terms simplified_terms.append newterm simplified_terms.extend [terms[i] for i in [_ for _ in todo if _ is not None ]] return simplified_terms
@receiver pre_save sender Microsite def on_microsite_updated sender instance **kwargs if instance.id original Microsite.objects.get id instance.id _make_archive_copy original
def strict_positive_int integer_string cutoff None ret int integer_string if ret < 0 raise ValueError if cutoff ret min ret cutoff return ret
def max_api_calls user return _rules_for_user user [ -1 ][1]
@utils.arg 'server' metavar '<server>' help 'NameorIDofserver.' def do_restore cs args utils.find_resource cs.servers args.server deleted True .restore
def get_client_for_backend backend_name vserver_name None config get_backend_configuration backend_name client client_cmode.Client transport_type config.netapp_transport_type username config.netapp_login password config.netapp_password hostname config.netapp_server_hostname port config.netapp_server_port vserver vserver_name or config.netapp_vserver trace utils.TRACE_API return client
def partitioning_index df npartitions return hash_pandas_object df index False % int npartitions
def get_and_delete_messages request include_auth False assert hasattr request 'session' "django-session-messagesrequiressessionmiddlewaretobeinstalled.EdityourMIDDLEWARE_CLASSESsettingtoinsert'django.contrib.sessions.middleware.SessionMiddleware'."messages request.session.pop 'messages' [] if include_auth and request.user.is_authenticated messages.extend request.user.get_and_delete_messages return messages
def is_vlanid_used vlan_id LOG.debug _ 'is_vlanid_used called' session db.get_session try vlanid session.query l2network_models.VlanID .filter_by vlan_id vlan_id .one return vlanid['vlan_used']except exc.NoResultFound raise c_exc.VlanIDNotFound vlan_id vlan_id
def _init_globals global _FROM_MODEL_MAP _TO_MODEL_MAP _SESSION_HANDLERif not _FROM_MODEL_MAP _FROM_MODEL_MAP defaultdict str _FROM_MODEL_MAP.update dict c.model c.natural_key for c in ContentType.objects.all if not _TO_MODEL_MAP _TO_MODEL_MAP defaultdict str _TO_MODEL_MAP.update dict c.natural_key c.model_class for c in ContentType.objects.all if not _SESSION_HANDLER from evennia.server.sessionhandler import SESSION_HANDLER as _SESSION_HANDLER
def truncate_fields old_value new_value max_value_length settings.TRACK_MAX_EVENT / 4 serialized_old_value old_was_truncated _get_truncated_setting_value old_value max_length max_value_length serialized_new_value new_was_truncated _get_truncated_setting_value new_value max_length max_value_length truncated_values []if old_was_truncated truncated_values.append 'old' if new_was_truncated truncated_values.append 'new' return {'old' serialized_old_value 'new' serialized_new_value 'truncated' truncated_values}
def prod a axis None dtype None out None keepdims False return a.prod axis dtype out keepdims
def transpose matlist K return [list a for a in zip *matlist ]
@mock_streams 'stdout' def test_puts_with_user_output_on s 'string!'output.user Trueputs s show_prefix False eq_ sys.stdout.getvalue s + '\n'
def request_middleware api None def decorator middleware_method apply_to_api hug.API api if api else hug.api.from_object middleware_method class MiddlewareRouter object __slots__ def process_request self request response return middleware_method request response apply_to_api.http.add_middleware MiddlewareRouter return middleware_methodreturn decorator
def retrieve fid share_key None url build_url RESOURCE id fid params make_params share_key share_key return request 'get' url params params
def randbelow exclusive_upper_bound if exclusive_upper_bound < 0 raise ValueError 'Upperboundmustbepositive.' return _sysrand._randbelow exclusive_upper_bound
def getBearingCenterXs bearingCenterX numberOfSteps stepX bearingCenterXs []for stepIndex in xrange numberOfSteps + 1 bearingCenterXs.append bearingCenterX bearingCenterX + stepXreturn bearingCenterXs
def create_country_codes user tk.get_action 'get_site_user' {'ignore_auth' True} {} context {'user' user['name']}try data {'id' 'country_codes'}tk.get_action 'vocabulary_show' context data logging.info 'Examplegenrevocabularyalreadyexists skipping.' except tk.ObjectNotFound logging.info "Creatingvocab'country_codes'" data {'name' 'country_codes'}vocab tk.get_action 'vocabulary_create' context data for tag in u'uk' u'ie' u'de' u'fr' u'es' logging.info "Addingtag{0}tovocab'country_codes'".format tag data {'name' tag 'vocabulary_id' vocab['id']}tk.get_action 'tag_create' context data
def ring_of_cliques num_cliques clique_size if num_cliques < 2 raise nx.NetworkXError 'Aringofcliquesmusthaveatleasttwocliques' if clique_size < 2 raise nx.NetworkXError 'Thecliquesmusthaveatleasttwonodes' G nx.Graph for i in range num_cliques edges itertools.combinations range i * clique_size i * clique_size + clique_size 2 G.add_edges_from edges G.add_edge i * clique_size + 1 i + 1 * clique_size % num_cliques * clique_size return G
def redirect_to_message title html http_status_code None context None message_id generate_hash length 8 message {u'context' context or {} u'http_status_code' http_status_code or 200 }message[u'context'].update {u'header' title u'title' title u'message' html} cache .set_value u'message_id {0}'.format message_id message expires_in_sec 60 location u'/message?id {0}'.format message_id if not getattr local u'is_ajax' False local.response[u'type'] u'redirect'local.response[u'location'] locationelse return location
def send_msg app msg reply_cls None reply_multi False return app.send_request event.SendMsgRequest msg msg reply_cls reply_cls reply_multi reply_multi
def add_path path config None log.debug 'Addpath%s' % path if not path return []added []parent os.path.dirname path if parent and os.path.exists os.path.join path '__init__.py' added.extend add_path parent config elif not path in sys.path log.debug 'insert%sintosys.path' path sys.path.insert 0 path added.append path if config and config.srcDirs for dirname in config.srcDirs dirpath os.path.join path dirname if os.path.isdir dirpath sys.path.insert 0 dirpath added.append dirpath return added
def matrix_dot *args rval args[0]for a in args[1 ] rval theano.tensor.dot rval a return rval
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def bpm_from_config config extra getattr config 'BOT_EXTRA_BACKEND_DIR' [] return SpecificPluginManager config 'backends' ErrBot CORE_BACKENDS extra_search_dirs extra
def _parse_multi_options options split_token ' ' if options return [o.strip for o in options.split split_token if o.strip ]else return options
def _get_state pkg cmd ['opkg' 'status']cmd.append pkg out __salt__['cmd.run'] cmd python_shell False state_flag ''for line in salt.utils.itertools.split out '\n' if line.startswith 'Status' _status _state_want state_flag _state_status line.split return state_flag
def _replaceBR mo txt mo.group 0 return txt.replace '<br>' ' '
def strip_ccx val retval valccx_id Noneif isinstance retval CCXLocator ccx_id retval.ccxretval retval.to_course_locator elif isinstance retval CCXBlockUsageLocator ccx_id retval.course_key.ccxretval retval.to_block_locator else for field_name in XMODULE_FIELDS_WITH_USAGE_KEYS if hasattr retval field_name stripped_field_value ccx_id strip_ccx getattr retval field_name setattr retval field_name stripped_field_value return retval ccx_id
def omniscient_datetime *args d original_datetime *args if settings.USE_TZ d timezone.make_aware d timezone.utc return d
def _make_nxm __name __vendor __field __len None type None **kw if type is None type _nxm_numeric_entry else type _fix_types type t _make_type __vendor __field kw['_nxm_type'] tif __len is not None kw['_nxm_length'] __lenimport __builtin__typ __builtin__.typec typ __name tuple type kw _nxm_type_to_class[t] c_nxm_name_to_type[__name] tassert __name not in globals globals [__name] creturn c
def cart2sph z y x width len z elevation numpy.empty [width width] radius numpy.empty [width width] azimuth numpy.empty [width width] radius numpy.sqrt x ** 2 + y ** 2 + z ** 2 azimuth numpy.arctan2 y x elevation numpy.arctan2 z numpy.sqrt x ** 2 + y ** 2 azimuth * 180.0 / numpy.pi elevation * 180.0 / numpy.pi sphere numpy.array [elevation azimuth radius] sphere numpy.rollaxis sphere 0 3 return sphere
def to_ascii input_string return unicodedata.normalize 'NFKD' unicode input_string .encode 'ascii' 'ignore'
def parse_cost_equation source constraints if 'cost' in constraints raise error 'morethanonecostequation' source.string source.pos cost {}parse_cost_term source cost while source.match '+' parse_cost_term source cost max_inc parse_fuzzy_compare source if max_inc is None raise ParseError max_cost int parse_count source if not max_inc max_cost - 1if max_cost < 0 raise error 'badfuzzycostlimit' source.string source.pos cost['max'] max_costconstraints['cost'] cost
def test_none_transform sc SkyCoord 0 * u.deg 1 * u.deg sc_arr SkyCoord 0 * u.deg [1 2] * u.deg sc2 sc.transform_to ICRS assert sc.ra sc2.ra and sc.dec sc2.dec sc5 sc.transform_to u'fk5' assert sc5.ra sc2.transform_to u'fk5' .ra sc_arr2 sc_arr.transform_to ICRS sc_arr5 sc_arr.transform_to u'fk5' npt.assert_array_equal sc_arr5.ra sc_arr2.transform_to u'fk5' .ra
def LSTD_values T R fMap discountFactor **kwargs statMatrix statResidual trueFeatureStats T R fMap discountFactor **kwargs weights lstsq statMatrix statResidual [0]return dot weights fMap
def create_children store parent category load_factor created_count 0for child_index in range load_factor child_object ItemFactory.create parent_location parent.location category category display_name u'{}{}{}'.format category child_index time.clock modulestore store publish_item True start datetime 2015 3 1 tzinfo UTC created_count + 1if category in COURSE_CHILD_STRUCTURE created_count + create_children store child_object COURSE_CHILD_STRUCTURE[category] load_factor return created_count
def get_ref_to_error error return get_ref_to_doc 'webapi2.0-error-%s' % error.code
def web_listing_all_files url count 0 max_count None urls [] dirs files parse_web_listing url for f in files urls.append url + f count + 1if max_count is not None and count > max_count logger.warning 'Reachedmaximumlimitforthiscategory' return urls count for d in dirs new_urls count web_listing_all_files url + d count max_count urls + new_urlsif max_count is not None and count > max_count breakreturn urls count
def _get_namespaces apiserver_url name '' url '{0}/api/v1/namespaces/{1}'.format apiserver_url name ret http.query url if ret.get 'body' return json.loads ret.get 'body' else return None
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def root_test return True
def process_value name value action ACTIONS.get name if not action return valueif callable action.type return action.type value if action.const return bool int value return value
def getGeometryOutputByConnection connectionEnd connectionStart geometryOutput xmlElement firstValue geometryOutput.values [0]firstValue['connectionStart'] connectionStartfirstValue['connectionEnd'] connectionEndreturn solid.getGeometryOutputByManipulation geometryOutput xmlElement
def teredoAddrExtractInfo x addr inet_pton socket.AF_INET6 x server inet_ntop socket.AF_INET addr[4 8] flag struct.unpack '!H' addr[8 10] [0]mappedport struct.unpack '!H' strxor addr[10 12] '\xff' * 2 [0]mappedaddr inet_ntop socket.AF_INET strxor addr[12 16] '\xff' * 4 return server flag mappedaddr mappedport
def _get_vm_by_id vmid allDetails False for vm_name vm_details in six.iteritems get_resources_vms includeConfig allDetails if str vm_details['vmid'] str vmid return vm_detailslog.info 'VMwithID"{0}"couldnotbefound.'.format vmid return False
def resource_path resource *elements return _join_path_tuple resource_path_tuple resource *elements
def match document topic None result_key None result_relative_url '/_ah/prospective_search' result_task_queue 'default' result_batch_size DEFAULT_RESULT_BATCH_SIZE result_return_document True from google.appengine.ext import dbrequest prospective_search_pb.MatchRequest if isinstance document db.Model topic _get_document_topic document topic doc_pb db.model_to_protobuf document if result_return_document request.set_result_python_document_class _doc_class.MODEL elif isinstance document datastore.Entity topic _get_document_topic document topic doc_pb document.ToPb if result_return_document request.set_result_python_document_class _doc_class.ENTITY else raise DocumentTypeError request.set_topic topic request.mutable_document .CopyFrom doc_pb if result_key request.set_result_key result_key request.set_result_relative_url result_relative_url request.set_result_task_queue result_task_queue request.set_result_batch_size result_batch_size response prospective_search_pb.MatchResponse _make_sync_call 'matcher' 'Match' request response
def fetch_google uuid fetch_url constants.UrlfetchTestIdentifiers.GOOGLE_URLreturn fetch fetch_url
def cleanup_list wdir skip_nzb if cfg.cleanup_list try files os.listdir wdir except files for filename in files path os.path.join wdir filename if os.path.isdir path cleanup_list path skip_nzb elif on_cleanup_list filename skip_nzb try logging.info 'Removingunwantedfile%s' path os.remove path except logging.error T 'Removing%sfailed' clip_path path logging.info 'Traceback ' exc_info True if files try remove_dir wdir except pass
def addPixelToPixelTable pixelDictionary value x y pixelDictionary[getStepKey x y ] value
def fix_frame_records_filenames records fixed_records []for frame filename line_no func_name lines index in records filename py3compat.cast_unicode_py2 filename 'utf-8' if not filename.endswith '.pyx' '.pxd' '.pxi' better_fn frame.f_globals.get '__file__' None if isinstance better_fn str filename better_fnfixed_records.append frame filename line_no func_name lines index return fixed_records
def suspend_to_disk set_power_state 'disk'
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def libvlc_media_subitems p_md f _Cfunctions.get 'libvlc_media_subitems' None or _Cfunction 'libvlc_media_subitems' 1 class_result MediaList ctypes.c_void_p Media return f p_md
def _community_defaults return {'mode' 'ro'}
def isLocked name l FilesystemLock name result Nonetry result l.lock finally if result l.unlock return not result
def double_nibble_hex_encoding t parts []for c in t x y _get_nibbles c parts.append '%%%X%%%X' % ord x ord y return '%' + '%'.join parts
def connect_to_cloud_networks region None return _create_client ep_name 'compute network' region region
def askquestion title None message None **options return _show title message QUESTION YESNO **options
def test_aws_cf_simple capsys tmpdir mocked_aws_cf_simple info desc check_success capsys tmpdir mocked_aws_cf_simple assert info['type'] 'cloudformation' assert 'stack_name' in info assert 'region' in info['provider'] assert 'access_key_id' in info['provider'] assert 'secret_access_key' in info['provider'] assert info['ssh']['key_name'] 'default' assert info['ssh']['delete_with_stack'] is False assert info['ssh']['private_key'] MOCK_SSH_KEY_DATA assert info['ssh']['user'] 'core' assert 'stack_name' in desc
def get_index_key_from_params params if len params ! 5 and len params ! 4 raise ValueError 'Badnumberofparams' if params[ -1 ] is None key dbconstants.KEY_DELIMITER.join params[ -1 ] + dbconstants.KEY_DELIMITER else key dbconstants.KEY_DELIMITER.join params return key
def validate_loop doctype name lft rgt if name in frappe.db.sql_list u'selectnamefrom`tab%s`wherelft< %sandrgt> %s' % doctype u'%s' u'%s' lft rgt frappe.throw _ u'Itemcannotbeaddedtoitsowndescendents' NestedSetRecursionError
def remaining start ends_in now None relative True now now or datetime.now end_date start + ends_in if not relative end_date delta_resolution end_date ends_in return end_date - now
@keras_testdef test_masking_layer I np.random.random 6 3 4 V np.abs np.random.random 6 3 5 V / V.sum axis -1 keepdims True model Sequential model.add Masking input_shape 3 4 model.add recurrent.LSTM output_dim 5 return_sequences True unroll False model.compile loss 'categorical_crossentropy' optimizer 'adam' model.fit I V nb_epoch 1 batch_size 100 verbose 1 model Sequential model.add Masking input_shape 3 4 model.add recurrent.LSTM output_dim 5 return_sequences True unroll True model.compile loss 'categorical_crossentropy' optimizer 'adam' model.fit I V nb_epoch 1 batch_size 100 verbose 1
def dict_to_json xcol ycols labels value_columns json_data dict json_data['cols'] [{'id' xcol 'label' as_unicode labels[xcol] 'type' 'string'}]for ycol in ycols json_data['cols'].append {'id' ycol 'label' as_unicode labels[ycol] 'type' 'number'} json_data['rows'] []for value in value_columns row {'c' []}if isinstance value[xcol] datetime.date row['c'].append {'v' str value[xcol] } else row['c'].append {'v' value[xcol]} for ycol in ycols if value[ycol] row['c'].append {'v' value[ycol]} else row['c'].append {'v' 0} json_data['rows'].append row return json_data
def get_import_stacklevel import_hook py_version sys.version_info[ 2]if py_version < 3 2 return 4 if import_hook else 2 elif py_version 3 3 return 8 if import_hook else 10 elif py_version 3 4 return 10 if import_hook else 8 else return 4 if import_hook else 2
def get_vmdk_create_spec client_factory size_in_kb adapter_type 'lsiLogic' disk_type 'preallocated' create_vmdk_spec client_factory.create 'ns0 FileBackedVirtualDiskSpec' create_vmdk_spec.adapterType adapter_typecreate_vmdk_spec.diskType disk_typecreate_vmdk_spec.capacityKb size_in_kbreturn create_vmdk_spec
def ensure_container_agent_enabled node to_enable d is_container_agent_running node def change_if_needed enabled if enabled ! to_enable return set_container_agent_enabled_on_node node to_enable d.addCallback change_if_needed return d
def get_bits flags reverse False bits 8 mybits 1 2 4 8 16 32 64 128 256 512 1024 2048 [ bits]rev_num 1if reverse rev_num -1 ret array 'B' ret_append ret.appendfor bit in mybits[ rev_num] ret_append flags & bit ! 0 return ret
def delfacl acl_type acl_name '' *args **kwargs recursive kwargs.pop 'recursive' False _raise_on_no_files *args cmd 'setfacl'if recursive cmd + '-R'cmd + '-x'cmd '{0}{1} {2}'.format cmd _acl_prefix acl_type acl_name for dentry in args cmd + '"{0}"'.format dentry __salt__['cmd.run'] cmd python_shell False return True
def atrous_conv2d x kernel rate 1 border_mode 'valid' dim_ordering 'default' image_shape None filter_shape None if dim_ordering 'default' dim_ordering image_dim_ordering if dim_ordering not in {'th' 'tf'} raise ValueError 'Unknowndim_ordering' + str dim_ordering if rate 1 return conv2d x kernel strides 1 1 border_mode border_mode dim_ordering dim_ordering x _preprocess_conv2d_input x dim_ordering kernel _preprocess_conv2d_kernel kernel dim_ordering padding _preprocess_border_mode border_mode x tf.nn.atrous_conv2d x kernel rate padding return _postprocess_conv2d_output x dim_ordering
def add_debugging_monkeypatches from twisted.application.service import Serviceold_startService Service.startServiceold_stopService Service.stopServicedef startService self assert not self.running return old_startService self def stopService self assert self.runningreturn old_stopService self Service.startService startServiceService.stopService stopServiceif twisted.version.major < 9 and sys.version_info[ 2] 2 7 def nopatch self *args raise unittest.SkipTest 'unittest.TestCase.patchisnotavailable' unittest.TestCase.patch nopatch
def _parse_date_hungarian dateString m _hungarian_date_format_re.match dateString if not m or m.group 2 not in _hungarian_months return Nonemonth _hungarian_months[m.group 2 ]day m.group 3 if len day 1 day '0' + day hour m.group 4 if len hour 1 hour '0' + hour w3dtfdate '% year s-% month s-% day sT% hour s % minute s% zonediff s' % {'year' m.group 1 'month' month 'day' day 'hour' hour 'minute' m.group 5 'zonediff' m.group 6 } return _parse_date_w3dtf w3dtfdate
def test_cube vertices filled outline create_cube assert_array_equal np.arange len vertices np.unique filled assert_array_equal np.arange len vertices np.unique outline
def vtk_old global _vtk_versionif _vtk_version is None raise RuntimeException u'VTKisnotcorrectlyinstalled.' return _vtk_version[0] < 6
def PackFloat name value pbvalue pbvalue.set_doublevalue value
def get_type_size param return TYPE_LEN.get param 1
def _ToDatastoreError err return _DatastoreExceptionFromErrorCodeAndDetail err.application_error err.error_detail
def _calculate_emissions emission_probs emissions dict for state symbol in emission_probs try emissions[state].append symbol except KeyError emissions[state] [symbol]return emissions
def cache_permission func def wrapper user target_object if user is None user User.objects.get username appsettings.ANONYMOUS_USER_NAME if target_object is None obj_key Noneelse obj_key target_object.get_full_slug if not hasattr user 'acl_permissions_cache' user.acl_permissions_cache {}key func.__name__ obj_key if key not in user.acl_permissions_cache user.acl_permissions_cache[key] func user target_object return user.acl_permissions_cache[key]return wrapper
def make_loopback_control_client test_case reactor control_amp_service build_control_amp_service test_case reactor reactor client LoopbackAMPClient command_locator ControlAMP reactor control_amp_service .locator return control_amp_service client
def class_option argument if argument is None raise ValueError 'argumentrequiredbutnonesupplied' names argument.split class_names []for name in names class_name nodes.make_id name if not class_name raise ValueError 'cannotmake"%s"intoaclassname' % name class_names.append class_name return class_names
def _zero_mantissa dval bb _double_as_bytes dval return bb[1] & 15 | reduce operator.or_ bb[2 ] 0
def globfind directory pattern blacklist STD_BLACKLIST for curdir dirnames filenames in os.walk directory _handle_blacklist blacklist dirnames filenames for fname in fnmatch.filter filenames pattern yield join curdir fname
def test_line line Line rng [8 12 23 73 39 57]line.add 'Singleserie' rng line.title 'Oneserie'q line.render_pyquery assert len q '.axis.x' 0 assert len q '.axis.y' 1 assert len q '.plot.seriespath' 1 assert len q '.x.axis.guides' 0 assert len q '.y.axis.guides' 7
def add_empty_vol in_file out_file None import nibabel as nbimport os.path as opimport numpy as npimport mathif out_file is None fname fext op.splitext op.basename in_file if fext u'.gz' fname _ op.splitext fname out_file op.abspath u'./%s_4D.nii.gz' % fname im nb.load in_file zim nb.Nifti1Image np.zeros_like im.get_data im.affine im.header nb.funcs.concat_images [im zim] .to_filename out_file return out_file
def should_stage_conflicts path title msg N_ u'Stageconflicts?' info N_ u'%sappearstocontainmergeconflicts.\n\nYoushouldprobablyskipthisfile.\nStageitanyways?' % path ok_text N_ u'Stageconflicts' cancel_text N_ u'Skip' return Interaction.confirm title msg info ok_text default False cancel_text cancel_text
def _GetModelTypeForListPropertyType property_type from google.appengine.ext import db_LISTPROPERTY_TYPE_TO_SCHEMA_ENTRY {basestring db.StringProperty str db.StringProperty unicode db.StringProperty bool db.BooleanProperty int db.IntegerProperty float db.FloatProperty db.Text db.TextProperty}return _LISTPROPERTY_TYPE_TO_SCHEMA_ENTRY.get property_type None
def specificity classify lambda document False documents [] TP TN FP FN confusion_matrix classify documents return float TN / TN + FP or 1
def spherical_to_cartesian r lat lon if not hasattr r u'unit' r r * u.dimensionless_unscaled if not hasattr lat u'unit' lat lat * u.radian if not hasattr lon u'unit' lon lon * u.radian sph SphericalRepresentation distance r lat lat lon lon cart sph.represent_as CartesianRepresentation return cart.x cart.y cart.z
def has_field model fieldname mapper sqlalchemy_inspect model descriptors mapper.all_orm_descriptorsif fieldname not in descriptors return Falsefield descriptors[fieldname]if hasattr field 'fset' return field.fset is not None return not callable getattr model fieldname
def make_toplevel master title None class_ None if class_ widget Toplevel master class_ class_ else widget Toplevel master if title widget.title title widget.iconname title return widget
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def move_subscription remove_users source_event source_node new_event new_node NotificationSubscription apps.get_model 'osf.NotificationSubscription' OSFUser apps.get_model 'osf.OSFUser' if source_node new_node returnold_sub NotificationSubscription.load to_subscription_key source_node._id source_event if not old_sub returnelif old_sub old_sub._id to_subscription_key new_node._id new_event old_sub.event_name new_eventold_sub.owner new_nodenew_sub old_subnew_sub.save for notification_type in constants.NOTIFICATION_TYPES if new_sub for user_id in remove_users[notification_type] related_manager getattr new_sub notification_type None subscriptions related_manager.all if related_manager else [] if user_id in subscriptions user OSFUser.load user_id new_sub.remove_user_from_subscription user
def test_dpsswavelet freqs np.arange 5 25 3 Ws _make_dpss 1000 freqs freqs n_cycles freqs / 2.0 time_bandwidth 4.0 zero_mean True assert_true len Ws 3 assert_true np.abs np.mean np.real Ws[0][0] < 1e-05 assert_true len Ws[0] len freqs
def average_gradients tower_grads average_grads []for grad_and_vars in zip *tower_grads grads []for g _ in grad_and_vars expanded_g tf.expand_dims g 0 grads.append expanded_g grad tf.concat_v2 grads 0 grad tf.reduce_mean grad 0 v grad_and_vars[0][1]grad_and_var grad v average_grads.append grad_and_var return average_grads
@skip 'silverlight' @skip 'netstandard' def test_multiple_inheritance clr.AddReference 'System.Windows.Forms' class foo System.Windows.Forms.Form System.Windows.Forms.Control pass
def registry_cache_filename cache_dir config.cache_dir default os.path.join cache_dir 'registry-cache.pck' cache_filename config.rc.get 'registry.registry-cache' default dirname os.path.dirname cache_filename if not os.path.exists dirname log.info 'Creatingdirectory%r' dirname os.makedirs dirname return cache_filename
def get_expired_sessions expired []for device in u'desktop' u'mobile' expired + frappe.db.sql_list u'selectsidfromtabSessions\n DCTB DCTB DCTB DCTB whereTIMEDIFF NOW lastupdate >TIME %s \n DCTB DCTB DCTB DCTB anddevice %s' get_expiry_period device device return expired
def tagTest tag comment None return getattr pytest.mark tag
def split_first s delims min_idx Nonemin_delim Nonefor d in delims idx s.find d if idx < 0 continueif min_idx is None or idx < min_idx min_idx idxmin_delim dif min_idx is None or min_idx < 0 return s '' None return s[ min_idx] s[ min_idx + 1 ] min_delim
def solve_undetermined_coeffs equ coeffs sym **flags if isinstance equ Equality equ equ.lhs - equ.rhs equ cancel equ .as_numer_denom [0]system list collect equ.expand sym evaluate False .values if not any equ.has sym for equ in system return solve system *coeffs **flags else return None
def remove_headers_from_response response *headers response.remove_headers headers
def get_merge_commit commit branch u'master' commit_range u'{}..{}'.format commit branch ancestry_paths git.rev_list commit_range ancestry_path True .splitlines first_parents git.rev_list commit_range first_parent True .splitlines both set ancestry_paths & set first_parents for commit_hash in reversed ancestry_paths if commit_hash in both return repo.commit commit_hash msg u'Nomergecommitfor{commit}in{branch}!'.format commit commit branch branch raise DoesNotExist msg commit branch
def get_profile_model if not getattr settings u'ACCOUNTS_PROFILE_MODEL' None raise ProfileNotConfiguredtry return apps.get_model settings.ACCOUNTS_PROFILE_MODEL except ValueError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELmustbeoftheform'app_label.model_name'" except LookupError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELreferstomodel'%s'thathasnotbeeninstalled" % settings.ACCOUNTS_PROFILE_MODEL
def replaceInFile filename oldToNew os.rename filename filename + '.bak' f open filename + '.bak' d f.read f.close for k v in oldToNew.items d d.replace k v f open filename + '.new' 'w' f.write d f.close os.rename filename + '.new' filename os.unlink filename + '.bak'
@control_command def election state id topic action None **kwargs if state.consumer.gossip state.consumer.gossip.election id topic action
def test_require_virtualenv from fabtools.require.python import virtualenvtry virtualenv '/tmp/venv' assert is_dir '/tmp/venv' assert is_file '/tmp/venv/bin/python' finally run 'rm-rf/tmp/venv'
def uninstall pkg user None env None cmd ['ghc-pkgunregister']cmd.append '"{0}"'.format pkg result __salt__['cmd.run_all'] ''.join cmd runas user env env if result['retcode'] ! 0 raise CommandExecutionError result['stderr'] return result
def _get_number_of_subtasks total_num_items items_per_task num_subtasks remainder divmod total_num_items items_per_task if remainder num_subtasks + 1return num_subtasks
def get_duplicate_provider messages social_auth_messages [m for m in messages if m.message.endswith 'isalreadyinuse.' ]if not social_auth_messages returnassert len social_auth_messages 1 backend_name social_auth_messages[0].extra_tags.split [1]return backend_name
def libtree lib root Node {} {} for item in lib.items dest item.destination fragment True parts util.components dest _insert root parts item.id return root
def stop_gradient variables return theano.gradient.disconnected_grad variables
def get_db_ips return list set [get_db_master_ip ] + get_db_slave_ips
def ca_exists ca_name cacert_path None ca_filename None set_ca_path cacert_path if not ca_filename ca_filename '{0}_ca_cert'.format ca_name certp '{0}/{1}/{2}.crt'.format cert_base_path ca_name ca_filename if os.path.exists certp maybe_fix_ssl_version ca_name cacert_path cacert_path ca_filename ca_filename return Truereturn False
def correspond Z Y is_valid_linkage Z throw True distance.is_valid_y Y throw True Z np.asarray Z order 'c' Y np.asarray Y order 'c' return distance.num_obs_y Y num_obs_linkage Z
def rowwise_rank array mask None return argsort argsort array
def add_array array_large array_small position if all large_shape > small_shape for large_shape small_shape in zip array_large.shape array_small.shape large_slices small_slices overlap_slices array_large.shape array_small.shape position array_large[large_slices] + array_small[small_slices]return array_largeelse raise ValueError u"Can'taddarray.Smallarraytoolarge."
def apphook_post_delete_title_checker instance **kwargs from cms.cache import invalidate_cms_page_cacheinvalidate_cms_page_cache if instance.page.application_urls request_finished.connect trigger_restart dispatch_uid DISPATCH_UID
def list_ profile 'splunk' client _get_splunk profile searches [x['name'] for x in client.saved_searches]return searches
def color_triple color if color.startswith '#' and len color 4 return int color[1] 16 int color[2] 16 int color[3] 16 if color.startswith '#' and len color 7 return int color[1 3] 16 int color[3 5] 16 int color[5 7] 16 elif color.startswith '#' and len color 13 return int color[1 5] 16 int color[5 9] 16 int color[9 13] 16
def _NeedsIndexes func def UpdateIndexesWrapper self *args **kwargs self._SetupIndexes try return func self *args **kwargs finally self._UpdateIndexes return UpdateIndexesWrapper
def verify_username strategy backend details user None **kwargs if not user and u'username' in details if User.objects.filter username__iexact details[u'username'] .exists raise AuthAlreadyAssociated backend _ u'Thisusernameisalreadytaken.Pleasechooseanother.'
def t_two_sample a b tails 'two-sided' exp_diff 0 if len a 1 or len b 1 if len a < len b t p t_one_observation a b tails exp_diff else t p t_one_observation b a tails exp_diff return t p t _ ttest_ind asarray a - exp_diff asarray b axis 0 equal_var True if isnan t or isinf t return nan nan p tprob t len a + len b - 2.0 tails return float t p
def deprecated_version_of f oldname newname None if newname is None newname f.__name__warning 'Thefunction``%s``isdeprecatedandiskepttemporarilyforbackwardscompatibility.\nPleaseusethenewname ``%s`` instead.' % oldname newname def fdepr *a **kw warnings.warn 'MoviePy ' + warning PendingDeprecationWarning return f *a **kw fdepr.__doc__ warningreturn fdepr
def sensitive_post_parameters *parameters def decorator view @functools.wraps view def sensitive_post_parameters_wrapper request *args **kwargs assert isinstance request HttpRequest "sensitive_post_parametersdidn'treceiveanHttpRequest.Ifyouaredecoratingaclassmethod besuretouse@method_decorator."if parameters request.sensitive_post_parameters parameterselse request.sensitive_post_parameters '__ALL__'return view request *args **kwargs return sensitive_post_parameters_wrapperreturn decorator
def getLimitRange count plusOne False retVal Nonecount int count limitStart limitStop 1 count if isinstance conf.limitStop int and conf.limitStop > 0 and conf.limitStop < limitStop limitStop conf.limitStopif isinstance conf.limitStart int and conf.limitStart > 0 and conf.limitStart < limitStop limitStart conf.limitStartretVal xrange limitStart limitStop + 1 if plusOne else xrange limitStart - 1 limitStop return retVal
def get_current_date time_zone 'local' increment 0 result_format 'timestamp' exclude_millis False if time_zone.upper 'LOCAL' dt datetime.now elif time_zone.upper 'UTC' dt datetime.utcnow else raise ValueError "Unsupportedtimezone'%s'." % time_zone date Date dt + Time increment return date.convert result_format millis is_falsy exclude_millis
def wotan2universal token tag if tag.startswith 'Adv' return token ADV return penntreebank2universal *wotan2penntreebank token tag
def test_slice_setslice_forbidden global setValclass foo def __setslice__ self i j value global setValsetVal i j value def __setitem__ self index value global setValsetVal index value foo [ None] 23AreEqual setVal slice None None None 23 foo [ None] 23AreEqual setVal slice None None None 23
def equatePoints points prefix revolutions xmlElement equateVertexesByFunction equateCylindrical points prefix revolutions xmlElement equateVertexesByFunction equateCylindricalDotAzimuth points prefix revolutions xmlElement equateVertexesByFunction equateCylindricalDotRadius points prefix revolutions xmlElement equateVertexesByFunction equateCylindricalDotZ points prefix revolutions xmlElement equateVertexesByFunction equatePolar points prefix revolutions xmlElement equateVertexesByFunction equatePolarDotAzimuth points prefix revolutions xmlElement equateVertexesByFunction equatePolarDotRadius points prefix revolutions xmlElement equateVertexesByFunction equateRectangular points prefix revolutions xmlElement equateVertexesByFunction equateRectangularDotX points prefix revolutions xmlElement equateVertexesByFunction equateRectangularDotY points prefix revolutions xmlElement equateVertexesByFunction equateRectangularDotZ points prefix revolutions xmlElement equateVertexesByFunction equateSpherical points prefix revolutions xmlElement equateVertexesByFunction equateSphericalDotAzimuth points prefix revolutions xmlElement equateVertexesByFunction equateSphericalDotElevation points prefix revolutions xmlElement equateVertexesByFunction equateSphericalDotRadius points prefix revolutions xmlElement
def register_admin_widget widget_cls primary False widget_id widget_cls.widget_idif not widget_id raise ValueError u'Thewidget_idattributemustbeseton%r' % widget_cls if widget_cls in primary_widgets or widget_cls in secondary_widgets raise KeyError u'"%s"isalreadyaregisteredadministrationwidget' % widget_id if primary primary_widgets.append widget_cls else secondary_widgets.append widget_cls
def test_goto_definition_not_multiple s dedent 'importrandom\nclassA \ndef__init__ self a \nself.a 3\n\ndeffoo self \npass\n\nifrandom.randint 0 1 \na A 2 \nelse \na A 1 \na' assert len api.Script s .goto_definitions 1
def set_field java_object field_name value command_part get_command_part value java_object._gateway_client.gateway_property.pool command proto.FIELD_COMMAND_NAME + proto.FIELD_SET_SUBCOMMAND_NAME + java_object._target_id + u'\n' + field_name + u'\n' + command_part + u'\n' + proto.END_COMMAND_PART answer java_object._gateway_client.send_command command if answer proto.NO_MEMBER_COMMAND or is_error answer [0] raise Py4JError u'nofield{0}inobject{1}'.format field_name java_object._target_id return get_return_value answer java_object._gateway_client java_object._target_id field_name
def render_in_context context template_text html_intent False env SandboxedEnvironment autoescape html_intent template env.from_string template_text return template.render context.get_variables
def tosequence x if isinstance x np.ndarray return np.asarray x elif isinstance x Sequence return xelse return list x
def _tool_from_string name known_tools sorted _known_tools.keys if name in known_tools tool_fn _known_tools[name]if isinstance tool_fn string_types tool_fn _known_tools[tool_fn]return tool_fn else matches text difflib.get_close_matches name.lower known_tools 'similar' if not matches matches text known_tools 'possible' raise ValueError "unexpectedtoolname'%s' %stoolsare%s" % name text nice_join matches
def get_document_json document return json.dumps {u'id' document.id u'title' document.title u'url' document.url u'edit_link' reverse u'wagtaildocs edit' args document.id }
def upload_exec_summary_to_store data_dict report_name course_id generated_at config_name 'FINANCIAL_REPORTS' report_store ReportStore.from_config config_name output_buffer StringIO render_to_string 'instructor/instructor_dashboard_2/executive_summary.html' data_dict report_store.store course_id u'{course_prefix}_{report_name}_{timestamp_str}.html'.format course_prefix course_filename_prefix_generator course_id report_name report_name timestamp_str generated_at.strftime '%Y-%m-%d-%H%M' output_buffer tracker.emit REPORT_REQUESTED_EVENT_NAME {'report_type' report_name}
def test_class_assign class x object def set self value AssertUnreachable prop property lambda x 42 set x.prop 42AreEqual x.__dict__['prop'] 42
def check_major_version api_version available_versions get_available_major_versions if not api_version.is_null and str api_version.ver_major not in available_versions if len available_versions 1 msg _ "Invalidclientversion'% version s'.Majorpartshouldbe'% major s'" % {'version' api_version.get_string 'major' available_versions[0]} else msg _ "Invalidclientversion'% version s'.Majorpartmustbeoneof '% major s'" % {'version' api_version.get_string 'major' ' '.join available_versions } raise exceptions.UnsupportedVersion msg
def soft_delete_aware_query context *args **kwargs query context.session.query *args show_deleted kwargs.get 'show_deleted' or context.show_deleted if not show_deleted query query.filter_by deleted_at None return query
def test_LogLocator_set_params loc mticker.LogLocator loc.set_params numticks 7 numdecs 8 subs [2.0] base 4 assert loc.numticks 7 assert loc.numdecs 8 assert loc._base 4 assert list loc._subs [2.0]
def DW_matrices graph W nx.to_scipy_sparse_matrix graph format 'csc' entries W.sum axis 0 D sparse.dia_matrix entries 0 shape W.shape .tocsc return D W
def getGeometryOutput derivation xmlElement if derivation None derivation ShaftDerivation derivation.setToXMLElement xmlElement shaftPath getShaftPath derivation.depthBottom derivation.depthTop derivation.radius derivation.sides return lineation.getGeometryOutputByLoop lineation.SideLoop shaftPath xmlElement
def application_icon path pkg_resources.resource_filename __name__ 'icons/orange-canvas.svg' return QIcon path
def read_plain_int64 file_obj count return struct.unpack '<{0}q'.format count .encode u'utf-8' file_obj.read 8 * count
def Any s result CodeRanges chars_to_ranges s result.str 'Any %s ' % repr s return result
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def get_messages_from_report name report frappe.get_doc u'Report' name messages _get_messages_from_page_or_report u'Report' name frappe.db.get_value u'DocType' report.ref_doctype u'module' if report.query messages.extend [ None message for message in re.findall u'" [^ ^"]* ' report.query if is_translatable message ] messages.append None report.report_name return messages
def test_convolutional_network skip.skip_if_no_data yaml_file_path os.path.abspath os.path.join os.path.dirname __file__ '..' save_path os.path.dirname os.path.realpath __file__ save_path.replace '\\' '\\\\' yaml open '{0}/conv.yaml'.format yaml_file_path 'r' .read hyper_params {'train_stop' 50 'valid_stop' 50050 'test_stop' 50 'batch_size' 50 'output_channels_h2' 4 'output_channels_h3' 4 'max_epochs' 1 'save_path' save_path}yaml yaml % hyper_params train yaml_parse.load yaml train.main_loop try os.remove '{}/convolutional_network_best.pkl'.format save_path except OSError pass
def format_option_value optdict value if isinstance value list tuple value ' '.join value elif isinstance value dict value ' '.join [ '%s %s' % k v for k v in value.items ] elif hasattr value 'match' value value.patternelif optdict.get 'type' 'yn' value value and 'yes' or 'no' elif isinstance value string_types and value.isspace value "'%s'" % value elif optdict.get 'type' 'time' and isinstance value float int long value format_time value elif optdict.get 'type' 'bytes' and hasattr value '__int__' value format_bytes value return value
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def validate_non_negative_integer option value val validate_integer option value if val < 0 raise ValueError 'Thevalueof%smustbeanonnegativeinteger' % option return val
def lpn n z if not isscalar n and isscalar z raise ValueError 'argumentsmustbescalars.' if n ! floor n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n < 1 n1 1else n1 nif iscomplex z pn pd specfun.clpn n1 z else pn pd specfun.lpn n1 z return pn[ n + 1 ] pd[ n + 1 ]
def setup_scanner hass config see devices config[CONF_DEVICES]qos config[CONF_QOS]dev_id_lookup {}def device_tracker_message_received topic payload qos 'MQTTmessagereceived.'see dev_id dev_id_lookup[topic] location_name payload for dev_id topic in devices.items dev_id_lookup[topic] dev_idmqtt.subscribe hass topic device_tracker_message_received qos return True
def validate_password_dictionary value password_max_edit_distance getattr settings 'PASSWORD_DICTIONARY_EDIT_DISTANCE_THRESHOLD' None password_dictionary getattr settings 'PASSWORD_DICTIONARY' None if password_max_edit_distance and password_dictionary for word in password_dictionary distance nltk.metrics.distance.edit_distance value word if distance < password_max_edit_distance raise ValidationError _ 'Toosimilartoarestricteddictionaryword.' code 'dictionary_word'
def getch try import msvcrtreturn msvcrt.getch except ImportError import sysimport ttyimport termiosfd sys.stdin.fileno old_settings termios.tcgetattr fd try tty.setraw sys.stdin.fileno ch sys.stdin.read 1 finally termios.tcsetattr fd termios.TCSADRAIN old_settings return ch
def get_country_time_zones country_code None if country_code is None return _get_sorted_time_zone_list common_timezones if country_code.upper in set countries.alt_codes return _get_sorted_time_zone_list country_timezones country_code raise CountryCodeError
def _same_filesystem path1 path2 return os.lstat path1 .st_dev os.lstat path2 .st_dev
def test_timeit_return res _ip.run_line_magic 'timeit' '-n10-r10-o1' assert res is not None
def encode_polyline points last_lat last_lng 0result ''for point in points ll normalize_lat_lng point lat int round ll[0] * 100000.0 lng int round ll[1] * 100000.0 d_lat lat - last_lat d_lng lng - last_lng for v in [d_lat d_lng] v ~ v << 1 if v < 0 else v << 1 while v > 32 result + chr 32 | v & 31 + 63 v >> 5result + chr v + 63 last_lat latlast_lng lngreturn result
def xydist p1 0.0 0.0 p2 0.0 0.0 return numpy.sqrt pow p1[0] - p2[0] 2 + pow p1[1] - p2[1] 2
def get_shared doctype user None rights None if not user user frappe.session.userif not rights rights [u'read']condition u'and'.join [u'`{0}` 1'.format right for right in rights] return frappe.db.sql_list u'selectshare_namefromtabDocShare\n DCTB DCTB where user %s{everyone} andshare_doctype %sand{condition}'.format condition condition everyone u'oreveryone 1' if user ! u'Guest' else u'' user doctype
def cleanup_test_name name strip_tags True strip_scenarios False if strip_tags tags_start name.find '[' tags_end name.find ']' if tags_start > 0 and tags_end > tags_start newname name[ tags_start]newname + name[ tags_end + 1 ]name newnameif strip_scenarios tags_start name.find ' ' tags_end name.find ' ' if tags_start > 0 and tags_end > tags_start newname name[ tags_start]newname + name[ tags_end + 1 ]name newnamereturn name
def make_view context builder aryty ary return_type data shapes strides retary make_array return_type context builder populate_array retary data data shape shapes strides strides itemsize ary.itemsize meminfo ary.meminfo parent ary.parent return retary
def check_title_slugs page for title in page.title_set.all old_slug old_path title.slug title.path title.slug get_available_slug title if title.slug ! old_slug or title.path ! old_path title.save
def dup_copy f return list f
def set_virt_bridge self vbridge if vbridge is None or vbridge '' vbridge self.settings.default_virt_bridgeself.virt_bridge vbridge
def find_template_variables code return re.findall re_template_var code
def makeCentered data return data - data.mean axis 0
def compute_jac_scale J scale_inv_old None if issparse J scale_inv np.asarray J.power 2 .sum axis 0 .ravel ** 0.5 else scale_inv np.sum J ** 2 axis 0 ** 0.5 if scale_inv_old is None scale_inv[ scale_inv 0 ] 1else scale_inv np.maximum scale_inv scale_inv_old return 1 / scale_inv scale_inv
def test_min_informative_str A tensor.matrix name 'A' B tensor.matrix name 'B' C A + B C.name 'C'D tensor.matrix name 'D' E tensor.matrix name 'E' F D + E G C + F mis min_informative_str G .replace ' DCTB ' '' reference 'A.Elemwise{add no_inplace}\nB.C\nC.Elemwise{add no_inplace}\nD.D\nE.E'if mis ! reference print '--' + mis + '--' print '--' + reference + '--' assert mis reference
def keypair_list profile None conn _auth profile return conn.keypair_list
def mult_align sum_dict align_dict mult_align_dict {}for j in align_dict.abs 1 .pos_align_dict mult_align_dict[j] ''for i in range 1 len align_dict + 1 for j in align_dict.abs i .pos_align_dict mult_align_dict[j] + align_dict.abs i .pos_align_dict[j].aaalpha Alphabet.Gapped Alphabet.IUPAC.extended_protein fssp_align MultipleSeqAlignment [] alphabet alpha for i in sorted mult_align_dict fssp_align.append SeqRecord Seq mult_align_dict[i] alpha sum_dict[i].pdb2 + sum_dict[i].chain2 return fssp_align
def commonfooter request messages None is_mobile False if messages is None messages {}hue_settings Settings.get_settings template 'common_footer.mako'if is_mobile template 'common_footer_m.mako'return django_mako.render_to_string template {'request' request 'messages' messages 'version' hue_version 'collect_usage' collect_usage 'tours_and_tutorials' hue_settings.tours_and_tutorials}
@pytest.mark.slow@pytest.mark.models@pytest.mark.parametrize u'text expected_sents' TEST_CASES def test_parser_sbd_prag EN text expected_sents doc EN text sents []for sent in doc.sents sents.append u''.join doc[i].string for i in range sent.start sent.end .strip assert sents expected_sents
def empty_and_escape value if value is None return ''else return escape value
def _find_splitting_points expr x p q [Wild n exclude [x] for n in 'pq']def compute_innermost expr res if not isinstance expr Expr returnm expr.match p * x + q if m and m[p] ! 0 res.add - m[q] / m[p] returnif expr.is_Atom returnfor arg in expr.args compute_innermost arg res innermost set compute_innermost expr innermost return innermost
def get_file_spec global file_specif file_spec is None if sys.version_info[0] 3 import _iofile_spec list set dir _io.TextIOWrapper .union set dir _io.BytesIO else file_spec file
def encode_number_as_hex num num bytes hex num [2 ].upper nlen len num if nlen % 2 ! 0 num '0' + num return encode_string num
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def create_cache_security_group name description region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile created conn.create_cache_security_group name description if created log.info 'Createdcachesecuritygroup{0}.'.format name return Trueelse msg 'Failedtocreatecachesecuritygroup{0}.'.format name log.error msg return False
def specialization_signature_string fused_compound_type fused_to_specific fused_types fused_compound_type.get_fused_types if len fused_types 1 fused_type fused_types[0]else fused_type fused_compound_typereturn fused_type.specialize fused_to_specific .typeof_name
def preBuild site optimize site.config.get 'optimize' [] if 'js' in optimize site.external_manager.register_optimizer ClosureJSOptimizer if 'css' in optimize site.external_manager.register_optimizer YUICSSOptimizer
def load_data_and_labels positive_data_file negative_data_file positive_examples list open positive_data_file 'r' .readlines positive_examples [s.strip for s in positive_examples]negative_examples list open negative_data_file 'r' .readlines negative_examples [s.strip for s in negative_examples]x_text positive_examples + negative_examples x_text [clean_str sent for sent in x_text]positive_labels [[0 1] for _ in positive_examples]negative_labels [[1 0] for _ in negative_examples]y np.concatenate [positive_labels negative_labels] 0 return [x_text y]
def string_similarity string1 string2 vocabulary set list string1 + string2 vec1 [string1.count v for v in vocabulary]vec2 [string2.count v for v in vocabulary]try return float sum vec1[i] * vec2[i] for i in range len vocabulary / math.sqrt sum v1 ** 2 for v1 in vec1 * math.sqrt sum v2 ** 2 for v2 in vec2 except ZeroDivisionError return 0
def basedir_def *args return os.path.join '$pybasedir' *args
def devname pcap_name return ifaces.devname pcap_name
def _section_metrics course access course_key course.idsection_data {'section_key' 'metrics' 'section_display_name' _ 'Metrics' 'access' access 'course_id' unicode course_key 'sub_section_display_name' get_section_display_name course_key 'section_has_problem' get_array_section_has_problem course_key 'get_students_opened_subsection_url' reverse 'get_students_opened_subsection' 'get_students_problem_grades_url' reverse 'get_students_problem_grades' 'post_metrics_data_csv_url' reverse 'post_metrics_data_csv' }return section_data
def json_iso_dttm_ser obj val base_json_conv obj if val is not None return valif isinstance obj datetime obj obj.isoformat elif isinstance obj date obj obj.isoformat elif isinstance obj time obj obj.isoformat else raise TypeError u'Unserializableobject{}oftype{}'.format obj type obj return obj
def _SkipLengthDelimited buffer pos end size pos _DecodeVarint buffer pos pos + sizeif pos > end raise _DecodeError 'Truncatedmessage.' return pos
def get_table_list cursor cursor.execute 'SELECTTABLE_NAMEFROMUSER_TABLES' return [row[0] for row in cursor.fetchall ]
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def form_view_with_template request if request.method 'POST' form TestForm request.POST if form.is_valid message 'POSTdataOK'else message 'POSTdatahaserrors'else form TestForm message 'GETformpage'return render request 'form_view.html' {'form' form 'message' message}
def clean_filename filename split_fname filename.rsplit '.' 1 split_fname[0] FILENAME_TOKENreturn '.'.join split_fname
def add_offsetboxes ax size 10 margin 0.1 color u'black' m mp margin 1 + margin anchor_points [ - m - m - m 0.5 - m mp mp 0.5 0.5 mp mp mp 0.5 - m mp - m 0.5 - m ]for point in anchor_points da DrawingArea size size background Rectangle 0 0 width size height size facecolor color edgecolor u'None' linewidth 0 antialiased False da.add_artist background anchored_box AnchoredOffsetbox loc 10 child da pad 0.0 frameon False bbox_to_anchor point bbox_transform ax.transAxes borderpad 0.0 ax.add_artist anchored_box return anchored_box
def assert_mask_matches arr expected_mask mask np.ma.getmaskarray arr assert_equal mask expected_mask
def cpuid attrs None where None return _osquery_cmd table 'cpuid' attrs attrs where where
def pid_by_name name def match p if p.status 'zombie' return Falseif p.name name return Truetry if p.exe name return Trueexcept Exception passreturn Falseprocesses p for p in psutil.process_iter if match p processes sorted processes key lambda p p.create_time return list reversed [p.pid for p in processes]
def _validate_interface_option attr value addrfam 'inet' valid _value errmsg False value 'Unknownvalidator' attrmaps ATTRMAPS.get addrfam [] for attrmap in attrmaps if attr in attrmap validate_func attrmap[attr] valid _value errmsg validate_func value breakreturn valid _value errmsg
def count_pingbacks_handler sender **kwargs entry kwargs['entry']entry.pingback_count F 'pingback_count' + 1 entry.save update_fields ['pingback_count']
def find_matching_headers name headers return [h for h in headers if h.lower name.lower ]
def simplify_mul tree neg inputs treeif isinstance inputs list s_inputs []for s_i in imap simplify_mul inputs if s_i[1] is None neg ^ s_i[0]else s_inputs.append s_i if not s_inputs rval [neg None]elif len s_inputs 1 s_inputs[0][0] ^ negrval s_inputs[0]else rval [neg s_inputs]else rval treereturn rval
def get_indent_fix text indent_chars '' * 4 tab_stop_width_spaces 4 sol False app qapplication editor CodeEditor parent None editor.setup_editor language 'Python' indent_chars indent_chars tab_stop_width_spaces tab_stop_width_spaces editor.set_text text cursor editor.textCursor cursor.movePosition QTextCursor.End if sol lines text.splitlines True repeat len lines[ -1 ].lstrip cursor.movePosition QTextCursor.Left n repeat editor.setTextCursor cursor editor.fix_indent return to_text_string editor.toPlainText
def convert_vif_model name if name network_model.VIF_MODEL_E1000 return 'VirtualE1000'if name network_model.VIF_MODEL_E1000E return 'VirtualE1000e'if name network_model.VIF_MODEL_PCNET return 'VirtualPCNet32'if name network_model.VIF_MODEL_SRIOV return 'VirtualSriovEthernetCard'if name network_model.VIF_MODEL_VMXNET return 'VirtualVmxnet'if name network_model.VIF_MODEL_VMXNET3 return 'VirtualVmxnet3'if name not in ALL_SUPPORTED_NETWORK_DEVICES msg _ '%sisnotsupported.' % name raise exception.Invalid msg return name
def gcd *a if len a > 1 return reduce gcd2 a if hasattr a[0] '__iter__' return reduce gcd2 a[0] return a[0]
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def validate_power_type power_type power_types get_power_types if not power_types raise CX 'youneedtohavefence-agentsinstalled' if power_type not in power_types raise CX 'powermanagementtypemustbeoneof %s' % ' '.join power_types
def get_qual_stats qual_bins score_min ave_bins []std_dev_bins []total_bases_bins []found_first_poor_qual_pos Falsesuggested_trunc_pos Nonefor base_position in qual_bins total_bases_bins.append len base_position std_dev_bins.append std base_position ave_bins.append average base_position if not found_first_poor_qual_pos if average base_position < score_min suggested_trunc_pos qual_bins.index base_position found_first_poor_qual_pos Truereturn ave_bins std_dev_bins total_bases_bins suggested_trunc_pos
def findBiggest root if root.right is None return rootelse return findBiggest root.right
def setup_worker_optimizations app hostname None global trace_task_rethostname hostname or gethostname _install_stack_protection app.set_current app.set_default app.finalize _localized[ ] [app._tasks prepare_accept_content app.conf.accept_content hostname]trace_task_ret _fast_trace_taskfrom celery.worker import request as request_modulerequest_module.trace_task_ret _fast_trace_taskrequest_module.__optimize__
def arbitrary_element iterable if is_iterator iterable raise ValueError 'cannotreturnanarbitraryitemfromaniterator' return next iter iterable
def get_print_name node simple_form True name node.fullnameif hasattr node u'_interface' pkglist node._interface.__class__.__module__.split u'.' interface node._interface.__class__.__name__destclass u''if len pkglist > 2 destclass u'.%s' % pkglist[2] if simple_form name node.fullname + destclass else name u'.'.join [node.fullname interface] + destclass if simple_form parts name.split u'.' if len parts > 2 return u' '.join parts[1 ] + u' ' elif len parts 2 return parts[1]return name
def _assert_all_finite X X np.asanyarray X if X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite X.sum and not np.isfinite X .all raise ValueError 'InputcontainsNaN infinityoravaluetoolargefor%r.' % X.dtype
def test_voigt_model m models.Voigt1D x_0 5 amplitude_L 10 fwhm_L 0.5 fwhm_G 0.9 x np.arange 0 10 0.01 y m x assert y[500] y.max
def _parse_schema_resource info if 'fields' not in info return Noneschema []for r_field in info['fields'] name r_field['name']field_type r_field['type']mode r_field.get 'mode' 'NULLABLE' description r_field.get 'description' sub_fields _parse_schema_resource r_field schema.append SchemaField name field_type mode description sub_fields return schema
def modeladmin_register modeladmin_class instance modeladmin_class instance.register_with_wagtail
def slices indices indices list sorted indices if indices first last indices[0]for i in indices[1 ] if i last + 1 last ielse yield first last + 1 first last i yield first last + 1
def _get_codegen obj if isinstance obj BaseContext return obj.codegen elif isinstance obj CodeLibrary return obj.codegenelif isinstance obj CompileResult return obj.target_context.codegen else raise TypeError type obj
def _initialise bot BridgeInstance bot 'samplebridge' IncomingMessages
def load_key_bindings_for_prompt **kw kw.setdefault u'enable_abort_and_exit_bindings' True kw.setdefault u'enable_search' True kw.setdefault u'enable_auto_suggest_bindings' True return load_key_bindings **kw
def _falling_factorial x n val 1for k in range x - n + 1 x + 1 val * kreturn val
def GetModuleForCLSID clsid clsid_str str clsid try typelibCLSID lcid major minor clsidToTypelib[clsid_str]except KeyError return Nonetry mod GetModuleForTypelib typelibCLSID lcid major minor except ImportError mod Noneif mod is not None sub_mod mod.CLSIDToPackageMap.get clsid_str if sub_mod is None sub_mod mod.VTablesToPackageMap.get clsid_str if sub_mod is not None sub_mod_name mod.__name__ + '.' + sub_mod try __import__ sub_mod_name except ImportError info typelibCLSID lcid major minor if info in demandGeneratedTypeLibraries info demandGeneratedTypeLibraries[info]import makepymakepy.GenerateChildFromTypeLibSpec sub_mod info mod sys.modules[sub_mod_name]return mod
def _CheckFieldNames names for name in names _CheckFieldName name return names
def _flash_encryption_tweak_range flash_crypt_config 15 tweak_range []if flash_crypt_config & 1 ! 0 tweak_range + range 67 if flash_crypt_config & 2 ! 0 tweak_range + range 67 132 if flash_crypt_config & 4 ! 0 tweak_range + range 132 195 if flash_crypt_config & 8 ! 0 tweak_range + range 195 256 return tweak_range
def pportSelect state global ctrlRegif state 0 ctrlReg ctrlReg | 8 else ctrlReg ctrlReg & ~ 8 port.DlPortWritePortUchar ctrlRegAdrs ctrlReg
def _ComputeOTP secret t h hmac.new base64.b32decode secret struct.pack '>Q' t hashlib.sha1 hash h.digest offset struct.unpack 'B' hash[ -1 ] [0] & 15 truncated_hash struct.unpack '>I' hash[offset offset + 4 ] [0]truncated_hash & 2147483647truncated_hash % _VERIFY_MODULUSreturn truncated_hash
def proxied_attribute local_attr proxied_attr doc def fget self return getattr getattr self local_attr proxied_attr def fset self value setattr getattr self local_attr proxied_attr value def fdel self delattr getattr self local_attr proxied_attr return property fget fset fdel doc
def ContentLengthRewriter response request_headers env_dict if env_dict and env_dict.get 'REQUEST_METHOD' '' 'HEAD' returnif response.status_code ! httplib.NOT_MODIFIED response.headers['Content-Length'] str _RemainingDataSize response.body elif 'Content-Length' in response.headers del response.headers['Content-Length']
def _createDataset numSequences originalSequences relativeFrequencies dataSet []trainingCummulativeFrequencies numpy.cumsum relativeFrequencies for _ in xrange numSequences whichSequence numpy.searchsorted trainingCummulativeFrequencies _RGEN.random_sample dataSet.append originalSequences[whichSequence] return dataSet
def _NewFieldsFromPb field_list return [_NewFieldFromPb f for f in field_list]
def test_bad_setv cant_compile u' setvif*1 ' cant_compile u' setv ab [12] '
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def register linter linter.register_checker ExceptionsChecker linter
def validator_data_dict return { 'otherkey' 'othervalue'}
@hgcommanddef sync ui repo **opts if codereview_disabled raise hg_util.Abort codereview_disabled if not opts['local'] if hg_incoming ui repo err hg_pull ui repo update True else err hg_update ui repo if err return errsync_changes ui repo
def _received_message_pb_to_mapping received_message_pb return {'ackId' received_message_pb.ack_id 'message' _message_pb_to_mapping received_message_pb.message }
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def _ClearUserHistory _history.clear
def permanent_delete fid url build_url RESOURCE id fid route 'permanent_delete' return request 'delete' url
def graph_atlas i if not 0 < i < NUM_GRAPHS raise ValueError 'indexmustbebetween0and{}'.format NUM_GRAPHS return next islice _generate_graphs i None
def add_wildcards arg if not arg.startswith u'*' arg u'*' + arg if not arg.endswith u'*' arg arg + u'*' return arg
def isPointAddedAroundClosest pixelTable layerExtrusionWidth paths removedEndpointPoint width closestDistanceSquared 1e+18closestPathIndex Nonefor pathIndex in xrange len paths path paths[pathIndex]for pointIndex in xrange len path point path[pointIndex]distanceSquared abs point - removedEndpointPoint if distanceSquared < closestDistanceSquared closestDistanceSquared distanceSquaredclosestPathIndex pathIndexif closestPathIndex None returnif closestDistanceSquared < 0.8 * layerExtrusionWidth * layerExtrusionWidth returnclosestPath paths[closestPathIndex]closestPointIndex getWithLeastLength closestPath removedEndpointPoint if isAddedPointOnPathFree closestPath pixelTable removedEndpointPoint closestPointIndex width addPointOnPath closestPath closestPathIndex pixelTable removedEndpointPoint closestPointIndex width return Truereturn isSidePointAdded pixelTable closestPath closestPathIndex closestPointIndex layerExtrusionWidth removedEndpointPoint width
def markup_description description if apply_markdown description apply_markdown description else description escape description .replace u'\n' u'<br/>' description u'<p>' + description + u'</p>' return mark_safe description
def _load_libzmq import sys ctypes platformdlopen hasattr sys 'getdlopenflags' if dlopen dlflags sys.getdlopenflags sys.setdlopenflags ctypes.RTLD_GLOBAL | dlflags try from . import libzmqexcept ImportError passelse globals ['_libzmq'] libzmqif platform.python_implementation .lower 'pypy' ctypes.CDLL libzmq.__file__ ctypes.RTLD_GLOBAL finally if dlopen sys.setdlopenflags dlflags
def approx_equal a b epsilon EPSILON return abs a - b < epsilon
def textfile_to_semi_redundant_sequences path seq_maxlen 25 redun_step 3 to_lower_case False pre_defined_char_idx None text open path .read if to_lower_case text text.lower return string_to_semi_redundant_sequences text seq_maxlen redun_step pre_defined_char_idx
def proportions_ztost count nobs low upp prop_var 'sample' if prop_var 'limits' prop_var_low lowprop_var_upp uppelif prop_var 'sample' prop_var_low prop_var_upp Falseelif prop_var 'null' prop_var_low prop_var_upp 0.5 * low + upp elif np.isreal prop_var prop_var_low prop_var_upp prop_vartt1 proportions_ztest count nobs alternative 'larger' prop_var prop_var_low value low tt2 proportions_ztest count nobs alternative 'smaller' prop_var prop_var_upp value upp return np.maximum tt1[1] tt2[1] tt1 tt2
def num2julian n if cbook.iterable n n np.asarray n return n - 1721425.5
def sign_blob bytes_to_sign deadline None rpc create_rpc deadline make_sign_blob_call rpc bytes_to_sign rpc.wait return rpc.get_result
def style_change_check request path authorized Trueif request.method 'POST' if not request.user.is_authenticated authorized Falseif request.method 'PUT' if path 'rest/layers' authorized Trueelse style_name os.path.splitext request.path [0].split '/' [ -1 ]try style Style.objects.get name style_name for layer in style.layer_styles.all if not request.user.has_perm 'change_layer_style' obj layer authorized Falseexcept authorized Falselogger.warn 'Thereisnotastylewithsuchaname %s.' % style_name return authorized
def _parse_composites fh d {}for line in fh line line.rstrip if not line continueif line.startswith 'EndComposites' return dvals line.split ';' cc vals[0].split name numParts cc[1] _to_int cc[2] pccParts []for s in vals[1 -1 ] pcc s.split name dx dy pcc[1] _to_float pcc[2] _to_float pcc[3] pccParts.append name dx dy d[name] pccPartsraise RuntimeError u'Badcompositesparse'
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def f32_as_int32 builder val assert val.type Type.float return builder.bitcast val Type.int 32
def check_http_server host port req get 'http //{host} {port}'.format host host port port timeout SOCKET_TIMEOUT_FOR_POLLING persistent False def failed failure return Falsedef succeeded result return Truereq.addCallbacks succeeded failed return req
def cc_library_config append None **kwargs blade_config.update_config 'cc_library_config' append kwargs
def make_events add_nulls def gen_date_interleavings for e1 e2 t1 t2 in product * [critical_dates] * 4 if e1 < e2 yield e1 e2 t1 t2 event_frames []for sid e1 e2 t1 t2 in enumerate gen_date_interleavings event_frames.append make_events_for_sid sid [e1 e2] [t1 t2] if add_nulls for date in critical_dates event_frames.append make_null_event_date_events np.arange sid + 1 timestamp date return pd.concat event_frames ignore_index True
def makeSQLTests base suffix globals connectors [PySQLite2Connector SQLite3Connector PyPgSQLConnector PsycopgConnector MySQLConnector FirebirdConnector]tests {}for connclass in connectors name connclass.TEST_PREFIX + suffix class testcase connclass base unittest.TestCase __module__ connclass.__module__testcase.__name__ nameif hasattr connclass '__qualname__' testcase.__qualname__ '.'.join connclass.__qualname__.split [0 -1 ] + [name] tests[name] testcaseglobals.update tests
def dup_hermite n K seq [[K.one] [K 2 K.zero]]for i in range 2 n + 1 a dup_lshift seq[ -1 ] 1 K b dup_mul_ground seq[ -2 ] K i - 1 K c dup_mul_ground dup_sub a b K K 2 K seq.append c return seq[n]
def chprofile name profile return update name name profile profile
def _update_lut cmap colors cmap._lut[ 256] colorscmap._set_extremes
def test_SAMPProxyError SAMPProxyError 'test' 'any'
def getattrs value attrs default _no_default try for attr in attrs value getattr value attr except AttributeError if default is _no_default raisevalue defaultreturn value
def store x global freelistp freelistif p is None p len referents referents.append x else freelist referents[p]referents[p] xreturn p
def valid_email emailaddress domains GENERIC_DOMAINS if len emailaddress < 6 return Falsetry localpart domainname emailaddress.rsplit '@' 1 host toplevel domainname.rsplit '.' 1 except ValueError return Falseif len toplevel ! 2 and toplevel not in domains return Falsefor i in '-_.%+.' localpart localpart.replace i '' for i in '-_.' host host.replace i '' if localpart.isalnum and host.isalnum return Trueelse return False
def remote function_argument public True if hasattr function_argument '__call__' return _intercept function_argument None public else if not _isstr function_argument if not isinstance function_argument bool raise Exception 'ExpectedanRPCmethodnameorvisibilitymodifier!' else def _wrap_revised function function _intercept function None function_argument return functionreturn _wrap_reviseddef _wrap_remapped function function _intercept function function_argument public return functionreturn _wrap_remapped
def aws_output args aws_config environment os.environ.copy environment.update aws_config return check_output ['aws'] + args env environment
def _generateModel0 numCategories initProb numpy.zeros numCategories initProb[0] 0.5initProb[4] 0.5firstOrder dict for catIdx in range numCategories key str [catIdx] probs numpy.ones numCategories / numCategories if catIdx 0 or catIdx 4 probs.fill 0 probs[1] 1.0firstOrder[key] probssecondOrder dict for firstIdx in range numCategories for secondIdx in range numCategories key str [firstIdx secondIdx] probs numpy.ones numCategories / numCategories if key str [0 1] probs.fill 0 probs[2] 0.8probs[3] 0.2elif key str [4 1] probs.fill 0 probs[2] 0.2probs[3] 0.8secondOrder[key] probsreturn initProb firstOrder secondOrder 3
def decode_and_decrypt encoded_data key return aes_decrypt base64.urlsafe_b64decode encoded_data key
def shared_memory attrs None where None if __grains__['os_family'] in ['RedHat' 'Debian'] return _osquery_cmd table 'shared_memory' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonRedHatorDebianbasedsystems.'}
def get_display spec if spec is None return Noneelif isinstance spec six.string_types return pyglet.canvas.Display spec else raise error.Error 'Invaliddisplayspecification {}. Mustbeastringlike 0orNone. '.format spec
def _find_get_notepad_pages if config.WEB_GET_NOTEPAD_PAGES is None return Noneif type config.WEB_GET_NOTEPAD_PAGES is not tuple config.WEB_GET_NOTEPAD_PAGES config.WEB_GET_NOTEPAD_PAGES return functools.partial GET_NOTEPAD_PAGES[config.WEB_GET_NOTEPAD_PAGES[0]] *config.WEB_GET_NOTEPAD_PAGES[1]
def latex_highlight classified_text title 'python' commands default_latex_commands document default_latex_document macros '\n'.join '\\newcommand{\\py%s}[1]{%s}' % c for c in commands.items result []for kind text in classified_text if kind result.append '\\py%s{' % kind result.append alltt_escape text if kind result.append '}' return default_latex_document % dict title title macros macros body ''.join result
def getimagesize url try from PIL import ImageFileexcept ImportError try import ImageFileexcept ImportError return Nonetry import urllib2except ImportError return Nonetry p ImageFile.Parser f urllib2.urlopen url while True s f.read 1024 if not s breakp.feed s if p.image return 'width "%i"height "%i"' % p.image.size except IOError ValueError return None
def to_timestamp value return value - epoch .total_seconds
def sm_backend_conf_update context sm_backend_conf_id values return IMPL.sm_backend_conf_update context sm_backend_conf_id values
def datetime_tuple_to_iso tup iso datetime.strftime tup.astimezone iso8601.iso8601.UTC '%Y-%m-%dT%H %M %S.%fZ' return iso
def dice_hard_coe output target epsilon 1e-10 output tf.cast output > 0.5 dtype tf.float32 target tf.cast target > 0.5 dtype tf.float32 inse tf.reduce_sum output * target l tf.reduce_sum output * output r tf.reduce_sum target * target dice 2 * inse / l + r if epsilon 0 return diceelse return tf.clip_by_value dice 0 1.0 - epsilon
def create_process progname sensor return subprocess.Popen CMDLINE % {'progname' progname 'sensor' SENSORS.get sensor sensor } shell True stdin subprocess.PIPE
def cool rc u'image' cmap u'cool' im gci if im is not None im.set_cmap cm.cool
@decoratordef rollback_open_connections fn *args **kw try fn *args **kw finally testing_reaper.rollback_all
@set_databasedef get_or_create item **kwargs if item return Item.create_or_get **parse_model_data item
def connect_to_cloud_dns region None return _create_client ep_name 'dns' region region
def get_ctx_file_path_from_manifest filename repo changeset_revision stripped_filename basic_util.strip_path filename for changeset in reversed_upper_bounded_changelog repo changeset_revision manifest_ctx repo.changectx changeset for ctx_file in manifest_ctx.files ctx_file_name basic_util.strip_path ctx_file if ctx_file_name stripped_filename return manifest_ctx ctx_file return None None
def test_tokenize_0 s '123klsdgh56.7?98.2---\\%-1e3'true_tokens ['' 123 'klsdgh' 56.7 '?' 98.2 '---\\%' -1000.0 ]tokens tokenize_by_number s assert token_lists_match tokens true_tokens
def convert_id32 id_64 out ['STEAM_0 ']final id_64 - ID_BASE if final % 2 0 out.append '0 ' else out.append '1 ' out.append str final // 2 return ''.join out
def read_plain_int96 file_obj count items struct.unpack '<qi' * count file_obj.read 12 * count args [iter items ] * 2 return [ q << 32 | i for q i in zip *args ]
def volume_glance_metadata_create context volume_id key value return IMPL.volume_glance_metadata_create context volume_id key value
def test_reconnect samp_hub my_client SAMPIntegratedClient my_client.connect my_client.disconnect my_client.connect
def to_latex expr if expr is None return ''expr_s latex expr expr_s expr_s.replace '\\XI' 'XI' expr_s re.sub 'script [a-zA-Z0-9]+ ' '\\mathcal{\\1}' expr_s if expr_s[0] '$' return '[mathjax]%s[/mathjax]<br>' % expr_s[1 -1 ] return '[mathjax]%s[/mathjax]<br>' % expr_s
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def pants_version return _VERSION
def flipwritable fn mode None if os.access fn os.W_OK return Noneold_mode os.stat fn .st_modeos.chmod fn stat.S_IWRITE | old_mode return old_mode
def _syspath dev dev _devbase dev dev re.sub '^ [vhs][a-z]+ [0-9]+ ' '\\1/\\1\\2' dev return os.path.join '/sys/block/' dev
def merge_map old new deep_merge False if not old return newfor k v in new.items if v if not deep_merge old[k] velif isinstance v collections.Mapping old_v old.get k old[k] merge_map old_v v deep_merge if old_v else v elif isinstance v collections.Sequence and not isinstance v six.string_types old_v old.get k old[k] merge_list old_v v if old_v else v elif isinstance v six.string_types old[k] ''.join [old.get k '' v] else old[k] vreturn old
def slugify_uniquely_for_queryset value queryset slugfield 'slug' suffix 0potential base django_slugify unidecode value if len potential 0 potential 'null'while True if suffix potential '-'.join [base str suffix ] if not queryset.filter **{slugfield potential} .exists return potentialsuffix + 1
def _strip_additional_query_parameters schema req additional_properties schema.get 'addtionalProperties' True pattern_regexes []patterns schema.get 'patternProperties' None if patterns for regex in patterns pattern_regexes.append re.compile regex if additional_properties for param in set req.GET.keys if param not in schema['properties'].keys if not list regex for regex in pattern_regexes if regex.match param del req.GET[param]
def attach_dummy_node node name object _marker enode EmptyNode enode.object object_attach_local_node node enode name
def xml_str s encoded_str smart_str s encoding 'utf8' errors 'xmlcharrefreplace' encoded_str re.sub INVALID_XML '?' encoded_str return encoded_str
def extract_token_from_cookie request try token request.headers.cookie[u'csrf_token'].valueexcept KeyError token Noneelse token _sanitize_token token if _requesting_asset request token Noneelse token token or _get_new_token return {u'csrf_token' token}
def wcs_to_celestial_frame wcs for mapping_set in WCS_FRAME_MAPPINGS for func in mapping_set frame func wcs if frame is not None return frameraise ValueError u'CouldnotdeterminecelestialframecorrespondingtothespecifiedWCSobject'
def sig_cmp u v order if u[1] > v[1] return -1 if u[1] v[1] if order u[0] < order v[0] return -1 return 1
def s3_flatlist nested for item in nested if isinstance item collections.Iterable and not isinstance item basestring for sub in s3_flatlist item yield sub else yield item
def vat_number_check_digit vat_number normalized_vat_number smart_str vat_number .zfill 10 total 0for i in range 0 10 2 total + int normalized_vat_number[i] for i in range 1 11 2 quotient remainder divmod int normalized_vat_number[i] * 2 10 total + quotient + remainder return smart_unicode 10 - total % 10 % 10
def geometric_conj_ab a b a b map sympify a b if abs a oo or abs b oo return a if abs b oo else b else return a * b / a + b
def diff_dict orig new result dict k ['-'] for k in set orig.keys - set new.keys for key value in new.items if key not in orig or value ! orig[key] result[key] ['+' value]return result
@register.tag name 'wishlists_containing_product' def do_basket_form parse token tokens token.split_contents if len tokens ! 5 raise template.TemplateSyntaxError '%rtagusesthefollowingsyntax {%%wishlists_containing_productwishlistsproductasctx_var%%}' % tokens[0] wishlists_var product_var name_var tokens[1] tokens[2] tokens[4] return ProductWishlistsNode wishlists_var product_var name_var
def _solve_inequality ie s expr ie.lhs - ie.rhs try p Poly expr s if p.degree ! 1 raise NotImplementedErrorexcept PolynomialError NotImplementedError try return reduce_rational_inequalities [[ie]] s except PolynomialError return solve_univariate_inequality ie s a b p.all_coeffs if a.is_positive or ie.rel_op in '! ' ' ' return ie.func s - b / a elif a.is_negative return ie.reversed.func s - b / a else raise NotImplementedError
def iter_errback iterable errback *a **kw it iter iterable while True try yield next it except StopIteration breakexcept errback failure.Failure *a **kw
def assert_equal_none logical_line res asse_equal_start_with_none_re.match logical_line or asse_equal_end_with_none_re.match logical_line if res yield 0 'G318 assertEqual A None orassertEqual None A sentencesnotallowed'
def ttfa_yaml_formatter table_dict data_string table_dict['data'].strip data_list data_string.split '\n' table_string 'TTFA {\n'for definition_string in data_list definition_list definition_string.split ' ' field definition_list[0].strip if len definition_list > 1 value definition_list[1].strip else value "''"table_string table_string + '' * 4 + field + ' ' + value + ' \n' table_string table_string + '}\n\n' return table_string
def mock_requests_get *args **kwargs response_transcript_list '\n<transcript_list>\n<trackid "1"name "Custom"lang_code "en"/>\n<trackid "0"name "Custom1"lang_code "en-GB"/>\n</transcript_list>\n'response_transcript textwrap.dedent '\n<transcript>\n<textstart "100"dur "100">subs#1</text>\n<textstart "200"dur "40">subs#2</text>\n<textstart "240"dur "140">subs#3</text>\n</transcript>\n' if kwargs {'params' {'lang' 'en' 'v' 'good_id_2'}} return Mock status_code 200 text '' elif kwargs {'params' {'type' 'list' 'v' 'good_id_2'}} return Mock status_code 200 text response_transcript_list content response_transcript_list elif kwargs {'params' {'lang' 'en' 'v' 'good_id_2' 'name' 'Custom'}} return Mock status_code 200 text response_transcript content response_transcript return Mock status_code 404 text ''
def get_form_data if is_form_submitted formdata request.formif request.files formdata formdata.copy formdata.update request.files return formdatareturn None
def mode_cmd_no_target mode text text_inp chan conn notice split text_inp.split '' if split[0].startswith '#' channel split[0]notice 'Attemptingto{}{}...'.format text channel conn.send 'MODE{}{}'.format channel mode else channel channotice 'Attemptingto{}{}...'.format text channel conn.send 'MODE{}{}'.format channel mode
def check_anyuri uri config None pos None if uri is not None and not xml_check.check_anyuri uri warn_or_raise W05 W05 uri config pos return Falsereturn True
@pytest.fixture scope u'module' def dummy_input request tmpdir_factory input_path tmpdir_factory.mktemp u'input_data' .join u'datasink_test_s3.txt' input_path.write_binary 'ABCD1234' return str input_path
@bdd.when bdd.parsers.parse 'Isetupafakeeditorreplacing"{text}"by"{replacement}"' def set_up_editor_replacement quteproc httpbin tmpdir text replacement text text.replace ' port ' str httpbin.port script tmpdir / 'script.py' script.write textwrap.dedent '\nimportsys\n\nwithopen sys.argv[1] encoding \'utf-8\' asf \ndata f.read \n\ndata data.replace "{text}" "{replacement}" \n\nwithopen sys.argv[1] \'w\' encoding \'utf-8\' asf \nf.write data \n'.format text text replacement replacement editor '"{}""{}"{{}}'.format sys.executable script quteproc.set_setting 'general' 'editor' editor
@Profiler.profiledef test_orm_query_cols_only n session Session bind engine for id_ in random.sample ids n session.query Customer.id Customer.name Customer.description .filter Customer.id id_ .one
def make_static global_conf document_root cache_max_age None if cache_max_age is not None cache_max_age int cache_max_age return StaticURLParser document_root cache_max_age cache_max_age
def getFileNamesByFilePaths pluginFilePaths fileNames []for pluginFilePath in pluginFilePaths pluginBasename os.path.basename pluginFilePath pluginBasename getUntilDot pluginBasename fileNames.append pluginBasename return fileNames
def _kput url data headers {'Content-Type' 'application/json'}ret http.query url method 'PUT' header_dict headers data json.dumps data if ret.get 'error' return retelse return json.loads ret.get 'body'
def test_equalto value other return value other
def test_scenario_matches_tags_fuzzywuzzy scenario Scenario.from_string SCENARIO1 original_string SCENARIO1.strip tags ['anothertag' 'another-tag'] assert scenario.matches_tags ['~another']
def _safe_read fp size if size < 0 return ''if size < SAFEBLOCK return fp.read size data []while size > 0 block fp.read min size SAFEBLOCK if not block breakdata.append block size - len block return ''.join data
def _matchFriends tg friends mfilter lambda s len ''.join re.findall re.sub '[\\.\\ \\-\\_]' '' '|'.join tg.split .lower re.sub '[\\.\\ \\-\\_]' '' ''.join filter None s .lower return sorted filter lambda s mfilter s > 0 friends key mfilter reverse True
def dtlz1 individual obj g 100 * len individual[ obj - 1 ] + sum xi - 0.5 ** 2 - cos 20 * pi * xi - 0.5 for xi in individual[ obj - 1 ] f [ 0.5 * reduce mul individual[ obj - 1 ] 1 * 1 + g ]f.extend 0.5 * reduce mul individual[ m] 1 * 1 - individual[m] * 1 + g for m in reversed xrange obj - 1 return f
def rooms socketio flask.current_app.extensions['socketio']return socketio.server.rooms flask.request.sid namespace flask.request.namespace
def get_overall_ratings_for_exploration exploration_id exp_summary exp_services.get_exploration_summary_by_id exploration_id return exp_summary.ratings
@njitdef _repeat_1d x K out N x.shape[0]L out.shape[0] // K * N for n in range N val x[n]for k in range K for l in range L ind k * N * L + n * L + l out[ind] val
def wait_for_qos_operations client qos_id operation args None start_time int time.time while True if operation 'qos-key-unset' body client.show_qos qos_id ['qos_specs']if not any key in body['specs'] for key in args returnelif operation 'disassociate' body client.show_association_qos qos_id ['qos_associations']if not any args in body[i]['id'] for i in range 0 len body returnelif operation 'disassociate-all' body client.show_association_qos qos_id ['qos_associations']if not body returnelse msg 'operationvalueiseithernotdefinedorincorrect.'raise lib_exc.UnprocessableEntity msg if int time.time - start_time > client.build_timeout raise lib_exc.TimeoutExceptiontime.sleep client.build_interval
@handle_response_format@treeio_login_required@module_admin_required def pagefolder_edit request folder_id response_format 'html' folder get_object_or_404 PageFolder pk folder_id if request.POST form PageFolderForm request.POST instance folder if form.is_valid folder form.save return HttpResponseRedirect reverse 'core_admin_pagefolder_view' args [folder.id] else form PageFolderForm instance folder return render_to_response 'core/administration/pagefolder_edit' {'folder' folder 'form' form} context_instance RequestContext request response_format response_format
@_docstring 'recording' def search_recordings query '' limit None offset None strict False **fields return _do_mb_search 'recording' query fields limit offset strict
def _get_dev_size dev module blockdev_cmd module.get_bin_path 'blockdev' required True rc devsize_in_bytes err module.run_command '%s%s%s' % blockdev_cmd '--getsize64' dev return int devsize_in_bytes
def _get_units args kwargs if u'unit' not in kwargs units [None None None]else units kwargs.pop u'unit' if isinstance units six.string_types units [x.strip for x in units.split u' ' ]if len units 1 units [units[0] units[0] units[0]]elif isinstance units Unit IrreducibleUnit units [units units units]try units [ Unit x if x else None for x in units]units.extend None for x in range 3 - len units if len units > 3 raise ValueError except Exception raise ValueError u'Unitkeywordmusthaveonetothreeunitvaluesastupleorcomma-separatedstring' return units
def list_projects request return render request 'projects.html' {'projects' Project.objects.all_acl request.user 'title' _ 'Projects' }
def provider_fw_rule_destroy context rule_id return IMPL.provider_fw_rule_destroy context rule_id
def test_sample_weight_adaboost_regressor class DummyEstimator BaseEstimator def fit self X y passdef predict self X return np.zeros X.shape[0] boost AdaBoostRegressor DummyEstimator n_estimators 3 boost.fit X y_regr assert_equal len boost.estimator_weights_ len boost.estimator_errors_
def pathpatch_2d_to_3d pathpatch z 0 zdir u'z' path pathpatch.get_path trans pathpatch.get_patch_transform mpath trans.transform_path path pathpatch.__class__ PathPatch3Dpathpatch.set_3d_properties mpath z zdir
def package_of pkg_or_module pkg_name package_name pkg_or_module __import__ pkg_name return sys.modules[pkg_name]
def fixup adict k v for key in adict.keys if key k adict[key] velif isinstance adict[key] dict fixup adict[key] k v
def _set_config c func sdl2.SDL_GL_SetAttributefunc sdl2.SDL_GL_RED_SIZE c['red_size'] func sdl2.SDL_GL_GREEN_SIZE c['green_size'] func sdl2.SDL_GL_BLUE_SIZE c['blue_size'] func sdl2.SDL_GL_ALPHA_SIZE c['alpha_size'] func sdl2.SDL_GL_DEPTH_SIZE c['depth_size'] func sdl2.SDL_GL_STENCIL_SIZE c['stencil_size'] func sdl2.SDL_GL_DOUBLEBUFFER 1 if c['double_buffer'] else 0 samps c['samples']func sdl2.SDL_GL_MULTISAMPLEBUFFERS 1 if samps > 0 else 0 func sdl2.SDL_GL_MULTISAMPLESAMPLES samps if samps > 0 else 0 func sdl2.SDL_GL_STEREO c['stereo']
def get_valid_cwd try cwd os.getenv 'PWD' or os.getcwd except warn 'Yourcurrentdirectoryisinvalid.Ifyouopenaticketat' + 'https //github.com/milkbikis/powerline-shell/issues/new' + 'wewouldlovetohelpfixtheissue.' sys.stdout.write '>' sys.exit 1 parts cwd.split os.sep up cwdwhile parts and not os.path.exists up parts.pop up os.sep.join parts if cwd ! up warn 'Yourcurrentdirectoryisinvalid.Lowestvaliddirectory ' + up return cwd
def deprecated_attribute old new since None remove None doc None def _warn version u'.'.join six.text_type x for x in since message [u'{}hasbeendeprecatedsince{}'.format old version ]if remove version u'.'.join six.text_type x for x in remove message.append u'andwillberemovedbyversion{}'.format version message.append u'.Use{}instead.'.format new logger.warning u''.join message logger.debug u''.join six.text_type x for x in traceback.format_stack def fget self _warn return getattr self new def fset self value _warn setattr self new value def decorator dummy return property fget fget fset fset doc doc return decorator
def check_theano_variable variable n_dim dtype_prefix if variable is None returnif not isinstance variable tensor.Variable variable tensor.as_tensor_variable variable if n_dim and variable.ndim ! n_dim raise ValueError 'Wrongnumberofdimensions \n DCTB expected{} got{}'.format n_dim variable.ndim if dtype_prefix and not variable.dtype.startswith dtype_prefix raise ValueError 'Wrongdtypeprefix \n DCTB expectedstartingwith{} got{}'.format dtype_prefix variable.dtype
def _py_vq_1d obs code_book raise RuntimeError '_py_vq_1dbuggy donotuserank1arraysfornow' n obs.sizenc code_book.sizedist np.zeros n nc for i in range nc dist[ i] np.sum obs - code_book[i] print dist code np.argmin dist min_dist dist[code]return code np.sqrt min_dist
def _patched_describe_step emr_conn *args **kwargs try boto.emr.emrobject.ClusterTimeline _PatchedClusterTimelinereturn emr_conn.describe_step *args **kwargs finally boto.emr.emrobject.ClusterTimeline ClusterTimeline
def validate_color_or_inherit s if s u'inherit' return sreturn validate_color s
def getExceptionFrameLocals retVal {}if sys.exc_info trace sys.exc_info [2]while trace.tb_next trace trace.tb_nextretVal trace.tb_frame.f_localsreturn retVal
def test_can_parse_tables step Step.from_string I_HAVE_TASTY_BEVERAGES assert isinstance step.hashes list assert_equals len step.hashes 2 assert_equals step.hashes[0] {'Name' 'Skol' 'Type' 'Beer' 'Price' '3.80'} assert_equals step.hashes[1] {'Name' 'Nestea' 'Type' 'Ice-tea' 'Price' '2.10'}
def getFilePathWithUnderscoredBasename fileName suffix suffixFileName getUntilDot fileName + suffix suffixDirectoryName os.path.dirname suffixFileName suffixReplacedBaseName os.path.basename suffixFileName .replace '' '_' return os.path.join suffixDirectoryName suffixReplacedBaseName
def chunked iterable n iterable iter iterable while 1 t tuple islice iterable n if t yield t else return
def normalize_pack_version version version str version version_seperator_count version.count '.' if version_seperator_count 1 version version + '.0' return version
def make_full_parser **kwargs features tuple PARSER_MODULES.iterkeys return make_parser *features **kwargs
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def okay_random length *seeds secret ''while len secret < length secret + sha512b64 os.urandom 128 + length * 2 '%s' % time.time '%x' % random.randint 0 4294967295 *seeds secret CleanText secret banned CleanText.NONALNUM + 'O01l\n DCTB ' .clean[ length]return secret
def get_pid_location module for dir in ['/var/run' '/var/lib/run' '/run' os.path.expanduser '~/' ] try if os.path.isdir dir and os.access dir os.R_OK | os.W_OK return os.path.join dir '.accelerate.pid' except passmodule.fail_json msg "couldn'tfindanyvaliddirectorytousefortheacceleratepidfile"
def _get_bkroot return os.path.join __salt__['config.get'] 'cachedir' 'file_backup'
def string_to_dict string kwargs {}if string string str string if ' ' not in string string + ' 'for arg in string.split ' ' arg arg.strip if arg '' continue kw val arg.split ' ' 1 kwargs[kw] valreturn kwargs
def returner ret conn mdb _get_conn ret if isinstance ret['return'] dict back _remove_dots ret['return'] else back ret['return']if isinstance ret dict full_ret _remove_dots ret else full_ret retlog.debug back sdata {'minion' ret['id'] 'jid' ret['jid'] 'return' back 'fun' ret['fun'] 'full_ret' full_ret}if 'out' in ret sdata['out'] ret['out']if float version > 2.3 mdb.saltReturns.insert_one sdata.copy else mdb.saltReturns.insert sdata.copy
def _releaseLock if _lock _lock.release
def render_to template None mimetype None def renderer function @wraps function def wrapper request *args **kwargs output function request *args **kwargs if not isinstance output dict return outputtmpl output.pop 'TEMPLATE' template return render_to_response tmpl output context_instance RequestContext request mimetype mimetype return wrapperreturn renderer
def network_associate context project_id network_id None force False return IMPL.network_associate context project_id network_id force
def render_accordion request course table_of_contents context dict [ 'toc' table_of_contents 'course_id' unicode course.id 'csrf' csrf request ['csrf_token'] 'due_date_display_format' course.due_date_display_format ] + TEMPLATE_IMPORTS.items return render_to_string 'courseware/accordion.html' context
def systemInformationType17 a L2PseudoLength l2pLength 1 b TpPd pd 6 c MessageType mesType 62 d Si17RestOctets packet a / b / c / d return packet
def _set obj attribute value obj.__dict__[attribute] value
def _get_manifest_by_dir package_dir f os.path.join package_dir roslib.manifest.MANIFEST_FILE if f return roslib.manifest.parse_file f else return None
def _closest_date target_dt date_list before_target None fb lambda d d - target_dt if d > target_dt else datetime.timedelta.max fa lambda d d - target_dt if d < target_dt else datetime.timedelta.min fnone lambda d target_dt - d if d < target_dt else d - target_dt if before_target is None return min date_list key fnone .date if before_target return min date_list key fb .date else return min date_list key fa .date
def getYadisXRD xrd_tree xrd Nonefor xrd in xrd_tree.findall xrd_tag passif xrd is None raise XRDSError 'NoXRDpresentintree' return xrd
def get_subproject request project subproject skip_acl False subproject get_object_or_404 SubProject.objects.prefetch project__slug project slug subproject if not skip_acl subproject.check_acl request return subproject
def ExecutionResult *sources **options if not sources raise DataError 'Oneormoredatasourceneeded.' if options.pop 'merge' False return _merge_results sources[0] sources[1 ] options if len sources > 1 return _combine_results sources options return _single_result sources[0] options
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _check_ports dpid _dirty_switches.pop dpid None con core.openflow.getConnection dpid if con is None returncon.send of.ofp_barrier_request con.send of.ofp_features_request log.debug 'Requestedswitchfeaturesfor%s' str con
def ngettext singular plural number global _default _activet _active.get currentThread None if t is not None return t.ngettext singular plural number if _default is None from django.conf import settings_default translation settings.LANGUAGE_CODE return _default.ngettext singular plural number
def make_query qname rdtype rdclass dns.rdataclass.IN use_edns None want_dnssec False ednsflags 0 payload 1280 request_payload None options None if isinstance qname str unicode qname dns.name.from_text qname if isinstance rdtype str unicode rdtype dns.rdatatype.from_text rdtype if isinstance rdclass str unicode rdclass dns.rdataclass.from_text rdclass m Message m.flags | dns.flags.RDm.find_rrset m.question qname rdclass rdtype create True force_unique True m.use_edns use_edns ednsflags payload request_payload options m.want_dnssec want_dnssec return m
def file_option s return s
def _translate_key key d _get_deprecated_option key if d return d.rkey or key else return key
def _set_retcode ret __context__['retcode'] 0if isinstance ret list __context__['retcode'] 1returnif not salt.utils.check_state_result ret __context__['retcode'] 2
def _colorbar_extension_length spacing cmap norms _get_cmap_norms fig plt.figure fig.subplots_adjust hspace 0.6 for i extension_type in enumerate u'neither' u'min' u'max' u'both' norm norms[extension_type]boundaries values norm.boundariesfor j extendfrac in enumerate None u'auto' 0.1 cax fig.add_subplot 12 1 i * 3 + j + 1 for item in cax.get_xticklabels + cax.get_yticklabels + cax.get_xticklines + cax.get_yticklines item.set_visible False ColorbarBase cax cmap cmap norm norm boundaries boundaries values values extend extension_type extendfrac extendfrac orientation u'horizontal' spacing spacing return fig
def memory_setting label suffixes {u'K' 1000.0 u'M' 1000.0 ** 2 u'G' 1000.0 ** 3 u'T' 1000.0 ** 4 }try mem float label return memexcept ValueError prefix label[ -1 ]suffix label[ -1 ].upper if suffix not in suffixes.keys raise ValueError u'cannotparsememorysetting"{}"'.format label try multiplier float prefix return multiplier * suffixes[suffix] except ValueError raise ValueError u'cannotparsememorysetting"{}"'.format label
def test_quantity_representation t QTable [ [1 2] * u.m ] assert t.pformat ['col0' 'm' '----' '1.0' '2.0']
def check_service protocol None service_address None **kwargs cmd '{0}'.format _build_cmd protocol protocol service_address service_address **kwargs if not kwargs cmd + ''all_rules get_rules out all_rules.find cmd if out ! -1 ret Trueelse ret 'Error servicenotexists'return ret
def expected_bar_value asset_id date colname from_asset asset_id * 100000 from_colname OHLCV.index colname * 1000 from_date date - PSEUDO_EPOCH .daysreturn from_asset + from_colname + from_date
def vm_allocate call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thevm_allocatefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}path kwargs.get 'path' None data kwargs.get 'data' None hold kwargs.get 'hold' False if data if path log.warning "Boththe'data'and'path'argumentswereprovided.'data'willtakeprecedence." elif path data salt.utils.fopen path mode 'r' .read else raise SaltCloudSystemExit "Thevm_allocatefunctionrequireseither'data'orafile'path'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.vm.allocate auth data salt.utils.is_true hold ret {'action' 'vm.allocate' 'allocated' response[0] 'vm_id' response[1] 'error_code' response[2]}return ret
def deunicodise string encoding None errors 'replace' if not encoding encoding S3.Config.Config .encodingif type string ! unicode return str string debug 'DeUnicodising%rusing%s' % string encoding try return string.encode encoding errors except UnicodeEncodeError raise UnicodeEncodeError 'Conversionfromunicodefailed %r' % string
def optimizer f rval FromFunctionOptimizer f rval.__name__ f.__name__return rval
def has_request_context return _request_ctx_stack.top is not None
def layout *args **kwargs responsive kwargs.pop 'responsive' None sizing_mode kwargs.pop 'sizing_mode' 'fixed' children kwargs.pop 'children' None if responsive sizing_mode _convert_responsive responsive _verify_sizing_mode sizing_mode children _handle_children children children *args rows []for r in children row_children []for item in r if isinstance item LayoutDOM item.sizing_mode sizing_moderow_children.append item else raise ValueError 'OnlyLayoutDOMitemscanbeinsertedintoalayout.\nTriedtoinsert %softype%s' % item type item rows.append row children row_children sizing_mode sizing_mode grid column children rows sizing_mode sizing_mode return grid
def enable_pretty_logging options None logger None if options is None from tornado.options import optionsif options.logging is None or options.logging.lower 'none' returnif logger is None logger logging.getLogger logger.setLevel getattr logging options.logging.upper if options.log_file_prefix channel logging.handlers.RotatingFileHandler filename options.log_file_prefix maxBytes options.log_file_max_size backupCount options.log_file_num_backups channel.setFormatter LogFormatter color False logger.addHandler channel if options.log_to_stderr or options.log_to_stderr is None and not logger.handlers channel logging.StreamHandler channel.setFormatter LogFormatter logger.addHandler channel
@register.filter name 'key_exist' def key_exist username if os.path.isfile os.path.join KEY_DIR 'user' username + '.pem' return Trueelse return False
def test_neg_type_misc global calledclr.AddReference 'IronPythonTest' import IronPythonTest.interop.net.type.clrtype as IPTfrom IronPython.Runtime.Types import PythonTypecalled Falseclass MyType type def __clrtype__ self global calledcalled Truereturn IPT.NegativeEmptyclass X object __metaclass__ MyTypea X AreEqual clr.GetClrType type a clr.GetClrType IPT.NegativeEmpty class MyType type def __clrtype__ self global calledcalled Truereturn IPT.NegativeNoConstructorclass X object __metaclass__ MyTypea X AreEqual clr.GetClrType type a clr.GetClrType int
def exact_files directory ignore_links False found []for root _ files in os.walk directory followlinks not ignore_links for f in files p os.path.join root f if ignore_links and os.path.islink p continuefound.append os.path.relpath p directory return found
def skip_on_access_denied only_if None def decorator fun @functools.wraps fun def wrapper *args **kwargs try return fun *args **kwargs except psutil.AccessDenied if only_if is not None if not only_if raisemsg '%rwasskippedbecauseitraisedAccessDenied' % fun.__name__ raise unittest.SkipTest msg return wrapperreturn decorator
def dmp_include f J u K if not J return f F f dmp_to_dict f u {} for monom coeff in F.items monom list monom for j in J monom.insert j 0 f[tuple monom ] coeffu + len J return dmp_from_dict f u K
def _rec_get_names args names None if names is None names []for arg in args if isinstance arg Tuple _rec_get_names arg.elts names else names.append arg.name return names
def strxor_c term c expect_byte_string term if not 0 < c < 256 raise ValueError 'cmustbeinrange 256 ' result create_string_buffer len term _raw_strxor.strxor_c term c result c_size_t len term return get_raw_buffer result
def arma_acf ar ma nobs 10 acovf arma_acovf ar ma nobs return acovf / acovf[0]
def setup_dummy_social_apps sender **kwargs from allauth.socialaccount.providers import registryfrom allauth.socialaccount.models import SocialAppfrom allauth.socialaccount.providers.oauth.provider import OAuthProviderfrom allauth.socialaccount.providers.oauth2.provider import OAuth2Providerfrom django.contrib.sites.models import Sitesite Site.objects.get_current for provider in registry.get_list if isinstance provider OAuth2Provider or isinstance provider OAuthProvider try SocialApp.objects.get provider provider.id sites site except SocialApp.DoesNotExist print 'Installingdummyapplicationcredentialsfor%s.AuthenticationviathisproviderwillnotworkuntilyouconfigurepropercredentialsviatheDjangoadmin `SocialApp`models ' % provider.id app SocialApp.objects.create provider provider.id secret 'secret' client_id 'client-id' name 'Dummy%sapp' % provider.id app.sites.add site
def ssh_connect connection try ssh paramiko.SSHClient ssh.set_missing_host_key_policy paramiko.AutoAddPolicy ssh.connect connection.host username connection.username password connection.password port connection.port key_filename connection.keyfile timeout constants.POWERVM_CONNECTION_TIMEOUT return sshexcept Exception LOG.exception _ 'ConnectionerrorconnectingPowerVMmanager' raise exception.PowerVMConnectionFailed
def get_size start_path total_size 0for dirpath __ filenames in os.walk start_path for f in filenames fp os.path.join dirpath f total_size + os.path.getsize fp return total_size
def test_feature_has_scenarios feature Feature.from_string FEATURE1 expect feature.scenarios .to.be.a list expect feature.scenarios .to.have.length_of 3 expected_scenario_names ['Rentingafeaturedmovie' 'Rentinganon-featuredmovie' 'Rentingtwomoviesallowsclienttotakeonemorewithoutcharge']for scenario expected_name in zip feature.scenarios expected_scenario_names expect scenario .to.be.a Scenario expect scenario.name .to.equal expected_name expect feature.scenarios[1].steps[0].keys .to.equal 'Name' 'Rating' 'New' 'Available' expect list feature.scenarios[1].steps[0].hashes .to.equal [{'Name' 'Anightatthemuseum2' 'Rating' '3stars' 'New' 'yes' 'Available' '9'} {'Name' 'MatrixRevolutions' 'Rating' '4stars' 'New' 'no' 'Available' '6'}]
def qObjectTree root childs [root]for ch in pg.QtCore.QObject.children root childs + qObjectTree ch return childs
@jinja2.contextfunction@library.global_functiondef number context n if n is None return ''return format_decimal n locale _babel_locale _contextual_locale context
def _maybe_coerce_freq code assert code is not None if isinstance code offsets.DateOffset code code.rule_codereturn code.upper
def layer_bitmap layer coord from . import getTile mime body getTile layer coord 'png' image Image.open StringIO body .convert 'RGBA' return Blit.Bitmap image
def get_zoneinfo global zoneinfoif zoneinfo is None zoneinfo zipfile.ZipFile zoneinfo_path return zoneinfo
def itilbert x h period None _cache _cache tmp asarray x if iscomplexobj tmp return itilbert tmp.real h period + 1j * itilbert tmp.imag h period if period is not None h h * 2 * pi / period n len x omega _cache.get n h if omega is None if len _cache > 20 while _cache _cache.popitem def kernel k h h if k return - tanh h * k return 0omega convolve.init_convolution_kernel n kernel d 1 _cache[ n h ] omegaoverwrite_x _datacopied tmp x return convolve.convolve tmp omega swap_real_imag 1 overwrite_x overwrite_x
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def snapshot_get_all_active_by_window context begin end None project_id None return IMPL.snapshot_get_all_active_by_window context begin end project_id
def blog def prep r s3db.configure r.tablename listadd False return Trues3.prep prepdef postp r output if r.record response.view s3base.S3CRUD._view r 'cms/blog.html' return outputs3.postp postpoutput s3_rest_controller 'cms' 'series' return output
def distfitmc sample distr nrepl 100 distkwds {} arg distkwds.pop 'arg' nobs len sample res np.zeros nrepl for ii in range nrepl x distr.rvs arg size nobs **distkwds res[ii] distr.fit_fr x frozen [np.nan 0.0 1.0] return res
def _getcdlistdir return os.listdir getcwd
def test_tukeylambda_stats_invalid lam [ -1.0 -0.5 ]var tukeylambda_variance lam assert_equal var np.array [np.nan np.inf] lam [ -1.0 -0.25 ]kurt tukeylambda_kurtosis lam assert_equal kurt np.array [np.nan np.inf]
@functools.wraps linecache.getlines def getlines filename module_globals None warn '`IPython.utils.ulinecache.getlines`isdeprecatedsinceIPython6.0andwillberemovedinfutureversions.' DeprecationWarning stacklevel 2 return linecache.getlines filename module_globals module_globals
def libvlc_video_set_subtitle_file p_mi psz_subtitle f _Cfunctions.get 'libvlc_video_set_subtitle_file' None or _Cfunction 'libvlc_video_set_subtitle_file' 1 1 None ctypes.c_int MediaPlayer ctypes.c_char_p return f p_mi psz_subtitle
def p4_read_pipe_lines c real_cmd p4_build_cmd c return read_pipe_lines real_cmd
def megacycles_to_cpu_seconds mcycles return mcycles / MCYCLES_PER_SECOND
def class_for_name class_name tokens class_name.split '.' if len tokens > 1 package '.'.join tokens[ -1 ] class_name tokens[ -1 ]exec 'from%simport%s' % package class_name return eval class_name
def cossim vec1 vec2 vec1 vec2 dict vec1 dict vec2 if not vec1 or not vec2 return 0.0vec1len 1.0 * math.sqrt sum val * val for val in itervalues vec1 vec2len 1.0 * math.sqrt sum val * val for val in itervalues vec2 assert vec1len > 0.0 and vec2len > 0.0 'sparsedocumentsmustnotcontainanyexplicitzeroentries'if len vec2 < len vec1 vec1 vec2 vec2 vec1 result sum value * vec2.get index 0.0 for index value in iteritems vec1 result / vec1len * vec2len return result
def internals input_string source_path None destination_path None input_encoding 'unicode' settings_overrides None if settings_overrides overrides settings_overrides.copy else overrides {}overrides['input_encoding'] input_encoding output pub core.publish_programmatically source_class io.StringInput source input_string source_path source_path destination_class io.NullOutput destination None destination_path destination_path reader None reader_name 'standalone' parser None parser_name 'restructuredtext' writer None writer_name 'null' settings None settings_spec None settings_overrides overrides config_section None enable_exit_status None return pub.writer.document pub
def test_gmail_folders_no_flags monkeypatch folders [ '\\HasNoChildren' '/' u'INBOX' '\\Noselect' '\\HasChildren' '/' u'[Gmail]' '\\HasNoChildren' '\\All' '/' u'[Gmail]/AllMail' '\\HasNoChildren' '\\Drafts' '/' u'[Gmail]/Drafts' '\\HasNoChildren' '\\Important' '/' u'[Gmail]/Important' '\\HasNoChildren' '/' u'[Gmail]/SentMail' '\\HasNoChildren' '/' u'[Gmail]/Spam' '\\Flagged' '\\HasNoChildren' '/' u'[Gmail]/Starred' '\\HasNoChildren' '/' u'[Gmail]/Trash' '\\HasNoChildren' '/' u'reference' ]gmail_role_map {'[Gmail]/AllMail' 'all' 'Inbox' 'inbox' '[Gmail]/Trash' 'trash' '[Gmail]/Spam' 'spam' '[Gmail]/Drafts' 'drafts' '[Gmail]/SentMail' 'sent' '[Gmail]/Important' 'important' '[Gmail]/Starred' 'starred' 'reference' None}client patch_gmail_client monkeypatch folders raw_folders client.folders generic_folder_checks raw_folders gmail_role_map client 'gmail'
def bold text return u''.join [CONTROL_BOLD text CONTROL_BOLD]
def get_logger global _loggerif not _logger import logging atexitif hasattr atexit 'unregister' atexit.unregister _exit_function atexit.register _exit_function else atexit._exithandlers.remove _exit_function {} atexit._exithandlers.append _exit_function {} _check_logger_class _logger logging.getLogger LOGGER_NAME return _logger
def send_notification_email language email notification translation_obj None context None headers None user None info None email get_notification_email language email notification translation_obj context headers user info send_mails [email]
def transcode text input PREFERRED_ENCODING output PREFERRED_ENCODING try return text.decode 'cp437' .encode 'cp1252' except UnicodeError try return text.decode 'cp437' .encode output except UnicodeError return text
def _kwa val onts mdb_safe False if not mdb_safe return dict [ k from_dict v onts for k v in val.items if k not in EXP_SKIP ] else _skip ['_id']_skip.extend EXP_SKIP return dict [ k.replace '__' '.' from_dict v onts for k v in val.items if k not in _skip ]
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def jacardCoefficient a b if a.shape ! b.shape raise ValueError 'Arraysmustbeofsameshape' length a.shape[0]a a.astype bool b b.astype bool return float a b .sum / length
def set_learning_phase value global _GRAPH_LEARNING_PHASESif value not in {0 1} raise ValueError 'Expectedlearningphasetobe0or1.' _GRAPH_LEARNING_PHASES[tf.get_default_graph ] value
def dumps obj key None salt u'django.core.signing' serializer JSONSerializer compress False data serializer .dumps obj is_compressed Falseif compress compressed zlib.compress data if len compressed < len data - 1 data compressedis_compressed Truebase64d b64_encode data if is_compressed base64d '.' + base64d return TimestampSigner key salt salt .sign base64d
def qsub_sanitize_job_name testjobname if testjobname[0].isalpha return testjobnameelse return u'J' + testjobname
def gen_query_hash sql sql COMMENTS_REGEX.sub '' sql sql ''.join sql.split .lower return hashlib.md5 sql.encode 'utf-8' .hexdigest
def shared_normal num_rows num_cols scale 1 return theano.shared numpy.random.normal scale scale size num_rows num_cols .astype theano.config.floatX
def _find_exe path exe_list for filename in os.listdir path if os.path.isfile os.path.join path filename if '.exe' in filename exe_list.append path + '\\' + filename else exe_list _find_exe path + '\\' + filename exe_list return exe_list
def remove_file filename if os.path.exists filename os.remove filename
def columnize items row_first False separator '' displaywidth 80 spread False if not items return '\n' matrix info compute_item_matrix items row_first row_first separator_size len separator displaywidth displaywidth if spread separator separator.ljust int info['optimal_separator_width'] fmatrix [filter None x for x in matrix]sjoin lambda x separator.join [y.ljust w '' for y w in zip x info['column_widths'] ] return '\n'.join map sjoin fmatrix + '\n'
def static prefix view serve **kwargs if not settings.DEBUG or prefix and ' //' in prefix return []elif not prefix raise ImproperlyConfigured 'Emptystaticprefixnotpermitted' return [url '^%s ?P<path>.* $' % re.escape prefix.lstrip '/' view kwargs kwargs ]
def set_subprocess _subprocess None global subprocesssubprocess _subprocess
def blend *cols **kwargs return Blend *cols **kwargs
def pathignore registry xml_parent data ruby XML.SubElement xml_parent 'ruby-proxy-object' robj XML.SubElement ruby 'ruby-object' attrib {'pluginid' 'pathignore' 'ruby-class' 'Jenkins Plugin Proxies BuildWrapper'} pluginid XML.SubElement robj 'pluginid' {'pluginid' 'pathignore' 'ruby-class' 'String'} pluginid.text 'pathignore'obj XML.SubElement robj 'object' {'ruby-class' 'PathignoreWrapper' 'pluginid' 'pathignore'} ignored XML.SubElement obj 'ignored__paths' {'pluginid' 'pathignore' 'ruby-class' 'String'} ignored.text data.get 'ignored' '' XML.SubElement obj 'invert__ignore' {'ruby-class' 'FalseClass' 'pluginid' 'pathignore'}
def IsErrorSuppressedByNolint category linenum return linenum in _error_suppressions.get category set or linenum in _error_suppressions.get None set
def get_colormaps return _colormaps.copy
def _create_open_message local_ip port description 'UPnPPunch' protocol 'TCP' upnp_schema 'WANIPConnection' soap_message '<?xmlversion "1.0"?>\n<s Envelopexmlns s "http //schemas.xmlsoap.org/soap/envelope/"s encodingStyle "http //schemas.xmlsoap.org/soap/encoding/">\n<s Body>\n<u AddPortMappingxmlns u "urn schemas-upnp-org service {upnp_schema} 1">\n<NewRemoteHost></NewRemoteHost>\n<NewExternalPort>{port}</NewExternalPort>\n<NewProtocol>{protocol}</NewProtocol>\n<NewInternalPort>{port}</NewInternalPort>\n<NewInternalClient>{host_ip}</NewInternalClient>\n<NewEnabled>1</NewEnabled>\n<NewPortMappingDescription>{description}</NewPortMappingDescription>\n<NewLeaseDuration>0</NewLeaseDuration>\n</u AddPortMapping>\n</s Body>\n</s Envelope>'.format port port protocol protocol host_ip local_ip description description upnp_schema upnp_schema return REMOVE_WHITESPACE.sub '><' soap_message 'AddPortMapping'
def ismodule object return isinstance object types.ModuleType
def setup_environment global oldstuff platformstuffoldstuff env.copy os.name sys.platform path.get_home_dir IPython.__file__ os.getcwd
def minibatch_map fn batch_size input_data output_data None output_width None if output_width is None if output_data is None raise ValueError 'output_dataoroutput_widthshouldbeprovided' output_width output_data.shape[1]output_length input_data.shape[0]if output_data is None output_data numpy.empty output_length output_width else assert output_data.shape[0] input_data.shape[0] 'output_datashouldhavethesamelengthasinput_data' output_data.shape[0] input_data.shape[0] for i in xrange 0 output_length batch_size output_data[i i + batch_size ] fn input_data[i i + batch_size ] return output_data
def remove_directory dirpath if os.path.exists dirpath shutil.rmtree dirpath ignore_errors True
def dt_to_decimal utc decimal.getcontext .prec 30return decimal.Decimal str calendar.timegm utc.utctimetuple + decimal.Decimal str utc.microsecond / decimal.Decimal '1000000.0'
def restart_httpd_all request notifier .restart 'http' notifier .restart 'django' return HttpResponse 'OK'
def buildTableFromCompletedList data_source headers data_source[0]items data_source[2 ]table TABLE _id 'completed_list' _class 'dataTabledisplay' hr TR for title in headers hr.append TH title header THEAD hr body TBODY for row in items tr TR for answer in row tr.append TD answer body.append tr table.append header table.append body current.response.s3.no_sspag Trueattr S3DataTable.getConfigData form S3DataTable.htmlConfig table 'completed_list' [[0 'asc']] '' None **attr return form
def data_url path data utils.read_file path binary True filename utils.resource_filename path mimetype mimetypes.guess_type filename assert mimetype is not None pathreturn urlutils.data_url mimetype[0] data .toString
def extractTextTagContent page page page or '' if REFLECTED_VALUE_MARKER in page page re.sub ' ?si [^\\s>]*%s[^\\s<]*' % REFLECTED_VALUE_MARKER '' page return filter None _.group 'result' .strip for _ in re.finditer TEXT_TAG_REGEX page
def error_next_redirect request default '/' additional_params None next_key None redirect_url None canvas False if not next_key next_key ['error_next' 'next']redirect next_redirect request default additional_params next_key redirect_url canvas return redirect
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def test_setitem_as_column_name t Table t['a'] ['x' 'y']t['b'] 'b'assert np.all t['a'] ['x' 'y'] assert np.all t['b'] ['b' 'b']
def convert_CategoryProperty model prop kwargs return get_TextField kwargs
def metadata_accept rule '-ptcp-mtcp--dport%s%s-jACCEPT' % CONF.metadata_port _iptables_dest CONF.metadata_host if netaddr.IPAddress CONF.metadata_host .version 4 iptables_manager.ipv4['filter'].add_rule 'INPUT' rule else iptables_manager.ipv6['filter'].add_rule 'INPUT' rule iptables_manager.apply
def takes_args function return bool function.__code__.co_flags & 4
def _slow_construct_edges G radius p for u pu v pv in combinations G.nodes data 'pos' 2 if sum abs a - b ** p for a b in zip pu pv < radius ** p G.add_edge u v
def _item_to_metric iterator log_metric_pb resource MessageToDict log_metric_pb return Metric.from_api_repr resource iterator.client
def packOpen_direct_tcpip destination source connHost connPort destination origHost origPort sourceif isinstance connHost unicode connHost connHost.encode 'utf-8' if isinstance origHost unicode origHost origHost.encode 'utf-8' conn common.NS connHost + struct.pack '>L' connPort orig common.NS origHost + struct.pack '>L' origPort return conn + orig
def is_valid_git_sha1 hash if len hash ! 40 return Falsetry value int hash 16 except ValueError return Falsereturn True
def _valid_size size if size % 1024 0 return True '' return False 'Filesystemsizemustbemultipleof1024 not%d' % size
def table_plot data np.array [[1 4 2 5 2] [2 1 1 3 6] [5 3 6 4 1]] index np.arange len data[0] color_index ['r' 'g' 'b']bottom np.array [0 0 0 0 0] for i in range len data plt.bar index + 0.25 data[i] width 0.5 color color_index[i] bottom bottom alpha 0.7 label 'label%d' % i bottom + data[i]plt.legend loc 'upperleft' shadow True plt.show return
def test_enn_sample_wt_fit enn EditedNearestNeighbours random_state RND_SEED assert_raises RuntimeError enn.sample X Y
def chunk_xml xml depth 0 data etree.tostring xml root xml.findall 'add' and 'add' or 'delete' content_length len data if content_length < _CHUNK_SIZE yield data else depth + 1print 'WARNING Chunking depth %s ' % depth half len xml / 2 left_half xmlright_half etree.Element root right_half.append xml[half ] for chunk in chunk_xml left_half depth depth yield chunk for chunk in chunk_xml right_half depth depth yield chunk
def matshow A fignum None **kw A np.asanyarray A if fignum is False or fignum is 0 ax gca else fig figure fignum figsize figaspect A ax fig.add_axes [0.15 0.09 0.775 0.775] im ax.matshow A **kw sci im return im
def _square_of_sums a axis 0 a axis _chk_asarray a axis s np.sum a axis if not np.isscalar s return s.astype float * s else return float s * s
def is_letter uni_char category Category.get uni_char return category Category.UPPERCASE_LETTER or category Category.LOWERCASE_LETTER or category Category.TITLECASE_LETTER or category Category.MODIFIER_LETTER or category Category.OTHER_LETTER
def publish long_description make_long_description if long_description ! read RST_DESCRIPTION_PATH print 'Descriptionfilenotup-to-date %s\nRunthefollowingcommandandcommitthechanges--\n\npythonsetup.py%s\n' % RST_DESCRIPTION_PATH PREP_COMMAND sys.exit print 'Descriptionup-to-date %s' % RST_DESCRIPTION_PATH answer raw_input 'AreyousureyouwanttopublishtoPyPI yes/no ?' if answer ! 'yes' exit 'Aborted nothingpublished' os.system 'pythonsetup.pysdistupload'
def hmac_sha512 k m key OpenSSL.malloc k len k d OpenSSL.malloc m len m md OpenSSL.malloc 0 64 i OpenSSL.pointer OpenSSL.c_int 0 OpenSSL.HMAC OpenSSL.EVP_sha512 key len k d len m md i return md.raw
def walk_packages path None prefix '' onerror None def seen p m {} if p in m return Truem[p] Truefor importer name ispkg in iter_modules path prefix yield importer name ispkg if ispkg try __import__ name except ImportError if onerror is not None onerror name except Exception if onerror is not None onerror name else raiseelse path getattr sys.modules[name] '__path__' None or [] path [p for p in path if not seen p ]for item in walk_packages path name + '.' onerror yield item
def check_symlinks directory symlinks True for root _ files in os.walk directory for f in files p os.path.join root f if symlinks ^ os.path.islink p return Falsereturn True
def describe_attributes obj attrs func None if not func func lambda x x pairs []for attr in attrs value getattr obj attr None if func value pairs.append '%s %s' % attr value return ' '.join pairs
def parallel_func func n_jobs verbose 5 try try from joblib import Parallel delayedexcept ImportError from sklearn.externals.joblib import Parallel delayedparallel Parallel n_jobs verbose verbose my_func delayed func if n_jobs -1 try import multiprocessingn_jobs multiprocessing.cpu_count except ImportError NotImplementedError import warningswarnings.warn module_unavailable_doc.format 'multiprocessing' ModuleUnavailableWarning n_jobs 1except ImportError import warningswarnings.warn module_unavailable_doc.format 'joblib' ModuleUnavailableWarning n_jobs 1my_func funcparallel listreturn parallel my_func n_jobs
def computeObjectKey id generationNum encryptionKey keyLengthBytes algorithm 'RC4' key encryptionKey + struct.pack '<i' id [ 3] + struct.pack '<i' generationNum [ 2] if algorithm 'AES' key + 'sAlT'key hashlib.md5 key .digest if keyLengthBytes + 5 < 16 key key[ keyLengthBytes + 5 ]else key key[ 16]return key
def quay_versions namespace pkg_name if requests is None raise Exception 'requetslibraryisunavailable functionalitynotavailable.' assert namespace is not None assert pkg_name is not None url 'https //quay.io/api/v1/repository/%s/%s' % namespace pkg_name response requests.get url timeout None data response.json if 'error_type' in data and data['error_type'] 'invalid_token' return []if 'tags' not in data raise Exception 'Unexpectedresponsefromquay.io-nottagsdescriptionfound[%s]' % data return [tag for tag in data['tags'] if tag ! 'latest' ]
def build_inverse_barcode_map seqs inverse_map {}map_count defaultdict int for label seq in seqs map_id seq_id label.split [ 2]map_id map_id.split '_' [0]inverse_map[seq_id] map_idmap_count[map_id] + 1return inverse_map map_count
def result_to_country result if 'country' in result mapbox_country result['country']codes dict v k for k v in product_details.get_regions 'en-US' .iteritems code codes.get mapbox_country['name'] '' lookup_args {'name' mapbox_country['name']}args {'mapbox_id' mapbox_country['id'] 'code' code}args.update lookup_args query Q **lookup_args | Q mapbox_id mapbox_country['id'] country_qs Country.objects.filter query .distinct if country_qs.exists if country_qs.count 2 deduplicate_countries country_qs[0] country_qs[1] country_qs.update **args country country_qs[0]else country Country.objects.create **args return country
def UpdateResourcesFromDict dstpath res types None names None languages None if types types set types if names names set names if languages languages set languages for type_ in res if not types or type_ in types for name in res[type_] if not names or name in names for language in res[type_][name] if not languages or language in languages UpdateResources dstpath res[type_][name][language] [type_] [name] [language]
def search_keys text keyserver None user None if GPG_1_3_1 raise SaltInvocationError 'Thesearch_keysfunctionisnotsupportwiththisversionofpython-gnupg.' else if not keyserver keyserver 'pgp.mit.edu'_keys []for _key in _search_keys text keyserver user tmp {'keyid' _key['keyid'] 'uids' _key['uids']}expires _key.get 'expires' None date _key.get 'date' None length _key.get 'length' None if expires tmp['expires'] time.strftime '%Y-%m-%d' time.localtime float _key['expires'] if date tmp['created'] time.strftime '%Y-%m-%d' time.localtime float _key['date'] if length tmp['keyLength'] _key['length']_keys.append tmp return _keys
def _delete_calendar db_session calendar count 0for e in calendar.events db_session.delete e count + 1if count % 100 0 db_session.commit db_session.commit db_session.delete calendar db_session.commit
def halt return shutdown
def expandedEpoch epoch int getEpoch return [str epoch str epoch - 1 str epoch + 1 ]
def run_if_active func @functools.wraps func def inner self if not keyczar_active returnreturn func self return inner
def term_translation_show context data_dict model context['model']trans_table model.term_translation_tableq _select [trans_table] if 'terms' not in data_dict raise ValidationError {'terms' 'termsnotindata'} terms _get_or_bust data_dict 'terms' if isinstance terms basestring terms [terms]if terms q q.where trans_table.c.term.in_ terms if 'lang_codes' in data_dict lang_codes _get_or_bust data_dict 'lang_codes' if isinstance lang_codes basestring lang_codes [lang_codes]q q.where trans_table.c.lang_code.in_ lang_codes conn model.Session.connection cursor conn.execute q results []for row in cursor results.append _table_dictize row context return results
def cublas_init pass
def generate_sha1 string salt None if not isinstance string str text_type string str string if not salt salt sha1 str random.random .encode 'utf-8' .hexdigest [ 5]salted_bytes smart_bytes salt + smart_bytes string hash_ sha1 salted_bytes .hexdigest return salt hash_
@when u'westartexternaleditorprovidingafilename' def step_edit_file context context.editor_file_name u'test_file_{0}.sql'.format context.conf[u'vi'] if os.path.exists context.editor_file_name os.remove context.editor_file_name context.cli.sendline u'\\e{0}'.format context.editor_file_name _expect_exact context u'nano' timeout 2
def get_compile_mode node if not isinstance node mod raise TypeError 'expectedmodnode got%r' % node.__class__.__name__ return {Expression 'eval' Interactive 'single'}.get node.__class__ 'expr'
def end_block fid kind write_int fid FIFF.FIFF_BLOCK_END kind
def get_cgroup_mountpoint controller if controller not in get_all_controllers raise error.TestError "Doesn'tsupportcontroller<%s>" % controller f_cgcon open '/proc/mounts' 'rU' cgconf_txt f_cgcon.read f_cgcon.close mntpt re.findall '\\s \\S*cgroup/\\S* *%s *\\S* ' % controller cgconf_txt return mntpt[0]
def gnc_graph n create_using None seed None if create_using is None create_using nx.DiGraph elif not create_using.is_directed raise nx.NetworkXError 'DirectedGraphrequiredincreate_using' if seed is not None random.seed seed G empty_graph 1 create_using G.name 'gnc_graph %s ' % n if n 1 return Gfor source in range 1 n target random.randrange 0 source for succ in G.successors target G.add_edge source succ G.add_edge source target return G
def _out_encoding return _stream_encoding sys.stdout
def linear x return x
def _parse_creation creation_string field_name split_creation_string creation_string.split '.' 1 if len split_creation_string ! 2 raise _CreationFormatError 'Couldnotparsecreation%sinfield%s.' % creation_string field_name timestamp_string microsecond split_creation_stringtry timestamp time.strptime timestamp_string _BASE_CREATION_HEADER_FORMAT microsecond int microsecond except ValueError raise _CreationFormatError 'Couldnotparsecreation%sinfield%s.' % creation_string field_name return datetime.datetime * timestamp[ 6] + tuple [microsecond]
def createNetwork dataSource network Network network.addRegion 'sensor' 'py.RecordSensor' json.dumps {'verbosity' _VERBOSITY} sensor network.regions['sensor'].getSelf sensor.encoder createEncoder sensor.dataSource dataSourcesys.path.append os.path.dirname os.path.abspath __file__ from custom_region.identity_region import IdentityRegionNetwork.registerRegion IdentityRegion network.addRegion 'identityRegion' 'py.IdentityRegion' json.dumps {'dataWidth' sensor.encoder.getWidth } network.link 'sensor' 'identityRegion' 'UniformLink' '' network.initialize return network
def versioned_id_field resource_settings return resource_settings['id_field'] + app.config['VERSION_ID_SUFFIX']
def _generate_image_and_label_batch image label min_queue_examples batch_size shuffle num_preprocess_threads 16if shuffle images label_batch tf.train.shuffle_batch [image label] batch_size batch_size num_threads num_preprocess_threads capacity min_queue_examples + 3 * batch_size min_after_dequeue min_queue_examples else images label_batch tf.train.batch [image label] batch_size batch_size num_threads num_preprocess_threads capacity min_queue_examples + 3 * batch_size tf.image_summary 'images' images return images tf.reshape label_batch [batch_size]
def string_partial_matching alternatives inp ret_index True if not alternatives or not inp return []matches defaultdict list inp_words inp.lower .split for altindex alt in enumerate alternatives alt_words alt.lower .split last_index 0score 0for inp_word in inp_words submatch [ last_index + alt_num for alt_num alt_word in enumerate alt_words[last_index ] if alt_word.startswith inp_word ]if submatch last_index min submatch + 1 score + 1else score 0breakif score if ret_index matches[score].append altindex else matches[score].append alt if matches return matches[max matches ]return []
def test_read_bin_lush_matrix_float_3tensor path example_bin_lush_path + 'float_3tensor.lushbin' result read_bin_lush_matrix path assert str result.dtype 'float32' assert len result.shape 3 if result.shape ! 4 3 2 raise AssertionError 'ubyte_3tensor.lushbinstoresa3-tensorofshape 4 3 2 butread_bin_lush_matrixthinksithasshape' + str result.shape for i in xrange 1 result.shape[0] + 1 for j in xrange 1 result.shape[1] + 1 for k in xrange 1 result.shape[2] + 1 assert np.allclose result[ i - 1 j - 1 k - 1 ] i + 1.5 * j + 1.7 * k
@click.command u'write-docs' @pass_context@click.argument u'app' @click.option u'--target' default None @click.option u'--local' default False is_flag True help u'Runapplocally' def write_docs context app target None local False from frappe.utils.setup_docs import setup_docsif not target target os.path.abspath os.path.join u'..' u'docs' app for site in context.sites try frappe.init site site frappe.connect make setup_docs app make.make_docs target local finally frappe.destroy
def get_by session model pk_value primary_key None result query_by_primary_key session model pk_value primary_key return result.first
def build_launch_request authenticated True request RequestFactory .post '/' request.user UserFactory.create request.user.is_authenticated MagicMock return_value authenticated request.session {}request.POST.update LTI_DEFAULT_PARAMS return request
def getTokenByNumber number return '_%s_' % number
def _get_fast_dot try from sklearn.utils.extmath import fast_dotexcept ImportError fast_dot np.dotreturn fast_dot
def fix_attribute_names payload api_model data payload.copy for key in payload if api_model[key].attribute data[api_model[key].attribute] data[key]del data[key]return data
@core_helperdef convert_to_dict object_type objs def dictize_revision_list revision context def process_names items array []for item in items array.append item.name return arrayrev {'id' revision.id 'state' revision.state 'timestamp' revision.timestamp 'author' revision.author 'packages' process_names revision.packages 'groups' process_names revision.groups 'message' revision.message}return revimport ckan.lib.dictization.model_dictize as mdconverters {'package' md.package_dictize 'revisions' dictize_revision_list}converter converters[object_type]items []context {'model' model}for obj in objs item converter obj context items.append item return items
def pfilter f patterns None use_regex False if patterns is None return Trueif use_regex for p in patterns r re.compile p if r.match f return Trueelse for p in patterns if fnmatch.fnmatch f p return Truereturn False
def R2 w if w.startswith tuple overstemmed return R1 R1 R1 w return R1 R1 w
def create_principal name enctypes None ret {}krb_cmd 'addprinc-randkey'if enctypes krb_cmd + '-e{0}'.format enctypes krb_cmd + '{0}'.format name cmd __execute_kadmin krb_cmd if cmd['retcode'] ! 0 or cmd['stderr'] if not cmd['stderr'].splitlines [ -1 ].startswith 'WARNING ' ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retreturn True
def chebys n monic False if n < 0 raise ValueError 'nmustbenonnegative.' if n 0 n1 n + 1 else n1 n x w mu0 roots_chebys n1 mu True if n 0 x w [] [] hn pikn 1.0p orthopoly1d x w hn kn wfunc lambda x sqrt 1 - x * x / 4.0 limits -2 2 monic monic if not monic factor n + 1.0 / p 2 p._scale factor p.__dict__['_eval_func'] lambda x eval_chebys n x return p
def for_app *app_names **kwargs def _for_app fn command if is_app command *app_names **kwargs return fn command else return Falsereturn decorator _for_app
def _api_queue_change_complete_action output value kwargs sabnzbd.change_queue_complete_action value return report output
def createTables tables ifNotExists True for table in tables _dbschema_logger.info 'creatingtable%s' table._imdbpyName table.createTable ifNotExists if table._imdbpySchema.values _dbschema_logger.info 'insertingvaluesintotable%s' table._imdbpyName for key in table._imdbpySchema.values for value in table._imdbpySchema.values[key] table **{key unicode value }
def MakeGuid name seed 'msvs_new' d _new_md5 str seed + str name .hexdigest .upper guid '{' + d[ 8] + '-' + d[8 12] + '-' + d[12 16] + '-' + d[16 20] + '-' + d[20 32] + '}' return guid
def is_pkiz token_text return token_text.startswith PKIZ_PREFIX
def _clear_dict endpoint_props return dict prop_name prop_val for prop_name prop_val in six.iteritems endpoint_props if prop_val is not None
def mangle_mako_loop node printer loop_variable LoopVariable node.accept_visitor loop_variable if loop_variable.detected node.nodes[ -1 ].has_loop_context Truematch _FOR_LOOP.match node.text if match printer.writelines 'loop __M_loop._enter %s ' % match.group 2 'try ' text 'for%sinloop ' % match.group 1 else raise SyntaxError "Couldn'tapplyloopcontext %s" % node.text else text node.textreturn text
def ffmpeg_merge_video_audio video audio output vcodec 'copy' acodec 'copy' ffmpeg_output False verbose True cmd [get_setting 'FFMPEG_BINARY' '-y' '-i' audio '-i' video '-vcodec' vcodec '-acodec' acodec output]subprocess_call cmd verbose verbose
def init_manager signal.signal signal.SIGINT signal.SIG_IGN
def valid_memslice_dtype dtype i 0 if dtype.is_complex and dtype.real_type.is_int return Falseif dtype is PyrexTypes.c_bint_type return Falseif dtype.is_struct and dtype.kind 'struct' for member in dtype.scope.var_entries if not valid_memslice_dtype member.type return Falsereturn Truereturn dtype.is_error or dtype.is_array and i < 8 and valid_memslice_dtype dtype.base_type i + 1 or dtype.is_numeric or dtype.is_pyobject or dtype.is_fused or dtype.is_typedef and valid_memslice_dtype dtype.typedef_base_type
def _parse_add_values argvish new_cmd_format opts args validate_args argvish parsed_devs []if len args > 0 if new_cmd_format or len args % 2 ! 0 print Commands.add.__doc__.strip exit EXIT_ERROR devs_and_weights izip islice args 0 len args 2 islice args 1 len args 2 for devstr weightstr in devs_and_weights dev_dict parse_add_value devstr if dev_dict['region'] is None stderr.write 'WARNING Noregionspecifiedfor%s.Defaultingtoregion1.\n' % devstr dev_dict['region'] 1if dev_dict['replication_ip'] is None dev_dict['replication_ip'] dev_dict['ip']if dev_dict['replication_port'] is None dev_dict['replication_port'] dev_dict['port']weight float weightstr if weight < 0 raise ValueError 'Invalidweightvalue %s' % devstr dev_dict['weight'] weightparsed_devs.append dev_dict else parsed_devs.append build_dev_from_opts opts return parsed_devs
def parse_authorization_header value if not value returnvalue wsgi_to_bytes value try auth_type auth_info value.split None 1 auth_type auth_type.lower except ValueError returnif auth_type 'basic' try username password base64.b64decode auth_info .split ' ' 1 except Exception returnreturn Authorization 'basic' {'username' bytes_to_wsgi username 'password' bytes_to_wsgi password } elif auth_type 'digest' auth_map parse_dict_header auth_info for key in 'username' 'realm' 'nonce' 'uri' 'response' if key not in auth_map returnif 'qop' in auth_map if not auth_map.get 'nc' or not auth_map.get 'cnonce' returnreturn Authorization 'digest' auth_map
def WrapLinkerMany linkers wrappers def wrapper *args for f in wrappers f *args return WrapLinker linkers wrapper
def onTimedEvent source e global COUNTCOUNT COUNT + 1
def _ticket_tuple ticket attempts ticket.getAttempt date ticket.getTime ip ticket.getIP matches ticket.getMatches return ip attempts date matches
def g return 5
def whiten obs check_finite True obs _asarray_validated obs check_finite check_finite std_dev np.std obs axis 0 zero_std_mask std_dev 0 if zero_std_mask.any std_dev[zero_std_mask] 1.0warnings.warn 'Somecolumnshavestandarddeviationzero.Thevaluesofthesecolumnswillnotchange.' RuntimeWarning return obs / std_dev
def header_check octet return chr octet ! _QUOPRI_HEADER_MAP[octet]
def GetStub si GetSi if si return si._GetStub return None
def get_custom_sql app from django.db.models import get_modelsoutput []app_models get_models app app_dir os.path.normpath os.path.join os.path.dirname app.__file__ 'sql' for model in app_models output.extend get_custom_sql_for_model model return output
def vm_state_from_status status for state task_map in _STATE_MAP.iteritems status_string task_map.get 'default' if status.lower status_string.lower return state
def get_locale_path lang_code None if not lang_code return settings.USER_WRITABLE_LOCALE_DIRelse return os.path.join settings.USER_WRITABLE_LOCALE_DIR lcode_to_django_dir lang_code
def _candidate_tempdir_list dirlist []for envname in 'TMPDIR' 'TEMP' 'TMP' dirname _os.getenv envname if dirname dirlist.append dirname if _os.name 'nt' dirlist.extend ['c \\temp' 'c \\tmp' '\\temp' '\\tmp'] else dirlist.extend ['/tmp' '/var/tmp' '/usr/tmp'] try dirlist.append _os.getcwd except AttributeError OSError dirlist.append _os.curdir return dirlist
def cache_local tex_root name generate try result read_local tex_root name except CacheMiss result generate write_local tex_root name result return result
def to_hgrid node auth **data return NodeFileCollector node auth **data .to_hgrid
def convert_perm perm if isinstance perm six.integer_types perm six.text_type perm return int perm 8
def do_deactivate_realm realm if realm.deactivated returnrealm.deactivated Truerealm.save update_fields ['deactivated'] for user in active_humans_in_realm realm delete_user_sessions user
@_FFI.callback u'Value ExternContext* Value** uint64_t bool ' def extern_store_list context_handle vals_ptr_ptr vals_len merge c _FFI.from_handle context_handle vals tuple c.from_value val for val in _FFI.unpack vals_ptr_ptr vals_len if merge merged_set set def merged for outer_val in vals for inner_val in outer_val if inner_val in merged_set continuemerged_set.add inner_val yield inner_val vals tuple merged return c.to_value vals
def is_iterable_but_not_string obj return is_iterable obj and not hasattr obj 'strip'
def TruncDelta delta return datetime.timedelta days delta.days seconds delta.seconds
def _ips_get_pkgversion line return line.split [0].split '@' [1].strip
def test_normal_mode img data.coins keypoints corner_peaks corner_harris img min_distance 5 threshold_abs 0 threshold_rel 0.1 extractor BRIEF descriptor_size 8 sigma 2 extractor.extract img keypoints[ 8] expected np.array [[False True False False True False True False] [True False True True False True False False] [True False False True False True False True] [True True True True False True False True] [True True True False False True True True] [False False False False True False False False] [False True False False True False True False] [False False False False False False False False]] dtype bool assert_array_equal extractor.descriptors expected
def set_opt_out flag if flag and not is_opt_out PersistentCacheEntry.objects.create data True **OPT_OUT_KWARGS return Trueelse PersistentCacheEntry.objects.filter **OPT_OUT_KWARGS .delete return False
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def callback_method pass
def truncate_millisecond dt measure d datetime dt.year dt.month dt.day tzinfo dt.tzinfo seconds total_seconds dt - d * 1000 // measure * measure / 1000.0 + 1e-07 return dt.utcfromtimestamp seconds + utctotimestamp d
def PermissionWithGetter Base getter class Perm Base def get_object self request view obj if callable getter return getter request view obj return operator.attrgetter getter obj def has_object_permission self request view obj obj self.get_object request view obj return super Perm self .has_object_permission request view obj return Perm
def list_renderers *args renderers_ salt.loader.render __opts__ [] renderers set if not args for rend in six.iterkeys renderers_ renderers.add rend return sorted renderers for module in args for rend in fnmatch.filter renderers_ module renderers.add rend return sorted renderers
def translateKey key return _ keyToXML key
def _get_securitygroupname_id securitygroupname_list securitygroupid_set set if not isinstance securitygroupname_list list securitygroupname_list [securitygroupname_list]params {'Action' 'DescribeSecurityGroups'}for sg in aws.query params location get_location provider get_provider opts __opts__ sigver '4' if sg['groupName'] in securitygroupname_list log.debug 'AWSSecurityGroupIDof{0}is{1}'.format sg['groupName'] sg['groupId'] securitygroupid_set.add sg['groupId'] return list securitygroupid_set
@commands u'getchanneltz' u'getctz' @example u'.getctz[channel]' def get_channel_tz bot trigger if not pytz bot.reply u"Sorry Idon'thavetimezonesupportinstalled." else channel trigger.group 2 if not channel channel trigger.senderchannel channel.strip timezone bot.db.get_channel_value channel u'timezone' if timezone bot.say u"%s'stimezone %s" % channel timezone else bot.say u'%shasnopreferredtimezone' % channel
@disabled 'http //ironpython.codeplex.com/WorkItem/View.aspx?WorkItemId 25860' def test_system_diagnostics_contracts class KNew object def m1 self p0 Contract.Requires True k KNew k.m1 0
def generate_adapter adapter name 'url_for' map_name 'url_map' values {u'server_name' dumps adapter.server_name u'script_name' dumps adapter.script_name u'subdomain' dumps adapter.subdomain u'url_scheme' dumps adapter.url_scheme u'name' name u'map_name' map_name}return u'var% name s % map_name s \n% server_name s \n% script_name s \n% subdomain s \n% url_scheme s\n ;' % values
def list_sizes provider 'all' client _get_client sizes client.list_sizes provider return sizes
def _base_and_stride freqstr groups opattern.match freqstr if not groups raise ValueError 'Couldnotevaluate%s' % freqstr stride groups.group 1 if len stride stride int stride else stride 1base groups.group 2 return base stride
def convert_IntegerProperty model prop kwargs return get_IntegerField kwargs
def getGAEObjects context return context.extra.setdefault 'gae_objects' GAEReferenceCollection
def startDebugMode Failure.__init__ _debuginit
@given u'afilenamed"{filename}"andencoding "{encoding}"with' def step_a_file_named_filename_and_encoding_with context filename encoding __encoding_is_valid Trueassert context.text is not None 'ENSURE multilinetextisprovided.'assert not os.path.isabs filename assert __encoding_is_validcommand_util.ensure_workdir_exists context filename2 os.path.join context.workdir filename pathutil.create_textfile_with_contents filename2 context.text encoding
def check_indices indices if not isinstance indices tuple or len indices ! 2 raise ValueError 'indicesmustbeatupleoflength2' if len indices[0] ! len indices[1] raise ValueError 'Indexarraysindices[0]andindices[1]musthavethesamelength' return indices
def authtypes **kwargs for name in _auth_names if name not in kwargs kwargs[name] Falsereturn AuthTypes **kwargs
def site_config_dirs appname if WINDOWS path os.path.normpath _get_win_folder 'CSIDL_COMMON_APPDATA' pathlist [os.path.join path appname ]elif sys.platform 'darwin' pathlist [os.path.join '/Library/ApplicationSupport' appname ]else xdg_config_dirs os.getenv 'XDG_CONFIG_DIRS' '/etc/xdg' if xdg_config_dirs pathlist [os.path.join expanduser x appname for x in xdg_config_dirs.split os.pathsep ]else pathlist []pathlist.append '/etc' return pathlist
def add_course course_id enrollment_start None enrollment_end None invite_only False course_modes None course_info {'course_id' course_id 'enrollment_end' enrollment_end 'course_modes' [] 'enrollment_start' enrollment_start 'invite_only' invite_only}if not course_modes course_info['course_modes'].append _DEFAULT_FAKE_MODE else for mode in course_modes new_mode copy.deepcopy _DEFAULT_FAKE_MODE new_mode['slug'] modecourse_info['course_modes'].append new_mode _COURSES.append course_info
def test_read_normal_names table '\n#comment withblanklineabove \n \nCol1Col2\n \n1.2"hello"\n2.4\'sworlds\n \n'reader ascii.get_reader Reader ascii.RST names 'name1' 'name2' dat reader.read table assert_equal dat.colnames ['name1' 'name2'] assert_almost_equal dat[1][0] 2.4
def match document topic None result_key None result_relative_url '/_ah/prospective_search' result_task_queue 'default' result_batch_size DEFAULT_RESULT_BATCH_SIZE result_return_document True from google.appengine.ext import dbrequest prospective_search_pb.MatchRequest if isinstance document db.Model topic _get_document_topic document topic doc_pb db.model_to_protobuf document if result_return_document request.set_result_python_document_class _doc_class.MODEL elif isinstance document datastore.Entity topic _get_document_topic document topic doc_pb document.ToPb if result_return_document request.set_result_python_document_class _doc_class.ENTITY else raise DocumentTypeError request.set_topic topic request.mutable_document .CopyFrom doc_pb if result_key request.set_result_key result_key request.set_result_relative_url result_relative_url request.set_result_task_queue result_task_queue request.set_result_batch_size result_batch_size response prospective_search_pb.MatchResponse _make_sync_call 'matcher' 'Match' request response
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _dtype_to_recformat dtype if not isinstance dtype np.dtype dtype np.dtype dtype kind dtype.base.kindif kind in 'U' 'S' recformat kind 'a'else itemsize dtype.base.itemsizerecformat kind + str itemsize return recformat kind dtype
def add_enabled_units units context _UnitContext get_current_unit_registry get_current_unit_registry .add_enabled_units units return context
def run_pip initial_args status_code pip.main initial_args logger.consumers []if status_code raise PipException status_code
def maximals A le lambda x y x < y r []for x in A for a in A if le x a and not le a x breakelse for a in r if le x a breakelse r.append x return r
def get_path_of_temp_url url return '{}/static/{}'.format app.config['BASE_DIR'] url[len '/serve_static/' ]
def inflate b64string decoded_data base64.b64decode b64string return zlib.decompress decoded_data -15
def _naive_eval_2 x t c k n len t - k + 1 assert n > k + 1 assert len c > n assert t[k] < x < t[n] return sum c[i] * _naive_B x k i t for i in range n
def init_log debug False syslog False logthreshold None logfile None logformat LOG_FORMAT logdateformat LOG_DATE_FORMAT fmt None rotation_parameters None handler None logger logging.getLogger if handler is None handler get_handler debug syslog logfile rotation_parameters logger.handlers [handler]logthreshold get_threshold debug logthreshold logger.setLevel logthreshold if fmt is None if debug fmt get_formatter logformat logformat logdateformat logdateformat else fmt logging.Formatter logformat logdateformat handler.setFormatter fmt return handler
def cleanup_directory tempdir skip_cleanup 'GALAXY_TEST_NO_CLEANUP' in os.environ or 'TOOL_SHED_TEST_NO_CLEANUP' in os.environ if skip_cleanup log.info 'GALAXY_TEST_NO_CLEANUPison.Temporaryfilesin%s' % tempdir returntry if os.path.exists tempdir and skip_cleanup shutil.rmtree tempdir except Exception pass
def simplify_class_decorator class_decorator @wraps class_decorator def outer fn None *decorator_args **decorator_kwargs def actual_decorator fn instance class_decorator fn *decorator_args **decorator_kwargs _wrapped_view instance.__call__ return _wrapped_viewif fn is not None wrapped_view actual_decorator fn else wrapped_view actual_decoratorreturn wrapped_viewreturn outer
def get_node_init_process_name runner node parser ProcessNameParser d runner.run node _GET_INIT_PROCESS_NAME_COMMAND handle_stdout parser.lineReceived d.addCallback lambda _ignored parser.result return d
def _get_first_child_data node return node.childNodes[0].data
def check_series_params_or_404 group start end format if group not in SERIES_GROUPS or format not in SERIES_FORMATS raise http.Http404return get_daterange_or_404 start end
def hexencode value return utf8encode value .encode 'hex'
def arma_acovf ar ma nobs 10 if np.abs np.sum ar - 1 > 0.9 nobs_ir max 1000 2 * nobs else nobs_ir max 100 2 * nobs ir arma_impulse_response ar ma nobs nobs_ir while ir[ -1 ] > 5 * 1e-05 nobs_ir * 10ir arma_impulse_response ar ma nobs nobs_ir if nobs_ir > 50000 and nobs < 1001 acovf np.array [np.dot ir[ nobs - t ] ir[t nobs] for t in range nobs ] else acovf np.correlate ir ir 'full' [ len ir - 1 ]return acovf[ nobs]
def libvlc_vlm_del_media p_instance psz_name f _Cfunctions.get 'libvlc_vlm_del_media' None or _Cfunction 'libvlc_vlm_del_media' 1 1 None ctypes.c_int Instance ctypes.c_char_p return f p_instance psz_name
def test_no_data_with_empty_serie_interpolation Chart chart Chart interpolate 'cubic' chart.add 'Serie' [] q chart.render_pyquery assert q '.text-overlaytext' .text 'Nodata'
def clear_review apps schema_editor DocumentSpamAttempt apps.get_model u'wiki' u'DocumentSpamAttempt' to_clear DocumentSpamAttempt.objects.filter review REVIEW_UNAVAILABLE to_clear.update review NEEDS_REVIEW
@jit nopython True def sa_indices num_states num_actions L num_states * num_actions dtype np.int_s_indices np.empty L dtype dtype a_indices np.empty L dtype dtype i 0for s in range num_states for a in range num_actions s_indices[i] sa_indices[i] ai + 1return s_indices a_indices
def get_client_id _scope _maybe_call_get_oauth_user _scope return _get_client_id_from_environ
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
def fourier_cos_seq func limits n from sympy.integrals import integrate x L limits[0] limits[2] - limits[1] cos_term cos 2 * n * pi * x / L formula 2 * cos_term * integrate func * cos_term limits / L a0 formula.subs n S.Zero / 2 return a0 SeqFormula 2 * cos_term * integrate func * cos_term limits / L n 1 oo
def contingency_matrix labels_true labels_pred eps None sparse False if eps is not None and sparse raise ValueError "Cannotset'eps'whensparse True" classes class_idx np.unique labels_true return_inverse True clusters cluster_idx np.unique labels_pred return_inverse True n_classes classes.shape[0]n_clusters clusters.shape[0]contingency sp.coo_matrix np.ones class_idx.shape[0] class_idx cluster_idx shape n_classes n_clusters dtype np.int if sparse contingency contingency.tocsr contingency.sum_duplicates else contingency contingency.toarray if eps is not None contingency contingency + eps return contingency
def dictAsString d s '{'for key val in sorted d.items s + '%s %s ' % key val s s.rstrip ' ' s + '}'return s
def find_lines code strs linenos find_lines_from_code code strs for c in code.co_consts if isinstance c types.CodeType linenos.update find_lines c strs return linenos
def _maybe_real A B tol None if np.isrealobj A and np.iscomplexobj B if tol is None tol {0 feps * 1000.0 1 eps * 1000000.0 }[_array_precision[B.dtype.char]]if np.allclose B.imag 0.0 atol tol B B.realreturn B
def GetDefaultToken token if token is None token default_tokenif not isinstance token access_control.ACLToken raise access_control.UnauthorizedAccess 'Tokenisnotproperlyspecified.Itshouldbeaninstanceofgrr.lib.access_control.ACLToken ' return token
def split_args args args_dict {}for arg in args split_arg arg.split ' ' 1 if len split_arg > 1 value split_arg[1]else value Trueargs_dict[split_arg[0]] valuereturn args_dict
def get_db_master_ip return file_io.read constants.MASTERS_FILE_LOC .rstrip
def _api_test_pushover name output kwargs logging.info 'SendingPushovernotification' res sabnzbd.notifier.send_pushover 'SABnzbd' T 'TestNotification' 'other' force True test kwargs return report output error res
def get_unix_group group None if isinstance group six.string_types try group_info grp.getgrnam group except KeyError try i int group except ValueError raise KeyError "groupname'%s'notfound" % group try group_info grp.getgrgid i except KeyError raise KeyError 'groupid%dnotfound' % i elif isinstance group int try group_info grp.getgrgid group except KeyError raise KeyError 'groupid%dnotfound' % group elif group is None group_info grp.getgrgid os.getegid else group_cls_name reflection.get_class_name group fully_qualified False raise TypeError 'groupmustbestring intorNone;not%s %r ' % group_cls_name group return group_info.gr_gid group_info.gr_name
def image_info call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Theimage_infofunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None image_id kwargs.get 'image_id' None if image_id if name log.warning "Boththe'image_id'and'name'argumentswereprovided.'image_id'willtakeprecedence." elif name image_id get_image_id kwargs {'name' name} else raise SaltCloudSystemExit "Theimage_infofunctionrequireseithera'nameoran'image_id'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] info {}response server.one.image.info auth int image_id [1]tree _get_xml response info[tree.find 'NAME' .text] _xml_to_dict tree return info
def _extract_from_egg toc new_toc []for item in toc modname pth typ itemif not os.path.isfile pth pth check_extract_from_egg pth [0][0]new_toc.append modname pth typ return new_toc
def minimize *rules **kwargs objective kwargs.get 'objective' identity def minrule expr return min [rule expr for rule in rules] key objective return minrule
def install_gobject_iteration from kivy.clock import Clocktry from gi.repository import GObject as gobjectexcept ImportError import gobjectif hasattr gobject '_gobject_already_installed' returngobject._gobject_already_installed Trueloop gobject.MainLoop gobject.threads_init context loop.get_context def _gobject_iteration *largs loop 0while context.pending and loop < 10 context.iteration False loop + 1Clock.schedule_interval _gobject_iteration 0
@frappe.whitelist def send_now name auto_email_report frappe.get_doc u'AutoEmailReport' name auto_email_report.check_permission auto_email_report.send
def get_tmux_configs version for fname matcher priority file_version in list_all_tmux_configs if matcher file_version version yield fname priority + file_version.minor * 10 + file_version.major * 10000
def getDivmod x y return divmod x y
def additions_umount mount_point ret __salt__['mount.umount'] mount_point if ret os.rmdir mount_point return ret
def spectral_projection u eigenpairs coeff []evect eigenpairs[1]for ev in evect c sum [ evv * uv for evv uv in zip ev u ] coeff.append c return coeff
def dup_pow f n K if not n return [K.one]if n < 0 raise ValueError "can'traisepolynomialtoanegativepower" if n 1 or not f or f [K.one] return fg [K.one]while True n m n // 2 n if m % 2 g dup_mul g f K if not n breakf dup_sqr f K return g
def update_dashboard_stats_log user_id model user_models.UserStatsModel.get_or_create user_id if model.schema_version ! feconf.CURRENT_DASHBOARD_STATS_SCHEMA_VERSION _migrate_dashboard_stats_to_latest_schema model weekly_dashboard_stats {get_current_date_as_string {'num_ratings' model.num_ratings or 0 'average_ratings' model.average_ratings 'total_plays' model.total_plays or 0 }}model.weekly_creator_stats_list.append weekly_dashboard_stats model.put
def gf_sqr f p K df gf_degree f dh 2 * df h [0] * dh + 1 for i in range 0 dh + 1 coeff K.zerojmin max 0 i - df jmax min i df n jmax - jmin + 1 jmax jmin + n // 2 - 1 for j in range jmin jmax + 1 coeff + f[j] * f[ i - j ] coeff + coeffif n & 1 elem f[ jmax + 1 ]coeff + elem ** 2 h[i] coeff % p return gf_strip h
def parse_parameters lines results num_params parameters {}parameters parse_parameter_list lines parameters num_params parameters parse_kappas lines parameters parameters parse_rates lines parameters parameters parse_freqs lines parameters results['parameters'] parametersreturn results
def dup_abs f K return [K.abs coeff for coeff in f]
def test_download_exit_status_code_when_blank_requirements_file script script.scratch_path.join 'blank.txt' .write '\n' script.pip 'download' '-r' 'blank.txt'
def geometric_mean_prediction forward_props presoftmax []for out in forward_props assert isinstance out.owner.op T.nnet.Softmax assert len out.owner.inputs 1 presoftmax.append out.owner.inputs[0] average reduce operator.add presoftmax / float len presoftmax return T.nnet.softmax average
def strip_rst docs for func docstring in six.iteritems docs if not docstring continuedocstring_new re.sub '*..code-block \\S+\\n{1 2}' '' docstring docstring_new re.sub '..note ' 'Note ' docstring_new docstring_new re.sub '..warning ' 'Warning ' docstring_new docstring_new re.sub '..versionadded ' 'Newinversion' docstring_new docstring_new re.sub '..versionchanged ' 'Changedinversion' docstring_new if docstring ! docstring_new docs[func] docstring_newreturn docs
def b64decode data if isinstance data six.string_types try data data.encode 'ascii' except UnicodeEncodeError raise ValueError 'unicodeargumentshouldcontainonlyASCIIcharacters' elif not isinstance data six.binary_type raise TypeError 'argumentshouldbeastrorunicode' return base64.urlsafe_b64decode data + ' ' * 4 - len data % 4
def email_split_and_format text if not text return []return [formataddr addr[0] addr[1] for addr in getaddresses [text] if addr[1] if '@' in addr[1] ]
def memoize_default default NO_DEFAULT evaluator_is_first_arg False second_arg_is_evaluator False def func function def wrapper obj *args **kwargs if evaluator_is_first_arg cache obj.memoize_cacheelif second_arg_is_evaluator cache args[0].memoize_cacheelse cache obj._evaluator.memoize_cachetry memo cache[function]except KeyError memo {}cache[function] memokey obj args frozenset kwargs.items if key in memo return memo[key]else if default is not NO_DEFAULT memo[key] defaultrv function obj *args **kwargs if inspect.isgenerator rv rv list rv memo[key] rvreturn rvreturn wrapperreturn func
@login_required@require_http_methods ['GET'] def learner_profile request username try return render_to_response 'student_profile/learner_profile.html' learner_profile_context request username request.user.is_staff except UserNotAuthorized UserNotFound ObjectDoesNotExist raise Http404
def simplex_projection v b 1 v np.asarray v p len v v v > 0 * v u np.sort v [ -1 ]sv np.cumsum u rho np.where u > sv - b / np.arange 1 p + 1 [0][ -1 ]theta np.max [0 sv[rho] - b / rho + 1 ] w v - theta w[ w < 0 ] 0return w
def init_rtmbot rtmbot RtmBot {'SLACK_TOKEN' 'test-12345' 'BASE_PATH' '/tmp/' 'LOGFILE' '/tmp/rtmbot.log' 'DEBUG' True} return rtmbot
def _get_installed_entrypoint subproject if subproject not in migration_entrypoints alembic_util.err _ 'Package%snotinstalled' % subproject return migration_entrypoints[subproject]
def assign_textbook_id textbook used_ids tid Location.clean textbook['tab_title'] if not tid[0].isdigit tid random.choice string.digits + tid while tid in used_ids tid tid + random.choice string.ascii_lowercase return tid
@step 'Iresetthedatabase' def reset_the_db _step reset_data None
def resolve_encoding alias _aliases _ENCODING_ALIASES return _aliases.get alias.lower alias
def recursive_rowfunc t stop funcs []while not t.isidentical stop funcs.append rowfunc t t child t return compose *funcs
def _filter_list input_list search_key search_value output_list list for dictionary in input_list if dictionary.get search_key search_value output_list.append dictionary return output_list
def debug host 'localhost' port 6000 authkey 'secretpassword' init host port authkey qdb.do_debug
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def department mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepif not auth.s3_has_role ADMIN s3.filter auth.filter_by_root_org s3db.hrm_department output s3_rest_controller return output
def moment a moment 1 axis 0 a axis _chk_asarray a axis if moment 1 shape list a.shape del shape[axis]if shape return np.zeros shape dtype float else return np.float64 0.0 else n_list [moment]current_n momentwhile current_n > 2 if current_n % 2 current_n current_n - 1 / 2 else current_n / 2n_list.append current_n a_zero_mean a - ma.expand_dims a.mean axis axis if n_list[ -1 ] 1 s a_zero_mean.copy else s a_zero_mean ** 2 for n in n_list[ -2 -1 ] s s ** 2 if n % 2 s * a_zero_meanreturn s.mean axis
def miso_lfilter ar ma x useic False ma np.asarray ma ar np.asarray ar inp signal.correlate x ma[ -1 ] [ x.shape[1] + 1 // 2 ]nobs x.shape[0]if useic return signal.lfilter [1] ar inp zi signal.lfiltic np.array [1.0 0.0] ar useic [0][ nobs] inp[ nobs] else return signal.lfilter [1] ar inp [ nobs] inp[ nobs]
def chunk_indexing indexer chunk_size chunks list indexer.get_indexable .values_list 'id' flat True return chunked chunks chunk_size len chunks
def has_matplotlib version '1.2' try import matplotlibexcept Exception has_mpl Falseelse if LooseVersion matplotlib.__version__ > LooseVersion version has_mpl Trueelse has_mpl Falsereturn has_mpl
def with_metaclass meta *bases class metaclass meta __call__ type.__call____init__ type.__init__def __new__ cls name this_bases d if this_bases is None return type.__new__ cls name d return meta name bases d return metaclass 'DummyMetaClass' None {}
def _validate_namespace name if name.find '.' 1 len name - 1 < 0 raise errors.InvalidConfiguration "InvalidMongoDBnamespace'%s'!" % name
def _get_opts localconfig None opts copy.deepcopy __opts__ if localconfig opts salt.config.minion_config localconfig defaults opts return opts
def some_calculation x y z 1 return x * y / z
def ndiff a b linejunk None charjunk IS_CHARACTER_JUNK return Differ linejunk charjunk .compare a b
def make_response data headers url code msg mime_headers make_headers headers r closeable_response StringIO data mime_headers url code msg return response_seek_wrapper r
def formatTime when timeFormat timeFormatRFC3339 default u'-' if timeFormat is None or when is None return defaultelse tz FixedOffsetTimeZone.fromLocalTimeStamp when datetime DateTime.fromtimestamp when tz return unicode datetime.strftime timeFormat
def _GetActualName name if _allowCapitalizedNames name UncapitalizeVmodlName name for defMap in _dataDefMap _managedDefMap _enumDefMap dic defMap.get name if dic return dic[0]return None
def handler req profname '%s.%.3f.prof' % req.uri.strip '/' .replace '/' '.' time.time profname os.path.join PROFILE_DATA_DIR profname prof hotshot.Profile profname return prof.runcall ModPythonHandler req
def build_hover_tooltips hover_spec None chart_cols None if isinstance hover_spec bool tooltips [ col '@' + col for col in chart_cols]elif isinstance hover_spec[0] tuple tooltips hover_specelse tooltips [ col '@' + col for col in hover_spec]return tooltips
def test_array test_data ds ChartDataSource.from_data *test_data.array_data assert len ds.columns 2 assert len ds.index 4
def MkFileBox w msg Tix.Message w relief Tix.FLAT width 240 anchor Tix.N text 'TheTixFileSelectBoxisaMotif-styleboxwithvariousenhancements.Forexample youcanadjustthesizeofthetwolistboxesandyourpastselectionsarerecorded.' box Tix.FileSelectBox w msg.pack side Tix.TOP expand 1 fill Tix.BOTH padx 3 pady 3 box.pack side Tix.TOP fill Tix.X padx 3 pady 3
def setBasicLoggerWARN setLoggerClass BasicLogger BasicLogger.setLevel WARN
def test_make_imbalance_single_class y_ np.zeros X.shape[0] ratio 0.5assert_raises ValueError make_imbalance X y_ ratio
@set_databasedef get_or_create item **kwargs if item return Item.create_or_get **parse_model_data item
def indentby parser token args token.split_contents largs len args if largs not in 2 4 raise template.TemplateSyntaxError '%rtagrequires1or3arguments' indent_level args[1]if_statement Noneif largs 4 if_statement args[3]nodelist parser.parse 'endindentby' parser.delete_first_token return IndentByNode nodelist indent_level if_statement
def user_activity_list_html context data_dict activity_stream user_activity_list context data_dict offset int data_dict.get 'offset' 0 extra_vars {'controller' 'user' 'action' 'activity' 'id' data_dict['id'] 'offset' offset}return activity_streams.activity_list_to_html context activity_stream extra_vars
def get_module_root path while not module_manifest path new_path os.path.abspath opj path os.pardir if path new_path return Nonepath new_pathreturn path
def _truncate words cutlength stems {}for word in words stem word[ cutlength]try stems[stem].update [word] except KeyError stems[stem] set [word] return stems
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def run _task
def set_x layout cmd 'setxkbmap{0}'.format layout __salt__['cmd.run'] cmd return layout
def getFile parent title cb filter '*.*' dir None key None assert not dir or not key if not dir dirkey key + 'Directory' dir aqt.mw.pm.profile.get dirkey '' else dirkey Noned QFileDialog parent d.setFileMode QFileDialog.ExistingFile if os.path.exists dir d.setDirectory dir d.setWindowTitle title d.setNameFilter filter ret []def accept file str list d.selectedFiles [0] if dirkey dir os.path.dirname file aqt.mw.pm.profile[dirkey] dirif cb cb file ret.append file d.accepted.connect accept d.exec_ return ret and ret[0]
def obfuscate_whisper whisper level 0.0 level min max 0.0 level 1.0 olevel int 13.0 * level return _RE_WHISPER_OBSCURE[olevel].sub '...' if olevel 13.0 else '-' whisper
def find_xem_numbering indexer_id indexer season episode if indexer_id is None or season is None or episode is None return season episode indexer_id int indexer_id indexer int indexer xem_refresh indexer_id indexer main_db_con db.DBConnection rows main_db_con.select 'SELECTscene_season scene_episodeFROMtv_episodesWHEREindexer ?andshowid ?andseason ?andepisode ?and scene_seasonorscene_episode ! 0' [indexer indexer_id season episode] if rows return int rows[0]['scene_season'] int rows[0]['scene_episode']
def send_command remote_conn cmd cmd cmd.rstrip remote_conn.write cmd + '\n' time.sleep 1 return remote_conn.read_very_eager
def object_download_fileobj self Fileobj ExtraArgs None Callback None Config None return self.meta.client.download_fileobj Bucket self.bucket_name Key self.key Fileobj Fileobj ExtraArgs ExtraArgs Callback Callback Config Config
def _variance values return _mean [ v ** 2 for v in values] - _mean values ** 2
def confusion_matrix rater_a rater_b min_rating None max_rating None assert len rater_a len rater_b if min_rating is None min_rating min rater_a + rater_b if max_rating is None max_rating max rater_a + rater_b num_ratings int max_rating - min_rating + 1 conf_mat [[0 for i in range num_ratings ] for j in range num_ratings ]for a b in zip rater_a rater_b conf_mat[ a - min_rating ][ b - min_rating ] + 1return conf_mat
def course_specific_login request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id course modulestore .get_course course_key if not course return redirect_with_get 'signin_user' request.GET if settings.FEATURES.get 'AUTH_USE_SHIB' and course.enrollment_domain and course.enrollment_domain.startswith SHIBBOLETH_DOMAIN_PREFIX return redirect_with_get 'shib-login' request.GET return redirect_with_get 'signin_user' request.GET
def mvn_loglike_sum x sigma nobs len x nobs2 nobs / 2.0 SSR x ** 2 .sum llf - np.log SSR * nobs2 llf - 1 + np.log np.pi / nobs2 * nobs2 if np.any sigma and sigma.ndim 2 llf - 0.5 * np.log np.linalg.det sigma return llf
def test_scenario_outline2_ptbr_from_string ptbr Language 'pt-br' scenario Scenario.from_string SCENARIO_OUTLINE2 language ptbr assert_equals scenario.name 'Cadastrarumalunonobancodedados' assert_equals scenario.outlines [{'nome' u'Gabriel' u'idade' '99'} {'nome' u'Jo\xe3o' u'idade' '100'}]
def convUp images filters targets numModulesX paddingStart moduleStride numImgColors numGroups 1 numImages images.shape[0]numFilters filters.shape[0]assert targets.shape numImages numFilters * numModulesX * numModulesX '%s%d%d-%d-%d' % targets.shape.__str__ numImages numFilters numModulesX numModulesX _ConvNet.convUp images.p_mat filters.p_mat targets.p_mat numModulesX - paddingStart moduleStride numImgColors numGroups
def build_class name basenames doc None node Class name doc for base in basenames basenode Name basenode.name basenode.bases.append basenode basenode.parent nodereturn node
def api_manage *args **kwargs ctx context.RequestContext fake.USER_ID fake.PROJECT_ID True vol {'status' 'creating' 'display_name' 'fake_name' 'availability_zone' 'nova' 'tenant_id' fake.PROJECT_ID 'id' fake.VOLUME_ID 'volume_type' None 'snapshot_id' None 'user_id' fake.USER_ID 'size' 0 'attach_status' fields.VolumeAttachStatus.DETACHED 'volume_type_id' None}return fake_volume.fake_volume_obj ctx **vol
def askopenfilenames **options options['multiple'] 1return Open **options .show
def symptom_usability_of_Fernet_key_repository fernet_utils utils.FernetUtils CONF.fernet_tokens.key_repository CONF.fernet_tokens.max_active_keys return 'fernet' in CONF.token.provider and not fernet_utils.validate_key_repository
def drop_db name **client_args if not db_exists name **client_args log.info "DB'{0}'doesnotexist".format name return Falseclient _client **client_args client.drop_database name return True
def get_key_func key_func if key_func is not None if callable key_func return key_funcelse key_func_module_path key_func_name key_func.rsplit u'.' 1 key_func_module import_module key_func_module_path return getattr key_func_module key_func_name return default_key_func
@macro 'test' def tmac *tree return HyList tree
def read_ssh_data remote_conn delay 1 time.sleep delay return remote_conn.recv 65535
def _query_super func_name def wrapped self *args **kwargs return getattr self.clean func_name *args **kwargs return wrapped
def test_dpll A B C symbols 'A B C' assert dpll [ A | B ] [A B] {A True B True} {A True B True}
def test_positive_integer try positive_integer '-1' assert Falseexcept Exception pass
def _verify leniency numobj candidate if leniency Leniency.POSSIBLE return is_possible_number numobj elif leniency Leniency.VALID if not is_valid_number numobj or not _contains_only_valid_x_chars numobj candidate return Falsereturn _is_national_prefix_present_if_required numobj elif leniency Leniency.STRICT_GROUPING return _verify_strict_grouping numobj candidate elif leniency Leniency.EXACT_GROUPING return _verify_exact_grouping numobj candidate else raise Exception 'Error unsupportedLeniencyvalue%s' % leniency
def write_to_ports_conf module temp tempfile.NamedTemporaryFile try temp.write '#ManagedByAnsible\n' for k in sorted module.ports_conf_hash.keys port_setting module.ports_conf_hash[k]_str '%s %s\n' % k port_setting temp.write _str temp.seek 0 shutil.copyfile temp.name PORTS_CONF except IOError error_msg get_exception module.fail_json msg 'Failedtowriteto%s %s' % PORTS_CONF error_msg finally temp.close
def continuous_query_exists database name **client_args if get_continuous_query database name **client_args return Truereturn False
def mailchimp_get_endpoint **kwargs return {} http.OK
def ellipse width height dtype np.uint8 selem np.zeros 2 * height + 1 2 * width + 1 dtype dtype rows cols draw.ellipse height width height + 1 width + 1 selem[ rows cols ] 1return selem
def rate_limit_user request user domain ratelimited time is_ratelimited user domain request._ratelimit_applied_limits Truerequest._ratelimit_secs_to_freedom timerequest._ratelimit_over_limit ratelimitedif ratelimited statsd.incr 'ratelimiter.limited.%s.%s' % type user user.id raise RateLimited incr_ratelimit user domain calls_remaining time_reset api_calls_left user domain request._ratelimit_remaining calls_remainingrequest._ratelimit_secs_to_freedom time_reset
def get_metadata_for_threads course_id threads user user_info def infogetter thread return get_annotated_content_infos course_id thread user user_info metadata reduce merge_dict map infogetter threads {} return metadata
def _get_bufsize_linux iface ret {'result' False}cmd '/sbin/ethtool-g{0}'.format iface out __salt__['cmd.run'] cmd pat re.compile '^ .+ \\s+ \\d+ $' suffix 'max-'for line in out.splitlines res pat.match line if res ret[ res.group 1 .lower .replace '' '-' + suffix ] int res.group 2 ret['result'] Trueelif line.endswith 'maximums ' suffix '-max'elif line.endswith 'settings ' suffix ''if not ret['result'] parts out.split if parts[0].endswith 'sh ' out ''.join parts[1 ] ret['comment'] outreturn ret
def montage2d arr_in fill 'mean' rescale_intensity False grid_shape None assert arr_in.ndim 3 n_images height width arr_in.shapearr_in arr_in.copy if rescale_intensity for i in range n_images arr_in[i] exposure.rescale_intensity arr_in[i] if grid_shape alpha_y alpha_x grid_shapeelse alpha_y alpha_x int np.ceil np.sqrt n_images if fill 'mean' fill arr_in.mean n_missing int alpha_y * alpha_x - n_images missing np.ones n_missing height width dtype arr_in.dtype * fill arr_out np.vstack arr_in missing arr_out arr_out.reshape alpha_y alpha_x height width arr_out arr_out.swapaxes 1 2 arr_out arr_out.reshape alpha_y * height alpha_x * width return arr_out
def command_mkdir args errors 0for directory in args.dirs if os.path.exists directory if not os.path.isdir directory sys.stdout.write 'mkdir %s\n' % directory sys.stdout.write 'ERROR Existsalready butasfile...\n' errors + 1else assert not os.path.isdir directory sys.stdout.write 'mkdir %s\n' % directory os.makedirs directory return errors
def migPipe deme k pipein pipeout selection replacement None emigrants selection deme k if replacement is None immigrants emigrantselse immigrants replacement deme k pipeout.send emigrants buf pipein.recv for place immigrant in zip immigrants buf indx deme.index place deme[indx] immigrant
def process_class c_name obj c_sk c_md c_mdt c_idt c_has_doctest mod_path sph sphinx True if c_name.startswith '_' c_sk.append c_name return False False None c Falsec_dt Falsetry source line_no inspect.getsourcelines obj except IOError return False False None c Truefull_name 'LINE%d %s' % line_no c_name if not obj.__doc__ c_md.append full_name elif not '>>>' in obj.__doc__ c_mdt.append full_name elif _is_indirect c_name obj.__doc__ c_idt.append full_name else c_dt Truec_has_doctest.append full_name in_sphinx Falseif sphinx in_sphinx find_sphinx c_name mod_path if not in_sphinx sph.append full_name return c_dt c source
def is_sys_or_user_meta server_type key return is_user_meta server_type key or is_sys_meta server_type key
@pytest.fixture params sorted MIXIN_COLS def mixin_cols request cols OrderedDict mixin_cols deepcopy MIXIN_COLS cols['i'] table.Column [0 1 2 3] name 'i' cols['a'] table.Column ['a' 'b' 'b' 'c'] name 'a' cols['b'] table.Column ['b' 'c' 'a' 'd'] name 'b' cols['m'] mixin_cols[request.param]return cols
def code_assist project source_code offset resource None templates None maxfixes 1 later_locals True if templates is not None warnings.warn 'Codeassistnolongersupportstemplates' DeprecationWarning stacklevel 2 assist _PythonCodeAssist project source_code offset resource resource maxfixes maxfixes later_locals later_locals return assist
def get_game_high_scores token user_id chat_id None message_id None inline_message_id None method_url 'getGameHighScores'payload {'user_id' user_id}if chat_id payload['chat_id'] chat_idif message_id payload['message_id'] message_idif inline_message_id payload['inline_message_id'] inline_message_idreturn _make_request token method_url params payload
def _convert_other other raiseit False allow_float False if isinstance other Decimal return otherif isinstance other int return Decimal other if allow_float and isinstance other float return Decimal.from_float other if raiseit raise TypeError 'Unabletoconvert%stoDecimal' % other return NotImplemented
def instance_group_create context values policies None members None return IMPL.instance_group_create context values policies members
def get_mdict_item_or_list mdict key if hasattr mdict 'getlist' v mdict.getlist key if len v 1 value v[0]if value '' value Nonereturn valueelif len v 0 return Noneelse return tuple v return None
def annotate clip txt txt_color 'white' bg_color 0 0 255 txtclip TextClip txt fontsize 20 font 'Ubuntu-bold' color txt_color txtclip txtclip.on_color clip.w txtclip.h + 6 color 0 0 255 pos 6 'center' cvc CompositeVideoClip [clip txtclip.set_pos 0 'bottom' ] return cvc.set_duration clip.duration
def isCloseToLast paths point radius if len paths < 1 return FalselastPath paths[ -1 ]return abs lastPath[ -1 ] - point < radius
def gettempprefix return template
def _properties_from_dict d key_name 'key' fields []for key value in six.iteritems d if isinstance value dict fields.append {key_name key 'refValue' value['ref']} else fields.append {key_name key 'stringValue' value} return fields
@_FFI.callback u'Key ExternContext* Value* ' def extern_key_for context_handle val c _FFI.from_handle context_handle return c.value_to_key val
def cholesky a lower False l u _cholesky a if lower return lelse return u
def verify_location_strategy conf None strategies _available_strategies if not conf conf CONF.location_strategyif conf not in strategies msg _ 'Invalidlocation_strategyoption % name s.Thevalidstrategyoption s is are % strategies s' % {'name' conf 'strategies' ' '.join strategies.keys } LOG.error msg raise RuntimeError msg
def int64_as_f64 builder val assert val.type Type.int 64 return builder.bitcast val Type.double
def read_ros_handshake_header sock b buff_size header_str Nonewhile not header_str d sock.recv buff_size if not d raise ROSHandshakeException 'connectionfromsenderterminatedbeforehandshakeheaderreceived.%sbyteswerereceived.Pleasechecksenderforadditionaldetails.' % b.tell b.write d btell b.tell if btell > 4 bval b.getvalue size struct.unpack '<I' bval[0 4] if btell - 4 > size header_str bvalleftovers bval[ size + 4 ]b.truncate len leftovers b.seek 0 b.write leftovers header_recvd Truereturn decode_ros_handshake_header bval
def test_logout dcos_api_session r dcos_api_session.get '/acs/api/v1/auth/logout' cookieheader r.headers['set-cookie']assert 'dcos-acs-auth-cookie ;' in cookieheader or 'dcos-acs-auth-cookie "";' in cookieheader assert 'expires' in cookieheader.lower
def get_primary_at source_code offset retry True obj ''left re.split '[^0-9a-zA-Z_.]' source_code[ offset] if left and left[ -1 ] obj left[ -1 ]right re.split '\\W' source_code[offset ] if right and right[0] obj + right[0]if obj and obj[0].isdigit obj ''if not obj and retry and offset and source_code[ offset - 1 ] in ' [.' return get_primary_at source_code offset - 1 retry False return obj
def default_data_selector connection return []
def xpath_lower_case arg return "translate %s 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 'abcdefghijklmnopqrstuvwxyz' " % arg
def get_http_data data get_stack_trace_data_real data['request'] {'cookies' VARS 'data' VARS 'env' VARS 'headers' VARS 'method' 'GET' 'query_string' '' 'url' 'http //localhost/'}return data
def merge_dicts d1 d2 result copy.deepcopy d1 for key value in six.iteritems d2 if isinstance value dict result[key] merge_dicts result[key] value elif key not in result or value is not None result[key] valuereturn result
def _compute_dir_contents n path show_hidden False url_append ''if show_hidden url_append '?hidden 1'if path ! '/' yield '..' '../' + url_append '' for sub in n display sub.namelink urllib.quote sub.name if stat.S_ISDIR sub.try_resolve .mode link + '/'if not show_hidden and len display > 1 and display.startswith '.' continuesize Noneif stat.S_ISDIR sub.mode display + '/'elif stat.S_ISLNK sub.mode display + '@'else size sub.size size opt.human_readable and format_filesize size or size yield display link + url_append size
def encode_basestring s _PY3 PY3 _q u '"' if _PY3 if isinstance s binary_type s s.decode 'utf-8' elif isinstance s str and HAS_UTF8.search s is not None s s.decode 'utf-8' def replace match return ESCAPE_DCT[match.group 0 ]return _q + ESCAPE.sub replace s + _q
def dict_from_cookiejar cj cookie_dict {}for cookie in cj cookie_dict[cookie.name] cookie.valuereturn cookie_dict
def Gompertz name b eta return rv name GompertzDistribution b eta
def init_console_logging formatter logging.Formatter '% asctime s[% name s]% levelname s % message s' ch ConsoleHandler ch.setFormatter formatter log.addHandler ch log.setLevel logging.INFO
def build_ipy_lexer python3 if python3 PyLexer Python3Lexername 'IPython3'aliases ['ipython3']doc 'IPython3Lexer'else PyLexer PythonLexername 'IPython'aliases ['ipython2' 'ipython']doc 'IPythonLexer'tokens PyLexer.tokens.copy tokens['root'] ipython_tokens + tokens['root'] attrs {'name' name 'aliases' aliases 'filenames' [] '__doc__' doc 'tokens' tokens}return type name PyLexer attrs
def _get_trans trans fro 'mri' to 'head' if isinstance trans string_types if not op.isfile trans raise IOError 'transfile"%s"notfound' % trans if op.splitext trans [1] in ['.fif' '.gz'] fro_to_t read_trans trans else t np.genfromtxt trans if t.ndim ! 2 or t.shape ! 4 4 raise RuntimeError 'File"%s"didnothave4x4entries' % trans fro_to_t Transform to fro t elif isinstance trans dict fro_to_t transtrans 'dict'elif trans is None fro_to_t Transform fro to trans 'identity'else raise ValueError 'transformtype%snotknown mustbestr dict orNone' % type trans fro_to_t _ensure_trans fro_to_t fro to return fro_to_t trans
def model_custom_form cf_data model tmp model.clone 'TempModel' cf json.loads cf_data for key in tmp if key in cf if cf[key]['require'] 1 tmp[key].required Trueelif cf[key]['require'] 0 tmp[key].required Falsereturn tmp
def run _task
def _get_dirs user_dir startup_dir try users os.listdir user_dir except WindowsError users []full_dirs []for user in users full_dir os.path.join user_dir user startup_dir if os.path.exists full_dir full_dirs.append full_dir return full_dirs
def test_seed_same skip_if_no_scipy rng np.random.RandomState [1 2 3] seed rng.randint 2147462579 dim 3mu rng.randn dim rank dimX rng.randn rank dim cov np.dot X.T X mnd1 MND sigma cov mu mu seed seed num_samples 5rd1 mnd1.random_design_matrix num_samples rd1 function [] rd1 mnd2 MND sigma cov mu mu seed seed rd2 mnd2.random_design_matrix num_samples rd2 function [] rd2 assert np.all rd1 rd2
def enable_microsites_pre_startup log if is_feature_enabled BACKEND.enable_microsites_pre_startup log
def asset s3db.asset_asset.item_id.comment S3PopupLink f 'item' label T 'CreateItem' title T 'Item' tooltip T "TypethenameofanexistingcatalogitemORClick'CreateItem'toaddanitemwhichisnotinthecatalog." return s3db.asset_controller
def get_shortcut context name return CONF.get 'shortcuts' '%s/%s' % context name
def url_prefix mat return '/' + mat.string[ mat.start ].strip '/'
def get_authenticated_user auth_provider username uid match models.DjangoStorage.user.get_social_auth provider auth_provider.backend_name uid uid if not match or match.user.username ! username raise User.DoesNotExistuser match.useruser.backend auth_provider.get_authentication_backend return user
def volume_types_get_by_name_or_id context volume_type_list return IMPL.volume_types_get_by_name_or_id context volume_type_list
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def _get_scodon_moves tmp_seq_blocks scodon_moves {'query' [] 'hit' []}for seq_type in scodon_moves scoords []for block in tmp_seq_blocks m_start re.search _RE_SCODON_START block[seq_type] m_end re.search _RE_SCODON_END block[seq_type] if m_start m_start len m_start.group 1 scoords.append m_start 0 else scoords.append 0 0 if m_end m_end len m_end.group 1 scoords.append 0 m_end else scoords.append 0 0 scodon_moves[seq_type] scoordsreturn scodon_moves
def _do_bistochastic_test scaled _do_scale_test scaled assert_almost_equal scaled.sum axis 0 .mean scaled.sum axis 1 .mean decimal 1
def stashedHTML2text text md def _html_sub m u'Substituterawhtmlwithplaintext.'try raw safe md.htmlStash.rawHtmlBlocks[int m.group 1 ]except IndexError TypeError return m.group 0 if md.safeMode and not safe return u''return re.sub u' <[^>]+> | &[\\#a-zA-Z0-9]+; ' u'' raw return HTML_PLACEHOLDER_RE.sub _html_sub text
def CurrentAuditLog now_sec rdfvalue.RDFDatetime.Now .AsSecondsFromEpoch rollover config_lib.CONFIG['Logging.aff4_audit_log_rollover']current_log now_sec // rollover * rollover return ROOT_URN.Add 'audit' .Add 'logs' .Add str current_log
def extract_mentions txt return re.findall u' ? [^\\w]|^ @ [\\w]* ' txt
def backoffPolicy initialDelay 1.0 maxDelay 60.0 factor 1.5 jitter _goodEnoughRandom def policy attempt return min initialDelay * factor ** attempt maxDelay + jitter return policy
def with_requires *requirements ws pkg_resources.WorkingSet try ws.require *requirements skip Falseexcept pkg_resources.VersionConflict skip Truemsg 'requires {}'.format ' '.join requirements return unittest.skipIf skip msg
def match_coordinates_sky matchcoord catalogcoord nthneighbor 1 storekdtree u'kdtree_sky' if catalogcoord.isscalar or len catalogcoord < 1 raise ValueError u'Thecatalogforcoordinatematchingcannotbeascalarorlength-0.' newmatch matchcoord.transform_to catalogcoord match_urepr newmatch.data.represent_as UnitSphericalRepresentation newmatch_u newmatch.realize_frame match_urepr cat_urepr catalogcoord.data.represent_as UnitSphericalRepresentation newcat_u catalogcoord.realize_frame cat_urepr storekdtree catalogcoord.cache.get storekdtree storekdtree idx sep2d sep3d match_coordinates_3d newmatch_u newcat_u nthneighbor storekdtree if not isinstance catalogcoord.data UnitSphericalRepresentation or isinstance newmatch.data UnitSphericalRepresentation sep3d catalogcoord[idx].separation_3d newmatch if isinstance storekdtree six.string_types catalogcoord.cache[storekdtree] newcat_u.cache[storekdtree]elif storekdtree is True catalogcoord.cache[u'kdtree'] newcat_u.cache[u'kdtree']return idx sep2d sep3d
def test_line_secondary line Line rng [8 12 23 73 39 57]line.add 'Firstserie' rng line.add 'Secondaryserie' map lambda x x * 2 rng secondary True line.title 'Oneserie'q line.render_pyquery assert len q '.axis.x' 0 assert len q '.axis.y' 1 assert len q '.plot.seriespath' 2 assert len q '.x.axis.guides' 0 assert len q '.y.axis.guides' 7
def permute arr permutation return array [arr[i] for i in permutation]
def get_max_denom tup return max Fraction f .denominator for f in tup
def get_file_subs_from_folder addon user kind path name folder dict kind kind path path name name file_tree addon._get_file_tree filenode folder user user version 'latest-published' return list_of_files file_tree
def find_cover_page container ver container.opf_version_parsedif ver.major < 3 mm container.mime_mapguide_type_map container.guide_type_mapfor ref_type name in guide_type_map.iteritems if ref_type.lower u'cover' and mm.get name u'' .lower in OEB_DOCS return nameelse for name in container.manifest_items_with_property u'calibre title-page' return name
def MakeExpiredResponse reference json.loads kVerifyResponseRenewedExpired return json.dumps {'status' reference['status'] 'receipt' reference['receipt']}
def compile_matcher regex if not regex return lambda x True elif regex '!' return lambda x False elif regex.startswith '!' rx re.compile regex[1 ] return lambda x rx.search x is None else rx re.compile regex return lambda x rx.search x is not None
def api_version f @wraps f def wrapped *args **kwargs rv f *args **kwargs rv.headers[u'API-Version'] __version__return rvreturn wrapped
def get_package_directories ls_tree_out check_output 'git' 'ls-tree' '-d' '--name-only' '--full-name' 'HEAD' PROJECT_ROOT result []for package in ls_tree_out.split '\n' if package not in IGNORED_DIRECTORIES result.append package return result
def get_validation_digit number sum 0dvs [4 3 6 7 8 9 2]number str number for i in range 0 len number sum int number[ -1 - i ] * dvs[i] + sum % 10 return 10 - sum % 10
def as_floatX variable if isinstance variable float return numpy.cast[theano.config.floatX] variable if isinstance variable numpy.ndarray return numpy.cast[theano.config.floatX] variable return theano.tensor.cast variable theano.config.floatX
@task base BaseInstructorTask def calculate_may_enroll_csv entry_id xmodule_instance_args action_name ugettext_noop 'generated' task_fn partial upload_may_enroll_csv xmodule_instance_args return run_main_task entry_id task_fn action_name
def compare_multiset_w_baseline multiplicities letters 'abcdefghijklmnopqrstuvwxyz'bl_partitions multiset_partitions_baseline multiplicities letters aocp_partitions set for state in multiset_partitions_taocp multiplicities p1 tuple sorted [tuple p for p in list_visitor state letters ] aocp_partitions.add p1 assert bl_partitions aocp_partitions
def quota_class_destroy context class_name resource return IMPL.quota_class_destroy context class_name resource
def init mpstate return CmdlongModule mpstate
def append_cflags value return append_var 'CFLAGS' value
def save_stats instance migration info remaining migration.memory_total info.memory_totalmigration.memory_processed info.memory_processedmigration.memory_remaining info.memory_remainingmigration.disk_total info.disk_totalmigration.disk_processed info.disk_processedmigration.disk_remaining info.disk_remainingmigration.save instance.progress 100 - remaining instance.save
def InvokeCommand _cmdName _input None *args **kws cmd Command _cmdName for arg in args cmd.Parameters.Add CommandParameter None fix_arg arg for name value in kws.items cmd.Parameters.Add CommandParameter name fix_arg value pipeline _runspace.CreatePipeline pipeline.Commands.Add cmd if _input ret pipeline.Invoke fix_arg _input else ret pipeline.Invoke return ShellOutput ret
def _get_doc_and_fallback_reason document_locale document_slug doc Nonefallback_reason Nonetry doc Document.objects.get locale document_locale slug document_slug if not doc.current_revision and doc.parent and doc.parent.current_revision fallback_reason 'translation_not_approved'elif not doc.current_revision fallback_reason 'no_content'except Document.DoesNotExist passreturn doc fallback_reason
def is_sh executable try fp open executable magic fp.read 2 fp.close except OSError IOError return executablereturn magic '#!'
def patch_ast node source sorted_children False if hasattr node 'region' return nodewalker _PatchingASTWalker source children sorted_children ast.call_for_nodes node walker return node
def mail_reply reply user review reply.base_reply_toreview_request review.review_requestif not review_request.public returnextra_context {u'user' reply.user u'review' review u'reply' reply} has_error extra_context[u'comment_entries'] build_diff_comment_fragments reply.comments.order_by u'filediff' u'first_line' extra_context u'notifications/email_diff_comment_fragment.html' reviewer reply.user to_field cc_field build_recipients reviewer review_request review_request.participants to_field cc_field filter_email_recipients_from_hooks to_field cc_field reply_published reply reply user user review review review_request review_request summary _ensure_unicode review_request.summary reply.email_message_id send_review_mail user review_request u'Re ReviewRequest%d %s' % review_request.display_id summary review.email_message_id to_field cc_field u'notifications/reply_email.txt' u'notifications/reply_email.html' extra_context reply.time_emailed timezone.now reply.save
def benchmark_estimator estimator X_test n_bulk_repeats 30 verbose False atomic_runtimes atomic_benchmark_estimator estimator X_test verbose bulk_runtimes bulk_benchmark_estimator estimator X_test n_bulk_repeats verbose return atomic_runtimes bulk_runtimes
def wait_and_close_handle process_handle WaitForSingleObject process_handle INFINITE CloseHandle process_handle
def getVector3ByPrefixes elementNode prefixes vector3 for prefix in prefixes vector3 getVector3ByPrefix vector3 elementNode prefix return vector3
def mindtouch_namespace_redirect request namespace slug new_locale new_slug Noneif namespace in 'Talk' 'Project' 'Project_talk' locale _ doc_slug slug.partition '/' new_locale settings.MT_TO_KUMA_LOCALE_MAP.get locale 'en-US' new_slug '%s %s' % namespace doc_slug elif namespace 'User' new_slug '%s %s' % namespace slug try rev Revision.objects.filter document__slug new_slug .latest 'created' new_locale rev.document.localeexcept Revision.DoesNotExist new_locale 'en-US'else new_locale 'en-US'new_slug '%s %s' % namespace slug if new_locale new_url '/%s/docs/%s' % request.LANGUAGE_CODE new_slug return redirect new_url permanent True
def validate_response response content response.contentstatus_code response.status_codetry parsed_content response.json except ValueError message content if content else 'NoContent' raise exceptions.PlotlyRequestError message status_code content message ''if isinstance parsed_content dict error parsed_content.get 'error' if error message errorelif response.ok returnif not message message content if content else 'NoContent' raise exceptions.PlotlyRequestError message status_code content
def log_logistic X out None is_1d X.ndim 1 X np.atleast_2d X X check_array X dtype np.float64 n_samples n_features X.shapeif out is None out np.empty_like X _log_logistic_sigmoid n_samples n_features X out if is_1d return np.squeeze out return out
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
def has_perm user perm obj check get_check user perm return user.has_perm perm or check and check obj
def could_be_isomorphic G1 G2 if G1.order ! G2.order return Falsed1 G1.degree t1 nx.triangles G1 c1 nx.number_of_cliques G1 props1 [[d t1[v] c1[v]] for v d in d1]props1.sort d2 G2.degree t2 nx.triangles G2 c2 nx.number_of_cliques G2 props2 [[d t2[v] c2[v]] for v d in d2]props2.sort if props1 ! props2 return Falsereturn True
def cache_available config if config.has_option 'cache' 'cache_dir' dpath config.get 'cache' 'cache_dir' try existing os.stat '/'.join [dpath 'inventory'] except return Falseif config.has_option 'cache' 'cache_max_age' maxage config.get 'cache' 'cache_max_age' if int time.time - int existing.st_mtime < int maxage return Truereturn False
def is_smtp_enabled backend None if backend is None backend get_mail_backend return backend not in settings.SENTRY_SMTP_DISABLED_BACKENDS
def task_uninstall_flocker distribution return _flocker_uninstallers[distribution]
def _aybabtu c l [c Versioned]for b in inspect.getmro c if b not in l and issubclass b Versioned l.append b return l[2 ]
def test2 buildPackage '/Users/dinu/Desktop/reportlab' Title 'reportlab' Version '1.10' Description "ReportLab'sOpenSourcePDFtoolkit." DefaultLocation '/Applications/ReportLab' Relocatable 'YES'
def getShortestUniqueSettingName settingName settings for length in xrange 3 len settingName numberOfEquals 0shortName settingName[ length]for setting in settings if setting.name[ length] shortName numberOfEquals + 1if numberOfEquals < 2 return shortName.lower return settingName.lower
def aware_to_naive d offset d.utcoffset if offset d d.replace tzinfo None d d - offset return d
def to_bytes text default 0 mult_key_org text.lstrip '-1234567890' mult_key mult_key_org.lower mult_key_len len mult_key if mult_key.endswith 'b' mult_key mult_key[0 -1 ]try multiplier BYTE_MULTIPLIERS[mult_key]if mult_key_len text text[0 - mult_key_len ]return int text * multiplier except KeyError msg _ 'Unknownbytemultiplier %s' % mult_key_org raise TypeError msg except ValueError return default
def sqeuclidean u v utype vtype None None if not hasattr u 'dtype' and np.issubdtype u.dtype np.inexact utype np.float64if not hasattr v 'dtype' and np.issubdtype v.dtype np.inexact vtype np.float64u _validate_vector u dtype utype v _validate_vector v dtype vtype u_v u - v return np.dot u_v u_v
def _setPluginPathEnviron if 'VLC_PLUGIN_PATH' in os.environ.keys returndllPath vlc.dll._namefrom os.path import split joinnSteps 0last dllPathwhile nSteps < 4 last split last [0]pluginPath join last 'plugins' if os.path.isdir pluginPath os.environ['VLC_PLUGIN_PATH'] pluginPathbreaknSteps + 1
def check_available mod return mod in available
def _update_badge_context context course user badge Noneif badges_enabled and course.issue_badges badges get_completion_badge course.location.course_key user .get_for_user user if badges badge badges[0]context['badge'] badge
def submit_echoprints recording_echoprints warn 'Echoprintswereneverintroduced\nnothingwillbesubmitted' Warning stacklevel 2 return {'message' {'text' 'OK'}}
def indentation logical_line previous_logical indent_char indent_level previous_indent_level if indent_char '' and indent_level % 4 return 0 'E111indentationisnotamultipleoffour' indent_expect previous_logical.endswith ' ' if indent_expect and indent_level < previous_indent_level return 0 'E112expectedanindentedblock' if indent_level > previous_indent_level and not indent_expect return 0 'E113unexpectedindentation'
def setStateLocation stateLocation if stateLocation is None returnif not stateLocation.endswith '/' stateLocation + '/'stateLocation + const.TRANSPORT_NAME.lower + '/' if not os.path.exists stateLocation log.info "Creatingdirectorypath`%s'." % stateLocation os.makedirs stateLocation log.debug "Settingthestatelocationto`%s'." % stateLocation const.STATE_LOCATION stateLocation
def webclient request _shared_login request pagevars {'browser_sessid' request.session.session_key}return render request 'webclient.html' pagevars
def _IsTestFilename filename if filename.endswith '_test.cc' or filename.endswith '_unittest.cc' or filename.endswith '_regtest.cc' return Trueelse return False
def _isSequence obj mType type obj return mType is list or mType is tuple
def _bind_parameters operation parameters string_parameters {}for name value in parameters.iteritems if value is None string_parameters[name] 'NULL'elif isinstance value basestring string_parameters[name] "'" + _escape value + "'" else string_parameters[name] str value return operation % string_parameters
def _identity_nodes graph include_iterables return [node for node in nx.topological_sort graph if isinstance node._interface IdentityInterface and include_iterables or getattr node u'iterables' is None ]
def p_compound_stmt p p[0] p[1]
def send_score_update assignment score xml generate_replace_result_xml assignment.lis_result_sourcedid score try response sign_and_send_replace_result assignment xml except RequestException response Nonelog.exception 'OutcomeService Errorwhensendingresult.' if not response and check_replace_result_response response log.error 'OutcomeService FailedtoupdatescoreonLTIconsumer.User %s course %s usage %s score %s status %s body %s' assignment.user assignment.course_key assignment.usage_key score response response.text if response else 'Unknown'
def getLengthMinusOneMinimumOne elementList return max 1 len elementList - 1
def takewhile_inclusive pred seq for e in seq yield e if not pred e return
def encode_cert cert return encode_b64jose OpenSSL.crypto.dump_certificate OpenSSL.crypto.FILETYPE_ASN1 cert.wrapped
def _preferred_alias aliases if not aliases returnaliases [a for a in aliases if 'locale' in a ]for locale in config['import']['languages'].as_str_seq matches [a for a in aliases if a['locale'] locale and 'primary' in a ]if not matches continuereturn matches[0]
def get_allowed_view_plugins data_dict can_view []for plugin in p.PluginImplementations p.IResourceView plugin_info plugin.info if plugin_info.get 'always_available' False or plugin.can_view data_dict can_view.append plugin return can_view
def sigmoid_cross_entropy x t use_cudnn True normalize True return SigmoidCrossEntropy use_cudnn normalize x t
def setSettingsPath path global settingsPathsettingsPath path
def cublas_shutdown CUDAMatrix.ones 0_cudamat.cublas_shutdown
def sm_flavor_get context sm_flavor return IMPL.sm_flavor_get context sm_flavor
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def attr_ge accessing_obj accessed_obj *args **kwargs return attr accessing_obj accessed_obj *args **{'compare' 'ge'}
def survey_getQuestionFromCode code series_id None s3db current.s3dbsertable s3db.survey_seriesq_ltable s3db.survey_question_listqsntable s3db.survey_questionif series_id ! None query sertable.id series_id & q_ltable.template_id sertable.template_id & q_ltable.question_id qsntable.id & qsntable.code code else query q_ltable.template_id sertable.template_id & q_ltable.question_id qsntable.id & qsntable.code code record current.db query .select qsntable.id qsntable.code qsntable.name qsntable.type q_ltable.posn limitby 0 1 .first question {}if record ! None question_row record.survey_questionquestion['qstn_id'] question_row.idquestion['code'] question_row.codequestion['name'] question_row.namequestion['type'] question_row.typequestion['posn'] record.survey_question_list.posnreturn question
def enabled name **kwargs ret {'name' name 'result' True 'changes' {} 'comment' []}current_schedule __salt__['schedule.list'] show_all True return_yaml False if name in current_schedule if 'test' in __opts__ and __opts__['test'] kwargs['test'] Trueresult __salt__['schedule.enable_job'] name **kwargs ret['comment'].append result['comment'] else result __salt__['schedule.enable_job'] name **kwargs if not result['result'] ret['result'] result['result']ret['comment'] result['comment']return retelse ret['comment'].append 'Enabledjob{0}fromschedule'.format name else ret['comment'].append 'Job{0}notpresentinschedule'.format name ret['comment'] '\n'.join ret['comment'] return ret
def whitespace_around_comma logical_line line logical_linefor m in WHITESPACE_AFTER_COMMA_REGEX.finditer line found m.start + 1 if ' DCTB ' in m.group yield found "E242tabafter'%s'" % m.group [0] else yield found "E241multiplespacesafter'%s'" % m.group [0]
@with_support storage NullStorage def test_no_srcdir support raises RuntimeError support.build
def connect_euca host None aws_access_key_id None aws_secret_access_key None port 8773 path '/services/Eucalyptus' is_secure False **kwargs from boto.ec2 import EC2Connectionfrom boto.ec2.regioninfo import RegionInfoif not aws_access_key_id aws_access_key_id config.get 'Credentials' 'euca_access_key_id' None if not aws_secret_access_key aws_secret_access_key config.get 'Credentials' 'euca_secret_access_key' None if not host host config.get 'Boto' 'eucalyptus_host' None reg RegionInfo name 'eucalyptus' endpoint host return EC2Connection aws_access_key_id aws_secret_access_key region reg port port path path is_secure is_secure **kwargs
def get_user_objects current_user user module None preformat False objects dict if module user_objects _get_module_objects module current_user user 'get_user_objects' if user_objects for key in user_objects user_objects[key]['module'] moduleobjects[ 'related_user.' + key ] user_objects[key]modules [module]else perspective current_user.get_perspective modules perspective.modules.filter display True .order_by 'title' if not modules modules Module.objects.filter display True .order_by 'title' for module in modules user_objects _get_module_objects module current_user user 'get_user_objects' if user_objects for key in user_objects user_objects[key]['module'] moduleobjects[ 'related_user.' + key ] user_objects[key]if preformat return _preformat_objects modules objects return objects
def import_and_wrap_deprecated module_name module_dict warn_import True if warn_import deprecated_import module_name from importlib import import_modulemodule import_module module_name for attr in module.__all__ module_dict[attr] deprecated getattr module attr
def iterencode iterator encoding errors 'strict' **kwargs encoder getincrementalencoder encoding errors **kwargs for input in iterator output encoder.encode input if output yield output output encoder.encode '' True if output yield output
def _get_upgradable dist_upgrade True **kwargs cmd ['apt-get' '--just-print']if dist_upgrade cmd.append 'dist-upgrade' else cmd.append 'upgrade' fromrepo _get_repo **kwargs if fromrepo cmd.extend ['-o' 'APT Default-Release {0}'.format fromrepo ] call __salt__['cmd.run_all'] cmd python_shell False output_loglevel 'trace' if call['retcode'] ! 0 msg 'Failedtogetupgrades'for key in 'stderr' 'stdout' if call[key] msg + ' ' + call[key] breakraise CommandExecutionError msg else out call['stdout']rexp re.compile ' ?m ^Conf [^]+ \\ [^]+ ' keys ['name' 'version']_get lambda l k l[keys.index k ] upgrades rexp.findall out ret {}for line in upgrades name _get line 'name' version_num _get line 'version' ret[name] version_numreturn ret
def _factorize_from_iterables iterables if len iterables 0 return [[] []]return map list lzip *[_factorize_from_iterable it for it in iterables]
def oo_image_tag_to_rpm_version version include_dash False if not isinstance version string_types raise errors.AnsibleFilterError '|failedexpectsastringorunicode' if version.startswith 'v' version version[1 ]version version.split '-' [0]if include_dash and version and not version.startswith '-' version '-' + version return version
def isinteractive return matplotlib.is_interactive
def webuse data baseurl 'http //www.stata-press.com/data/r11/' as_df True from statsmodels.iolib import genfromdtaurl urljoin baseurl data + '.dta' dta urlopen url dta BytesIO dta.read if as_df return DataFrame.from_records genfromdta dta else return genfromdta dta
def getUniqueQuoteIndex uniqueQuoteIndex word uniqueQuoteIndex + 1while getTokenByNumber uniqueQuoteIndex in word uniqueQuoteIndex + 1return uniqueQuoteIndex
def is_update flags if from_flags flags UPDATE return Truereturn False
def fd f return f.fileno if hasattr f 'fileno' else f
def FileWriter context if context.format context.html_format return HtmlFileWriter context if context.format context.tsv_format return TsvFileWriter context if context.pipe_separated return PipeSeparatedTxtWriter context return SpaceSeparatedTxtWriter context
@csrf_protect@login_requireddef flag request comment_id next None comment get_object_or_404 comments.get_model pk comment_id site__pk settings.SITE_ID if request.method 'POST' perform_flag request comment return next_redirect request fallback next or 'comments-flag-done' c comment.pk else return render_to_response 'comments/flag.html' {'comment' comment 'next' next} template.RequestContext request
def _hadoop_cmd module command *args out Noneif module and command if module in __authorized_modules__ cmd 'hadoop{0}-{1}{2}'.format module command ''.join args out __salt__['cmd.run'] cmd python_shell False else return 'Error Unknownmodule'else return 'Error Moduleandcommandnotdefined'return out
def rs_compose_add p1 p2 R p1.ringx R.gens[0]prec p1.degree * p2.degree + 1 np1 rs_newton p1 x prec np1e rs_hadamard_exp np1 np2 rs_newton p2 x prec np2e rs_hadamard_exp np2 np3e rs_mul np1e np2e x prec np3 rs_hadamard_exp np3e True np3a np3[ 0 ] - np3 / x q rs_integrate np3a x q rs_exp q x prec q _invert_monoms q q q.primitive [1]dp p1.degree * p2.degree - q.degree if dp q q * x ** dp return q
def widget_settings_dir return os.path.join data_dir 'widgets'
def run_DESeq2 input_path out_path mapping_category subcategory_1 subcategory_2 DESeq2_diagnostic_plots outfile_diagnostic if DESeq2_diagnostic_plots True command_args [ '-i%s-o%s-c%s-x%s-y%s-d%s-e%s' % input_path out_path mapping_category subcategory_1 subcategory_2 DESeq2_diagnostic_plots outfile_diagnostic ]else command_args [ '-i%s-o%s-c%s-x%s-y%s' % input_path out_path mapping_category subcategory_1 subcategory_2 ]rsl RExecutor TmpDir get_qiime_temp_dir app_result rsl command_args command_args script_name 'DESeq2_nbinom.r' return app_result
def paired_manhattan_distances X Y X Y check_paired_arrays X Y diff X - Y if issparse diff diff.data np.abs diff.data return np.squeeze np.array diff.sum axis 1 else return np.abs diff .sum axis -1
def test_setting_from_masked_column mask_b np.array [True True False False] for select in mask_b slice 0 2 t Table masked True t['a'] Column [1 2 3 4] t['b'] MaskedColumn [11 22 33 44] mask mask_b t['c'] MaskedColumn [111 222 333 444] mask [True False True False] t['b'][select] t['c'][select]assert t['b'][1] t[1]['b'] assert t['b'][0] is np.ma.masked assert t['b'][1] 222 assert t['b'][2] 33 assert t['b'][3] 44 assert np.all t['b'].mask t.mask['b'] mask_before_add t.mask.copy t['d'] np.arange len t assert np.all t.mask['b'] mask_before_add['b']
def is_iter y ignore six.string_types if ignore and isinstance y ignore return Falsetry iter y return Trueexcept TypeError return False
def sysctl ret {}sysctl_jail __salt__['cmd.run'] 'sysctlsecurity.jail' for line in sysctl_jail.splitlines key value line.split ' ' 1 ret[key.strip ] value.strip return ret
def _PadLabels3d logits labels logits_shape shapes.tensor_shape logits labels_shape shapes.tensor_shape labels labels tf.reshape labels [ -1 labels_shape[2]] labels _PadLabels2d logits_shape[2] labels labels tf.reshape labels [labels_shape[0] -1 ] labels _PadLabels2d logits_shape[1] * logits_shape[2] labels return tf.reshape labels [labels_shape[0] logits_shape[1] logits_shape[2]]
def isProcedureDoneOrFileIsEmpty gcodeText procedure if gcodeText '' return Truereturn isProcedureDone gcodeText procedure
def akismet_spam_check user_ip user_agent **optional AKISMET_API_KEY getattr settings 'AKISMET_API_KEY' '' AKISMET_CHECK_ENABLED waffle.switch_is_active 'AKISMET_CHECK_ENABLED' if not AKISMET_API_KEY or not AKISMET_CHECK_ENABLED return NoneAKISMET_URL 'https //{0}.rest.akismet.com/1.1/comment-check'.format AKISMET_API_KEY parameters {'blog' settings.SITE_URL 'user_ip' user_ip 'user_agent' user_agent}parameters.update optional response requests.post AKISMET_URL data parameters response.raise_for_status try return {'true' True 'false' False}[response.text]except KeyError error response.headers.get 'x-akismet-debug-help' raise Exception 'Akismetraisedanerror {0}'.format error
def temporaryApplyOverrides repository global globalTemporaryOverridesif repository.baseName in globalTemporaryOverrides settingTable {}for setting in repository.preferences settingTable[setting.name] settingfor name value in overrides[repository.baseName].items if name in settingTable settingTable[name].setValueToString value else print 'Overridenotappliedfor %s %s' % name value
def _get_rois_blob im_rois im_scale_factors rois levels _project_im_rois im_rois im_scale_factors rois_blob np.hstack levels rois return rois_blob.astype np.float32 copy False
def _poll_while predicate steps sleep None return poll_until lambda not predicate steps sleep
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def required_length nmin nmax class RequiredLength Action def __call__ self parser args values option_string None if not nmin < len values < nmax raise ArgumentError self u'requiresbetween%sand%sarguments' % nmin nmax setattr args self.dest values return RequiredLength
def test_table_groups_mask_index T1 for masked in False True t1 Table T1 masked masked .group_by 'a' t2 t1.groups[np.array [True False True] ]assert len t2.groups 2 assert t2.groups[0].pformat t1.groups[0].pformat assert t2.groups[1].pformat t1.groups[2].pformat assert np.all t2.groups.keys['a'] np.array [0 2]
def test_unicode_escapes s '"a\\xac\\u1234\\u20ac\\U00008000"'assert len s 29 entry tokenize s [0]assert len entry 5 assert [ord x for x in entry] [97 172 4660 8364 32768]
def _pragma_cursor cursor if cursor.closed cursor.fetchone lambda None cursor.fetchall lambda [] return cursor
def _parse_log_statement options for i in options if _is_reference i _add_reference i _current_statement elif _is_junction i _add_junction i elif _is_inline_definition i _add_inline_definition i _current_statement
@app.route '/notes' methods ['POST' 'PUT'] def add_note id_token request.headers['Authorization'].split '' .pop claims google.oauth2.id_token.verify_firebase_token id_token HTTP_REQUEST if not claims return 'Unauthorized' 401 data request.get_json note Note parent ndb.Key Note claims['sub'] message data['message'] note.friendly_id claims.get 'name' claims.get 'email' 'Unknown' note.put return 'OK' 200
def gcal2jd year month day year int year month int month day int day a ipart month - 14 / 12.0 jd ipart 1461 * year + 4800 + a / 4.0 jd + ipart 367 * month - 2 - 12 * a / 12.0 x ipart year + 4900 + a / 100.0 jd - ipart 3 * x / 4.0 jd + day - 2432075.5 jd - 0.5return MJD_0 jd
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def diop_ternary_quadratic_normal eq var coeff diop_type classify_diop eq _dict False if diop_type 'homogeneous_ternary_quadratic_normal' return _diop_ternary_quadratic_normal var coeff
def test_ada_bad_ratio ratio -1.0 ada ADASYN ratio ratio random_state RND_SEED assert_raises ValueError ada.fit X Y ratio 100.0ada ADASYN ratio ratio random_state RND_SEED assert_raises ValueError ada.fit X Y ratio 'rnd'ada ADASYN ratio ratio random_state RND_SEED assert_raises ValueError ada.fit X Y ratio [0.5 0.5]ada ADASYN ratio ratio random_state RND_SEED assert_raises ValueError ada.fit X Y
def _get node nodeId nodeAttrs 'id' 'class' 'model' 'pattern' if hasattr node 'hasAttributes' and node.hasAttributes for nodeAttr in nodeAttrs if str node.getAttribute nodeAttr nodeId return nodeif node.hasChildNodes if hasattr node.childNodes 'length' length node.childNodes.lengthelse length len node.childNodes for childNum in range length result _get node.childNodes[childNum] nodeId if result return result
def title_or_url node title getattr node 'display_name' None if not title title node.location.to_deprecated_string return title
def make_providers_strings providers if not providers return Noneif len providers 1 providers_string providers[0]elif len providers 2 providers_string _ '{first_provider}and{second_provider}' .format first_provider providers[0] second_provider providers[1] else providers_string _ '{first_providers} and{last_provider}' .format first_providers u' '.join providers[ -1 ] last_provider providers[ -1 ] return providers_string
def ensure_tenant_exists keystone tenant_name tenant_description check_mode try tenant get_tenant keystone tenant_name except KeyError passelse if tenant.description tenant_description return False tenant.id elif check_mode return True tenant.id else tenant.update description tenant_description return True tenant.id if check_mode return True None ks_tenant keystone.tenants.create tenant_name tenant_name description tenant_description enabled True return True ks_tenant.id
def __SendDataPart data connection deprecated 'calltodeprecatedfunction__SendDataPart' if isinstance data str connection.send data returnelif ElementTree.iselement data connection.send ElementTree.tostring data returnelif hasattr data 'read' while 1 binarydata data.read 100000 if binarydata '' breakconnection.send binarydata returnelse connection.send str data return
def _parse_network_details machine_id logging.debug _ 'Receivedmachine_idfromvmtools %s' % machine_id[0] network_details []if machine_id[1].strip '1' passelse for machine_id_str in machine_id[0].split '#' network_info_list machine_id_str.split ';' if len network_info_list % 6 ! 0 breakno_grps len network_info_list / 6 i 0while i < no_grps k i * 6 network_details.append network_info_list[k].strip .lower network_info_list[ k + 1 ].strip network_info_list[ k + 2 ].strip network_info_list[ k + 3 ].strip network_info_list[ k + 4 ].strip network_info_list[ k + 5 ].strip .split ' ' i + 1logging.debug _ 'NICinformationfromvmtools %s' % network_details return network_details
def test_template e HTTPInternalServerError e.template 'A% ping sand<b>% pong s</b>message.'assert str e .startswith '500InternalServerError' assert e.plain {'ping' 'fun' 'pong' 'happy'} '500InternalServerError\r\nAfunandhappymessage.\r\n' assert '<p>Afunand<b>happy</b>message.</p>' in e.html {'ping' 'fun' 'pong' 'happy'}
def recursively_remove dir if not _os.path.exists dir returnshutil.rmtree dir
def get_hosts_and_tests host_info {}q dbmodels.Q test_name__startswith 'kernbench' | dbmodels.Q test_name__startswith 'dbench' | dbmodels.Q test_name__startswith 'tbench' | dbmodels.Q test_name__startswith 'unixbench' | dbmodels.Q test_name__startswith 'iozone' test_query models.TestView.objects.filter q .values 'test_name' 'hostname' 'machine_idx' .distinct for result_dict in test_query hostname result_dict['hostname']test result_dict['test_name']machine_idx result_dict['machine_idx']host_info.setdefault hostname {} host_info[hostname].setdefault 'tests' [] host_info[hostname]['tests'].append test host_info[hostname]['id'] machine_idxreturn rpc_utils.prepare_for_serialization host_info
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def getLoopStartingNearest extrusionHalfWidth location loop nearestIndex getNearestDistanceIndex location loop .indexloop getAroundLoop nearestIndex nearestIndex loop nearestPoint getNearestPointOnSegment loop[0] loop[1] location if abs nearestPoint - loop[0] > extrusionHalfWidth and abs nearestPoint - loop[1] > extrusionHalfWidth loop [nearestPoint] + loop[1 ] + [loop[0]] elif abs nearestPoint - loop[0] > abs nearestPoint - loop[1] loop loop[1 ] + [loop[0]] return loop
def _do_mb_delete path return _mb_request path 'DELETE' AUTH_YES True
def AccessDenied message response shortcuts.render_to_response '404.html' {'message' message} logging.warn message response.status_code 403stats.STATS.IncrementCounter 'http_access_denied' return response
def farness user return sum len paths[0] for paths in user['shortest_paths'].values
def getFilePathsRecursively fileInDirectory '' filePaths getFilePaths fileInDirectory filePathsRecursively filePaths[ ]for filePath in filePaths if os.path.isdir filePath directory os.listdir filePath if len directory > 0 filePathsRecursively + getFilePathsRecursively os.path.join filePath directory[0] return filePathsRecursively
def is_distance_regular G try intersection_array G return Trueexcept nx.NetworkXError return False
@facebook_required_lazy page_tab True def page_tab request graph signed_request_string request.POST['signed_request']signed_request parse_signed_request signed_request_string context {'signed_request' signed_request}return render request 'django_facebook/page_tab.html' context
def list_nodes_min ret {}cmd '{0}listvms'.format vboxcmd for line in salt.modules.cmdmod.run cmd .splitlines if not line.strip continuecomps line.split name comps[0].replace '"' '' ret[name] Truereturn ret
def fixed_ip_disassociate context address return IMPL.fixed_ip_disassociate context address
def user_follower_count context data_dict return _follower_count context data_dict ckan.logic.schema.default_follow_user_schema context['model'].UserFollowingUser
def permalink func from django.core.urlresolvers import reversedef inner *args **kwargs bits func *args **kwargs return reverse bits[0] None *bits[1 3] return inner
def verify cypher key return gluechops cypher key['e'] key['n'] encrypt_int
def _geometric_transform input mapping coordinates matrix offset output order mode cval extra_arguments extra_keywords _nd_image.geometric_transform input mapping coordinates matrix offset output order mode cval extra_arguments extra_keywords if output is not None and not output.dtype.isnative output.byteswap True return output
def _kpatch url data headers {'Content-Type' 'application/json-patch+json'}ret http.query url method 'PATCH' header_dict headers data json.dumps data if ret.get 'error' log.error 'Gotanerror {0}'.format ret.get 'error' return retelse return json.loads ret.get 'body'
def set_ key value profile None conn salt.utils.memcached.get_conn profile time profile.get 'expire' DEFAULT_EXPIRATION return salt.utils.memcached.set_ conn key value time time
def pytest_unconfigure config if config.getoption '--qute-profile-subprocs' stats pstats.Stats for fn in os.listdir 'prof' stats.add os.path.join 'prof' fn stats.dump_stats os.path.join 'prof' 'combined.pstats'
def docstr2rst docstr idx_whitespace len docstr.rstrip - len docstr whitespace docstr[idx_whitespace ]return eval docstr + whitespace
def init_git_pillar opts ret []for opts_dict in [x for x in opts.get 'ext_pillar' [] ] if 'git' in opts_dict if isinstance opts_dict['git'] six.string_types try import gitexcept ImportError return retparts opts_dict['git'].strip .split try br parts[0]loc parts[1]except IndexError log.critical 'Unabletoextractexternalpillardata {0}'.format opts_dict['git'] else ret.append git_pillar._LegacyGitPillar br loc opts else pillar salt.utils.gitfs.GitPillar opts pillar.init_remotes opts_dict['git'] git_pillar.PER_REMOTE_OVERRIDES ret.append pillar return ret
def sec_to_hms sec if sec < -1 return '[endless]'h sec / 3600 sec % 3600m sec / 60 sec % 60return '[%d %02d %02d]' % h m sec
def iter_filename_info dir_name pattern re.compile '^ .+ __ .+ __ [^-]+ \\.png' for t in os.walk dir_name for filename in t[2] if filename.endswith '.png' m pattern.match filename if m is None yield {'error' 'pngfilenamenotfollowingscreenshotpattern {}'.format filename } else d m.group 2 .replace '__' sep yield {'dunder' m.group 1 'dir' d 'file' m.group 3 'ext' m.group 4 'source' slash d m.group 3 + '.' + m.group 4 }
def getNewRepository return FillRepository
def disk_io_counters device None if not device return dict psutil.disk_io_counters ._asdict else stats psutil.disk_io_counters perdisk True if device in stats return dict stats[device]._asdict else return False
def make_wdg_validate_middleware app global_conf wdg_path 'validate' return WDGValidateMiddleware app global_conf wdg_path wdg_path
def get_notifications user notifications []try user.idexcept return []try if not getattr settings 'HARDTREE_ALLOW_GRITTER_NOTIFICATIONS' False return notificationsrequest HttpRequest request.user userstorage default_storage request for msg in storage._get [0] notifications.append {'message' msg.message 'tags' msg._get_tags } storage._store None except passreturn notifications
def paranoid_urlparser_method check def check_wrapper parser *args **kwargs return UrlParser.perform_paranoid_check parser check *args **kwargs return check_wrapper
def list_datastores service_instance return list_objects service_instance vim.Datastore
def utcnow if utcnow.override_time try return utcnow.override_time.pop 0 except AttributeError return utcnow.override_timereturn datetime.datetime.utcnow
def search_reverse prog chars col m prog.search chars if not m return Nonefound None i j m.span while i < col and j < col found mif i j j j + 1 m prog.search chars j if not m break i j m.span return found
def test_misc_conversions pass
@blueprint.route '/projects/<project>/meters/<meter>/volume/sum' def compute_project_volume_sum project meter check_authorized_project project return _get_statistics 'sum' meter meter project project
def _to_list obj ret {}for attr in __attrs ret[attr] obj.__dict__[attr]return ret
@manager.option u'-d' u'--debug' action u'store_true' help u'Startthewebserverindebugmode' @manager.option u'-a' u'--address' default config.get u'SUPERSET_WEBSERVER_ADDRESS' help u'Specifytheaddresstowhichtobindthewebserver' @manager.option u'-p' u'--port' default config.get u'SUPERSET_WEBSERVER_PORT' help u'Specifytheportonwhichtorunthewebserver' @manager.option u'-w' u'--workers' default config.get u'SUPERSET_WORKERS' 2 help u'Numberofgunicornwebserverworkerstofireup' @manager.option u'-t' u'--timeout' default config.get u'SUPERSET_WEBSERVER_TIMEOUT' help u'Specifythetimeout seconds forthegunicornwebserver' def runserver debug address port timeout workers debug debug or config.get u'DEBUG' if debug app.run host u'0.0.0.0' port int port threaded True debug True else cmd u'gunicorn-w{workers}--timeout{timeout}-b{address} {port}--limit-request-line0--limit-request-field_size0superset app'.format **locals print u'Startingserverwithcommand ' + cmd Popen cmd shell True .wait
@command 'historyrecent' def recent_history view_history duplicates False
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def school_type return s3_rest_controller
def test_solve_discrete_lyapunov_zero A np.eye 4 * 0.95 B np.zeros 4 4 X qme.solve_discrete_lyapunov A B assert_allclose X np.zeros 4 4
def test_precision_exceeds_64bit t1 Time 123456789000.0 format 'cxcsec' t2 t1 + dt_tiny assert t1.jd t2.jd
def synctasklet func taskletfunc tasklet func @utils.wrapping func def synctasklet_wrapper *args **kwds __ndb_debug__ utils.func_info func return taskletfunc *args **kwds .get_result return synctasklet_wrapper
def db_add_group **kwargs name kwargs.get 'name' group get_object UserGroup name name users kwargs.pop 'users_id' if not group group UserGroup **kwargs group.save for user_id in users group_add_user group user_id
def eglTerminate display _lib.eglTerminate display
def write_megam_file train_toks encoding stream bernoulli True explicit True labels encoding.labels labelnum dict label i for i label in enumerate labels for featureset label in train_toks if hasattr encoding 'cost' stream.write ' '.join str encoding.cost featureset label l for l in labels else stream.write '%d' % labelnum[label] if not explicit _write_megam_features encoding.encode featureset label stream bernoulli else for l in labels stream.write '#' _write_megam_features encoding.encode featureset l stream bernoulli stream.write '\n'
def assert_python_ok *args **env_vars return _assert_python True *args **env_vars
def gen_extractor_classes return _ALL_CLASSES
def fixed_ips_by_virtual_interface context vif_id return IMPL.fixed_ips_by_virtual_interface context vif_id
def resolve_mro model name predicate result []for cls in type model .__mro__ if name in cls.__dict__ value cls.__dict__[name]if not predicate value breakresult.append value return result
def tamper payload **kwargs retVal ''if payload retVal '%s%ssp_password' % payload '--' if not any _ if _ in payload else None for _ in '#' '--' else '' return retVal
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer.warn "Therequestedsection'{section}'isnotexistent.Thusitcannotbeexecuted.".format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def goto_grep line parsed_line parse_grep_line line if parsed_line filename line_number contents parsed_linedo cmds.Edit [filename] line_number line_number
def remove_root root paths return [pth.replace root + '/' '' for pth in paths]
def grains if not GRAINS_CACHE return _grains DETAILS['host'] DETAILS['protocol'] DETAILS['port'] return GRAINS_CACHE
def make_dict_copy from_dict copy_from_dict {}for key value in from_dict.items if type value .__name__ 'dict' copy_from_dict[key] make_dict_copy value elif isinstance value list copy_from_dict[key] make_list_copy value else copy_from_dict[key] valuereturn copy_from_dict
def _mongo_client host port authenticate True direct False **kwargs client_options client_context.ssl_client_options.copy if client_context.replica_set_name and not direct client_options['replicaSet'] client_context.replica_set_nameclient_options.update kwargs client MongoClient _connection_string host port authenticate port **client_options return client
def ternary value true_val false_val if value return true_valelse return false_val
def resource_fields resource fields if fields resource {key item for key item in resource.items if key in fields }return attributes.populate_project_info resource
def start_hass_instance hass hass.start
def migration_get context migration_id return IMPL.migration_get context migration_id
def test_rechunk_2d a np.random.uniform 0 1 300 .reshape 10 30 x da.from_array a chunks 1 2 3 4 5 * 6 new 5 5 15 * 2 x2 rechunk x chunks new assert x2.chunks new assert np.all x2.compute a
def _key_string key key_prefix '' server_to_user_dict None if _is_pair key key key[1]if not isinstance key basestring raise TypeError 'Keymustbeastringinstance received%r' % key if not isinstance key_prefix basestring raise TypeError 'key_prefixmustbeastringinstance received%r' % key_prefix server_key key_prefix + key if isinstance server_key unicode server_key server_key.encode 'utf-8' if len server_key > MAX_KEY_SIZE server_key hashlib.sha1 server_key .hexdigest if server_to_user_dict is not None assert isinstance server_to_user_dict dict server_to_user_dict[server_key] keyreturn server_key
def fnunpickle fileorname number 0 usecPickle True if usecPickle and six.PY2 import cPickle as pickleelse import pickleif isinstance fileorname six.string_types f open fileorname u'rb' close Trueelse f fileornameclose Falsetry if number > 0 res []for i in range number res.append pickle.load f elif number < 0 res []eof Falsewhile not eof try res.append pickle.load f except EOFError eof Trueelse res pickle.load f finally if close f.close return res
def start_server data_stream port 5557 hwm 20 logging.basicConfig level 'INFO' context zmq.Context socket context.socket zmq.PUSH socket.set_hwm hwm socket.bind 'tcp //* {}'.format port it data_streamlogger.info 'serverstarted' while True try data next it stop Falselogger.debug 'sending{}arrays'.format len data except StopIteration it data_streamdata Nonestop Truelogger.debug 'sendingStopIteration' send_arrays socket data stop stop
@register.inclusion_tag 'inclusion.html' def inclusion_unlimited_args one two 'hi' *args return {'result' 'inclusion_unlimited_args-Expectedresult %s' % ' '.join [six.text_type arg for arg in [one two] + list args ] }
def test_good_create_config_from_post tmpdir workspace tmpdir.strpathtemp_config_path workspace + '/config.yaml' make_default_config_if_needed temp_config_path temp_ip_detect_path workspace + '/ip-detect' f open temp_ip_detect_path 'w' f.write '#/bin/bashfoo' good_post_data {'agent_list' ['10.0.0.2'] 'master_list' ['10.0.0.1'] 'cluster_name' 'GoodTest' 'resolvers' ['4.4.4.4'] 'ip_detect_filename' temp_ip_detect_path}expected_good_messages {}messages backend.create_config_from_post post_data good_post_data config_path temp_config_path assert messages expected_good_messages
def get_user_meta_prefix server_type return 'x-%s-%s-' % server_type.lower 'meta'
def normal_lower_bound probability mu 0 sigma 1 return inverse_normal_cdf 1 - probability mu sigma
def _sym_decorrelation W s u linalg.eigh np.dot W W.T return np.dot np.dot u * 1.0 / np.sqrt s u.T W
def matrix2numpy m dtype object from numpy import emptya empty m.shape dtype for i in range m.rows for j in range m.cols a[ i j ] m[ i j ]return a
def _track_event event_name bookmark tracker.emit event_name {'course_id' unicode bookmark.course_key 'bookmark_id' bookmark.resource_id 'component_type' bookmark.usage_key.block_type 'component_usage_id' unicode bookmark.usage_key }
def test_unicode_axes bar Bar [1 2 3] bar.axis_titles x u'\u8001\u7279\u6d1b\u4f0a\u5457' y u'ZA\u017b\xd3\u0141\u0106G\u0118\u015aL\u0104JA\u0179\u0143'
def complete_xonfig prefix line start end ctx args line.split '' if len args 0 or args[0] ! 'xonfig' return Nonecurix args.index prefix if curix 1 possible {'info' 'wizard' 'styles' 'colors' '-h'}elif curix 2 and args[1] 'colors' possible set xt.color_style_names else raise StopIterationreturn {i for i in possible if i.startswith prefix }
def askopenfile mode 'r' **options filename Open **options .show if filename return open filename mode return None
@task name 'all' help {'args' 'Commandlineargsfortestrun.'} def test_all ctx args '' options '' pytest_args select_by_prefix args ctx.pytest.scopes behave_args select_by_prefix args ctx.behave_test.scopes pytest_should_run not args or args and pytest_args behave_should_run not args or args and behave_args if pytest_should_run pytest ctx pytest_args options options if behave_should_run behave ctx behave_args options options
def _ParsePort port description try port int port if not 65535 > port > 0 raise ValueErrorreturn portexcept ValueError print >>sys.stderr 'Invalidvalue%ssuppliedfor%s' % port description PrintUsageExit 1
def import_required mod_name error_msg try return import_module mod_name except ImportError raise RuntimeError error_msg
def _convert value T if type value is T return valueif issubclass T int and value.denominator ! 1 T floattry return T value except TypeError if issubclass T Decimal return T value.numerator / T value.denominator else raise
def search_python_list python_code template_names retval []for tn in template_names retval.extend search_python python_code tn retval list set retval retval.sort return retval
def is_algebraic p if p.is_Rational return Trueelif p.is_Atom return Falseelif is_sqrt p or p.is_Pow and p.exp.is_Integer return is_algebraic p.base elif p.is_Add or p.is_Mul return all is_algebraic x for x in p.args else return False
def user_media_url what default '%s%s/' % settings.MEDIA_URL what key '{0}_URL'.format what.upper .replace '-' '_' return getattr settings key default
def _StripLeadingOrTrailingDoubleColons addr_string if addr_string.startswith ' ' return addr_string[1 ]if addr_string.endswith ' ' return addr_string[ -1 ]return addr_string
def parse_rec filename tree ET.parse filename objects []for obj in tree.findall 'object' obj_struct {}obj_struct['name'] obj.find 'name' .textobj_struct['pose'] obj.find 'pose' .textobj_struct['truncated'] int obj.find 'truncated' .text obj_struct['difficult'] int obj.find 'difficult' .text bbox obj.find 'bndbox' obj_struct['bbox'] [int bbox.find 'xmin' .text int bbox.find 'ymin' .text int bbox.find 'xmax' .text int bbox.find 'ymax' .text ]objects.append obj_struct return objects
def get_hub_class global _threadlocaltry hubtype _threadlocal.Hubexcept AttributeError hubtype Noneif hubtype is None hubtype _threadlocal.Hub Hubreturn hubtype
def dotted_netmask mask bits 4294967295 ^ 1 << 32 - mask - 1 return socket.inet_ntoa struct.pack '>I' bits
def _minimalPercentEncode text safe unsafe set _genDelims + _subDelims - set safe return u''.join c if c not in unsafe else '%{ 02X}'.format ord c for c in text
def _compute_hist tensor hist nbins 64 offset -48 threads 128assert nbins < threads and nbins > 0 size tensor.sizestrides np.floor np.sqrt size / threads * threads if strides < threads strides max size / threads * threads threads blocks max 1 int strides // threads kernel_args [hist tensor.gpudata int strides size]hist_kern _get_hist_kernel tensor.dtype.str nbins offset hist_kern.prepared_call blocks 1 1 threads 1 1 *kernel_args
def timefunc func @functools.wraps func def inner *args **kwargs start_time time.time try return func *args **kwargs finally total_time time.time - start_time LOG.debug _ "timefunc '% name s'took% total_time .2fsecs" % dict name func.__name__ total_time total_time return inner
def can_list access_key secret_key if not access_key and secret_key return Falsetry connect_s3 access_key secret_key .get_all_buckets except exception.S3ResponseError return Falsereturn True
def test_instantiate_regression yaml "{'a' &test!obj pylearn2.config.tests.test_yaml_parse.DumDum{} 'b' *test}"obj load yaml assert obj['a'] is obj['b']
def is_decimal string return all ch in DIGITS for ch in string
def pkgfiles opts return LazyLoader _module_dirs opts 'pkgfiles' base_path os.path.join SALT_BASE_PATH 'spm' opts tag 'pkgfiles'
def kruskal_wallis data return kruskal *data
def argmin_random_tie seq func return random.choice argmin_list seq func
def strip_uri_prefix path return re.sub '^ /v\\d+ ?' '' six.text_type path
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def config_check name passed default module diff DefaultVMConfig passed default if len diff.shallow_diff module.fail_json msg 'Missingrequiredkey/pair[%s].%smustcontain%s' % ' '.join diff.shallow_diff name default if diff.recursive_diff module.fail_json msg 'Configmismatchfor%son%s' % name diff.recursive_diff return True
def jitdevice func link [] debug False inline False if link raise ValueError 'linkkeywordinvalidfordevicefunction' return compile_device_template func debug debug inline inline
def build_expression_tree Omega rewrites class Node def ht self return reduce lambda x y x + y [x.ht for x in self.before] 1 nodes {}for expr v in Omega n Node n.before []n.var vn.expr exprnodes[v] nfor _ v in Omega if v in rewrites n nodes[v]r rewrites[v]for _ v2 in Omega if r.has v2 n.before.append nodes[v2] return nodes
def notrack cls cls._no_instance_tracking Truereturn cls
def attach_roles queryset as_field 'roles_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json users_role \nORDERBYusers_role.order\n \nFROMusers_role\nWHEREusers_role.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def test_rgb_to_hsl_part_11 assert rgb_to_hsl 102 102 153 240 20 50 assert rgb_to_hsl 51 51 204 240 60 50 assert rgb_to_hsl 0 0 255 240 100 50
def make_projector projs ch_names bads include_active True return _make_projector projs ch_names bads include_active
@pytest.fixture def _temp_analyze_files_prime tmpdir orig_img tmpdir.join u'orig_prime.img' orig_hdr tmpdir.join u'orig_prime.hdr' orig_img.open u'w+' .close orig_hdr.open u'w+' .close return str orig_img str orig_hdr
def date_from_adverb base_date name adverb_date datetime base_date.year base_date.month base_date.day if name 'today' or name 'tonite' or name 'tonight' return adverb_date.today elif name 'yesterday' return adverb_date - timedelta days 1 elif name 'tomorrow' or name 'tom' return adverb_date + timedelta days 1
def cmReestablishmentRequest LocalAreaId_presence 0 a TpPd pd 5 b MessageType mesType 40 c CiphKeySeqNrAndSpareHalfOctets e MobileStationClassmark2 f MobileId if LocalAreaId_presence is 1 g LocalAreaId iei 19 eightbit 0 packet packet / g packet a / b / c / e / f return packet
def domain_match A B A A.lower B B.lower if A B return Trueif not is_HDN A return Falsei A.rfind B if i -1 or i 0 return Falseif not B.startswith '.' return Falseif not is_HDN B[1 ] return Falsereturn True
def libvlc_media_player_set_position p_mi f_pos f _Cfunctions.get 'libvlc_media_player_set_position' None or _Cfunction 'libvlc_media_player_set_position' 1 1 None None MediaPlayer ctypes.c_float return f p_mi f_pos
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def divisible a b return not a % b
def get_or_create_anonymous_cart_from_token token cart_queryset Cart.objects.all return cart_queryset.open .filter token token user None .get_or_create defaults {u'user' None} [0]
def _DefaultAppId return os.getenv 'APPLICATION_ID' '_'
def nice s if type s is StringType return repr s else return str s
def generate_email start_ref end_ref release_date None if release_date is None release_date default_release_date prbe prs_by_email start_ref end_ref email u"\nTo {emails}\n\nYoumergedatleastonepullrequestforedx-platformthatisgoingout\ninthisupcomingrelease andyouareresponsibleforverifyingthose\nchangesonthestagingserversbeforethecodeisreleased.Pleasego\ntothereleasepagetodoso \n\nhttps //openedx.atlassian.net/wiki/display/ENG/{date}+Release\n\nThestagingserveris https //stage.edx.org\n\nNotethatyouareresponsibleforverifyinganypullrequeststhatyou\nmerged whetheryouwrotethecodeornot. Ifyoudidn'twritethecode \nyoucanandshouldtrytogetthepersonwhowrotethecodetohelp\nverifythechanges--butevenifyoucan't you'restillresponsible! \nIfyoufindanybugs pleasenotifymeandrecordthebugsonthe\nreleasepage.Thanks!\n\nBytheway ifyouhavean@edx.orgemailaddressandarehavingtroublelogging\nintostage youmayneedtoresetyourpassword.\n\nIfyouwouldpreferthisemailbesenttoadifferentemailaddressofyours \nsendarequesttooscm@edx.orgwiththedetails.\n\n".format emails u' '.join prbe.keys date release_date.isoformat return textwrap.dedent email .strip
def vmstat vm_stat ['vmstatus ']vm_stat + utils.system_output 'vmstat' verbose False .splitlines vm_stat + ['\n']return vm_stat
def comparePortionDirection portionDirection otherPortionDirection if portionDirection.portion > otherPortionDirection.portion return 1if portionDirection.portion < otherPortionDirection.portion return -1 if portionDirection.directionReversed < otherPortionDirection.directionReversed return -1 return portionDirection.directionReversed > otherPortionDirection.directionReversed
def CmpToKey mycmp class K object def __init__ self obj self.obj objdef __lt__ self other return mycmp self.obj other.obj -1 return K
def _periodicity args symbol periods []for f in args period periodicity f symbol if period is None return Noneif period is not S.Zero periods.append period if len periods > 1 return lcim periods return periods[0]
def get_warnings_state warnings.warn warn_txt DeprecationWarning stacklevel 2 return warnings.filters[ ]
def parse_authorization_header value if not value returnvalue wsgi_to_bytes value try auth_type auth_info value.split None 1 auth_type auth_type.lower except ValueError returnif auth_type 'basic' try username password base64.b64decode auth_info .split ' ' 1 except Exception returnreturn Authorization 'basic' {'username' bytes_to_wsgi username 'password' bytes_to_wsgi password } elif auth_type 'digest' auth_map parse_dict_header auth_info for key in 'username' 'realm' 'nonce' 'uri' 'response' if key not in auth_map returnif 'qop' in auth_map if not auth_map.get 'nc' or not auth_map.get 'cnonce' returnreturn Authorization 'digest' auth_map
def generate_dataset_shelve filename number_items 1000 if os.path.exists filename os.remove filename data shelve.open filename names get_names totalnames len names random.seed for i in range number_items data[str i + 1 ] {'name' names[random.randint 0 totalnames - 1 ] 'age' random.randint 1 100 'description' li_words 50 False }data.close
def parse_method_descriptor descr name None assert descr and descr[0] ' ' descr descr[1 ]params_list []while descr[0] ! ' ' param descr eat_descriptor descr params_list.append param type tail eat_descriptor descr[1 ] assert not tail params ' '.join params_list if name return '%s%s %s ' % type name params else return '%s %s ' % type params
def get_bytes_from_wsgi environ key default value environ.get key default return value.encode ISO_8859_1
def read_epochs_eeglab input_fname events None event_id None montage None eog verbose None uint16_codec None epochs EpochsEEGLAB input_fname input_fname events events eog eog event_id event_id montage montage verbose verbose uint16_codec uint16_codec return epochs
def equateX point returnValue point.x returnValue
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def question_list output s3_rest_controller return output
def get_all_entries feed_url d feedparser.parse feed_url entries []for e in d['entries'] published make_aware datetime.datetime *e['published_parsed'][ 7] timezone utc entry {'title' e['title'] 'summary' e.get 'summary' '' 'pub_date' published 'url' e['link']}entries.append entry return entries
def cols lst ncols nrows int math.ceil 1.0 * len lst / ncols lst lst + [None for i in range len lst nrows * ncols ] cols [lst[i i + nrows ] for i in range 0 nrows * ncols nrows ]rows zip *cols rows [filter lambda x x is not None r for r in rows]return rows
def sortkey item return type item .__name__ item
def get_ipython_cache_dir xdgdir get_xdg_cache_dir if xdgdir is None return get_ipython_dir ipdir os.path.join xdgdir 'ipython' if not os.path.exists ipdir and _writable_dir xdgdir ensure_dir_exists ipdir elif not _writable_dir xdgdir return get_ipython_dir return py3compat.cast_unicode ipdir fs_encoding
def fmin_ncg f x0 fprime fhess_p None fhess None args avextol 1e-05 epsilon _epsilon maxiter None full_output 0 disp 1 retall 0 callback None opts {'xtol' avextol 'eps' epsilon 'maxiter' maxiter 'disp' disp 'return_all' retall}res _minimize_newtoncg f x0 args fprime fhess fhess_p callback callback **opts if full_output retlist res['x'] res['fun'] res['nfev'] res['njev'] res['nhev'] res['status'] if retall retlist + res['allvecs'] return retlistelif retall return res['x'] res['allvecs'] else return res['x']
def _set_price_list quotation cart_settings if quotation.selling_price_list returnselling_price_list Noneif quotation.customer from erpnext.accounts.party import get_default_price_listselling_price_list get_default_price_list frappe.get_doc u'Customer' quotation.customer if not selling_price_list selling_price_list cart_settings.price_listquotation.selling_price_list selling_price_list
def rackconnect vm_ return config.get_cloud_config_value 'rackconnect' vm_ __opts__ default False search_global False
@bdd.then bdd.parsers.parse 'thepageshouldcontainthehtml"{text}"' def check_contents_html quteproc text content quteproc.get_content plain False assert text in content
def _volume_type_and_iops_for_profile_name profile_name size volume_type Noneiops Nonetry A EBSMandatoryProfileAttributes.lookupByName MandatoryProfiles.lookupByValue profile_name .name .valueexcept ValueError passelse volume_type A.volume_type.valueiops A.requested_iops size return volume_type iops
def gf_zassenhaus f p K factors []for factor n in gf_ddf_zassenhaus f p K factors + gf_edf_zassenhaus factor n p K return _sort_factors factors multiple False
def uid_sequence uidlist def getrange start end if start end return str start return '%s %s' % start end if not len uidlist return '' start end None None retval []sorted_uids sorted map int uidlist for item in iter sorted_uids item int item if start None start end item item elif item end + 1 end itemelse retval.append getrange start end start end item item retval.append getrange start end return ' '.join retval
def get_rect_xmax data return max data[0][0] data[1][0] data[2][0] data[3][0]
def register_canonical_role name role_fn set_implicit_options role_fn _role_registry[name] role_fn
def apiinfo_version **connection_args conn_args _login **connection_args try if conn_args method 'apiinfo.version'params {}ret _query method params conn_args['url'] conn_args['auth'] return ret['result']else raise KeyErrorexcept KeyError return False
def get_data_for_recent_jobs recency_msec DEFAULT_RECENCY_MSEC recent_job_models job_models.JobModel.get_recent_jobs NUM_JOBS_IN_DASHBOARD_LIMIT recency_msec return [_get_job_dict_from_job_model model for model in recent_job_models]
def install_grubby_if_necessary path None installed_grubby Falseif path is None if find_executable GRUBBY_DEFAULT_USER_PATH executable GRUBBY_DEFAULT_USER_PATHelse executable find_executable GRUBBY_DEFAULT_SYSTEM_PATH else executable find_executable path if executable is None log.info 'Installinggrubbybecauseitwasnotfoundonthissystem' grubby Grubby path grubby.grubby_install installed_grubby Trueelse grubby Grubby executable current_version grubby.get_grubby_version if current_version is None log.error 'Couldnotfindversionforgrubbyexecutable"%s"' executable path grubby.grubby_install installed_grubby Trueelif current_version < GRUBBY_REQ_VERSION log.info 'Installinggrubbybecausecurrentlyinstalledversion %s.%s isnotrecentenough' current_version[0] current_version[1] path grubby.grubby_install installed_grubby Trueif installed_grubby grubby Grubby path installed_version grubby.get_grubby_version_raw log.debug 'Installed %s' installed_version
def title s *args **kwargs return gca .set_title s *args **kwargs
def scp_from_remote host port username password remote_path local_path limit '' log_filename None timeout 600 interface None if limit limit '-l%s' % limit if host and host.lower .startswith 'fe80' if not interface raise SCPError 'Whenusingipv6linklocaladdressmustassign ' 'theinterfacetheneighbourattache' host '%s%%%s' % host interface command 'scp-v-oUserKnownHostsFile /dev/null-oPreferredAuthentications password-r%s-P%s%s@\\[%s\\] %s%s' % limit port username host remote_path local_path password_list []password_list.append password remote_scp command password_list log_filename timeout
def test_ast_anon_fns_basics code can_compile u' fn x *xx ' .body[0]assert type code ast.FunctionDef code can_compile u' fn x ' .body[0]cant_compile u' fn '
def managed name servers None ret {'name' name 'changes' {} 'result' True 'comment' 'NTPserversalreadyconfiguredasspecified'}if not _check_servers servers ret['result'] Falseret['comment'] 'NTPserversmustbealistofstrings'before_servers _get_servers desired_servers set servers if before_servers desired_servers return retif __opts__['test'] ret['result'] Noneret['comment'] 'NTPserverswillbeupdatedto {0}'.format ' '.join sorted desired_servers return ret__salt__['ntp.set_servers'] *desired_servers after_servers _get_servers if after_servers desired_servers ret['comment'] 'NTPserversupdated'ret['changes'] {'old' sorted before_servers 'new' sorted after_servers }else ret['result'] Falseret['comment'] 'FailedtoupdateNTPservers'if before_servers ! after_servers ret['changes'] {'old' sorted before_servers 'new' sorted after_servers }return ret
def sysctl ret {}sysctl_jail __salt__['cmd.run'] 'sysctlsecurity.jail' for line in sysctl_jail.splitlines key value line.split ' ' 1 ret[key.strip ] value.strip return ret
def _remove_tags conn load_balancer_names tags params {}conn.build_list_params params load_balancer_names 'LoadBalancerNames.member.%d' conn.build_list_params params tags 'Tags.member.%d.Key' return conn.get_status 'RemoveTags' params verb 'POST'
def test_import from ... import numpy as anpassert anp.matmul is matmul
def test_ch_loc raw_py read_raw_kit sqd_path mrk_path elp_txt_path hsp_txt_path stim '<' raw_bin read_raw_fif op.join data_dir 'test_bin_raw.fif' ch_py raw_py._raw_extras[0]['sensor_locs'][ 5]ch_py[ 3] * 1000.0ch_sns read_sns op.join data_dir 'sns.txt' assert_array_almost_equal ch_py ch_sns 2 assert_array_almost_equal raw_py.info['dev_head_t']['trans'] raw_bin.info['dev_head_t']['trans'] 4 for py_ch bin_ch in zip raw_py.info['chs'] raw_bin.info['chs'] if bin_ch['ch_name'].startswith 'MEG' assert_array_almost_equal py_ch['loc'] bin_ch['loc'] decimal 2 mrks [mrk_path mrk2_path mrk3_path]read_raw_kit sqd_path mrks elp_txt_path hsp_txt_path preload False raw_bin.info['dig'] raw_bin.info['dig'][ 8]raw_py.info['dig'] raw_py.info['dig'][ 8]assert_dig_allclose raw_py.info raw_bin.info
def harden allow_root_login False allow_password_auth False sshd_config '/etc/ssh/sshd_config' if not allow_password_auth disable_password_auth sshd_config sshd_config if not allow_root_login disable_root_login sshd_config sshd_config
def ipow a b a ** breturn a
def uncamelcase name separator '_' s1 FIRST_CAP_RE.sub '\\1%s\\2' % separator name return ALL_CAP_RE.sub '\\1%s\\2' % separator s1 .lower
def test_can_parse_a_unary_array_from_single_step steps Step.many_from_lines I_HAVE_TASTY_BEVERAGES.splitlines assert_equals len steps 1 assert isinstance steps[0] Step assert_equals steps[0].sentence string.split I_HAVE_TASTY_BEVERAGES '\n' [0]
def zulip registry xml_parent data XML.SubElement xml_parent 'hudson.plugins.humbug.HumbugNotifier'
def transform_tawn2 t theta k def _check_args theta k condth theta > 0 cond1 theta + 3 * k > 0 and theta + k < 1 and theta + 2 * k < 1 return condth and cond1 if not np.all _check_args theta k raise ValueError 'invalidargs' transf 1 - theta + k * t + theta * t * t + k * t ** 3 return transf
def get_canonical_path project resource offset pymod project.get_pymodule resource pyname rope.base.evaluate.eval_location pymod offset defmod lineno pyname.get_definition_location if not defmod return Nonescope defmod.get_scope .get_inner_scope_for_line lineno names []if isinstance pyname pynamesdef.ParameterName names [ worder.get_name_at pymod.get_resource offset 'PARAMETER' ]elif isinstance pyname pynamesdef.AssignedName names [ worder.get_name_at pymod.get_resource offset 'VARIABLE' ]while scope.parent if isinstance scope pyscopes.FunctionScope scope_type 'FUNCTION'elif isinstance scope pyscopes.ClassScope scope_type 'CLASS'else scope_type Nonenames.append scope.pyobject.get_name scope_type scope scope.parentnames.append defmod.get_resource .real_path 'MODULE' names.reverse return names
def _generate_overlap_table prefix table [0] * len prefix for i in range 1 len prefix idx table[ i - 1 ]while prefix[i] ! prefix[idx] if idx 0 table[i] 0breakidx table[ idx - 1 ]else table[i] idx + 1 return table
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def profile_post_save instance sender **kwargs from django.contrib.auth.models import Group anon_group created Group.objects.get_or_create name 'anonymous' instance.groups.add anon_group if instance.email not in [u'' '' None] and not kwargs.get 'raw' False address created EmailAddress.objects.get_or_create user instance primary True defaults {'email' instance.email 'verified' False} if not created EmailAddress.objects.filter user instance primary True .update email instance.email
def get_run_configuration fname configurations _get_run_configurations for filename options in configurations if fname filename runconf RunConfiguration runconf.set options return runconf
@requires_duration@apply_to_maskdef time_symmetrize clip return concatenate_videoclips [clip clip.fx time_mirror ]
def path *s joined os.path.join os.path.abspath config.STORE_DIR *s absolute os.path.abspath joined verify absolute return absolute
def clear_middleware app def clear_throw_errors environ start_response headers_sent []def replacement status headers exc_info None if headers_sent return start_response status headers exc_info headers_sent.append True return start_response status headers if 'paste.throw_errors' in environ del environ['paste.throw_errors']return app environ replacement return clear_throw_errors
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def put_ keyname val mdata _check_mdata_put ret {}if mdata cmd 'echo{2}|{0}{1}'.format mdata keyname val ret __salt__['cmd.run_all'] cmd python_shell True return ret['retcode'] 0
@blueprint.route '/autocomplete/path' methods ['GET'] def path_autocomplete path flask.request.args.get 'query' '' if not os.path.isabs path path os.path.sep + path suggestions [os.path.abspath p for p in glob.glob path + '*' ]if platform.system 'Windows' suggestions [p.replace '\\' '/' for p in suggestions]result {'suggestions' sorted suggestions }return json.dumps result
@utils.arg 'tenant' metavar '<tenant_id>' help 'UUIDoftenanttosetthequotasfor.' @utils.arg '--monitors' metavar '<monitors>' type int default None help 'Newvalueforthe"monitors"quota.' @utils.arg '--snapshots' metavar '<snapshots>' type int default None help 'Newvalueforthe"snapshots"quota.' @utils.arg '--gigabytes' metavar '<gigabytes>' type int default None help 'Newvalueforthe"gigabytes"quota.' @utils.service_type 'monitor' def do_quota_update cs args _quota_update cs.quotas args.tenant args
def spherical_jn n z derivative False if derivative return _spherical_jn_d n z else return _spherical_jn n z
def clear_triggers name location '\\' if name not in list_tasks location return '{0}notfoundin{1}'.format name location pythoncom.CoInitialize task_service win32com.client.Dispatch 'Schedule.Service' task_service.Connect task_folder task_service.GetFolder location task_definition task_folder.GetTask name .Definitiontriggers task_definition.Triggerstriggers.Clear return _save_task_definition name name task_folder task_folder task_definition task_definition user_name task_definition.Principal.UserID password None logon_type task_definition.Principal.LogonType
def deferredGenerator f def unwindGenerator *args **kwargs return _deferGenerator f *args **kwargs Deferred return mergeFunctionMetadata f unwindGenerator
def do_email_change_request user new_email activation_key None pec_list PendingEmailChange.objects.filter user user if len pec_list 0 pec PendingEmailChange pec.user userelse pec pec_list[0]if not activation_key activation_key uuid.uuid4 .hexpec.new_email new_emailpec.activation_key activation_keypec.save context {'key' pec.activation_key 'old_email' user.email 'new_email' pec.new_email}subject render_to_string 'emails/email_change_subject.txt' context subject ''.join subject.splitlines message render_to_string 'emails/email_change.txt' context from_address configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL try mail.send_mail subject message from_address [pec.new_email] except Exception log.error u'Unabletosendemailactivationlinktouserfrom"%s"' from_address exc_info True raise ValueError _ 'Unabletosendemailactivationlink.Pleasetryagainlater.' tracker.emit SETTING_CHANGE_INITIATED {'setting' 'email' 'old' context['old_email'] 'new' context['new_email'] 'user_id' user.id}
def merge_solution var var_t solution sol []if None in solution return solution iter solution params numbered_symbols 'n' integer True start 1 for v in var if v in var_t sol.append next solution else sol.append next params for val symb in zip sol var if check_assumptions val **symb.assumptions0 is False return tuple return tuple sol
def get_location_details complete_id db current.dbs3db current.s3dblocations {}ctable s3db.survey_completeqtable s3db.survey_questionatable s3db.survey_answerquery atable.question_id qtable.id & atable.complete_id ctable.id code_list ['STD-P-Code' 'STD-L0' 'STD-L1' 'STD-L2' 'STD-L3' 'STD-L4' 'STD-Lat' 'STD-Lon']for location_code in code_list record db query & qtable.code location_code .select qtable.id limitby 0 1 .first if record widget_obj survey_getWidgetFromQuestion record.id widget_obj.loadAnswer complete_id record.id locations[location_code] widget_objreturn locations
@memoizedef check key ver return check_version get key ver
def _get_migrate_command if __salt__['config.option'] 'virt.tunnel' return 'virshmigrate--p2p--tunnelled--live--persistent--undefinesource'return 'virshmigrate--live--persistent--undefinesource'
def get_hosts service_instance datacenter_name None host_names None cluster_name None get_all_hosts False properties ['name']if not host_names host_names []if cluster_name properties.append 'parent' if datacenter_name start_point get_datacenter service_instance datacenter_name if cluster_name cluster get_cluster start_point cluster_name else start_point get_root_folder service_instance hosts get_mors_with_properties service_instance vim.HostSystem container_ref start_point property_list properties filtered_hosts []for h in hosts name_condition get_all_hosts or h['name'] in host_names cluster_condition not datacenter_name or not cluster_name or isinstance h['parent'] vim.ClusterComputeResource and h['parent'].name cluster_name if name_condition and cluster_condition filtered_hosts.append h['object'] return filtered_hosts
def up iface iface_type None if iface_type not in ['slave'] return __salt__['cmd.run'] 'iplinkset{0}up'.format iface return None
def _file_iter_range fp offset bytes maxread 1024 * 1024 fp.seek offset while bytes > 0 part fp.read min bytes maxread if not part breakbytes - len part yield part
def lpmerge L R setitem L.__setitem__[setitem k v for k v in items R if v is not None ]return L
def showErrorDlg errmsg parent trcbk False if trcbk error u''f StringIO print_exc file f error_mess f.getvalue .splitlines for line in error_mess error error + str line + u'\n' errmsg errmsg + u'\n\n' + error return error_dialog parent _ PLUGIN_NAME + u'v' + PLUGIN_VERSION _ errmsg show True
def run_module name file if name '__main__' nose.runmodule argv [file '-vvs' '-x' '--pdb' '--pdb-failure'] exit False
def shouldRefresh exList MAX_REFRESH_AGE_SECS 86400cache_db_con db.DBConnection 'cache.db' rows cache_db_con.select 'SELECTlast_refreshedFROMscene_exceptions_refreshWHERElist ?' [exList] if rows lastRefresh int rows[0]['last_refreshed'] return int time.mktime datetime.datetime.today .timetuple > lastRefresh + MAX_REFRESH_AGE_SECS else return True
def check_account_exists username None email None conflicts []if email is not None and User.objects.filter email email .exists conflicts.append 'email' if username is not None and User.objects.filter username username .exists conflicts.append 'username' return conflicts
def _call cmds cwd None for c in cmds if cwd subprocess.check_call c cwd cwd else subprocess.check_call c
def ldflags libs True flags False libs_dir False include_dir False ldflags_str theano.config.blas.ldflagsreturn _ldflags ldflags_str ldflags_str libs libs flags flags libs_dir libs_dir include_dir include_dir
def sample_from_mixture x pred_weights pred_means pred_std amount samples np.zeros amount 2 n_mix len pred_weights[0] to_choose_from np.arange n_mix for j weights means std_devs in enumerate zip pred_weights pred_means pred_std index np.random.choice to_choose_from p weights samples[ j 1 ] np.random.normal means[index] std_devs[index] size 1 samples[ j 0 ] x[j]if j amount - 1 breakreturn samples
def remove_credential tenant_id credential_id session db.get_session try cred session.query l2network_models.Credential .filter_by tenant_id tenant_id .filter_by credential_id credential_id .one session.delete cred session.flush return credexcept exc.NoResultFound pass
def handle_cat_api output kwargs name kwargs.get 'keyword' if not name name kwargs.get 'name' if not name return Nonefeed config.get_config 'categories' name if feed feed.set_dict kwargs else config.ConfigCat name kwargs return name
def create_param value size return lo.LinOp lo.PARAM size [] value
def shim_xmodule_js block fragment if not fragment.js_init_fn fragment.initialize_js 'XBlockToXModuleShim' fragment.json_init_args {'xmodule-type' block.js_module_name}
def native_type_range fmt if fmt 'c' lh 0 256 elif fmt '?' lh 0 2 elif fmt 'f' lh - 1 << 63 1 << 63 elif fmt 'd' lh - 1 << 1023 1 << 1023 else for exp in 128 127 64 63 32 31 16 15 8 7 try struct.pack fmt 1 << exp - 1 breakexcept struct.error passlh - 1 << exp 1 << exp if exp & 1 else 0 1 << exp return lh
def test_raises_value_error_non_nonnegative P np.array [[0.4 0.6] [ -0.2 1.2]] assert_raises ValueError MarkovChain P assert_raises ValueError MarkovChain sparse.csr_matrix P
def pack_bits bits packed 0level 0for bit in bits if bit packed + 2 ** level level + 1return packed
def do_not_recurse value return value
def Chi name k return rv name ChiDistribution k
def equatePolarDotRadius point returnValue equateCylindricalDotRadius point returnValue
def getLoggerClass return _loggerClass
def find_torrent info_hash torrent_list for t in torrent_list if t.info_hash info_hash return t
def _getpen if Turtle._pen is None Turtle._pen Turtle return Turtle._pen
def dumpconf return __salt__['ps.pkill'] 'znc' signal signal.SIGUSR1
def vlatex expr **settings latex_printer VectorLatexPrinter settings return latex_printer.doprint expr
def list_zones verbose True installed False configured False hide_global True zones {}header 'zoneid zonename state zonepath uuid brand ip-type'.split ' ' zone_data __salt__['cmd.run_all'] 'zoneadmlist-p-c' if zone_data['retcode'] 0 for zone in zone_data['stdout'].splitlines zone zone.split ' ' zone_t {}for i in range 0 len header zone_t[header[i]] zone[i]if hide_global and zone_t['zonename'] 'global' continueif not installed and zone_t['state'] 'installed' continueif not configured and zone_t['state'] 'configured' continuezones[zone_t['zonename']] zone_tdel zones[zone_t['zonename']]['zonename']return zones if verbose else sorted zones.keys
def imview_async *args **kwargs if 'figure' in kwargs raise ValueError 'passingafigureargumentnotsupported' def fork_image_viewer f plt.figure kwargs['figure'] fimview *args **kwargs if 'window_title' in kwargs f.set_window_title kwargs['window_title'] plt.show p Process None fork_image_viewer p.start return p
def grains if not GRAINS_CACHE return _grains DETAILS['host'] DETAILS['protocol'] DETAILS['port'] return GRAINS_CACHE
def _minimize_scalar_brent func brack None args xtol 1.48e-08 maxiter 500 **unknown_options _check_unknown_options unknown_options tol xtolif tol < 0 raise ValueError 'toleranceshouldbe> 0 got%r' % tol brent Brent func func args args tol tol full_output True maxiter maxiter brent.set_bracket brack brent.optimize x fval nit nfev brent.get_result full_output True return OptimizeResult fun fval x x nit nit nfev nfev success nit < maxiter
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def deferToThreadInReactor reactor f *args **kwargs d defer.Deferred reactor.callInThread _putResultInDeferred reactor d f args kwargs return d
@event u'manager.initialize' def make_environment manager global environmentenvironment Environment undefined StrictUndefined loader ChoiceLoader [PackageLoader u'flexget' FileSystemLoader os.path.join manager.config_base u'templates' ] extensions [u'jinja2.ext.loopcontrols'] environment.template_class FlexGetTemplatefor name filt in list globals .items if name.startswith u'filter_' environment.filters[name.split u'_' 1 [1]] filt
def _repr_column_dict dumper data return dumper.represent_mapping u'tag yaml.org 2002 map' data
def synset_distance statement other_statement from nltk.corpus import wordnetfrom nltk import word_tokenizefrom chatterbot import utilsimport itertoolstokens1 word_tokenize statement.text.lower tokens2 word_tokenize other_statement.text.lower tokens1 utils.remove_stopwords tokens1 language 'english' tokens2 utils.remove_stopwords tokens2 language 'english' max_possible_similarity max len statement.text.split len other_statement.text.split max_similarity 0.0for combination in itertools.product *[tokens1 tokens2] synset1 wordnet.synsets combination[0] synset2 wordnet.synsets combination[1] if synset1 and synset2 for synset in itertools.product *[synset1 synset2] similarity synset[0].path_similarity synset[1] if similarity and similarity > max_similarity max_similarity similarityif max_possible_similarity 0 return 0return max_similarity / max_possible_similarity
def mx2num mxdates scalar Falseif not cbook.iterable mxdates scalar Truemxdates [mxdates]ret epoch2num [m.ticks for m in mxdates] if scalar return ret[0]else return ret
def getDate date None if date is None return datetime.date.today if isinstance date datetime.date return dateif isinstance date datetime.datetime return date.date if isinstance date int long float return datetime.date.fromtimestamp date if isinstance date basestring date date.replace '' '0' if len date 6 return datetime.date *time.strptime date '%y%m%d' [ 3] return datetime.date *time.strptime date '%Y%m%d' [ 3] if hasattr date '__getitem__' return datetime.date *date[ 3] return datetime.date.fromtimestamp date.ticks
def _validate_device device if os.path.exists device dev os.stat device .st_modeif stat.S_ISBLK dev returnraise CommandExecutionError 'Invaliddevicepassedtopartitionmodule.'
def _engine_namespace_handler k v engine cherrypy.engineif k 'SIGHUP' engine.subscribe 'SIGHUP' v elif k 'SIGTERM' engine.subscribe 'SIGTERM' v elif '.' in k plugin attrname k.split '.' 1 plugin getattr engine plugin if attrname 'on' if v and hasattr getattr plugin 'subscribe' None '__call__' plugin.subscribe returnelif not v and hasattr getattr plugin 'unsubscribe' None '__call__' plugin.unsubscribe returnsetattr plugin attrname v else setattr engine k v
def commit_unless_managed using None if using is None using DEFAULT_DB_ALIASconnection connections[using]connection.commit_unless_managed
def bruteforce val res []printable range 32 128 for x in xrange 65536 c x - 13106 & 65535 hi c >> 8 lo c & 255 if hi ^ lo val and x >> 8 in printable and x & 255 in printable res.append x return res
def require_instance_exists_using_uuid f @functools.wraps f def wrapper context instance_uuid *args **kwargs instance_get_by_uuid context instance_uuid return f context instance_uuid *args **kwargs return wrapper
def os_release_attr attribute return _distro.os_release_attr attribute
def convert_starred_uri uri assert type uri six.text_type cnt_stars uri.count u'*' if cnt_stars 0 match u'exact'elif cnt_stars 1 and uri[ -1 ] u'*' match u'prefix'uri uri[ -1 ]else match u'wildcard'uri uri.replace u'*' u'' return uri match
def temporal_padding x padding 1 pattern [[0 0] [padding padding] [0 0]]return tf.pad x pattern
def test_version_int assert version_int '3.5.0a1pre2' 3050000001002 assert version_int '' 200100 assert version_int '0' 200100 assert version_int '*' 99000000200100 assert version_int MAXVERSION MAXVERSION assert version_int MAXVERSION + 1 MAXVERSION assert version_int '9999999' MAXVERSION
def restrict permission def decorator fx def wrapper *args **kwargs UserManager.get .require_permission extract_context permission return fx *args **kwargs return wrapperreturn decorator
def _system_email email plaintext_body kind reply_to '' thing None from_address g.feedback_email html_body '' list_unsubscribe_header '' user None suppress_username False if suppress_username user Noneelif user is None and c.user_is_loggedin user c.userEmail.handler.add_to_queue user email g.domain from_address kind body plaintext_body reply_to reply_to thing thing
def widget_settings_dir return os.path.join data_dir 'widgets'
def get_task_user return UserProfile.objects.get pk settings.TASK_USER_ID
def raise_error_on_parallel_unavailable qiime_config None if qiime_config is None qiime_config load_qiime_config if 'jobs_to_start' not in qiime_config or int qiime_config['jobs_to_start'] < 2 raise RuntimeError 'ParallelQIIMEisnotavailable. Haveyouset' + 'jobs_to_starttogreaterthan1inyourqiime_config?'
def dmp_add_term f c i u K if not u return dup_add_term f c i K v u - 1 if dmp_zero_p c v return fn len f m n - i - 1 if i n - 1 return dmp_strip [dmp_add f[0] c v K ] + f[1 ] u elif i > n return [c] + dmp_zeros i - n v K + f else return f[ m] + [dmp_add f[m] c v K ] + f[ m + 1 ]
def check_entry_points dist attr value try pkg_resources.EntryPoint.parse_map value except ValueError e sys.exc_info [1]raise DistutilsSetupError e
@step CHECK_PREFIX + 'Ihavesent \\d+ emails?' def mail_sent_count step count count int count assert len mail.outbox count 'Lengthofoutboxis{0}'.format count
def _oauth_uri name discovery params if name not in ['request' 'access' 'authorize'] raise KeyError name keys discovery[name]['parameters'].keys query {}for key in keys if key in params query[key] params[key]return discovery[name]['url'] + '?' + urllib.urlencode query
@receiver post_save sender Release def purge_fastly_download_pages sender instance **kwargs if kwargs.get 'raw' False returnif instance.is_published purge_url '/downloads/' purge_url '/downloads/latest/python2/' purge_url '/downloads/latest/python3/' purge_url '/downloads/mac-osx/' purge_url '/downloads/source/' purge_url '/downloads/windows/' if instance.get_version is not None purge_url '/ftp/python/{}/'.format instance.get_version purge_url instance.get_absolute_url
def colname2num s s s.upper n 0for c in s assert 'A' < c < 'Z' n n * 26 + ord c - ord 'A' + 1 return n
def _build_user_auth token None user_id None username None password None tenant_id None tenant_name None trust_id None auth_json {}if token is not None auth_json['token'] tokenif username or password auth_json['passwordCredentials'] {}if username is not None auth_json['passwordCredentials']['username'] usernameif user_id is not None auth_json['passwordCredentials']['userId'] user_idif password is not None auth_json['passwordCredentials']['password'] passwordif tenant_name is not None auth_json['tenantName'] tenant_nameif tenant_id is not None auth_json['tenantId'] tenant_idif trust_id is not None auth_json['trust_id'] trust_idreturn auth_json
@require_context@_retry_instance_update @pick_context_manager_writerdef instance_update_and_get_original context instance_uuid values columns_to_join None expected None instance_ref _instance_get_by_uuid context instance_uuid columns_to_join columns_to_join return copy.copy instance_ref _instance_update context instance_uuid values expected original instance_ref
def readGif filename asNumpy True if PIL is None raise RuntimeError 'NeedPILtoreadanimatedgiffiles.' if np is None raise RuntimeError 'NeedNumpytoreadanimatedgiffiles.' if not os.path.isfile filename raise IOError 'Filenotfound ' + str filename pilIm PIL.Image.open filename pilIm.seek 0 images []try while True tmp pilIm.convert a np.asarray tmp if len a.shape 0 raise MemoryError 'ToolittlememorytoconvertPILimagetoarray' images.append a pilIm.seek pilIm.tell + 1 except EOFError passif not asNumpy images2 imagesimages []for im in images2 images.append PIL.Image.fromarray im return images
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _calc_cp base_attack base_defense base_stamina iv_attack 15 iv_defense 15 iv_stamina 15 cp_multiplier 0.0 assert base_attack > 0 assert base_defense > 0 assert base_stamina > 0 if cp_multiplier < 0.0 cp_multiplier LevelToCPm.MAX_CPMassert cp_multiplier > 0.0 return base_attack + iv_attack * base_defense + iv_defense ** 0.5 * base_stamina + iv_stamina ** 0.5 * cp_multiplier ** 2 / 10
def exit setConfigOptions exitCleanup False atexit._run_exitfuncs if sys.platform 'darwin' for fd in range 3 4096 if fd not in [7] os.close fd else os.closerange 3 4096 os._exit 0
def __django_version_setup django_version _config_handle.django_versionif django_version is not None from google.appengine.dist import use_libraryuse_library 'django' str django_version else from google.appengine.dist import _library version explicit _library.installed.get 'django' '0.96' False if not explicit logging.warn 'YouareusingthedefaultDjangoversion %s .ThedefaultDjangoversionwillchangeinanAppEnginereleaseinthenearfuture.Pleasecalluse_library toexplicitlyselectaDjangoversion.Formoreinformationsee%s' version 'https //developers.google.com/appengine/docs/python/tools/libraries#Django' try import djangoif not hasattr django 'VERSION' from django import v0_96except ImportError pass
def AddLibrary name version explicit sys.path.insert 1 CreatePath name version installed[name] version explicit
def get_collection_owner_names collection_id collection_rights get_collection_rights collection_id return user_services.get_human_readable_user_ids collection_rights.owner_ids
def find_max_daily_commits contributions_calendar daily_counts parse_contributions_calendar contributions_calendar return max daily_counts
def encint value forward True if value < 0 raise ValueError u'Cannotencodenegativenumbersasvwi' byts bytearray while True b value & 127 value >> 7byts.append b if value 0 breakbyts[ 0 if forward else -1 ] | 128byts.reverse return bytes byts
def isPathInsideLoop loop path return isPointInsideLoop loop getLeftPoint path
def test_singletablemixin_with_non_paginated_view class Table tables.Table class Meta model Regionclass View tables.SingleTableMixin TemplateView table_class Tabletable_data MEMORY_DATAtemplate_name 'dummy.html'View.as_view build_request '/'
def validate_review_groups form field u'review_groups' groups form.cleaned_data.get field [] local_site form.cleaned_data[u'local_site']for group in groups if group.local_site ! local_site raise ValidationError [ _ u'Thereviewgroup%sdoesnotexist.' % group.name ] return groups
def data_to_graph6 data if len data > 0 and min data < 0 or max data > 63 raise NetworkXError 'graph6dataunitsmustbewithin0..63' return ''.join [chr d + 63 for d in data]
def parse_qs qs keep_blank_values False strict_parsing False encoding 'utf-8' errors 'replace' dict {}pairs parse_qsl qs keep_blank_values strict_parsing encoding encoding errors errors for name value in pairs if name in dict dict[name].append value else dict[name] [value]return dict
def fs_relpath_from_url_path url_path url_path unquote url_path if sys.platform 'win32' and len url_path url_path url_path.replace '/' '\\' return url_path
def _update_return_dict ret success data errors None warnings None errors [] if errors is None else errors warnings [] if warnings is None else warnings ret['success'] successret['data'].update data ret['errors'] ret['errors'] + errors ret['warnings'] ret['warnings'] + warnings return ret
def list_to_scope scope if isinstance scope unicode_type or scope is None return scopeelif isinstance scope set tuple list return u''.join [unicode_type s for s in scope] else raise ValueError u'Invalidscope %s mustbestring tuple set orlist.' % scope
def dupAssemblies num for i in xrange num createAssembly 'DUP' + str i '' i
def movorder x order 'med' windsize 3 lag 'lagged' if lag 'lagged' lead windsize // 2 elif lag 'centered' lead 0elif lag 'leading' lead - windsize // 2 + 1 else raise ValueErrorif np.isfinite order True ord orderelif order 'med' ord windsize - 1 / 2 elif order 'min' ord 0elif order 'max' ord windsize - 1 else raise ValueErrorxext expandarr x windsize return signal.order_filter xext np.ones windsize ord [ windsize - lead - windsize + lead ]
def parse_token_contents parser token bits token.split_contents tag bits.pop 0 args []kwargs {}asvar Noneif len bits > 2 and bits[ -2 ] u'as' asvar bits[ -1 ]bits bits[ -2 ]if len bits for bit in bits match kwarg_re.match bit if not match raise TemplateSyntaxError u'Malformedargumentstotag"{}"'.format tag name value match.groups if name kwargs[name] parser.compile_filter value else args.append parser.compile_filter value return {u'tag' tag u'args' args u'kwargs' kwargs u'asvar' asvar}
def _reset_http_connections http if getattr http 'connections' None for conn_key in list http.connections.keys if ' ' in conn_key del http.connections[conn_key]
def has_mne_c return 'MNE_ROOT' in os.environ
def _on_walk_error err log.error '%s %s' err.filename err.strerror
def copy_func f name None return types.FunctionType six.get_function_code f six.get_function_globals f name or f.__name__ six.get_function_defaults f six.get_function_closure f
def upper_keys dictionary return dict k.upper v for k v in dictionary.items
def fireplace_route path name None kwargs {}if name kwargs['name'] namereturn url '^%s$' % path views.commonplace {'repo' 'fireplace'} **kwargs
def brier_score_loss y_true y_prob sample_weight None pos_label None y_true column_or_1d y_true y_prob column_or_1d y_prob assert_all_finite y_true assert_all_finite y_prob if pos_label is None pos_label y_true.max y_true np.array y_true pos_label int y_true _check_binary_probabilistic_predictions y_true y_prob return np.average y_true - y_prob ** 2 weights sample_weight
def _temp_exists method ip _type method.replace 'temp' '' .upper cmd "csf-t|awk-vcode 1-vtype _type-vip ip'$1 type&&$2 ip{{code 0}}END{{exitcode}}'".format _type _type ip ip exists __salt__['cmd.run_all'] cmd return not bool exists['retcode']
def _to_micros dur if hasattr dur 'total_seconds' return int dur.total_seconds * 1000000.0 return dur.microseconds + dur.seconds + dur.days * 24 * 3600 * 1000000
@register_canonicalize@register_specialize@gof.local_optimizer [T.ScalarFromTensor] def local_scalar_tensor_scalar node if isinstance node.op T.ScalarFromTensor t node.inputs[0]if t.owner and isinstance t.owner.op T.TensorFromScalar s t.owner.inputs[0]return [s]
def set_image_opacity img alpha 0.5 return imageops.set_opacity image_from_data img alpha
def CustomConfigDefault pass
def FromFile f more_formatters lambda x None _constructor None _constructor _constructor or Template options {}while 1 line f.readline match _OPTION_RE.match line if match name value match.group 1 match.group 2 name name.lower if name in _OPTION_NAMES name name.replace '-' '_' value value.strip if name 'default_formatter' and value.lower 'none' value Noneoptions[name] valueelse breakelse breakif options if line.strip raise CompilationError 'Mustbeoneblanklinebetweentemplateoptionsandbody got%r ' % line body f.read else body line + f.read return _constructor body more_formatters more_formatters **options
def probe_from_definition definition types if definition.get '__ignore__' False return ''elif len definition['args'] 0 return return_probe_from_definition definition types else entry_probe entry_probe_from_definition definition return_probe return_probe_from_definition definition types return entry_probe + return_probe
def convert_to_bytes string factors {'K' 1024 'M' 1024 * 1024 'G' 1024 * 1024 * 1024 'T' 1024 * 1024 * 1024 * 1024 'P' 1024 * 1024 * 1024 * 1024 * 1024 'E' 1024 * 1024 * 1024 * 1024 * 1024 * 1024 }for f fm in factors.items if string.endswith f number float string[ -1 ] number number * fm return long number return long string
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
def setup_app_for_worker app loglevel logfile app.finalize app.set_current app.set_default type app.log ._setup Falseapp.log.setup loglevel loglevel logfile logfile
def Vectorize v if operator.isSequenceType v v DirectX.Vector3 System.Single v[0] System.Single v[1] System.Single v[2] return v
@command 'set\\s+ [-\\w]+ \\s* .* ' def setconfig key val key key.replace '-' '_' if key.upper 'ALL' and val.upper 'DEFAULT' for ci in config config[ci].value config[ci].defaultconfig.save message 'Defaultconfigurationreinstated'elif not key.upper in config message 'Unknownconfigitem %s%s%s' % c.r key c.w elif val.upper 'DEFAULT' att config[key.upper ]att.value att.defaultmessage '%s%s%ssetto%s%s%s default 'dispval att.display or 'None' message message % c.y key c.w c.y dispval c.w config.save else message config[key.upper ].set val showconfig g.message message
def get_metadata headers return dict k v for k v in headers.iteritems if k.startswith 'x-goog-meta-'
@csrf_exempt@login_required@require_POSTdef draft_revision request draft_form DraftRevisionForm request.POST if draft_form.is_valid draft_form.save request request return HttpResponse status 201 return HttpResponseBadRequest
def create_event name message_type routing_key 'everyone' **kwargs ret {'name' name 'changes' {} 'result' None 'comment' ''}if __opts__['test'] ret['comment'] 'Needtocreateevent {0}'.format name return retres __salt__['victorops.create_event'] message_type message_type routing_key routing_key **kwargs if res['result'] 'success' ret['result'] Trueret['comment'] 'Createdevent {0}forentity{1}'.format name res['entity_id'] else ret['result'] Falseret['comment'] 'Failedtocreateevent {0}'.format res['message'] return ret
def _parse_scram_response response return dict item.split ' ' 1 for item in response.split ' '
def _add_kind one if one['ctfkind'] int '47314252' 16 one['kind'] 1elif one['ctfkind'] int '47324252' 16 one['kind'] 2elif one['ctfkind'] int '47334252' 16 one['kind'] 3else one['kind'] int one['ctfkind']
def envs ignore_cache False if not ignore_cache env_cache os.path.join __opts__['cachedir'] 'hgfs/envs.p' cache_match salt.fileserver.check_env_cache __opts__ env_cache if cache_match is not None return cache_matchret set for repo in init repo['repo'].open if repo['branch_method'] in 'branches' 'mixed' for branch in _all_branches repo['repo'] branch_name branch[0]if branch_name repo['base'] branch_name 'base'ret.add branch_name if repo['branch_method'] in 'bookmarks' 'mixed' for bookmark in _all_bookmarks repo['repo'] bookmark_name bookmark[0]if bookmark_name repo['base'] bookmark_name 'base'ret.add bookmark_name ret.update [x[0] for x in _all_tags repo['repo'] ] repo['repo'].close return [x for x in sorted ret if _env_is_exposed x ]
def elimination_matrix n vech_indices vec np.tril np.ones n n return np.eye n * n [ vech_indices ! 0 ]
def _testConfig baseParams expMissingMin 0 expMissingMax 0 **mods params dict baseParams params.update mods func params['seqFunction'] numCols trainingSequences func **params if params['numCols'] is None params['numCols'] numColstps createTPs **params tpStats evalSequences tps tps trainingSequences trainingSequences testSequences None **params for name stats in tpStats.iteritems print 'Detected%dmissingpredictionsoverallduringinference' % stats['totalMissing'] if expMissingMin is not None and stats['totalMissing'] < expMissingMin print 'FAILURE Expectedatleast%dtotalmissingbutgot%d' % expMissingMin stats['totalMissing'] assert Falseif expMissingMax is not None and stats['totalMissing'] > expMissingMax print 'FAILURE Expectedatmost%dtotalmissingbutgot%d' % expMissingMax stats['totalMissing'] assert Falsereturn True
def find_ref_chain obj predicate max_depth 20 extra_ignore return _find_chain obj predicate gc.get_referents max_depth max_depth extra_ignore extra_ignore [ -1 ]
@gof.local_optimizer [SparseBlockGemv] inplace True def local_inplace_sparse_block_gemv node if isinstance node.op SparseBlockGemv and not node.op.inplace new_node sparse_block_gemv_inplace *node.inputs copy_stack_trace node.outputs[0] new_node return [new_node]return False
def has_isoinfo return has_userland_tool 'isoinfo'
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def CMO ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.CMO timeperiod
def volume_attach context values return IMPL.volume_attach context values
def cross_domain_config func feature_flag_decorator patch.dict settings.FEATURES {'ENABLE_CORS_HEADERS' True 'ENABLE_CROSS_DOMAIN_CSRF_COOKIE' True} settings_decorator override_settings CORS_ORIGIN_WHITELIST ['www.edx.org'] CROSS_DOMAIN_CSRF_COOKIE_NAME 'prod-edx-csrftoken' CROSS_DOMAIN_CSRF_COOKIE_DOMAIN '.edx.org' is_secure_decorator patch.object WSGIRequest 'is_secure' return_value True return feature_flag_decorator settings_decorator is_secure_decorator func
def arcsech val return numpy.arccosh 1.0 / val
def final_status statuses return sorted statuses key itemgetter 'updated_at' [ -1 ]
def find_on_path targets if sabnzbd.WIN32 paths os.getenv 'PATH' .split ';' else paths os.getenv 'PATH' .split ' ' if isinstance targets basestring targets targets for path in paths for target in targets target_path os.path.abspath os.path.join path target if os.path.isfile target_path and os.access target_path os.X_OK return target_pathreturn None
def test_module_level_skip_error testdir testdir.makepyfile '\nimportpytest\n@pytest.skip\ndeftest_func \nassertTrue\n' result testdir.runpytest result.stdout.fnmatch_lines '*Usingpytest.skipoutsideofatestisnotallowed*'
def proxying_engine conn_cls DBAPIProxyConnection cursor_cls DBAPIProxyCursor def mock_conn return conn_cls config.db cursor_cls return testing_engine options {'creator' mock_conn}
def response resp return [{'url' '' 'title' '' 'content' ''}]
def GetUnregisterServerKeys clsid progID None verProgID None customKeys None ret [ 'CLSID\\%s' % str clsid win32con.HKEY_CLASSES_ROOT ]if verProgID ret.append verProgID win32con.HKEY_CLASSES_ROOT if progID ret.append progID win32con.HKEY_CLASSES_ROOT ret.append 'AppID\\%s' % str clsid win32con.HKEY_CLASSES_ROOT if customKeys ret ret + customKeys return ret
def getPacFiles pacFiles []if sys.platform 'win32' try import _winreg as winregexcept ImportError import winregnet winreg.OpenKey winreg.HKEY_CURRENT_USER 'Software\\Microsoft\\Windows\\CurrentVersion\\InternetSettings' nSubs nVals lastMod winreg.QueryInfoKey net subkeys {}for i in range nVals thisName thisVal thisType winreg.EnumValue net i subkeys[thisName] thisValif 'AutoConfigURL' in subkeys.keys and len subkeys['AutoConfigURL'] > 0 pacFiles.append subkeys['AutoConfigURL'] elif sys.platform 'darwin' import plistlibsysPrefs plistlib.readPlist '/Library/Preferences/SystemConfiguration/preferences.plist' networks sysPrefs['NetworkServices']for network in networks.items netKey network networkif 'ProxyAutoConfigURLString' in network['Proxies'].keys pacFiles.append network['Proxies']['ProxyAutoConfigURLString'] return list set pacFiles
def start_interactive_mode result debuggers result.debuggersdescrs result.error_descrs + result.fail_descrs if len debuggers 1 debuggers[0].start else while True testindex 0print 'Chooseatesttodebug ' print '\n'.join [ ' DCTB %s %s' % i descr for i _ descr in enumerate descrs ] print "Type'exit' or^D toquit" print try todebug input 'Enteratestname ' if todebug.strip .lower 'exit' print breakelse try testindex int todebug debugger debuggers[descrs[testindex][0]]except ValueError IndexError print 'ERROR invalidtestnumber%r' % todebug else debugger.start except EOFError KeyboardInterrupt print break
def task_install_api_certificates api_cert api_key return sequence [run 'mkdir-p/etc/flocker' run 'chmodu rwX g o /etc/flocker' put path '/etc/flocker/plugin.crt' content api_cert.getContent put path '/etc/flocker/plugin.key' content api_key.getContent log_content_filter _remove_private_key ]
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def epost db **keywds cgi 'https //eutils.ncbi.nlm.nih.gov/entrez/eutils/epost.fcgi'variables {'db' db}variables.update keywds return _open cgi variables post True
def get_cohort_id user course_key use_cached False cohort get_cohort user course_key use_cached use_cached return None if cohort is None else cohort.id
def generate_settings dev False context {'secret_key' generate_secret_key 'debug_flag' dev 'mail.backend' 'console' if dev else 'smtp' }py load_config_template DEFAULT_SETTINGS_OVERRIDE 'default' % context yaml load_config_template DEFAULT_SETTINGS_CONF 'default' % context return py yaml
def json_encode value return json.dumps value .replace '</' '<\\/'
def create_gs_thumbnail layer overwrite False params {'layers' layer.typename.encode 'utf-8' 'format' 'image/png8' 'width' 200 'height' 150 'TIME' '-99999999999-01-01T00 00 00.0Z/99999999999-01-01T00 00 00.0Z'}if None not in layer.bbox params['bbox'] layer.bbox_stringp '&'.join '%s %s' % item for item in params.items thumbnail_remote_url ogc_server_settings.PUBLIC_LOCATION + 'wms/reflect?' + p thumbnail_create_url ogc_server_settings.LOCATION + 'wms/reflect?' + p create_thumbnail layer thumbnail_remote_url thumbnail_create_url ogc_client http_client overwrite overwrite
def compile_fnclex context codegen context.codegen library codegen.create_library 'kb982107' ir_mod '\ndefinevoid@fnclex {\ncallvoidasmsideeffect"fnclex" "" \nretvoid\n}\n'll.initialize_native_asmparser library.add_llvm_module ll.parse_assembly ir_mod library.finalize return library
def resolve_allowed_tags model_obj tags_curr tags_new request_user AnonymousUser ns_tags_curr parse_tag_namespaces tags_curr ns_tags_new parse_tag_namespaces tags_new all_ns set ns_tags_curr.keys + ns_tags_new.keys tags_out []for ns in all_ns if model_obj.allows_tag_namespace_for ns request_user if ns in ns_tags_new tags_out.extend ns_tags_new[ns] elif ns in ns_tags_curr tags_out.extend ns_tags_curr[ns] return tags_out
def _nmeaFloat degrees minutes return '%i%0.3f' % degrees minutes
def _ChunkFactory chunk_type stream_rdr offset chunk_cls_map {PNG_CHUNK_TYPE.IHDR _IHDRChunk PNG_CHUNK_TYPE.pHYs _pHYsChunk}chunk_cls chunk_cls_map.get chunk_type _Chunk return chunk_cls.from_offset chunk_type stream_rdr offset
@functools.lru_cache maxsize None def is_language_prefix_patterns_used urlconf for url_pattern in get_resolver urlconf .url_patterns if isinstance url_pattern LocaleRegexURLResolver return True url_pattern.prefix_default_language return False False
def semanage_port_get_ports seport setype proto records seport.get_all_by_type if setype proto in records return records[ setype proto ]else return []
def jobconf_from_env variable default None name variable.replace '.' '_' if name in os.environ return os.environ[name]for var in _JOBCONF_MAP.get variable {} .values name var.replace '.' '_' if name in os.environ return os.environ[name]return default
def _archive_package_sources package sources sources_dir manifest []for s in sources f str s if f.startswith sources_dir path os.path.relpath f sources_dir else path os.path.basename f package f path manifest.append '%s%s' % s.get_csig path return manifest
def getPreferenceColour name colorString getPreference name return [ float int colorString[1 3] 16 / 255 float int colorString[3 5] 16 / 255 float int colorString[5 7] 16 / 255 1.0]
def handle_sigusr1 signal_number stack_frame handlers logging.getLoggerClass .manager.root.handlersreopen_log_files handlers handlers
@event u'manager.db_cleanup' def db_cleanup manager session existing_tasks list manager.tasks + [None] session.query SimpleKeyValue .filter ~ SimpleKeyValue.task.in_ existing_tasks .delete synchronize_session False
def key_to_cmp key def key_cmp a b return cmp key a key b return key_cmp
def fnmatch_all names patterns for name in names matches Falsefor pattern in patterns matches fnmatch.fnmatch name pattern if matches breakif not matches return Falsereturn True
def setup_ssl_options config_dir src dest option_path os.path.join config_dir dest shutil.copyfile src option_path return option_path
@pytest.mark.parametrize 'i' range len ITEMS def test_valid objects i assert objects.history.itemAt i .isValid
def get_cohort_by_name course_key name return CourseUserGroup.objects.get course_id course_key group_type CourseUserGroup.COHORT name name
def allowed uid global votersfor _uid _timestamp in voters.items if time.time - _timestamp > TIME_LIMIT del voters[_uid]if uid in voters last_voted voters[uid]return False timeformat.time_until last_voted now time.time - TIME_LIMIT else voters[uid] time.time return True 0
def _item_to_subscription_for_topic iterator subscription_path subscription_name subscription_name_from_path subscription_path iterator.client.project return Subscription subscription_name iterator.topic
def auth_sub_string_from_body http_body for response_line in http_body.splitlines if response_line.startswith 'Token ' return response_line[6 ]return None
def test_iht_fit_sample_gradient_boosting est 'gradient-boosting'iht InstanceHardnessThreshold est random_state RND_SEED X_resampled y_resampled iht.fit_sample X Y X_gt np.array [[ -0.3879569 0.6894251] [ -0.09322739 1.28177189] [ -0.77740357 0.74097941] [0.91542919 -0.65453327 ] [ -0.43877303 1.07366684] [ -0.85795321 0.82980738] [ -0.18430329 0.52328473] [ -0.65571327 0.42412021] [ -0.28305528 0.30284991] [1.06446472 -1.09279772 ] [0.30543283 -0.02589502 ] [ -0.00717161 0.00318087]] y_gt np.array [0 1 1 0 1 1 1 0 1 0 0 0] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def _get_spec tree_base spec template saltenv 'base' spec_tgt os.path.basename spec dest os.path.join tree_base 'SPECS' spec_tgt return __salt__['cp.get_url'] spec dest saltenv saltenv
def metadef_tag_count context namespace_name session None session session or get_session return metadef_tag_api.count context namespace_name session
@auth.s3_requires_membership 1 def ticket import tracebackfrom gluon.restricted import RestrictedErrorif len request.args ! 2 session.error T 'Invalidticket' redirect URL r request app request.args[0]ticket request.args[1]e RestrictedError e.load request app ticket return dict app app ticket ticket traceback s3base.Traceback e.traceback code e.code layer e.layer
def minkowski_distance x y p 2 x np.asarray x y np.asarray y if p np.inf or p 1 return minkowski_distance_p x y p else return minkowski_distance_p x y p ** 1.0 / p
def _substitute_bcc raw_message bcc_regexp re.compile '^Bcc [^\\r\\n]*\\r\\n' re.IGNORECASE | re.MULTILINE return bcc_regexp.sub '' raw_message
def iter_tracebacks logdir crash_files sorted glob op.join logdir '*.pkl*' for cf in crash_files yield cf load_pklz_traceback cf
def requireAttrs obj *attributes missing [name for name in attributes if not hasattr obj name ]return skipWithClientIf missing "don'thave" + ' '.join name for name in missing
def _update_epoch_data params start params['t_start']n_epochs params['n_epochs']end start + n_epochs * len params['epochs'].times data params['orig_data'][ start end]types params['types']for pick ind in enumerate params['inds'] params['data'][pick] data[ind] / params['scalings'][types[pick]] params['plot_fun']
def sort_nicely l l.sort key alphanum_key
def get_zonecode return salt.utils.mac_utils.execute_return_result 'date+%Z'
def add_node node visit_function None depart_function None docutils.nodes._add_node_class_names [node.__name__] if visit_function setattr docutils.writers.html4css1.HTMLTranslator u'visit_' + node.__name__ visit_function if depart_function setattr docutils.writers.html4css1.HTMLTranslator u'depart_' + node.__name__ depart_function
def _parse_update_data topic data parts topic.split '/' room parts[ -1 ]device_id slugify data.get ATTR_ID .upper distance data.get 'distance' parsed_data {ATTR_DEVICE_ID device_id ATTR_ROOM room ATTR_DISTANCE distance}return parsed_data
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def snapshot_get_all_for_volume context volume_id return IMPL.snapshot_get_all_for_volume context volume_id
def parallel_pick_otus_trie_process_run_results_f f lines list f basic_process_run_results_f [lines[1]] try basic_process_run_results_f [lines[2]] basic_process_run_results_f [lines[3]] except IndexError passfields lines[0].strip .split infiles_list fields[ -1 ]out_filepath fields[ -1 ]try of open out_filepath 'w' except IOError raise IOError "Pollercan'topenfinaloutputfile %s" % out_filepath + '\nLeavingindividualjobsoutput.\nDoyouhavewriteaccess?' unique_otu_map {}otu_id 0for fp in infiles_list for line in open fp fields line.strip .split of.write ' DCTB '.join [ '%d' % otu_id ] + fields[1 ] of.write '\n' otu_id + 1of.close return True
def get_prompt_tokens cli now datetime.datetime.now return [ Token.Prompt u'%s %s %s' % now.hour now.minute now.second Token.Prompt u'Entersomething ' ]
def inside_gamut r g b return r > 0 and g > 0 and b > 0
def update_scene_exceptions indexer_id scene_exceptions season -1 [sickrage.srCore.cacheDB.db.delete x[u'doc'] for x in sickrage.srCore.cacheDB.db.get_many u'scene_exceptions' indexer_id with_doc True if x[u'doc'][u'season'] season ]sickrage.srCore.srLogger.info u'Updatingsceneexceptions' if indexer_id in exceptionsCache exceptionsCache[indexer_id] {}exceptionsCache[indexer_id][season] scene_exceptionsfor cur_exception in scene_exceptions sickrage.srCore.cacheDB.db.insert {u'_t' u'scene_exceptions' u'indexer_id' indexer_id u'show_name' cur_exception u'season' season}
def get_info_file filename data ''errors re.compile '\\b error|fail|failed \\b' re.IGNORECASE if os.path.isfile filename f open '%s' % filename 'r' lines f.readlines f.close rx re.compile ' \'|" ' for line in lines new_line rx.sub '' line errors_found errors.findall new_line if len errors_found > 0 data + '<fontcolor red>%s</font><br>' % str new_line else data + '%s<br>' % str new_line if not data data 'NoInformationFound.<br>'else data 'Filenotfound.<br>'return data
def facility_geojson s3db.org_facility_geojson
def _chunk_write chunk local_file progress local_file.write chunk progress.update_with_increment_value len chunk
def eigvals_banded a_band lower False overwrite_a_band False select 'a' select_range None check_finite True return eig_banded a_band lower lower eigvals_only 1 overwrite_a_band overwrite_a_band select select select_range select_range check_finite check_finite
def hrm_training_organisation row try person_id row.hrm_training.person_idexcept AttributeError person_id Noneif person_id s3db current.s3dbtable s3db.hrm_human_resourcequery table.person_id person_id & table.status ! 2 orgs current.db query .select table.organisation_id distinct True if orgs output ''represent s3db.org_OrganisationRepresent for org in orgs repr represent org.organisation_id if output output '%s %s' % output repr else output reprreturn outputreturn current.messages['NONE']
def message_question text title informative_text None details None buttons None default_button None exc_info False parent None return message QMessageBox.Question text title informative_text details buttons default_button exc_info parent
@constructordef argmin x axis None keepdims False x as_tensor_variable x str_x_type str x.dtype if str_x_type.startswith 'float' or str_x_type in int_dtypes return argmax - x axis axis keepdims keepdims else raise NotImplementedError
def _find_review_request_object review_request_id local_site q ReviewRequest.objects.all if local_site q q.filter local_site local_site local_id review_request_id else q q.filter pk review_request_id try q q.select_related u'submitter' u'repository' return q.get except ReviewRequest.DoesNotExist raise Http404
def _get_site_profile self local_site if not hasattr self u'_site_profiles' self._site_profiles {}if local_site.pk not in self._site_profiles site_profile LocalSiteProfile.objects.get user self local_site local_site site_profile.user selfsite_profile.local_site local_siteself._site_profiles[local_site.pk] site_profilereturn self._site_profiles[local_site.pk]
def generate_clone_url_for_installed_repository app repository tool_shed_url get_tool_shed_url_from_tool_shed_registry app str repository.tool_shed return util.build_url tool_shed_url pathspec ['repos' str repository.owner str repository.name ]
def list_rooms api_url None api_key None api_version None foo _query function 'rooms' api_url api_url api_key api_key api_version api_version log.debug 'foo{0}'.format foo return foo
def system_info return cmd 'system_info'
@pytest.fixture def default_groups database return create_default_groups
def rand_sleep max 60 time.sleep random.randint 0 max return True
def create_python27_stop_cmd port stop_cmd '/usr/bin/python2{0}/scripts/stop_service.pydev_appserver.py{1}'.format constants.APPSCALE_HOME port return stop_cmd
def join_urls *urls if not urls returnurl urls[0]for u in urls[1 ] if not url.endswith '/' url + '/'while u.startswith '/' u utils.lstrips u '/' url + ureturn url
def selfSimilarityMatrix featureVectors [nDims nVectors] featureVectors.shape[featureVectors2 MEAN STD] aT.normalizeFeatures [featureVectors.T] featureVectors2 featureVectors2[0].TS 1.0 - distance.squareform distance.pdist featureVectors2.T 'cosine' return S
def tanm A A _asarray_square A return _maybe_real A solve cosm A sinm A
def _run_on_all_nodes nodes task return parallel list run_remotely username 'root' address node.address commands task node for node in nodes
def normaltest a axis 0 a axis _chk_asarray a axis s _ skewtest a axis k _ kurtosistest a axis k2 s * s + k * k return NormaltestResult k2 distributions.chi2.sf k2 2
def path_to_slug path from mezzanine.urls import PAGES_SLUGlang_code translation.get_language_from_path path for prefix in lang_code settings.SITE_PREFIX PAGES_SLUG if prefix path path.replace prefix u'' 1 return clean_slashes path or u'/'
def zpickle data return zlib.compress pickle.dumps data pickle.HIGHEST_PROTOCOL
def image_resize_images vals big_name 'image' medium_name 'image_medium' small_name 'image_small' if big_name in vals vals.update image_get_resized_images vals[big_name] return_big True return_medium True return_small True big_name big_name medium_name medium_name small_name small_name avoid_resize_big True avoid_resize_medium False avoid_resize_small False elif medium_name in vals vals.update image_get_resized_images vals[medium_name] return_big True return_medium True return_small True big_name big_name medium_name medium_name small_name small_name avoid_resize_big True avoid_resize_medium True avoid_resize_small False elif small_name in vals vals.update image_get_resized_images vals[small_name] return_big True return_medium True return_small True big_name big_name medium_name medium_name small_name small_name avoid_resize_big True avoid_resize_medium True avoid_resize_small True
def heappushpop heap item if heap and cmp_lt heap[0] item item heap[0] heap[0] item _siftup heap 0 return item
def F1 classify lambda document False documents [] average None return test classify documents average [3]
def test_one_dot line Line line.add 'onedot' [12] line.x_labels ['one']q line.render_pyquery assert len q '.axis.x' 1 assert len q '.axis.y' 1 assert len q '.y.axis.guides' 1
def org_service_root_service service_id db current.dbtable current.s3db.org_servicerecord db table.id service_id .select table.id table.root_service table.parent .first try parent record.parentcurrent_root record.root_serviceexcept AttributeError current.log.error 'Cannotfindrecordwithservice_id %s' % service_id raiseif parent if parent service_id raise KeyError 'Service#%sshowingwithparent#%s' % service_id parent new_root org_service_root_service parent else new_root service_idif current_root ! new_root def descendants ids rows db table.parent.belongs ids .select table.id children set row.id for row in rows if children children | descendants children return ids | children else return idsnodes descendants set [service_id] db table.id.belongs nodes .update root_service new_root return new_root
def get_sysprefix return run "condainfo-s|grep-e'sys.prefix'|awk'{print$2}'"
def CheckForMultilineCommentsAndStrings filename clean_lines linenum error line clean_lines.elided[linenum]line line.replace '\\\\' '' if line.count '/*' > line.count '*/' error filename linenum 'readability/multiline_comment' 5 'Complexmulti-line/*...*/-stylecommentfound.Lintmaygiveboguswarnings.Considerreplacingthesewith//-stylecomments with#if0...#endif orwithmoreclearlystructuredmulti-linecomments.' if line.count '"' - line.count '\\"' % 2 error filename linenum 'readability/multiline_string' 5 'Multi-linestring "..." found.Thislintscriptdoesn\'tdowellwithsuchstrings andmaygiveboguswarnings.UseC++11rawstringsorconcatenationinstead.'
def gf_mul f g p K df gf_degree f dg gf_degree g dh df + dg h [0] * dh + 1 for i in range 0 dh + 1 coeff K.zerofor j in range max 0 i - dg min i df + 1 coeff + f[j] * g[ i - j ] h[i] coeff % p return gf_strip h
def provides_csp_features response return len retrieve_csp_policies response + len retrieve_csp_policies response True > 0
def Clean cwd os.path.dirname os.path.abspath __file__ for root _ files in os.walk cwd for filename in files full_filename os.path.join root filename if full_filename.endswith '_pb2.py' or full_filename.endswith '_pb2.pyc' os.unlink full_filename
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
def get_registered_trophy_types warnings.warn u'get_registered_trophy_types isdeprecated.Pleaseiteratethroughreviewboard.accounts.trophies trophies_registryinstead.' DeprecationWarning return {trophy.category trophy for trophy in trophies_registry}
def _different difference_tuple if difference_tuple member1 member2 difference_tuplereturn member1 ! member2 else return False
def whitelist_check path left path.dirnamelast_left Nonemodule_path path.purebasenamewhile len left and left ! last_left last_left left left tail os.path.split left module_path u'.'.join [tail module_path] if module_path in default_test_modules return Falsereturn True
def find_difference string1 string2 assert len string1 + 1 len string2 char_array list string2 for char in string1 ind char_array.index char char_array.pop ind return char_array[0]
def _get_all_packages mirror DEFAULT_MIRROR cyg_arch 'x86_64' if 'cyg.all_packages' not in __context__ __context__['cyg.all_packages'] {}if mirror not in __context__['cyg.all_packages'] __context__['cyg.all_packages'][mirror] []if not len __context__['cyg.all_packages'][mirror] pkg_source '/'.join [mirror cyg_arch 'setup.bz2'] file_data _urlopen pkg_source .read file_lines bz2.decompress file_data .decode 'utf_8' errors 'replace' .splitlines packages [re.search '^@ [^]+ ' line .group 1 for line in file_lines if re.match '^@[^]+' line ]__context__['cyg.all_packages'][mirror] packagesreturn __context__['cyg.all_packages'][mirror]
@step u'Iinputananswerona" [^"]* "problem" [^"]* ly"' def input_problem_answer _ problem_type correctness assert correctness in ['correct' 'incorrect'] assert problem_type in PROBLEM_DICT answer_problem world.scenario_dict['COURSE'].number problem_type correctness
def get_easy_s3 config_file None cache False cfg get_config config_file cache return cfg.get_easy_s3
def prefix handlers default None error 'Therequestedprefixdoesnotmatchanyofthoseallowed' def output_type data request response path request.pathhandler defaultfor prefix_test prefix_handler in handlers.items if path.startswith prefix_test handler prefix_handlerbreakif not handler raise falcon.HTTPNotAcceptable error response.content_type handler.content_typereturn handler data request request response response output_type.__doc__ 'Supportsanyofthefollowingformats {0}'.format ' '.join function.__doc__ for function in handlers.values output_type.content_type ' '.join handlers.keys return output_type
def mock_tab_from_json tab_dict return tab_dict
def html_doctype_matches text return doctype_matches text 'html\\s+PUBLIC\\s+"-//W3C//DTDX?HTML.*'
def validate_pack_name name if not name raise ValueError 'Contentpacknamecannotbeempty' if name.lower in USER_PACK_NAME_BLACKLIST raise ValueError 'Name"%s"isblacklistedandcan\'tbeused' % name.lower return name
@when u'weinsertintotable' def step_insert_into_table context context.cli.sendline u"insertintoa x values 'xxx' ;"
def get_sql_reset app return get_sql_delete app + get_sql_all app
def repeat_func func *args **kwargs if kwargs return starmap lambda args kwargs func *args **kwargs repeat args kwargs else return starmap func repeat args
def connect_mailchimp api_key mailchimp MailSnake api_key result mailchimp.ping log.debug result return mailchimp
def default_size parent width height if parent is not None width parent.width height parent.height return width height
def install_locally mobsf_home local_config mobsf_home read_config rewrite_config create_folders tools_nuget tools_binskim tools_binscope _place_lockfile mobsf_home
def _schema_builder urn_nid method attributes soap ET.Element 'soap Body' {'xmlns m' 'https //durabledns.com/services/dns/%s' % method } urn ET.SubElement soap 'urn %s %s' % urn_nid method for attribute in attributes ET.SubElement urn 'urn %s %s' % urn_nid attribute return soap
def formatStatResponse msgs i 0bytes 0for size in msgs i + 1bytes + size yield None yield successResponse '%d%d' % i bytes
def _convert_state state state state.lower if u'play' in state return u'play'if u'pause' in state return u'pause'if u'stop' in state return u'stop'return u'fallback'
def test_against_pyephem obstime Time u'2011-09-1808 50 00' location EarthLocation lon Angle u'-109d24m53.1s' lat Angle u'33d41m46.0s' height 30000.0 * u.m altaz_frame AltAz obstime obstime location location temperature 15 * u.deg_C pressure 1.01 * u.bar altaz SkyCoord u'6.8927d-60.7665d' frame altaz_frame radec_actual altaz.transform_to u'icrs' radec_expected SkyCoord u'196.497518d-4.569323d' frame u'icrs' distance radec_actual.separation radec_expected .to u'arcsec' assert distance < 1000.0 * u.arcsec radec_expected SkyCoord u'196.495372d-4.560694d' frame u'icrs' distance radec_actual.separation radec_expected .to u'arcsec' assert distance < 1 * u.arcsec
def deserialize_field field value try deserialized json.loads value if deserialized is None return deserializedtry field.from_json deserialized return deserializedexcept ValueError TypeError return valueexcept ValueError TypeError return value
def mask_hash hash show 6 char '*' masked hash[ show]masked + char * len hash[show ] return masked
def salt_main import salt.cli.saltif '' in sys.path sys.path.remove '' client salt.cli.salt.SaltCMD _install_signal_handlers client client.run
def ctype_to_model val if isinstance val dict and 'pk' in val and 'ctype' in val ctype ContentType.objects.get_for_id val['ctype'] ModelClass ctype.model_class val ModelClass.objects.get pk val['pk'] return val
def makeSetup **args distutils.core._setup_stop_after 'commandline'args.setdefault 'script_args' ['install'] try return setuptools.setup **args finally distutils.core_setup_stop_after None
def inlineCallbacks f def unwindGenerator *args **kwargs return _inlineCallbacks None f *args **kwargs Deferred return mergeFunctionMetadata f unwindGenerator
def clear_limit key limits get_limits to_clear [key] if isinstance key basestring else key for key in to_clear if key in limits del limits[key]update_site_config u'limits' limits validate False frappe.conf.limits limits
def assertLogMessage testCase expectedMessages callable *args **kwargs loggedMessages []log.addObserver loggedMessages.append testCase.addCleanup log.removeObserver loggedMessages.append callable *args **kwargs testCase.assertEqual [m['message'][0] for m in loggedMessages] expectedMessages
def LinGetRawDevice path device_map GetMountpoints path utils.SmartUnicode path mount_point path utils.NormalizePath path '/' result rdf_paths.PathSpec pathtype rdf_paths.PathSpec.PathType.OS while mount_point try result.path fs_type device_map[mount_point]if fs_type in ['ext2' 'ext3' 'ext4' 'vfat' 'ntfs'] result.pathtype rdf_paths.PathSpec.PathType.OSelse result.pathtype rdf_paths.PathSpec.PathType.UNSETpath utils.NormalizePath path[len mount_point ] result.mount_point mount_pointreturn result path except KeyError mount_point os.path.dirname mount_point
def RetryWithBackoff callable_func retry_notify_func initial_delay 1 backoff_factor 2 max_delay 60 max_tries 20 delay initial_delaynum_tries 0while True done opaque_value callable_func num_tries + 1if done return True opaque_value if num_tries > max_tries return False opaque_value retry_notify_func opaque_value delay time.sleep delay delay min delay * backoff_factor max_delay
def __resource_with_deleted self member_name collection_name **kwargs collection_path kwargs.get 'path_prefix' '' + '/' + collection_name + '/deleted' member_path collection_path + '/{id}' self.connect 'deleted_' + collection_name collection_path controller collection_name action 'index' deleted True conditions dict method ['GET'] self.connect 'deleted_' + member_name member_path controller collection_name action 'show' deleted True conditions dict method ['GET'] self.connect 'undelete_deleted_' + member_name member_path + '/undelete' controller collection_name action 'undelete' conditions dict method ['POST'] self.resource member_name collection_name **kwargs
def DumpLocalGroups path 'WinNT //%s computer' % local_name ob ADsGetObject path IID_IADsContainer ob.put_Filter ['Group'] for sub_ob in ob print 'Group %s %s ' % sub_ob.Name sub_ob.ADsPath members sub_ob.Members for member in members print 'Groupmember %s %s ' % member.Name member.ADsPath
def not_allowed func def inner self *args **kwargs raise NotImplementedError '%sisnotallowedon%sinstances' % func type self .__name__ return inner
def _get_private_key_obj private_key passphrase None private_key _text_or_file private_key private_key get_pem_entry private_key pem_type 'RSAPRIVATEKEY' rsaprivkey M2Crypto.RSA.load_key_string private_key callback _passphrase_callback passphrase evpprivkey M2Crypto.EVP.PKey evpprivkey.assign_rsa rsaprivkey return evpprivkey
def to_mlab_linkage Z Z np.asarray Z order 'c' dtype np.double Zs Z.shapeif len Zs 0 or len Zs 1 and Zs[0] 0 return Z.copy is_valid_linkage Z throw True name 'Z' ZP Z[ 0 3].copy ZP[ 0 2] + 1.0return ZP
def _blocked_elementwise func block_size 2 ** 20 def wrapper x if x.shape[0] < block_size return func x else y0 func x[ block_size] y np.zeros x.shape[0] + y0.shape[1 ] dtype y0.dtype y[ block_size] y0del y0for j in range block_size x.shape[0] block_size y[j j + block_size ] func x[j j + block_size ] return yreturn wrapper
def islink path try st os.lstat path except os.error AttributeError return Falsereturn stat.S_ISLNK st.st_mode
def getDotProductPlusOne firstComplex secondComplex return 1.0 + getDotProduct firstComplex secondComplex
def response_middleware api None def decorator middleware_method apply_to_api hug.API api if api else hug.api.from_object middleware_method class MiddlewareRouter object __slots__ def process_response self request response resource return middleware_method request response resource apply_to_api.http.add_middleware MiddlewareRouter return middleware_methodreturn decorator
def logmgf_exact q priv_eps l if q < 0.5 t_one 1 - q * math.pow 1 - q / 1 - math.exp priv_eps * q l t_two q * math.exp priv_eps * l t t_one + t_two try log_t math.log t except ValueError print 'GotValueErrorinmath.logforvalues ' + str q priv_eps l t log_t priv_eps * l else log_t priv_eps * l return min 0.5 * priv_eps * priv_eps * l * l + 1 log_t priv_eps * l
def lottery_promoted_links sr_names n 10 promo_tuples get_live_promotions sr_names weights {p p.weight or 0.001 for p in promo_tuples}selected []while weights and len selected < n s weighted_lottery weights del weights[s]selected.append s return selected
def enforce credentials action target do_raise True init extra {}if do_raise extra.update exc exception.ForbiddenAction action action do_raise do_raise return _ENFORCER.enforce action target credentials **extra
def _make_ellipse mean cov ax level 0.95 color None from matplotlib.patches import Ellipse v w np.linalg.eigh cov u w[0] / np.linalg.norm w[0] angle np.arctan u[1] / u[0] angle 180 * angle / np.pi v 2 * np.sqrt v * stats.chi2.ppf level 2 ell Ellipse mean[ 2] v[0] v[1] 180 + angle facecolor 'none' edgecolor color lw 1.5 ell.set_clip_box ax.bbox ell.set_alpha 0.5 ax.add_artist ell
def positive_int_list argument if ' ' in argument entries argument.split ' ' else entries argument.split return [positive_int entry for entry in entries]
def ToSentences paragraph include_token True s_gen SnippetGen paragraph SENTENCE_START SENTENCE_END include_token return [s for s in s_gen]
def _replace_newline obj if isinstance obj dict d dict for key val in list obj.items d[key] _replace_newline val return delif isinstance obj list l list for index entry in enumerate obj l + [_replace_newline entry ]return lelif isinstance obj six.string_types s obj.replace '\n' '<br>' if s ! obj warnings.warn "Lookslikeyouusedanewlinecharacter '\\n'.\n\nPlotlyusesasubsetofHTMLescapecharacters\ntodothingslikenewline <br> bold <b></b> \nitalics <i></i> etc.Yournewlinecharacters\nhavebeenconvertedto'<br>'sotheywillshow\nuprightonyourPlotlyfigure!" return selse return obj
def writable_preferred_server_selector selection return writable_server_selector selection or secondary_server_selector selection
def task_tag def prep r if r.method ! 'options' or r.representation ! 's3json' return Falsereturn Trues3.prep prepreturn s3_rest_controller
def stacked_value_added_taxes price taxes def money_sum iterable return sum iterable Money 0 price.currency if not taxes return TaxedPrice TaxfulPrice price TaxlessPrice price [] if price.includes_tax taxful pricerate_sum sum tax.rate for tax in taxes if tax.rate amount_sum money_sum tax.amount for tax in taxes if tax.amount taxless TaxlessPrice taxful.amount - amount_sum / 1 + rate_sum else taxful Nonetaxless priceline_taxes [SourceLineTax.from_tax tax tax base_amount taxless.amount for tax in taxes]if taxful is None total_tax_amount money_sum x.amount for x in line_taxes taxful TaxfulPrice taxless.amount + total_tax_amount return TaxedPrice taxful taxless line_taxes
def test_lambda_list_keywords_kwonly kwonly_demo u' fn[&kwonlya[b2]] printab 'if PY3 code can_compile kwonly_demo for i kwonlyarg_name in enumerate u'a' u'b' assert kwonlyarg_name code.body[0].args.kwonlyargs[i].arg assert code.body[0].args.kw_defaults[0] is None assert code.body[0].args.kw_defaults[1].n 2 else exception cant_compile kwonly_demo assert isinstance exception HyTypeError message exception.argsassert message u'keyword-onlyargumentsareonlyavailableunderPython3'
def cho_factor a lower False overwrite_a False check_finite True c lower _cholesky a lower lower overwrite_a overwrite_a clean False check_finite check_finite return c lower
def get_task_data task_id result AsyncResult task_id state info result.state result.info if state 'PENDING' raise TaskNotFound task_id if 'task_name' not in info raise TaskNotFound task_id try task celery_app.tasks[info['task_name']]except KeyError raise TaskNotFound task_id return task state info
def set_mindays name mindays pre_info info name if mindays pre_info['min'] return Truecmd 'chage-m{0}{1}'.format mindays name __salt__['cmd.run'] cmd python_shell False post_info info name if post_info['min'] ! pre_info['min'] return post_info['min'] mindays return False
def test_arg_of_sigmoid_good X T.matrix Y T.nnet.sigmoid X Z arg_of_sigmoid Y assert X is Z
def addLoop infillWidth infillPaths loop rotationPlaneAngle simplifiedLoop euclidean.getSimplifiedLoop loop infillWidth if len simplifiedLoop < 2 returnsimplifiedLoop.append simplifiedLoop[0] planeRotated euclidean.getPointsRoundZAxis rotationPlaneAngle simplifiedLoop infillPaths.append planeRotated
def ensure_list_from_str_or_list x lineno None col None return ast.IfExp test ast.Call func ast.Name id 'isinstance' ctx ast.Load lineno lineno col_offset col args [x ast.Name id 'str' ctx ast.Load lineno lineno col_offset col ] keywords [] starargs None kwargs None lineno lineno col_offset col body ast.List elts [x] ctx ast.Load lineno lineno col_offset col orelse x lineno lineno col_offset col
def user_from_str identifier try user_id int identifier except ValueError return User.objects.get email identifier return User.objects.get id user_id
def portCoerce value value int value if value < 0 or value > 65535 raise ValueError 'Portnumbernotinrange %s' % value return value
def _consolidate sets k G nx.Graph nodes {i s for i s in enumerate sets }G.add_nodes_from nodes G.add_edges_from u v for u v in combinations nodes 2 if len nodes[u] & nodes[v] > k for component in nx.connected_components G yield set.union *[nodes[n] for n in component]
def _udivisors n factorpows [ p ** e for p e in factorint n .items ]for i in range 2 ** len factorpows d j k 1 i 0 while j if j & 1 d * factorpows[k]j >> 1k + 1 yield d
def random_upper t return ''.join c.upper if random.random > 0.5 else c for c in t
def test_advinc_subtensor1 for shp in [ 3 3 3 3 3 ] shared cuda.shared_constructorxval numpy.arange numpy.prod shp dtype 'float32' .reshape shp + 1 yval numpy.empty 2 + shp[1 ] dtype 'float32' yval[ ] 10x shared xval name 'x' y T.tensor dtype 'float32' broadcastable False * len shp name 'y' expr T.advanced_inc_subtensor1 x y [0 2] f theano.function [y] expr mode mode_with_gpu assert sum [isinstance node.op cuda.GpuAdvancedIncSubtensor1 for node in f.maker.fgraph.toposort ] 1 rval f yval rep xval.copy rep[[0 2]] + yvalutt.assert_allclose rval rep
def _recode x levels from pandas import Seriesname Noneif isinstance x Series name x.namex x.valuesif x.dtype.type not in [np.str_ np.object_] raise ValueError 'Thisisnotacategorialfactor.Arrayofstrtyperequired.' elif not isinstance levels dict raise ValueError 'Thisisnotavalidvalueforlevels.Dictrequired.' elif not np.unique x np.unique list iterkeys levels .all raise ValueError 'Thelevelsdonotmatchthearrayvalues.' else out np.empty x.shape[0] dtype np.int for level coding in iteritems levels out[ x level ] codingif name out Series out out.name namereturn out
def CreateFeedItemAddOperation name price date adgroup_id ad_customizer_feed feed_item {'feedId' ad_customizer_feed['feedId'] 'adGroupTargeting' {'TargetingAdGroupId' adgroup_id} 'attributeValues' [{'feedAttributeId' ad_customizer_feed['feedAttributes'][0]['id'] 'stringValue' name} {'feedAttributeId' ad_customizer_feed['feedAttributes'][1]['id'] 'stringValue' price} {'feedAttributeId' ad_customizer_feed['feedAttributes'][2]['id'] 'stringValue' date}]}return {'operator' 'ADD' 'operand' feed_item}
def get_node_zones try file open buddyinfo_file 'r' except IOError return 0metrics {}for line in file metrics re.split '\\s+' line node_id metrics[1].replace ' ' '' zone metrics[3].lower zones.append 'node' + node_id + '_' + zone
def createBufferTexture texID texw texh gl.glActiveTexture gl.GL_TEXTURE0 gl.glBindTexture gl.GL_TEXTURE_2D texID black 0.0 0.0 0.0 0.0 gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_MIN_FILTER gl.GL_NEAREST gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_MAG_FILTER gl.GL_NEAREST gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_WRAP_S gl.GL_CLAMP_TO_EDGE gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_WRAP_T gl.GL_CLAMP_TO_EDGE gl.glTexParameterfv gl.GL_TEXTURE_2D gl.GL_TEXTURE_BORDER_COLOR black gl.glTexImage2D gl.GL_TEXTURE_2D 0 gl.GL_RGBA texw texh 0 gl.GL_RGBA gl.GL_UNSIGNED_BYTE '\x00' * texw * texh * 4 gl.glBindTexture gl.GL_TEXTURE_2D 0 checkGLError
def raw_arg *args **kwargs ret {'args' args 'kwargs' kwargs}return ret
def create_private_ip linode_id kwargs {'LinodeID' linode_id}result _query 'linode' 'ip.addprivate' args kwargs return _clean_data result
def test_make_sphere_model info read_info fname_raw assert_raises ValueError make_sphere_model 'foo' 'auto' info assert_raises ValueError make_sphere_model 'auto' 'auto' None assert_raises ValueError make_sphere_model 'auto' 'auto' info relative_radii sigmas assert_raises ValueError make_sphere_model 'auto' 'auto' info relative_radii 1 bem make_sphere_model 'auto' 'auto' info assert_true '3layers' in repr bem assert_true 'Sphere' in repr bem assert_true 'mm' in repr bem bem make_sphere_model 'auto' None info assert_true 'nolayers' in repr bem assert_true 'Sphere' in repr bem
def synchronous_switch_listener dbapi_conn connection_rec dbapi_conn.execute 'PRAGMAsynchronous OFF'
@lower_builtin 'setitem' types.Buffer types.Any types.Any def setitem_array context builder sig args aryty idxty valty sig.args ary idx val argsif isinstance idxty types.BaseTuple index_types idxty.typesindices cgutils.unpack_tuple builder idx count len idxty else index_types idxty indices idx ary make_array aryty context builder ary index_types indices normalize_indices context builder index_types indices try dataptr shapes strides basic_indexing context builder aryty ary index_types indices except NotImplementedError use_fancy_indexing Trueelse use_fancy_indexing bool shapes if use_fancy_indexing return fancy_setslice context builder sig args index_types indices val context.cast builder val valty aryty.dtype store_item context builder aryty val dataptr
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def linebreaks value from django.utils.html import linebreaksreturn linebreaks value
def split_train_test all_instances n None random.seed 12345 random.shuffle all_instances if not n or n > len all_instances n len all_instances train_set all_instances[ int 0.8 * n ]test_set all_instances[int 0.8 * n n]return train_set test_set
def _filter_apis name apis return [api for api in apis if api['name'] name ]
def copy_dedent source return lambda target dedent copy source target
def least_load registry xml_parent data least XML.SubElement xml_parent 'org.bstick12.jenkinsci.plugins.leastload.LeastLoadDisabledProperty' XML.SubElement least 'leastLoadDisabled' .text str data.get 'disabled' True .lower
def pure_complex v or_real False h t v.as_coeff_Add if not t if or_real return h t return c i t.as_coeff_Mul if i is S.ImaginaryUnit return h c
def tmin a lowerlimit None axis 0 inclusive True a axis _chk_asarray a axis am trima a lowerlimit None inclusive False return ma.minimum.reduce am axis
def addElementToPixelListFromPoint element pixelDictionary point addElementToPixelList element pixelDictionary int round point.real int round point.imag
def length_gte value arg return len value > int arg
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg 'console_type' metavar '<console-type>' help _ 'Typeofvncconsole "novnc"or"xvpvnc" .' def do_get_vnc_console cs args server _find_server cs args.server data server.get_vnc_console args.console_type print_console cs data
def check_clusterer_compute_labels_predict name Clusterer X y make_blobs n_samples 20 random_state 0 clusterer Clusterer if hasattr clusterer 'compute_labels' if hasattr clusterer 'random_state' clusterer.set_params random_state 0 X_pred1 clusterer.fit X .predict X clusterer.set_params compute_labels False X_pred2 clusterer.fit X .predict X assert_array_equal X_pred1 X_pred2
def lqn n z if not isscalar n and isscalar z raise ValueError 'argumentsmustbescalars.' if n ! floor n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n < 1 n1 1else n1 nif iscomplex z qn qd specfun.clqn n1 z else qn qd specfun.lqnb n1 z return qn[ n + 1 ] qd[ n + 1 ]
def rgba2rgb rgba background 1 1 1 arr _prepare_rgba_array rgba if isinstance background tuple and len background ! 3 raise ValueError 'thebackgroundmustbeatuplewith3items-theRGBcolorofthebackground.Got{0}items.'.format len background alpha arr[... -1 ]channels arr[... -1 ]out np.empty_like channels for ichan in range channels.shape[ -1 ] out[... ichan] np.clip 1 - alpha * background[ichan] + alpha * channels[... ichan] a_min 0 a_max 1 return out
def GetActiveObject Class clsctx pythoncom.CLSCTX_ALL resultCLSID pywintypes.IID Class dispatch pythoncom.GetActiveObject resultCLSID dispatch dispatch.QueryInterface pythoncom.IID_IDispatch return __WrapDispatch dispatch Class resultCLSID resultCLSID clsctx clsctx
def get_interface_config_commands interface intf existing commands []desc interface.get 'description' if desc commands.append 'description{0}'.format desc mode interface.get 'mode' if mode if mode 'layer2' command 'switchport'elif mode 'layer3' command 'noswitchport'commands.append command admin_state interface.get 'admin_state' if admin_state command get_admin_state interface intf admin_state commands.append command ip_forward interface.get 'ip_forward' if ip_forward if ip_forward 'enable' commands.append 'ipforward' else commands.append 'noipforward' fabric_forwarding_anycast_gateway interface.get 'fabric_forwarding_anycast_gateway' if fabric_forwarding_anycast_gateway is not None if fabric_forwarding_anycast_gateway is True commands.append 'fabricforwardingmodeanycast-gateway' elif fabric_forwarding_anycast_gateway is False commands.append 'nofabricforwardingmodeanycast-gateway' if commands commands.insert 0 'interface' + intf return commands
def inplace_csr_row_scale X scale assert scale.shape[0] X.shape[0] X.data * np.repeat scale np.diff X.indptr
def tan x return Tan x
def _render_certificate_template request context course user_certificate if settings.FEATURES.get 'CUSTOM_CERTIFICATE_TEMPLATES_ENABLED' False custom_template get_certificate_template course.id user_certificate.mode if custom_template template Template custom_template output_encoding 'utf-8' input_encoding 'utf-8' default_filters ['decode.utf8'] encoding_errors 'replace' context RequestContext request context return HttpResponse template.render context return render_to_response 'certificates/valid.html' context
def _character_matches name1 name2 if name1[0] '*' for i in range len name2 + 1 yield 1 i if name2[0] '*' for i in range len name1 + 1 yield i 1 if name1[0] name2[0] yield 1 1
def rv_subs expr symbols None if symbols is None symbols random_symbols expr if not symbols return exprswapdict {rv rv.symbol for rv in symbols}return expr.xreplace swapdict
def create_consumers endpoints prefix topic_details start_listening True connection n_rpc.create_connection for details in topic_details topic operation node_name itertools.islice itertools.chain details [None] 3 topic_name topics.get_topic_name prefix topic operation connection.create_consumer topic_name endpoints fanout True if node_name node_topic_name '%s.%s' % topic_name node_name connection.create_consumer node_topic_name endpoints fanout False if start_listening connection.consume_in_threads return connection
def _compute_eps log_moments delta min_eps float 'inf' for moment_order log_moment in log_moments if moment_order 0 continueif math.isinf log_moment or math.isnan log_moment sys.stderr.write 'The%d-thorderisinforNan\n' % moment_order continuemin_eps min min_eps log_moment - math.log delta / moment_order return min_eps
def detect_django_settings matches []for root dirnames filenames in os.walk os.getcwd for filename in fnmatch.filter filenames '*settings.py' full os.path.join root filename if 'site-packages' in full continuefull os.path.join root filename package_path full.replace os.getcwd '' package_module package_path.replace os.sep '.' .split '.' 1 [1].replace '.py' '' matches.append package_module return matches
def p_pointer_3 t pass
def clear_timeline_contents pipeline timeline_key truncate_timeline pipeline timeline_key 0 timeline_key truncate_timeline pipeline make_digest_key timeline_key 0 timeline_key pipeline.delete make_last_processed_timestamp_key timeline_key
def is_fp_closed obj try return obj.isclosed except AttributeError passtry return obj.closedexcept AttributeError passtry return obj.fp is None except AttributeError passraise ValueError 'Unabletodeterminewhetherfpisclosed.'
@blueprint.route '/completed_jobs.json' methods ['GET'] def completed_jobs completed_datasets get_job_list dataset.DatasetJob False completed_models get_job_list model.ModelJob False running_datasets get_job_list dataset.DatasetJob True running_models get_job_list model.ModelJob True pretrained_models get_job_list pretrained_model.PretrainedModelJob False model_output_fields set data {'running' [json_dict j model_output_fields for j in running_datasets + running_models ] 'datasets' [json_dict j model_output_fields for j in completed_datasets] 'models' [json_dict j model_output_fields for j in completed_models] 'pretrained_models' [json_dict j model_output_fields for j in pretrained_models] 'model_output_fields' sorted list model_output_fields }return flask.jsonify data
def combine_max_stats games return reduce lambda a b a + b [g.max_player_stats for g in games if g is not None ]
def sense chip fahrenheit False extra_args ''if fahrenheit is True extra_args '-f'sensors __salt__['cmd.run'] '/usr/bin/sensors{0}{1}'.format chip extra_args python_shell False .splitlines ret {}for sensor in sensors sensor_list sensor.split ' ' if len sensor_list > 2 ret[sensor_list[0]] sensor_list[1].lstrip return ret
def getRepositoryWriter title repositoryWriter cStringIO.StringIO repositoryWriter.write 'Formatistabseparated%s.\n' % title repositoryWriter.write '_Name%sValue\n' % globalSpreadsheetSeparator return repositoryWriter
def get_path name scheme _get_default_scheme vars None expand True return get_paths scheme vars expand [name]
def set_obey_over18 c.obey_over18 request.GET.get 'obey_over18' 'true'
def MACDEXT ds count fastperiod - 2 ** 31 fastmatype 0 slowperiod - 2 ** 31 slowmatype 0 signalperiod - 2 ** 31 signalmatype 0 ret call_talib_with_ds ds count talib.MACDEXT fastperiod fastmatype slowperiod slowmatype signalperiod signalmatype if ret is None ret None None None return ret
def delete_column_constraints func def _column_rm self table_name column_name *args **opts try self.delete_foreign_key table_name column_name except ValueError passtry reverse self._lookup_reverse_constraint table_name column_name for cname rtable rcolumn in reverse self.delete_foreign_key rtable rcolumn except DryRunError passreturn func self table_name column_name *args **opts return _column_rm
def allow_connection_pickling from multiprocessing import reduction
def widgets_entry_points ep_iter pkg_resources.iter_entry_points WIDGETS_ENTRY chain [[default_entry_point ] ep_iter]return itertools.chain *chain
def openshift_dep_verify registry xml_parent data osb XML.SubElement xml_parent 'com.openshift.jenkins.plugins.pipeline.OpenShiftDeploymentVerifier' mapping [ 'api-url' 'apiURL' 'https //openshift.default.svc.cluster.local' 'dep-cfg' 'depCfg' 'frontend' 'namespace' 'namespace' 'test' 'replica-count' 'replicaCount' 0 'auth-token' 'authToken' '' 'verbose' 'verbose' False ]convert_mapping_to_xml osb data mapping fail_required True
def tag_autocomplete context data_dict _check_access 'tag_autocomplete' context data_dict matching_tags count _tag_search context data_dict if matching_tags return [tag.name for tag in matching_tags]else return []
def Msg msg print color.B_YELLOW + '[' + color.B_GREEN + '!' + color.B_YELLOW + ']%s' % msg + color.END
def get_service_name *args raw_services _get_services services dict for raw_service in raw_services if args if raw_service['DisplayName'] in args or raw_service['ServiceName'] in args or raw_service['ServiceName'].lower in args services[raw_service['DisplayName']] raw_service['ServiceName']else services[raw_service['DisplayName']] raw_service['ServiceName']return services
def getProviderByName name if name.lower 'mapnik' from . import Mapnikreturn Mapnik.ImageProviderelif name.lower 'proxy' return Proxyelif name.lower 'urltemplate' return UrlTemplateelif name.lower 'vector' from . import Vectorreturn Vector.Providerelif name.lower 'mbtiles' from . import MBTilesreturn MBTiles.Providerelif name.lower 'mapnikgrid' from . import Mapnikreturn Mapnik.GridProviderelif name.lower 'sandwich' from . import Sandwichreturn Sandwich.Providerraise Exception 'Unknownprovidername "%s"' % name
def config_true_value value return value is True or isinstance value basestring and value.lower in TRUE_VALUES
def get_python_doc_path if os.name 'nt' doc_path osp.join sys.prefix 'Doc' if not osp.isdir doc_path returnpython_chm [path for path in os.listdir doc_path if re.match ' ?i Python[0-9]{3 6}.chm' path ]if python_chm return file_uri osp.join doc_path python_chm[0] else vinf sys.version_infodoc_path '/usr/share/doc/python%d.%d/html' % vinf[0] vinf[1] python_doc osp.join doc_path 'index.html' if osp.isfile python_doc return file_uri python_doc
def find_dsym_file project image_uuid image_uuid image_uuid.lower try return ProjectDSymFile.objects.filter uuid image_uuid project project .select_related 'file' .get except ProjectDSymFile.DoesNotExist passtry return GlobalDSymFile.objects.filter uuid image_uuid .select_related 'file' .get except GlobalDSymFile.DoesNotExist return None
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def get_enrollment_attributes user_id course_id return _ENROLLMENT_ATTRIBUTES
def group_get_all context filters None marker None limit None offset None sort_keys None sort_dirs None return IMPL.group_get_all context filters filters marker marker limit limit offset offset sort_keys sort_keys sort_dirs sort_dirs
@testing.requires_testing_data@requires_freesurfer@requires_nibabel def test_get_volume_label_names aseg_fname op.join subjects_dir 'sample' 'mri' 'aseg.mgz' label_names label_colors get_volume_labels_from_aseg aseg_fname return_colors True assert_equal label_names.count 'Brain-Stem' 1 assert_equal len label_colors len label_names
def execute_concurrent_with_args session statement parameters *args **kwargs return execute_concurrent session zip cycle statement parameters *args **kwargs
def subprocess_visible_devices gpus if not isinstance gpus list raise ValueError 'gpusshouldbealist' gpus [int g for g in gpus]old_cvd os.environ.get 'CUDA_VISIBLE_DEVICES' None if old_cvd is None real_gpus gpuselse map_visible_to_real {}for visible real in enumerate old_cvd.split ' ' map_visible_to_real[visible] int real real_gpus []for visible_gpu in gpus real_gpus.append map_visible_to_real[visible_gpu] return ' '.join str g for g in real_gpus
def get_script_name environ from google.appengine._internal.django.conf import settingsif settings.FORCE_SCRIPT_NAME is not None return force_unicode settings.FORCE_SCRIPT_NAME script_url environ.get 'SCRIPT_URL' u'' if not script_url script_url environ.get 'REDIRECT_URL' u'' if script_url return force_unicode script_url[ - len environ.get 'PATH_INFO' '' ] return force_unicode environ.get 'SCRIPT_NAME' u''
def get_rotation rotation try angle float rotation except ValueError TypeError isString isinstance rotation six.string_types if isString and rotation u'horizontal' or rotation is None angle 0.0elif isString and rotation u'vertical' angle 90.0else raise ValueError u"rotationis{0}expectedeither'horizontal''vertical' numericvalueorNone".format rotation return angle % 360
def to_join obj if isinstance obj tuple list alias Nonemethod Noneif len obj 3 alias obj[2]elif len obj 4 alias method obj[2] obj[3] elif len obj < 2 or len obj > 4 raise ArgumentError 'Joinobjectcanhave1to4itemshas{} {}'.format len obj obj master to_join_key obj[0] detail to_join_key obj[1] return Join master detail alias method elif hasattr obj 'get' return Join to_join_key obj.get 'master' to_join_key obj.get 'detail' obj.get 'alias' obj.get 'method' else return Join to_join_key obj.master to_join_key obj.detail obj.alias obj.method
def generateElementsQNamed list name uri for n in list if IElement.providedBy n and n.name name and n.uri uri yield n
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def compile_ir typingctx targetctx func_ir args return_type flags locals lifted lifted_from None library None pipeline Pipeline typingctx targetctx library args return_type flags locals return pipeline.compile_ir func_ir func_ir lifted lifted lifted_from lifted_from
def get_hook name return _HOOKS.setdefault name Hook
def link_pantsrefs soups precomputed for page soup in soups.items for a in soup.find_all u'a' if a.has_attr u'pantsref' pantsref a[u'pantsref']if not pantsref in precomputed.pantsref raise TaskError u'Page{0}haspantsref"{1}"andIcannotfindpantsmarkforit'.format page pantsref a[u'href'] rel_href page precomputed.pantsref[pantsref]
def save_state ArticleCache.do.flush_articles NzbQueue.do.save BPSMeter.do.save rss.save Rating.do.save DirScanner.do.save PostProcessor.do.save
@receiver user_logged_in def handle_customer_login sender **kwargs try kwargs[u'request'].customer kwargs[u'request'].user.customerexcept AttributeError ObjectDoesNotExist kwargs[u'request'].customer SimpleLazyObject lambda CustomerModel.objects.get_from_request kwargs[u'request']
def getChainMatrixSVG elementNode matrixSVG matrixSVG matrixSVG.getOtherTimesSelf getMatrixSVG elementNode .tricomplex if elementNode.parentNode ! None matrixSVG getChainMatrixSVG elementNode.parentNode matrixSVG return matrixSVG
def test_tl_sample_wt_fit tl TomekLinks random_state RND_SEED assert_raises RuntimeError tl.sample X Y
def extract_sd_config config sd_config {}if config.has_option 'Main' 'sd_config_backend' sd_config['sd_config_backend'] config.get 'Main' 'sd_config_backend' else sd_config['sd_config_backend'] Noneif config.has_option 'Main' 'sd_template_dir' sd_config['sd_template_dir'] config.get 'Main' 'sd_template_dir' else sd_config['sd_template_dir'] SD_TEMPLATE_DIRif config.has_option 'Main' 'sd_backend_host' sd_config['sd_backend_host'] config.get 'Main' 'sd_backend_host' if config.has_option 'Main' 'sd_backend_port' sd_config['sd_backend_port'] config.get 'Main' 'sd_backend_port' if config.has_option 'Main' 'sd_jmx_enable' sd_config['sd_jmx_enable'] config.get 'Main' 'sd_jmx_enable' return sd_config
def _get_blob_storage return apiproxy_stub_map.apiproxy.GetStub 'blobstore' .storage
def post context url data '' return request context url method 'POST' data data
def getEdgeWidth elementNode if elementNode None return 0.72preferences skeinforge_craft.getCraftPreferences 'carve' layerHeight skeinforge_craft.getCraftValue 'LayerHeight' preferences layerHeight getCascadeFloatWithoutSelf layerHeight elementNode 'layerHeight' edgeWidthOverHeight skeinforge_craft.getCraftValue 'EdgeWidthoverHeight' preferences edgeWidthOverHeight getCascadeFloatWithoutSelf edgeWidthOverHeight elementNode 'edgeWidthOverHeight' return getCascadeFloatWithoutSelf edgeWidthOverHeight * layerHeight elementNode 'edgeWidth'
def _validate_groupby_fields groupby_fields valid_fields set ['user_id' 'resource_id' 'project_id' 'source' 'resource_metadata.instance_type'] invalid_fields set groupby_fields - valid_fields if invalid_fields raise wsme.exc.UnknownArgument invalid_fields 'Invalidgroupbyfields' return list set groupby_fields
def make_consumer request session request.session.setdefault 'OPENID' {} store DjangoOpenIDStore return Consumer session store
def fountain url zsock zcontext.socket zmq.PUSH zsock.bind url words [w for w in dir __builtins__ if w.islower ]while True zsock.send random.choice words time.sleep 0.4
def visit_scenario_item item_key url django_url reverse 'jump_to' kwargs {'course_id' unicode world.scenario_dict['COURSE'].id 'location' unicode world.scenario_dict[item_key].location } world.browser.visit url
def _make_c_string string if isinstance string bytes try _utf_8_decode string None True return string + '\x00' except UnicodeError raise InvalidStringData 'stringsindocumentsmustbevalidUTF-8 %r' % string else return _utf_8_encode string [0] + '\x00'
def write_version_info conn version_table version_value conn.execute sa.insert version_table values {'version' version_value}
def nan_dot A B should_be_nan_1 np.dot np.isnan A B ! 0 should_be_nan_2 np.dot A ! 0 np.isnan B should_be_nan should_be_nan_1 + should_be_nan_2 C np.dot np.nan_to_num A np.nan_to_num B C[should_be_nan] np.nanreturn C
def checkSystemEncoding if sys.getdefaultencoding 'cp720' try codecs.lookup 'cp720' except LookupError errMsg 'thereisaknownPythonissue #1616979 related'errMsg + "tosupportforcharset'cp720'.Pleasevisit"errMsg + "'http //blog.oneortheother.info/tip/python-fix-cp720-encoding/index.html'"errMsg + 'andfollowtheinstructionstobeabletofixit'logger.critical errMsg warnMsg "temporaryswitchingtocharset'cp1256'"logger.warn warnMsg reload sys sys.setdefaultencoding 'cp1256'
def buildAppropriateDataset module if module.sequential d SequentialDataSet module.indim module.outdim for dummy in range 2 d.newSequence for dummy in range 3 d.addSample randn module.indim randn module.outdim else d SupervisedDataSet module.indim module.outdim for dummy in range 3 d.addSample randn module.indim randn module.outdim return d
def test_ast_require can_compile u' requiretests.resources.tlib ' can_compile u' require[tests.resources.tlib[qplahparald]] ' can_compile u' require[tests.resources.tlib[*]] ' can_compile u' require[tests.resources.tlib asfoobar] ' can_compile u' require[tests.resources.tlib[qplah asquiz]] ' can_compile u' require[tests.resources.tlib[qplah asquizparald]] ' cant_compile u' require[tests.resources.tlib] ' cant_compile u' require[tests.resources.tlib[*qplah]] ' cant_compile u' require[tests.resources.tlib[qplah*]] ' cant_compile u' require[tests.resources.tlib[**]] '
def rewriterule source target variables condition None assume None def rewrite_rl expr assumptions True for match in unify source expr {} variables variables if condition and not condition *[match.get var var for var in variables] continueif assume and not ask assume.xreplace match assumptions continueexpr2 subs match target if isinstance expr2 Expr expr2 rebuild expr2 yield expr2 return rewrite_rl
def save_workbook workbook filename writer ExcelWriter workbook writer.save filename return True
def pci_device_destroy context node_id address return IMPL.pci_device_destroy context node_id address
def CheckHost host_data os_name None cpe None labels None exclude_checks None restrict_checks None kb host_data.get 'KnowledgeBase' if os_name is None os_name kb.osif cpe is None passif labels is None passreturn CheckRegistry.Process host_data os_name os_name cpe cpe labels labels restrict_checks restrict_checks exclude_checks exclude_checks
def locateMark mark payload index payload.find mark 0 const.MAX_PADDING_LENGTH + const.MARK_LENGTH if index < 0 log.debug 'Couldnotfindthemarkjustyet.' return Noneif len payload - index - const.MARK_LENGTH < const.HMAC_SHA256_128_LENGTH log.debug 'FoundthemarkbuttheHMACisstillincomplete.' return Nonelog.debug 'Successfullylocatedthemark.' return index
def getattr_str obj attr fmt None fallback '?' if hasattr obj attr if fmt is not None return fmt % getattr obj attr return str getattr obj attr return fallback
def win_getpass prompt 'Password ' stream None if sys.stdin is not sys.__stdin__ return fallback_getpass prompt stream import msvcrtfor c in prompt msvcrt.putch c pw ''while 1 c msvcrt.getch if c '\r' or c '\n' breakif c '\x03' raise KeyboardInterruptif c '\x08' pw pw[ -1 ]else pw pw + c msvcrt.putch '\r' msvcrt.putch '\n' return pw
def getNextEdgeIndexAroundZ edge faces remainingEdgeTable for faceIndex in edge.faceIndexes face faces[faceIndex]for edgeIndex in face.edgeIndexes if edgeIndex in remainingEdgeTable return edgeIndexreturn -1
def rescale_layout pos scale 1 lim 0for i in range pos.shape[1] pos[ i] - pos[ i].mean lim max pos[ i].max lim if lim > 0 for i in range pos.shape[1] pos[ i] * scale / lim return pos
def combine_funcs obj funcs out x obj for x in funcs return '<ul>%s</ul>' % ''.join '<li>%s</li>' % x for x in out if x
def update_translations lang untranslated_file translated_file clear_cache full_dict get_full_dict lang def restore_newlines s return s.replace u'|||||' u'\\\n' .replace u'|||||' u'\\\n' .replace u'||||' u'\\n' .replace u'||||' u'\\n' .replace u'|||' u'\n' .replace u'|||' u'\n' translation_dict {}for key value in zip frappe.get_file_items untranslated_file ignore_empty_lines False frappe.get_file_items translated_file ignore_empty_lines False translation_dict[restore_newlines key ] restore_newlines value full_dict.update translation_dict for app in frappe.get_all_apps True write_translations_file app lang full_dict
def variance x n len x deviations de_mean x return sum_of_squares deviations / n - 1
def _parse_snippets_file data filename lines LineIterator data for line in lines if not line.strip continue head tail head_tail line if head 'extends' yield handle_extends tail lines.line_index elif head in 'snippet' snippet _parse_snippet line lines filename if snippet is not None yield snippet elif head and not head.startswith '#' yield 'error' 'Invalidline%r' % line.rstrip lines.line_index
def test_unschedule_self observer class EventHandler FileSystemEventHandler def on_modified self event observer.unschedule watch unschedule_finished.set unschedule_finished Event watch observer.schedule EventHandler u'' observer.start emitter observer.emittersemitter.queue_event FileModifiedEvent u'' assert unschedule_finished.wait assert len observer.emitters 0
def collectstatic settings_module bin_env None no_post_process False ignore None dry_run False clear False link False no_default_ignore False pythonpath None env None args ['noinput']kwargs {}if no_post_process args.append 'no-post-process' if ignore kwargs['ignore'] ignoreif dry_run args.append 'dry-run' if clear args.append 'clear' if link args.append 'link' if no_default_ignore args.append 'no-default-ignore' return command settings_module 'collectstatic' bin_env pythonpath env *args **kwargs
def report_clone_repo_errors task if task.cmd is None or task.cmd.ok returnInteraction.critical task.cmd.error_message message task.cmd.error_message details task.cmd.error_details
def _get_static_settings static_dir os.path.join galaxy_root 'static' return dict static_enabled True static_cache_time 360 static_dir static_dir static_images_dir os.path.join static_dir 'images' '' static_favicon_dir os.path.join static_dir 'favicon.ico' static_scripts_dir os.path.join static_dir 'scripts' '' static_style_dir os.path.join static_dir 'june_2007_style' 'blue' static_robots_txt os.path.join static_dir 'robots.txt'
def is_sequence_of_strings obj if not cbook.iterable obj return Falseif not isinstance obj np.ndarray and cbook.is_string_like obj return Falsefor o in obj if not cbook.is_string_like o return Falsereturn True
def tzname_in_python2 myfunc def inner_func *args **kwargs if PY3 return myfunc *args **kwargs else return myfunc *args **kwargs .encode return inner_func
def path *s joined os.path.join os.path.abspath config.STORE_DIR *s absolute os.path.abspath joined verify absolute return absolute
def deny ip return __apf_cmd '-d{0}'.format ip
def time_in_a_while days 0 seconds 0 microseconds 0 milliseconds 0 minutes 0 hours 0 weeks 0 delta timedelta days seconds microseconds milliseconds minutes hours weeks return datetime.utcnow + delta
def create_consumers endpoints prefix topic_details start_listening True connection n_rpc.create_connection for details in topic_details topic operation node_name itertools.islice itertools.chain details [None] 3 topic_name topics.get_topic_name prefix topic operation connection.create_consumer topic_name endpoints fanout True if node_name node_topic_name '%s.%s' % topic_name node_name connection.create_consumer node_topic_name endpoints fanout False if start_listening connection.consume_in_threads return connection
def from_migration_import module_name fromlist module_path 'glance.db.sqlalchemy.migrate_repo.versions.%s' % module_name module __import__ module_path globals locals fromlist 0 return [getattr module item for item in fromlist]
def matrix_to_vector matrix system outvec Vector.zerovects system.base_vectors for i x in enumerate matrix outvec + x * vects[i] return outvec
def get_token_for_user user scope data { 'user_%s_id' % scope user.id}return signing.dumps data
def find_font_face_rules sheet oeb ans []try rules sheet.data.cssRulesexcept AttributeError rules sheet.cssRulesfor i rule in enumerate rules if rule.type ! rule.FONT_FACE_RULE continueprops get_font_properties rule default u'normal' if not props[u'font-family'] or not props[u'src'] continuetry path sheet.abshref props[u'src'] except AttributeError path props[u'src']ff oeb.manifest.hrefs.get urlnormalize path None if not ff continueprops[u'item'] ffif props[u'font-weight'] in {u'bolder' u'lighter'} props[u'font-weight'] u'400'props[u'weight'] int props[u'font-weight'] props[u'rule'] ruleprops[u'chars'] set ans.append props return ans
def permissions_string permissions known_permissions to_set []if permissions is None to_set ['+all']else to_set ['-all']omitted sorted known_permissions - set permissions to_set.extend '-{}'.format x for x in omitted to_set.extend '+{}'.format x for x in permissions return ' '.join to_set
def test_math_subclass import mathclass myfloat float passclass mylong long passmf myfloat 1 ml mylong 1 for x in math.log math.log10 math.log1p math.asinh math.acosh math.atanh math.factorial math.trunc math.isinf try resf x mf except ValueError resf Nonetry resl x ml except ValueError resl NoneAreEqual resf resl
@bdd.when bdd.parsers.re 'Iwaitforthe ?P<category>error|message|warning " ?P<message>.* "' def wait_for_message quteproc httpbin category message quteproc.log_summary 'Waitingfor{}"{}"'.format category message expect_message quteproc httpbin category message
def yvp v z n 1 if not isinstance n int or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n 0 return yv v z else return _bessel_diff_formula v z n yv -1
def _check_comp comp ref_sens Nonekind -1 for k c_k in enumerate comp if c_k['coeff_type'] ! kind c_ref c_kref_sens c_ref['sensors']kind c_k['coeff_type']elif not c_k['sensors'] ref_sens raise RuntimeError 'Cannotuseanunevencompensationmatrix'
def precompute_pantsrefs soups accumulator {}for page soup in soups.items existing_anchors find_existing_anchors soup count 100for tag in soup.find_all u'a' if tag.has_attr u'pantsmark' pantsmark tag[u'pantsmark']if pantsmark in accumulator raise TaskError u'pantsmarksareuniquebut"{0}"appearsin{1}and{2}'.format pantsmark page accumulator[pantsmark] anchor tag.get u'id' or tag.get u'name' if not anchor anchor pantsmarkwhile anchor in existing_anchors count + 1anchor u'{0}_{1}'.format pantsmark count tag[u'id'] anchorexisting_anchors find_existing_anchors soup link u'{0}.html#{1}'.format page anchor accumulator[pantsmark] linkreturn accumulator
def _get_child_branch trie c for branch in _get_child_branches trie if branch[0] c return branchreturn None
def longest_id ids seqs lengths map len [seqs.get id_ '' for id_ in ids] return ids[argmax lengths ]
def get_relative_path path components split_all path if len components < 1 return os.curdirelse parents [os.pardir] * len components - 1 return os.path.join *parents
def get_search_location try return file_io.read constants.SEARCH_FILE_LOC .rstrip except IOError logging.warning 'Searchroleisnotconfigured.' return ''
def set_vif_guest_frontend_config conf mac model driver conf.mac_addr macif model is not None conf.model modelif driver is not None conf.driver_name driver
def ports2nmapspec portlist portlist sorted set portlist result []current None None for port in portlist if port - 1 current[1] current current[0] port else if current[0] is not None result.append str current[0] if current[0] current[1] else '%d-%d' % current current port port if current[0] is not None result.append str current[0] if current[0] current[1] else '%d-%d' % current return ' '.join result
def psaux name sanitize_name str name pattern re.compile sanitize_name salt_exception_pattern re.compile 'salt.+ps.psaux.+' ps_aux __salt__['cmd.run'] 'psaux' found_infos []ret []nb_lines 0for info in ps_aux.splitlines found pattern.search info if found is not None if not salt_exception_pattern.search info nb_lines + 1found_infos.append info pid_count str nb_lines + 'occurence s .' ret []ret.extend [sanitize_name found_infos pid_count] return ret
def get_zen_unitdata translation request search_result search translation request try offset int request.GET.get u'offset' 0 except ValueError offset 0if isinstance search_result HttpResponse return search_result None search_result[u'last_section'] offset + 20 > len search_result[u'ids'] search_result[u'offset'] offsetunits translation.unit_set.filter pk__in search_result[u'ids'][offset offset + 20 ] unitdata [{u'unit' unit u'secondary' unit.get_secondary_units request.user if request.user.is_authenticated and request.user.profile.secondary_in_zen else None u'form' TranslationForm translation unit tabindex 100 + unit.position * 10 u'offset' offset + pos } for pos unit in enumerate units ]return search_result unitdata
def xdg_config_dir xdg_config os.getenv 'XDG_CONFIG_HOME' os.path.expanduser '~/.config' xdg_config_directory os.path.join xdg_config 'salt' return xdg_config_directory
def eglInitialize display majorVersion _c_int * 1 minorVersion _c_int * 1 res _lib.eglInitialize display majorVersion minorVersion if res EGL_FALSE raise RuntimeError 'Couldnotinitialize' return majorVersion[0] minorVersion[0]
def _recommendation results if not results return Recommendation.nonemin_dist results[0].distanceif min_dist < config['match']['strong_rec_thresh'].as_number rec Recommendation.strongelif min_dist < config['match']['medium_rec_thresh'].as_number rec Recommendation.mediumelif len results 1 rec Recommendation.lowelif results[1].distance - min_dist > config['match']['rec_gap_thresh'].as_number rec Recommendation.lowelse return Recommendation.nonekeys set min_dist.keys if isinstance results[0] hooks.AlbumMatch for track_dist in min_dist.tracks.values keys.update track_dist.keys max_rec_view config['match']['max_rec']for key in keys if key in max_rec_view.keys max_rec max_rec_view[key].as_choice {'strong' Recommendation.strong 'medium' Recommendation.medium 'low' Recommendation.low 'none' Recommendation.none} rec min rec max_rec return rec
def name_filter sum_dict align_dict name_list new_sum_dict FSSP.FSSPSumDict new_align_dict copy.deepcopy align_dict for cur_pdb_name in name_list for prot_num in sum_dict if sum_dict[prot_num].pdb2 + sum_dict[prot_num].chain2 cur_pdb_name new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict.abs_res_dict new_align_dict.abs pos_num .pos_align_dict {}for prot_num in prot_numbers new_align_dict.abs pos_num .pos_align_dict[prot_num] align_dict.abs pos_num .pos_align_dict[prot_num]return new_sum_dict new_align_dict
def test_tmp_dir_exists_in_env script script.assert_no_temp assert script.environ['TMPDIR'] script.temp_path assert isdir script.temp_path
def test_oss_sk_estimator check_estimator OneSidedSelection
def forget func *xs return Forget func *xs
@register.inclusion_tag u'admin/includes/recent_actions.html' takes_context True def recent_actions context return context
def widthratio parser token bits token.contents.split if len bits ! 4 raise TemplateSyntaxError 'widthratiotakesthreearguments' tag this_value_expr max_value_expr max_width bitstry max_width int max_width except ValueError raise TemplateSyntaxError 'widthratiofinalargumentmustbeaninteger' return WidthRatioNode parser.compile_filter this_value_expr parser.compile_filter max_value_expr max_width
def test_represent_hadamard circuit HadamardGate 0 * Qubit '00' answer represent circuit nqubits 2 assert answer Matrix [sqrt2_inv sqrt2_inv 0 0]
def amp_server_context_factory ca_certificate control_credential return _ControlServiceContextFactory ca_certificate control_credential 'node-'
def get_info_from_core path full_exe_path Noneoutput commands.getoutput 'gdb-c%sbatch' % path path_pattern re.compile "Corewasgeneratedby` [^\x00]+ '" re.IGNORECASE match re.findall path_pattern output for m in match m m.split '' [0]if os.path.isfile m full_exe_path mbreakif full_exe_path is None syslog.syslog 'Couldnotdeterminefromwhichapplicationcorefile%sisfrom' % path return {'full_exe_path' full_exe_path}
def force_exit event sys.exit 'Quit'
def reap_children for col in all_living_collectors now int time.time status col.proc.poll if status is None continuecol.proc Noneif status 13 LOG.info 'removing%sfromthelistofcollectors byrequest ' col.name col.dead Trueelif status ! 0 LOG.warning 'collector%sterminatedafter%dsecondswithstatuscode%d markingdead' col.name now - col.lastspawn status col.dead Trueelse register_collector Collector col.name col.interval col.filename col.mtime col.lastspawn
def getOuterLoops loops outerLoops []for loop in loops if not euclidean.isPathInsideLoops outerLoops loop outerLoops.append loop intercircle.directLoops True outerLoops return outerLoops
def hg_revision return local 'hgidentify-i' capture True
def error_response_app error_code message debug_message None __warn True if __warn warnings.warn 'wsgilib.error_response_appisdeprecated;usethewsgi_applicationmethodonanHTTPExceptionobjectinstead' DeprecationWarning 2 def application environ start_response status headers body error_response environ error_code message debug_message debug_message __warn False start_response status headers return [body]return application
def _do_extra_actions api_content cc_content request_fields actions_form context request for field form_value in actions_form.cleaned_data.items if field in request_fields and form_value ! api_content[field] api_content[field] form_valueif field 'following' _handle_following_field form_value context['cc_requester'] cc_content elif field 'abuse_flagged' _handle_abuse_flagged_field form_value context['cc_requester'] cc_content elif field 'voted' _handle_voted_field form_value cc_content api_content request context elif field 'read' _handle_read_field api_content form_value context['cc_requester'] cc_content else raise ValidationError {field ['InvalidKey']}
def selective_len str max res 0for c in str if ord c < max res + 1return res
def getDoubleFromCharacterSplitLineValue character splitLine value splitLineFloat getDoubleFromCharacterSplitLine character splitLine if splitLineFloat None return valuereturn splitLineFloat
def handle text mic profile messages ["I'msorry couldyourepeatthat?" 'Myapologies couldyoutrysayingthatagain?' 'Saythatagain?' 'Ibegyourpardon?']message random.choice messages mic.say message
def get_hostmask_regex mask mask re.escape mask mask mask.replace u'\\*' u'.*' return re.compile mask + u'$' re.I
def enter_xml_in_advanced_problem step text world.edit_component type_in_codemirror 0 text world.save_component
@_uniquedef uninstallation_paths dist r csv.reader FakeFile dist.get_metadata_lines 'RECORD' for row in r path os.path.join dist.location row[0] yield path if path.endswith '.py' dn fn os.path.split path base fn[ -3 ]path os.path.join dn base + '.pyc' yield path
def db_initial_version database 'main' return IMPL.db_initial_version database database
def _get_yaml_path builtin_name runtime runtime_specific os.path.join _handler_dir builtin_name INCLUDE_FILENAME_TEMPLATE % runtime if runtime and os.path.exists runtime_specific return runtime_specificreturn os.path.join _handler_dir builtin_name DEFAULT_INCLUDE_FILENAME
def test_escaped_task_kwarg_split argstr 'cmd arg escaped\\ arg nota\\ kwarg regular kwarg escaped regular\\ kwarg'args ['arg' 'escaped arg' 'nota kwarg']kwargs {'regular' 'kwarg' 'escaped' 'regular kwarg'}eq_ parse_arguments [argstr] [0] 'cmd' args kwargs [] [] []
def entropy image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._entropy image selem out out mask mask shift_x shift_x shift_y shift_y out_dtype np.double
def get_build_exe_options opts freeze.get_build_exe_options skip_html True opts['includes'] + pytest.freeze_includes opts['includes'] + ['unittest.mock' 'PyQt5.QtTest' 'hypothesis' 'bs4' 'httpbin' 'jinja2.ext' 'cheroot' 'pstats' 'queue']httpbin_dir os.path.dirname httpbin.__file__ opts['include_files'] + [ 'tests/end2end/data' 'end2end/data' os.path.join httpbin_dir 'templates' 'end2end/templates' ]opts['packages'].append 'qutebrowser' return opts
def generate_map map name 'url_map' map.update rules []converters []for rule in map.iter_rules trace [{'is_dynamic' is_dynamic 'data' data} for is_dynamic data in rule._trace]rule_converters {}for key converter in rule._converters.iteritems js_func js_to_url_function converter try index converters.index js_func except ValueError converters.append js_func index len converters - 1 rule_converters[key] indexrules.append {u'endpoint' rule.endpoint u'arguments' list rule.arguments u'converters' rule_converters u'trace' trace u'defaults' rule.defaults} return render_template name_parts name and name.split '.' or [] rules dumps rules converters converters
def schedule_url year stype week xmlurl 'http //www.nfl.com/ajax/scorestrip?'if stype 'POST' week + 17if week 21 week + 1return '%sseason %d&seasonType %s&week %d' % xmlurl year stype week
def restack stack index 0 x stack.pop index stack.append x return x
def _InsertNodeAt new_node target after False if new_node.parent is not None raise RuntimeError 'insertingnodewhichalreadyhasaparent' new_node new_node.parent parent_of_target target.parentif parent_of_target is None raise RuntimeError 'expectedtargetnodetohaveaparent' target for i child in enumerate parent_of_target.children if child is target insertion_index i + 1 if after else i parent_of_target.insert_child insertion_index new_node returnraise RuntimeError 'unabletofindinsertionpointfortargetnode' target
def skipIfCustomUser test_func return skipIf settings.AUTH_USER_MODEL ! 'auth.User' 'Customusermodelinuse' test_func
def configure_input_data obj data if vtk_old obj.input dataelse obj.set_input_data data
def nlmeans_pipeline name 'Denoise' params {'patch_radius' 1 'block_radius' 5} inputnode pe.Node niu.IdentityInterface fields ['in_file' 'in_mask'] name 'inputnode' outputnode pe.Node niu.IdentityInterface fields ['out_file'] name 'outputnode' nmask pe.Node niu.Function input_names ['in_file' 'in_mask'] output_names ['out_file'] function bg_mask name 'NoiseMsk' nlmeans pe.Node dipy.Denoise **params name 'NLMeans' wf pe.Workflow name name wf.connect [ inputnode nmask [ 'in_file' 'in_file' 'in_mask' 'in_mask' ] inputnode nlmeans [ 'in_file' 'in_file' 'in_mask' 'in_mask' ] nmask nlmeans [ 'out_file' 'noise_mask' ] nlmeans outputnode [ 'out_file' 'out_file' ] ] return wf
def compile_device_template pyfunc debug False inline False from .descriptor import CUDATargetDescdft DeviceFunctionTemplate pyfunc debug debug inline inline class device_function_template AbstractTemplate key dftdef generic self args kws assert not kws return dft.compile args typingctx CUDATargetDesc.typingctxtypingctx.insert_user_function dft device_function_template return dft
def get_role_by_name name result Role.get name name return result
@with_config DEBUG True ASSETS_DEBUG True def test_debug_inheritance sub2 Bundle 's4' filters [js] output 'bar' sub1 Bundle 's3' sub2 debug 'merge' output 'foo' filters [css] b Bundle 's1' 's2' sub1 filters [js] jl bundle_to_joblist b assert len jl 3 assert 's1' in jl and 's2' in jl assert jl['foo'][0][0] [] assert jl['foo'][1][0] [] sub2.debug Truejl bundle_to_joblist b assert len jl 4 assert 's1' in jl and 's2' in jl and 's4' in jl assert jl['foo'][0][0] []
def describe_volumes kwargs None call None if call ! 'function' log.error 'Thedescribe_volumesfunctionmustbecalledwith-for--function.' return Falseif not kwargs kwargs {}params {'Action' 'DescribeVolumes'}if 'volume_id' in kwargs volume_id kwargs['volume_id'].split ' ' for volume_index volume_id in enumerate volume_id params['VolumeId.{0}'.format volume_index ] volume_idlog.debug params data aws.query params return_url True location get_location provider get_provider opts __opts__ sigver '4' return data
def is_client_error status return 400 < status < 499
def syncSwapBuffers n try v ctypes.c_int n cocoa.CGLSetParameter cocoa.CGLGetCurrentContext kCGLCPSwapInterval ctypes.pointer v except Exception logging.warning 'Unabletosetvsyncmode.Usingdriverdefaults'
def self accessing_obj accessed_obj *args **kwargs return accessing_obj accessed_obj
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def is_valid_short_number numobj region_codes region_codes_for_country_code numobj.country_code short_number national_significant_number numobj region_code _region_code_for_short_number_from_region_list numobj region_codes if len region_codes > 1 and region_code is not None return Truereturn is_valid_short_number_for_region short_number region_code
def CreatePath name version package_dir '%s-%s' % name version return os.path.join PYTHON_LIB 'versions' 'third_party' package_dir
@flake8extdef check_builtins_gettext logical_line tokens filename lines noqa if noqa returnmodulename os.path.normpath filename .split '/' [0]if '%s/tests' % modulename in filename returnif os.path.basename filename in 'i18n.py' '_i18n.py' returntoken_values [t[1] for t in tokens]i18n_wrapper '%s._i18n' % modulename if '_' in token_values i18n_import_line_found Falsefor line in lines split_line [elm.rstrip ' ' for elm in line.split ]if len split_line > 1 and split_line[0] 'from' and split_line[1] i18n_wrapper and '_' in split_line i18n_import_line_found Truebreakif not i18n_import_line_found msg 'N341 _frompythonbuiltinsmoduleisused.Use_from%sinstead.' % i18n_wrapper yield 0 msg
def set_debug debug global _debug_debug debug
def assign_parent node while node and isinstance node astroid.AssName astroid.Tuple astroid.List node node.parentreturn node
def bufsize_type_to_bufsize bf_type if bf_type 1 bufsize 1024elif bf_type 0 bufsize 1else bufsize bf_typereturn bufsize
def insert_into target keys value for key in keys[ -1 ] if key not in target target[key] {}target target[key]target[keys[ -1 ]] value
def avail_images call None if call 'action' raise SaltCloudSystemExit 'Theavail_imagesfunctionmustbecalledwith-for--function orwiththe--list-imagesoption' server user password _get_xml_rpc auth ' '.join [user password] image_pool server.one.imagepool.info auth -2 -1 -1 [1]images {}for image in _get_xml image_pool images[image.find 'NAME' .text] _xml_to_dict image return images
def getNewDerivation elementNode return GridDerivation elementNode
def verify_secret_key request if request.user.username return Trueelse key request.GET['secret'] user_id secret key.split '.' 1 try profile User.objects.get pk user_id except return Falseif key get_secret_key request profile request.user profile.userreturn Truereturn False
def create_drawdowns pnl hwm [0]idx pnl.indexdrawdown pd.Series index idx duration pd.Series index idx for t in range 1 len idx hwm.append max hwm[ t - 1 ] pnl.ix[t] drawdown.ix[t] hwm[t] - pnl.ix[t] duration.ix[t] 0 if drawdown.ix[t] 0 else duration.ix[ t - 1 ] + 1 return drawdown drawdown.max duration.max
def get_request_header key default None return request.headers.get key default
def get_list json_object parent_node_name child_node_name None if not json_object return []return_list []if isinstance json_object[parent_node_name] list for detail in json_object[parent_node_name] if child_node_name return_list.append detail[child_node_name] else return_list.append detail elif child_node_name return_list.append json_object[parent_node_name][child_node_name] else return_list.append json_object[parent_node_name] return return_list
def uniquify lst dct {}result []for k in lst if k not in dct result.append k dct[k] 1return result
def airport def prep r s3db.gis_location_filter r if r.interactive if r.component if r.component.name 'human_resource' s3db.org_site_staff_config r elif r.component.name 'inv_item' s3db.configure 'inv_inv_item' create False deletable False editable False listadd False elif r.method 'update' field r.table.obsoletefield.readable field.writable Truereturn Trues3.prep prepreturn s3_rest_controller rheader s3db.transport_rheader
def fixLinks document ext supported_schemes ['http' 'https' 'ftp' 'mailto']for node in domhelpers.findElementsWithAttribute document 'href' href node.getAttribute 'href' if urlparse.urlparse href [0] in supported_schemes continueif node.getAttribute 'class' 'absolute' continueif node.getAttribute 'class' .find 'listing' ! -1 continueif href.endswith 'html' or href[ href.rfind '#' ].endswith 'html' fname fext os.path.splitext href if '#' in fext fext ext + '#' + fext.split '#' 1 [1] else fext extnode.setAttribute 'href' fname + fext
def crop_image img x y width height img image_from_data img width min width img.width - x height min height img.height - y return img.copy x y width height
def image_file_to_string filename cleanup cleanup_scratch_flag graceful_errors True bool_digits False try call_tesseract filename scratch_text_name_root bool_digits text util.retrieve_text scratch_text_name_root except errors.Tesser_General_Exception if graceful_errors im Image.open filename text image_to_string im cleanup bool_digits else raisefinally if cleanup util.perform_cleanup scratch_image_name scratch_text_name_root return text
def vm_netstats vm_ None def _info vm_ dom _get_domain vm_ nics get_nics vm_ ret {'rx_bytes' 0 'rx_packets' 0 'rx_errs' 0 'rx_drop' 0 'tx_bytes' 0 'tx_packets' 0 'tx_errs' 0 'tx_drop' 0}for attrs in six.itervalues nics if 'target' in attrs dev attrs['target']stats dom.interfaceStats dev ret['rx_bytes'] + stats[0]ret['rx_packets'] + stats[1]ret['rx_errs'] + stats[2]ret['rx_drop'] + stats[3]ret['tx_bytes'] + stats[4]ret['tx_packets'] + stats[5]ret['tx_errs'] + stats[6]ret['tx_drop'] + stats[7]return retinfo {}if vm_ info[vm_] _info vm_ else for vm_ in list_domains info[vm_] _info vm_ return info
def _replace_booleans tok toknum tokval tokif toknum tokenize.OP if tokval '&' return tokenize.NAME 'and' elif tokval '|' return tokenize.NAME 'or' return toknum tokval return toknum tokval
def items_equal left right return sorted left sorted right
def apply_finite_diff order x_list y_list x0 S 0 N len x_list - 1 if len x_list ! len y_list raise ValueError 'x_listandy_listnotequalinlength.' delta finite_diff_weights order x_list x0 derivative 0for nu in range 0 len x_list derivative + delta[order][N][nu] * y_list[nu] return derivative
def dumps obj key None salt u'django.core.signing' serializer JSONSerializer compress False data serializer .dumps obj is_compressed Falseif compress compressed zlib.compress data if len compressed < len data - 1 data compressedis_compressed Truebase64d b64_encode data if is_compressed base64d '.' + base64d return TimestampSigner key salt salt .sign base64d
def versionOptions local True majorMinor sorted list {'.'.join v.split '.' [ 2] for v in availableVersions local local } reverse True major sorted list {v.split '.' [0] for v in majorMinor} reverse True special ['latest']return special + major + majorMinor
def construct **kwargs point_x kwargs.pop 'point_x' None point_y kwargs.pop 'point_y' None if 'point' in kwargs raise TypeError 'Unknownkeyword point' if None not in point_x point_y kwargs['point'] EccPoint point_x point_y eq1 pow Integer point_y 2 _curve.p x Integer point_x eq2 pow x 3 _curve.p x * -3 eq2 + xeq2 + _curve.beq2 % _curve.pif eq1 ! eq2 raise ValueError 'Thepointisnotonthecurve' d kwargs.get 'd' None if d is not None and 'point' in kwargs pub_key _curve.G * d if pub_key.x ! point_x or pub_key.y ! point_y raise ValueError 'PrivateandpublicECCkeysdonotmatch' return EccKey **kwargs
def op_sequence op *classes log []instances []for c in classes instances.append c log.append try op *instances except TypeError passreturn log
def createOrphanField fieldset address field_cls *args **kw save_size fieldset._current_sizetry fieldset._current_size addressfield field_cls fieldset *args **kw finally fieldset._current_size save_sizereturn field
def get_thread_count t config.NUMBA_NUM_THREADSif t < 1 raise ValueError 'Numberofthreadsspecifiedmustbe>0.' return t
def human_time seconds units [ u'y' 60 * 60 * 24 * 7 * 52 u'w' 60 * 60 * 24 * 7 u'd' 60 * 60 * 24 u'h' 60 * 60 u'm' 60 u's' 1 ]seconds int seconds if seconds < 60 return u'{0 2d}s'.format seconds for i in range len units - 1 unit1 limit1 units[i] unit2 limit2 units[ i + 1 ]if seconds > limit1 return u'{0 2d}{1}{2 2d}{3}'.format seconds // limit1 unit1 seconds % limit1 // limit2 unit2 return u'~inf'
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def tool_shed_is_this_tool_shed toolshed_base_url cleaned_toolshed_base_url common_util.remove_protocol_from_tool_shed_url toolshed_base_url cleaned_tool_shed common_util.remove_protocol_from_tool_shed_url str url_for '/' qualified True return cleaned_toolshed_base_url cleaned_tool_shed
def parse_expr s local_dict global_dict {}exec_ 'fromsympyimport*' global_dict try a parse s.strip mode 'eval' except SyntaxError raise SympifyError 'Cannotparse%s.' % repr s a Transform local_dict global_dict .visit a e compile a '<string>' 'eval' return eval e global_dict local_dict
def cube width dtype np.uint8 return np.ones width width width dtype dtype
def test_scenario_outline1_ru_from_string ru Language 'ru' scenario Scenario.from_string SCENARIO_OUTLINE1 language ru assert_equals scenario.name u'\u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439\u0432\u0431\u0430\u0437\u0443' assert_equals scenario.outlines [{u'\u0438\u043c\u044f' u'\u0412\u0430\u0441\u044f' u'\u0432\u043e\u0437\u0440\u0430\u0441\u0442' '22'} {u'\u0438\u043c\u044f' u'\u041f\u0435\u0442\u044f' u'\u0432\u043e\u0437\u0440\u0430\u0441\u0442' '30'}]
def set_wake_alarm alarm_time utils.write_one_line '/sys/class/rtc/rtc0/wakealarm' str alarm_time
def split_datastore_path datastore_path spl datastore_path.split '[' 1 [1].split ']' 1 path ''if len spl 1 datastore_url spl[0]else datastore_url path splreturn datastore_url path.strip
def _sym_decorrelation W s u linalg.eigh np.dot W W.T return np.dot np.dot u * 1.0 / np.sqrt s u.T W
def apply_sdb opts sdb_opts None import salt.utils.sdbif sdb_opts is None sdb_opts optsif isinstance sdb_opts string_types and sdb_opts.startswith 'sdb //' return salt.utils.sdb.sdb_get sdb_opts opts elif isinstance sdb_opts dict for key value in six.iteritems sdb_opts if value is None continuesdb_opts[key] apply_sdb opts value elif isinstance sdb_opts list for key value in enumerate sdb_opts if value is None continuesdb_opts[key] apply_sdb opts value return sdb_opts
def _blobs_page_start iterator page response page.prefixes tuple response.get 'prefixes' iterator.prefixes.update page.prefixes
def _maybe_get_pandas_wrapper X trim_head None trim_tail None if _is_using_pandas X None return _get_pandas_wrapper X trim_head trim_tail else return
def _get_date_value date try return '{0}'.format date except ValueError return 'Never'
def maybe_sanitize_url url mask u'**' if isinstance url string_t and u' //' in url return sanitize_url url mask return url
def _shrink_cache cache_dict args_dict locale_sensitive max_length divisor 5 cache_keys tuple cache_dict.keys overage len cache_keys - max_length if overage < 0 returnnumber_to_toss max_length // divisor + overage import randomif not hasattr random 'sample' returnfor doomed_key in random.sample cache_keys number_to_toss try del cache_dict[doomed_key]except KeyError passargs_dict.clear sensitivity_dict {}for pattern pattern_type flags args default_version locale in tuple cache_dict args_dict[ pattern pattern_type flags default_version locale ] argstry sensitivity_dict[ pattern_type pattern ] locale_sensitive[ pattern_type pattern ]except KeyError passlocale_sensitive.clear locale_sensitive.update sensitivity_dict
def submit_calculate_grades_csv request course_key task_type 'grade_course'task_class calculate_grades_csvtask_input {}task_key ''return submit_task request task_type task_class course_key task_input task_key
def delimitedList expr delim ' ' combine False if combine return Combine expr + ZeroOrMore delim + expr .setName _ustr expr + _ustr delim + '...' else return expr + ZeroOrMore Suppress delim + expr .setName _ustr expr + _ustr delim + '...'
@requires_good_networkdef test_downloads data_dir _TempDir path datasets._fake.data_path path data_dir update_path False assert_true op.isfile op.join path 'bar' assert_true datasets._fake.get_version is None
def phrase_extent_for_head tokens head_index begin tokens[head_index]['text']['beginOffset']end begin + len tokens[head_index]['text']['content'] for child in dependents tokens head_index child_begin child_end phrase_extent_for_head tokens child begin min begin child_begin end max end child_end return begin end
def _coefficient_t p t i j tR p.ringexpv1 [0] * R.ngens expv1[i] jexpv1 tuple expv1 p1 R 0 for expv in p if expv[i] j p1[monomial_div expv expv1 ] p[expv]return p1
def to_txt journal return journal.pprint
def starting_expression source_code offset word_finder worder.Worder source_code True expression starting starting_offset word_finder.get_splitted_primary_before offset if expression return expression + '.' + starting return starting
def bucket_download_file self Key Filename ExtraArgs None Callback None Config None return self.meta.client.download_file Bucket self.name Key Key Filename Filename ExtraArgs ExtraArgs Callback Callback Config Config
def getAbsTime return int time.mktime time.localtime
def register_log_filtering policy if policy global_redaction_engine.add_policy policy logfilter.add_log_redaction_filter_to_logger global_redaction_engine logging.root
def item_pack s3db.configure 'supply_item_pack' listadd False return s3_rest_controller
def get_resources_vms call None resFilter None includeConfig True log.debug 'Gettingresource vms.. filter {0} '.format resFilter resources query 'get' 'cluster/resources' ret {}for resource in resources if 'type' in resource and resource['type'] in ['openvz' 'qemu' 'lxc'] name resource['name']ret[name] resourceif includeConfig ret[name]['config'] get_vmconfig ret[name]['vmid'] ret[name]['node'] ret[name]['type'] if resFilter is not None log.debug 'Filtergiven {0} returningrequestedresource nodes'.format resFilter return ret[resFilter]log.debug 'Filternotgiven {0} returningallresource nodes'.format ret return ret
def _find_hypervisor cs hypervisor return utils.find_resource cs.hypervisors hypervisor
def overload func jit_options {} from .typing.templates import make_overload_template infer_globalopts _overload_default_jit_options.copy opts.update jit_options def decorate overload_func template make_overload_template func overload_func opts infer template if hasattr func '__module__' infer_global func types.Function template return overload_funcreturn decorate
def pop_local_dict _local_dict_stack.pop
def has_binding_new api module_name api_to_module[api]from importlib.util import find_specrequired ['QtCore' 'QtGui' 'QtSvg']if api in QT_API_PYQT5 QT_API_PYSIDE2 required.append 'QtWidgets' for submod in required try spec find_spec '%s.%s' % module_name submod except ImportError return Falseelse if spec is None return Falseif api QT_API_PYSIDE import PySidereturn check_version PySide.__version__ '1.0.3' return True
def bytes_leading raw_bytes needle ZERO_BYTE leading 0_byte needle[0]for x in raw_bytes if x _byte leading + 1else breakreturn leading
def copy_file source_path output_path output_dir os.path.dirname output_path if not os.path.exists output_dir os.makedirs output_dir shutil.copy source_path output_path
def infer_value_types values depth 0 inferred Unknown for value in sample values type infer_value_type value depth inferred combine_types inferred type return inferred
def _expand type try return short2long[type]except KeyError return type
def test_import_nested from os import pathpath2 import_item 'os.path' nt.assert_true path is path2
def get_config_paths config_home os.environ.get u'XDG_CONFIG_HOME' os.path.join os.path.expanduser u'~' u'.config' config_path join config_home u'powerline' config_paths [config_path]config_dirs os.environ.get u'XDG_CONFIG_DIRS' DEFAULT_SYSTEM_CONFIG_DIR if config_dirs is not None config_paths[ 0] reversed [join d u'powerline' for d in config_dirs.split u' ' ] plugin_path join os.path.realpath os.path.dirname __file__ u'config_files' config_paths.insert 0 plugin_path return config_paths
def get_pathext default_pathext None if default_pathext is None default_pathext os.pathsep.join ['.COM' '.EXE' '.BAT' '.CMD'] pathext os.environ.get 'PATHEXT' default_pathext return pathext
def test_lex_mangling_qmark entry tokenize 'foo?' assert entry [HySymbol 'is_foo' ] entry tokenize '?' assert entry [HySymbol '?' ] entry tokenize 'im?foo' assert entry [HySymbol 'im?foo' ] entry tokenize '.foo?' assert entry [HySymbol '.is_foo' ] entry tokenize 'foo.bar?' assert entry [HySymbol 'foo.is_bar' ] entry tokenize 'foo?.bar' assert entry [HySymbol 'is_foo.bar' ] entry tokenize '.foo?.bar.baz?' assert entry [HySymbol '.is_foo.bar.is_baz' ]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def pow_complexity num exp if num in 0 1 or exp in 0 1 return 0elif num & num - 1 0 return exp ** 1.092 * num.bit_length ** 1.65 / 623212911.121 else return exp ** 1.59 * num.bit_length ** 1.73 / 36864057619.3
def Binomial name n p succ 1 fail 0 return rv name BinomialDistribution n p succ fail
def _get_most_recent_snapshot snapshots max_snapshot_age_secs None now None if len snapshots 0 return Noneif not now now datetime.datetime.utcnow youngest_snapshot max snapshots key _get_snapshot_starttime snapshot_start datetime.datetime.strptime youngest_snapshot.start_time '%Y-%m-%dT%H %M %S.000Z' snapshot_age now - snapshot_start if max_snapshot_age_secs is not None if snapshot_age.total_seconds > max_snapshot_age_secs return Nonereturn youngest_snapshot
def softsign x return tf.nn.softsign x
def trg_validate uid res_type res_id signal cr assert isinstance signal basestring return WorkflowService.new cr uid res_type res_id .validate signal
def get_sample_size format return pa.get_sample_size format
def conductance G S T None weight None if T is None T set G - set S num_cut_edges cut_size G S T weight weight volume_S volume G S weight weight volume_T volume G T weight weight return num_cut_edges / min volume_S volume_T
def _base64ify data chunksize None if chunksize is None chunksize _base64_chunksizeb64 data.encode 'base64_codec' b64 b64.replace '\n' '' l len b64 if l > chunksize chunks []i 0while i < l chunks.append b64[i i + chunksize ] i + chunksizeb64 ''.join chunks return b64
def _project_correlation_factors X nm np.sqrt X * X .sum 1 ii np.flatnonzero nm > 1 if len ii > 0 X[ii ] / nm[ii][ None]
def delete_session session_year tables {'bill_id' ['bill_detail_vote_tbl' 'bill_history_tbl' 'bill_summary_vote_tbl' 'bill_analysis_tbl' 'bill_tbl' 'committee_hearing_tbl' 'daily_file_tbl'] 'bill_version_id' ['bill_version_authors_tbl' 'bill_version_tbl'] 'session_year' ['legislator_tbl' 'location_code_tbl']}logger.info 'Deletingalldataforsessionyear%s...' % session_year connection MySQLdb.connect user MYSQL_USER passwd MYSQL_PASSWORD db 'capublic' connection.autocommit True cursor connection.cursor for token names in tables.items for table_name in names sql "DELETEFROMcapublic.{table_name}where{token}like'{session_year}%';"sql sql.format **locals logger.debug 'executingsql "%s"' % sql cursor.execute sql cursor.close connection.close logger.info '...donedeletingsessiondata.'
def get_win32_compiler for v in sys.argv if 'mingw32' in v return 'mingw32'return 'msvc'
def p_conditional_expression_1 t pass
def _cluster_mask_to_indices components for ci c in enumerate components if not isinstance c slice components[ci] np.where c [0]return components
def create_weight_initializer fan_in_shape stddev 1 / math.sqrt np.prod fan_in_shape return tf.truncated_normal_initializer stddev stddev
def _get_level_lengths levels sentinel '' if len levels 0 return []control [True for x in levels[0]]result []for level in levels last_index 0lengths {}for i key in enumerate level if control[i] and key sentinel passelse control[i] Falselengths[last_index] i - last_index last_index ilengths[last_index] len level - last_index result.append lengths return result
def message_information text title None informative_text None details None buttons None default_button None exc_info False parent None if title is None title 'Information'if not text text 'Iamnotanumber.'return message QMessageBox.Information text title informative_text details buttons default_button exc_info parent
def discrete_log n a b order None prime_order None if order is None order n_order b n if prime_order is None prime_order isprime order if order < 1000 return _discrete_log_trial_mul n a b order elif prime_order if order < 1000000000000 return _discrete_log_shanks_steps n a b order return _discrete_log_pollard_rho n a b order return _discrete_log_pohlig_hellman n a b order
def discretize_center_1D model x_range x np.arange *x_range return model x
def gemset_present name ruby 'default' user None ret {'name' name 'result' None 'comment' '' 'changes' {}}ret _check_rvm ret user if ret['result'] is False return retif '@' in name ruby name name.split '@' ret _check_ruby ret ruby if not ret['result'] ret['result'] Falseret['comment'] 'Requestedrubyimplementationwasnotfound.'return retif name in __salt__['rvm.gemset_list'] ruby runas user ret['result'] Trueret['comment'] 'Gemsetalreadyexists.'else if __opts__['test'] ret['result'] Noneret['comment'] 'Settoinstallgemset{0}'.format name return retif __salt__['rvm.gemset_create'] ruby name runas user ret['result'] Trueret['comment'] 'Gemsetsuccessfullycreated.'ret['changes'][name] 'created'else ret['result'] Falseret['comment'] 'Gemsetcouldnotbecreated.'return ret
@webob.dec.wsgify@util.check_accept 'application/json' def get_aggregates req microversion.raise_404_if_not_version req 1 1 context req.environ['placement.context']uuid util.wsgi_path_item req.environ 'uuid' resource_provider objects.ResourceProvider.get_by_uuid context uuid aggregate_uuids resource_provider.get_aggregates return _send_aggregates req.response aggregate_uuids
def _active_contributors_id from_date to_date locale product editors Revision.objects.filter created__gte from_date .values_list 'creator' flat True .distinct reviewers Revision.objects.filter reviewed__gte from_date .values_list 'reviewer' flat True .distinct if to_date editors editors.filter created__lt to_date reviewers reviewers.filter reviewed__lt to_date if locale editors editors.filter document__locale locale reviewers reviewers.filter document__locale locale if product editors editors.filter Q document__products product | Q document__parent__products product reviewers reviewers.filter Q document__products product | Q document__parent__products product return set list editors + list reviewers
def purge_options app env docname if not hasattr env 'optionlist_all_options' returnenv.optionlist_all_options [option for option in env.optionlist_all_options if option['docname'] ! docname ]env.optionlist_indexed_options dict [ option['options']['config'] option for option in env.optionlist_all_options]
def is_errant_log log return log.should_hide is not True and log.action in mdl.NodeLog.PROJECT_REGISTERED and log.user is None and log.date.hour 4 and log.date.minute 0 or log.action in mdl.NodeLog.REGISTRATION_APPROVAL_APPROVED and log.date.hour 4 and log.date.minute 0
def lp2hp b a wo 1.0 a b map atleast_1d a b try wo float wo except TypeError wo float wo[0] d len a n len b if wo ! 1 pwo pow wo numpy.arange max d n else pwo numpy.ones max d n b.dtype.char if d > n outa a[ -1 ] * pwo outb resize b d outb[n ] 0.0outb[ n] b[ -1 ] * pwo[ n] else outb b[ -1 ] * pwo outa resize a n outa[d ] 0.0outa[ d] a[ -1 ] * pwo[ d] return normalize outb outa
def additive_chi2_kernel X Y None if issparse X or issparse Y raise ValueError 'additive_chi2doesnotsupportsparsematrices.' X Y check_pairwise_arrays X Y if X < 0 .any raise ValueError 'Xcontainsnegativevalues.' if Y is not X and Y < 0 .any raise ValueError 'Ycontainsnegativevalues.' result np.zeros X.shape[0] Y.shape[0] dtype X.dtype _chi2_kernel_fast X Y result return result
def sizeof_fmt num for item in ['bytes' 'KB' 'MB' 'GB'] if num < 1024.0 return '%3.1f%s' % num item num / 1024.0return '%3.1f%s' % num 'TB'
@cache_page XDOMAIN_PROXY_CACHE_TIMEOUT def xdomain_proxy request config XDomainProxyConfiguration.current if not config.enabled return HttpResponseNotFound allowed_domains []for domain in config.whitelist.split '\n' if domain.strip allowed_domains.append domain.strip if not allowed_domains log.warning u'Nowhitelistconfiguredforcross-domainproxy.YoucanconfigurethewhitelistinDjangoAdminusingtheXDomainProxyConfigurationmodel.' return HttpResponseNotFound context {'xdomain_masters' json.dumps {domain '*' for domain in allowed_domains} }return render_to_response 'cors_csrf/xdomain_proxy.html' context
def get_file_info_map file_infos return dict file_info[0] file_info[1 ] for file_info in file_infos
def visit_all_objects f ids set ls locals import inspectcf inspect.currentframe for o in gc.get_objects if o is ids or o is ls or o is cf continueif not id o in ids ids.add id o f o for so in gc.get_referents o if not id so in ids ids.add id so f so
def ensure_cache_root environ None ensure_directory cache_root environ environ
def replace_params_with_consts expr if expr.type lo.PARAM return create_const check_param_val expr.data expr.size else new_args []for arg in expr.args new_args.append replace_params_with_consts arg if isinstance expr.data lo.LinOp and expr.data.type lo.PARAM data_lin_op expr.dataval check_param_val data_lin_op.data data create_const val data_lin_op.size else data expr.datareturn lo.LinOp expr.type expr.size new_args data
def jupyter_notebook_skeleton py_version sys.version_infonotebook_skeleton {'cells' [] 'metadata' {'kernelspec' {'display_name' 'Python' + str py_version[0] 'language' 'python' 'name' 'python' + str py_version[0] } 'language_info' {'codemirror_mode' {'name' 'ipython' 'version' py_version[0]} 'file_extension' '.py' 'mimetype' 'text/x-python' 'name' 'python' 'nbconvert_exporter' 'python' 'pygments_lexer' 'ipython' + str py_version[0] 'version' '{0}.{1}.{2}'.format *sys.version_info[ 3] }} 'nbformat' 4 'nbformat_minor' 0}return notebook_skeleton
def csrf request def _get_val token get_token request if token is None return 'NOTPROVIDED'else return force_text token return {'csrf_token' SimpleLazyObject _get_val }
def get_user_permission_full_codename perm User get_user_model model_name User._meta.model_namereturn u'%s.%s_%s' % User._meta.app_label perm model_name
def get_other_props all_props reserved_props if hasattr all_props 'items' and callable all_props.items return dict [ k v for k v in all_props.items if k not in reserved_props ]
def test_trigonometric Chart datas chart Chart interpolate 'trigonometric' chart make_data chart datas assert chart.render
def _determine_function_name_type node if not node.is_method return 'function'if node.decorators decorators node.decorators.nodeselse decorators []for decorator in decorators if isinstance decorator astroid.Name or isinstance decorator astroid.Getattr and decorator.attrname 'abstractproperty' infered safe_infer decorator if infered and infered.qname in PROPERTY_CLASSES return 'attr'elif isinstance decorator astroid.Getattr and decorator.attrname in 'setter' 'deleter' return 'attr'return 'method'
def default_filter src dst return dst
def server_track request event_type event page None if event_type.startswith '/event_logs' and request.user.is_staff returntry username request.user.usernameexcept username 'anonymous'event {'username' username 'ip' _get_request_ip request 'referer' _get_request_header request 'HTTP_REFERER' 'accept_language' _get_request_header request 'HTTP_ACCEPT_LANGUAGE' 'event_source' 'server' 'event_type' event_type 'event' event 'agent' _get_request_header request 'HTTP_USER_AGENT' .decode 'latin1' 'page' page 'time' datetime.datetime.utcnow 'host' _get_request_header request 'SERVER_NAME' 'context' eventtracker.get_tracker .resolve_context }shim.remove_shim_context event log_event event
def split_by array group_size filler args [iter array ] * group_size return list map list zip_longest fillvalue filler *args
def compile_string template_string origin if settings.TEMPLATE_DEBUG from debug import DebugLexer DebugParser lexer_class parser_class DebugLexer DebugParser else lexer_class parser_class Lexer Parser lexer lexer_class template_string origin parser parser_class lexer.tokenize return parser.parse
def xl_range first_row first_col last_row last_col range1 xl_rowcol_to_cell first_row first_col range2 xl_rowcol_to_cell last_row last_col return range1 + ' ' + range2
def state_path_rel *args return os.path.join CONF.state_path *args
def get_input prompt if sys.version_info.major > 3 return input prompt else return raw_input prompt .decode u'utf8'
def eGetS Handle pIOType Channel pValue x1 if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pv ctypes.c_double pValue ec staticLib.eGetS Handle pIOType Channel ctypes.byref pv x1 if ec ! 0 raise LabJackException ec return pv.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def put_original_alpha original_image new_image try alpha_idx original_image.mode.index 'A' alpha_channel original_image.split [alpha_idx]new_image.putalpha alpha_channel except ValueError passreturn new_image
def geoexplorer bing_key settings.get_gis_api_bing google_key settings.get_gis_api_google yahoo_key settings.get_gis_api_yahoo print_service settings.get_gis_print_service geoserver_url settings.get_gis_geoserver_url response.title 'GeoExplorer'return dict bing_key bing_key google_key google_key yahoo_key yahoo_key print_service print_service geoserver_url geoserver_url
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def remove_operation feed activities trim True batch_interface None t timer msg_format 'running%s.remove_manyoperationfor%sactivitiesbatchinterface%s'logger.debug msg_format feed len activities batch_interface feed.remove_many activities trim trim batch_interface batch_interface logger.debug 'removemanyoperationtook%sseconds' t.next
def _label_all rag attr_name node rag.nodes [0]new_label rag.node[node]['labels'][0]for n d in rag.nodes_iter data True d[attr_name] new_label
def get_server_id if salt.utils.is_proxy return {}return {'server_id' abs hash __opts__.get 'id' '' % 2 ** 31 }
def flatten_errors cfg res levels None results None if levels is None levels []results []if res True return sorted results if res False or isinstance res Exception results.append levels[ ] None res if levels levels.pop return sorted results for key val in list res.items if val True continueif isinstance cfg.get key collections.Mapping levels.append key flatten_errors cfg[key] val levels results continueresults.append levels[ ] key val if levels levels.pop return sorted results
def getClippedSimplifiedLoopPath clip loopPath radius return getSimplifiedPath getClippedLoopPath clip loopPath radius
def _parse_resolve contents _read_file _DEB_RESOLV_FILE return contents
def random_circuit ngates nqubits gate_space X Y Z S T H CNOT SWAP qubit_space range nqubits result []for i in range ngates g random.choice gate_space if g CNotGate or g SwapGate qubits random.sample qubit_space 2 g g *qubits else qubit random.choice qubit_space g g qubit result.append g return Mul *result
def snapshot_from_bdm snapshot_id template copy_from_template 'disk_bus' 'device_type' 'boot_index' 'delete_on_termination' 'volume_size' 'device_name' snapshot_dict {'source_type' 'snapshot' 'destination_type' 'volume' 'snapshot_id' snapshot_id}for key in copy_from_template snapshot_dict[key] template.get key return BlockDeviceDict snapshot_dict
def get_vmdk_detach_config_spec client_factory device destroy_disk False config_spec client_factory.create 'ns0 VirtualMachineConfigSpec' device_config_spec []virtual_device_config_spec detach_virtual_disk_spec client_factory device destroy_disk device_config_spec.append virtual_device_config_spec config_spec.deviceChange device_config_specreturn config_spec
def write_pack_object f type object sha None if type in DELTA_TYPES delta_base object objectelse delta_base Noneheader bytes pack_object_header type delta_base len object comp_data zlib.compress object crc32 0for data in header comp_data f.write data if sha is not None sha.update data crc32 binascii.crc32 data crc32 return crc32 & 4294967295
def tsharkVersion versionStr quietRun 'tshark-v' versionMatch re.findall 'TShark[^\\d]* \\d+.\\d+.\\d+ ' versionStr return versionMatch[0]
def translate_snapshot_exception method def wrapper self ctx snapshot_id *args **kwargs try res method self ctx snapshot_id *args **kwargs except keystone_exception.NotFound cinder_exception.NotFound _reraise exception.SnapshotNotFound snapshot_id snapshot_id return resreturn translate_cinder_exception wrapper
def migrate_meter_table conn table meter_table conn.table table meter_filter "RowFilter 'regexstring [\\w\\._-]*_\\d{19}_\\w*' "gen meter_table.scan filter meter_filter for row data in gen parts row.rsplit '_' 2 new_row hbase_utils.prepare_key *parts meter_table.put new_row data meter_table.delete row
def take n iterable return islice iterable n
def get_downloaded_track_list albumpath downloaded_track_list []for root dirs files in os.walk albumpath for _file in files extension os.path.splitext _file [1].lower [1 ]if extension in headphones.MEDIA_FORMATS downloaded_track_list.append os.path.join root _file return downloaded_track_list
def _get_current_inventory_resources conn rp cur_res_sel sa.select [_INV_TBL.c.resource_class_id] .where _INV_TBL.c.resource_provider_id rp.id existing_resources conn.execute cur_res_sel .fetchall return set [r[0] for r in existing_resources]
def construct_message labels face_annotations response_text PRETEXTlabel_desc ''pos_labels ['verylikely' 'likely' 'possibly']for i in range len labels label_desc + '\nScoreis%sfor%s' % labels[i]['score'] labels[i]['description'] joy anger sorrow surprise extract_sentiment face_annotations for i in range len pos_labels if joy[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingjoy' % joy[i] pos_labels[i] if anger[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencinganger' % anger[i] pos_labels[i] if sorrow[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingsorrow' % sorrow[i] pos_labels[i] if surprise[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingsurprise' % surprise[i] pos_labels[i] if not label_desc label_desc 'Nolabelsfound.'response_text + label_descresp twilio.twiml.Response resp.message response_text return resp
def import_image src repo tag None client _get_client status base_status.copy try ret client.import_image src repository repo tag tag if ret image_logs _info _parse_image_multilogs_string ret _create_image_assemble_error_status status ret image_logs if status['status'] is not False infos _get_image_infos image_logs[0]['status'] _valid status comment 'Image{0}wascreated'.format infos['Id'] id_ infos['Id'] out ret else _invalid status except Exception _invalid status out traceback.format_exc return status
def _resp_status_property def getter self return '%s%s' % self.status_int self.title def setter self value if isinstance value int long self.status_int valueself.explanation self.title RESPONSE_REASONS[value][0]else if isinstance value unicode value value.encode 'utf-8' self.status_int int value.split '' 1 [0] self.explanation self.title value.split '' 1 [1]return property getter setter doc "RetrieveandsettheResponsestatus e.g.'200OK'"
def get_localzone return _get_localzone
def get_test_value v if not isinstance v graph.Variable v_var theano.tensor.as_tensor_variable v else v_var vreturn PureOp._get_test_value v_var
def generic_send_email_script_template_factory identifier event name description help_text initial None attrs {}attrs.setdefault u'identifier' identifier attrs.setdefault u'event' event attrs.setdefault u'name' name attrs.setdefault u'description' description attrs.setdefault u'help_text' help_text attrs.setdefault u'initial' initial or dict return type str u'GenericSendEmailScriptTemplate' GenericSendEmailScriptTemplate attrs
def test_collect_2 a b x symbols 'a b x' assert collect a * cos x + sin x + b * cos x + sin x sin x + cos x a + b * cos x + sin x
def add_parse_callback callback options.add_parse_callback callback
@app.route '/drip' def drip args CaseInsensitiveDict request.args.items duration float args.get 'duration' 2 numbytes min int args.get 'numbytes' 10 10 * 1024 * 1024 code int args.get 'code' 200 pause duration / numbytes delay float args.get 'delay' 0 if delay > 0 time.sleep delay def generate_bytes for i in xrange numbytes yield u'*'.encode 'utf-8' time.sleep pause response Response generate_bytes headers {'Content-Type' 'application/octet-stream' 'Content-Length' str numbytes } response.status_code codereturn response
def attachment_destroy context attachment_id return IMPL.attachment_destroy context attachment_id
def fail_without_changes name ret {'name' name 'changes' {} 'result' False 'comment' 'Failure!'}if __opts__['test'] ret['result'] Falseret['comment'] "Ifweweren'ttesting thiswouldbeafailure!"return ret
def rotation_multi x rg 20 is_random False row_index 0 col_index 1 channel_index 2 fill_mode 'nearest' cval 0.0 if is_random theta np.pi / 180 * np.random.uniform - rg rg else theta np.pi / 180 * rg rotation_matrix np.array [[np.cos theta - np.sin theta 0] [np.sin theta np.cos theta 0] [0 0 1]] h w x[0].shape[row_index] x[0].shape[col_index] transform_matrix transform_matrix_offset_center rotation_matrix h w results []for data in x results.append apply_transform data transform_matrix channel_index fill_mode cval return np.asarray results
def support_redirect request **kwargs return HttpResponseRedirect get_support_url request
def challenge crap ''for x in range random.randrange 15 25 crap crap + chr random.randint 65 90 crap md5 crap .digest return crap
def stat_mode_to_index_mode mode if S_ISLNK mode return S_IFLNKif S_ISDIR mode or S_IFMT mode S_IFGITLINK return S_IFGITLINKreturn S_IFREG | 420 | mode & 73
def sortdict dict items dict.items items.sort reprpairs [ '%r %r' % pair for pair in items]withcommas ' '.join reprpairs return '{%s}' % withcommas
def search_channel_tag key None category None return Channel.objects.get_by_tag key key category category
def apply_metaquery_filter session query metaquery for k value in six.iteritems metaquery key k[9 ]try _model sql_utils.META_TYPE_MAP[type value ]except KeyError raise ceilometer.NotImplementedError 'Queryon% key sisof% value stypeandisnotsupported' % {'key' k 'value' type value } else meta_alias aliased _model on_clause and_ models.Resource.internal_id meta_alias.id meta_alias.meta_key key query query.outerjoin meta_alias on_clause query query.filter meta_alias.value value return query
def deny_demo request messages.warning request _ u'Youcannotchangedemoaccountonthedemoserver.' return redirect_profile request.POST.get u'activetab'
def clear_alarms alarm if _TRAFFICCTL cmd _traffic_ctl 'alarm' 'clear' alarm else cmd _traffic_line '--clear_alarms' alarm log.debug 'Running %s' cmd return _subprocess cmd
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def _parse_ndp_options raw prev offset 0 buf_len None _offset offsetif buf_len is None buf_len len raw remaining buf_len - offset r []while offset < buf_len - 2 if buf_len - offset % 8 ! 0 raise RuntimeError 'Badoptiondatalength' offset o NDOptionBase.unpack_new raw offset buf_len prev prev r.append o return offset r
def _compile pathname timestamp codestring open pathname 'rU' .read if codestring and codestring[ -1 ] ! '\n' codestring codestring + '\n' code __builtin__.compile codestring pathname 'exec' try f open pathname + _suffix_char 'wb' except IOError passelse f.write '\x00\x00\x00\x00' f.write struct.pack '<I' timestamp marshal.dump code f f.flush f.seek 0 0 f.write imp.get_magic f.close return code
def group_members request slug template_name 'groups/group_members.html' group get_object_or_404 Group slug slug is_active True member_list group.members.all return render request template_name {'group' group 'member_list' member_list}
def fetch_raw_image context target image_id images.fetch context image_id target
def validate_is_document_type option value if not isinstance value collections.MutableMapping RawBSONDocument raise TypeError '%smustbeaninstanceofdict bson.son.SON bson.raw_bson.RawBSONDocument oratypethatinheritsfromcollections.MutableMapping' % option
def dict_from_cookiejar cj cookie_dict {}for cookie in cj cookie_dict[cookie.name] cookie.valuereturn cookie_dict
def sweep_poly t poly phi 0 phase _sweep_poly_phase t poly phi * pi / 180 return cos phase + phi
def set_backend name None possible list _BACKENDS if name is None names []else names name.split ' ' for name in reversed names for backend in list possible if backend.NAME name possible.remove backend possible.insert 0 backend breakelse raise LookupError 'Unkownbackend %r' % name if 'null' not in names possible [b for b in possible if b.NAME ! 'null' ]_ACTIVE_BACKENDS[ ] possible
def alpha_max emp_cov A np.copy emp_cov A.flat[ A.shape[0] + 1 ] 0return np.max np.abs A
def change_qq_header uri headers body return uri headers body
def gone ctx.status '410Gone'header 'Content-Type' 'text/html' return output 'gone'
def getSafeExString ex encoding None retVal exif getattr ex 'message' None retVal ex.messageelif getattr ex 'msg' None retVal ex.msgreturn getUnicode retVal encoding encoding
def prepare annotations def expand_annotation annotation if isinstance annotation dict return MapAnnotation annotation elif isinstance annotation string_t return mlazy instantiate annotation return annotationif annotations is None return elif not isinstance annotations list tuple annotations annotations return [expand_annotation anno for anno in annotations]
@api_view ['GET'] @permission_classes [permissions.IsAuthenticatedOrReadOnly] def has_node request node_id request.GET.get 'node_id' '' exists storage.has_node node_id return Response {'exists' exists}
def StartOperation description operation DatastoreAdminOperation description description id db.allocate_ids db.Key.from_path DatastoreAdminOperation.kind 1 1 [0] operation.put config _CreateDatastoreConfig return operation
def normalized_cut_size G S T None weight None if T is None T set G - set S num_cut_edges cut_size G S T T weight weight volume_S volume G S weight weight volume_T volume G T weight weight return num_cut_edges * 1 / volume_S + 1 / volume_T
def positive_int argument value int argument if value < 1 raise ValueError 'negativeorzerovalue;mustbepositive' return value
def compute_node_delete context compute_id return IMPL.compute_node_delete context compute_id
def build_provider_location system lun_type lun_id version location_dict {'system' system 'type' lun_type 'id' six.text_type lun_id 'version' version}return dump_provider_location location_dict
def contains_at_depth haystack needle n if not hasattr haystack '__iter__' return Falseif n 0 return needle in haystack else for item in haystack if contains_at_depth item needle n - 1 return Truereturn False
def from_7L7777M data return data[0] + data[1] << 7 + data[2] << 14 + data[3] << 21 + data[4] << 28
def urlparams url_ hash None **query url urlparse.urlparse url_ fragment hash if hash is not None else url.fragment q url.queryquery_dict dict urlparse.parse_qsl force_bytes q if q else {} query_dict.update k force_bytes v if v is not None else v for k v in query.items query_string urlencode [ k urllib.unquote v for k v in query_dict.items if v is not None ] new urlparse.ParseResult url.scheme url.netloc url.path url.params query_string fragment return new.geturl
def get_external_downloader external_downloader bn os.path.splitext os.path.basename external_downloader [0]return _BY_NAME[bn]
def _check_vlim vlim return not np.isscalar vlim and vlim is not None
def pyramid_gaussian image max_layer -1 downscale 2 sigma None order 1 mode 'reflect' cval 0 _check_factor downscale image img_as_float image layer 0rows image.shape[0]cols image.shape[1]prev_layer_image image yield image while layer ! max_layer layer + 1layer_image pyramid_reduce prev_layer_image downscale sigma order mode cval prev_rows rowsprev_cols colsprev_layer_image layer_imagerows layer_image.shape[0]cols layer_image.shape[1]if prev_rows rows and prev_cols cols break yield layer_image
def empty_formatter view value return ''
def build_cluster_status_fsm convergence_loop_fsm return constructFiniteStateMachine inputs ClusterStatusInputs outputs ClusterStatusOutputs states ClusterStatusStates initial ClusterStatusStates.DISCONNECTED table _CLUSTER_STATUS_FSM_TABLE richInputs [_ConnectedToControlService _StatusUpdate] inputContext {} world MethodSuffixOutputer ClusterStatus convergence_loop_fsm
def get_br_service_url node return 'http //{0} {1}{2}'.format node hermes_constants.BR_SERVICE_PORT hermes_constants.BR_SERVICE_PATH
def canon_bp p if isinstance p TensExpr return p.canon_bp return p
def course_image_url course image_key 'course_image' if course.static_asset_path url '/static/' + course.static_asset_path or getattr course 'data_dir' '' if hasattr course image_key and getattr course image_key ! course.fields[image_key].default url + '/' + getattr course image_key else url + '/images/' + image_key + '.jpg' elif not getattr course image_key url settings.STATIC_URL + settings.DEFAULT_COURSE_ABOUT_IMAGE_URL else loc StaticContent.compute_location course.id getattr course image_key url StaticContent.serialize_asset_key_with_slash loc return url
def template_validator request settings_modules {}for mod in settings.ADMIN_FOR settings_module __import__ mod {} {} [''] settings_modules[settings_module.SITE_ID] settings_modulemanipulator TemplateValidator settings_modules new_data errors {} {} if request.POST new_data request.POST.copy errors manipulator.get_validation_errors new_data if not errors request.user.message_set.create message 'Thetemplateisvalid.' return render_to_response 'admin/template_validator.html' {'title' 'Templatevalidator' 'form' oldforms.FormWrapper manipulator new_data errors } context_instance template.RequestContext request
def check_if_expired if not has_expired returnlimits get_limits expires_on formatdate limits.get u'expiry' support_email limits.get u'support_email' if limits.upgrade_url message _ u'Yoursubscriptionexpiredon{0}.Torenew {1}.' .format expires_on get_upgrade_link limits.upgrade_url elif support_email message _ u'Yoursubscriptionexpiredon{0}.Torenew pleasesendanemailto{1}.' .format expires_on support_email else message _ u'Yoursubscriptionexpiredon{0}' .format expires_on frappe.throw message SiteExpiredError
def getComplexPath vector3Path complexPath []for point in vector3Path complexPath.append point.dropAxis return complexPath
def make_contrib superclass func None def contribute_to_class self cls name if func func self cls name else super superclass self .contribute_to_class cls name setattr cls self.name Creator self return contribute_to_class
def check_access_and_print_warning sock_dir if os.access sock_dir os.R_OK and os.access sock_dir os.W_OK and os.access sock_dir os.X_OK returnelse print 'WARNING Eventswillnotbereported notabletoaccess{0} '.format sock_dir
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
def config_file_provider registry xml_parent data cfp XML.SubElement xml_parent 'org.jenkinsci.plugins.configfiles.builder.ConfigFileBuildStep' cfp.set 'plugin' 'config-file-provider' config_file_provider_builder cfp data
def timeformat when None when when if when else time.time tz_offset datetime.utcfromtimestamp when - datetime.fromtimestamp when tz_offset tz_offset.days * 86400 + tz_offset.seconds when datetime.utcfromtimestamp when - tz_offset tz_hour abs int tz_offset // 3600 tz_mins abs int tz_offset // 60 % 60 tz_sign '-' if tz_offset > 0 else '+' return '%d-%02d-%02d%02d %02d %02d%s%02d%02d' % when.year when.month when.day when.hour when.minute when.second tz_sign tz_hour tz_mins
def findStoredTicket bridge assert bridgeticketFile const.STATE_LOCATION + const.CLIENT_TICKET_FILE log.debug "Attemptingtoreadmasterkeyandticketfromfile`%s'." % ticketFile yamlBlurb util.readFromFile ticketFile if yamlBlurb is None or len yamlBlurb 0 return Nonetickets yaml.safe_load yamlBlurb try timestamp masterKey ticket tickets[str bridge ]except KeyError log.info "Foundnoticketforbridge`%s'." % str bridge return Nonelog.debug 'Deletingticketsinceitisabouttoberedeemed.' del tickets[str bridge ]util.writeToFile yaml.dump tickets ticketFile ticketAge int time.time - timestamp if ticketAge > const.SESSION_TICKET_LIFETIME log.warning 'Wedidhaveaticketbutitalreadyexpired%sago.' % str datetime.timedelta seconds ticketAge - const.SESSION_TICKET_LIFETIME return Nonereturn masterKey ticket
def _prep_panel_data data if isinstance data Panel return datareturn Panel.fromDict data
def showpage path try import webbrowserwebbrowser.open_new os.path.abspath path except traceback.print_exc
def _find_migrate_repo path os.path.join os.path.abspath os.path.dirname __file__ 'migrate_repo' assert os.path.exists path return path
@subliminal.command @click.option '--clear-subliminal' is_flag True help "Clearsubliminal'scache.UsethisONLYifyourcacheiscorruptedorifyouexperienceissues." @click.pass_contextdef cache ctx clear_subliminal if clear_subliminal for file in glob.glob os.path.join ctx.parent.params['cache_dir'] cache_file + '*' os.remove file click.echo "Subliminal'scachecleared." else click.echo 'Nothingdone.'
def getProgramFilesPath keyname 'SOFTWARE\\Microsoft\\Windows\\CurrentVersion'currentV win32api.RegOpenKeyEx win32con.HKEY_LOCAL_MACHINE keyname 0 win32con.KEY_READ return win32api.RegQueryValueEx currentV 'ProgramFilesDir' [0]
def merge_init_structs s0 s1 for k in s1['model'] assert not k in s0['model'] 'Error lookslikeparameter%sistryingtobeinitializedtwice!' % k s0['model'][k] s1['model'][k]s0['update'].extend s1['update'] s0['regularize'].extend s1['regularize']
def interp_avg data_low data_high n if isinstance data_low int long for i in range 1 n yield data_low * n - i + data_high * i / n else pairs zip data_low data_high pair_iters [interp_avg x y n for x y in pairs]for i in range 1 n yield [iter.next for iter in pair_iters]
def test_regression_3920 loc EarthLocation.from_geodetic 0 * u.deg 0 * u.deg 0 time Time u'2010-1-1' aa AltAz location loc obstime time sc SkyCoord 10 * u.deg 3 * u.deg assert sc.transform_to aa .shape tuple sc2 SkyCoord 10 * u.deg 3 * u.deg 1 * u.AU assert sc2.transform_to aa .shape tuple icoo ICRS sc.data icoo2 ICRS sc2.data assert icoo.transform_to aa .shape tuple assert icoo2.transform_to aa .shape tuple
def _qname_matches tag namespace qname if qname is None member_tag Nonemember_namespace Noneelif qname.startswith '{' member_namespace qname[1 qname.index '}' ]member_tag qname[ qname.index '}' + 1 ]else member_namespace Nonemember_tag qnamereturn tag is None and namespace is None or namespace is None and member_tag tag or tag is None and member_namespace namespace or tag is None and namespace '' and member_namespace is None or tag member_tag and namespace member_namespace or tag member_tag and namespace '' and member_namespace is None
def cs_operation func ordinate False get False if get func.errcheck check_cs_getdbl_param POINTER c_double else func.errcheck check_cs_opdbl_param c_doubleif ordinate func.argtypes [CS_PTR c_uint c_uint dbl_param]else func.argtypes [CS_PTR c_uint dbl_param]func.restype c_intreturn func
def get_extras_path file_path if extras_dir is None return file_pathreturn os.path.join extras_dir file_path
def CreateAdsWithCustomizations client adgroup_ids feed_name adgroup_ad_service client.GetService 'AdGroupAdService' text_ad {'xsi_type' 'TextAd' 'headline' 'LuxuryCruiseto{ %s.Name}' % feed_name 'description1' 'Only{ %s.Price}' % feed_name 'description2' 'Offerendsin{ countdown %s.Date }!' % feed_name 'finalUrls' ['http //www.example.com'] 'displayUrl' 'www.example.com'}operations [{'operator' 'ADD' 'operand' {'adGroupId' adgroup 'ad' text_ad}} for adgroup in adgroup_ids]response adgroup_ad_service.mutate operations if response and 'value' in response for ad in response['value'] print "CreatedanadwithID'%s' type'%s' andstatus'%s'." % ad['ad']['id'] ad['ad']['Ad.Type'] ad['status'] else raise errors.GoogleAdsError 'Noadswereadded.'
def Plotly **options clf options.pop 'clf' True Config **options import plotly.plotly as plotlyurl plotly.plot_mpl pyplot.gcf if clf Clf return url
def makeFakeKQueue testKQueue testKEvent @implementer _IKQueue class FakeKQueue object kqueue testKQueuekevent testKEventreturn FakeKQueue
def _add_axis_labels_title plot xlabel ylabel title try if hasattr plot 'set_title' plot.set_title title plot.set_xlabel xlabel plot.set_ylabel ylabel else plot.title title plot.xlabel xlabel plot.ylabel ylabel except pass
def test_read_write_info tempdir _TempDir info read_info raw_fname temp_file op.join tempdir 'info.fif' info['dev_head_t']['trans'] np.eye 4 t1 info['dev_head_t']['trans']write_info temp_file info info2 read_info temp_file t2 info2['dev_head_t']['trans']assert_true len info['chs'] len info2['chs'] assert_array_equal t1 t2 creator u'\xe9'info read_info chpi_fname info['proc_history'][0]['creator'] creatorinfo['hpi_meas'][0]['creator'] creatorinfo['subject_info']['his_id'] creatorwrite_info temp_file info info read_info temp_file assert_equal info['proc_history'][0]['creator'] creator assert_equal info['hpi_meas'][0]['creator'] creator assert_equal info['subject_info']['his_id'] creator
def guard_loglevel global LOG_FLAGLOG_FLAG True
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def addEnvPath env name value try oldval env[name]if not oldval.endswith ';' oldval oldval + ';' except KeyError oldval ''if not value.endswith ';' value value + ';' env[name] oldval + value
def _mask_trigs events mask mask_type if not isinstance mask_type string_types or mask_type not in 'not_and' 'and' raise ValueError 'mask_typemustbe"not_and"or"and" got%s' % mask_type if mask is not None if not isinstance mask int raise TypeError 'Youprovideda n %s.' % type mask + 'MaskmustbeanintorNone.' n_events len events if n_events 0 return events.copy if mask is not None if mask_type 'not_and' mask np.bitwise_not mask elif mask_type ! 'and' if mask_type is not None raise ValueError "'mask_type'shouldbeeither'and'or'not_and' insteadof'%s'" % mask_type events[ 1 ] np.bitwise_and events[ 1 ] mask events events[ events[ 1] ! events[ 2] ]return events
def test_host_role_merge_deduping @roles 'r1' 'r2' @hosts 'a' def command passtrue_eq_hosts command ['a' 'b' 'c'] env {'roledefs' fake_roles}
def ivp v z n 1 if not isinstance n int or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n 0 return iv v z else return _bessel_diff_formula v z n iv 1
def computeCRC data crc 65535for a in data idx __crc16_table[ crc ^ ord a & 255 ]crc crc >> 8 & 255 ^ idx swapped crc << 8 & 65280 | crc >> 8 & 255 return swapped
def LHOST return commands.getoutput '/sbin/ifconfig' .split '\n' [1].split [1]
def idzp_id eps A A np.asfortranarray A k idx rnorms _id.idzp_id eps A n A.shape[1]proj A.T.ravel [ k * n - k ].reshape k n - k order 'F' return k idx proj
def validate_integer value name min_value None max_value None try value int str value except ValueError UnicodeEncodeError msg _ '% value_name smustbeaninteger' raise exception.InvalidInput reason msg % {'value_name' name} if min_value is not None if value < min_value msg _ '% value_name smustbe> % min_value d' raise exception.InvalidInput reason msg % {'value_name' name 'min_value' min_value} if max_value is not None if value > max_value msg _ '% value_name smustbe< % max_value d' raise exception.InvalidInput reason msg % {'value_name' name 'max_value' max_value} return value
def load_all unload_all plugins config.get 'ckan.plugins' '' .split + find_system_plugins if 'synchronous_search' not in plugins and asbool config.get 'ckan.search.automatic_indexing' True log.debug 'Loadingthesynchronoussearchplugin' plugins.append 'synchronous_search' load *plugins
def get_forums query_result user it itertools.groupby query_result operator.itemgetter 0 if user.is_authenticated for key value in it forums key [ item[1] item[2] for item in value] else for key value in it forums key [ item[1] None for item in value] return forums
def _ppid ret {}if __grains__['kernel'] 'SunOS' cmd 'ps-a-opid ppid|tail-n+2'else cmd 'ps-ax-opid ppid|tail-n+2'out __salt__['cmd.run'] cmd python_shell True for line in out.splitlines pid ppid line.split ret[pid] ppidreturn ret
def hash_data data return base64.b64encode hashlib.sha1 data .digest
def sizefilter st size if size is None or size > 0 and st.st_size > abs size or size < 0 and st.st_size < abs size return Truereturn False
def setup_authentication conf None if conf is None conf cfg.CONFfor method_name in conf.auth.methods if method_name not in constants._DEFAULT_AUTH_METHODS option cfg.StrOpt method_name _register_auth_plugin_opt conf option
def gen_random_usernames while 1 yield hex int random.random * 16 ** 12 [2 ].zfill 12 .decode 'ASCII'
def singularities expr sym if not expr.is_rational_function sym raise NotImplementedError 'Algorithmsfindingsingularitiesfornonrationalfunctionsarenotyetimplemented' else return solveset simplify 1 / expr sym
def relevant_values all_values return dict option value for option value in six.iteritems all_values if _relevant option and cli.option_was_set option value
def remove_repeating_from_task task_name s module str task_name .rpartition u'.' [0] + u'.' return remove_repeating module s
def escape_cdata cdata return xml_safe cdata .replace ']]>' ']]>]]&gt;<![CDATA['
@pytest.fixture scope u'session' def celery_enable_logging return False
def start_notification_server global NOTIFICATION_SERVERif NOTIFICATION_SERVER is None NOTIFICATION_SERVER NotificationServer NOTIFICATION_SERVER.start return NOTIFICATION_SERVER
def _get_deps deps tree_base saltenv 'base' deps_list ''if deps is None return deps_listif not isinstance deps list raise SaltInvocationError "'deps'mustbeaPythonlistorcomma-separatedstring" for deprpm in deps parsed _urlparse deprpm depbase os.path.basename deprpm dest os.path.join tree_base depbase if parsed.scheme __salt__['cp.get_url'] deprpm dest saltenv saltenv else shutil.copy deprpm dest deps_list + '{0}'.format dest return deps_list
def register linter linter.register_checker ExceptionsChecker linter
def Sourceify path if '$ ' in path return pathif os.path.isabs path return pathreturn srcdir_prefix + path
def _fetch_templates src templates []log.debug 'Listingcontentsof{0}'.format src for item in os.listdir src s os.path.join src item if os.path.isdir s template_path os.path.join s TEMPLATE_FILE_NAME if os.path.isfile template_path templates.append _get_template template_path item else log.debug 'Directorydoesnotcontain{1}{0}'.format template_path TEMPLATE_FILE_NAME return templates
def error xml try ET.XML xml except ET.ParseError return sys.exc_value
def _get_current_site request crum.get_current_request if not request returnreturn {'id' request.site.id 'domain' request.site.domain 'name' request.site.name}
def _soft_update a b a.update {k v for k v in b.items if k not in a }
def _split_commits_and_tags obj_store lst ignore_unknown False commits set tags set others set for e in lst try o obj_store[e]except KeyError if not ignore_unknown raiseelse if isinstance o Commit commits.add e elif isinstance o Tag tags.add e tagged o.object[1] c t o _split_commits_and_tags obj_store [tagged] ignore_unknown ignore_unknown commits | ctags | tothers | oelse others.add e return commits tags others
def _get_ax_freq ax ax_freq getattr ax 'freq' None if ax_freq is None if hasattr ax 'left_ax' ax_freq getattr ax.left_ax 'freq' None elif hasattr ax 'right_ax' ax_freq getattr ax.right_ax 'freq' None if ax_freq is None shared_axes ax.get_shared_x_axes .get_siblings ax if len shared_axes > 1 for shared_ax in shared_axes ax_freq getattr shared_ax 'freq' None if ax_freq is not None breakreturn ax_freq
def copy_tcltk src dest symlink for libversion in '8.5' '8.6' for libname in 'tcl' 'tk' srcdir join src 'tcl' libname + libversion destdir join dest 'tcl' libname + libversion if os.path.exists srcdir and not os.path.exists destdir copyfileordir srcdir destdir symlink
def changePasswordTo disp newpassword host None if not host host disp._owner.Serverresp disp.SendAndWaitForResponse Iq 'set' NS_REGISTER to host payload [Node 'username' payload [disp._owner.Server] Node 'password' payload [newpassword] ] if isResultNode resp return 1
def ElementWithText tag text **extra e Element tag **extra e.text textreturn e
def get_test_classes_from_testsuite suite if not isinstance suite unittest.TestSuite raise TypeError 'notaTestSuite' suite results set for test in suite._tests if isinstance test unittest.TestCase results.add test.__class__ else classes get_test_classes_from_testsuite test results.update classes return results
def set_enabled_all objects enable for obj in objects obj.setEnabled enable
def dataset_followee_list context data_dict _check_access 'dataset_followee_list' context data_dict if not context.get 'skip_validation' schema context.get 'schema' or ckan.logic.schema.default_follow_user_schema data_dict errors _validate data_dict schema context if errors raise ValidationError errors model context['model']user_id _get_or_bust data_dict 'id' followees model.UserFollowingDataset.followee_list user_id datasets [model.Package.get followee.object_id for followee in followees]datasets [dataset for dataset in datasets if dataset is not None ]return [model_dictize.package_dictize dataset context for dataset in datasets]
def flatten expr new new cls expr.__class__args []for arg in expr.args if arg.__class__ cls args.extend arg.args else args.append arg return new expr.__class__ *args
def _gen_find subseq generator subseq list subseq pos 0saved []for c in generator saved.append c if len saved > len subseq saved.pop 0 pos + 1if saved subseq return posreturn -1
def _ask_and_call cmds cwd None def quote s return '"%s"' % s if '' in s else s sys.stdout.write 'Okaytoexecute \n\n%s\n y/n ?\n' % '\n'.join [''.join [quote s for s in c] for c in cmds] while 1 input sys.stdin.readline .strip .lower if input in ['y' 'n'] breakaccepted input 'y' if accepted _call cmds cwd return accepted
def test_modes try x file 'test_file' 'w' AreEqual x.mode 'w' x.close AssertErrorWithMessage ValueError 'emptymodestring' file 'abc' '' AssertErrorWithMessage ValueError "modestringmustbeginwithoneof'r' 'w' 'a'or'U' not'p'" file 'abc' 'p' AssertErrorWithMessage ValueError "universalnewlinemodecanonlybeusedwithmodesstartingwith'r'" file 'abc' 'Uw' AssertErrorWithMessage ValueError "universalnewlinemodecanonlybeusedwithmodesstartingwith'r'" file 'abc' 'Ua' AssertErrorWithMessage ValueError "universalnewlinemodecanonlybeusedwithmodesstartingwith'r'" file 'abc' 'Uw+' AssertErrorWithMessage ValueError "universalnewlinemodecanonlybeusedwithmodesstartingwith'r'" file 'abc' 'Ua+' AssertError ValueError file 'test_file' 'pU' AssertError ValueError file 'test_file' 'pU+' AssertError ValueError file 'test_file' 'rFOOBAR' finally os.unlink 'test_file'
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def getInnerText node inner_text []for child in node.childNodes if child.nodeType child.TEXT_NODE or child.nodeType child.CDATA_SECTION_NODE inner_text.append child.data elif child.nodeType child.ELEMENT_NODE inner_text.extend getInnerText child else passreturn u''.join inner_text
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def initialized return DETAILS.get 'initialized' False
def romanize string lang 'en' romanizer romanizers.get lang 'en' return romanizer.romanize string
def server_enabled s_name **connection_args server _server_get s_name **connection_args return server is not None and server.get_state 'ENABLED'
@cache_permissiondef can_upload_dictionary user project return check_permission user project 'trans.upload_dictionary'
def _score estimator X_test y_test scorer if y_test is None score scorer estimator X_test else score scorer estimator X_test y_test if hasattr score 'item' try score score.item except ValueError passif not isinstance score numbers.Number raise ValueError 'scoringmustreturnanumber got%s %s instead.' % str score type score return score
def test_reset_in_length _ip.run_cell "print'foo'" _ip.run_cell 'reset-fin' nt.assert_equal len _ip.user_ns['In'] _ip.displayhook.prompt_count + 1
def is_task_mutable context task if context.is_admin return Trueif context.owner is None return Falsereturn task.owner context.owner
def getincrementalencoder encoding encoder lookup encoding .incrementalencoderif encoder is None raise LookupError encoding return encoder
def udivisor_count n if n 0 return 0return 2 ** len [p for p in factorint n if p > 1 ]
def get_current_site_theme if not is_comprehensive_theming_enabled return Nonerequest get_current_request if not request return Nonereturn getattr request 'site_theme' None
def cwd_at path def decorator func @functools.wraps func def wrapper *args **kwds try oldcwd os.getcwd repo_root os.path.dirname test_dir os.chdir os.path.join repo_root path return func *args **kwds finally os.chdir oldcwd return wrapperreturn decorator
def p_definition_literal p print_code p[1] 0
def output_opt_info conf names for name in names LOG.info _LI ' DCTB % name -35s% attr s' {'name' name + ' ' 'attr' getattr conf name }
def savedJSONInvariants testCase savedJSON testCase.assertIsInstance savedJSON unicode testCase.assertEqual savedJSON.count '\n' 0 return savedJSON
def dmp_degree_in f j u if not j return dmp_degree f u if j < 0 or j > u raise IndexError '0< j< %sexpected got%s' % u j return _rec_degree_in f u 0 j
def create_bem_flow name 'bem' out_format 'stl' '\nInitializetheworkflow\n'bemflow pe.Workflow name name '\nDefinetheinputstotheworkflow.\n'inputnode pe.Node niu.IdentityInterface fields ['subject_id' 'subjects_dir'] name 'inputspec' '\nDefineallthenodesoftheworkflow \n\nfssource usedtoretrieveaseg.mgz\nmri_convert convertsaseg.mgztoaseg.nii\ntessellate tessellatesregionsinaseg.mgz\nsurfconvert convertsregionstostereolithographic .stl format\n\n'watershed_bem pe.Node interface mne.WatershedBEM name 'WatershedBEM' surfconvert pe.MapNode fs.MRIsConvert out_datatype out_format iterfield ['in_file'] name 'surfconvert' '\nConnectthenodes\n'bemflow.connect [ inputnode watershed_bem [ 'subject_id' 'subject_id' 'subjects_dir' 'subjects_dir' ] watershed_bem surfconvert [ 'mesh_files' 'in_file' ] ] '\nSetupanoutputnodethatdefinesrelevantinputsoftheworkflow.\n'outputnode pe.Node niu.IdentityInterface fields ['meshes'] name 'outputspec' bemflow.connect [ surfconvert outputnode [ 'converted' 'meshes' ] ] return bemflow
def ownership_required function None def decorator request *args **kwargs group get_object_or_404 Group slug kwargs['slug'] if request.user.is_anonymous return HttpResponseRedirect reverse 'django.contrib.auth.views.login' if GroupMember.objects.is_owner group request.user return function request *args **kwargs else raise Http404return decorator
def getNewRepository return FillRepository
def identityPumpPolicy queue target while queue bytes queue.get if bytes is None breaktarget.dataReceived bytes
def warn_config_absent sections argument log_printer if all argument not in section for section in sections.values log_printer.warn 'coalawillnotrunanyanalysis.Didyouforgettogivethe`--{}`argument?'.format argument return Truereturn False
def isAquaTk if not _tk_type _init_tk_type return _tk_type 'cocoa' or _tk_type 'carbon'
def get_collection_summary_from_model collection_summary_model return collection_domain.CollectionSummary collection_summary_model.id collection_summary_model.title collection_summary_model.category collection_summary_model.objective collection_summary_model.language_code collection_summary_model.tags collection_summary_model.status collection_summary_model.community_owned collection_summary_model.owner_ids collection_summary_model.editor_ids collection_summary_model.viewer_ids collection_summary_model.contributor_ids collection_summary_model.contributors_summary collection_summary_model.version collection_summary_model.node_count collection_summary_model.collection_model_created_on collection_summary_model.collection_model_last_updated
@check_is_trading@export_as_api@ExecutionContext.enforce_phase EXECUTION_PHASE.HANDLE_BAR EXECUTION_PHASE.SCHEDULED def order_shares id_or_ins amount style None order_book_id assure_order_book_id id_or_ins if amount 0 user_log.error _ 'order_shares{order_book_id}amountis0.' .format order_book_id order_book_id returnround_lot int get_data_proxy .instrument order_book_id .round_lot amount int amount // round_lot * round_lot bar_dict ExecutionContext.get_current_bar_dict order get_simu_exchange .create_order bar_dict order_book_id amount style return order.order_id
def slice_shape lst slices if atomp lst return []return [len lst[slices[0]] ] + slice_shape lst[0] slices[1 ]
@requires_application @requires_pyopengl def test_functionality_pyopengl _test_functionality 'pyopengl2'
def get_profile_model if not getattr settings u'ACCOUNTS_PROFILE_MODEL' None raise ProfileNotConfiguredtry return apps.get_model settings.ACCOUNTS_PROFILE_MODEL except ValueError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELmustbeoftheform'app_label.model_name'" except LookupError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELreferstomodel'%s'thathasnotbeeninstalled" % settings.ACCOUNTS_PROFILE_MODEL
def random adjacency_mat directed False random_state None if random_state is None random_state np.randomelif not isinstance random_state np.random.RandomState random_state np.random.RandomState random_state if issparse adjacency_mat adjacency_mat adjacency_mat.tocoo num_nodes adjacency_mat.shape[0]node_coords random_state.rand num_nodes 2 line_vertices arrows _straight_line_vertices adjacency_mat node_coords directed yield node_coords line_vertices arrows
def remove_entity_headers headers allowed 'expires' 'content-location' allowed set x.lower for x in allowed headers[ ] [ key value for key value in headers if not is_entity_header key or key.lower in allowed ]
@with_setup prepare_stdout def test_output_level_1_success runner Runner join abspath dirname __file__ 'output_features' 'many_successful_scenarios' verbosity 1 runner.run assert_stdout_lines '..\n1feature 1passed \n2scenarios 2passed \n2steps 2passed \n'
def _AddRateToSummary tag rate step sw sw.add_summary summary_pb2.Summary value [summary_pb2.Summary.Value tag tag simple_value rate ] step
def _get_bench_name bench_func return bench_func.__name__[ len BENCH_METHOD_PREFIX + 1 ]
def libvlc_audio_equalizer_release p_equalizer f _Cfunctions.get 'libvlc_audio_equalizer_release' None or _Cfunction 'libvlc_audio_equalizer_release' 1 None None ctypes.c_void_p return f p_equalizer
def getCenterByPaths elementNode transformedPaths elementNode.xmlObject.getTransformedPaths return 0.5 * euclidean.getMaximumByVector3Paths transformedPaths + euclidean.getMinimumByVector3Paths transformedPaths
def polynomial_kernel X Y None degree 3 gamma None coef0 1 X Y check_pairwise_arrays X Y if gamma is None gamma 1.0 / X.shape[1] K safe_sparse_dot X Y.T dense_output True K * gammaK + coef0K ** degreereturn K
@utils.arg 'monitor' metavar '<monitor>' help 'IDofthemonitortodelete.' @utils.service_type 'monitor' def do_delete cs args monitor _find_monitor cs args.monitor monitor.delete
def readmodule_ex module path None return _readmodule module path or []
def get_default_contact doctype name out frappe.db.sql u'selectparent \n DCTB DCTB DCTB selectis_primary_contactfromtabContactcwherec.name dl.parent \n DCTB DCTB DCTB DCTB asis_primary_contact\n DCTB DCTB from\n DCTB DCTB DCTB `tabDynamicLink`dl\n DCTB DCTB where\n DCTB DCTB DCTB dl.link_doctype %sand\n DCTB DCTB DCTB dl.link_name %sand\n DCTB DCTB DCTB dl.parenttype "Contact"' doctype name if out return sorted out lambda x y cmp y[1] x[1] [0][0]else return None
def transform_soups config soups precomputed fixup_internal_links config soups ensure_headings_linkable soups generate_page_tocs soups precomputed link_pantsrefs soups precomputed
def group_revision_list context data_dict _check_access 'group_revision_list' context data_dict return _group_or_org_revision_list context data_dict
def authenticate username password service 'login' @CONV_FUNCdef my_conv n_messages messages p_response app_data 'Simpleconversationfunctionthatrespondstoany\npromptwheretheechoisoffwiththesuppliedpassword'addr CALLOC n_messages sizeof PamResponse p_response[0] cast addr POINTER PamResponse for i in range n_messages if messages[i].contents.msg_style PAM_PROMPT_ECHO_OFF pw_copy STRDUP str password p_response.contents[i].resp cast pw_copy c_char_p p_response.contents[i].resp_retcode 0return 0handle PamHandle conv PamConv my_conv 0 retval PAM_START service username pointer conv pointer handle if retval ! 0 return Falseretval PAM_AUTHENTICATE handle 0 return retval 0
def config_get pattern '*' host None port None db None password None server _connect host port db password return server.config_get pattern
def get_provider name None id None if id is not None provider ALL_PROVIDERS_BY_ID[id] else if name is None name settings.DEFAULT_PAYMENT_PROVIDERprovider ALL_PROVIDERS[name] if provider.name not in settings.PAYMENT_PROVIDERS raise ImproperlyConfigured 'Theprovider{p}isnotoneoftheallowedPAYMENT_PROVIDERS.'.format p provider.name return provider
@skip 'silverlight' def test_weakref x _struct.Struct 'i' import _weakrefAreEqual _weakref.proxy x .size x.size
def _whatsnd data hdr data[ 512]fakefile BytesIO hdr for testfn in sndhdr.tests res testfn hdr fakefile if res is not None return _sndhdr_MIMEmap.get res[0] return None
def make_fastq_rec header seq qual offset 33 result []if header.startswith '>' header header[1 ]result.append '@' + header result.append seq result.append '+' + header result.append ''.join map chr [ 33 + i for i in qual] return '\n'.join result
def _inverse_permutation p n p.sizes np.zeros n dtype np.int32 i np.arange n dtype np.int32 np.put s p i return s
@blueprint.route '/datasets/<job_id>/abort' methods ['POST'] @blueprint.route '/models/<job_id>/abort' methods ['POST'] @blueprint.route '/jobs/<job_id>/abort' methods ['POST'] @utils.auth.requires_login redirect False def abort_job job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' if scheduler.abort_job job_id return 'Jobaborted.'else raise werkzeug.exceptions.Forbidden 'Jobnotaborted'
def _skip_nonwhitespace data pos while pos < len data if data[pos].isspace breakpos + 1return pos
def setup_test_view cursor connection.cursor cursor.execute 'DROPVIEWIFEXISTStko_test_view_2' cursor.execute get_create_test_view_sql
def safeExp x return exp clip x -500 500
def read_pyc filename data read_file filename 'rb' if not is_gae and data[ 4] ! imp.get_magic raise SystemError 'compiledcodeisincompatible' return marshal.loads data[marshal_header_size ]
def rads2radsec in_file delta_te out_file None import numpy as npimport nibabel as nbimport os.path as opimport mathif out_file is None fname fext op.splitext op.basename in_file if fext u'.gz' fname _ op.splitext fname out_file op.abspath u'./%s_radsec.nii.gz' % fname im nb.load in_file data im.get_data .astype np.float32 * 1.0 / delta_te nb.Nifti1Image data im.affine im.header .to_filename out_file return out_file
def tmin a lowerlimit None axis 0 inclusive True a axis _chk_asarray a axis am trima a lowerlimit None inclusive False return ma.minimum.reduce am axis
def is_member_mutable context member if context.is_admin return Trueif context.owner is None return Falsereturn member.member_id context.owner
def split filenames format_string shards parsed_formats parser.parse format_string sizes [files.stat filename .st_size for filename in filenames]size_per_shard float sum sizes / shards if not size_per_shard returnif parsed_formats[0].can_split return _deep_split filenames size_per_shard parsed_formats else return _shallow_split filenames size_per_shard parsed_formats sizes
def fit_mps dist data x0 None xsorted np.sort data if x0 is None x0 getstartparams dist xsorted args xsorted dist print x0 return optimize.fmin logmps x0 args args
def uninstall_python python runas None python re.sub '^python-' '' python args '--force{0}'.format python _pyenv_exec 'uninstall' args runas runas return True
@FileSystem.in_directory current_directory 'django' 'brocolis' def test_harvest_uses_test_runner status out run_scenario 'leaves' 'disabled' assert_equals status 0 out assert 'Customtestrunnerenabled.' in out
def escape_parameter text return escape_identifier text.replace '-' '_'
def get_css_dependencies group if settings.PIPELINE_ENABLED return [settings.PIPELINE_CSS[group]['output_filename']]else return settings.PIPELINE_CSS[group]['source_filenames']
def iter_errback iterable errback *a **kw it iter iterable while True try yield next it except StopIteration breakexcept errback failure.Failure *a **kw
def _has_uncommitted_files uncommitted_files subprocess.check_output GIT_IS_DIRTY_CMD.split '' return bool len uncommitted_files
def _raise_error_iface iface option expected msg _error_msg_iface iface option expected log.error msg raise AttributeError msg
def _is_bad_link info base tip resolved joinpath base dirname info.name return _is_bad_path info.linkname base tip
def delete_exploration committer_id exploration_id force_deletion False exploration_rights_model exp_models.ExplorationRightsModel.get exploration_id exploration_rights_model.delete committer_id '' force_deletion force_deletion exploration_model exp_models.ExplorationModel.get exploration_id exploration_model.delete committer_id feconf.COMMIT_MESSAGE_EXPLORATION_DELETED force_deletion force_deletion exploration_memcache_key _get_exploration_memcache_key exploration_id memcache_services.delete exploration_memcache_key delete_documents_from_search_index [exploration_id] delete_exploration_summary exploration_id activity_services.remove_featured_activity feconf.ACTIVITY_TYPE_EXPLORATION exploration_id
def _ecmaCodeTableCoordinate column row return bytes bytearray [ column << 4 | row ]
def filename if not _state raise RuntimeError 'noactiveinput ' return _state.filename
def _parse_token word chunk 'O' pnp 'O' relation 'O' anchor 'O' format [WORD POS CHUNK PNP REL ANCHOR LEMMA] tags []for tag in format if tag WORD tags.append xml_decode word.value elif tag POS tags.append xml_decode word.get XML_TYPE 'O' elif tag CHUNK tags.append chunk elif tag PNP tags.append pnp elif tag REL tags.append relation elif tag ANCHOR tags.append anchor elif tag LEMMA tags.append xml_decode word.get XML_LEMMA '' else tags.append xml_decode word.get tag 'O' return tags
def trained_type return s3_rest_controller
def creation_sequence_to_weights creation_sequence first creation_sequence[0]if isinstance first str if isinstance creation_sequence list wseq creation_sequence[ ]else wseq list creation_sequence elif isinstance first tuple wseq [v[1] for v in creation_sequence]elif isinstance first int wseq uncompact creation_sequence else raise TypeError 'Notavalidcreationsequencetype' wseq.reverse w 0prev 'i'for j s in enumerate wseq if s 'i' wseq[j] wprev selif prev 'i' prev sw + 1wseq.reverse for j s in enumerate wseq if s 'd' wseq[j] wprev selif prev 'd' prev sw + 1if prev 'd' w + 1wscale 1.0 / float w return [ ww * wscale for ww in wseq]
def p_const_map_seq p _parse_seq p
def _do_plot x y dist None line False ax None fmt 'bo' **kwargs fig ax utils.create_mpl_ax ax ax.set_xmargin 0.02 ax.plot x y fmt **kwargs if line if line not in ['r' 'q' '45' 's'] msg '%soptionforlinenotunderstood' % line raise ValueError msg qqline ax line x x y y dist dist return fig ax
def log_line filename line global _open_log_files _log_file_dirpath get_path _log_file_dir filename if path not in _open_log_files close_log_file filename try os.makedirs os.path.dirname path except OSError pass_open_log_files[path] open path 'w' timestr time.strftime '%Y-%m-%d%H %M %S' _open_log_files[path].write '%s %s\n' % timestr line _open_log_files[path].flush
def special_rss_site url return cfg.rss_filenames or match_str url cfg.rss_odd_titles
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def position_of_ngram ngram sentence for i sublist in enumerate ngrams sentence len ngram if ngram sublist return i
def list_datastore_clusters service_instance return list_objects service_instance vim.StoragePod
@handle_response_format@treeio_login_required@module_admin_required def perspective_view request perspective_id response_format 'html' perspective get_object_or_404 Perspective pk perspective_id all_modules Module.objects.all message request.session.pop 'message' '' return render_to_response 'core/administration/perspective_view' {'perspective' perspective 'all_modules' all_modules 'message' message} context_instance RequestContext request response_format response_format
def serve_protected_file request path try file_obj File.objects.get file path is_public False except File.DoesNotExist raise Http404 'Filenotfound' if not file_obj.has_read_permission request if settings.DEBUG raise PermissionDeniedelse raise Http404 'Filenotfound' return server.serve request file_obj file_obj.file save_as False
def assert_allclose_cc actual desired **kw try assert_allclose actual desired **kw except assert_allclose actual conj desired **kw
def merge_sync dsk1 dsk2 dsk2_topo toposort dsk2 sd _sync_keys dsk1 dsk2 dsk2_topo new_dsk dsk1.copy for key in dsk2_topo if key in sd new_key sd[key]else if key in dsk1 new_key next merge_sync.names else new_key keysd[key] new_keytask dsk2[key]for a b in sd.items task subs task a b new_dsk[new_key] taskreturn new_dsk sd
def get_module app modname verbose failfast module_name '%s.%s' % app modname app_mod import_module app try imp.find_module modname app_mod.__path__ if hasattr app_mod '__path__' else None except ImportError if failfast raiseelif verbose print u'Couldnotfind%rfrom%r' % modname app traceback.print_exc return Nonemodule import_module module_name if verbose print u'Loaded%rfrom%r' % modname app return module
@dispatch Reduction def group_apply expr key expr._namecol '$' + expr._child._name if isinstance expr count return {key {'$sum' 1}}if isinstance expr sum return {key {'$sum' col}}if isinstance expr max return {key {'$max' col}}if isinstance expr min return {key {'$min' col}}if isinstance expr mean return {key {'$avg' col}}raise NotImplementedError 'Reduction%snotyetsupportedinMongoDB' % type expr .__name__
def override_system_resolver resolver None if resolver is None resolver get_default_resolver global _resolver_resolver resolversocket.getaddrinfo _getaddrinfosocket.getnameinfo _getnameinfosocket.getfqdn _getfqdnsocket.gethostbyname _gethostbynamesocket.gethostbyname_ex _gethostbyname_exsocket.gethostbyaddr _gethostbyaddr
def provision_for_any_user node package_source variants username node.get_default_username if username 'root' return provision_as_root node package_source variants commands []start []def for_thirty_seconds *args **kwargs if not start start.append time return Effect Constant time - start[0] < 30 commands.append run_remotely username username address node.address commands retry task_install_ssh_key for_thirty_seconds commands.append run_remotely username username address node.address commands task_enable_root_logins node.distribution commands.append provision_as_root node package_source variants return sequence commands
def device_extents devmem s drvapi.cu_device_ptr n c_size_t devptr device_ctypes_pointer devmem driver.cuMemGetAddressRange byref s byref n devptr s n s.value n.value return s s + n
def from_epoch_milliseconds ms seconds int ms / 1000.0 microseconds ms - 1000 * seconds * 1000.0 return EPOCH + timedelta seconds seconds microseconds microseconds
def set_diff_renderer_class renderer assert rendererglobals [u'_diff_renderer_class'] renderer
def wrap text width 70 **kwargs w TextWrapper width width **kwargs return w.wrap text
def verify_certificate certificate now timeutils.utcnow if now < certificate.not_valid_before raise exception.SignatureVerificationError reason _ 'Certificateisnotvalidbefore %sUTC' % certificate.not_valid_before elif now > certificate.not_valid_after raise exception.SignatureVerificationError reason _ 'Certificateisnotvalidafter %sUTC' % certificate.not_valid_after
def MakeEntityForQuery query *path pseudo_pb entity_pb.EntityProto pseudo_pb.mutable_entity_group pseudo_pk pseudo_pb.mutable_key pseudo_pk.set_app query.app if query.has_name_space pseudo_pk.set_name_space query.name_space for i in xrange 0 len path 2 pseudo_pe pseudo_pk.mutable_path .add_element pseudo_pe.set_type path[i] if isinstance path[ i + 1 ] basestring pseudo_pe.set_name path[ i + 1 ] else pseudo_pe.set_id path[ i + 1 ] return pseudo_pb
def drawIndex probs tolerant False if not sum probs < 1.00001 or not sum probs > 0.99999 if tolerant probs / sum probs else print probs 1 - sum probs raise ValueError r random s 0for i p in enumerate probs s + pif s > r return ireturn choice list range len probs
def GetAuditLogFiles offset now token oldest_time now - offset - rdfvalue.Duration config_lib.CONFIG['Logging.aff4_audit_log_rollover'] parentdir aff4.FACTORY.Open 'aff4 /audit/logs' token token logs list parentdir.ListChildren age oldest_time.AsMicroSecondsFromEpoch now.AsMicroSecondsFromEpoch if not logs raise ValueError "Couldn'tfindanylogsinaff4 /audit/logsbetween%sand%s" % oldest_time now return aff4.FACTORY.MultiOpen logs aff4_type collects.RDFValueCollection token token
def reachable stepFunction start destinations _alreadyseen None if len start 0 or len destinations 0 return {}if _alreadyseen is None _alreadyseen []_alreadyseen.extend start res {}for s in start if s in destinations res[s] 0start.remove s new set for s in start new.update stepFunction s new.difference_update _alreadyseen ndestinations list destinations for s in list new if s in destinations res[s] 1new.remove s ndestinations.remove s _alreadyseen.append s deeper reachable stepFunction new ndestinations _alreadyseen for k val in list deeper.items res[k] val + 1 return res
def test_credentials_in_url_auth_flag_has_priority httpbin_both url add_auth httpbin_both.url + '/basic-auth/user/password' auth 'user wrong' r http '--auth user password' 'GET' url assert HTTP_OK in r assert r.json {'authenticated' True 'user' 'user'}
def check_subnet_ip cidr ip_address ip netaddr.IPAddress ip_address net netaddr.IPNetwork cidr return ip ! net.network and net.version 6 or ip ! net[ -1 ] and net.netmask & ip net.network
@task name 'all' help {'args' 'Commandlineargsfortestrun.'} def test_all ctx args '' options '' pytest_args select_by_prefix args ctx.pytest.scopes behave_args select_by_prefix args ctx.behave_test.scopes pytest_should_run not args or args and pytest_args behave_should_run not args or args and behave_args if pytest_should_run pytest ctx pytest_args options options if behave_should_run behave ctx behave_args options options
def _get_volume_tag volume name if volume.tags for tag in volume.tags if tag['Key'] name return tag['Value']raise TagNotFound volume.id name volume.tags
def _do_inf_pots mri_rr bem_rr mri_Q sol bounds np.concatenate [np.arange 0 len mri_rr 200 [len mri_rr ]] B np.empty len mri_rr * 3 sol.shape[1] for bi in range len bounds - 1 v0s _bem_inf_pots mri_rr[bounds[bi] bounds[ bi + 1 ]] bem_rr mri_Q v0s.shape v0s.shape[0] * 3 v0s.shape[2] B[ 3 * bounds[bi] 3 * bounds[ bi + 1 ] ] np.dot v0s sol return B
def no_mutable_default_args logical_line msg "N322 Method'sdefaultargumentshouldn'tbemutable!"if mutable_default_args.match logical_line yield 0 msg
def get_gdp_year rdint vs.random request Request vs.MACRO_URL % vs.P_TYPE['http'] vs.DOMAINS['sina'] rdint vs.MACRO_TYPE[0] 0 70 rdint text urlopen request timeout 10 .read text text.decode 'gbk' if ct.PY3 else text regSym re.compile '\\ count .*? \\}' datastr regSym.findall text datastr datastr[0]datastr datastr.split 'data ' [1]datastr datastr.replace '"' '' .replace 'null' '0' js json.loads datastr df pd.DataFrame js columns vs.GDP_YEAR_COLS df[ df 0 ] np.NaNreturn df
def _sudo_prefix user group None prefix env.sudo_prefix % env if user is not None or group is not None return '%s%s%s' % prefix _sudo_prefix_argument '-u' user _sudo_prefix_argument '-g' group return prefix
def _is_protected_type obj return isinstance obj types.NoneType int long datetime.datetime datetime.date datetime.time float Decimal basestring
def file_exists session ds_browser ds_path file_name client_factory session.vim.client.factorysearch_spec search_datastore_spec client_factory file_name search_task session._call_method session.vim 'SearchDatastore_Task' ds_browser datastorePath str ds_path searchSpec search_spec try task_info session._wait_for_task search_task except vexc.FileNotFoundException return Falsefile_exists getattr task_info.result 'file' False and task_info.result.file[0].path file_name return file_exists
def natsort_case_insensitive seq return natsort seq case_sensitive False
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
@app.route '/authorized' def authorized_view session_auth_state session.get 'authstate' auth_code request.args.get 'code' auth_state request.args.get 'state' if session_auth_state ! auth_state abort 401 redirect_uri session.get 'redirecturiafterauthorized' auth.clear_session_token token_response auth.get_tokens auth_code auth.set_session_token_response token_response if not redirect_uri redirect_uri url_for 'home_view' return redirect redirect_uri
def default_component return {'host' '192.168.0.1' 'port' 8090 'name' 'soundtouch'}
def _in_encoding return _stream_encoding sys.stdin
def _check_update_montage info montage path None update_ch_names False if montage is not None if not isinstance montage string_types Montage err 'Montagemustbestr None orinstanceofMontage.%swasprovided' % type montage raise TypeError err if montage is not None if isinstance montage string_types montage read_montage montage path path _set_montage info montage update_ch_names update_ch_names missing_positions []exclude FIFF.FIFFV_EOG_CH FIFF.FIFFV_MISC_CH FIFF.FIFFV_STIM_CH for ch in info['chs'] if not ch['kind'] in exclude if np.unique ch['loc'] .size 1 missing_positions.append ch['ch_name'] if missing_positions raise KeyError 'Thefollowingpositionsaremissingfromthemontagedefinitions %s.IfthosechannelslackpositionsbecausetheyareEOGchannelsusetheeogparameter.' % str missing_positions
def function1 individual position height width value 0.0for x p in zip individual position value + x - p ** 2 return height / 1 + width * value
def twitter_outbox if not auth.s3_logged_in session.error T 'RequiresLogin!' redirect URL c 'default' f 'user' args 'login' tablename 'msg_twitter'table s3db.msg_twitters3.filter table.inbound False table.inbound.readable Falses3.crud_strings[tablename] Storage title_display T 'TweetDetails' title_list T 'SentTweets' label_list_button T 'ViewSentTweets' label_delete_button T 'DeleteTweet' msg_record_deleted T 'Tweetdeleted' msg_list_empty T 'NoTweetscurrentlyinOutbox' def postp r output if isinstance output dict add_btn A T 'Compose' _class 'action-btn' _href URL f 'compose' output['rheader'] add_btnreturn outputs3.postp postps3db.configure tablename editable False insertable False listadd False list_fields ['id' 'date' 'to_address' 'body'] return s3_rest_controller module 'twitter'
def _fit_chpi_pos coil_dev_rrs coil_head_rrs x0 from scipy.optimize import fmin_cobyladenom np.sum coil_head_rrs - np.mean coil_head_rrs axis 0 ** 2 objective partial _chpi_objective coil_dev_rrs coil_dev_rrs coil_head_rrs coil_head_rrs x0 x0.copy x0[3 ] * 10.0x fmin_cobyla objective x0 _unit_quat_constraint rhobeg 0.001 rhoend 1e-05 disp False result objective x x[3 ] / 10.0return x 1.0 - result / denom
def is_comprehensive_theming_enabled if settings.ENABLE_COMPREHENSIVE_THEMING and current_request_has_associated_site_theme return Trueif microsite.is_request_in_microsite return Falsereturn settings.ENABLE_COMPREHENSIVE_THEMING
def alternatives *rules def _alternatives integral alts []for rule in rules result rule integral if result and not isinstance result DontKnowRule and result ! integral and result not in alts alts.append result if len alts 1 return alts[0]elif alts doable [rule for rule in alts if not contains_dont_know rule ]if doable return AlternativeRule doable *integral else return AlternativeRule alts *integral return _alternatives
def revoke_admin_privileges name **client_args client _client **client_args client.revoke_admin_privileges name return True
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def MakeDescriptor desc_proto package '' full_message_name [desc_proto.name]if package full_message_name.insert 0 package fields []for field_proto in desc_proto.field full_name '.'.join full_message_name + [field_proto.name] field FieldDescriptor field_proto.name full_name field_proto.number - 1 field_proto.number field_proto.type FieldDescriptor.ProtoTypeToCppProtoType field_proto.type field_proto.label None None None None False None has_default_value False fields.append field desc_name '.'.join full_message_name return Descriptor desc_proto.name desc_name None None fields [] [] []
def _task_get context task_id session None force_show_deleted False session session or get_session query session.query models.Task .options sa_orm.joinedload models.Task.info .filter_by id task_id if not force_show_deleted and not context.can_see_deleted query query.filter_by deleted False try task_ref query.one except sa_orm.exc.NoResultFound LOG.debug 'NotaskfoundwithID%s' task_id raise exception.TaskNotFound task_id task_id if not _is_task_visible context task_ref msg 'Forbiddingrequest task%sisnotvisible' % task_id LOG.debug msg raise exception.Forbidden msg return task_ref
def p_additive_expression_2 t pass
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def recursive_map fn element sequence_type None if sequence_type is None return recursive_map fn element type element elif isinstance element sequence_type return map lambda x recursive_map fn x sequence_type element else return fn element
def rs_atan p x prec if rs_is_puiseux p x return rs_puiseux rs_atan p x prec R p.ringconst 0if _has_constant_term p x zm R.zero_monomc p[zm]if R.domain is EX c_expr c.as_expr const atan c_expr elif isinstance c PolyElement try c_expr c.as_expr const R atan c_expr except ValueError raise DomainError "Thegivenseriescan'tbeexpandedinthisdomain." else try const R atan c except ValueError raise DomainError "Thegivenseriescan'tbeexpandedinthisdomain." dp p.diff x p1 rs_square p x prec + R 1 p1 rs_series_inversion p1 x prec - 1 p1 rs_mul dp p1 x prec - 1 return rs_integrate p1 x + const
def create_kernel_image context session instance name_label image_id image_type filename ''if CONF.cache_images args {}args['cached-image'] image_idargs['new-image-uuid'] str uuid.uuid4 filename session.call_plugin 'kernel' 'create_kernel_ramdisk' args if filename '' return _fetch_disk_image context session instance name_label image_id image_type else vdi_type ImageType.to_string image_type return {vdi_type dict uuid None file filename }
def cuckoo_main max_analysis_count 0 cur_path os.getcwd os.chdir CUCKOO_ROOT try sched Scheduler max_analysis_count sched.start except KeyboardInterrupt sched.stop os.chdir cur_path
def CDLHOMINGPIGEON barDs count return call_talib_with_ohlc barDs count talib.CDLHOMINGPIGEON
@translations.command 'new' @click.option '--plugin' '-p' type click.STRING help 'Addsanewlanguagetoaplugin.' @click.argument 'lang' def new_translation lang plugin if plugin validate_plugin plugin click.secho '[+]Addingnewlanguage{}forplugin{}...'.format lang plugin fg 'cyan' add_plugin_translations plugin lang else click.secho '[+]Addingnewlanguage{}...'.format lang fg 'cyan' add_translations lang
def _make_sync_method name def sync_wrapper self *args **kwds method getattr self name future method *args **kwds return future.get_result return sync_wrapper
def puts_err s '' newline True stream STDERR puts s newline stream
def getCraftSequence return 'carvescalebottomprefacewideninsetfillmultiplyspeedtemperatureraftskirtchambertowerjitterclipsmoothstretchskincombcoolhopwipeoozebanesplodgehomelashfilletlimitunpausedimensionaltshellalterationexport'.split
def decistmt s result []g generate_tokens StringIO s .readline for toknum tokval _ _ _ in g if toknum NUMBER and '.' in tokval result.extend [ NAME 'Decimal' OP ' ' STRING repr tokval OP ' ' ] else result.append toknum tokval return untokenize result
def get_available_ctid current_ctids list_ctids if current_ctids return max current_ctids + 1 else return 1000
def assert_static_analysis case actual desired a set actual d set desired assert actual desired '\nTest%rfailed.\nnotraised %s\nunspecified %s\n' % case sorted d - a sorted a - d
def test_arithmetic_cov cov read_cov cov_fname cov_sum cov + cov assert_array_almost_equal 2 * cov.nfree cov_sum.nfree assert_array_almost_equal 2 * cov.data cov_sum.data assert_true cov.ch_names cov_sum.ch_names cov + covassert_array_almost_equal cov_sum.nfree cov.nfree assert_array_almost_equal cov_sum.data cov.data assert_true cov_sum.ch_names cov.ch_names
def get_h5_data_group grp_name parent '/' f get_h5_data_file existed Truetry group f.getNode parent + grp_name except existed Falsemsg 'datafor{}tests'.format grp_name + '.py' group f.create_group parent grp_name msg return existed group
@celery.task name 'redash.tasks.cleanup_query_results' base BaseTask def cleanup_query_results logging.info 'Runningqueryresultscleanup removingmaximumof%dunusedresults thatare%ddaysoldormore ' settings.QUERY_RESULTS_CLEANUP_COUNT settings.QUERY_RESULTS_CLEANUP_MAX_AGE unused_query_results models.QueryResult.unused settings.QUERY_RESULTS_CLEANUP_MAX_AGE .limit settings.QUERY_RESULTS_CLEANUP_COUNT total_unused_query_results models.QueryResult.unused .count deleted_count models.Query.query.filter models.Query.id.in_ unused_query_results.subquery .delete synchronize_session False models.db.session.commit logger.info 'Deleted%dunusedqueryresultsoutoftotalof%d.' % deleted_count total_unused_query_results
def comment return s3_rest_controller
def circular adjacency_mat directed False if issparse adjacency_mat adjacency_mat adjacency_mat.tocoo num_nodes adjacency_mat.shape[0]t np.linspace 0 2 * np.pi num_nodes endpoint False dtype np.float32 node_coords 0.5 * np.array [np.cos t np.sin t ] + 0.5 .T line_vertices arrows _straight_line_vertices adjacency_mat node_coords directed yield node_coords line_vertices arrows
def generate s limit 20 return _gen parse s limit
def _rec_integrate_in g m v i j K if i j return dmp_integrate g m v K w i v - 1 i + 1 return dmp_strip [_rec_integrate_in c m w i j K for c in g] v
def match_filter filter_list userargs found_filter Nonefor f in filter_list if f.match userargs if isinstance f filters.ExecCommandFilter leaf_filters [fltr for fltr in filter_list if not isinstance fltr filters.ExecCommandFilter ]args f.exec_args userargs if not args or not match_filter leaf_filters args continueif not os.access f.exec_path os.X_OK if not found_filter found_filter fcontinuereturn freturn found_filter
def bgsave host None port None db None password None server _connect host port db password return server.bgsave
def get_course_topics request course_key topic_ids None course _get_course course_key request.user courseware_topics existing_courseware_topic_ids get_courseware_topics request course_key course topic_ids non_courseware_topics existing_non_courseware_topic_ids get_non_courseware_topics request course_key course topic_ids if topic_ids not_found_topic_ids topic_ids - existing_courseware_topic_ids | existing_non_courseware_topic_ids if not_found_topic_ids raise DiscussionNotFoundError "Discussionnotfoundfor'{}'.".format ' '.join str id for id in not_found_topic_ids return {'courseware_topics' courseware_topics 'non_courseware_topics' non_courseware_topics}
def threaded func return threaded_factory func True
def _refine_value value value str value .lower if value in '1' 'on' 'yes' 'true' return 'on'if value in '0' 'off' 'no' 'false' return 'off'return None
def extract_nothing fileobj keywords comment_tags options return []
def submit_delete_problem_state_for_all_students request usage_key modulestore .get_item usage_key task_type 'delete_problem_state'task_class delete_problem_state task_input task_key encode_problem_and_student_input usage_key return submit_task request task_type task_class usage_key.course_key task_input task_key
def reflected_binary_operator op assert not is_comparison op @with_name method_name_for_op op commute True @coerce_numbers_to_my_dtypedef reflected_binary_operator self other if isinstance self NumericalExpression self_expr other_expr new_inputs self.build_binary_op op other return NumExprFactor ' {left} {op} {right} '.format left other_expr right self_expr op op new_inputs dtype binop_return_dtype op other.dtype self.dtype elif isinstance other Number return NumExprFactor '{constant}{op}x_0'.format op op constant other binds self dtype binop_return_dtype op other.dtype self.dtype raise BadBinaryOperator op other self return reflected_binary_operator
@_helpers.positional 3 def credentials_from_clientsecrets_and_code filename scope code message None redirect_uri 'postmessage' http None cache None device_uri None flow flow_from_clientsecrets filename scope message message cache cache redirect_uri redirect_uri device_uri device_uri credentials flow.step2_exchange code http http return credentials
def cluster_create version name 'main' port None locale None encoding None datadir None cmd [salt.utils.which 'pg_createcluster' ]if port cmd + ['--port' str port ]if locale cmd + ['--locale' locale]if encoding cmd + ['--encoding' encoding]if datadir cmd + ['--datadir' datadir]cmd + [version name]cmdstr ''.join [pipes.quote c for c in cmd] ret __salt__['cmd.run_all'] cmdstr python_shell False if ret.get 'retcode' 0 ! 0 log.error 'ErrorcreatingaPostgresqlcluster{0}/{1}'.format version name return Falsereturn ret
def _reverse_cmp_pkg_versions pkg1 pkg2 if LooseVersion pkg1 > LooseVersion pkg2 return 1else return -1
def test_classification_report_imbalanced_multiclass iris datasets.load_iris y_true y_pred _ make_prediction dataset iris binary False expected_report 'prerecspef1geoibasupsetosa0.830.790.920.810.860.7424versicolor0.330.100.860.150.440.1931virginica0.420.900.550.570.630.3720avg/total0.510.530.800.470.620.4175'report classification_report_imbalanced y_true y_pred labels np.arange len iris.target_names target_names iris.target_names assert_equal _format_report report expected_report expected_report 'prerecspef1geoibasup00.830.790.920.810.860.742410.330.100.860.150.440.193120.420.900.550.570.630.3720avg/total0.510.530.800.470.620.4175'report classification_report_imbalanced y_true y_pred assert_equal _format_report report expected_report
def reverse_dict d result {}for key in d for val in d[key] result[val] result.get val tuple + key return result
def find_name name state high ext_id []if name in high ext_id.append name state elif state 'sls' for nid item in six.iteritems high if item['__sls__'] name ext_id.append nid next iter item else for nid in high if state in high[nid] if isinstance high[nid][state] list for arg in high[nid][state] if not isinstance arg dict continueif len arg ! 1 continueif arg[next iter arg ] name ext_id.append nid state return ext_id
def country_mobile_token country_code return _MOBILE_TOKEN_MAPPINGS.get country_code U_EMPTY_STRING
def test_mapping_task_classes list_output 'mapping' 'normal' COMMANDS_HEADER + ' \n\nmapping_task'
def fields_from_log fh rows fh.read row rows.split '\n' [0]fields []matches re.search TIMESTAMP_PATTERN row if matches fields.append 'timestamp' 'tdate' fields.append 'message' 'text_general' return fields
def remove_key kwargs None call None if call ! 'function' log.error 'Thecreate_keyfunctionmustbecalledwith-for--function.' return Falsetry result query method 'account' command 'keys/' + kwargs['id'] http_method 'delete' except KeyError log.info '`id`argumentmustbespecified' return Falsereturn result
def strategy_random_sequential G colors nodes list G random.shuffle nodes return nodes
def _microtime val1 val2 math.modf time.time val2 int val2 return '{0 f}{1}'.format val1 val2
def is_transparency_supported if sys.platform 'win32' return is_dwm_compositing_enabled elif sys.platform 'cygwin' return Falseelif sys.platform 'darwin' if has_x11 return is_x11_compositing_enabled else return Trueelif sys.platform.startswith 'linux' return is_x11_compositing_enabled elif sys.platform.startswith 'freebsd' return is_x11_compositing_enabled elif has_x11 return is_x11_compositing_enabled else return False
def module_not_found additional_depth 0 tb sys.exc_info [2]if len traceback.extract_tb tb > 1 + additional_depth return Falsereturn True
def describe_vpc_peering_connection name region None key None keyid None profile None conn _get_conn3 region region key key keyid keyid profile profile return {'VPC-Peerings' _get_peering_connection_ids name conn }
def source_location_to_tuple locpb if locpb is None return Noneif not locpb.file and not locpb.line and not locpb.function_name return Nonereturn locpb.file locpb.line locpb.function_name
def test_return_text assert 'foo' in color 'foo' 11
def to_bytes text default 0 mult_key_org text.lstrip '-1234567890' mult_key mult_key_org.lower mult_key_len len mult_key if mult_key.endswith 'b' mult_key mult_key[0 -1 ]try multiplier BYTE_MULTIPLIERS[mult_key]if mult_key_len text text[0 - mult_key_len ]return int text * multiplier except KeyError msg _ 'Unknownbytemultiplier %s' % mult_key_org raise TypeError msg except ValueError return default
def tabular_model dim name None table np.zeros [2] * dim inputs tuple u'x{0}'.format idx for idx in range table.ndim members {u'lookup_table' table u'inputs' inputs}if name is None model_id _Tabular._id_Tabular._id + 1name u'Tabular{0}'.format model_id return type str name _Tabular members
@must_have_addon SHORT_NAME 'node' @must_be_addon_authorizer SHORT_NAME def dropbox_folder_list node_addon **kwargs folder_id request.args.get 'folder_id' return node_addon.get_folders folder_id folder_id
def skip reason def decorator test_item if isinstance test_item type and issubclass test_item TestCase test_item.__unittest_skip__ Truetest_item.__unittest_skip_why__ reasonreturn test_item@functools_copy.wraps test_item def skip_wrapper *args **kwargs raise SkipTest reason return skip_wrapperreturn decorator
def linear_gradient start end nbins eps 1e-10 start array start end array end result []n_minus_1 max float nbins - 1 eps for i in range nbins result.append list start * n_minus_1 - i / n_minus_1 + end * i / n_minus_1 return result
def _find_dirs metadata ret {}for bucket_name data in six.iteritems metadata if bucket_name not in ret ret[bucket_name] set for path in [k['Key'] for k in data] prefix ''for part in path.split '/' [ -1 ] directory prefix + part + '/' ret[bucket_name].add directory prefix directoryreturn ret
def num2julian n if cbook.iterable n n np.asarray n return n - 1721425.5
def bag_zip *bags npartitions bags[0].npartitionsassert all bag.npartitions npartitions for bag in bags name 'zip-' + tokenize *bags dsk dict name i reify zip + tuple bag.name i for bag in bags for i in range npartitions bags_dsk merge * bag.dask for bag in bags return Bag merge bags_dsk dsk name npartitions
def delta_t ts time while True t time dt ts t - ts t yield dt
def test_cache_deactivated_metadata config_stub tmpdir config_stub.data {'storage' {'cache-size' 1024} 'general' {'private-browsing' True}}url 'http //qutebrowser.org'disk_cache cache.DiskCache str tmpdir assert disk_cache.metaData QUrl url QNetworkCacheMetaData
def model_from_configuration deployment_state applications deployment_configuration nodes deployment_from_configuration deployment_state deployment_configuration applications return Deployment nodes frozenset nodes
def RGS_unrank rank m if m < 1 raise ValueError 'Thesupersetsizemustbe> 1' if rank < 0 or RGS_enum m < rank raise ValueError 'Invalidarguments' L [1] * m + 1 j 1D RGS_generalized m for i in range 2 m + 1 v D[ m - i j ]cr j * v if cr < rank L[i] j + 1 rank - crj + 1else L[i] int rank / v + 1 rank % vreturn [ x - 1 for x in L[1 ]]
def gen_test_env_paths envs shell num_test_folders 5 paths [os.path.join envs u'test{}'.format test_folder + 1 for test_folder in range num_test_folders ]for path in paths[ 2] symlink_conda path sys.prefix shell converter shells[shell][u'path_to']paths {i converter path for i path in enumerate paths }paths[u'root'] u'root'paths[u'bad'] u'foobarbazqux'envname {k shells[shell][u'var_set'].format variable u'CONDA_ENVNAME' value path for k path in paths.items }return paths envname
def ensure_files_present original_file_dict modified_file_dict original_files set original_file_dict.keys modified_files set modified_file_dict.keys affected_files original_files | modified_files original_unique_files affected_files - modified_files renamed_files_dict {}for file in filter lambda filter_file filter_file not in original_files affected_files for comparable_file in original_unique_files s SequenceMatcher None ''.join modified_file_dict[file] ''.join original_file_dict[comparable_file] if s.real_quick_ratio > 0.5 and s.ratio > 0.5 renamed_files_dict[comparable_file] filebreakelse original_file_dict[file] []for file in filter lambda filter_file filter_file not in modified_files affected_files modified_file_dict[file] []return renamed_files_dict
def get_theme_names return get_themes .keys
def recvfd socketfd data flags ancillary recv1msg socketfd [ cmsg_level cmsg_type packedFD ] ancillary[unpackedFD] unpack 'i' packedFD return unpackedFD data
def confirm_user user if user.confirmed_at is not None return Falseuser.confirmed_at datetime.utcnow _datastore.put user user_confirmed.send app._get_current_object user user return True
@blueprint.route '/projects/<project>/meters' def list_meters_by_project project check_authorized_project project rq flask.requestmeters rq.storage_conn.get_meters project project metaquery _get_metaquery rq.args return flask.jsonify meters [m.as_dict for m in meters]
def clone_repo parent runtask progress finish spawn result prompt_for_clone if result is None return url destdir resultprogress.set_details N_ u'CloneRepository' N_ u'Cloningrepositoryat%s' % url task CloneTask url destdir spawn parent runtask.start task finish finish progress progress
def requires_ext **kwargs def decorator func @functools.wraps func def wrapper *func_args **func_kwargs if not is_extension_enabled kwargs['extension'] kwargs['service'] msg 'Skippedbecause%sextension %sisnotenabled' % kwargs['service'] kwargs['extension'] raise testtools.TestCase.skipException msg return func *func_args **func_kwargs return wrapperreturn decorator
def get_build_platform try from sysconfig import get_platformexcept ImportError from distutils.util import get_platformplat get_platform if sys.platform 'darwin' and not plat.startswith 'macosx-' try version _macosx_vers machine os.uname [4].replace '' '_' return 'macosx-%d.%d-%s' % int version[0] int version[1] _macosx_arch machine except ValueError passreturn plat
def service_get_all_volume_sorted context return IMPL.service_get_all_volume_sorted context
def _has_explicit_scheme url return url.isValid and url.scheme and url.host or url.path and '' not in url.path and not url.path .startswith ' '
def set_binary_path name global __SYSLOG_NG_BINARY_PATHold __SYSLOG_NG_BINARY_PATH__SYSLOG_NG_BINARY_PATH namechanges _format_changes old name return _format_state_result name result True changes changes
def _clean_nans scores scores as_float_array scores copy True scores[np.isnan scores ] np.finfo scores.dtype .minreturn scores
def read_request_load_scenario reactor cluster method 'version' request_rate 10 sample_size DEFAULT_SAMPLE_SIZE timeout 45 tolerance_percentage 0.2 validate_no_arg_method IFlockerAPIV1Client method request getattr cluster.get_control_service reactor method return RequestLoadScenario reactor ReadRequest request request_rate request_rate sample_size sample_size timeout timeout tolerance_percentage tolerance_percentage
def getEvaluatedExpressionValueEvaluators evaluators for evaluatorIndex evaluator in enumerate evaluators evaluator.executeCenterOperation evaluators evaluatorIndex for negativeIndex in xrange 1 - len evaluators 0 evaluatorIndex negativeIndex + len evaluators evaluators[evaluatorIndex].executeRightOperation evaluators evaluatorIndex executeLeftOperations evaluators 200 for operationLevel in [80 60 40 20 15] executePairOperations evaluators operationLevel executeLeftOperations evaluators 13 executePairOperations evaluators 12 for negativeIndex in xrange - len evaluators 0 evaluatorIndex negativeIndex + len evaluators evaluators[evaluatorIndex].executePairOperation evaluators evaluatorIndex 10 for evaluatorIndex in xrange len evaluators - 1 -1 -1 evaluators[evaluatorIndex].executePairOperation evaluators evaluatorIndex 0 return evaluators
def fix_sys_path current_path def add_path_first path sys.path [path] + [p for p in sys.path if not p path and not p path + '/' ] path os.path.dirname os.path.abspath current_path if not os.path.isfile os.path.join path 'web2py.py' i 0while i < 10 i + 1if os.path.exists os.path.join path 'web2py.py' breakpath os.path.abspath os.path.join path '..' paths [path os.path.abspath os.path.join path 'site-packages' os.path.abspath os.path.join path 'gluon' ''][add_path_first path for path in paths]
def sqlors left lst if isinstance lst iters lst list lst ln len lst if ln 0 return SQLQuery '1 2' if ln 1 lst lst[0]if isinstance lst iters return SQLQuery [' '] + sum [[left sqlparam x 'OR'] for x in lst] [] + ['1 2 '] else return left + sqlparam lst
def reverse_with_get view args None kwargs None get None if args is None args dict url urlresolvers.reverse view args args kwargs kwargs if get is not None and len get > 0 params urlencode get url url + '?' + params return url
def is_absolute_url path return path.startswith 'http'
def test_report topic user report Report reason 'TestReport' report.save user user post topic.first_post assert report.reason 'TestReport' report.reason 'TestReportEdited'report.save assert report.reason 'TestReportEdited' report.delete report Report.query.filter_by id report.id .first assert report is None
def stp br None state 'disable' iface None kernel __grains__['kernel']if kernel 'Linux' states {'enable' 'on' 'disable' 'off'}return _os_dispatch 'stp' br states[state] elif kernel in SUPPORTED_BSD_LIKE states {'enable' 'stp' 'disable' '-stp'}return _os_dispatch 'stp' br states[state] iface else return False
def is_malicious app id changeset_revision **kwd repository_metadata get_repository_metadata_by_changeset_revision app id changeset_revision if repository_metadata return repository_metadata.maliciousreturn False
def trackpoint return s3_rest_controller
def get_valid_serial_nos sr_nos qty 0 item_code u'' serial_nos cstr sr_nos .strip .replace u' ' u'\n' .split u'\n' valid_serial_nos []for val in serial_nos if val val val.strip if val in valid_serial_nos frappe.throw _ u'Serialnumber{0}enteredmorethanonce' .format val else valid_serial_nos.append val if qty and len valid_serial_nos ! abs qty frappe.throw _ u'{0}validserialnosforItem{1}' .format abs qty item_code return valid_serial_nos
def _checkCPython sys sys platform platform return platform.python_implementation 'CPython'
def resource_name res_pkg_name name my_pkg None if res_pkg_name ! my_pkg return res_pkg_name + PRN_SEPARATOR + name return name
def getCrossProduct firstComplex secondComplex return firstComplex.real * secondComplex.imag - firstComplex.imag * secondComplex.real
def torque_job cmd pollpath name queue qsub_call 'qsub-koe-N%s-q%s' % 'MOTU' queue to_submit 'echo"%s;echo$?>%s"|%s' % cmd pollpath qsub_call return to_submit
@with_setup step_runner_environ def test_steps_that_match_named_groups_takes_them_as_parameters @step 'Whena ?P<what>\\w+ at" ?P<city>.* "' def given_action_named step what city assert_equals what 'foreign' assert_equals city 'RiodeJaneiro' f Feature.from_string FEATURE5 feature_result f.run scenario_result feature_result.scenario_results[0]assert_equals len scenario_result.steps_passed 1 assert_equals scenario_result.total_steps 1
def _discrete_log_shanks_steps n a b order None a % nb % nif order is None order n_order b n m isqrt order + 1 T dict x 1for i in range m T[x] ix x * b % n z mod_inverse b n z pow z m n x afor i in range m if x in T return i * m + T[x] x x * z % n raise ValueError 'Logdoesnotexist'
def parse_siteclass_proportions line_floats site_classes {}if line_floats for n in range len line_floats site_classes[n] {'proportion' line_floats[n]}return site_classes
def channelModeModifyAcknowledge a TpPd pd 6 b MessageType mesType 23 c ChannelDescription2 d ChannelMode packet a / b / c / d return packet
def _rebuild_reduction cls *args return cls._rebuild *args
def sceneToNormalShowNames name if not name return []name_list [name]new_name re.sub u' ?i [\\.] and [\\.] ' u'\\1&\\2' name re.I if new_name not in name_list name_list.append new_name results []for cur_name in name_list results.append re.sub u' \\D \\d{4} $' u'\\1 \\2 ' cur_name country_match_str u'|'.join countryList.values results.append re.sub u' ?i [._-] ' + country_match_str + u' $' u'\\1 \\2 ' cur_name results + name_listreturn list set results
def ConvertNodes node from_type to_type to_text if node.getType from_type new_node CreateQueryNode to_text to_type else new_node nodeconvert_children lambda c ConvertNodes c from_type to_type to_text new_node.children map convert_children node.children return new_node
def get_clusters x_original axis 'row' x x_original.copy if axis 'column' x x.Tnr x.shape[0]row_dissims pw_distances x ids map str range nr metric 'euclidean' linkage_matrix linkage row_dissims.condensed_form method 'average' tree TreeNode.from_linkage_matrix linkage_matrix row_dissims.ids return [int tip.name for tip in tree.tips ]
def translate_syntax_error error source None error.source sourceerror.translated Trueexc_info error.__class__ error None filename error.filenameif filename is None filename '<unknown>'return fake_exc_info exc_info filename error.lineno
def _legacy_str_to_test_flags fs_desc_string match re.search ' .*? / .*? / .*? / .* $' fs_desc_string.strip if not match raise ValueError 'unrecognizedFSlistentry%r' % fs_desc_string flags_obj partition.FsOptions fstype match.group 1 .strip mkfs_flags match.group 2 .strip mount_options match.group 3 .strip fs_tag match.group 4 .strip return flags_obj
def infinite_sleeps sleep_for for i in count yield i time.sleep sleep_for
def validate_model metadata validator ModelMetadataValidator metadata return validator.validate
def action name def decorator func func.wsgi_action namereturn funcreturn decorator
def filter_symbols iterator exclude exclude set exclude for s in iterator if s not in exclude yield s
def consul_fetch client path return client.kv.get path recurse True
def passthru arg return arg
def futrig e **kwargs from sympy.simplify.fu import hyper_as_trigfrom sympy.simplify.simplify import bottom_upe sympify e if not isinstance e Basic return eif not e.args return eold ee bottom_up e lambda x _futrig x **kwargs if kwargs.pop 'hyper' True and e.has HyperbolicFunction e f hyper_as_trig e e f _futrig e if e ! old and e.is_Mul and e.args[0].is_Rational e Mul *e.as_coeff_Mul return e
def setClockShowDate kvalue **kwargs if kvalue is not True and kvalue is not False return False_gsession _GSettings user kwargs.get 'user' schema 'org.gnome.desktop.interface' key 'clock-show-date' return _gsession._set kvalue
def _s word seq suffix 's' return word + suffix if len seq ! 1 else ''
def printProgress layerIndex procedureName printProgressByString '%slayercount%s...' % procedureName.capitalize layerIndex + 1
def composite_transform_factory a b if isinstance a IdentityTransform return belif isinstance b IdentityTransform return aelif isinstance a AffineBase and isinstance b AffineBase return CompositeAffine2D a b return CompositeGenericTransform a b
def build output worklist force False output_path abspath output source_paths []for f files in worklist source_paths.extend map abspath files update_needed Falseif not os.path.exists output_path if not settings.ASSETS_AUTO_CREATE and not force raise MergeError "'%s'needstobecreated butASSETS_AUTO_CREATEisdisabled" % output else update_needed Trueelif not force update_needed get_updater output_path source_paths if update_needed or force output output_pathtry try for filters files in worklist output merge map abspath files output filters output_path close False finally if hasattr output 'close' output.close except if os.path.exists output_path os.remove output_path raise
def usage parser.print_help sys.exit 2
def get url conn urlopen url resp conn.read conn.close return resp
def _api_config_set_nzbkey output kwargs cfg.nzb_key.set config.create_api_key config.save_config return report output keyword 'nzbkey' data cfg.nzb_key
def NormalizeAndTypeCheckKeys keys keys multiple NormalizeAndTypeCheck keys basestring Entity Key keys [_GetCompleteKeyOrError key for key in keys]return keys multiple
def syncdb settings_module bin_env None migrate False database None pythonpath None env None noinput True args []kwargs {}if migrate args.append 'migrate' if database kwargs['database'] databaseif noinput args.append 'noinput' return command settings_module 'syncdb' bin_env pythonpath env *args **kwargs
def arma_pacf ar ma nobs 10 apacf np.zeros nobs acov arma_acf ar ma nobs nobs + 1 apacf[0] 1.0for k in range 2 nobs + 1 r acov[ k]apacf[ k - 1 ] linalg.solve linalg.toeplitz r[ -1 ] r[1 ] [ -1 ]return apacf
def get_repository_heads repo heads [repo[h] for h in repo.heads None ]return heads
def _execute_types_in_stmt evaluator stmt definitions evaluator.eval_element stmt types_list [_execute_array_values evaluator d for d in definitions]type_list list chain.from_iterable types_list return type_list
def mchoicefield form field default if field in form.initial cm form.initial[field]else cm form.fields[field].initialif cm '*' form.initial[field] defaultelif ' ' in cm form.initial[field] cm.split ' ' else form.initial[field] [cm]
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def run_shell_command cmd child sp.Popen cmd shell True stdout sp.PIPE stderr sp.STDOUT output child.communicate [0]rc child.returncodereturn output rc
def _oauth2_web_server_flow_params kwargs params {'access_type' 'offline' 'response_type' 'code'}params.update kwargs approval_prompt params.get 'approval_prompt' if approval_prompt is not None logger.warning 'Theapproval_promptparameterforOAuth2WebServerFlowisdeprecated.Pleaseusethepromptparameterinstead.' if approval_prompt 'force' logger.warning 'approval_prompt "force"hasbeenadjustedtoprompt "consent"' params['prompt'] 'consent'del params['approval_prompt']return params
def record_agreement_to_terms user_id user_settings get_user_settings user_id strict True user_settings.last_agreed_to_terms datetime.datetime.utcnow _save_user_settings user_settings
def read_comments ws xml_source root fromstring xml_source authors _get_author_list root comment_nodes safe_iterator root '{%s}comment' % SHEET_MAIN_NS for node in comment_nodes author authors[int node.attrib['authorId'] ]cell node.attrib['ref']text_node node.find '{%s}text' % SHEET_MAIN_NS substrs []for run in text_node.findall '{%s}r' % SHEET_MAIN_NS runtext ''.join [t.text for t in run.findall '{%s}t' % SHEET_MAIN_NS ] substrs.append runtext comment_text ''.join substrs comment Comment comment_text author ws.cell coordinate cell .comment comment
def sigmoid_kernel X Y None gamma None coef0 1 X Y check_pairwise_arrays X Y if gamma is None gamma 1.0 / X.shape[1] K safe_sparse_dot X Y.T dense_output True K * gammaK + coef0np.tanh K K return K
def description_of file name 'stdin' u UniversalDetector for line in file u.feed line u.close result u.resultif result['encoding'] return '%s %swithconfidence%s' % name result['encoding'] result['confidence'] else return '%s noresult' % name
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def resetdb from airflow import modelslogging.info u'Droppingtablesthatexist' models.Base.metadata.drop_all settings.engine mc MigrationContext.configure settings.engine if mc._version.exists settings.engine mc._version.drop settings.engine initdb
def _lowess_initial_fit x_copy y_copy k n weights np.zeros n k dtype x_copy.dtype nn_indices [0 k]X np.ones k 2 fitted np.zeros n for i in range n left_width x_copy[i] - x_copy[nn_indices[0]] right_width x_copy[ nn_indices[1] - 1 ] - x_copy[i] width max left_width right_width _lowess_wt_standardize weights[i ] x_copy[nn_indices[0] nn_indices[1]] x_copy[i] width _lowess_tricube weights[i ] weights[i ] np.sqrt weights[i ] X[ 1] x_copy[nn_indices[0] nn_indices[1]]y_i weights[i ] * y_copy[nn_indices[0] nn_indices[1]] beta lstsq weights[i ].reshape k 1 * X y_i [0]fitted[i] beta[0] + beta[1] * x_copy[i] _lowess_update_nn x_copy nn_indices i + 1 return fitted weights
def init_host ip_range is_external False add_snat_rule ip_range is_external rules []if is_external for snat_range in CONF.force_snat_range rules.append 'PREROUTING-pipv4--ip-src%s--ip-dst%s-jredirect--redirect-targetACCEPT' % ip_range snat_range if rules ensure_ebtables_rules rules 'nat' iptables_manager.ipv4['nat'].add_rule 'POSTROUTING' '-s%s-d%s/32-jACCEPT' % ip_range CONF.metadata_host for dmz in CONF.dmz_cidr iptables_manager.ipv4['nat'].add_rule 'POSTROUTING' '-s%s-d%s-jACCEPT' % ip_range dmz iptables_manager.ipv4['nat'].add_rule 'POSTROUTING' '-s% range s-d% range s-mconntrack!--ctstateDNAT-jACCEPT' % {'range' ip_range} iptables_manager.apply
def _get_logs_used_space logs_dir settings.get_value 'COMMON' 'test_output_dir' default None autodir os.path.abspath os.path.join os.path.dirname __file__ '..' '..' if logs_dir is None logs_dir os.path.join autodir 'results' usage psutil.disk_usage logs_dir return int usage.percent
def instance_update_db context instance_uuid extra_values None now timeutils.utcnow values {'host' None 'node' None 'scheduled_at' now}if extra_values values.update extra_values return db.instance_update context instance_uuid values
def take_msb_bytes read crc32 None ret []while len ret 0 or ret[ -1 ] & 128 b read 1 if crc32 is not None crc32 binascii.crc32 b crc32 ret.append ord b[ 1] return ret crc32
def collect_parameters computation_graph parameters parameter_values parameter_sizes parameter_shapes [] [] [] for parameter in parameters parameter_values.append parameter.get_value borrow True parameter_sizes.append parameter_values[ -1 ].size parameter_shapes.append parameter_values[ -1 ].shape new_parameters shared_floatx_zeros sum parameter_sizes new_parameters.set_value numpy.concatenate [value.flatten for value in parameter_values] new_parameters.name 'collected_parameters'add_role new_parameters COLLECTOR replacements {}for parameter shape i j in zip parameters parameter_shapes numpy.cumsum [0] + parameter_sizes[ -1 ] numpy.cumsum parameter_sizes new_parameter new_parameters[i j].reshape shape new_parameter.replacement_of parameteradd_role new_parameter COLLECTED replacements[parameter] new_parameterreturn computation_graph.replace replacements
def as_column a if a.ndim ! 1 raise ValueError 'as_columnexpectedan1-dimensionalarray butgotanarrayofshape%s' % a.shape return a[ None]
def decode_slice slc ret []for x in slc.start slc.stop slc.step if hasattr x '__index__' x x.__index__ ret.append x return tuple ret
def DeconstructAssetId id_prefix asset_id assert IdPrefix.IsValid id_prefix id_prefixassert asset_id[0] id_prefix asset_idbyte_str base64hex.B64HexDecode asset_id[1 ] padding False device_id num_bytes util.DecodeVarLengthNumber byte_str uniquifier _DecodeUniquifier byte_str[num_bytes ] return device_id uniquifier
def analytics_upageviews_by_revisions revisions if not revisions return {}revision_ids [r.id for r in revisions]start_date min r.created for r in revisions return analytics_upageviews revision_ids start_date
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _makeHeaderIPv4 sig V2_SIGNATURE verCom '!' famProto '\x11' addrLength '\x00\x0c' addrs '\x7f\x00\x00\x01\x7f\x00\x00\x01' ports '\x1f\x90"\xb8' return sig + verCom + famProto + addrLength + addrs + ports
def test_legacy_format script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' 'simple2 3.0' result script.pip 'list' '--format legacy' assert 'simple 1.0 ' in result.stdout str result assert 'simple2 3.0 ' in result.stdout str result
def save filename None family 'ipv4' if _conf and not filename filename _conf family log.debug 'Savingrulesto{0}'.format filename parent_dir os.path.dirname filename if not os.path.isdir parent_dir os.makedirs parent_dir cmd '{0}-save'.format _iptables_cmd family ipt __salt__['cmd.run'] cmd if len _conf_save_filters > 0 ipt _regex_iptables_save ipt out __salt__['file.write'] filename ipt return out
def get_request_user request RequestCache.get_current_request return getattr request u'user' None
@when u'wewaitforprompt' def step_wait_prompt context _expect_exact context u'{0}>'.format context.conf[u'dbname'] timeout 5
def setup_warning_catcher caught_warnings []original_showwarning warnings.showwarningdef custom_showwarning *args **kwargs caught_warnings.append args[0] warnings.showwarning custom_showwarningdef restore_showwarning warnings.showwarning original_showwarningreturn caught_warnings restore_showwarning
def register_custom_supported_check alias f plugin_agnostic False EXTENSION_SUPPORTED_CHECK_MAP[alias] fif plugin_agnostic _PLUGIN_AGNOSTIC_EXTENSIONS.add alias
def add_domains args_or_config domains validated_domains []for domain in domains.split ' ' domain util.enforce_domain_sanity domain.strip validated_domains.append domain if domain not in args_or_config.domains args_or_config.domains.append domain return validated_domains
def add_settings mod settings for setting in dir mod if not setting.isupper continuesetting_value getattr mod setting if setting in 'INSTALLED_APPS' 'TEMPLATE_DIRS' and isinstance setting_value six.string_types setting_value setting_value if setting[ 6] 'EXTRA_' base_setting setting[6 ]if isinstance getattr settings base_setting list tuple curval getattr settings base_setting setattr settings base_setting curval + type curval setting_value continuesetattr settings setting setting_value
def test_can_parse_tabular_step_followed_by_regular_step steps Step.many_from_lines I_HAVE_TASTY_BEVERAGES.splitlines + I_LIKE_VEGETABLES.splitlines assert_equals len steps 2 assert isinstance steps[0] Step assert isinstance steps[1] Step assert_equals steps[0].sentence string.split I_HAVE_TASTY_BEVERAGES '\n' [0] assert_equals steps[1].sentence I_LIKE_VEGETABLES
def Browse ob __main__ root MakeHLI ob 'root' if not root.IsExpandable raise TypeError 'Browse argumentmusthave__dict__attribute orbeaBrowsersupportedtype' dlg dynamic_browser root dlg.CreateWindow
def is_fixed_orient forward orig False if orig fixed_ori forward['_orig_source_ori'] FIFF.FIFFV_MNE_FIXED_ORI else fixed_ori forward['source_ori'] FIFF.FIFFV_MNE_FIXED_ORI return fixed_ori
def spherical_bessel_fn n x None **args if n < 0 dup dup_spherical_bessel_fn_minus - int n ZZ else dup dup_spherical_bessel_fn int n ZZ poly DMP dup ZZ if x is not None poly Poly.new poly 1 / x else poly PurePoly.new poly 1 / Dummy 'x' if not args.get 'polys' False return poly.as_expr else return poly
def get_auth_url try return __opts__['keystone.auth_url']except KeyError return 'http //localhost 35357/v2.0'
def validate_argsort_with_ascending ascending args kwargs if is_integer ascending or ascending is None args ascending + args ascending Truevalidate_argsort args kwargs max_fname_arg_count 1 return ascending
def CurrentLineAndColumn line column vim.current.window.cursorline - 1return line column
def change_username old_username new_username _xml '<RIBCLVERSION "2.0">\n<LOGINUSER_LOGIN "adminname"PASSWORD "password">\n<USER_INFOMODE "write">\n<MOD_USERUSER_LOGIN "{0}">\n<USER_NAMEvalue "{1}"/>\n<USER_LOGINvalue "{1}"/>\n</MOD_USER>\n</USER_INFO>\n</LOGIN>\n</RIBCL>'.format old_username new_username return __execute_cmd 'Change_username' _xml
def _create_association context namespace_name resource_type_name values session namespace_resource_type_rec models.MetadefNamespaceResourceType metadef_utils.drop_protected_attrs models.MetadefNamespaceResourceType values namespace_resource_type_rec.update values.copy try namespace_resource_type_rec.save session session except db_exc.DBDuplicateEntry LOG.debug 'Themetadatadefinitionresource-typeassociationofresource_type % resource_type_name stonamespace % namespace_name s alreadyexists.' {'resource_type_name' resource_type_name 'namespace_name' namespace_name} raise exc.MetadefDuplicateResourceTypeAssociation resource_type_name resource_type_name namespace_name namespace_name return namespace_resource_type_rec.to_dict
@step u'{word w}stepfailswith' def step_fails_with_text context word assert context.text is not None 'REQUIRE text'step_fails_with_message context word context.text
def network_create request **kwargs LOG.debug 'network_create kwargs %s' % kwargs body {'network' kwargs}network quantumclient request .create_network body body .get 'network' return Network network
@pytest.mark.parametrize 'parallel' [True False] def test_read_tab parallel read_tab if parallel pytest.xfail 'Multiprocessingcanfailwithquotedfields' text '1 DCTB 2 DCTB 3\na DCTB b DCTB \nc DCTB "d\ne" DCTB 'table read_tab text parallel parallel assert_equal table['1'][0] 'a' assert_equal table['2'][0] 'b' assert table['3'][0] is ma.masked assert_equal table['2'][1] 'de' assert_equal table['3'][1] ''
def test_random_permutation n_samples 10random_state 42python_randperm random_permutation n_samples random_state matlab_randperm np.array [7 6 5 1 4 9 10 3 8 2] assert_array_equal python_randperm matlab_randperm - 1
def untracked_files git git paths None if paths is None paths []args [u'--'] + paths out git.ls_files z True others True exclude_standard True *args [STDOUT]if out return out[ -1 ].split u'\x00' return []
def remove_interface zone interface permanent True if interface not in get_interfaces zone permanent log.info 'Interfaceisnotboundtozone.' cmd '--zone {0}--remove-interface {1}'.format zone interface if permanent cmd + '--permanent'return __firewall_cmd cmd
def verify_for_closed_enrollment user cart None if cart is None cart Order.get_cart_for_user user expired_cart_items []expired_cart_item_names []valid_cart_item_tuples []cart_items cart.orderitem_set.all .select_subclasses is_any_course_expired Falsefor cart_item in cart_items course_key getattr cart_item 'course_id' None if course_key is not None course get_course_by_id course_key depth 0 if CourseEnrollment.is_enrollment_closed user course is_any_course_expired Trueexpired_cart_items.append cart_item expired_cart_item_names.append course.display_name else valid_cart_item_tuples.append cart_item course return is_any_course_expired expired_cart_items expired_cart_item_names valid_cart_item_tuples
def test_cases suite for suite_or_case in suite._tests if isinstance suite_or_case unittest.TestCase yield suite_or_case else for case in test_cases suite_or_case yield case
def is_non_string_iterable obj return not isinstance obj six.string_types and isinstance obj Iterable
def locales names family distrib_family if family 'debian' command 'dpkg-reconfigure--frontend noninteractivelocales'config_file '/etc/locale.gen'_locales_generic names config_file config_file command command elif family in ['arch' 'gentoo'] _locales_generic names config_file '/etc/locale.gen' command 'locale-gen' elif distrib_family 'redhat' _locales_redhat names else raise UnsupportedFamily supported ['debian' 'arch' 'gentoo' 'redhat']
def disconnect_discussion_signals post_save.disconnect sender comment_model dispatch_uid COMMENT_PS_COUNT_DISCUSSIONS pre_delete.disconnect sender comment_model dispatch_uid COMMENT_PD_COUNT_DISCUSSIONS comment_was_flagged.disconnect sender comment_model dispatch_uid COMMENT_WF_COUNT_DISCUSSIONS comment_was_posted.disconnect sender comment_model dispatch_uid COMMENT_WP_COUNT_COMMENTS pingback_was_posted.disconnect sender comment_model dispatch_uid PINGBACK_WF_COUNT_PINGBACKS trackback_was_posted.disconnect sender comment_model dispatch_uid TRACKBACK_WF_COUNT_TRACKBACKS
def dir2 obj try words set dir obj except Exception words set words [w for w in words if isinstance w str ]return sorted words
def _default_stim_chs info return pick_types info meg False ref_meg False misc True exclude [] [ 8]
def _clear_cache tgt None tgt_type 'glob' clear_pillar_flag False clear_grains_flag False clear_mine_flag False clear_mine_func_flag None if tgt is None return Falsepillar_util salt.utils.master.MasterPillarUtil tgt tgt_type use_cached_grains True grains_fallback False use_cached_pillar True pillar_fallback False opts __opts__ return pillar_util.clear_cached_minion_data clear_pillar clear_pillar_flag clear_grains clear_grains_flag clear_mine clear_mine_flag clear_mine_func clear_mine_func_flag
def _addSlash request url URL.fromText request.uri.decode 'ascii' url url.replace path list url.path + [u''] return url.asText .encode 'ascii'
def ast_compile ast filename mode flags __future__.CO_FUTURE_DIVISION | __future__.CO_FUTURE_PRINT_FUNCTION return compile ast filename mode flags
def __assert_sorted collection if collection ! sorted collection raise ValueError 'Collectionmustbesorted' return True
def intColor index hues 9 values 1 maxValue 255 minValue 150 maxHue 360 minHue 0 sat 255 alpha 255 **kargs hues int hues values int values ind int index % hues * values indh ind % hues indv ind / hues if values > 1 v minValue + indv * maxValue - minValue / values - 1 else v maxValueh minHue + indh * maxHue - minHue / hues c QtGui.QColor c.setHsv h sat v c.setAlpha alpha return c
def update_travis_deploy_password encrypted_password config load_yaml_config TRAVIS_CONFIG_FILE config['deploy']['password'] dict secure encrypted_password save_yaml_config TRAVIS_CONFIG_FILE config line '#Thisfilewasautogeneratedandwilloverwriteeachtimeyouruntravis_pypi_setup.py\n'prepend_line TRAVIS_CONFIG_FILE line
def tail conn stack_name log_func _tail_print sleep_time 5 include_initial True seen set initial_events get_events conn stack_name for e in initial_events if include_initial log_func e seen.add e.event_id while 1 events get_events conn stack_name for e in events if e.event_id not in seen log_func e seen.add e.event_id time.sleep sleep_time
def subscribe_to_creator user_id creator_id subscribers_model_creator user_models.UserSubscribersModel.get creator_id strict False subscriptions_model_user user_models.UserSubscriptionsModel.get user_id strict False if not subscribers_model_creator subscribers_model_creator user_models.UserSubscribersModel id creator_id if not subscriptions_model_user subscriptions_model_user user_models.UserSubscriptionsModel id user_id if user_id not in subscribers_model_creator.subscriber_ids subscribers_model_creator.subscriber_ids.append user_id subscriptions_model_user.creator_ids.append creator_id subscribers_model_creator.put subscriptions_model_user.put
def process_java_resources target source env shutil.copy2 str source[0] str target[0] return None
def insertionsort a for i in range len a item a[i]j iwhile j > 0 and a[ j - 1 ] > item a[j] a[ j - 1 ]j - 1a[j] itemreturn a
def register_service service frame inspect.currentframe m_name frame.f_back.f_globals['__name__']m sys.modules[m_name]m._SERVICE_NAME service
def test_warning_on_non_existant_path_FileLinks fls display.FileLinks 'example' nt.assert_true fls._repr_html_ .startswith 'Path <tt>example</tt> '
def eigenvector_centrality_numpy G weight 'weight' max_iter 50 tol 0 import scipy as spfrom scipy.sparse import linalgif len G 0 raise nx.NetworkXPointlessConcept 'cannotcomputecentralityforthenullgraph' M nx.to_scipy_sparse_matrix G nodelist list G weight weight dtype float eigenvalue eigenvector linalg.eigs M.T k 1 which 'LR' maxiter max_iter tol tol largest eigenvector.flatten .realnorm sp.sign largest.sum * sp.linalg.norm largest return dict zip G largest / norm
def MaxPool images targets numChannels subsX startX strideX outputsX numImages images.shape[0]assert targets.shape numImages numChannels * outputsX * outputsX _ConvNet.MaxPool images.p_mat targets.p_mat numChannels subsX startX strideX outputsX
def _removeSender senderkey _removeBackrefs senderkey try del connections[senderkey]except KeyError passtry del senders[senderkey]except pass
def package_id_or_name_exists package_id_or_name context model context['model']session context['session']result session.query model.Package .get package_id_or_name if result return package_id_or_nameresult session.query model.Package .filter_by name package_id_or_name .first if not result raise Invalid '%s %s' % _ 'Notfound' _ 'Dataset' return package_id_or_name
def chown path owner execute 'chown' owner path run_as_root True
def deactivate_packages module port_path packages deactivated_c 0for package in packages if not query_package module port_path package module.fail_json msg 'failedtoactivate%s package s notpresent' % package if not query_package module port_path package state 'active' continue rc out err module.run_command '%sdeactivate%s' % port_path package if query_package module port_path package state 'active' module.fail_json msg 'failedtodeactivated%s %s' % package out deactivated_c + 1if deactivated_c > 0 module.exit_json changed True msg 'deactivated%spackage s ' % deactivated_c module.exit_json changed False msg 'package s alreadyinactive'
def send_email_for_after_purchase email invoice_id order_url event_name event_organiser send_email to email action TICKET_PURCHASED subject MAILS[TICKET_PURCHASED]['subject'].format invoice_id invoice_id event_name event_name html MAILS[TICKET_PURCHASED]['message'].format order_url order_url event_name event_name event_organiser event_organiser
def load_backend full_backend_path path_bits full_backend_path.split u'.' if len path_bits < 2 raise ImproperlyConfigured u"Theprovidedbackend'%s'isnotacompletePythonpathtoaBaseEnginesubclass." % full_backend_path return import_class full_backend_path
def test_escapes entry tokenize ' foo"foo\\n" ' [0]assert entry[1] 'foo\n' entry tokenize ' foo"foo\\s" ' [0]assert entry[1] 'foo\\s'
def create_autoscaler gce mig params changed Falseas_policy _gen_gce_as_policy params['policy'] autoscaler gce.ex_create_autoscaler name params['name'] zone mig.zone instance_group mig policy as_policy if autoscaler changed Truereturn changed
def _can_download_report user try access_group Group.objects.get name settings.PAYMENT_REPORT_GENERATOR_GROUP except Group.DoesNotExist return Falsereturn access_group in user.groups.all
@local_optimizer [GpuElemwise] def local_pycuda_gpu_elemwise node if isinstance node.op GpuElemwise if not any [any i.type.broadcastable for i in node.inputs] and all [ i.ndim < 2 for i in node.inputs] new_op PycudaElemwiseSourceModuleOp node.op.scalar_op node.op.inplace_pattern *node.inputs return [new_op]
def _process_to_string to_string return [x for x in re.split '\\s| |;| ' to_string if x]
def make_attrgetter environment attribute if not isinstance attribute string_types or '.' not in attribute and not attribute.isdigit return lambda x environment.getitem x attribute attribute attribute.split '.' def attrgetter item for part in attribute if part.isdigit part int part item environment.getitem item part return itemreturn attrgetter
def map_reduce inputs mapper reducer collector defaultdict list for input in inputs for key value in mapper input collector[key].append value return [output for key values in collector.iteritems for output in reducer key values ]
def get_privs ret {}cmd __execute_kadmin 'get_privs' if cmd['retcode'] ! 0 or cmd['stderr'] ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retfor i in cmd['stdout'].splitlines [1 ] prop val i.split ' ' 1 ret[prop] [j for j in val.split ]return ret
def getMaximum firstComplex secondComplex return complex max firstComplex.real secondComplex.real max firstComplex.imag secondComplex.imag
def format_screen strng par_re re.compile '\\\\$' re.MULTILINE strng par_re.sub '' strng return strng
def from_mlab_linkage Z Z np.asarray Z dtype np.double order 'c' Zs Z.shapeif len Zs 0 or len Zs 1 and Zs[0] 0 return Z.copy if len Zs ! 2 raise ValueError 'Thelinkagearraymustberectangular.' if Zs[0] 0 return Z.copy Zpart Z.copy if Zpart[ 0 2].min ! 1.0 and Zpart[ 0 2].max ! 2 * Zs[0] raise ValueError 'Theformatoftheindicesisnot1..N' Zpart[ 0 2] - 1.0CS np.zeros Zs[0] dtype np.double _hierarchy.calculate_cluster_sizes Zpart CS int Zs[0] + 1 return np.hstack [Zpart CS.reshape Zs[0] 1 ]
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def _docker_client wrapped @functools.wraps wrapped def wrapper *args **kwargs '\nEnsurethattheclientispresent\n'client_timeout __context__.get 'docker.timeout' CLIENT_TIMEOUT _get_client timeout client_timeout return wrapped *args **salt.utils.clean_kwargs **kwargs return wrapper
def apply_profile node profile if not profile or profile.fct_call_time 0 return Nonetime profile.apply_time.get node 0 call_time profile.fct_call_timereturn [time call_time]
def tolerant_equals a b atol 1e-06 rtol 1e-06 equal_nan False if equal_nan and isnan a and isnan b return Truereturn math.fabs a - b < atol + rtol * math.fabs b
def user_exists username **kwargs if 'database' not in kwargs return Falsereturn len tsql_query query "SELECTnameFROMsysusersWHEREname '{0}'".format username **kwargs 1
def _is_svc svc_path run_file os.path.join svc_path 'run' if os.path.exists svc_path and os.path.exists run_file and os.access run_file os.X_OK return Truereturn False
def getRequestType packet return ord packet[7]
def init_bookmark_completions log.completion.debug 'Initializingbookmarkcompletion.' try _instances[usertypes.Completion.bookmark_by_url].deleteLater except KeyError passmodel miscmodels.BookmarkCompletionModel _instances[usertypes.Completion.bookmark_by_url] model
def add_group_type_access context group_type_id project_id if group_type_id is None msg _ 'group_type_idcannotbeNone' raise exception.InvalidGroupType reason msg elevated context if context.is_admin else context.elevated if is_public_group_type elevated group_type_id msg _ 'Typeaccessmodificationisnotapplicabletopublicgrouptype.' raise exception.InvalidGroupType reason msg return db.group_type_access_add elevated group_type_id project_id
def get_data_home data_home None if data_home is None data_home os.environ.get 'SEABORN_DATA' os.path.join '~' 'seaborn-data' data_home os.path.expanduser data_home if not os.path.exists data_home os.makedirs data_home return data_home
def _get_tls_cacert url config if not config.tls_verify return Falsecerts getattr config 'tls_cacerts' None if not certs return Trueelif isinstance certs string_types tuple return certselse hostname urlsplit url [1]if '@' in hostname hostname hostname.split '@' [1]return certs.get hostname True
def parse_text directive text node_type nodes.paragraph where None assert text is not None 'Missingtextduringparse_textin%s' % where vl ViewList for line in text.split '\n' vl.append line line node node_type rawsource text directive.state.nested_parse vl 0 node return node
def test_ast_tuple code can_compile u' 123 ' .body[0].valueassert type code ast.Tuple
def _activation_even_odd W_list b_list samples beta odd True for i in xrange odd len samples 2 samples[i] hi_given samples i W_list b_list beta apply_sigmoid False
def get_by_name name try return _readline_commands[name]except KeyError raise KeyError u'Unknownreadlinecommand %r' % name
def remove_backslashes path if os.name 'nt' if path.endswith '\\' and not path.endswith '\\\\' path path[ -1 ]path path.replace '\\' '/' path path.replace "/'" "\\'" return path
def set_ key value profile None conn salt.utils.memcached.get_conn profile time profile.get 'expire' DEFAULT_EXPIRATION return salt.utils.memcached.set_ conn key value time time
def delete_cache_security_group name region None key None keyid None profile None **args return _delete_resource name name_param 'CacheSecurityGroupName' desc 'cachesecuritygroup' res_type 'cache_security_group' region region key key keyid keyid profile profile **args
@login_required@has_perm_or_owns_or_403 'forums_forum.thread_edit_forum' 'creator' Thread 'id__iexact' 'thread_id' Forum 'slug__iexact' 'forum_slug' def edit_thread request forum_slug thread_id forum get_object_or_404 Forum slug forum_slug thread get_object_or_404 Thread pk thread_id forum forum if thread.is_locked raise PermissionDeniedif request.method 'GET' form EditThreadForm instance thread return render request 'forums/edit_thread.html' {'form' form 'forum' forum 'thread' thread} form EditThreadForm request.POST if form.is_valid log.warning 'User%siseditingthreadwithid %s' % request.user thread.id thread.title form.cleaned_data['title']thread.save url reverse 'forums.posts' args [forum_slug thread_id] return HttpResponseRedirect url return render request 'forums/edit_thread.html' {'form' form 'forum' forum 'thread' thread}
def _close_event event params params['epochs'].drop params['bads'] params['epochs'].info['bads'] params['info']['bads']logger.info 'Channelsmarkedasbad %s' % params['epochs'].info['bads']
def pool_create request **kwargs body {'pool' {'name' kwargs['name'] 'description' kwargs['description'] 'subnet_id' kwargs['subnet_id'] 'protocol' kwargs['protocol'] 'lb_method' kwargs['lb_method'] 'admin_state_up' kwargs['admin_state_up']}}pool quantumclient request .create_pool body .get 'pool' return Pool pool
def karatsuba x y b 10 if x < 1000 or y < 1000 return x * y m min len str x / 2 len str y / 2 bm b ** m x1 x0 x / bm x % bm y1 y0 y / bm y % bm z1 karatsuba x1 y1 b z3 karatsuba x0 y0 b z2 karatsuba x1 + x0 y1 + y0 b - z1 - z3 return bm ** 2 * z1 + bm * z2 + z3
def get_blockdeviceapi config get_blockdevice_config backend api_args backend_and_api_args_from_configuration config api get_api backend backend api_args api_args reactor reactor cluster_id make_cluster_id TestTypes.FUNCTIONAL return api
def is_instance_of gateway java_object java_class if isinstance java_class basestring param java_classelif isinstance java_class JavaClass param java_class._fqnelif isinstance java_class JavaObject param java_class.getClass else raise Py4JError u'java_classmustbeastring aJavaClass oraJavaObject' return gateway.jvm.py4j.reflection.TypeUtil.isInstanceOf param java_object
def transform_surface_to surf dest trans copy False if isinstance dest string_types if dest not in _str_to_frame raise KeyError 'destmustbeoneof%s not"%s"' % list _str_to_frame.keys dest dest _str_to_frame[dest]if surf['coord_frame'] dest return surftrans _ensure_trans trans int surf['coord_frame'] dest surf['coord_frame'] destsurf['rr'] apply_trans trans surf['rr'] surf['nn'] apply_trans trans surf['nn'] move False return surf
def test_zeros AreEqual binascii.b2a_hex '\x00\x00\x10\x00' '00001000'
@csrf_exempt@use_master@require_POSTdef chargeback request raise NotImplementedError
def upload_to field_path default from mezzanine.conf import settingsfor k v in settings.UPLOAD_TO_HANDLERS.items if k.lower field_path.lower return import_dotted_path v return default
def authorization_headers username server if not username if 'AUTOTEST_USER' in os.environ username os.environ['AUTOTEST_USER']else username getpass.getuser password getpass.getpass 'Enterthepasswordfor%s ' % username base64string base64.encodestring '%s %s' % username password [ -1 ]return {'AUTHORIZATION' 'Basic%s' % base64string }
def hyperexpand f allow_hyper False rewrite 'default' place None f sympify f def do_replace ap bq z r _hyperexpand Hyper_Function ap bq z rewrite rewrite if r is None return hyper ap bq z else return rdef do_meijer ap bq z r _meijergexpand G_Function ap[0] ap[1] bq[0] bq[1] z allow_hyper rewrite rewrite place place if not r.has nan zoo oo - oo return rreturn f.replace hyper do_replace .replace meijerg do_meijer
def read_nih_image_header fh byteorder dtype count a fh.read_record NIH_IMAGE_HEADER byteorder byteorder a a.newbyteorder byteorder a.xunit a.xunit[ a._xunit_len]a.um a.um[ a._um_len]return a
def _get_groupings dist_matrix_header dist_matrix groups within True suppress_symmetry_and_hollowness_check False if not suppress_symmetry_and_hollowness_check if not is_symmetric_and_hollow dist_matrix raise ValueError 'Thedistancematrixmustbesymmetricandhollow.' result []group_items groups.items for i row_group row_ids in enumerate group_items row_indices _get_indices dist_matrix_header row_ids if within block dist_matrix[row_indices][ row_indices]size len row_indices indices []for i in range size for j in range i size if i ! j indices.append block[i][j] if indices result.append row_group row_group indices else for j in range i + 1 len groups col_group col_ids group_items[j]col_indices _get_indices dist_matrix_header col_ids vals dist_matrix[row_indices][ col_indices]vals map None vals.flat if vals result.append row_group col_group vals return result
@frappe.whitelist def get_due_date posting_date party_type party company due_date Noneif posting_date and party due_date posting_date credit_days_based_on credit_days get_credit_days party_type party company if credit_days_based_on u'FixedDays' and credit_days due_date add_days posting_date credit_days elif credit_days_based_on u'LastDayoftheNextMonth' due_date get_first_day posting_date 0 2 + datetime.timedelta -1 .strftime u'%Y-%m-%d' return due_date
def _setConfAttributes debugMsg 'initializingtheconfiguration'logger.debug debugMsg conf.authUsername Noneconf.authPassword Noneconf.boundaries []conf.cj Noneconf.dbmsConnector Noneconf.dbmsHandler Noneconf.dnsServer Noneconf.dumpPath Noneconf.hashDB Noneconf.hashDBFile Noneconf.httpHeaders []conf.hostname Noneconf.ipv6 Falseconf.multipleTargets Falseconf.outputPath Noneconf.paramDict {}conf.parameters {}conf.path Noneconf.port Noneconf.proxyList Noneconf.resultsFilename Noneconf.resultsFP Noneconf.scheme Noneconf.tests []conf.trafficFP Noneconf.wFileType None
def datetime_to_microseconds dt return int time.mktime dt.timetuple * 1000000 + dt.microsecond
def _safe_region region None context None ret region or settings.get 'region' context context or identity if not ret if not context _create_identity context identityret context.get_default_region if not ret try ret regions[0]except IndexError ret ''return ret
def isatty stream fn getattr stream 'isatty' None if fn is None return Falsereturn fn
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def query_descendants model_instance result Query .ancestor model_instance result.filter datastore_types.KEY_SPECIAL_PROPERTY + '>' model_instance.key return result
def csrf_failure request reason '' from django.middleware.csrf import REASON_NO_REFERERt Template CSRF_FAILURE_TEMPLATE c Context {'DEBUG' settings.DEBUG 'reason' reason 'no_referer' reason REASON_NO_REFERER } return HttpResponseForbidden t.render c mimetype 'text/html'
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
@pytest.yield_fixture scope 'module' def real_db engine main_engine session new_session engine yield session session.rollback session.close
def readmodule module path None res {}for key value in _readmodule module path or [] .items if isinstance value Class res[key] valuereturn res
def _psd_pinv_decomposed_log_pdet mat cond None rcond None lower True check_finite True s u scipy.linalg.eigh mat lower lower check_finite check_finite if rcond is not None cond rcondif cond in [None -1 ] t u.dtype.char.lower factor {'f' 1000.0 'd' 1000000.0}cond factor[t] * np.finfo t .eps eps cond * np.max abs s if np.min s < - eps raise ValueError 'thecovariancematrixmustbepositivesemidefinite' s_pinv _pinv_1d s eps U np.multiply u np.sqrt s_pinv log_pdet np.sum np.log s[ s > eps ] return U log_pdet
def get_courses courses [c for c in modulestore .get_courses if isinstance c CourseDescriptor ]courses sorted courses key lambda course course.location.course return courses
def function_variable *a **kw return a kw
def DisplayTree node children level 0 value ''node_type ''if 'caseValue' in node case_value node['caseValue']node_type case_value['ProductDimension.Type']if node_type 'ProductCanonicalCondition' value case_value['condition'] if 'condition' in case_value else 'OTHER' elif node_type 'ProductBiddingCategory' value '%s %s ' % case_value['type'] case_value['value'] if 'value' in case_value else 'OTHER' else value case_value['value'] if 'value' in case_value else 'OTHER' print '%sid %s node_type %s value %s\n' % '' * level node['id'] node_type value for child_node in children[node['id']] DisplayTree child_node children level + 1
def assure_container fnc @wraps fnc def _wrapped self container *args **kwargs if not isinstance container Container container self.get container return fnc self container *args **kwargs return _wrapped
def get_schema frame name flavor None keys None con None dtype None pandas_sql pandasSQL_builder con con flavor flavor return pandas_sql._create_sql_schema frame name keys keys dtype dtype
def info return _nodetool 'info'
def test_operators for op in Operator.inheritors check_export.description 'AssertthattheTPOT{}operatorexportsasexpected'.format op.__name__ yield check_export op
def update_email_marketing_config enabled True key 'badkey' secret 'badsecret' new_user_list 'newlist' template 'Activation' enroll_cost 100 lms_url_override 'http //testserver' return EmailMarketingConfiguration.objects.create enabled enabled sailthru_key key sailthru_secret secret sailthru_new_user_list new_user_list sailthru_activation_template template sailthru_enroll_template 'enroll_template' sailthru_lms_url_override lms_url_override sailthru_get_tags_from_sailthru False sailthru_enroll_cost enroll_cost sailthru_max_retries 0 welcome_email_send_delay 600
def params_set module changed Falsemodule.params['ovs-vsctl'] module.get_bin_path 'ovs-vsctl' True fmt '% ovs-vsctl s-t% timeout sget% table s% record s% col s % key s'cmd fmt % module.params _ output _ cmd_run module cmd False if module.params['value'] not in output fmt '% ovs-vsctl s-t% timeout sset% table s% record s% col s % key s % value s'cmd fmt % module.params rtc _ err cmd_run module cmd if rtc ! 0 module.fail_json msg err changed Truemodule.exit_json changed changed
@utils.arg 'address' metavar '<ipaddress>' help _ 'NewIPAddress.' @utils.arg 'port' metavar '<port>' help _ 'NewPort.' def do_cloudpipe_configure cs args cs.cloudpipe.update args.address args.port
def load_pandas data _get_data return du.process_recarray_pandas data endog_idx 0 dtype float
def _calculate_batch_size image_count is_hdf5 False hdf5_dset_limit None image_channels None image_height None image_width None if is_hdf5 and hdf5_dset_limit is not None return min 100 image_count hdf5_dset_limit / image_channels * image_height * image_width else return min 100 image_count
def get_tool_shed_repository_by_id app repository_id return app.install_model.context.query app.install_model.ToolShedRepository .filter app.install_model.ToolShedRepository.table.c.id app.security.decode_id repository_id .first
def test_resize_promo_img resize_size [1050]final_size [ 1050 591 640 360 320 180 ]_promo_img_uploader resize_size final_size
def test_jpeg h f if h[6 10] in 'JFIF' 'Exif' or h[ 2] '\xff\xd8' and 'JFIF' in h[ 32] or '8BIM' in h[ 32] return 'jpeg'
def test_cache_line_split_issues assert jedi.Script 'int \n' .call_signatures [0].name 'int'
def auth_info encoded_info request.headers.get 'X-Endpoint-API-UserInfo' None if encoded_info info_json _base64_decode encoded_info user_info json.loads info_json else user_info {'id' 'anonymous'}return jsonify user_info
def chained func def wrapper *args **kwargs for xs in func *args **kwargs for x in xs yield x return wrapper
def set_preprint_providers providers {'osf' 'OpenScienceFramework' 'socarxiv' 'SocArXiv' 'engrxiv' 'EngrXiv' 'psyarxiv' 'PsyArXiv'}for key value in providers.items provider factories.PreprintProviderFactory provider._id keyprovider.name valuetry provider.save except KeyExistsException continue
def create_profile hostname username password profile_type name **kwargs ret {'name' name 'changes' {} 'result' False 'comment' ''}if __opts__['test'] return _test_output ret 'create' params {'hostname' hostname 'username' username 'password' password 'profile_type' profile_type 'name' name} existing __salt__['bigip.list_profile'] hostname username password profile_type name if existing['code'] 200 ret['result'] Trueret['comment'] 'Aprofilebythisnamecurrentlyexists.Nochangemade.'elif existing['code'] 404 response __salt__['bigip.create_profile'] hostname username password profile_type name **kwargs if response['code'] 200 ret['result'] Trueret['changes']['old'] {}ret['changes']['new'] response['content']ret['comment'] 'Profilewassuccessfullycreated.'else ret _load_result response ret else ret _load_result existing ret return ret
def selStochasticUniversalSampling individuals k s_inds sorted individuals key attrgetter 'fitness' reverse True sum_fits sum ind.fitness.values[0] for ind in individuals distance sum_fits / float k start random.uniform 0 distance points [ start + i * distance for i in xrange k ]chosen []for p in points i 0sum_ s_inds[i].fitness.values[0]while sum_ < p i + 1sum_ + s_inds[i].fitness.values[0]chosen.append s_inds[i] return chosen
def get_builtin_sites jsondb json.loads get_pkg_data_contents u'data/sites.json' return SiteRegistry.from_json jsondb
def cleanup_sff flowgrams header outhandle None outdir '/tmp' min_length 150 max_length 400 clean_filename ''if not outhandle fd clean_filename mkstemp dir outdir prefix 'cleanup_sff' suffix '.sff.txt' close fd outhandle open clean_filename 'w' l filter_sff_file flowgrams header [ lambda f within_length f min_length max_length lambda f f.hasProperKey ] outhandle return clean_filename l
def object_build_function node member localname args varargs varkw defaults getargspec member if varargs is not None args.append varargs if varkw is not None args.append varkw func build_function getattr member '__name__' None or localname args defaults six.get_function_code member .co_flags member.__doc__ node.add_local_node func localname
def _create_config_dir directory sqlcmd.DEFAULT_CONFIG_DIRif not os.access directory os.R_OK | os.W_OK | os.X_OK old_umask os.umask 63 os.makedirs sqlcmd.DEFAULT_CONFIG_DIR os.umask old_umask
def tprint call_name print 'testremotecall %s ' % call_name
def conv x y mode 2 warnings.warn "Usenumpy.convolve x y mode 'full' " DeprecationWarning return np.convolve x y mode
def is_multilabel y if hasattr y '__array__' y np.asarray y if not hasattr y 'shape' and y.ndim 2 and y.shape[1] > 1 return Falseif issparse y if isinstance y dok_matrix lil_matrix y y.tocsr return len y.data 0 or np.unique y.data .size 1 and y.dtype.kind in 'biu' or _is_integral_float np.unique y.data else labels np.unique y return len labels < 3 and y.dtype.kind in 'biu' or _is_integral_float labels
def loaded_vispy_modules import_module depth None all_modules False vispy_dir os.path.dirname os.path.dirname vispy.__file__ code "importsys %s;print ' '.join sys.modules " % import_module res run_subprocess [sys.executable '-c' code] cwd vispy_dir [0]loaded_modules [name.strip for name in res.split ' ' ]if all_modules return loaded_modulesvispy_modules set for m in loaded_modules if m.startswith 'vispy' and '__future__' not in m if depth parts m.split '.' m '.'.join parts[ depth] vispy_modules.add m return vispy_modules
def is_probably_part_of_multiline line return u'"""' in line or u"'''" in line or line.rstrip .endswith u'\\'
def test_nonexistent_extra_warns_user_no_wheel script data result script.pip 'install' '--no-binary all ' '--no-index' '--find-links ' + data.find_links 'simple[nonexistent]' expect_stderr True assert "simple3.0doesnotprovidetheextra'nonexistent'" in result.stderr
def rollback_unless_managed if not is_managed connection._rollback else set_dirty
def erfc x z abs x t 1.0 / 1 + 0.5 * z r 0.0for y in 0.17087277 -0.82215223 1.48851587 -1.13520398 0.27886807 -0.18628806 0.09678418 0.37409196 1.00002368 -1.26551223 r y + t * r r t * exp - z ** 2 + r if x > 0 return rreturn 2.0 - r
def compute_targets gt_bb rp_bb x y w h _get_xywh rp_bb x_gt y_gt w_gt h_gt _get_xywh gt_bb targets_dx x_gt - x / w targets_dy y_gt - y / h targets_dw np.log w_gt / w targets_dh np.log h_gt / h targets np.concatenate targets_dx[ np.newaxis] targets_dy[ np.newaxis] targets_dw[ np.newaxis] targets_dh[ np.newaxis] axis 1 return targets
def blend *cols **kwargs return Blend *cols **kwargs
@unique_valuesdef find_external_links url page for match in REL.finditer page tag rel match.groups rels set map str.strip rel.lower .split ' ' if 'homepage' in rels or 'download' in rels for match in HREF.finditer tag yield urljoin url htmldecode match.group 1 for tag in '<th>HomePage' '<th>DownloadURL' pos page.find tag if pos ! -1 match HREF.search page pos if match yield urljoin url htmldecode match.group 1
def safe_max_abs_diff A ia B ib A A[ia] if np.sum ia else 0.0 B B[ib] if np.sum ia else 0.0 return np.max np.abs A - B
def getInsetLoopsFromVector3Loop loop radius thresholdRatio 0.9 if len loop < 2 return [loop]loopComplex euclidean.getComplexPath loop loopComplexes getInsetLoopsFromLoop loopComplex radius return euclidean.getVector3Paths loopComplexes loop[0].z
def test_sparse_oneclasssvm X_blobs _ make_blobs n_samples 100 centers 10 random_state 0 X_blobs sparse.csr_matrix X_blobs datasets [[X_sp None T] [X2_sp None T2] [X_blobs[ 80] None X_blobs[80 ]] [iris.data None iris.data]]kernels ['linear' 'poly' 'rbf' 'sigmoid']for dataset in datasets for kernel in kernels clf svm.OneClassSVM kernel kernel random_state 0 sp_clf svm.OneClassSVM kernel kernel random_state 0 check_svm_model_equal clf sp_clf *dataset
def validate_setup_for_nested_quota_use ctxt resources nested_quota_driver fix_allocated_quotas False try project_roots get_all_root_project_ids ctxt for root in project_roots root_proj get_project_hierarchy ctxt root subtree_as_ids True nested_quota_driver.validate_nested_setup ctxt resources {root_proj.id root_proj.subtree} fix_allocated_quotas fix_allocated_quotas except exceptions.VersionNotAvailable msg _ 'Keystoneversion3orgreatermustbeusedtogetnestedquotasupport.' raise exception.CinderException message msg except exceptions.Forbidden msg _ 'MustrunthiscommandascloudadminusingaKeystonepolicy.jsonwhichallowscloudadmintolistandgetanyproject.' raise exception.CinderException message msg
def get_user_copy module_name user None if not user user frappe.session.userdesktop_icon_name frappe.db.get_value u'DesktopIcon' {u'module_name' module_name u'owner' user u'standard' 0} if desktop_icon_name return frappe.get_doc u'DesktopIcon' desktop_icon_name else return make_user_copy module_name user
def make_tags_in_aws_format tags formatted_tags list for key val in tags.items formatted_tags.append {'Key' key 'Value' val} return formatted_tags
def parse_html_list dictionary prefix '' ret {}regex re.compile '^%s\\[ [0-9]+ \\] .* $' % re.escape prefix for field value in dictionary.items match regex.match field if not match continue index key match.groups index int index if not key ret[index] valueelif isinstance ret.get index dict ret[index][key] valueelse ret[index] MultiValueDict {key [value]} return [ret[item] for item in sorted ret.keys ]
def x [a for a in h if hio]if hio pass
def get_page_context_from_template path for app in frappe.get_installed_apps frappe_last True app_path frappe.get_app_path app folders frappe.local.flags.web_pages_folders or u'www' u'templates/pages' for start in folders search_path os.path.join app_path start path options search_path search_path + u'.html' search_path + u'.md' search_path + u'/index.html' search_path + u'/index.md' for o in options if os.path.exists o and not os.path.isdir o return get_page_info o app app_path app_path return None
def get_system_encoding try encoding locale.getdefaultlocale [1] or 'ascii' codecs.lookup encoding except Exception encoding 'ascii'return encoding
def delete_bookmark user usage_key bookmark Bookmark.objects.get user user usage_key usage_key bookmark.delete _track_event 'edx.bookmark.removed' bookmark
def predicative adjective w adjective.lower if w in adjective_predicative return adjective_predicative[w]if w.endswith 'ari' return w + 'o' if w.endswith 'ali' 'ili' 'esi' 'nti' 'ori' return w[ -1 ] + 'e' if w.endswith 'isti' return w[ -1 ] + 'a' if w.endswith 'che' 'ghe' return w[ -2 ] + 'a' if w.endswith 'chi' 'ghi' return w[ -2 ] + 'o' if w.endswith 'i' return w[ -1 ] + 'o' if w.endswith 'e' return w[ -1 ] + 'a' return adjective
def _chr opt if isinstance opt basestring return optelse return chr opt
def get_secret filename '/etc/appscale/secret.key' return read_file os.path.abspath filename chomp True
def make_track_function request import track.viewsdef function event_type event return track.views.server_track request event_type event page 'x_module' return function
def uid_to_user uid try return pwd.getpwuid uid .pw_nameexcept KeyError NameError return uid
def gauss_chebyshev_t n n_digits xi []w []for i in range 1 n + 1 xi.append cos 2 * i - S.One / 2 * n * S.Pi .n n_digits w.append S.Pi / n .n n_digits return xi w
def feat_tokens for_artist True feat_words ['ft' 'featuring' 'feat' 'feat.' 'ft.']if for_artist feat_words + ['with' 'vs' 'and' 'con' '&']return ' ?< \\s ? {0} ? \\s '.format '|'.join re.escape x for x in feat_words
def wait_for_redis_worker job timeout 5 start_time time.time while time.time - start_time < timeout if job.result REDIS_SUCCESS_RETURN_VALUE returnelif job.result not in None REDIS_SUCCESS_RETURN_VALUE assert False 'Redisworkerfailed!'time.sleep 0.1 assert False 'Redisworkertimedout!'
def _compare_bem_surfaces surfs_1 surfs_2 names ['id' 'nn' 'rr' 'coord_frame' 'tris' 'sigma' 'ntri' 'np']ignores ['tri_cent' 'tri_nn' 'tri_area' 'neighbor_tri']for s0 s1 in zip surfs_1 surfs_2 assert_equal set names set s0.keys - set ignores assert_equal set names set s1.keys - set ignores for name in names assert_allclose s0[name] s1[name] rtol 0.001 atol 1e-06 err_msg 'Mismatch "%s"' % name
def show_tree repo tree decode outstream sys.stdout for n in tree outstream.write decode n + '\n'
def organize_commands corrected_commands try first_command next corrected_commands yield first_command except StopIteration returnwithout_duplicates {command for command in sorted corrected_commands key lambda command command.priority if command ! first_command }sorted_commands sorted without_duplicates key lambda corrected_command corrected_command.priority logs.debug 'Correctedcommands '.format ' '.join u'{}'.format cmd for cmd in [first_command] + sorted_commands for command in sorted_commands yield command
def cov_white_simple results use_correction True xu hessian_inv _get_sandwich_arrays results sigma S_white_simple xu cov_w _HCCM2 hessian_inv sigma if use_correction nobs k_params xu.shapecov_w * nobs / float nobs - k_params return cov_w
def shell_quote text return u"\\'".join u"'%s'" % p for p in text.split u"'"
def get_token_ref context try auth_context context['environment'][authorization.AUTH_CONTEXT_ENV]return auth_context['token']except KeyError msg _ "Couldn'tfindtheauthcontext." LOG.warning msg raise exception.Unauthorized msg
def nuttall M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym w _cos_win M [0.3635819 0.4891775 0.1365995 0.0106411] return _truncate w needs_trunc
def checkCell0 tp for c in range tp.numberOfCols assert tp.getNumSegmentsInCell c 0 0
def _testrepeat **kwargs import timekwargs['session'].msg repeat 'Repeatcalled %s' % time.time
def simple_conll_corpus_iterator corpus_file l corpus_file.readline while l line l.strip if line fields line.split '' ne_tag fields[ -1 ]word ''.join fields[ -1 ] yield word ne_tag else yield None None l corpus_file.readline
def pportD3 state global dataRegif state 0 dataReg dataReg & ~ 8 else dataReg dataReg | 8 port.DlPortWritePortUchar baseAddress dataReg
def candidate_split_labels data groups defaultdict list for attr in data.domain.attributes for item in attr.attributes.items groups[item].append attr by_keys defaultdict list for key _ attrs in groups.items by_keys[key].append attrs candidates []for key groups in by_keys.items count len groups[0] if all len attrs count for attrs in groups and len groups > 1 and count > 1 candidates.append key return candidates
def default_database_options if DATABASE.ENGINE.get .endswith 'oracle' return {'threaded' True}elif DATABASE.ENGINE.get .endswith 'sqlite3' return {'timeout' 30}else return {}
def sign_app src dest ids reviewer False local False tempname tempfile.mktemp try return _sign_app src dest ids reviewer tempname local finally try os.unlink tempname except OSError pass
def get_http_object *args **kwargs return httplib2.Http *args **kwargs
@_docstring 'release' def search_releases query '' limit None offset None strict False **fields return _do_mb_search 'release' query fields limit offset strict
def mplot3d f var1 var2 show True import warningswarnings.filterwarnings 'ignore' 'Couldnotmatch\\S' p import_module 'pylab' p3 import_module 'mpl_toolkits.mplot3d' __import__kwargs {'fromlist' ['something']} or import_module 'matplotlib.axes3d' if not p or not p3 sys.exit 'Matplotlibisrequiredtousemplot3d.' x y z sample f var1 var2 fig p.figure ax p3.Axes3D fig ax.plot_wireframe x y z ax.set_xlabel 'X' ax.set_ylabel 'Y' ax.set_zlabel 'Z' if show p.show
def adam_consensus trees clades [tree.root for tree in trees]return BaseTree.Tree root _part clades rooted True
def find_packages_by_root_package where root_package os.path.basename where packages [ '%s.%s' % root_package sub_package for sub_package in find_packages where ]packages.insert 0 root_package return packages
def p_postfix_expression_7 t pass
def pop_context _local.stack.pop
def write_info fname info data_type None reset_range True fid start_file fname start_block fid FIFF.FIFFB_MEAS write_meas_info fid info data_type reset_range end_block fid FIFF.FIFFB_MEAS end_file fid
def GrocTimeSpecification schedule timezone None parser groc.CreateParser schedule parser.timespec if parser.period_string return IntervalTimeSpecification parser.interval_mins parser.period_string parser.synchronized parser.start_time_string parser.end_time_string timezone else return SpecificTimeSpecification parser.ordinal_set parser.weekday_set parser.month_set parser.monthday_set parser.time_string timezone
def get_organization_by_short_name organization_short_name if not organizations_enabled return Nonefrom organizations import api as organizations_apifrom organizations.exceptions import InvalidOrganizationExceptiontry return organizations_api.get_organization_by_short_name organization_short_name except InvalidOrganizationException return None
def _identity X return X
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def assertResponseFailed self deferred reasonTypes return assertWrapperExceptionTypes self deferred ResponseFailed reasonTypes
def optional type_ return type_ type None
def csrf request def _get_val token get_token request if token is None return 'NOTPROVIDED'else return force_text token return {'csrf_token' SimpleLazyObject _get_val }
def Application name uid None gid None ret components.Componentized for comp in MultiService sob.Persistent ret name Process uid gid ret.addComponent comp ignoreClass 1 IService ret .setName name return ret
@then 'thefile"{filename}"shouldcontainthelogrecords' def step_file_should_contain_log_records context filename assert context.table 'REQUIRE context.table'context.table.require_columns ['category' 'level' 'message'] format getattr context 'log_record_format' context.config.logging_format for row in context.table.rows output LogRecordTable.make_output_for_row row format context.text outputstep_file_should_contain_multiline_text context filename
def cookie_date expires None return _dump_date expires '-'
def _read_until sock char chunks []while True chunk sock.recv 1 chunks.append chunk if chunk char breakreturn ''.join chunks
def get_core_apps overrides None if not overrides return OSCAR_CORE_APPSfrom django.utils import sixif isinstance overrides six.string_types raise ValueError 'get_core_appsexpectsalistortupleofappstooverride' def get_app_label app_label overrides pattern app_label.replace 'oscar.apps.' '' for override in overrides if override.endswith pattern if 'dashboard' in override and 'dashboard' not in pattern continuereturn overridereturn app_labelapps []for app_label in OSCAR_CORE_APPS apps.append get_app_label app_label overrides return apps
def p_enum_specifier_1 t pass
def add_local_bypass table chain ipv6 run_iptables_cmd '-t%s-A%s-ptcp-msocket-jRETURN' % table chain ipv6 ipv6 v4_addrs v6_addrs get_interface_addresses for addr in v4_addrs run_iptables_cmd '-t%s-A%s-ptcp-d%s-jRETURN' % table chain addr ipv6 False for addr in v6_addrs run_iptables_cmd '-t%s-A%s-ptcp-d%s-jRETURN' % table chain addr ipv4 False ipv6 ipv6
def from_buffer buffer mime False m _get_magic_type mime return m.from_buffer buffer
def add_users_autogroup apps schema_editor Group apps.get_model u'auth' u'Group' AutoGroup apps.get_model u'accounts' u'AutoGroup' group Group.objects.get_or_create name u'Users' [0]if not AutoGroup.objects.filter group group .exists AutoGroup.objects.create group group match u'^.*$'
def rehash runas None _pyenv_exec 'rehash' runas runas return True
def create_default_context context ssl.SSLContext ssl.PROTOCOL_SSLv23 context.verify_mode ssl.CERT_NONEcontext.check_hostname Falsecontext.options | ossllib.SSL_OP_NO_SSLv2context.options | ossllib.SSL_OP_NO_SSLv3context.options | ossllib.SSL_OP_NO_COMPRESSIONcontext.options | ossllib.SSL_OP_CIPHER_SERVER_PREFERENCEcontext.options | ossllib.SSL_OP_SINGLE_DH_USEcontext.options | ossllib.SSL_OP_SINGLE_ECDH_USEcontext._ctx.set_mode ossllib.SSL_MODE_ENABLE_PARTIAL_WRITE | ossllib.SSL_MODE_ACCEPT_MOVING_WRITE_BUFFER | ossllib.SSL_MODE_AUTO_RETRY return context
def hashes_data step return [hash_data hash_ for hash_ in step.hashes]
def function receiver if hasattr receiver '__call__' if hasattr receiver.__call__ 'im_func' or hasattr receiver.__call__ 'im_code' receiver receiver.__call__if hasattr receiver 'im_func' return receiver receiver.im_func.func_code 1 elif not hasattr receiver 'func_code' raise ValueError 'unknownrecievertype%s%s' % receiver type receiver return receiver receiver.func_code 0
def string_eval source node ast.parse source '<source>' mode 'eval' if not isinstance node.body ast.Str raise ValueError '%risnotastringliteral' % source return node.body.s
def escapedComment data if isinstance data unicode data data.encode 'utf-8' data data.replace '--' '--' .replace '>' '&gt;' if data and data[ -1 ] '-' data + ''return data
def echo data '' return data
def user_exists username **kwargs if 'database' not in kwargs return Falsereturn len tsql_query query "SELECTnameFROMsysusersWHEREname '{0}'".format username **kwargs 1
def CreateMDIInteractiveWindow makeDoc None makeFrame None global editif makeDoc is None makeDoc InteractiveDocumentif makeFrame is None makeFrame InteractiveFrameedit CInteractivePython makeDoc makeDoc makeFrame makeFrame
def reboot zone single False altinit None smf_options None ret {'status' True}boot_options ''if single boot_options '-s{0}'.format boot_options if altinit boot_options '-i{0}{1}'.format altinit boot_options if smf_options boot_options '-m{0}{1}'.format smf_options boot_options if boot_options ! '' boot_options '--{0}'.format boot_options.strip res __salt__['cmd.run_all'] 'zoneadm{zone}reboot{boot_opts}'.format zone '-u{0}'.format zone if _is_uuid zone else '-z{0}'.format zone boot_opts boot_options ret['status'] res['retcode'] 0 ret['message'] res['stdout'] if ret['status'] else res['stderr'] ret['message'] ret['message'].replace 'zoneadm ' '' if ret['message'] '' del ret['message']return ret
def function_mock request q_function_name **kwargs _patch patch q_function_name **kwargs request.addfinalizer _patch.stop return _patch.start
def create_volume ctxt host 'test_host' display_name 'test_volume' display_description 'thisisatestvolume' status 'available' migration_status None size 1 availability_zone 'fake_az' volume_type_id None replication_status 'disabled' replication_extended_status None replication_driver_data None consistencygroup_id None group_id None previous_status None testcase_instance None **kwargs vol {}vol['size'] sizevol['host'] hostvol['user_id'] ctxt.user_idvol['project_id'] ctxt.project_idvol['status'] statusif migration_status vol['migration_status'] migration_statusvol['display_name'] display_namevol['display_description'] display_descriptionvol['attach_status'] fields.VolumeAttachStatus.DETACHEDvol['availability_zone'] availability_zoneif consistencygroup_id vol['consistencygroup_id'] consistencygroup_idif group_id vol['group_id'] group_idif volume_type_id vol['volume_type_id'] volume_type_idfor key in kwargs vol[key] kwargs[key]vol['replication_status'] replication_statusif replication_extended_status vol['replication_extended_status'] replication_extended_statusif replication_driver_data vol['replication_driver_data'] replication_driver_dataif previous_status vol['previous_status'] previous_statusvolume objects.Volume ctxt **vol volume.create if testcase_instance testcase_instance.addCleanup volume.destroy return volume
def load_module_instances setting_name provide_category return [x for x in load_modules setting_name provide_category ]
def poweroff timeout 5 in_seconds False return shutdown timeout timeout in_seconds in_seconds
def compute_change labels before after result {}for label before after in zip labels before after matched_keys set before & set after value {key after[key] - before[key] for key in matched_keys}result[label] valuereturn result
def greedyQPolicy Qs dim len Qs numA len Qs[0] policy zeros dim numA for si in range dim actions all_argmax Qs[si] for a in actions policy[ si a ] 1.0 / len actions return policy
def dynamic_string_param registry xml_parent data dynamic_param_common registry xml_parent data 'StringParameterDefinition'
def _Q filter_ thing T type thing if isinstance {} T for k v in compat.iteritems thing if filter_ k if isinstance v type [] yield iter v else yield v if type v in type {} type [] yield Q filter_ v elif isinstance [] T for k in thing yield Q filter_ k else pass
def _norm_version version build '' l string.split version '.' if build l.append build try ints map int l except ValueError strings lelse strings map str ints version string.join strings[ 3] '.' return version
def stopDtmf a TpPd pd 3 b MessageType mesType 49 packet a / b return packet
def _type_repr obj if isinstance obj type and not isinstance obj TypingMeta if obj.__module__ u'__builtin__' return _qualname obj return u'%s.%s' % obj.__module__ _qualname obj if obj is Ellipsis return u'...'if isinstance obj types.FunctionType return obj.__name__return repr obj
def check_table table None family 'ipv4' if not table return 'Error tableneedstobespecified'nft_family _NFTABLES_FAMILIES[family]cmd '{0}listtables{1}'.format _nftables_cmd nft_family out __salt__['cmd.run'] cmd python_shell False .find 'table{0}{1}'.format nft_family table if out ! -1 out ''else return Falseif not out return Truereturn out
def url_in request environ if routers return map_url_in request environ return regex_url_in request environ
def without_none_values iterable try return {k v for k v in six.iteritems iterable if v is not None }except AttributeError return type iterable v for v in iterable if v is not None
def hide_button_menu_indicator button name button.__class__.__name__stylesheet u'\n% name s menu-indicator{\nimage none;\n}\n'if name u'QPushButton' stylesheet + u'\n% name s{\nborder-style none;\n}\n'button.setStyleSheet stylesheet % dict name name
def _copy_if_lds item return copy.deepcopy item if isinstance item list dict set else item
def EscapeShellArgument s return "'" + s.replace "'" "'\\''" + "'"
def _tree_namespace_handler k v cherrypy.tree.graft v v.script_name cherrypy.engine.log 'Mounted %son%s' % v v.script_name or '/'
def latapy_clustering G nodes None mode 'dot' if not nx.algorithms.bipartite.is_bipartite G raise nx.NetworkXError 'Graphisnotbipartite' try cc_func modes[mode]except KeyError raise nx.NetworkXError 'Modeforbipartiteclusteringmustbe dot minormax' if nodes is None nodes Gccs {}for v in nodes cc 0.0nbrs2 set [u for nbr in G[v] for u in G[nbr]] - set [v] for u in nbrs2 cc + cc_func set G[u] set G[v] if cc > 0.0 cc / len nbrs2 ccs[v] ccreturn ccs
def _run_suite suite if verbose runner unittest.TextTestRunner sys.stdout verbosity 2 else runner BasicTestRunner result runner.run suite if not result.wasSuccessful if len result.errors 1 and not result.failures err result.errors[0][1]elif len result.failures 1 and not result.errors err result.failures[0][1]else err 'errorsoccurred;runinverbosemodefordetails'raise TestFailed err
def method2format output _format 'png' mx None raw None try import pydotexcept ImportError error 'modulepydotnotfound' buff 'digraph{\n'buff + 'graph[rankdir TB]\n'buff + 'node[shape plaintext]\n'if raw data rawelse data method2dot mx buff + 'subgraphcluster_' + hashlib.md5 output .hexdigest + '{\nlabel "%s"\n' % data['name'] buff + data['nodes']buff + '}\n'buff + data['edges']buff + '}\n'd pydot.graph_from_dot_data buff if d getattr d 'write_' + _format.lower output
def _process_priv_part perms _tmp {}previous Nonefor perm in perms if previous is None _tmp[_PRIVILEGES_MAP[perm]] Falseprevious _PRIVILEGES_MAP[perm]elif perm '*' _tmp[previous] Trueelse _tmp[_PRIVILEGES_MAP[perm]] Falseprevious _PRIVILEGES_MAP[perm]return _tmp
def snakify name sep '_' name re.sub ' [A-Z]+ [A-Z][a-z] ' '\\1%s\\2' % sep name name re.sub ' [a-z\\d] [A-Z] ' '\\1%s\\2' % sep name return name.lower
def splitA fitnesses obj median_ median fitnesses itemgetter obj best_a worst_a [] [] best_b worst_b [] [] for fit in fitnesses if fit[obj] > median_ best_a.append fit best_b.append fit elif fit[obj] < median_ worst_a.append fit worst_b.append fit else best_a.append fit worst_b.append fit balance_a abs len best_a - len worst_a balance_b abs len best_b - len worst_b if balance_a < balance_b return best_a worst_a else return best_b worst_b
def update_versions consumer resource_versions _get_cached_tracker .update_versions consumer resource_versions
def import_classes name currmodule target Noneif currmodule target try_import currmodule + '.' + name if target is None target try_import name if target is None raise InheritanceException 'Couldnotimportclassormodule%rspecifiedforinheritancediagram' % name if inspect.isclass target return [target]elif inspect.ismodule target classes []for cls in target.__dict__.values if inspect.isclass cls and cls.__module__ target.__name__ classes.append cls return classesraise InheritanceException '%rspecifiedforinheritancediagramisnotaclassormodule' % name
def test_transformer_iterator test_path os.path.join pylearn2.__path__[0] 'datasets' 'tests' 'test.csv' raw CSVDataset path test_path expect_headers False block Block dataset TransformerDataset raw block iterator dataset.iterator 'shuffled_sequential' 3 try iter iterator except TypeError assert False "TransformerIteratorisn'titerable"
def getBeginXMLOutput output cStringIO.StringIO output.write "<?xmlversion '1.0'?>\n" return output
def alloc_timedelta_result builder name 'ret' ret cgutils.alloca_once builder TIMEDELTA64 name name builder.store NAT ret return ret
def _from_path path if not path.startswith 's3 //' raise ValueError 'BadS3path%s' % path r path[len 's3 //' ].split '/' 1 bucket key Noneif len r 2 bucket key r[0] r[1] else bucket r[0]if not bucket raise ValueError 'BadS3path%s' % path return bucket key
def retry_flaky run_test_factory None if run_test_factory is None run_test_factory testtools.RunTestreturn partial _RetryFlaky run_test_factory
def bsd_jail_id pid ps_output call GET_BSD_JAIL_ID_PS % pid [] if len ps_output 2 and len ps_output[1].split 1 jid ps_output[1].strip if jid.isdigit return int jid os_name platform.system if os_name 'FreeBSD' log.warn 'Unabletogetthejailidforprocess%s.' % pid else log.debug 'bsd_jail_id %s jailidsdonotexiston%s' % pid os_name return 0
def test_read_col_starts table '\n#59171828\n#|||||\nJohn555-1234192.168.1.10\nMary555-2134192.168.1.12\nBob555-4527192.168.1.9\n'dat ascii.read table Reader ascii.FixedWidthNoHeader names 'Name' 'Phone' 'TCP' col_starts 0 9 18 col_ends 5 17 28 assert_equal tuple dat.dtype.names 'Name' 'Phone' 'TCP' assert_equal dat[0][1] '555-1234' assert_equal dat[1][0] 'Mary' assert_equal dat[1][2] '192.168.1.' assert_equal dat[2][2] '192.168.1'
def _generate_seed x SystemRandom .randint 0 32 ** 16 - 1 h hex x .strip 'L' [2 ]if len h % 2 h '0' + h return h
def flat_unique ls return list unique chain.from_iterable ls key id
def _remove_discussion_tab course user_id course.tabs [tab for tab in course.tabs if not tab.type 'discussion' ]modulestore .update_item course user_id
def unslug s m _UNSLUG_RE.match s if not m return None None return m.group 1 int m.group 2
def get_page_size_args page_sizes {}for arg in request.args re_match re.findall 'psize_ .* ' arg if re_match page_sizes[re_match[0]] int request.args.get arg return page_sizes
def negotiate_websocket_version uri_opener websocket_url for version in {13 12 14} upgrade_request build_ws_upgrade_request websocket_url web_socket_version version try upgrade_response uri_opener.send_mutant upgrade_request except HTTPRequestException continueupgrade_code upgrade_response.get_code if upgrade_code in {101} return versionelif upgrade_code in {400} headers upgrade_response.get_headers version _ headers.iget 'Sec-WebSocket-Version' None if version is None continuereturn versionelse continuereturn DEFAULT_PROTOCOL_VERSION
def pressure_network_jacobian flow_rates Qtot k n len flow_rates pdiff np.diag flow_rates[1 ] * 2 * k[1 ] - 2 * flow_rates[0] * k[0] jac np.empty n n jac[ n - 1 n - 1 ] pdiff * 0 jac[ n - 1 n - 1 ] 0jac[ n - 1 ] np.ones n return jac
def obtain_vendor_model show_ver match re.search 'Cisco .+? .+bytesofmemory' show_ver if match return 'Cisco' match.group 1 else return None None
def test_gmail_missing_spam constants monkeypatch folder_base [ '\\HasNoChildren' '/' u'INBOX' '\\Noselect' '\\HasChildren' '/' u'[Gmail]' '\\HasNoChildren' '\\All' '/' u'[Gmail]/AllMail' '\\HasNoChildren' '\\Drafts' '/' u'[Gmail]/Drafts' '\\HasNoChildren' '\\Important' '/' u'[Gmail]/Important' '\\HasNoChildren' '\\Sent' '/' u'[Gmail]/SentMail' '\\Flagged' '\\HasNoChildren' '/' u'[Gmail]/Starred' '\\HasNoChildren' '\\Trash' '/' u'[Gmail]/Trash' '\\HasNoChildren' '/' u'reference' ]check_missing_generic 'spam' folder_base localized_folder_names['spam'] 'gmail' constants monkeypatch
def _get_ico_map fro to nearest dists _compute_nearest fro['rr'] to['rr'] return_dists True n_bads dists > 0.005 .sum if n_bads > 0 raise RuntimeError 'Nomatchingvertexfor%ddestinationvertices' % n_bads return nearest
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def build_swarm status 'Buildingswarm...' cwd getcwd scripts join cwd 'scripts' try tempdir mkdtemp if download_file 'https //github.com/torognes/swarm/archive/1.2.19.tar.gz' tempdir 'swarm-1.2.19.tar.gz' status 'Couldnotdownloadswarm socannotinstallit.\n' returnchdir tempdir if not system_call 'tarxzfswarm-1.2.19.tar.gz' 'extractswarmarchive' returnchdir 'swarm-1.2.19' if not system_call 'make' 'buildswarm' returncopy 'swarm' scripts copy 'scripts/amplicon_contingency_table.py' scripts copy 'scripts/swarm_breaker.py' scripts status 'swarmbuilt.\n' finally rmtree tempdir chdir cwd
def lpol_fima d n 20 from scipy.special import gammalnj np.arange n return np.exp gammaln d + j - gammaln j + 1 - gammaln d
def hashPassword password digestMod hashlib.sha512 iterations 10000 saltSize 32 digestname iterations salt hash hashPasswordTuple password digestMod iterations saltSize return Delimiter.join [digestname str iterations base64.b64encode salt .decode u'ascii' base64.b64encode hash .decode u'ascii' ]
def getdefaulttimeout if _GLOBAL_TIMEOUT_VALUE < 0.0 return Nonereturn _GLOBAL_TIMEOUT_VALUE
def get_thread_pool lock_name size 1024 @memoize lock_name def _get_thread_pool return wsgi.get_asynchronous_eventlet_pool size size return _get_thread_pool
def trivial_graph create_using None G empty_graph 1 create_using G.name 'trivial_graph 'return G
def is_terminal item return hasattr item u'__hash__' and not isinstance item Nonterminal
def p_relational_expression_2 t pass
def paginator_number cl i if i DOT return u'...'elif i cl.page_num return mark_safe u'<spanclass "this-page">%d</span>' % i + 1 else return mark_safe u'<ahref "%s"%s>%d</a>' % escape cl.get_query_string {PAGE_VAR i} i cl.paginator.num_pages - 1 and 'class "end"' or '' i + 1
def CheckInvalidIncrement filename clean_lines linenum error line clean_lines.elided[linenum]if _RE_PATTERN_INVALID_INCREMENT.match line error filename linenum 'runtime/invalid_increment' 5 'Changingpointerinsteadofvalue orunusedvalueofoperator* .'
def searchFileFor file name try fp open file except return Nonetry lines fp.readlines finally fp.close for line in lines idx line.find '#' if idx ! -1 line line[ idx]if not line continueparts line.split if name.lower in [s.lower for s in parts[1 ]] return parts[0]return None
def config_from_prefix prefix settings {}if prefix.lower in 'default' 'auto' '' settings['zmq_prefix'] ''settings['libzmq_extension'] Falsesettings['no_libzmq_extension'] Falseelif prefix.lower in 'bundled' 'extension' settings['zmq_prefix'] ''settings['libzmq_extension'] Truesettings['no_libzmq_extension'] Falseelse settings['zmq_prefix'] prefixsettings['libzmq_extension'] Falsesettings['no_libzmq_extension'] Truesettings['allow_legacy_libzmq'] Truereturn settings
def regex_from_ec2_regex ec2_re iter_ec2_re iter ec2_re py_re ''for char in iter_ec2_re if char '*' py_re + '.*'elif char '?' py_re + '.'elif char '\\' try next_char next iter_ec2_re except StopIteration next_char ''if next_char '*' or next_char '?' py_re + '[%s]' % next_char else py_re + '\\\\' + next_char else py_re + re.escape char return '\\A%s\\Z ?s ' % py_re
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def background func def internal *a **kw data ctx _context[currentThread ]_context[currentThread ] storage ctx.copy def newfunc _context[currentThread ] ctxfunc *a **kw t threading.Thread target newfunc background.threaddb[id t ] tt.start ctx.headers []return seeother changequery _t id t return internal
def unmount mountpoint cmd 'hdiutildetach"{0}"'.format mountpoint return __salt__['cmd.run'] cmd
def restorecon path recursive False if recursive cmd ['restorecon' '-FR' path]else cmd ['restorecon' '-F' path]return not __salt__['cmd.retcode'] cmd python_shell False
def delete_zone zone region None key None keyid None profile None if region is None region 'universal'conn _get_conn region region key key keyid keyid profile profile _zone conn.get_zone zone if _zone conn.delete_hosted_zone _zone.id return Truereturn False
def check_requires_python requires_python if requires_python is None return Truerequires_python_specifier specifiers.SpecifierSet requires_python python_version version.parse '.'.join map str sys.version_info[ 3] return python_version in requires_python_specifier
def create_mode request course_id PARAMETERS {'mode_slug' u'honor' 'mode_display_name' u'HonorCodeCertificate' 'min_price' 0 'suggested_prices' u'' 'currency' u'usd'}for parameter default in PARAMETERS.iteritems PARAMETERS[parameter] request.GET.get parameter default course_key CourseKey.from_string course_id CourseMode.objects.get_or_create course_id course_key **PARAMETERS return HttpResponse "Mode'{mode_slug}'createdfor'{course}'.".format mode_slug PARAMETERS['mode_slug'] course course_id
def is_buggy_ua agent return 'HumbugDesktop/' in agent or 'ZulipDesktop/' in agent or 'ZulipDesktop/' in agent and 'Mac' not in agent
def _check_editable_fields cc_content data context _check_fields get_editable_fields cc_content context data 'Thisfieldisnoteditable.'
def decodeIntToUnicode value retVal valueif isinstance value int try if value > 255 _ '%x' % value if len _ % 2 1 _ '0%s' % _ retVal getUnicode hexdecode _ encoding 'UTF-16' if Backend.isDbms DBMS.MSSQL else None else retVal getUnicode chr value except retVal INFERENCE_UNKNOWN_CHARreturn retVal
def prde_spde a b Q n DE R Z list zip *[gcdex_diophantine b a qi for qi in Q] A aB b + derivation a DE Qq [ zi - derivation ri DE for ri zi in zip R Z ]R list R n1 n - a.degree DE.t return A B Qq R n1
def encode_if_py2 func if not PY2 return funcdef wrapped *args **kwargs ret func *args **kwargs if not isinstance ret unicode raise TypeError 'Wrappedfunctionmustreturn`unicode`' return ret.encode 'utf-8' 'ignore' return wrapped
def ssh_version ret subprocess.Popen ['ssh' '-V'] stdout subprocess.PIPE stderr subprocess.PIPE .communicate try version_parts ret[1].split ' ' [0].split '_' [1]parts []for part in version_parts try parts.append int part except ValueError return tuple parts return tuple parts except IndexError return 2 0
def snmp_extract snmp_data if len snmp_data > 1 raise ValueError 'snmp_extractonlyallowsasingleelement' if len snmp_data 0 return Noneelse return snmp_data[0][1].prettyPrint
def getUsage api_key None api_version None ret {'res' True}if not api_key or not api_version try options __salt__['config.option'] 'random_org' if not api_key api_key options.get 'api_key' if not api_version api_version options.get 'api_version' except NameError KeyError AttributeError log.error 'NoRandom.orgapikeyfound.' ret['message'] 'NoRandom.orgapikeyorapiversionfound.'ret['res'] Falsereturn retif isinstance api_version int api_version str api_version _function RANDOM_ORG_FUNCTIONS.get api_version .get 'getUsage' .get 'method' data {}data['id'] 1911220data['jsonrpc'] '2.0'data['method'] _functiondata['params'] {'apiKey' api_key}result _query api_version api_version data data if result ret['bitsLeft'] result.get 'bitsLeft' ret['requestsLeft'] result.get 'requestsLeft' ret['totalBits'] result.get 'totalBits' ret['totalRequests'] result.get 'totalRequests' else ret['res'] Falseret['message'] result['message']return ret
def _have_soundcard global __have_soundcard_cacheif __have_soundcard_cache is None cscript_path _get_cscript_path if cscript_path is None return Truecheck_script os.path.join os.path.dirname __file__ 'check_soundcard.vbs' p subprocess.Popen [cscript_path check_script] stdout subprocess.PIPE __have_soundcard_cache not p.wait p.stdout.close return __have_soundcard_cache
def pass_obj f def new_func *args **kwargs return f get_current_context .obj *args **kwargs return update_wrapper new_func f
def get_cached_content location return CONTENT_CACHE.get unicode location .encode 'utf-8' version STATIC_CONTENT_VERSION
def cookie_is_encoded data return bool data.startswith tob '!' and tob '?' in data
def count_to count numbers ['one' 'two' 'three' 'four' 'five']for pos number in zip range count numbers yield number
def p_direct_abstract_declarator_5 t pass
def circmean samples high 2 * pi low 0 axis None samples ang _circfuncs_common samples high low S sin ang .sum axis axis C cos ang .sum axis axis res arctan2 S C mask res < 0 if mask.ndim > 0 res[mask] + 2 * pi elif mask res + 2 * pi return res * high - low / 2.0 / pi + low
def floating_ip_allocate_address context project_id pool auto_assigned False return IMPL.floating_ip_allocate_address context project_id pool auto_assigned
def test_even_sequences rng np.random.RandomState 123 lengths rng.randint 1 10 100 data [ ['w'] * l for l in lengths]batch_size 5my_iter EvenSequencesSubsetIterator data batch_size visited [False] * len data for ind_list in my_iter assert [ len data[i] len data[ind_list[0]] for i in ind_list]for i in ind_list visited[i] Trueassert all visited
def _AddEnumValues descriptor cls for enum_type in descriptor.enum_types setattr cls enum_type.name enum_type_wrapper.EnumTypeWrapper enum_type for enum_value in enum_type.values setattr cls enum_value.name enum_value.number
def getNewDerivation elementNode return GridDerivation elementNode
def check_initializers initializers keys if initializers is None return {}keys set keys if not issubclass type initializers dict raise TypeError "Adictofinitializerswasexpected butnotgiven.Youshoulddouble-checkthatyou'venestedtheinitializersforanysub-modulescorrectly." if not set initializers < keys extra_keys set initializers - keys raise KeyError 'Invalidinitializerkeys{} initializerscanonlybeprovidedfor{}'.format ' '.join "'{}'".format key for key in extra_keys ' '.join "'{}'".format key for key in keys def check_nested_callables dictionary for key entry in dictionary.iteritems if isinstance entry dict check_nested_callables entry elif not callable entry raise TypeError "Initializerfor'{}'isnotacallablefunctionordictionary".format key check_nested_callables initializers return dict initializers
@decoratordef rollback_open_connections fn *args **kw try fn *args **kw finally testing_reaper.rollback_all
def enable name **kwargs cmd '/usr/sbin/svcadmenable{0}'.format name return not __salt__['cmd.retcode'] cmd python_shell False
def test_completion_for_unknown_shell script error_msg 'nosuchoption --myfooshell'result script.pip 'completion' '--myfooshell' expect_error True assert error_msg in result.stderr 'testsforanunknownshellfailed'
def require_aggregate_exists f @functools.wraps f def wrapper context aggregate_id *args **kwargs aggregate_get context aggregate_id return f context aggregate_id *args **kwargs return wrapper
def newDerSetOf *der_objs der DerSetOf for obj in der_objs if isinstance obj DerObject der.add obj.encode else der.add obj return der
def _flatten_to_ascii txt if isinstance txt str txt txt.decode 'utf-8' return unicodedata.normalize 'NFKD' txt .encode 'ASCII' 'ignore' else return unicode unicodedata.normalize 'NFKD' txt .encode 'ASCII' 'ignore'
def dirsWavFeatureExtraction dirNames mtWin mtStep stWin stStep computeBEAT False features []classNames []fileNames []for i d in enumerate dirNames [f fn] dirWavFeatureExtraction d mtWin mtStep stWin stStep computeBEAT computeBEAT if f.shape[0] > 0 features.append f fileNames.append fn if d[ -1 ] '/' classNames.append d.split os.sep [ -2 ] else classNames.append d.split os.sep [ -1 ] return features classNames fileNames
def rep_expectation expr **options if not 'index' in options options['index'] 1if not isinstance expr Operator raise TypeError 'Thepassedexpressionisnotanoperator' basis_state get_basis expr **options if basis_state is None or not isinstance basis_state StateBase raise NotImplementedError 'Couldnotgetbasisketsforthisoperator' basis_kets enumerate_states basis_state options['index'] 2 bra basis_kets[1].dualket basis_kets[0]return qapply bra * expr * ket
def restart_local drain False if _TRAFFICCTL cmd _traffic_ctl 'server' 'restart' '--manager' else cmd _traffic_line '-L' if drain cmd '{0}{1}'.format cmd '--drain' log.debug 'Running %s' cmd return _subprocess cmd
def decrypt_hash_vista edata nlkm ch aes AES.new nlkm[16 32] AES.MODE_CBC ch out ''for i in range 0 len edata 16 buf edata[i i + 16 ]if len buf < 16 buf + 16 - len buf * '\x00' out + aes.decrypt buf return out
def do_fake_registration zone Zone name 'TheDangerZone' description 'Welcometoit.' zone.save device Device.get_own_device device_zone DeviceZone device device zone zone device_zone.save
def compute_file_sha f start_ofs 0 end_ofs 0 buffer_size 1 << 16 sha sha1 f.seek 0 SEEK_END length f.tell if end_ofs < 0 and length + end_ofs < start_ofs or end_ofs > length raise AssertionError 'Attempttoreadbeyondfilelength.start_ofs %d end_ofs %d filelength %d' % start_ofs end_ofs length todo length + end_ofs - start_ofs f.seek start_ofs while todo data f.read min todo buffer_size sha.update data todo - len data return sha
def can_access_self_blocks requesting_user course_key return requesting_user.id and CourseEnrollment.is_enrolled requesting_user course_key or has_access requesting_user CourseStaffRole.ROLE course_key
def dijkstra_path_length G source target weight 'weight' if source target return 0weight _weight_function G weight length _dijkstra G source weight target target try return length[target]except KeyError raise nx.NetworkXNoPath 'Node%snotreachablefrom%s' % target source
def get_sympy_dir global sys_case_insensitivethis_file os.path.abspath __file__ sympy_dir os.path.join os.path.dirname this_file '..' '..' sympy_dir os.path.normpath sympy_dir sys_case_insensitive os.path.isdir sympy_dir and os.path.isdir sympy_dir.lower and os.path.isdir sympy_dir.upper return sys_normcase sympy_dir
def fake_payment db participant team timestamp amount payday direction return insert_fake_data db 'payments' timestamp timestamp participant participant team team amount amount payday payday direction direction
def delete_containers containers container_client object_client for cont in containers try params {'limit' 9999 'format' 'json'} resp objlist container_client.list_container_contents cont params for obj in objlist test_utils.call_and_ignore_notfound_exc object_client.delete_object cont obj['name'] time.sleep 2 container_client.delete_container cont except lib_exc.NotFound pass
def module_modified_time module module asmodule module name module.__name__module_filename module.__file__provider pkg_resources.get_provider name if provider.loader m_time os.stat provider.loader.archive [stat.ST_MTIME]else basename os.path.basename module_filename path pkg_resources.resource_filename name basename m_time os.stat path [stat.ST_MTIME]return module_filename m_time
def decorator_from_middleware middleware_class return make_middleware_decorator middleware_class
def mergedefaults d1 d2 for k in d2 if k in d1 and isinstance d1[k] dict and isinstance d2[k] dict mergedefaults d1[k] d2[k] else d1.setdefault k d2[k]
def GetPhraseQueryNodeText node text GetQueryNodeText node if text if text[0] '"' and text[ -1 ] '"' text text[1 -1 ]return text
def merge_sorted *seqs **kwargs key kwargs.get 'key' None if key is None return heapq.merge *seqs else return _merge_sorted_key seqs key
def get_discussion_id_map_entry xblock return xblock.discussion_id {'location' xblock.location 'title' xblock.discussion_category.split '/' [ -1 ].strip + '/' + xblock.discussion_target }
def auth_audit_exempt action @functools.wraps action def wrapper context data_dict return action context data_dict wrapper.auth_audit_exempt Truereturn wrapper
def import_required mod_name error_msg try return import_module mod_name except ImportError raise RuntimeError error_msg
def GetResourceLimits logging_context error_fh sys.stderr resource_limits DEFAULT_RESOURCE_LIMITS.copy StatusUpdate 'Gettingcurrentresourcelimits.' error_fh resource_limits.update _GetRemoteResourceLimits logging_context logging.debug 'Usingresourcelimits %s' resource_limits return resource_limits
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def sdm_mul_term f term O K X c termif not f or not c return []elif K.is_one c return [ sdm_monomial_mul f_M X f_c for f_M f_c in f]else return [ sdm_monomial_mul f_M X f_c * c for f_M f_c in f]
def test_can_parse_regular_step_followed_by_tabular_step steps Step.many_from_lines I_LIKE_VEGETABLES.splitlines + I_HAVE_TASTY_BEVERAGES.splitlines assert_equals len steps 2 assert isinstance steps[0] Step assert isinstance steps[1] Step assert_equals steps[0].sentence I_LIKE_VEGETABLES assert_equals steps[1].sentence string.split I_HAVE_TASTY_BEVERAGES '\n' [0]
def decompress data results []while data decomp BZ2Decompressor try res decomp.decompress data except OSError if results breakelse raiseresults.append res if not decomp.eof raise ValueError 'Compresseddataendedbeforetheend-of-streammarkerwasreached' data decomp.unused_datareturn ''.join results
def arp_ip opcode src_mac src_ip dst_mac dst_ip return arp ARP_HW_TYPE_ETHERNET ether.ETH_TYPE_IP 6 4 opcode src_mac src_ip dst_mac dst_ip
@decorators.which_bin ['lsblk' 'df'] def fstype device if salt.utils.which 'lsblk' lsblk_out __salt__['cmd.run'] 'lsblk-ofstype{0}'.format device .splitlines if len lsblk_out > 1 fs_type lsblk_out[1].strip if fs_type return fs_typeif salt.utils.which 'df' df_out __salt__['cmd.run'] 'df-T{0}'.format device .splitlines if len df_out > 1 fs_type df_out[1]if fs_type return fs_typereturn ''
def enable_quota_volume name cmd 'volumequota{0}enable'.format name if not _gluster cmd return Falsereturn True
def get_remote_events ret salt.utils.mac_utils.execute_return_result 'systemsetup-getremoteappleevents' enabled salt.utils.mac_utils.validate_enabled salt.utils.mac_utils.parse_return ret return enabled 'on'
def CoefDetermination ys res return 1 - Var res / Var ys
def progress cls_name stats duration time.time - stats['t0'] s '%20sclassifier DCTB ' % cls_name s + '% n_train 6dtraindocs % n_train_pos 6dpositive ' % stats s + '% n_test 6dtestdocs % n_test_pos 6dpositive ' % test_stats s + 'accuracy % accuracy .3f' % stats s + 'in%.2fs %5ddocs/s ' % duration stats['n_train'] / duration return s
def quota_destroy_by_project context project_id return IMPL.quota_destroy_by_project context project_id
def _strip_af h base orbits transversals j base_len len base for i in range j + 1 base_len beta h[base[i]]if beta base[i] continueif beta not in orbits[i] return h i + 1 u transversals[i][beta]if h u return False base_len + 1 h _af_rmul _af_invert u h return h base_len + 1
def _expected_output_args f inspect.currentframe .f_back.f_backi f.f_lasti + 3 bytecode f.f_code.co_codeinstruction ordornot bytecode[i] while True if instruction dis.opmap['DUP_TOP'] if ordornot bytecode[ i + 1 ] dis.opmap['UNPACK_SEQUENCE'] return ordornot bytecode[ i + 2 ] i + 4instruction ordornot bytecode[i] continueif instruction dis.opmap['STORE_NAME'] return 1if instruction dis.opmap['UNPACK_SEQUENCE'] return ordornot bytecode[ i + 1 ] if instruction dis.opmap.get 'UNPACK_EX' -1 return ordornot bytecode[ i + 1 ] + ordornot bytecode[ i + 2 ] + 0.1 return 0
def systemInformationType8 a L2PseudoLength l2pLength 1 b TpPd pd 6 c MessageType mesType 24 d Si8RestOctets packet a / b / c / d return packet
def sms phone_number msg provider None if provider is None assert _voice is not None 'YoumustlogintoGoogleVoiceusinggoogle_voice_loginbeforesendingansmswithouttheproviderparameter.'if provider is not None assert _smtp is not None 'YoumustlogintoanSMTPserverusinggmail_loginorbypassingansmtplib.SMTPinstanceviathesmtpparameterbeforesendingansmswiththeproviderparameter.'if provider is None _google_voice_sms phone_number msg else to '%s@%s' % phone_number providers.get provider provider _send_email '' to 'To %s\r\n\r\n%s' % to msg
def create_exponential_delay_function base growth_factor return functools.partial delay_exponential base base growth_factor growth_factor
def is_ip_filter ip options None return is_ipv4_filter ip options options or is_ipv6_filter ip options options
def iter_notes self offset self['p_offset']end self['p_offset'] + self['p_filesz'] while offset < end note struct_parse self.elffile.structs.Elf_Nhdr self.stream stream_pos offset note['n_offset'] offsetoffset + self.elffile.structs.Elf_Nhdr.sizeof self.stream.seek offset disk_namesz roundup note['n_namesz'] 2 note['n_name'] bytes2str CString '' .parse self.stream.read disk_namesz offset + disk_nameszdesc_data bytes2str self.stream.read note['n_descsz'] note['n_desc'] desc_dataoffset + roundup note['n_descsz'] 2 note['n_size'] offset - note['n_offset'] yield note
def skipIfPy3 message from unittest import skipIffrom .platform import is_py3return skipIf is_py3 message
def attach_user_story_extra_info queryset as_field 'user_story_extra_info' model queryset.modelsql 'SELECTrow_to_json u \nFROM SELECT"userstories_userstory"."id"AS"id" \n"userstories_userstory"."ref"AS"ref" \n"userstories_userstory"."subject"AS"subject" \n SELECTjson_agg row_to_json t \nFROM SELECT"epics_epic"."id"AS"id" \n"epics_epic"."ref"AS"ref" \n"epics_epic"."subject"AS"subject" \n"epics_epic"."color"AS"color" \n SELECTrow_to_json p \nFROM SELECT"projects_project"."id"AS"id" \n"projects_project"."name"AS"name" \n"projects_project"."slug"AS"slug"\n p\n AS"project"\nFROM"epics_relateduserstory"\nINNERJOIN"epics_epic"\nON"epics_epic"."id" "epics_relateduserstory"."epic_id"\nINNERJOIN"projects_project"\nON"projects_project"."id" "epics_epic"."project_id"\nWHERE"epics_relateduserstory"."user_story_id" "{tbl}"."user_story_id"\nORDERBY"projects_project"."name" "epics_epic"."ref" t AS"epics"\nFROM"userstories_userstory"\nWHERE"userstories_userstory"."id" "{tbl}"."user_story_id" u'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def update_version_and_revision font version_number roboto_data.get_version_number version_record 'Version%s;%d' % version_number date.today .year font_data.set_name_record font 5 version_record font['head'].fontRevision float version_number
@partial.partialdef login_analytics strategy auth_entry *args **kwargs event_name Noneif auth_entry AUTH_ENTRY_LOGIN event_name 'edx.bi.user.account.authenticated'elif auth_entry in [AUTH_ENTRY_ACCOUNT_SETTINGS] event_name 'edx.bi.user.account.linked'if event_name is not None and hasattr settings 'LMS_SEGMENT_KEY' and settings.LMS_SEGMENT_KEY tracking_context tracker.get_tracker .resolve_context analytics.track kwargs['user'].id event_name {'category' 'conversion' 'label' None 'provider' kwargs['backend'].name} context {'ip' tracking_context.get 'ip' 'GoogleAnalytics' {'clientId' tracking_context.get 'client_id' }}
def cipheringModeComplete MobileId_presence 0 a TpPd pd 6 b MessageType mesType 50 packet a / b if MobileId_presence is 1 c MobileIdHdr ieiMI 23 eightBitMI 0 packet packet / c return packet
def in6_islladdr str return in6_isincluded str 'fe80 ' 10
def nameScore name year preferred_words try score 0name name.lower for value in name_scores v value.split ' ' add int v.pop if v.pop in name score + addif str year in name score + 5nzb_words re.split '\\W+' simplifyString name score + 100 * len list set nzb_words & set preferred_words return scoreexcept log.error 'FaileddoingnameScore %s' traceback.format_exc return 0
def get_messaging_urls if CONF.messaging.cluster_urls return CONF.messaging.cluster_urlsreturn [CONF.messaging.url]
def _shouldRelocateCommand cmd return cmd in _RELOCATABLE
def click_and_wait_for_page_load context elem wait_time MAX_PAGE_LOAD_TIME wait_elem context.browser.find_element_by_tag_name 'body' elem.click return WebDriverWait context.browser wait_time .until EC.staleness_of wait_elem
def snapshot_name_to_id name snap_name strict False runas None name _sdecode name snap_name _sdecode snap_name info prlctl 'snapshot-list' name runas runas snap_ids _find_guids info named_ids []for snap_id in snap_ids if snapshot_id_to_name name snap_id runas runas snap_name named_ids.append snap_id if len named_ids 0 raise SaltInvocationError u'NosnapshotsforVM"{0}"havename"{1}"'.format name snap_name elif len named_ids 1 return named_ids[0]else multi_msg u'MultiplesnapshotsforVM"{0}"havename"{1}"'.format name snap_name if strict raise SaltInvocationError multi_msg else log.warning multi_msg return named_ids
def echo data '' return data
def prioritize while True hp_qs Message.objects.high_priority .using u'default' mp_qs Message.objects.medium_priority .using u'default' lp_qs Message.objects.low_priority .using u'default' while hp_qs.count or mp_qs.count while hp_qs.count for message in hp_qs.order_by u'when_added' yield message while hp_qs.count 0 and mp_qs.count yield mp_qs.order_by u'when_added' [0] while hp_qs.count 0 and mp_qs.count 0 and lp_qs.count yield lp_qs.order_by u'when_added' [0] if Message.objects.non_deferred .using u'default' .count 0 break
def _accessible_courses_list request def course_filter course '\nFilteroutunusableandinaccessiblecourses\n'if isinstance course ErrorDescriptor return Falseif isinstance course.id CCXLocator return Falseif course.location.course 'templates' return Falsereturn has_studio_read_access request.user course.id courses filter course_filter modulestore .get_courses in_process_course_actions get_in_process_course_actions request return courses in_process_course_actions
def theano_simplify fgraph mode theano.compile.get_default_mode .excluding 'fusion' fgraph fgraph.clone mode.optimizer.optimize fgraph return fgraph
def hash_ldap_user_password user try password user['password']except KeyError return userelse return dict user password ldap_hash_password password
def StoreEntity entity clone entity_pb.EntityProto clone.CopyFrom entity PrepareSpecialPropertiesForStore clone return clone
def _keys_equal x y return x.lower y.lower
@requires_application def test_use_textures assert_raises ValueError Texture2D np.zeros 2 2 3 np.float32 format 'rgba'
def write_packet sock data already_pickled False if already_pickled sent_data dataelse sent_data pickle.dumps data PICKLE_HIGHEST_PROTOCOL sent_data struct.pack 'l' len sent_data + sent_data nsend len sent_data while nsend > 0 nsend - temp_fail_retry socket.error sock.send sent_data
def _cinder_execute *args **kargs cmd args[1 -3 ] if args[0] 'raidcom' else args ret stdout stderr EXECUTE_TABLE.get cmd CMD_SUCCEED if ret SUCCEED return stdout stderr else pee processutils.ProcessExecutionError exit_code ret stdout stdout stderr stderr raise pee
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def listens_for target identifier *args **kw def decorate fn listen target identifier fn *args **kw return fnreturn decorate
def feed2fields file import feedparserd feedparser.parse file for entry in d.entries date time.strftime u'%Y-%m-%d%H %M' entry.updated_parsed if hasattr entry u'updated_parsed' else None author entry.author if hasattr entry u'author' else None tags [e[u'term'] for e in entry.tags] if hasattr entry u'tags' else None slug slugify entry.title kind u'article' yield entry.title entry.description slug date author [] tags None kind u'html'
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def conda_creator env_name pkgs subprocess.call 'condacreate--yes-n%s%s' % env_name pkgs shell True
def test_bootstrap_options_no_config_only_sentry_options settings settings.SENTRY_OPTIONS {'system.secret-key' 'my-system-secret-key' 'mail.backend' 'my-mail-backend' 'mail.host' 'my-mail-host' 'mail.port' 123 'mail.username' 'my-mail-username' 'mail.password' 'my-mail-password' 'mail.use-tls' True 'mail.from' 'my-mail-from' 'mail.subject-prefix' 'my-mail-subject-prefix'}bootstrap_options settings assert settings.SECRET_KEY 'my-system-secret-key' assert settings.EMAIL_BACKEND 'my-mail-backend' assert settings.EMAIL_HOST 'my-mail-host' assert settings.EMAIL_PORT 123 assert settings.EMAIL_HOST_USER 'my-mail-username' assert settings.EMAIL_HOST_PASSWORD 'my-mail-password' assert settings.EMAIL_USE_TLS is True assert settings.SERVER_EMAIL 'my-mail-from' assert settings.EMAIL_SUBJECT_PREFIX 'my-mail-subject-prefix'
def _logistic_loss w X y alpha sample_weight None w c yz _intercept_dot w X y if sample_weight is None sample_weight np.ones y.shape[0] out - np.sum sample_weight * log_logistic yz + 0.5 * alpha * np.dot w w return out
def unique values values com._asarray_tuplesafe values f lambda htype caster _unique_object values htype caster return _hashtable_algo f values
def todo message def wrap func '\njustmarkthetest\n'func.todo messagereturn funcreturn wrap
def _find_type value fmts ['FIFF_'] exclude ['FIFF_UNIT'] value int value vals [k for k v in iteritems FIFF if v value and any fmt in k for fmt in fmts and not any exc in k for exc in exclude ]if len vals 0 vals ['???']return vals
def test_classes Chart chart Chart assert chart.render_pyquery .attr 'class' 'pygal-chart' chart Chart classes assert not chart.render_pyquery .attr 'class' chart Chart classes _ellipsis assert chart.render_pyquery .attr 'class' 'pygal-chart' chart Chart classes 'graph' assert chart.render_pyquery .attr 'class' 'graph' chart Chart classes 'pygal-chart' 'graph' assert chart.render_pyquery .attr 'class' 'pygal-chartgraph' chart Chart classes _ellipsis 'graph' assert chart.render_pyquery .attr 'class' 'pygal-chartgraph' chart Chart classes 'graph' _ellipsis assert chart.render_pyquery .attr 'class' 'graphpygal-chart'
def _region_code_for_number_from_list numobj regions national_number national_significant_number numobj for region_code in regions metadata PhoneMetadata.metadata_for_region region_code.upper None if metadata is None continueif metadata.leading_digits is not None leading_digit_re re.compile metadata.leading_digits match leading_digit_re.match national_number if match return region_codeelif _number_type_helper national_number metadata ! PhoneNumberType.UNKNOWN return region_codereturn None
def plotOutputsOverTime vectors buVectors None title 'On-times' import pylabpylab.ion pylab.figure imData vectors.transpose if buVectors is not None assert buVectors.shape vectors.shape imData imData.copy imData[buVectors.transpose .astype 'bool' ] 2pylab.imshow imData aspect 'auto' cmap pylab.cm.gray_r interpolation 'nearest' pylab.title title
def _sub_space m return '' * m.end - m.start
def print_string s width 70 print '\n'.join textwrap.wrap s width width
def encoder_type encode return {'0' '' '1' 'shikata_ga_nai' '2' '' '3' 'MULTIENCODE' '4' 'BACKDOOR'}.get encode 'ERROR'
def _get_device_size device size_file FilePath '/sys/block/{}/size'.format device return int size_file.getContent * 512
def create_ngram_set input_list ngram_value 2 return set zip *[input_list[i ] for i in range ngram_value ]
def bind_values clause v []def visit_bindparam bind v.append bind.effective_value visitors.traverse clause {} {'bindparam' visit_bindparam} return v
def quopri_encode input errors 'strict' assert errors 'strict' f StringIO str input g StringIO quopri.encode f g quotetabs True output g.getvalue return output len input
def make_np_rng rng_or_seed None default_seed None which_method None return make_rng rng_or_seed default_seed which_method numpy.random.RandomState
def sinc x N y np.sin N * x / 2 / np.sin x / 2 y[np.isnan y ] Nreturn y
def get_info app env account container None swift_source None env.setdefault 'swift.infocache' {} if container path '/v1/%s/%s' % account container path_env env.copy path_env['PATH_INFO'] pathreturn get_container_info path_env app swift_source swift_source else path '/v1/%s' % account path_env env.copy path_env['PATH_INFO'] pathreturn get_account_info path_env app swift_source swift_source
def generate_alias tbl return u''.join [l for l in tbl if l.isupper ] or [l for l prev in zip tbl u'_' + tbl if prev u'_' and l ! u'_' ]
def ParseResponse response *args **kwds return _ParseFileEx response response.geturl *args **kwds [1 ]
def check_and_decode_json result response_code def error body raise ResponseError result.code body if result.code ! response_code d content result d.addCallback error return dreturn json_content result
@open_file 1 mode 'wb' def write_multiline_adjlist G path delimiter '' comments '#' encoding 'utf-8' import sysimport timepargs comments + ''.join sys.argv header '{}\n'.format pargs + comments + 'GMT{}\n'.format time.asctime time.gmtime + comments + '{}\n'.format G.name path.write header.encode encoding for multiline in generate_multiline_adjlist G delimiter multiline + '\n'path.write multiline.encode encoding
def inv_expiry_date_represent date dtstr S3DateTime.date_represent date utc True if date and datetime.datetime date.year date.month date.day < current.request.now return SPAN dtstr _class 'expired' else return dtstr
def SymmetricGroup n if n 1 G PermutationGroup [Permutation [0] ] elif n 2 G PermutationGroup [Permutation [1 0] ] else a list range 1 n a.append 0 gen1 _af_new a a list range n a[0] a[1] a[1] a[0] gen2 _af_new a G PermutationGroup [gen1 gen2] if n < 3 G._is_abelian TrueG._is_nilpotent Trueelse G._is_abelian FalseG._is_nilpotent Falseif n < 5 G._is_solvable Trueelse G._is_solvable FalseG._degree nG._is_transitive TrueG._is_sym Truereturn G
def grok_environment_error exc prefix 'error ' if hasattr exc 'filename' and hasattr exc 'strerror' if exc.filename error prefix + '%s %s' % exc.filename exc.strerror else error prefix + '%s' % exc.strerror else error prefix + str exc[ -1 ] return error
def linenumbers value from django.utils.html import escapelines value.split '\n' width str len str len lines for i line in enumerate lines lines[i] '%0' + width + 'd.%s' % i + 1 escape line return '\n'.join lines
def reducer *tokens def decorator func if not hasattr func 'reducers' func.reducers []func.reducers.append list tokens return funcreturn decorator
def DateOfLogLine line m re.compile '[^[]+\\[ \\d+/[A-Za-z]+/\\d+ [^\\d]*' .match line if not m return Nonetry return datetime.date *time.strptime m.group 1 '%d/%b/%Y' [ 3] except ValueError return None
def getCraftedText fileName text '' liftRepository None return getCraftedTextFromText archive.getTextIfEmpty fileName text liftRepository
def make_minimal_cs_thread overrides None ret {'type' 'thread' 'id' 'dummy' 'course_id' 'dummy/dummy/dummy' 'commentable_id' 'dummy' 'group_id' None 'user_id' '0' 'username' 'dummy' 'anonymous' False 'anonymous_to_peers' False 'created_at' '1970-01-01T00 00 00Z' 'updated_at' '1970-01-01T00 00 00Z' 'last_activity_at' '1970-01-01T00 00 00Z' 'thread_type' 'discussion' 'title' 'dummy' 'body' 'dummy' 'pinned' False 'closed' False 'abuse_flaggers' [] 'votes' {'up_count' 0} 'comments_count' 0 'unread_comments_count' 0 'children' [] 'read' False 'endorsed' False 'resp_total' 0}ret.update overrides or {} return ret
def group_snapshot_update context group_snapshot_id values return IMPL.group_snapshot_update context group_snapshot_id values
def sub_post e replacements []for node in preorder_traversal e if isinstance node Mul and node.args[0] is S.One and node.args[1] is S.NegativeOne replacements.append node - Mul._from_args node.args[2 ] for node replacement in replacements e e.xreplace {node replacement} return e
def get_random_job_prefix fixed_prefix '' max_job_prefix_len 10 leading_trailing_underscores True length max_job_prefix_len - len fixed_prefix if leading_trailing_underscores length - 2result [choice RANDOM_JOB_PREFIX_CHARS for i in range length ]if leading_trailing_underscores return fixed_prefix + '_' + ''.join result + '_' else return fixed_prefix + ''.join result
def check_align_percent_field d if d['%IDENTITY'] return Trueelse return False
def date_breaks width period units parse_break_str width Locator LOCATORS.get units locator Locator interval period return locator
def writeToFile data fileName global memory_fileslog.debug "Openingmemoryfile`%s'forwriting." % fileName memory_files[fileName] StringIO.StringIO data
def ServerLoggingStartupInit global LOGGERtry from grr.lib.local import log as local_loglogging.debug 'UsinglocalLogInitfrom%s' local_log local_log.LogInit logging.debug 'UsinglocalAppLogInitfrom%s' local_log LOGGER local_log.AppLogInit except ImportError LogInit LOGGER AppLogInit
def mntd distmat return masked_array distmat eye distmat.shape[0] .min 0 .mean
def _get_indent_hint_line bar_positions bad_position if not bar_positions return ''markers [ pos '|' for pos in bar_positions]markers.append bad_position '^' markers.sort line [''] * markers[ -1 ][0] + 1 for position marker in markers line[position] markerreturn ''.join line
@with_setup prepare_stdout def test_output_snippets_with_groups_within_double_quotes_colorless runner Runner feature_name 'double-quoted-snippet' verbosity 3 no_color True runner.run assert_stdout_lines u'\nFeature double-quotedsnippetproposal#tests/functional/output_features/double-quoted-snippet/double-quoted-snippet.feature 1\n\nScenario Proposematchedgroups#tests/functional/output_features/double-quoted-snippet/double-quoted-snippet.feature 2\nGivenIhave"stuffhere"and"more@#$%\u02c6&bizarsutffh3r3"#tests/functional/output_features/double-quoted-snippet/double-quoted-snippet.feature 3 undefined \n\n1feature 0passed \n1scenario 0passed \n1step 1undefined 0passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u\'GivenIhave" [^"]* "and" [^"]* "\' \ndefgiven_i_have_group1_and_group2 step group1 group2 \nassertFalse \'Thisstepmustbeimplemented\'\n'
def _num_difference obj_a obj_b attrs_a set obj_a.__dict__ attrs_b set obj_b.__dict__ diff attrs_a.symmetric_difference attrs_b privates len [x for x in diff if x.startswith '_' ] return len diff - privates
def Check test msg '' error_code datastore_pb.Error.BAD_REQUEST if not test raise apiproxy_errors.ApplicationError error_code msg
def test_read_unbounded_right_column table '\n#comment withblanklineabove \n \nCol1Col2Col3\n \n1.22Hello\n2.44Worlds\n \n'reader ascii.get_reader Reader ascii.RST dat reader.read table assert_equal dat[0][2] 'Hello' assert_equal dat[1][2] 'Worlds'
def _m_enable if HAS_UPSTART return MagicMock return_value True else return MagicMock return_value False
def _add_name_space message namespace None if namespace is None namespace namespace_manager.get_namespace if not namespace message.clear_name_space else message.set_name_space namespace
def _getSha1hexDigest thing isfile False digester hashlib.sha1 if isfile filename thingif os.path.isfile filename f open filename 'rb' digester.update f.read f.close else return Noneelse digester.update str thing return digester.hexdigest
def cast_arg t val if t 'intbool' return cast_arg bool cast_arg int val else try return t val except ValueError raise ArgumentTypeError
@register.simple_tag takes_context True def bootstrap_messages context *args **kwargs if Context and isinstance context Context context context.flatten context.update {u'message_constants' message_constants} return render_template_file u'bootstrap3/messages.html' context context
def is_path_within_dependency_dir app path allowed Falseresolved_path os.path.realpath path tool_dependency_dir app.config.get 'tool_dependency_dir' None if tool_dependency_dir dependency_path os.path.abspath tool_dependency_dir allowed os.path.commonprefix [dependency_path resolved_path] dependency_path return allowed
def test_language_french lang Language 'fr' assert_equals lang.code u'fr' assert_equals lang.name u'French' assert_equals lang.native u'Fran\xe7ais' assert_equals lang.feature u'Fonctionnalit\xe9|Fonction' assert_equals lang.scenario u'Sc\xe9nario' assert_equals lang.examples u'Exemples|Sc\xe9narios' assert_equals lang.scenario_outline u'PlandeSc\xe9nario|PlanduSc\xe9nario' assert_equals lang.scenario_separator u' PlandeSc\xe9nario|PlanduSc\xe9nario|Sc\xe9nario '
def setup_filters warnings.filterwarnings 'ignore' category sa_exc.SAPendingDeprecationWarning warnings.filterwarnings 'error' category sa_exc.SADeprecationWarning warnings.filterwarnings 'error' category sa_exc.SAWarning warnings.filterwarnings 'error' category DeprecationWarning warnings.filterwarnings 'ignore' category DeprecationWarning message '.*StopIteration' warnings.filterwarnings 'ignore' category DeprecationWarning message '.*inspect.getargspec'
def init_tparams params tparams OrderedDict for kk pp in params.iteritems tparams[kk] theano.shared params[kk] name kk return tparams
def progress_element toppath path state progress_read if toppath not in state return Falseimported state[toppath]i bisect_left imported path return i ! len imported and imported[i] path
def majority_vote labels vote_counts Counter labels winner winner_count vote_counts.most_common 1 [0]num_winners len [count for count in vote_counts.values if count winner_count ] if num_winners 1 return winnerelse return majority_vote labels[ -1 ]
def retry jenkins_session url params print 'Retrying{}'.format url if params jenkins_session.post url + '/buildWithParameters' data params else jenkins_session.post url + '/build'
def congestionControl Cause_presence 0 a TpPd pd 3 b MessageType mesType 57 c CongestionLevelAndSpareHalfOctets packet a / b / c if Cause_presence is 1 e CauseHdr ieiC 8 eightBitC 0 packet packet / e return packet
def default_handlers handlers [] return handlers + [ '/gist/ [^\\/]+/ ? [0-9]+|[0-9a-f]{20 } ' GistHandler '/gist/ [^\\/]+/ ? [0-9]+|[0-9a-f]{20 } / ? files/ ? .* ' GistHandler '/ [0-9]+|[0-9a-f]{20 } ' GistRedirectHandler '/ [0-9]+|[0-9a-f]{20 } / .* ' GistRedirectHandler '/gist/ [^\\/]+ /?' UserGistsHandler ]
def generate_randomkey length chars string.letters + string.digits return ''.join [choice chars for i in range int length ]
@register u'reverse-search-history' def reverse_search_history event event.cli.current_search_state.direction IncrementalSearchDirection.BACKWARDevent.cli.push_focus SEARCH_BUFFER
def ShowString name string try msg TRANS string except msg 'EncodingError\n'return '\n<!DOCTYPEHTMLPUBLIC"-//W3C//DTDHTML4.0//EN">\n<html>\n<head>\n<title>%s</title>\n</head>\n<body>\n<FORM><INPUTTYPE "BUTTON"VALUE "%s"ONCLICK "history.go -1 "></FORM>\n<h3>%s</h3>\n<code><pre>%s</pre></code>\n</body>\n</html>\n' % xml_name name T 'Back' xml_name name escape unicoder msg
def policy_enforce handler @six.wraps handler def handle_stack_method controller req tenant_id **kwargs if req.context.tenant_id ! tenant_id and not req.context.is_admin raise exc.HTTPForbidden allowed req.context.policy.enforce context req.context action handler.__name__ scope controller.REQUEST_SCOPE if not allowed raise exc.HTTPForbidden return handler controller req **kwargs return handle_stack_method
def parse_colon_dict data result {}key Nonefor line in data.splitlines parts [value.strip for value in line.split ' ' 1 ]if len parts 2 key val partsresult[key] valelse result.setdefault key '' result[key] + parts[0]return result
def sort_flavor_list request flavors def get_key flavor sort_key try return getattr flavor sort_key except AttributeError LOG.warning 'Couldnotfindsortkey"%s".Usingthedefault"ram"instead.' sort_key return getattr flavor 'ram' try flavor_sort getattr settings 'CREATE_INSTANCE_FLAVOR_SORT' {} sort_key flavor_sort.get 'key' 'ram' rev flavor_sort.get 'reverse' False if not callable sort_key key lambda flavor get_key flavor sort_key else key sort_keyflavor_list [ flavor.id '%s' % flavor.name for flavor in sorted flavors key key reverse rev ]return flavor_listexcept Exception exceptions.handle request _ 'Unabletosortinstanceflavors.' return []
def _log_normalize X X make_nonnegative X min_value 1 if issparse X raise ValueError 'Cannotcomputelogofasparsematrix becauselog x divergesto-infinityasxgoesto0.' L np.log X row_avg L.mean axis 1 [ np.newaxis]col_avg L.mean axis 0 avg L.mean return L - row_avg - col_avg + avg
def ContextMiddleware_filter_factory global_conf **local_conf conf global_conf.copy conf.update local_conf def filter app return ContextMiddleware app conf return filter
def profile_line img src dst linewidth 1 order 1 mode 'constant' cval 0.0 perp_lines _line_profile_coordinates src dst linewidth linewidth if img.ndim 3 pixels [ndi.map_coordinates img[... i] perp_lines order order mode mode cval cval for i in range img.shape[2] ]pixels np.transpose np.asarray pixels 1 2 0 else pixels ndi.map_coordinates img perp_lines order order mode mode cval cval intensities pixels.mean axis 1 return intensities
def getCapitalizedSuffixKey prefix suffix if prefix '' or prefix.endswith '.' return prefix + suffix return prefix + suffix[ 1].upper + suffix[1 ]
def new_figure_manager num *args **kwargs FigureClass kwargs.pop 'FigureClass' Figure thisFig FigureClass *args **kwargs canvas FigureCanvasTemplate thisFig manager FigureManagerTemplate canvas num return manager
def execle file *args env args[ -1 ]execve file args[ -1 ] env
def exec_prompt_qt bus prompt from PyQt5.QtCore import QCoreApplicationapp QCoreApplication [] result []def callback dismissed unlocked result.append dismissed result.append unlocked app.quit exec_prompt bus prompt callback app.exec_ return result[0] result[1]
def item_brand item attributes_dict attribute_values_dict brand Nonebrand_attribute_pk attributes_dict.get u'brand' publisher_attribute_pk attributes_dict.get u'publisher' if brand_attribute_pk brand item.get_attribute brand_attribute_pk if brand is None brand item.product.get_attribute brand_attribute_pk if brand is None and publisher_attribute_pk is not None brand item.get_attribute publisher_attribute_pk if brand is None brand item.product.get_attribute publisher_attribute_pk if brand is not None brand_name attribute_values_dict.get brand if brand_name is not None return brand_namereturn brand
def get_matfile_version fileobj fileobj.seek 0 mopt_bytes fileobj.read 4 if len mopt_bytes 0 raise MatReadError 'Matfileappearstobeempty' mopt_ints np.ndarray shape 4 dtype np.uint8 buffer mopt_bytes if 0 in mopt_ints fileobj.seek 0 return 0 0 fileobj.seek 124 tst_str fileobj.read 4 fileobj.seek 0 maj_ind int tst_str[2] 'I'[0] maj_val byteord tst_str[maj_ind] min_val byteord tst_str[ 1 - maj_ind ] ret maj_val min_val if maj_val in 1 2 return retraise ValueError 'Unknownmatfiletype version%s %s' % ret
def ok_mm_primer primer_seq all_primer_seqs primer_mm for curr_pat in all_primer_seqs if count_mismatches primer_seq curr_pat primer_mm < primer_mm return Truereturn False
def copula_bv_indep u v return u * v
def safe_text_dupfile f mode default_encoding 'UTF8' encoding getattr f 'encoding' None try fd f.fileno except Exception if 'b' not in getattr f 'mode' '' and hasattr f 'encoding' return felse newfd os.dup fd if 'b' not in mode mode + 'b'f os.fdopen newfd mode 0 return EncodedFile f encoding or default_encoding
def _get_ethernet pkt ether pktwhile ether is not None and not isinstance ether Ether ether ether.underlayerreturn ether
def pylong_join count digits_ptr 'digits' join_type 'unsignedlong' return ' ' * count * 2 + '|'.join ' %s %s[%d] %s ' % join_type digits_ptr _i '<<PyLong_SHIFT' if _i else '' for _i in range count - 1 -1 -1
def _have_soundcard global __have_soundcard_cacheif __have_soundcard_cache is None cscript_path _get_cscript_path if cscript_path is None return Truecheck_script os.path.join os.path.dirname __file__ 'check_soundcard.vbs' p subprocess.Popen [cscript_path check_script] stdout subprocess.PIPE __have_soundcard_cache not p.wait p.stdout.close return __have_soundcard_cache
def conn2neo bulk rec query_cache conn2neo.query_cachelinkattrs 'proto' accumulators {}if rec['proto'] 'icmp' rec['type'] rec['code'] rec.pop 'id_orig_p' rec.pop 'id_resp_p' accumulators {'codes' '{code}' None }linkattrs linkattrs + 'type' elif 'id_orig_p' in rec and 'id_resp_p' in rec rec['sport'] rec['dport'] rec.pop 'id_orig_p' rec.pop 'id_resp_p' accumulators {'sports' '{sport}' 5 }linkattrs linkattrs + 'dport' counters {'cspkts' '{orig_pkts}' 'csbytes' '{orig_ip_bytes}' 'scpkts' '{resp_pkts}' 'scbytes' '{resp_ip_bytes}'}if linkattrs not in query_cache query_cache[linkattrs] db.flow.add_flow ['Flow'] linkattrs counters counters accumulators accumulators bulk.append query_cache[linkattrs] rec
def test_input_and_target_source mlp MLP layers [CompositeLayer 'composite' [Linear 10 'h0' 0.1 Linear 10 'h1' 0.1 ] {0 [1] 1 [0]} ] input_space CompositeSpace [VectorSpace 15 VectorSpace 20 ] input_source 'features0' 'features1' target_source 'targets0' 'targets1' np.testing.assert_equal mlp.get_input_source 'features0' 'features1' np.testing.assert_equal mlp.get_target_source 'targets0' 'targets1' mlp MLP layers [Linear 10 'h0' 0.1 ] input_space VectorSpace 15 np.testing.assert_equal mlp.get_input_source 'features' np.testing.assert_equal mlp.get_target_source 'targets'
def write_info_refs refs store for name sha in sorted refs.items if name 'HEAD' continuetry o store[sha]except KeyError continuepeeled store.peel_sha sha yield o.id + ' DCTB ' + name + '\n' if o.id ! peeled.id yield peeled.id + ' DCTB ' + name + ANNOTATED_TAG_SUFFIX + '\n'
def is_datasource tool_xml return tool_xml.getroot .attrib.get 'tool_type' '' 'data_source'
def as_draft location if location.category in DIRECT_ONLY_CATEGORIES return locationreturn location.replace revision MongoRevisionKey.draft
def _check_coefficients system if isinstance system tuple from scipy.signal import tf2zpk z p k tf2zpk *system else from scipy.signal import sos2zpk z p k sos2zpk system if np.any np.abs p > 1.0 raise RuntimeError 'Filterpolesoutsideunitcircle filterwillbeunstable.Considerusingdifferentfiltercoefficients.'
def reportDeprecatedWorkerModuleUsage message stacklevel None if stacklevel is None stacklevel 3else stacklevel + 2warnings.warn DeprecatedWorkerModuleWarning message None stacklevel
def apply_natural_sort collection key None to_digit lambda i int i if i.isdigit else i def tokenize_and_convert item key None if key item item[key]return [to_digit c for c in re.split ' [0-9]+ ' item ]return sorted collection key lambda i tokenize_and_convert i key key
def check_configs configs 'auxiliary.conf' 'avd.conf' 'cuckoo.conf' 'esx.conf' 'kvm.conf' 'memory.conf' 'physical.conf' 'processing.conf' 'qemu.conf' 'reporting.conf' 'virtualbox.conf' 'vmware.conf' 'vpn.conf' 'vsphere.conf' 'xenserver.conf' for config in [os.path.join CUCKOO_ROOT 'conf' f for f in configs] if not os.path.exists config raise CuckooStartupError 'Configfiledoesnotexistatpath {0}'.format config return True
def patch_response_headers response cache_timeout None if cache_timeout is None cache_timeout settings.CACHE_MIDDLEWARE_SECONDSif cache_timeout < 0 cache_timeout 0if settings.USE_ETAGS and not response.has_header 'ETag' warnings.warn "TheUSE_ETAGSsettingisdeprecatedinfavorofConditionalGetMiddlewarewhichsetstheETagregardlessofthesetting.patch_response_headers won'tdoETagprocessinginDjango2.1." RemovedInDjango21Warning if hasattr response 'render' and callable response.render response.add_post_render_callback set_response_etag else response set_response_etag response if not response.has_header 'Expires' response['Expires'] http_date time.time + cache_timeout patch_cache_control response max_age cache_timeout
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def stream_as_text stream for data in stream if not isinstance data six.text_type data data.decode u'utf-8' u'replace' yield data
def make_tests input_dir msg_dir filter_rgx callbacks if filter_rgx is_to_run re.compile filter_rgx .searchelse is_to_run lambda x 1 tests []for module_file messages_file in get_tests_info input_dir msg_dir 'func_' '' if not is_to_run module_file or module_file.endswith '.pyc' continuebase module_file.replace 'func_' '' .replace '.py' '' dependencies get_tests_info input_dir msg_dir base '.py' for callback in callbacks test callback input_dir msg_dir module_file messages_file dependencies if test tests.append test return tests
def nested_get ind coll if isinstance ind list return tuple [nested_get i coll for i in ind] else return coll[ind]
def parse_matrix lines col_headers Noneresult []row_headers []for line in lines if line[0] '#' continueif line[0] ' DCTB ' col_headers map strip line.split ' DCTB ' [1 ] else entries line.split ' DCTB ' result.append map float entries[1 ] row_headers.append entries[0] return col_headers row_headers asarray result
def unique_id_map seqs groups invert_dict seqs result {}for v in groups.values for i in v result[i] v[0]return result
def calculate_at_hash access_token hash_alg hash_digest hash_alg access_token.encode 'utf-8' .digest cut_at int len hash_digest / 2 truncated hash_digest[ cut_at]from jwt.utils import base64url_encodeat_hash base64url_encode truncated return at_hash.decode 'utf-8'
def get_coverage_grid_extent instance instance_wcs get_wcs_record instance grid instance_wcs.gridreturn [ int h - int l + 1 for h l in zip grid.highlimits grid.lowlimits ]
def add_suffix_to_extensions toc from .datastruct import TOCnew_toc TOC for inm fnm typ in toc if typ 'EXTENSION' if os.path.splitext inm [1] not in EXTENSION_SUFFIXES inm inm + os.path.splitext fnm [1] elif typ 'DEPENDENCY' binext os.path.splitext fnm [1]if not os.path.splitext inm [1] binext inm inm + binext new_toc.append inm fnm typ return new_toc
def get_vlan_binding netid LOG.debug _ 'get_vlan_binding called' session db.get_session try binding session.query l2network_models.VlanBinding .filter_by network_id netid .one return bindingexcept exc.NoResultFound raise q_exc.NetworkNotFound net_id netid
def get_human_readable_type item if isinstance item ndarray MaskedArray return item.dtype.nameelif isinstance item Image return 'Image'else text get_type_string item if text is None text to_text_string 'unknown' else return text[ text.find '.' + 1 ]
def composite_transform_factory a b if isinstance a IdentityTransform return belif isinstance b IdentityTransform return aelif isinstance a AffineBase and isinstance b AffineBase return CompositeAffine2D a b return CompositeGenericTransform a b
def addElementToListDictionaryIfNotThere element key listDictionary if key in listDictionary elements listDictionary[key]if element not in elements elements.append element else listDictionary[key] [element]
def test_contains_nan arr np.random.random 100 assert not contains_nan arr arr[0] np.nanassert contains_nan arr
def _sort_keys_by_values p return sorted pn for pn in p if p[pn] key lambda pn p[pn]
def clean_default widget_type default if widget_type ! 'CheckBox' return default.__name__ if callable default else default return default if isinstance default bool else False
def cut_lines pre post 0 what None def process app what_ name obj options lines if what and what_ not in what returndel lines[ pre]if post if lines and not lines[ -1 ] lines.pop -1 del lines[ - post ]if lines and lines[ -1 ] lines.append '' return process
def compare_mse im1 im2 _assert_compatible im1 im2 im1 im2 _as_floats im1 im2 return np.mean np.square im1 - im2 dtype np.float64
def verifyHostKey transport host pubKey fingerprint actualHost transport.factory.options['host']actualKey keys.Key.fromString pubKey kh KnownHostsFile.fromPath FilePath transport.factory.options['known-hosts'] or os.path.expanduser '~/.ssh/known_hosts' ui ConsoleUI lambda _open '/dev/tty' 'r+b' return kh.verifyHostKey ui actualHost host actualKey
def directLoopLists isWiddershins loopLists for loopList in loopLists directLoops isWiddershins loopList
def move_item item pos animate True duration None if not duration duration 250orangeqt.PlotItem.move_item item pos animate duration
def _unpack_lines out rexp ' ?ms ^ ?P<package>[^#]\\S+ [ DCTB ]+ ?P<question>\\S+ [ DCTB ]+ ?P<type>\\S+ [ DCTB ]+ ?P<value>[^\n]* $'lines re.findall rexp out return lines
def set_vif_host_backend_bridge_config conf brname tapname None conf.net_type 'bridge'conf.source_dev brnameif tapname conf.target_dev tapname
def AsValidator validator if isinstance validator str unicode return Regex validator type validator if isinstance validator type return Type validator if isinstance validator list tuple set return Options *tuple validator if isinstance validator Validator return validatorelse raise AttributeDefinitionError '%sisnotavalidvalidator' % str validator
def _translate_attachment_detail_view _context vol d _translate_attachment_summary_view _context vol return d
def get_unused_port_and_socket_ipv6 s socket.socket socket.AF_INET6 socket.SOCK_STREAM s.bind ' 1' 0 addr port flowinfo scopeid s.getsockname return port s
def create_from_breadcrumbs breadcrumb_str separator '>' category_names [x.strip for x in breadcrumb_str.split separator ]categories create_from_sequence category_names return categories[ -1 ]
def getSimplifiedLoops loops radius simplifiedLoops []for loop in loops simplifiedLoops.append getSimplifiedLoop loop radius return simplifiedLoops
def _parse_tag_data elem_code elem_num raw_data if elem_code in _BYTEFMT if elem_num 1 num ''else num str elem_num fmt '>' + num + _BYTEFMT[elem_code] assert len raw_data struct.calcsize fmt data struct.unpack fmt raw_data if elem_code not in [10 11] and len data 1 data data[0]if elem_code 2 return _bytes_to_string data elif elem_code 10 return str datetime.date *data elif elem_code 11 return str datetime.time *data[ 3] elif elem_code 13 return bool data elif elem_code 18 return _bytes_to_string data[1 ] elif elem_code 19 return _bytes_to_string data[ -1 ] else return dataelse return None
def rax_clb_node_to_dict obj if not obj return {}node obj.to_dict node['id'] obj.idnode['weight'] obj.weightreturn node
def db_alter name user None host None port None maintenance_db None password None tablespace None owner None owner_recurse False runas None if not any tablespace owner return Trueif owner and owner_recurse ret owner_to name owner user user host host port port password password runas runas else queries []if owner queries.append 'ALTERDATABASE"{0}"OWNERTO"{1}"'.format name owner if tablespace queries.append 'ALTERDATABASE"{0}"SETTABLESPACE"{1}"'.format name tablespace for query in queries ret _psql_prepare_and_run ['-c' query] user user host host port port maintenance_db maintenance_db password password runas runas if ret['retcode'] ! 0 return Falsereturn True
def _change_channel_group step params radio params['fig_selection'].radioidx radio._active_idxif step < 0 if idx < len radio.labels - 1 _set_radio_button idx + 1 params elif idx > 0 _set_radio_button idx - 1 params return
def read_cz_lsm_event_list fh count struct.unpack '<II' fh.read 8 [1]events []while count > 0 esize etime etype struct.unpack '<IdI' fh.read 16 etext stripnull fh.read esize - 16 events.append etime etype etext count - 1return events
def get_working_dir pwd_ os.environ.get 'PWD' cwd os.getcwd if pwd_ is None return cwdtry pwd_stat os.stat pwd_ cwd_stat os.stat cwd if pwd_stat.ino cwd_stat.ino and pwd_stat.dev cwd_stat.dev return pwd_except Exception passreturn cwd
def humanFrequency hertz divisor 1000if hertz < divisor return u'%uHz' % hertz units [u'kHz' u'MHz' u'GHz' u'THz']hertz float hertz for unit in units hertz hertz / divisor if hertz < divisor return u'%.1f%s' % hertz unit return u'%s%s' % hertz unit
def types_compatible var1 var2 type1 type var1 type2 type var2 if type1 is type2 return Trueif type1 is np.ndarray and var1.shape return type var1.item is type2 if type2 is np.ndarray and var2.shape return type var2.item is type1 return False
def is_tour_complete tour_key return configuration.get None 'shuup_%s_tour_complete' % tour_key False
def prob_bv_rectangle lower upper cdf probuu cdf *upper probul cdf upper[0] lower[1] problu cdf lower[0] upper[1] probll cdf *lower return probuu - probul - problu + probll
@functools.lru_cache maxsize None def is_language_prefix_patterns_used urlconf for url_pattern in get_resolver urlconf .url_patterns if isinstance url_pattern LocaleRegexURLResolver return True url_pattern.prefix_default_language return False False
def bernoulli n if not isscalar n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' n int n if n < 2 n1 2else n1 nreturn specfun.bernob int n1 [ n + 1 ]
def _make_request_id_aware_start_new_thread base_start_new_thread def _start_new_thread target args kw None if kw is None kw {}request_id remote_api_stub.RemoteStub._GetRequestId request request_state.get_request_state request_id def _run try remote_api_stub.RemoteStub._SetRequestId request_id request.start_thread target *args **kw finally request_environment.current_request.Clear request.end_thread return base_start_new_thread _run return _start_new_thread
def name_for_valid_number numobj lang script None region None return _prefix_description_for_number CARRIER_DATA CARRIER_LONGEST_PREFIX numobj lang script region
def format_user_and_project_subscriptions user return [{'node' {'id' user._id 'title' 'DefaultNotificationSettings' 'help' 'Thesearedefaultsettingsfornewprojectsyoucreate' + 'orareaddedto.Modifyingthesesettingswillnot' + 'modifysettingsonexistingprojects.' } 'kind' 'heading' 'children' format_user_subscriptions user } {'node' {'id' '' 'title' 'ProjectNotifications' 'help' 'Thesearesettingsforeachofyourprojects.Modifying' + 'thesesettingswillonlymodifythesettingsfortheselectedproject.' } 'kind' 'heading' 'children' format_data user get_configured_projects user }]
def canonicalize_url url keep_blank_values True keep_fragments False encoding None scheme netloc path params query fragment parse_url url keyvals cgi.parse_qsl query keep_blank_values keyvals.sort query urllib.urlencode keyvals path safe_url_string urllib.unquote path fragment '' if not keep_fragments else fragment return urlparse.urlunparse scheme netloc.lower path params query fragment
def _erfa_check ira idec astrom cra cdec erfa.atciq ira idec 0 0 0 0 astrom az zen ha odec ora erfa.atioq cra cdec astrom alt np.pi / 2 - zen cra2 cdec2 erfa.atoiq u'A' az zen astrom ira2 idec2 erfa.aticq cra2 cdec2 astrom dct locals del dct[u'astrom']return dct
def _is_virtio_blk device_path return device_path.basename .startswith 'vd'
def validate_key_names key_names_list for key_name in key_names_list if not VALID_KEY_NAME_REGEX.match key_name return Falsereturn True
def project_hfa_opts T current.Treturn {1 T 'HFA1 Ensurethatdisasterriskreductionisanationalandalocalprioritywithastronginstitutionalbasisforimplementation.' 2 T 'HFA2 Identify assessandmonitordisasterrisksandenhanceearlywarning.' 3 T 'HFA3 Useknowledge innovationandeducationtobuildacultureofsafetyandresilienceatalllevels.' 4 T 'HFA4 Reducetheunderlyingriskfactors.' 5 T 'HFA5 Strengthendisasterpreparednessforeffectiveresponseatalllevels.' }
def get_graph_reference path os.path.join 'package_data' 'default-schema.json' s resource_string 'plotly' path .decode 'utf-8' graph_reference utils.decode_unicode _json.loads s graph_reference['frames'] {'items' {'frames_entry' {'baseframe' {'description' "Thenameoftheframeintowhichthisframe'spropertiesaremergedbeforeapplying.Thisisusedtounifypropertiesandavoidneedingtospecifythesamevaluesforthesamepropertiesinmultipleframes." 'role' 'info' 'valType' 'string'} 'data' {'description' 'Alistoftracesthisframemodifies.Theformatisidenticaltothenormaltracedefinition.' 'role' 'object' 'valType' 'any'} 'group' {'description' 'Anidentifierthatspecifiesthegrouptowhichtheframebelongs usedbyanimatetoselectasubsetofframes.' 'role' 'info' 'valType' 'string'} 'layout' {'role' 'object' 'description' 'Layoutpropertieswhichthisframemodifies.Theformatisidenticaltothenormallayoutdefinition.' 'valType' 'any'} 'name' {'description' 'Alabelbywhichtoidentifytheframe' 'role' 'info' 'valType' 'string'} 'role' 'object' 'traces' {'description' 'Alistoftraceindicesthatidentifytherespectivetracesinthedataattribute' 'role' 'info' 'valType' 'info_array'}}} 'role' 'object'}return graph_reference
def _get_vm_ref_from_extraconfig session instance_uuid vms session._call_method vim_util 'get_objects' 'VirtualMachine' ['config.extraConfig["nvp.vm-uuid"]'] return _get_object_from_results session vms instance_uuid _get_object_for_optionvalue
def dmp_diff_in f m j u K if j < 0 or j > u raise IndexError '0< j< %sexpected got%s' % u j return _rec_diff_in f m u 0 j K
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def get_single name url module required getter u'__version__' mod get_version_module module name url version_getter getattr mod getter if hasattr version_getter u'__call__' current version_getter else current version_getterreturn name url current required
def getProgramFilesPath keyname 'SOFTWARE\\Microsoft\\Windows\\CurrentVersion'currentV win32api.RegOpenKeyEx win32con.HKEY_LOCAL_MACHINE keyname 0 win32con.KEY_READ return win32api.RegQueryValueEx currentV 'ProgramFilesDir' [0]
def isValidMCAddr ip FirstOct atol ip >> 24 & 255 return FirstOct > 224 and FirstOct < 239
def _api_cancel_pp name output kwargs nzo_id kwargs.get 'value' if PostProcessor.do.cancel_pp nzo_id return report output keyword '' data {'status' True 'nzo_id' nzo_id} else return report output _MSG_NO_ITEM
def _contains_special_directive directive_definition if directive_definition is None return Falseif len directive_definition.strip 0 return Falsespecial_directive_names [CSP_DIRECTIVE_SANDBOX CSP_DIRECTIVE_SCRIPT_NONCE]tmp directive_definition.lower for special_directive in special_directive_names if special_directive in tmp return Truereturn False
def add_components page item_type items is_advanced_problem False for item in items add_component page item_type item is_advanced_problem
def get_html_path path path os.path.splitext path [0]if os.path.basename path u'index' return path + u'.html' return u'/'.join path u'index.html'
def convert_TimeProperty model prop kwargs if prop.auto_now or prop.auto_now_add return Nonereturn f.DateTimeField format '%H %M %S' **kwargs
def find_packages where '.' exclude out []stack [ convert_path where '' ]while stack where prefix stack.pop 0 for name in os.listdir where fn os.path.join where name if '.' not in name and os.path.isdir fn and os.path.isfile os.path.join fn '__init__.py' out.append prefix + name stack.append fn prefix + name + '.' for pat in list exclude + ['ez_setup' 'distribute_setup'] from fnmatch import fnmatchcaseout [item for item in out if not fnmatchcase item pat ]return out
def _float_zeros_like x rval x.zeros_like if rval.type.dtype.find 'float' ! -1 return rvalreturn rval.astype theano.config.floatX
def getWrappedFloat floatValue modulo if floatValue > modulo return moduloif floatValue > 0 return floatValuereturn floatValue % modulo
def task_install_zfs distribution variants set commands []if is_ubuntu distribution commands + [run_network_interacting_from_args ['add-apt-repository' '-y' 'ppa zfs-native/stable'] ]commands + [apt_get_update apt_get_install ['libc6-dev'] apt_get_install ['zfsutils'] ]elif is_centos_or_rhel distribution commands + [yum_install [ZFS_REPO[distribution]] ]if distribution 'centos-7' commands.append yum_install ['epel-release'] if Variants.ZFS_TESTING in variants commands + [yum_install ['yum-utils'] run_from_args ['yum-config-manager' '--enable' 'zfs-testing'] ]commands.append yum_install ['zfs'] else raise DistributionNotSupported distribution return sequence commands
def create_org profile 'grafana' **kwargs if isinstance profile string_types profile __salt__['config.option'] profile response requests.post '{0}/api/orgs'.format profile['grafana_url'] json kwargs auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def mkExtractAssocMissingTest keys def test self msg mkAssocResponse *keys self.failUnlessRaises KeyError self.consumer._extractAssociation msg None return test
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def filter_consumer consumer_ref if consumer_ref consumer_ref consumer_ref.copy consumer_ref.pop 'secret' None return consumer_ref
@register.filter is_safe False def get_digit value arg try arg int arg value int value except ValueError return valueif arg < 1 return valuetry return int str value [ - arg ] except IndexError return 0
def constraint_for type_or_constraint if isinstance type_or_constraint Exactly return type_or_constraintelif isinstance type_or_constraint type return Exactly type_or_constraint else raise TypeError u'Expectedatypeorconstraint got {}'.format type_or_constraint
def default_zone return __firewall_cmd '--get-default-zone'
def Diff t diffs [ t[ i + 1 ] - t[i] for i in range len t - 1 ]return diffs
def _convert_etree_element_to_subscription entry_element subscription Subscription subscription_element entry_element.find './atom content/sb SubscriptionDescription' _etree_sb_feed_namespaces if subscription_element is not None mappings [ 'LockDuration' 'lock_duration' None 'RequiresSession' 'requires_session' _parse_bool 'DefaultMessageTimeToLive' 'default_message_time_to_live' None 'DeadLetteringOnFilterEvaluationExceptions' 'dead_lettering_on_filter_evaluation_exceptions' _parse_bool 'DeadLetteringOnMessageExpiration' 'dead_lettering_on_message_expiration' _parse_bool 'EnableBatchedOperations' 'enable_batched_operations' _parse_bool 'MaxDeliveryCount' 'max_delivery_count' int 'MessageCount' 'message_count' int ]for map in mappings _read_etree_element subscription_element map[0] subscription map[1] map[2] for name value in _ETreeXmlToObject.get_entry_properties_from_element entry_element True '/subscriptions' .items setattr subscription name value return subscription
def _EndRecData64 fpin offset endrec try fpin.seek offset - sizeEndCentDir64Locator 2 except IOError return endrecdata fpin.read sizeEndCentDir64Locator sig diskno reloff disks struct.unpack structEndArchive64Locator data if sig ! stringEndArchive64Locator return endrecif diskno ! 0 or disks ! 1 raise BadZipfile 'zipfilesthatspanmultipledisksarenotsupported' fpin.seek offset - sizeEndCentDir64Locator - sizeEndCentDir64 2 data fpin.read sizeEndCentDir64 sig sz create_version read_version disk_num disk_dir dircount dircount2 dirsize diroffset struct.unpack structEndArchive64 data if sig ! stringEndArchive64 return endrecendrec[_ECD_SIGNATURE] sigendrec[_ECD_DISK_NUMBER] disk_numendrec[_ECD_DISK_START] disk_direndrec[_ECD_ENTRIES_THIS_DISK] dircountendrec[_ECD_ENTRIES_TOTAL] dircount2endrec[_ECD_SIZE] dirsizeendrec[_ECD_OFFSET] diroffsetreturn endrec
def test_timedelta timedelta_chart TimeDeltaLine truncate_label 1000 timedelta_chart.add 'timedeltas' [ timedelta seconds 1 10 timedelta weeks 1 50 timedelta hours 3 seconds 30 3 timedelta microseconds 12112 0.3 ] q timedelta_chart.render_pyquery assert list t for t in q '.axis.xtext' .map texts if t ! '0 00 00' ['1day 3 46 40' '2days 7 33 20' '3days 11 20 00' '4days 15 06 40' '5days 18 53 20' '6days 22 40 00']
def parallax return [ si.arcsecond astrophys.parsec lambda x 1.0 / x ]
def getCraftedText fileName text '' liftRepository None return getCraftedTextFromText archive.getTextIfEmpty fileName text liftRepository
def check_with_pep8 source_code filename None try args get_checker_executable 'pep8' results check args source_code filename filename options ['-r'] except Exception results []if DEBUG_EDITOR traceback.print_exc return results
def _get_sss_rank sss inside sss['sss_info']['in_order']nfree inside + 1 ** 2 - 1 nfree - len sss['sss_info']['components'][ nfree] - sss['sss_info']['components'][ nfree].sum return nfree
def _from_args sudo if sudo return sudo_network_interacting_from_argselse return run_network_interacting_from_args
def Figure **options _Underride options figsize 6 8 pyplot.figure **options
def blackman M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym w _cos_win M [0.42 0.5 0.08] return _truncate w needs_trunc
@lower_cast types.IntEnumMember types.Integer def int_enum_to_int context builder fromty toty val return context.cast builder val fromty.dtype toty
def flatten_reshape variable name '' dim 1for d in variable.get_shape [1 ].as_list dim * dreturn tf.reshape variable shape [ -1 dim] name name
def session_destroy consul_url None session None **kwargs ret {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not session raise SaltInvocationError 'Requiredargument"session"ismissing.' query_params {}if 'dc' in kwargs query_params['dc'] kwargs['dc']function 'session/destroy/{0}'.format session res _query consul_url consul_url function function query_params query_params if res['res'] ret['res'] Trueret['message'] 'CreatedService{0}.'.format kwargs['name'] else ret['res'] Falseret['message'] 'Unabletocreateservice{0}.'.format kwargs['name'] return ret
def get_named_nodes graph return _get_named_nodes graph {}
def generate_image_url image_ref return '%s/images/%s' % generate_glance_url image_ref
def prep_im_for_blob im pixel_means target_size max_size im im.astype np.float32 copy False im - pixel_meansim_shape im.shapeim_size_min np.min im_shape[0 2] im_size_max np.max im_shape[0 2] im_scale float target_size / float im_size_min if np.round im_scale * im_size_max > max_size im_scale float max_size / float im_size_max im cv2.resize im None None fx im_scale fy im_scale interpolation cv2.INTER_LINEAR return im im_scale
def complete_python prefix line start end ctx rtn _complete_python prefix line start end ctx if not rtn prefix re.split '\\ | |{|\\[| ' prefix [ -1 ] if not prefix.startswith ' ' else prefix start line.find prefix rtn _complete_python prefix line start end ctx return rtn len prefix return rtn
def _make_bound_method func self class Foo object def meth self passf Foo bound_method type f.meth try return bound_method func self self.__class__ except TypeError return bound_method func self
def set_vif_host_backend_hw_veb conf net_type devname vlan tapname None conf.net_type net_typeif net_type 'direct' conf.source_mode 'passthrough'conf.source_dev pci_utils.get_ifname_by_pci_address devname conf.driver_name 'vhost'else conf.source_dev devnameconf.model Noneconf.vlan vlanif tapname conf.target_dev tapname
def switch_host_with_param request param_name request_json json.loads request.data.decode 'utf-8' if request_json.get param_name new_endpoint request_json[param_name]_switch_hosts request new_endpoint
def test_get_words_markdown expected_words ['A' 'Blockquote' 'Bold' 'Heading' 'Horizontal' 'Image' 'Inline' 'Italic' 'Link' 'List' 'One' 'Rule' 'Three' 'Two' 'a' 'after' 'b' 'backticks' 'blank' 'block' 'code' 'com' 'http' 'indent' 'jpg' 'line' 'or' 'org' 'paragraph' 'png' 'print' 'spaces' 'url' 'with']assert sorted expected_words sorted get_words_by_filename 'example.md' assert sorted expected_words sorted get_words_by_content 'example.md'
def _try_passwordless_paramiko server keyfile if paramiko is None msg 'Paramikounavaliable 'if sys.platform 'win32' msg + 'ParamikoisrequiredforsshtunneledconnectionsonWindows.'else msg + 'useOpenSSH.'raise ImportError msg username server port _split_server server client paramiko.SSHClient client.load_system_host_keys client.set_missing_host_key_policy paramiko.WarningPolicy try client.connect server port username username key_filename keyfile look_for_keys True except paramiko.AuthenticationException return Falseelse client.close return True
def get_system_roles result Role.query system True return result
def agefilter st now age timestamp if age is None or age > 0 and now - st.__getattribute__ 'st_%s' % timestamp > abs age or age < 0 and now - st.__getattribute__ 'st_%s' % timestamp < abs age return Truereturn False
def _match_routes iter_func request extra_args None extra_kwargs None method_not_allowed Falsefor route in iter_func try match route.match request if match route args kwargs matchif extra_args args + extra_argsif extra_kwargs kwargs.update extra_kwargs return route args kwargs except exc.HTTPMethodNotAllowed method_not_allowed Trueif method_not_allowed raise exc.HTTPMethodNotAllowed
def generateRandomInput numRecords elemSize 400 numSet 42 inputs []for _ in xrange numRecords input np.zeros elemSize dtype realDType for _ in range 0 numSet ind np.random.random_integers 0 elemSize - 1 1 [0]input[ind] 1while abs input.sum - numSet > 0.1 ind np.random.random_integers 0 elemSize - 1 1 [0]input[ind] 1inputs.append input return inputs
def _create_instance **kwargs ctxt context_maker.get_admin_context return db.instance_create ctxt _create_instance_dict **kwargs
def test_constructor_function AreEqual System.DateTime.__new__.__name__ '__new__' Assert System.DateTime.__new__.__doc__.find '__new__ cls type year int month int day int ' ! -1 if not is_silverlight and not is_netstandard Assert System.AssemblyLoadEventArgs.__new__.__doc__.find '__new__ cls type loadedAssembly Assembly ' ! -1
def _define_atomic_cas module ordering ftype ir.FunctionType ir.IntType 32 [_word_type.as_pointer _word_type _word_type _word_type.as_pointer ] fn_cas ir.Function module ftype name 'nrt_atomic_cas' [ptr cmp repl oldptr] fn_cas.argsbb fn_cas.append_basic_block builder ir.IRBuilder bb outtup builder.cmpxchg ptr cmp repl ordering ordering old ok cgutils.unpack_tuple builder outtup 2 builder.store old oldptr builder.ret builder.zext ok ftype.return_type return fn_cas
def set_multi key_value_mapping assert isinstance key_value_mapping dict unset_keys memcache.set_multi key_value_mapping return unset_keys
def test_timeout time.sleep 100
def test_missing_argument script result script.pip 'show' expect_error True assert 'ERROR Pleaseprovideapackagenameornames.' in result.stderr
def token_kwargs bits parser if not bits return {}kwargs OrderedDict while bits match kwarg_re.match bits[0] if not match or not match.group 1 return kwargs key value match.groups del bits[ 1]kwargs[parser.compile_filter key ] parser.compile_filter value return kwargs
def rabbitmq_queue_size from celery import current_appapp current_app._get_current_object conn app.connection chan conn.default_channelqueue chan.queue_declare 'celery' passive True return queue.message_count
def logDownload episode filename new_ep_quality release_group None version -1 showid int episode.show.indexerid season int episode.season epNum int episode.episode quality new_ep_qualityif release_group provider release_groupelse provider -1 action episode.status_logHistoryItem action showid season epNum quality filename provider version
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _base_authorization_headers username server if not username if 'AUTOTEST_USER' in os.environ username os.environ['AUTOTEST_USER']else username getpass.getuser return {'AUTHORIZATION' username}
def equateZ point returnValue point.z returnValue
def square_image img x y img.sizewhile y > x slice_height min y - x 10 bottom img.crop 0 y - slice_height x y top img.crop 0 0 x slice_height if image_entropy bottom < image_entropy top img img.crop 0 0 x y - slice_height else img img.crop 0 slice_height x y x y img.sizereturn img
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def _audioTimeCallback event movieInstanceRef streamPlayer if movieInstanceRef tm - event.u.new_time / 1000.0 movieInstanceRef ._audio_stream_clock.reset tm
@register.assignment_tag takes_context True def page_is_active context page feincms_page None path None if isinstance page PagePretender if path is None path context[u'request'].path_inforeturn path.startswith page.get_absolute_url else if feincms_page is None feincms_page context[u'feincms_page']return page.is_ancestor_of feincms_page include_self True
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
@with_config DEBUG True ASSETS_DEBUG True def test_no_output_no_merge bundle_to_joblist Bundle 's1' 's2'
def mergeFunctionMetadata f g try g.__name__ f.__name__except TypeError passtry g.__doc__ f.__doc__except TypeError AttributeError passtry g.__dict__.update f.__dict__ except TypeError AttributeError passtry g.__module__ f.__module__except TypeError passreturn g
def _check_caller_authority caller role if not caller.is_authenticated and caller.is_active raise PermissionDeniedif GlobalStaff .has_user caller returnif isinstance role GlobalStaff CourseCreatorRole raise PermissionDeniedelif isinstance role CourseRole if not user_has_role caller CourseInstructorRole role.course_key raise PermissionDenied
def make_double_frame master None class_ None name None relief RAISED borderwidth 1 if name if class_ frame Frame master class_ class_ name name else frame Frame master name name elif class_ frame Frame master class_ class_ else frame Frame master top Frame frame name 'topframe' relief relief borderwidth borderwidth bottom Frame frame name 'bottomframe' bottom.pack fill X padx '1m' pady '1m' side BOTTOM top.pack expand 1 fill BOTH padx '1m' pady '1m' frame.pack expand 1 fill BOTH top Frame top top.pack expand 1 fill BOTH padx '2m' pady '2m' return frame top bottom
def get_class lookup_view if isinstance lookup_view str mod_name func_name get_mod_func lookup_view if func_name ! '' lookup_view getattr __import__ mod_name {} {} ['*'] func_name if not callable lookup_view raise AttributeError "'%s.%s'isnotacallable." % mod_name func_name return lookup_view
def get_remaining_quota context db_api image_id None users_quota CONF.user_storage_quotapattern re.compile '^ \\d+ K|M|G|T ?B ?$' match pattern.match users_quota if not match LOG.error _LE 'Invalidvalueforoptionuser_storage_quota % users_quota s' % {'users_quota' users_quota} raise exception.InvalidOptionValue option 'user_storage_quota' value users_quota quota_value quota_unit match.groups [0 2]quota_unit quota_unit or 'B' factor getattr units quota_unit.replace 'B' 'i' 1 users_quota int quota_value * factor if users_quota < 0 returnusage db_api.user_get_storage_usage context context.owner image_id image_id return users_quota - usage
def set_gpu_fraction sess None gpu_fraction 0.3 print 'tensorlayer GPUMEMFraction%f' % gpu_fraction gpu_options tf.GPUOptions per_process_gpu_memory_fraction gpu_fraction sess tf.Session config tf.ConfigProto gpu_options gpu_options return sess
def mark_negation document double_neg_flip False shallow False if not shallow document deepcopy document labeled document and isinstance document[0] tuple list if labeled doc document[0]else doc documentneg_scope Falsefor i word in enumerate doc if NEGATION_RE.search word if not neg_scope or neg_scope and double_neg_flip neg_scope not neg_scope continueelse doc[i] + '_NEG'elif neg_scope and CLAUSE_PUNCT_RE.search word neg_scope not neg_scope elif neg_scope and not CLAUSE_PUNCT_RE.search word doc[i] + '_NEG'return document
@subscriber ResourceChanged for_resources 'group' for_actions ACTIONS.CREATE ACTIONS.UPDATE def on_groups_changed event permission_backend event.request.registry.permissionfor change in event.impacted_records if 'old' in change existing_record_members set change['old'].get 'members' [] else existing_record_members set group change['new']group_uri '/buckets/{bucket_id}/groups/{id}'.format id group['id'] **event.payload new_record_members set group.get 'members' [] new_members new_record_members - existing_record_members removed_members existing_record_members - new_record_members for member in new_members permission_backend.add_user_principal member group_uri for member in removed_members permission_backend.remove_user_principal member group_uri
@environmentfilterdef do_attr environment obj name try name str name except UnicodeError passelse try value getattr obj name except AttributeError passelse if environment.sandboxed and not environment.is_safe_attribute obj name value return environment.unsafe_undefined obj name return valuereturn environment.undefined obj obj name name
def host_memory_size obj s e host_memory_extents obj assert e > s 'memoryextendofnegativesize'return e - s
def pre_order_list node filter_func no_filter l stack [] [] poped index 0 0 while node if filter_func node if not poped l.append node if node.children and not poped stack.append node index index 0node node.children[0]else index + 1try node stack[ -1 ][0].children[index]except IndexError node Noneelse node Nonepoped 0if node is None and len stack > 1 node index stack.pop poped 1return l
def convert_dll_name_to_str dll_name if is_py3 and isinstance dll_name bytes return str dll_name encoding 'UTF-8' else return dll_name
def create_filters predicate_params predicate_factory filters []for predicate_param in predicate_params filters.append create_filter predicate_param predicate_factory return filters
def clebsch_gordan j_1 j_2 j_3 m_1 m_2 m_3 res -1 ** sympify j_1 - j_2 + m_3 * sqrt 2 * j_3 + 1 * wigner_3j j_1 j_2 j_3 m_1 m_2 - m_3 return res
def get_message_id return u'<{unique}@{site}>'.format site frappe.local.site unique email.utils.make_msgid random_string 10 .split u'@' [0].split u'<' [1]
def DiscreteUniform name items return rv name DiscreteUniformDistribution *items
def get_backend return rcParams['backend']
def pack_shards used_images num_shards sorted_images sorted used_images key lambda x x[1] reverse True shards []for i in range 0 num_shards shards.append {'images' [] 'sum' 0} for image in sorted_images shard min shards key lambda x x['sum'] shard['images'].append image shard['sum'] + image[1]return shards
@_refresh_mine_cache@_ensure_existsdef stop name timeout STOP_TIMEOUT **kwargs orig_state state name if orig_state 'paused' if kwargs.get 'unpause' False unpause_result _change_state name 'unpause' 'running' if unpause_result['result'] is False unpause_result['comment'] "Failedtounpausecontainer'{0}'".format name return unpause_resultelse return {'result' False 'state' {'old' orig_state 'new' orig_state} 'comment' "Container'{0}'ispaused runwithunpause Truetounpausebeforestopping".format name }ret _change_state name 'stop' 'stopped' timeout timeout ret['state']['old'] orig_statereturn ret
def compareAttributeKeyAscending key otherKey if key 'id' return -1 if otherKey 'id' return 1if key 'name' return -1 if otherKey 'name' return 1if key < otherKey return -1 return int key > otherKey
def _all_number_groups_remain_grouped numobj normalized_candidate formatted_number_groups from_index 0if numobj.country_code_source ! CountryCodeSource.FROM_DEFAULT_COUNTRY country_code str numobj.country_code from_index normalized_candidate.find country_code + len country_code for ii formatted_number_group in enumerate formatted_number_groups from_index normalized_candidate.find formatted_number_group from_index if from_index < 0 return Falsefrom_index + len formatted_number_group if ii 0 and from_index < len normalized_candidate region region_code_for_country_code numobj.country_code if ndd_prefix_for_region region True is not None and normalized_candidate[from_index].isdigit nsn national_significant_number numobj return normalized_candidate[ from_index - len formatted_number_group ].startswith nsn return normalized_candidate[from_index ].find numobj.extension or U_EMPTY_STRING ! -1
def get_profile_id service domain accounts service.management .accounts .list .execute account_ids [a['id'] for a in accounts.get 'items' ]for account_id in account_ids webproperties service.management .webproperties .list accountId account_id .execute webproperty_ids [p['id'] for p in webproperties.get 'items' ]for webproperty_id in webproperty_ids profiles service.management .profiles .list accountId account_id webPropertyId webproperty_id .execute for p in profiles.get 'items' if ' //' in p['websiteUrl'] name p['websiteUrl'].partition ' //' [ -1 ]else name p['websiteUrl']if name domain return p['id']
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep.join seq else return '%sor%s' % sep.join seq[ -1 ] seq[ -1 ]
def _CheckFacetValueLimit value_limit if value_limit is None return Noneelse return _CheckInteger value_limit 'facet_value_limit' zero_ok False upper_bound MAXIMUM_FACET_VALUES_TO_RETURN
def _RecAnnotate tree annotate_name annotate_value for child in tree.children _RecAnnotate child annotate_name annotate_value if isinstance tree pytree.Leaf cur_annotate pytree_utils.GetNodeAnnotation tree annotate_name default 0 if cur_annotate < annotate_value pytree_utils.SetNodeAnnotation tree annotate_name annotate_value
def run_DESeq2 input_path out_path mapping_category subcategory_1 subcategory_2 DESeq2_diagnostic_plots outfile_diagnostic if DESeq2_diagnostic_plots True command_args [ '-i%s-o%s-c%s-x%s-y%s-d%s-e%s' % input_path out_path mapping_category subcategory_1 subcategory_2 DESeq2_diagnostic_plots outfile_diagnostic ]else command_args [ '-i%s-o%s-c%s-x%s-y%s' % input_path out_path mapping_category subcategory_1 subcategory_2 ]rsl RExecutor TmpDir get_qiime_temp_dir app_result rsl command_args command_args script_name 'DESeq2_nbinom.r' return app_result
def find_conda_prefix conda_prefix None if conda_prefix is None return os.path.join os.path.expanduser '~' 'miniconda2' return conda_prefix
def restrict_forward_to_stc fwd stc fwd_out deepcopy fwd src_sel _stc_src_sel fwd['src'] stc fwd_out['source_rr'] fwd['source_rr'][src_sel]fwd_out['nsource'] len src_sel if is_fixed_orient fwd idx src_selelse idx 3 * src_sel[ None] + np.arange 3 .ravel fwd_out['source_nn'] fwd['source_nn'][idx]fwd_out['sol']['data'] fwd['sol']['data'][ idx]fwd_out['sol']['ncol'] len idx for i in range 2 fwd_out['src'][i]['vertno'] stc.vertices[i]fwd_out['src'][i]['nuse'] len stc.vertices[i] fwd_out['src'][i]['inuse'] fwd['src'][i]['inuse'].copy fwd_out['src'][i]['inuse'].fill 0 fwd_out['src'][i]['inuse'][stc.vertices[i]] 1fwd_out['src'][i]['use_tris'] np.array [] int fwd_out['src'][i]['nuse_tri'] np.array [0] return fwd_out
def create_addon name icon_type application **extra_kwargs kwargs {'status' STATUS_PUBLIC 'name' name 'slug' slugify name 'bayesian_rating' random.uniform 1 5 'average_daily_users' random.randint 200 2000 'weekly_downloads' random.randint 200 2000 'created' datetime.now 'last_updated' datetime.now 'icon_type' icon_type}kwargs.update extra_kwargs addon Addon.objects.create type ADDON_EXTENSION **kwargs generate_version addon addon app application addon.update_version addon.status STATUS_PUBLICaddon.save return addon
def _normalize_proj info _make_projector info['projs'] info.get 'ch_names' info.get 'names' info['bads'] include_active True inplace True
def parseaddr address a AddressList address lst a.addresslistif not lst return None None return lst[0]
def create_all_dirs path umask False result Trueif sabnzbd.WIN32 try os.makedirs path except result Falseelse lst []lst.extend path.split '/' path ''for d in lst if d path + '/' + d if not os.path.exists path try os.mkdir path result Trueexcept result Falseif umask mask cfg.umask if mask try os.chmod path int mask 8 | 448 except passreturn result
def sort_mapping_by_size cluster_mapping return sorted cluster_mapping.keys cmp lambda a b cmp len a len b key lambda k cluster_mapping[k] reverse True
def ufunc_can_cast from_ to has_mixed_inputs casting 'safe' from_ np.dtype from_ to np.dtype to if has_mixed_inputs and from_.kind in 'iu' and to.kind in 'cf' return Truereturn np.can_cast from_ to casting
@require_admin@api_handle_error_with_jsondef start_video_download request force_job 'videodownload' stop True locale request.language paths OrderedSet json.loads request.body or '{}' .get 'paths' [] lang json.loads request.body or '{}' .get 'lang' 'en' youtube_ids get_download_youtube_ids paths language lang downloaded False queue VideoQueue queue.add_files youtube_ids language lang force_job 'videodownload' _ 'DownloadVideos' locale lang return JsonResponseMessageSuccess _ 'Launchedvideodownloadprocesssuccessfully.'
def test_edf_annotations raw read_raw_edf edf_path preload True edf_events find_events raw output 'step' shortest_event 0 stim_channel 'STI014' events [[0.1344 0.256 2] [0.3904 1.0 2] [2.0 0.0 3] [2.5 2.5 2]]events np.array events events[ 2] * 512events np.array events dtype int events[ 1] - 1events[ events[ 1] < 0 1 ] 1events[ 1] + events[ 0]onsets events[ [0 2]]offsets events[ [1 2]]events np.zeros 2 * events.shape[0] 3 dtype int events[0 2 [0 2]] onsetsevents[1 2 [0 1]] offsetsassert_array_equal edf_events events
def get_project request project skip_acl False project get_object_or_404 Project slug project if not skip_acl project.check_acl request return project
def period_dates period end date.today - timedelta days 1 if period LAST_7_DAYS start end - timedelta days 7 elif period LAST_30_DAYS start end - timedelta days 30 elif period LAST_90_DAYS start end - timedelta days 90 elif ALL_TIME start settings.GA_START_DATEreturn start end
def _find_iso_sr session host session.host_reffor sr_ref sr_rec in session.get_all_refs_and_recs 'SR' LOG.debug 'ISO lookingatSR%s' sr_rec if not sr_rec['content_type'] 'iso' LOG.debug 'ISO notisocontent' continueif 'i18n-key' not in sr_rec['other_config'] LOG.debug "ISO isocontent_type no'i18n-key'key" continueif not sr_rec['other_config']['i18n-key'] 'local-storage-iso' LOG.debug "ISO isocontent_type i18n-keyvaluenot'local-storage-iso'" continueLOG.debug 'ISO SRMATCHingourcriteria' for pbd_ref in sr_rec['PBDs'] LOG.debug 'ISO ISO lookingtoseeifitishostlocal' pbd_rec session.get_rec 'PBD' pbd_ref if not pbd_rec LOG.debug 'ISO PBD%sdisappeared' pbd_ref continuepbd_rec_host pbd_rec['host']LOG.debug 'ISO PBDmatching want% pbd_rec s have% host s' {'pbd_rec' pbd_rec 'host' host} if pbd_rec_host host LOG.debug 'ISO SRwithlocalPBD' return sr_refreturn None
def test_eager_does_upgrade_dependecies_when_currently_satisfied script script.pip_install_local 'simple 2.0' expect_error True result script.pip_install_local '--upgrade' '--upgrade-strategy eager' 'require_simple' expect_error True assert script.site_packages / 'require_simple-1.0-py%s.egg-info' % pyversion not in result.files_deleted 'shouldhaveinstalledrequire_simple 1.0'assert script.site_packages / 'simple-2.0-py%s.egg-info' % pyversion in result.files_deleted 'shouldhaveuninstalledsimple 2.0'
def addXIntersectionsFromLoops loops xIntersections y for loop in loops addXIntersections loop xIntersections y
def dburl2dict url parts urlparse.urlparse unquote url return {'dbn' parts.scheme 'user' parts.username 'pw' parts.password 'db' parts.path[1 ] 'host' parts.hostname 'port' parts.port}
def getClippedAtEndLoopPath clip loopPath if clip < 0.0 return loopPathloopPathLength getPathLength loopPath clip min clip 0.3 * loopPathLength lastLength 0.0pointIndex 0totalLength 0.0clippedLength loopPathLength - clip while totalLength < clippedLength and pointIndex < len loopPath - 1 firstPoint loopPath[pointIndex]secondPoint loopPath[ pointIndex + 1 ]pointIndex + 1lastLength totalLengthtotalLength + abs firstPoint - secondPoint remainingLength clippedLength - lastLength clippedLoopPath loopPath[ pointIndex]ultimateClippedPoint loopPath[pointIndex]penultimateClippedPoint clippedLoopPath[ -1 ]segment ultimateClippedPoint - penultimateClippedPoint segmentLength abs segment if segmentLength < 0.0 return clippedLoopPathnewUltimatePoint penultimateClippedPoint + segment * remainingLength / segmentLength return clippedLoopPath + [newUltimatePoint]
def htmlentityreplace_errors ex if isinstance ex UnicodeEncodeError bad_text ex.object[ex.start ex.end]text _html_entities_escaper.escape bad_text return unicode text ex.end raise ex
def allow ip port None if port is None return __apf_cmd '-a{0}'.format ip
def _is_shell_needed_for_subprocess_calls return os.name u'nt'
def avail_images call None if call 'action' raise SaltCloudSystemExit 'Theavail_imagesfunctionmustbecalledwith-for--function orwiththe--list-imagesoption' server user password _get_xml_rpc auth ' '.join [user password] image_pool server.one.imagepool.info auth -2 -1 -1 [1]images {}for image in _get_xml image_pool images[image.find 'NAME' .text] _xml_to_dict image return images
def extract_tokens l known_tokens assert l[0].strip ' ' and l[ -1 ].strip ' ' ValueError l result {}result_has_key result.has_keyresult.update known_tokens i 0l_len len l while i < l_len if result_has_key l[i] token l[i]i + 1if i < l_len if result_has_key l[i] result[token] elif l[i] ' ' i + 1start iwhile i < l_len and l[i] ! ' ' i + 1result[token] tuple filter lambda v v ! '$' l[start i] i + 1else result[token] l[i] i + 1else i + 1return result
def _orbits_transversals_from_bsgs base strong_gens_distr transversals_only False from sympy.combinatorics.perm_groups import _orbit_transversalbase_len len base degree strong_gens_distr[0][0].sizetransversals [None] * base_len if transversals_only is False basic_orbits [None] * base_len for i in range base_len transversals[i] dict _orbit_transversal degree strong_gens_distr[i] base[i] pairs True if transversals_only is False basic_orbits[i] list transversals[i].keys if transversals_only return transversalselse return basic_orbits transversals
def lxml_trace data html True **kwargs from lxml import etreefor event element in etree.iterparse StringIO data html html **kwargs print '%s %4s %s' % event element.tag element.text
def test_ncr_sample_wt_fit ncr NeighbourhoodCleaningRule random_state RND_SEED assert_raises RuntimeError ncr.sample X Y
def generate_scale_free_graph steps growth_num self_loops False multi_edges False graph Graph.Graph store []for i in range growth_num for j in range i + 1 growth_num store.append i store.append j graph.add_edge i j for node in range growth_num steps * growth_num graph.add_node node while graph.out_degree node < growth_num nbr random.choice store if node nbr and not self_loops continueif graph.edge_by_node node nbr and not multi_edges continuegraph.add_edge node nbr for nbr in graph.out_nbrs node store.append node store.append nbr return graph
def getDocumentNode fileName xmlText getFileText 'test.xml' return DocumentNode fileName xmlText
def is_path_hidden filepath name os.path.basename os.path.abspath filepath if isinstance name bytes is_dotted name.startswith '.' else is_dotted name.startswith u'.' return is_dotted or _has_hidden_attribute filepath
def find_cover_image container strict False ver container.opf_version_parsedif ver.major < 3 return find_cover_image2 container strict strict else return find_cover_image3 container
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def build_simple_tree node TreeNode 1 node.left TreeNode 2 node.right TreeNode 3 node.right.left TreeNode 4 node.right.right TreeNode 5 return node
def format_payload enc **kwargs payload {'enc' enc}load {}for key in kwargs load[key] kwargs[key]payload['load'] loadreturn package payload
def run _task
def get_validation_schema models default_namespace None if default_namespace is None default_namespace models[0].get_namespace fake_app FakeApplication fake_app.tns default_namespacefake_app.services []interface Interface fake_app for m in models m.resolve_namespace m default_namespace interface.add_class m schema XmlSchema interface schema.build_validation_schema return schema.validation_schema
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u''.join choice chars for x in range length
def raise_if_custom_resource_class_pre_v1_1 rc if isinstance rc six.string_types if rc not in fields.ResourceClass.V1_0 raise ValueErrorelse try fields.ResourceClass.V1_0[rc]except IndexError raise ValueError
def libvlc_media_library_media_list p_mlib f _Cfunctions.get 'libvlc_media_library_media_list' None or _Cfunction 'libvlc_media_library_media_list' 1 class_result MediaList ctypes.c_void_p MediaLibrary return f p_mlib
def getCentersFromIntersectionLoop circleIntersectionLoop radius loop []for circleIntersection in circleIntersectionLoop loop.append circleIntersection.circleNodeAhead.circle * radius return loop
def capitalize_string input_string if input_string return input_string[0].upper + input_string[1 ] else return input_string
def bulk_disable workers lbn profile 'default' ret {}if isinstance workers str workers workers.split ' ' for worker in workers try ret[worker] worker_disable worker lbn profile except Exception ret[worker] Falsereturn ret
def namespaces return _DB.namespaces
def _fprime_ieqcons x_full k_params I np.eye k_params A np.concatenate I I axis 1 B np.concatenate - I I axis 1 C np.concatenate A B axis 0 return C
def _fileobj_to_fd fileobj if isinstance fileobj six.integer_types fd fileobjelse try fd int fileobj.fileno except AttributeError TypeError ValueError raise ValueError 'Invalidfileobject {0!r}'.format fileobj if fd < 0 raise ValueError 'Invalidfiledescriptor {0}'.format fd return fd
def updatePyExec bindir executable None bindir os.path.realpath bindir if executable is None executable sys.executablepypath os.path.join bindir 'fail2ban-python' isfile os.path.isfile os.path.realpath pypath if not isfile or os.path.realpath pypath ! os.path.realpath executable if isfile os.unlink pypath os.symlink executable pypath if bindir not in os.environ['PATH'].split os.pathsep os.environ['PATH'] os.environ['PATH'] + os.pathsep + bindir
def run_module name file if name '__main__' nose.runmodule argv [file '-vvs' '-x' '--pdb' '--pdb-failure'] exit False
def controller_scan directory None if directory is None return []def find_controllers dirname prefix '' 'Locatecontrollersinadirectory'controllers []for fname in os.listdir dirname filename os.path.join dirname fname if os.path.isfile filename and re.match '^[^_]{1 1}.*\\.py$' fname controllers.append prefix + fname[ -3 ] elif os.path.isdir filename controllers.extend find_controllers filename prefix prefix + fname + '/' return controllersdef longest_first fst lst 'Comparethelengthofonestringtoanother shortestgoesfirst'return cmp len lst len fst controllers find_controllers directory controllers.sort longest_first return controllers
def FixKeys entity_proto app_id def FixKey mutable_key mutable_key.set_app app_id def FixPropertyList property_list for prop in property_list prop_value prop.mutable_value if prop_value.has_referencevalue FixKey prop_value.mutable_referencevalue elif prop.meaning entity_pb.Property.ENTITY_PROTO embedded_entity_proto entity_pb.EntityProto try embedded_entity_proto.ParsePartialFromString prop_value.stringvalue except Exception logging.exception 'Failedtofix-keysforproperty%sof%s' prop.name entity_proto.key else FixKeys embedded_entity_proto app_id prop_value.set_stringvalue embedded_entity_proto.SerializePartialToString if entity_proto.has_key and entity_proto.key .path .element_size FixKey entity_proto.mutable_key FixPropertyList entity_proto.property_list FixPropertyList entity_proto.raw_property_list
def make_amp_agent_options_tests options_type class Tests TestCase def setUp self super Tests self .setUp self.options options_type self.scratch_directory FilePath self.mktemp self.scratch_directory.makedirs self.sample_content yaml.safe_dump {u'control-service' {u'hostname' u'10.0.0.1' u'port' 4524} u'version' 1} self.config self.scratch_directory.child 'dataset-config.yml' self.config.setContent self.sample_content def test_default_config_file self '\nThedefaultconfigfileisaFilePathwithpath\n``/etc/flocker/agent.yml``.\n'self.options.parseOptions [] self.assertEqual self.options['agent-config'] FilePath '/etc/flocker/agent.yml' def test_custom_config_file self '\nThe``--config-file``command-lineoptionallowsconfiguring\ntheconfigfile.\n'self.options.parseOptions ['--agent-config' '/etc/foo.yml'] self.assertEqual self.options['agent-config'] FilePath '/etc/foo.yml' return Tests
def is_empty body return len body 1 and isinstance body[0] astroid.Pass
def addFileHandler path addHandler logging.FileHandler path
def resolve_connection connection None if connection is not None return patch_connection connection connection get_current_connection if connection is None raise NoRedisConnectionException u'CouldnotresolveaRedisconnection' return connection
def _create_ecb_cipher factory **kwargs cipher_state factory._create_base_cipher kwargs if kwargs raise TypeError 'UnknownparametersforECB %s' % str kwargs return EcbMode cipher_state
def _api_auth name output kwargs auth 'None'if not cfg.disable_key auth 'badkey'key kwargs.get 'key' '' if not key auth 'apikey'else if key cfg.nzb_key auth 'nzbkey'if key cfg.api_key auth 'apikey'elif cfg.username and cfg.password auth 'login'return report output keyword 'auth' data auth
def euclidean_distances X Y squared False inverse True if X is Y X Y np.asanyarray X else X np.asanyarray X Y np.asanyarray Y if X.shape[1] ! Y.shape[1] raise ValueError 'IncompatibledimensionforXandYmatrices' if squared return ssd.cdist X Y 'sqeuclidean' XY ssd.cdist X Y return np.divide 1.0 1.0 + XY if inverse else XY
def _format_msg msg std_msg if msg is None msg std_msgelse try msg '%s %s' % std_msg msg except UnicodeDecodeError msg '%s %s' % _safe_str std_msg _safe_str msg return msg
@require_POST@csrf_exemptdef unhelpful_survey request vote get_object_or_404 HelpfulVote id smart_int request.POST.get 'vote_id' if not vote.helpful and not vote.metadata.filter key 'survey' .exists survey request.POST.copy survey.pop 'vote_id' survey.pop 'button' vote.add_metadata 'survey' truncated_json_dumps survey 1000 'comment' return HttpResponse json.dumps {'message' _ 'Thanksformakingusbetter!' }
@blueprint.route '/resources/<resource>/meters/<meter>/volume/max' def compute_max_resource_volume resource meter return _get_statistics 'max' meter meter resource resource project acl.get_limited_to_project flask.request.headers
def embed_album log album maxwidth None quiet False compare_threshold 0 ifempty False imagepath album.artpathif not imagepath log.info u'Noalbumartpresentfor{0}' album returnif not os.path.isfile syspath imagepath log.info u'Albumartnotfoundat{0}for{1}' displayable_path imagepath album returnif maxwidth imagepath resize_image log imagepath maxwidth log.info u'Embeddingalbumartinto{0}' album for item in album.items embed_item log item imagepath maxwidth None compare_threshold ifempty as_album True
def take n iterable return islice iterable n
def complete_rules rules cmd if not isinstance rules list rules [rules]ret []for r in rules ret + complete_rule r cmd return ret
def mesh_edges tris if np.max tris > len np.unique tris raise ValueError 'Cannotcomputeconnectivityonaselectionoftriangles.' npoints np.max tris + 1 ones_ntris np.ones 3 * len tris a b c tris.Tx np.concatenate a b c y np.concatenate b c a edges coo_matrix ones_ntris x y shape npoints npoints edges edges.tocsr edges edges + edges.T return edges
def div_roundup a b return int a + int b - 1 // int b
def shi i base '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz' s []while i > 0 i r divmod i len base s.append base[r] return ''.join reversed s
def survey_buildQuestionnaireFromTemplate template_id questions survey_getAllQuestionsForTemplate template_id return buildQuestionsForm questions readOnly True
def token_to_cms signed_text copy_of_text signed_text.replace '-' '/' lines ['-----BEGINCMS-----']lines + [copy_of_text[n n + 64 ] for n in range 0 len copy_of_text 64 ]lines.append '-----ENDCMS-----\n' return '\n'.join lines
def col_create fid body url build_url RESOURCE id fid route 'col' return request 'post' url json body
def build_absolute_uri host_url path None path path or '' if path.startswith 'http //' or path.startswith 'https //' return pathif host_url.endswith '/' and path.startswith '/' path path[1 ]return host_url + path
def get_vnc_port session min_port CONF.vmware.vnc_portport_total CONF.vmware.vnc_port_totalallocated_ports _get_allocated_vnc_ports session max_port min_port + port_total for port in range min_port max_port if port not in allocated_ports return portraise exception.ConsolePortRangeExhausted min_port min_port max_port max_port
def ignore_error error e_type e_value e_tb errorreturn issubclass e_type socket.error and e_value[0] in errno.ECONNRESET errno.EPIPE
def init mpstate return CmdlongModule mpstate
def inspect_stack return {'co_name' inspect.stack [1][3]}
def indicator return s3_rest_controller
def init_handler resource event trigger agent None global TRUNK_SKELETONmanager trunk_manager.TrunkManager agent.int_br handler ovsdb_handler.OVSDBHandler manager TRUNK_SKELETON OVSTrunkSkeleton handler
def getDescriptionCarve lines descriptionCarve ''layerThicknessString getSettingString lines 'carve' 'LayerHeight' if layerThicknessString ! None descriptionCarve + layerThicknessString.replace '.' '' + 'h' edgeWidthString getSettingString lines 'carve' 'EdgeWidthoverHeight' if edgeWidthString ! None descriptionCarve + 'x%sw' % str float edgeWidthString * float layerThicknessString .replace '.' '' return descriptionCarve
def _adjustLoggingFormatter if hasattr FORMATTER '_format' returndef format record message FORMATTER._format record message boldifyMessage message if kb.get 'prependFlag' message '\n%s' % message kb.prependFlag Falsereturn messageFORMATTER._format FORMATTER.formatFORMATTER.format format
def regenerate_certificates request course_key statuses_to_regenerate task_type 'regenerate_certificates_all_student'task_input {}task_input.update {'statuses_to_regenerate' statuses_to_regenerate} task_class generate_certificatestask_key ''instructor_task submit_task request task_type task_class course_key task_input task_key CertificateGenerationHistory.objects.create course_id course_key generated_by request.user instructor_task instructor_task is_regeneration True return instructor_task
def p_rule_empty p p[0] p[1] [[]]
def get_report_data year quarter if ct._check_input year quarter is True ct._write_head df _get_report_data year quarter 1 pd.DataFrame if df is not None df['code'] df['code'].map lambda x str x .zfill 6 return df
def _has_required_boto if not HAS_BOTO return Falseelif LooseVersion boto3.__version__ < LooseVersion required_boto3_version return Falseelse return True
def apply_overwrites_to_context context overwrite_context for variable overwrite in overwrite_context.items if variable not in context continuecontext_value context[variable]if isinstance context_value list if overwrite in context_value context_value.remove overwrite context_value.insert 0 overwrite else context[variable] overwrite
@skipif not has_qt def test_line_profile_rgb plugin setup_line_profile data.chelsea limits None for i in range 6 plugin.line_tool._thicken_scan_line line_image scan_data plugin.output assert_equal line_image[ line_image 128 ].size 750 assert_equal line_image[ line_image 255 ].size 151 assert_equal line_image.shape 300 451 assert_equal scan_data.shape 151 3 assert_allclose scan_data.max 0.772 rtol 0.001 assert_allclose scan_data.mean 0.4359 rtol 0.001
def getglobalui global globaluireturn globalui
def _loc_to_eeg_loc loc if loc[3 6].any return np.array [loc[0 3] loc[3 6]] .Telse return loc[0 3][ np.newaxis].copy
def capture_responder_args req resp resource params resource.captured_req reqresource.captured_resp respresource.captured_kwargs params
def send_translations translation_dict if u'__messages' not in frappe.local.response frappe.local.response[u'__messages'] {}frappe.local.response[u'__messages'].update translation_dict
def get_valid_qos_policy_group_info volume extra_specs None info dict legacy None spec None try volume_type get_volume_type_from_volume volume except KeyError LOG.exception _LE 'CannotgetQoSspecforvolume%s.' volume['id'] return infoif volume_type is None return infoif extra_specs is None extra_specs volume_type.get 'extra_specs' {} info['legacy'] get_legacy_qos_policy extra_specs info['spec'] get_valid_backend_qos_spec_from_volume_type volume volume_type msg 'QoSpolicygroupinfoforvolume% vol s % info s'LOG.debug msg {'vol' volume['name'] 'info' info} check_for_invalid_qos_spec_combination info volume_type return info
def get_configured_provider return config.is_provider_configured __opts__ __active_provider_name__ or __virtualname__ 'user' 'password' 'url'
def first_every_last iterable first every last did_first Falsefor item in iterable if not did_first did_first Truefirst item every item if did_first last item
def tstd_dlldy y df return - df + 1 / df - 2.0 / 1 + y ** 2 / df - 2.0 * y
def random_unicode length 20 def get_char return six.unichr random.randint 32 1000 chars u''.join [get_char for ii in six.moves.range length ] return _join_chars chars length
def getTreeWalker treeType implementation None **kwargs treeType treeType.lower if treeType not in treeWalkerCache if treeType u'dom' from . import domtreeWalkerCache[treeType] dom.TreeWalkerelif treeType u'genshi' from . import genshitreeWalkerCache[treeType] genshi.TreeWalkerelif treeType u'lxml' from . import etree_lxmltreeWalkerCache[treeType] etree_lxml.TreeWalkerelif treeType u'etree' from . import etreeif implementation is None implementation default_etreereturn etree.getETreeModule implementation **kwargs .TreeWalkerreturn treeWalkerCache.get treeType
@pytest.fixture scope 'module' params ['cpu'] def backend_cpu request be get_backend request datatype np.float32 def cleanup be request.getfuncargvalue 'backend_cpu' del berequest.addfinalizer cleanup return be
def test_feature_fr_from_string lang Language 'fr' feature Feature.from_string OUTLINED_FEATURE language lang assert_equals feature.name u'Faireplusieurchosesenm\xeametemps' assert_equals feature.description u"Defa\xe7on\xe0automatiserlestests\nEntantquefain\xe9ant\nJ'utiliselesplansdesc\xe9nario" scenario feature.scenariosassert_equals scenario.name 'Ajouter2nombres' assert_equals scenario.outlines [{u'input_1' u'20' u'input_2' u'30' u'bouton' u'add' u'output' u'50'} {u'input_1' u'2' u'input_2' u'5' u'bouton' u'add' u'output' u'7'} {u'input_1' u'0' u'input_2' u'40' u'bouton' u'add' u'output' u'40'}]
def in6_isaddrllallservers str return inet_pton socket.AF_INET6 'ff02 2' inet_pton socket.AF_INET6 str
def _is_url_naive urlstr url qurl_from_user_input urlstr assert url.isValid if not utils.raises ValueError ipaddress.ip_address urlstr return Trueif not QHostAddress urlstr .isNull return Falsehost url.host return '.' in host and not host.endswith '.'
def getRound value return round value
def update_viewer dataset pv vis_batch rows cols mapback hasattr dataset 'mapback_for_viewer' display_batch dataset.adjust_for_viewer vis_batch if display_batch.ndim 2 display_batch dataset.get_topological_view display_batch if mapback mapped_batch get_mapped_batch dataset vis_batch for i in xrange rows row_start cols * i for j in xrange cols pv.add_patch display_batch[ row_start + j ] rescale False if mapback pv.add_patch mapped_batch[ row_start + j ] rescale False
def libvlc_media_library_new p_instance f _Cfunctions.get 'libvlc_media_library_new' None or _Cfunction 'libvlc_media_library_new' 1 class_result MediaLibrary ctypes.c_void_p Instance return f p_instance
def get_access_flags_string value buff ''for i in ACCESS_FLAGS if i[0] & value i[0] buff + i[1] + '' if buff ! '' return buff[ -1 ]return buff
def _gluster_xml cmd if _get_minor_version < 6 result __salt__['cmd.run'] 'script-q-c"gluster--xml--mode script"' stdin '{0}\n\x04'.format cmd else result __salt__['cmd.run'] 'gluster--xml--mode script' stdin '{0}\n'.format cmd try root ET.fromstring _gluster_output_cleanup result except ET.ParseError raise CommandExecutionError '\n'.join result.splitlines [ -1 ] if _gluster_ok root output root.find 'output' if output is not None log.info 'Glustercall"{0}"succeeded {1}'.format cmd root.find 'output' .text else log.info 'Glustercall"{0}"succeeded'.format cmd else log.error 'Failedglustercall {0} {1}'.format cmd root.find 'opErrstr' .text return root
def pprint_dict_in_order dictionary order None order order or def prettyprint title body print_info '\n{} '.format title.capitalize if not isinstance body str for value_element in value print_info '-' value_element else print_info value keys dictionary.keys for element in order try key keys.pop keys.index element value dictionary[key]except KeyError ValueError passelse prettyprint element value for rest_keys in keys prettyprint rest_keys dictionary[rest_keys]
def MaxPoolUndo images targets grad maxes subsX startX strideX outputsX assert targets.shape images.shape _ConvNet.MaxPoolUndo images.p_mat grad.p_mat maxes.p_mat targets.p_mat subsX startX strideX outputsX
def files_exist comma_sep_fps filenames comma_sep_fps.split ' ' for file in filenames if not exists file return Falsereturn True
@register.filter name 'unix_to_datetime' def unix_to_datetime unixtime return datetime.datetime.fromtimestamp unixtime
def runModuleTestSuite module suite TestSuite [TestLoader .loadTestsFromModule module ] optionflags ELLIPSIS | NORMALIZE_WHITESPACE | REPORT_ONLY_FIRST_FAILURE | IGNORE_EXCEPTION_DETAIL try suite.addTest DocTestSuite module optionflags optionflags except ValueError passTextTestRunner .run suite
def PmfProbEqual pmf1 pmf2 total 0.0for v1 p1 in pmf1.Items for v2 p2 in pmf2.Items if v1 v2 total + p1 * p2 return total
def get_zk_locations_string zk_location_ips return ' ' + str zk.DEFAULT_PORT + ' ' .join zk_location_ips + ' ' + str zk.DEFAULT_PORT
def node_boundary G nbunch1 nbunch2 None nset1 {n for n in nbunch1 if n in G }bdy set chain.from_iterable G[v] for v in nset1 - nset1 if nbunch2 is not None bdy & set nbunch2 return bdy
@pytest.mark.skipif u'notHAS_SCIPY' def test_fit_with_fixed_and_bound_constraints m models.Gaussian1D amplitude 3 mean 4 stddev 1 bounds {u'mean' 4 5 } fixed {u'amplitude' True} x np.linspace 0 10 10 y np.exp - x ** 2 / 2 f fitting.LevMarLSQFitter fitted_1 f m x y assert fitted_1.mean > 4 assert fitted_1.mean < 5 assert fitted_1.amplitude 3.0 m.amplitude.fixed Falsefitted_2 f m x y assert fitted_1.mean > 4 assert fitted_1.mean < 5
def allowed_formats if gprefs[u'auto_add_everything'] allowed AllAllowed else allowed AUTO_ADDED - frozenset gprefs[u'blocked_auto_formats'] return allowed
def is_field_error errors if isinstance errors list tuple for e in errors if isinstance e string_types return Truereturn False
def dict_match d key default None if key in d and '[' not in key return d[key]else for pattern value in iteritems d if fnmatchcase key pattern return valuereturn default
def get_sync_num KEY datetime.date.today cache.add KEY 1 return cache.get KEY
def length value try return len value except ValueError TypeError return ''
@decorator.decoratordef convert_masks_to_RGB f clip *a **k if clip.ismask clip clip.to_RGB return f clip *a **k
def is_all_white line return re.match '^\\s*$' line is not None
def generate_certificates_for_students request course_key student_set None specific_student_id None if student_set task_type 'generate_certificates_student_set'task_input {'student_set' student_set}if student_set 'specific_student' task_type 'generate_certificates_certain_student'if specific_student_id is None raise SpecificStudentIdMissingError 'Attemptedtogeneratecertificateforasinglestudent butnospecificstudentidprovided' task_input.update {'specific_student_id' specific_student_id} else task_type 'generate_certificates_all_student'task_input {}task_class generate_certificatestask_key ''instructor_task submit_task request task_type task_class course_key task_input task_key CertificateGenerationHistory.objects.create course_id course_key generated_by request.user instructor_task instructor_task is_regeneration False return instructor_task
def next_monday dt if dt.weekday 5 return dt + timedelta 2 elif dt.weekday 6 return dt + timedelta 1 return dt
def generateAcceptHeader *elements parts []for element in elements if type element is str qs '1.0'mtype elementelse mtype q elementq float q if q > 1 or q < 0 raise ValueError 'Invalidpreferencefactor %r' % q qs '%0.1f' % q parts.append qs mtype parts.sort chunks []for q mtype in parts if q '1.0' chunks.append mtype else chunks.append '%s;q %s' % mtype q return ' '.join chunks
def _CheckForRemovedContactsReset tester user_id validator tester.validatornotifications validator._RunAsync Notification.RangeQuery validator.client user_id range_desc None limit 1 col_names None scan_forward False invalidate json.loads notifications[0].invalidate removed_contacts_reset 'contacts' in invalidate and 'all' in invalidate['contacts'] and invalidate['contacts']['all'] return removed_contacts_reset
def recommend username users nearest computeNearestNeighbor username users [0][1]recommendations []neighborRatings users[nearest]userRatings users[username]for artist in neighborRatings if not artist in userRatings recommendations.append artist neighborRatings[artist] return sorted recommendations key lambda artistTuple artistTuple[1] reverse True
def notify_about_instance_usage context instance event_suffix network_info None system_metadata None extra_usage_info None host None if not host host CONF.hostif not extra_usage_info extra_usage_info {}usage_info notifications.info_from_instance context instance network_info system_metadata **extra_usage_info notifier_api.notify context 'compute.%s' % host 'compute.instance.%s' % event_suffix notifier_api.INFO usage_info
def is_datetime_arraylike arr if isinstance arr ABCDatetimeIndex return Trueelif isinstance arr np.ndarray ABCSeries return arr.dtype object and lib.infer_dtype arr 'datetime' return getattr arr 'inferred_type' None 'datetime'
def BytesSizer field_number is_repeated is_packed tag_size _TagSize field_number local_VarintSize _VarintSizelocal_len lenassert not is_packed if is_repeated def RepeatedFieldSize value result tag_size * len value for element in value l local_len element result + local_VarintSize l + l return resultreturn RepeatedFieldSizeelse def FieldSize value l local_len value return tag_size + local_VarintSize l + l return FieldSize
def prlsrvctl sub_cmd args None runas None cmd ['prlsrvctl' sub_cmd]if args cmd.extend _normalize_args args return __salt__['cmd.run'] cmd runas runas
def describe_domain domain def clip_attrs items s return clipped_list [a.name for a in items] 1000 total_min 10 total ' total {{}}{} '.format s return OrderedDict [ 'Features' clip_attrs domain.attributes 'features' 'Metaattributes' bool domain.metas and clip_attrs domain.metas 'metaattributes' 'Target' bool domain.class_vars and clip_attrs domain.class_vars 'targetsvariables' ]
def init_ipython_session argv [] auto_symbols False auto_int_to_Integer False import IPythonif V IPython.__version__ > '0.11' if V IPython.__version__ > '1.0' from IPython.terminal import ipappelse from IPython.frontend.terminal import ipappapp ipapp.TerminalIPythonApp app.display_banner Falseapp.initialize argv if auto_symbols readline import_module 'readline' if readline enable_automatic_symbols app if auto_int_to_Integer enable_automatic_int_sympification app return app.shellelse from IPython.Shell import make_IPythonreturn make_IPython argv
def generate_instance table fieldname if table[fieldname].default instance TAG[fieldname] table[fieldname].default else instance TAG[fieldname] return instance
@hook.command 'tell' def tell_cmd text nick db notice conn query text.split '' 1 if len query ! 2 notice conn.config 'command_prefix' + tell_cmd.__doc__ returntarget query[0].lower message query[1].strip sender nickif target sender.lower notice 'Haveyoulookedinamirrorlately?' returnif target.lower conn.nick.lower notice "Invalidnick'{}'.".format target returnif not re.match '^[a-z0-9_|.\\-\\]\\[]*$' target.lower notice "Invalidnick'{}'.".format target returnif count_unread db conn.name target > 10 notice 'Sorry {}hastoomanymessagesqueuedalready.'.format target returnadd_tell db conn.name sender target message notice 'Yourmessagehasbeensaved and{}willbenotifiedoncetheyareactive.'.format target
def _soft_validate_additional_properties validator additional_properties_value instance schema if not validator.is_type instance 'object' or additional_properties_value returnproperties schema.get 'properties' {} patterns '|'.join schema.get 'patternProperties' {} extra_properties set for prop in instance if prop not in properties if patterns if not re.search patterns prop extra_properties.add prop else extra_properties.add prop if not extra_properties returnif patterns error 'Additionalpropertiesarenotallowed %s%sunexpected 'if len extra_properties 1 verb 'was'else verb 'were' yield jsonschema_exc.ValidationError error % ' '.join repr extra for extra in extra_properties verb else for prop in extra_properties del instance[prop]
def flavor_list request try return api.nova.flavor_list request except Exception exceptions.handle request _ 'Unabletoretrieveinstanceflavors.' return []
def is_macports_env env_prefix get_macports_prefix if env_prefix and base_prefix.startswith env_prefix return Truereturn False
def is_super node if getattr node 'name' None 'super' and node.root .name BUILTINS_NAME return Truereturn False
def version_number parser xml_parent data version_number XML.SubElement xml_parent 'org.jvnet.hudson.tools.versionnumber.VersionNumberBuilder' mapping [ 'variable-name' 'environmentVariableName' None 'format-string' 'versionNumberString' None 'skip-failed-builds' 'skipFailedBuilds' False 'display-name' 'useAsBuildDisplayName' False 'start-date' 'projectStartDate' '1970-1-100 00 00.0UTC' 'builds-today' 'oBuildsToday' '-1' 'builds-this-month' 'oBuildsThisMonth' '-1' 'builds-this-year' 'oBuildsThisYear' '-1' 'builds-all-time' 'oBuildsAllTime' '-1' ]convert_mapping_to_xml version_number data mapping fail_required True
def _msg controller message if isinstance controller stem.socket.ControlSocket controller.send message return controller.recv else return controller.msg message
def logger_name_from_path path return _name_from_project_path path None _LOGGER_TEMPLATE
def dfs_postorder_nodes G source None post v for u v d in nx.dfs_labeled_edges G source source if d 'reverse' return post
def match_to_source source *translations first Truebest_crc Nonefor translation in translations if translation is None continueif translation.number_replacement current_string number_replace source.string translation.string current_source number_replace source.string translation.source current_crc crc current_source elif '{num}' in translation.string print u'Warning {num}appearsin%s butnotmarkedfornumberreplacement.Discarding!' % translation continueelse current_string translation.stringcurrent_source translation.sourcecurrent_crc translation.source_crcif translation.fuzzy match Falseelif translation.official match Trueelif current_source match source.string current_source else match current_crc crc source.string if first or match best_string current_stringbest_crc current_crcif match breakfirst Falseif best_crc return source best_crc best_string match else return source None None None
def is_legal_resource_name name if name is None return Falsem RESOURCE_NAME_LEGAL_CHARS_P.match name return m is not None and m.group 0 name and not '//' in name
def angle_axis matrix m np.asanyarray matrix if m.shape[ -2 ] ! 3 3 raise ValueError 'matrixisnot3x3' axis np.zeros m.shape[ -1 ] axis[... 0] m[... 2 1] - m[... 1 2] axis[... 1] m[... 0 2] - m[... 2 0] axis[... 2] m[... 1 0] - m[... 0 1] r np.sqrt axis * axis .sum -1 keepdims True angle np.arctan2 r[... 0] m[... 0 0] + m[... 1 1] + m[... 2 2] - 1.0 return Angle angle u.radian - axis / r
def STOCHF barDs count fastk_period - 2 ** 31 fastd_period - 2 ** 31 fastd_matype 0 ret call_talib_with_hlc barDs count talib.STOCHF fastk_period fastd_period fastd_matype if ret is None ret None None return ret
def _get_modulestore_branch_setting def get_branch_setting '\nFindsandreturnsthebranchsettingbasedontheDjangorequestandtheconfigurationsettings\n'branch Nonehostname get_current_request_hostname if hostname mappings getattr settings 'HOSTNAME_MODULESTORE_DEFAULT_MAPPINGS' None if mappings for key in mappings.iterkeys if re.match key hostname return mappings[key]if branch is None branch getattr settings 'MODULESTORE_BRANCH' None return branchreturn get_branch_setting
def _bool_from_json value field if _not_null value field return value.lower in ['t' 'true' '1']
def _mostfunc lhs func X None fterms [tmp for tmp in lhs.atoms func if not X or X.is_Symbol and X in tmp.free_symbols or not X.is_Symbol and tmp.has X ]if len fterms 1 return fterms[0]elif fterms return max list ordered fterms key lambda x x.count func return None
def isend var dest tag return MPISend dest tag var
def _toset thing if thing is None return set if isinstance thing six.string_types return set thing try return set str x for x in thing except TypeError return set str thing
def tidy_fragment text options None keep_doc False document errors tidy_document text options keep_doc match RE_BODY.search document if match document match.group 1 .strip return document errors else raise ValueError 'tidy_fragmentfailedtoprocesstext'
def circle_perimeter_aa r c radius shape None return _circle_perimeter_aa r c radius shape
def is_my_process pid pid_existence pid_exists pid if not psutil or not pid_existence return pid_existenceif Platform.is_windows return Trueelse try command psutil.Process pid .cmdline or [] except psutil.Error return Falseexec_name os.path.basename inspect.stack [ -1 ][1] .lower return len command > 1 and exec_name in command[1].lower
def install_os name **kwargs ret {'name' name 'changes' {} 'result' True 'comment' ''}ret['changes'] __salt__['junos.install_os'] name **kwargs return ret
def has_vary_header response header_query if not response.has_header u'Vary' return Falsevary_headers cc_delim_re.split response[u'Vary'] existing_headers set [header.lower for header in vary_headers] return header_query.lower in existing_headers
def create_tree base_dir files mode 511 verbose 1 dry_run 0 need_dir {}for file in files need_dir[os.path.join base_dir os.path.dirname file ] 1need_dirs need_dir.keys need_dirs.sort for dir in need_dirs mkpath dir mode verbose verbose dry_run dry_run
def parse_options_header value def _tokenize string for match in _option_header_piece_re.finditer string key value match.groups key unquote_header_value key if value is not None value unquote_header_value value key 'filename' yield key value if not value return '' {} parts _tokenize ';' + value name parts.next [0]extra dict parts return name extra
def maybe_download filename work_directory if not os.path.exists work_directory os.mkdir work_directory filepath os.path.join work_directory filename if not os.path.exists filepath filepath _ urllib.request.urlretrieve SOURCE_URL + filename filepath statinfo os.stat filepath print 'Succesfullydownloaded' filename statinfo.st_size 'bytes.' return filepath
def make_overload_method_template typ attr overload_func return make_overload_attribute_template typ attr overload_func base _OverloadMethodTemplate
def match_template_filename project filename ext os.path.splitext os.path.basename filename [1][1 ]if ext in project.filetype_tool.template_extensions if ext not in project.filetype_tool.filetype_extensions return Trueelif not find_lang_postfix project filename return Truereturn False
def neuralnet cls NeuralNetBase.subclasses[cls.__name__] clsreturn cls
def get_default_yarncluster global MR_NAME_CACHEtry return conf.YARN_CLUSTERS[MR_NAME_CACHE]except KeyError return get_yarn
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def snmp_get_oid a_device oid '.1.3.6.1.2.1.1.1.0' display_errors False a_host community_string snmp_port a_devicesnmp_target a_host snmp_port cmd_gen cmdgen.CommandGenerator error_detected error_status error_index snmp_data cmd_gen.getCmd cmdgen.CommunityData community_string cmdgen.UdpTransportTarget snmp_target oid lookupNames True lookupValues True if not error_detected return snmp_dataelse if display_errors print 'ERRORDETECTED ' print '%-16s%-60s' % 'error_message' error_detected print '%-16s%-60s' % 'error_status' error_status print '%-16s%-60s' % 'error_index' error_index return None
def register_stanza_plugin stanza plugin iterable False overrides False tag u'{%s}%s' % plugin.namespace plugin.name plugin_info u'plugin_attrib_map' u'plugin_tag_map' u'plugin_iterables' u'plugin_overrides' for attr in plugin_info info getattr stanza attr setattr stanza attr info.copy stanza.plugin_attrib_map[plugin.plugin_attrib] pluginstanza.plugin_tag_map[tag] pluginif iterable stanza.plugin_iterables.add plugin if plugin.plugin_multi_attrib multiplugin multifactory plugin plugin.plugin_multi_attrib register_stanza_plugin stanza multiplugin if overrides for interface in plugin.overrides stanza.plugin_overrides[interface] plugin.plugin_attrib
def get_violations_reports violations_type violations_files []for subdir _dirs files in os.walk os.path.join Env.REPORT_DIR for f in files if f '{violations_type}.report'.format violations_type violations_type violations_files.append os.path.join subdir f return violations_files
def to_bytestring_tuple *x return tuple imap to_bytestring x
def python_major result sys.version_info[0]return result
def get_notifier publisher_id return NOTIFIER.prepare publisher_id publisher_id
def divide_to_width desired_chunks max_width chunks []for c in desired_chunks nb_divides int np.ceil c / max_width for i in range nb_divides n c // nb_divides - i chunks.append n c - nassert c 0 return tuple chunks
def emit_options options return ' '.join '%s %s' % k v for k v in options.items
def toplevel_wrapper *args **kwargs return ndb.toplevel *args **kwargs
def libvlc_media_list_event_manager p_ml f _Cfunctions.get 'libvlc_media_list_event_manager' None or _Cfunction 'libvlc_media_list_event_manager' 1 class_result EventManager ctypes.c_void_p MediaList return f p_ml
def tb_lineno tb return tb.tb_lineno
def initialize db.configure_db
def homogeneity_score labels_true labels_pred return homogeneity_completeness_v_measure labels_true labels_pred [0]
def p_definition_type p p[0] p[1]
def mkfs os_type fs_label target run_as_root True specified_fs None mkfs_command _MKFS_COMMAND.get os_type _DEFAULT_MKFS_COMMAND or '' % {'fs_label' fs_label 'target' target} if mkfs_command utils.execute run_as_root run_as_root *mkfs_command.split else if not specified_fs specified_fs CONF.default_ephemeral_formatif not specified_fs specified_fs _DEFAULT_FS_BY_OSTYPE.get os_type _DEFAULT_FILE_SYSTEM utils.mkfs specified_fs target fs_label run_as_root run_as_root
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def _timeitlike_time_format time_seconds precision 3 usec time_seconds * 1000000.0 if usec < 1000 return '%.*gusec' % precision usec else msec usec / 1000 if msec < 1000 return '%.*gmsec' % precision msec else sec msec / 1000 return '%.*gsec' % precision sec
def worker_get_all context until None db_filters None **filters return IMPL.worker_get_all context until until db_filters db_filters **filters
def prefix handlers default None error 'Therequestedprefixdoesnotmatchanyofthoseallowed' def output_type data request response path request.pathhandler defaultfor prefix_test prefix_handler in handlers.items if path.startswith prefix_test handler prefix_handlerbreakif not handler raise falcon.HTTPNotAcceptable error response.content_type handler.content_typereturn handler data request request response response output_type.__doc__ 'Supportsanyofthefollowingformats {0}'.format ' '.join function.__doc__ for function in handlers.values output_type.content_type ' '.join handlers.keys return output_type
def dmp_diff f m u K if not u return dup_diff f m K if m < 0 return fn dmp_degree f u if n < m return dmp_zero u deriv v [] u - 1 if m 1 for coeff in f[ - m ] deriv.append dmp_mul_ground coeff K n v K n - 1else for coeff in f[ - m ] k nfor i in range n - 1 n - m -1 k * ideriv.append dmp_mul_ground coeff K k v K n - 1return dmp_strip deriv u
def _check_precision_matrix precision covariance_type if not np.allclose precision precision.T and np.all linalg.eigvalsh precision > 0.0 raise ValueError "'%sprecision'shouldbesymmetric positive-definite" % covariance_type
def update_server_info repo repo._put_named_file os.path.join 'info' 'refs' ''.join generate_info_refs repo repo._put_named_file os.path.join 'objects' 'info' 'packs' ''.join generate_objects_info_packs repo
def findAround pic pat xy None r None if xy and r h w pat.shape[ 2] x y xypic pic[ y - r y + h + r x - r x + w + r ]matches cv2.matchTemplate pat pic cv2.TM_CCOEFF_NORMED yf xf np.unravel_index matches.argmax matches.shape return x - r + xf y - r + yf if xy and r else xf yf
def _iexp x M L 8 R _nbits x << L // M T - int -10 * len str M // 3 * L y _div_nearest x T Mshift M << R for i in range T - 1 0 -1 y _div_nearest x * Mshift + y Mshift * i for k in range R - 1 -1 -1 Mshift M << k + 2 y _div_nearest y * y + Mshift Mshift return M + y
def technical_500_response request exc_type exc_value tb reporter ExceptionReporter request exc_type exc_value tb html reporter.get_traceback_html return HttpResponseServerError html mimetype 'text/html'
@then u'itshouldfailbecause"{reason}"' def then_it_should_fail_because context reason assert False 'FAILED %s' % reason
def get_default_group_type name CONF.default_group_typegrp_type {}if name is not None ctxt context.get_admin_context try grp_type get_group_type_by_name ctxt name except exception.GroupTypeNotFoundByName LOG.exception _LE 'Defaultgrouptypeisnotfound.Pleasecheckdefault_group_typeconfig.' return grp_type
def do_send_confirmation_email invitee referrer subject_template_path 'confirmation/invite_email_subject.txt'body_template_path 'confirmation/invite_email_body.txt'context {'referrer' referrer 'support_email' settings.ZULIP_ADMINISTRATOR 'verbose_support_offers' settings.VERBOSE_SUPPORT_OFFERS}if referrer.realm.is_zephyr_mirror_realm subject_template_path 'confirmation/mituser_invite_email_subject.txt'body_template_path 'confirmation/mituser_invite_email_body.txt'Confirmation.objects.send_confirmation invitee invitee.email additional_context context subject_template_path subject_template_path body_template_path body_template_path host referrer.realm.host
def add_deprecated_argument add_argument argument_name nargs class ShowWarning argparse.Action 'Actiontologawarningwhenanargumentisused.'def __call__ self unused1 unused2 unused3 option_string None sys.stderr.write 'Useof{0}isdeprecated.\n'.format option_string configargparse.ACTION_TYPES_THAT_DONT_NEED_A_VALUE.add ShowWarning add_argument argument_name action ShowWarning help argparse.SUPPRESS nargs nargs
def get_mandlebrot_escape_values width height x_vals np.linspace -3 2 width y_vals np.linspace -1.5 1.5 height grid np.meshgrid x_vals y_vals v_get_num_escape_turns np.vectorize get_num_escape_turns return v_get_num_escape_turns *grid .astype np.float
def proxy_info_from_environment method 'http' if method not in ['http' 'https'] returnenv_var method + '_proxy' url os.environ.get env_var os.environ.get env_var.upper if not url returnpi proxy_info_from_url url method no_proxy os.environ.get 'no_proxy' os.environ.get 'NO_PROXY' '' bypass_hosts []if no_proxy bypass_hosts no_proxy.split ' ' if no_proxy '*' bypass_hosts AllHostspi.bypass_hosts bypass_hostsreturn pi
def group_type_access_remove context type_id project_id return IMPL.group_type_access_remove context type_id project_id
def npz_to_W_pdf path None regx 'w1pre_[0-9]+\\. npz ' file_list load_file_list path path regx regx for f in file_list W load_npz path f [0]print '%s-->%s' % f f.split '.' [0] + '.pdf' visualize.W W second 10 saveable True name f.split '.' [0] fig_idx 2012
def loop_template_list loop_positions instance instance_type default_template registery {} templates []local_loop_position loop_positions[1]global_loop_position loop_positions[0]instance_string slugify str instance for key in [ '%s-%s' % instance_type instance_string instance_string instance_type 'default'] try templates.append registery[key][global_loop_position] except KeyError passtemplates.append append_position default_template global_loop_position '-' templates.append append_position default_template local_loop_position '_' templates.append default_template return templates
def load_entry_point dist group name return get_distribution dist .load_entry_point group name
def http_response_iterator conn response size chunk response.read size while chunk yield chunk chunk response.read size conn.close
def activity_type_exists activity_type if activity_type in object_id_validators return activity_typeelse raise Invalid '%s %s' % _ 'Notfound' _ 'Activitytype'
def Authenticate opener host user pwd otp_entry request_dict {'username' user 'password' pwd 'otp' otp_entry}req _MakeRequest host '/otp' request_dict return _HandleResponse 'authentication' opener.open req
def get_base_type name return PyObject._get_base_type name
def environment return __proxy__['napalm.call'] 'get_environment' **{}
def shape x return tf.shape x
def _extract_future_flags globs flags 0for fname in __future__.all_feature_names feature globs.get fname None if feature is getattr __future__ fname flags | feature.compiler_flagreturn flags
def isBPFSocket obj return isinstance obj L2bpfListenSocket or isinstance obj L2bpfListenSocket or isinstance obj L3bpfSocket
def csort objs key idxs dict obj i for i obj in enumerate objs return sorted objs key lambda obj key obj idxs[obj]
def row name None dtype None if dtype is None dtype config.floatXtype TensorType dtype True False return type name
def test_list_add a HyList [1 2 3] b HyList [3 4 5] c a + b assert c [1 2 3 3 4 5] assert c.__class__ HyList
def _property_resolver arg try float arg except ValueError return Variable arg .resolveelse return itemgetter arg
def cache_disk seconds 86400 * 5 cache_folder '/tmp' def do_cache function def inner_function *args **kwargs 'Calculateacachekeybasedonthedecoratedmethodsignature\nargs[1]indicatesthedomainoftheinputs wehashondomain!\n'key sha1 str args[1] + str kwargs .encode 'utf-8' .hexdigest filepath os.path.join cache_folder key if os.path.exists filepath modified os.path.getmtime filepath age_seconds time.time - modified if age_seconds < seconds return pickle.load open filepath 'rb' result function *args **kwargs pickle.dump result open filepath 'wb' return resultreturn inner_functionreturn do_cache
def get_results_dir_list pid core_dir_basename pid_dir_dict {}for debugdir_file in glob.glob '/tmp/autotest_results_dir.*' a_pid os.path.splitext debugdir_file [1]results_dir open debugdir_file .read .strip pid_dir_dict[a_pid] os.path.join results_dir core_dir_basename results_dir_list []if pid is not None while pid > 1 if pid in pid_dir_dict results_dir_list.append pid_dir_dict[pid] pid get_parent_pid pid else results_dir_list pid_dir_dict.values return results_dir_list or pid_dir_dict.values or [os.path.join '/tmp' core_dir_basename ]
def _format_counters counters indent ' DCTB ' num_counters sum len counter_to_amount for group counter_to_amount in counters.items message 'Counters %d' % num_counters for group group_counters in sorted counters.items if group_counters message + '\n%s%s' % indent group for counter amount in sorted group_counters.items message + '\n%s%s%s %d' % indent indent counter amount return message
def enforce credentials action target do_raise True init extra {}if do_raise extra.update exc exception.ForbiddenAction action action do_raise do_raise return _ENFORCER.enforce action target credentials **extra
def repeat_elements x rep axis x_shape x.get_shape .as_list try splits tf.split value x num_or_size_splits x_shape[axis] axis axis except TypeError splits tf.split value x num_split x_shape[axis] split_dim axis x_rep [s for s in splits for i in range rep ]return concatenate x_rep axis
def running_service_owners exclude '/dev' '/home' '/media' '/proc' '/run' '/sys/' '/tmp' '/var' error {}if 'pkg.owner' not in __salt__ error['UnsupportedPackageManager'] 'Themoduleforthepackagemanageronthissystemdoesnotsupportlookingupwhichpackage s ownswhichfile s 'if 'file.open_files' not in __salt__ error['UnsupportedFileModule'] 'Thefilemoduleonthissystemdoesnotsupportlookingupopenfilesonthesystem'if error return {'Error' error}ret {}open_files __salt__['file.open_files'] execs __salt__['service.execs'] for path in open_files ignore Falsefor bad_dir in exclude if path.startswith bad_dir ignore Trueif ignore continueif not os.access path os.X_OK continuefor service in execs if path execs[service] pkg __salt__['pkg.owner'] path ret[service] next six.itervalues pkg return ret
def render s context None if context is None context {}t get_env .from_string s return t.render context
def notify_retweet t source t['user']created_at t['created_at']source_user cycle_color source['name'] + color_func c['NOTIFICATION']['source_nick'] '@' + source['screen_name'] notify color_func c['NOTIFICATION']['notify'] 'retweetedyourtweet' date parser.parse created_at clock fallback_humanize date clock color_func c['NOTIFICATION']['clock'] clock meta c['NOTIFY_FORMAT']meta source_user.join meta.split '#source_user' meta notify.join meta.split '#notify' meta clock.join meta.split '#clock' meta emojize meta printNicely '' printNicely meta draw t t['retweeted_status'] noti True
def _append_literal scope text if len text 0 returnscope.append _LiteralText text
def GetRegisteredServerOption clsid optionName keyNameRoot 'CLSID\\%s\\%s' % str clsid str optionName return _get_string keyNameRoot
def _read_header stream decoder strict False name_len stream.read_ushort name stream.read_utf8_string name_len required bool stream.read_uchar data_len stream.read_ulong pos stream.tell data decoder.readElement if strict and pos + data_len ! stream.tell raise pyamf.DecodeError 'Datareadfromstreamdoesnotmatchheaderlength' return name required data
@register.simple_tag takes_context True def simple_tag_without_context_parameter arg return 'Expectedresult'
def p_plist p if len p > 3 p[0] p[1]p[0].append p[3] else p[0] [p[1]]
def reset_vo_warnings from . import converters xmlutilfor module in converters exceptions tree xmlutil if hasattr module u'__warningregistry__' del module.__warningregistry__
def generate_tmp_file_name file_name ext None directory '/tmp/' while True file_name file_name + '-' + time.strftime '%Y%m%d-%H%M%S-' + generate_random_string 4 if ext file_name + '.' + ext file_name os.path.join directory file_name if not os.path.exists file_name breakreturn file_name
def _mark_package_install module base pkg_spec try base.install pkg_spec except dnf.exceptions.MarkingError module.fail_json msg 'Nopackage{}available.'.format pkg_spec
def verify cypher key return gluechops cypher key['e'] key['n'] encrypt_int
def require_super_admin handler def test_super_admin self **kwargs 'Checksiftheuserisloggedinandisasuperadmin.'if not self.user_id self.redirect current_user_services.create_login_url self.request.uri returnif not current_user_services.is_current_user_super_admin raise self.UnauthorizedUserException '%sisnotasuperadminofthisapplication' self.user_id return handler self **kwargs return test_super_admin
def _coerce_indexer_dtype indexer categories l len categories if l < _int8_max return _ensure_int8 indexer elif l < _int16_max return _ensure_int16 indexer elif l < _int32_max return _ensure_int32 indexer return _ensure_int64 indexer
def cmd_param args if len args > 0 wildcard args[0]else wildcard '*'k sorted mestate.mlog.params.keys for p in k if fnmatch.fnmatch str p .upper wildcard.upper print '%-16.16s%f' % str p mestate.mlog.params[p]
def runs_once func @wraps func def decorated *args **kwargs if not hasattr decorated 'return_value' decorated.return_value func *args **kwargs return decorated.return_valuedecorated _wrap_as_new func decorated return serial decorated
def tree_to_stream entries write ord_zero ord '0' bit_mask 7for binsha mode name in entries mode_str ''for i in xrange 6 mode_str bchr mode >> i * 3 & bit_mask + ord_zero + mode_str if byte_ord mode_str[0] ord_zero mode_str mode_str[1 ]if isinstance name text_type name name.encode defenc write ''.join mode_str '' name '\x00' binsha
def str_match arr pat case True flags 0 na np.nan as_indexer False if not case flags | re.IGNORECASEregex re.compile pat flags flags if not as_indexer and regex.groups > 0 warnings.warn 'Infutureversionsofpandas matchwillchangetoalwaysreturnaboolindexer.' FutureWarning stacklevel 3 if as_indexer and regex.groups > 0 warnings.warn 'Thispatternhasmatchgroups.Toactuallygetthegroups usestr.extract.' UserWarning stacklevel 3 if not as_indexer and regex.groups > 0 dtype objectdef f x m regex.match x if m return m.groups else return []else dtype boolf lambda x bool regex.match x return _na_map f arr na dtype dtype
def generate_srt_from_sjson sjson_subs speed output ''equal_len len sjson_subs['start'] len sjson_subs['end'] len sjson_subs['text'] if not equal_len return outputsjson_speed_1 generate_subs speed 1 sjson_subs for i in range len sjson_speed_1['start'] item SubRipItem index i start SubRipTime milliseconds sjson_speed_1['start'][i] end SubRipTime milliseconds sjson_speed_1['end'][i] text sjson_speed_1['text'][i] output + unicode item output + '\n'return output
def get_markup_filter_display_name name get_markup_filter_name return {'textile' u'Textile' 'markdown' u'Markdown' 'restructuredtext' u'reStructuredText'}.get name u'HTML'
def get_user_settings_from_username username user_model user_models.UserSettingsModel.get_by_normalized_username UserSettings.normalize_username username if user_model is None return Noneelse return get_user_settings user_model.id
def wrap text width 70 **kwargs w TextWrapper width width **kwargs return w.wrap text
def hello3 return dict message 'HelloWorld'
def map_reduce inputs mapper reducer collector defaultdict list for input in inputs for key value in mapper input collector[key].append value return [output for key values in collector.iteritems for output in reducer key values ]
def arrswapmid data assert len data % 2 0 ret [''] * len data ret[1 2] data[0 2]ret[0 2] data[1 2]return ret
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
@core_helper@maintain.deprecated 'h.get_facet_titleisdeprecatedin2.0andwillberemoved.' def get_facet_title name config_title config.get 'search.facets.%s.title' % name if config_title return config_titlefacet_titles {'organization' _ 'Organizations' 'groups' _ 'Groups' 'tags' _ 'Tags' 'res_format' _ 'Formats' 'license' _ 'Licenses' }return facet_titles.get name name.capitalize
def get_html_section name datetime time.strftime '%a%b%d%y %H %M %S' return "<h1>{}<spanclass 'timestamp'>{}</h1>".format name datetime
def get_meth_class_inst obj if PY2 return obj.im_selfelse return obj.__self__
def permission_check check def decorator cls cls.check_permission staticmethod check return clsreturn decorator
def wait_lock lk_fn dest wait_timeout 0 if not os.path.exists lk_fn return Falseif not os.path.exists dest time.sleep 1 if not os.path.isfile dest _unlock_cache lk_fn return Falsetimeout Noneif wait_timeout timeout time.time + wait_timeout s_count 0s_size os.stat dest .st_sizewhile True time.sleep 1 if not os.path.exists lk_fn return Falsesize os.stat dest .st_sizeif size s_size s_count + 1if s_count > 3 _unlock_cache lk_fn return Falseelse s_size sizeif timeout if time.time > timeout raise ValueError 'Timeout {0}s for{1} lock {2} elapsed'.format wait_timeout dest lk_fn return False
def _generateModel2 numCategories alpha 0.25 initProb numpy.ones numCategories / numCategories def generatePeakedProbabilities lastIdx numCategories numCategories alpha alpha probs numpy.random.dirichlet alpha [alpha] * numCategories probs[lastIdx] 0.0probs / probs.sum return probsfirstOrder dict for catIdx in range numCategories key str [catIdx] probs generatePeakedProbabilities catIdx firstOrder[key] probssecondOrder dict for firstIdx in range numCategories for secondIdx in range numCategories key str [firstIdx secondIdx] probs generatePeakedProbabilities secondIdx secondOrder[key] probsreturn initProb firstOrder secondOrder None
def getConnectError e if isinstance e Exception args e.argselse args etry number string argsexcept ValueError return ConnectError string e if hasattr socket 'gaierror' and isinstance e socket.gaierror klass UnknownHostErrorelse klass errnoMapping.get number ConnectError return klass number string
def check_if_project_can_be_transfered project new_owner if project.owner is None return {'can_be_updated' False 'reason' ERROR_PROJECT_WITHOUT_OWNER}if project.owner new_owner return True None if project.is_private current_projects new_owner.owned_projects.filter is_private True .count max_projects new_owner.max_private_projectserror_project_exceeded _ "Youcan'thavemoreprivateprojects" current_memberships project.memberships.count max_memberships new_owner.max_memberships_private_projectserror_memberships_exceeded _ 'Thisprojectreachesyourcurrentlimitofmembershipsforprivateprojects' else current_projects new_owner.owned_projects.filter is_private False .count max_projects new_owner.max_public_projectserror_project_exceeded _ "Youcan'thavemorepublicprojects" current_memberships project.memberships.count max_memberships new_owner.max_memberships_public_projectserror_memberships_exceeded _ 'Thisprojectreachesyourcurrentlimitofmembershipsforpublicprojects' if max_projects is not None and current_projects > max_projects return False error_project_exceeded if max_memberships is not None and current_memberships > max_memberships return False error_memberships_exceeded return True None
def _ch_neighbor_connectivity ch_names neighbors if len ch_names ! len neighbors raise ValueError '`ch_names`and`neighbors`musthavethesamelength' set_neighbors set [c for d in neighbors for c in d] rest set ch_names - set_neighbors if len rest > 0 raise ValueError 'Someofyourneighborsarenotpresentinthelistofchannelnames' for neigh in neighbors if not isinstance neigh list and not all isinstance c string_types for c in neigh raise ValueError '`neighbors`mustbealistoflistsofstr' ch_connectivity np.eye len ch_names dtype bool for ii neigbs in enumerate neighbors ch_connectivity[ ii [ch_names.index i for i in neigbs] ] Truech_connectivity sparse.csr_matrix ch_connectivity return ch_connectivity
def filename2pathlist path skipfirst False h pathl []while True h t os.path.split h if h '' and t '' breakif h '' and skipfirst continueif t ! '' l.append t l.reverse return l
def convert_EmailProperty model prop kwargs kwargs['validators'].append validators.email return get_TextField kwargs
def solution return s3_rest_controller
def remove_key kwargs None call None if call ! 'function' log.error 'Thecreate_keyfunctionmustbecalledwith-for--function.' return Falsetry result query method 'account' command 'keys/' + kwargs['id'] http_method 'delete' except KeyError log.info '`id`argumentmustbespecified' return Falsereturn result
def strand s1 s2 return ''.join map lambda x y chr ord x & ord y s1 s2
def mkchi2 k return SelectKBest chi2 k k
def get_ports_and_sgs context port_ids if len port_ids > MAX_PORTS_PER_QUERY LOG.debug 'Numberofports% pcount sexceedsthemaximumperquery% maxp s.Partitioningqueries.' {'pcount' len port_ids 'maxp' MAX_PORTS_PER_QUERY} return get_ports_and_sgs context port_ids[ MAX_PORTS_PER_QUERY] + get_ports_and_sgs context port_ids[MAX_PORTS_PER_QUERY ] LOG.debug 'get_ports_and_sgs calledforport_ids%s' port_ids if not port_ids return []ports_to_sg_ids get_sg_ids_grouped_by_port context port_ids return [make_port_dict_with_security_groups port sec_groups for port sec_groups in six.iteritems ports_to_sg_ids ]
def sci im gci._current im
def _validate_password password username if not isinstance password basestring raise AccountPasswordInvalid u'Passwordmustbeastring' if len password < PASSWORD_MIN_LENGTH raise AccountPasswordInvalid u'Passwordmustbeatleast{min}characterslong'.format min PASSWORD_MIN_LENGTH if len password > PASSWORD_MAX_LENGTH raise AccountPasswordInvalid u'Passwordmustbeatmost{max}characterslong'.format max PASSWORD_MAX_LENGTH if password username raise AccountPasswordInvalid u'Passwordcannotbethesameastheusername'
def convert_datetime obj if not PY2 and isinstance obj bytes bytearray obj obj.decode 'ascii' m DATETIME_RE.match obj if not m return convert_date obj try groups list m.groups groups[ -1 ] _convert_second_fraction groups[ -1 ] return datetime.datetime *[int x for x in groups] except ValueError return convert_date obj
def _url_collapse_path path path_parts path.split '/' head_parts []for part in path_parts[ -1 ] if part '..' head_parts.pop elif part and part ! '.' head_parts.append part if path_parts tail_part path_parts.pop if tail_part if tail_part '..' head_parts.pop tail_part ''elif tail_part '.' tail_part ''else tail_part ''splitpath '/' + '/'.join head_parts tail_part collapsed_path '/'.join splitpath return collapsed_path
def o_tmpfile_supported return all [linkat.available platform.system 'Linux' LooseVersion platform.release > LooseVersion '3.16' ]
def getGeometryOutputCopy object objectClass object.__class__if objectClass dict objectCopy {}for key in object objectCopy[key] getGeometryOutputCopy object[key] return objectCopyif objectClass list objectCopy []for value in object objectCopy.append getGeometryOutputCopy value return objectCopyif objectClass face.Face or objectClass Vector3 or objectClass Vector3Index return object.copy return object
def _level_traverse root get_children Q collections.deque [root] while Q v Q.popleft yield v Q.extend get_children v
def markdown_unescape escaped_text warnings.warn u'reviewboard.reviews.markdown_utils.markdown_unescapeisdeprecated.Pleaseusedjblets.markdown.markdown_unescape.' DeprecationWarning return djblets_markdown.markdown_unescape escaped_text
def _DetermineMustSplitAnnotation node if not _ContainsComments node if sum 1 for ch in node.children if pytree_utils.NodeName ch 'COMMA' < 2 returnif not isinstance node.children[ -1 ] pytree.Leaf or node.children[ -1 ].value ! ' ' returnnum_children len node.children index 0_SetMustSplitOnFirstLeaf node.children[0] while index < num_children - 1 child node.children[index]if isinstance child pytree.Leaf and child.value ' ' next_child node.children[ index + 1 ]if next_child.type grammar_token.COMMENT index + 1if index > num_children - 1 break_SetMustSplitOnFirstLeaf node.children[ index + 1 ] index + 1
def display2classmethod display L display.split '->' return L[0] L[1]
def parse_iscsi rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--ipaddr' dest 'ipaddr' action 'store' parser.add_argument '--port' dest 'port' action 'store' parser.add_argument '--target' dest 'target' action 'store' parser.add_argument '--iface' dest 'iface' action 'store' parser.add_argument '--user' dest 'user' action 'store' parser.add_argument '--password' dest 'password' action 'store' parser.add_argument '--reverse-user' dest 'reverse-user' action 'store' parser.add_argument '--reverse-password' dest 'reverse-password' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
def test_uninstall_rollback script data result script.pip 'install' '-f' data.find_links '--no-index' 'broken 0.1' assert script.site_packages / 'broken.py' in result.files_created list result.files_created.keys result2 script.pip 'install' '-f' data.find_links '--no-index' 'broken 0.2broken' expect_error True assert result2.returncode 1 str result2 assert script.run 'python' '-c' 'importbroken;print broken.VERSION ' .stdout '0.1\n' assert_all_changes result.files_after result2 [ script.venv / 'build' ]
def OpenDocumentTextMaster doc OpenDocument 'application/vnd.oasis.opendocument.text-master' doc.text Text doc.body.addElement doc.text return doc
def outf_writer_compat outfile encoding errors gzip_compress False if compat.PY3 if gzip_compress outf gzip.open outfile 'wt' encoding encoding errors errors else outf open outfile 'w' encoding encoding errors errors writer csv.writer outf else if gzip_compress outf gzip.open outfile 'wb' else outf open outfile 'wb' writer compat.UnicodeWriter outf encoding encoding errors errors return writer outf
@pytest.mark.skipif str u'notHAS_SCIPY' def test_distances_scipy from ...cosmology import WMAP5d4 Distance z 0.23 npt.assert_allclose d4.z 0.23 rtol 1e-08 d5 Distance z 0.23 cosmology WMAP5 npt.assert_allclose d5.compute_z WMAP5 0.23 rtol 1e-08 d6 Distance z 0.23 cosmology WMAP5 unit u.km npt.assert_allclose d6.value 3.5417046898762366e+22
def test_pretty_json test_data {'text' 'text'}assert hug.output_format.pretty_json test_data .decode 'utf8' '{\n"text" "text"\n}'
def _calc_uniform_order_statistic_medians n v np.zeros n dtype np.float64 v[ -1 ] 0.5 ** 1.0 / n v[0] 1 - v[ -1 ] i np.arange 2 n v[1 -1 ] i - 0.3175 / n + 0.365 return v
def addUnitTypeConversion unitLabel mappingFunc if unitLabel in _unit2PixMappings msg 'Theunittypelabel[{0}]isalreadyregisteredwithPsychoPy'raise ValueError msg.format unitLabel _unit2PixMappings[unitLabel] mappingFunc
def split_at_breaks array breaks axis 0 padded_breaks concat [[None] breaks [None]] slices [slice i j for i j in sliding_window 2 padded_breaks ]preslice slice None * axis split_array [array[ preslice + s ] for s in slices]return split_array
def processor_for content_model_or_slug exact_page False content_model Noneslug u''if isinstance content_model_or_slug str _str try parts content_model_or_slug.split u'.' 1 content_model apps.get_model *parts except TypeError ValueError LookupError slug content_model_or_slugelif issubclass content_model_or_slug Page content_model content_model_or_slugelse raise TypeError u'%sisnotavalidargumentforpage_processor whichshouldbeamodelsubclassofPageinclassorstringform app.model oravalidslug' % content_model_or_slug def decorator func parts func exact_page if content_model model_name content_model._meta.object_name.lower processors[model_name].insert 0 parts else processors[ u'slug %s' % slug ].insert 0 parts return funcreturn decorator
def confusion_matrix rater_a rater_b min_rating None max_rating None assert len rater_a len rater_b if min_rating is None min_rating min rater_a + rater_b if max_rating is None max_rating max rater_a + rater_b num_ratings int max_rating - min_rating + 1 conf_mat [[0 for i in range num_ratings ] for j in range num_ratings ]for a b in zip rater_a rater_b conf_mat[ a - min_rating ][ b - min_rating ] + 1return conf_mat
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def markdown text mode '' context '' raw False return gh.markdown text mode context raw
def executePairOperations evaluators operationLevel for negativeIndex in xrange 1 - len evaluators -1 evaluatorIndex negativeIndex + len evaluators evaluators[evaluatorIndex].executePairOperation evaluators evaluatorIndex operationLevel
def GenerateClasspathFile target_list target_dicts toplevel_dir toplevel_build out_name gyp.common.EnsureDirExists out_name result ET.Element 'classpath' def AddElements kind paths rel_paths set for path in paths if os.path.isabs path rel_paths.add os.path.relpath path toplevel_dir else rel_paths.add path for path in sorted rel_paths entry_element ET.SubElement result 'classpathentry' entry_element.set 'kind' kind entry_element.set 'path' path AddElements 'lib' GetJavaJars target_list target_dicts toplevel_dir AddElements 'src' GetJavaSourceDirs target_list target_dicts toplevel_dir AddElements 'con' ['org.eclipse.jdt.launching.JRE_CONTAINER'] AddElements 'output' [os.path.join toplevel_build '.eclipse-java-build' ] ET.ElementTree result .write out_name
def log_rewrite string if params.logging 'debug' logger.debug string elif params.logging 'off' or not params.logging passelif params.logging 'print' print string elif params.logging 'info' logger.info string elif params.logging 'warning' logger.warning string elif params.logging 'error' logger.error string elif params.logging 'critical' logger.critical string else logger.debug string
def set_public_lan lan_id conn get_conn datacenter_id get_datacenter_id try lan conn.get_lan datacenter_id datacenter_id lan_id lan_id if not lan['properties']['public'] conn.update_lan datacenter_id datacenter_id lan_id lan_id public True return lan['id']except Exception lan conn.create_lan datacenter_id LAN public True name 'PublicLAN' return lan['id']
def fix_stride builder slice stride return builder.mul slice.step stride
def test_grouping_structure complete_parser result convert complete_parser groupings result['widgets']assert isinstance groupings dict for name group in groupings.iteritems assert 'command' in group assert 'contents' in group assert isinstance group['contents'] list
def run_http_prompt args bin_path get_http_prompt_path p subprocess.Popen [bin_path] + args stdin PIPE stdout PIPE return p.communicate
def is_unique conn table field rows query conn "\nSELECTinformation_schema.constraint_column_usage.column_name\nFROMinformation_schema.table_constraints\nNATURALJOINinformation_schema.constraint_column_usage\nWHEREinformation_schema.table_constraints.table_name %s\nANDinformation_schema.constraint_column_usage.column_name %s\nANDinformation_schema.table_constraints.constraint_type 'UNIQUE'\n;" table field['column_name'] return rows and True or False
def get_progress_string tag epoch minibatch nbatches cost time blockchar u'\u2588' max_bar_width 20bar_width int float minibatch / nbatches * max_bar_width if isinstance cost np.ndarray s u'Epoch{ <3}[{}|{ <%s}|{ 4}/{ <4}batches {}costs { .2f}s]' % max_bar_width cost u' {} '.format u' '.join '{ .2f}'.format c for c in cost else s u'Epoch{ <3}[{}|{ <%s}|{ 4}/{ <4}batches { .2f}cost { .2f}s]' % max_bar_width return s.format epoch tag blockchar * bar_width minibatch nbatches cost time
def _expand_powers factors new_factors []for factor in factors.args if isinstance factor Pow and isinstance factor.args[1] Integer and factor.args[1] > 0 for n in range factor.args[1] new_factors.append factor.args[0] else new_factors.append factor return new_factors
def random_binomial shape p 0.0 dtype None seed None if dtype is None dtype floatx if seed is None seed np.random.randint 10000000.0 return tf.where tf.random_uniform shape dtype dtype seed seed < p tf.ones shape dtype dtype tf.zeros shape dtype dtype
def ProcessUrl service url for_proxy False if not isinstance url atom.url.Url url atom.url.parse_url url server url.hostssl Falseport 80if not server if hasattr service 'server' server service.serverelse server serviceif not url.protocol and hasattr service 'ssl' ssl service.sslif hasattr service 'port' port service.portelse if url.protocol 'https' ssl Trueelif url.protocol 'http' ssl Falseif url.port port int url.port elif port 80 and ssl port 443return server port ssl url.get_request_uri
def get_standby_timeout scheme None return _get_powercfg_minute_values scheme 'SUB_SLEEP' 'STANDBYIDLE' 'Sleepafter'
@audio_video_fxdef audio_fadein clip duration def fading gf t gft gf t if np.isscalar t factor min 1.0 * t / duration 1 factor np.array [factor factor] else factor np.minimum 1.0 * t / duration 1 factor np.vstack [factor factor] .Treturn factor * gft return clip.fl fading keep_duration True
def generate_all_example_rst app input_dir os.path.abspath app.builder.srcdir try plot_gallery eval app.builder.config.plot_gallery except TypeError plot_gallery bool app.builder.config.plot_gallery for dir_path dir_names file_names in os.walk input_dir if 'build' in dir_path.split os.sep or 'auto_examples' in dir_path.split os.sep continueif 'examples' in dir_names generate_example_rst os.path.join dir_path 'examples' os.path.join dir_path 'auto_examples' plot_gallery plot_gallery
def get_testdata *paths path os.path.join tests_datadir *paths return open path 'rb' .read
@db_api.retry_if_session_inactive def get_quota_usage_by_resource_and_tenant context resource tenant_id lock_for_update False query db_utils.model_query context quota_models.QuotaUsage query query.filter_by resource resource tenant_id tenant_id if lock_for_update query query.with_lockmode 'update' result query.first if not result returnreturn QuotaUsageInfo result.resource result.tenant_id result.in_use result.dirty
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
def pooled_standard_deviation input_variances return sqrt mean square [float i for i in input_variances]
def list_own t rel []next_cursor -1 while next_cursor ! 0 res t.lists.ownerships screen_name g['original_name'] cursor next_cursor rel + res['lists']next_cursor res['next_cursor']if rel print_list rel else printNicely light_magenta 'Youownnolists '
def lstrips text remove return _strips 'l' text remove
def _process_info_installed_output out filter_attrs ret {}name Noneattrs {}attr Nonefor line in salt.utils.itertools.split out '\n' if line and line[0] '' if filter_attrs is None or attr in filter_attrs line line.strip if len attrs[attr] attrs[attr] + '\n'attrs[attr] + linecontinueline line.strip if not line if name ret[name] attrsname Noneattrs {}attr Nonecontinue key value line.split ' ' 1 value value.lstrip attr _convert_to_standard_attr key if attr 'name' name valueelif filter_attrs is None or attr in filter_attrs attrs[attr] valueif name ret[name] attrsreturn ret
def instance_group_members_add context group_uuid members set_delete False return IMPL.instance_group_members_add context group_uuid members set_delete set_delete
def distributed_server_only handler def distributed_server_only_wrapper_fn *args **kwargs if settings.CENTRAL_SERVER raise Http404 _ 'Thispathisonlyavailableondistributedservers.' return handler *args **kwargs return distributed_server_only_wrapper_fn
def add_blank_lines tree blanks_before blanks_between try before blanks_before[tree.tag]between blanks_between[tree.tag]except KeyError for elem in tree if len elem add_blank_lines elem blanks_before blanks_between else last_elem Nonefor elem in tree tag elem.tagif last_elem is not None and last_elem.tag ! tag if tag in before and last_elem is not None e last_elem.getiterator [ -1 ]e.text e.text or '' + '\n' elif tag in between e last_elem.getiterator [ -1 ]e.text e.text or '' + '\n' if len elem add_blank_lines elem blanks_before blanks_between last_elem elem
def _istree obj return isinstance obj nltk.tree.Tree
def get_spectrogram from .utils import check_versionif check_version 'scipy' '0.16.0' from scipy.signal import spectrogramelse spectrogram _spectrogramreturn spectrogram
def check_sampling sampling n if sampling is None sampling 1.0if operator.isNumberType sampling sampling SplitSampling n evaluation_fraction sampling return sampling
def loadMovie theFile movieResRef Qt.OpenMovieFile theFile 1 movie d1 d2 Qt.NewMovieFromFile movieResRef 0 QuickTime.newMovieActive return movie
def get_shortcut context name return CONF.get 'shortcuts' '%s/%s' % context name
def _indent text amount indentation amount * '' return indentation + '\n' + indentation .join text.split '\n'
def _zpool_data grains if salt.utils.is_windows or 'proxyminion' in __opts__ return {}if not salt.utils.which 'zpool' return {}zpool_grains {}for zpool in __salt__['cmd.run'] 'zpoollist-H-oname size' .splitlines zpool zpool.split zpool_grains[zpool[0]] zpool[1]if len zpool_grains.keys < 1 return {}return {'zpool' zpool_grains}
def release_tidy_doc if hasattr thread_local_doc 'doc' tidy.tidyRelease thread_local_doc.doc del thread_local_doc.doc
def user return dict form auth
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def del_attribute instance key state dict_ instance_state instance instance_dict instance state.manager[key].impl.delete state dict_
@require_POST@login_requireddef watch_locale request product None kwargs {'locale' request.LANGUAGE_CODE}if product is not None kwargs['product'] productReviewableRevisionInLocaleEvent.notify request.user **kwargs statsd.incr 'wiki.watches.locale' return HttpResponse
def pyzmq_version_info return version_info
def json_in content_type [ntou 'application/json' ntou 'text/javascript' ] force True debug False processor json_processor request cherrypy.serving.requestif isinstance content_type basestring content_type [content_type]if force if debug cherrypy.log 'Removingbodyprocessors%s' % repr request.body.processors.keys 'TOOLS.JSON_IN' request.body.processors.clear request.body.default_proc cherrypy.HTTPError 415 'Expectedanentityofcontenttype%s' % ' '.join content_type for ct in content_type if debug cherrypy.log 'Addingbodyprocessorfor%s' % ct 'TOOLS.JSON_IN' request.body.processors[ct] processor
def isEllipticCurve kexAlgorithm return _IEllipticCurveExchangeKexAlgorithm.providedBy getKex kexAlgorithm
def _FloatDecoder local_unpack struct.unpackdef InnerDecode buffer pos new_pos pos + 4 float_bytes buffer[pos new_pos]if float_bytes[3] in '\x7f\xff' and float_bytes[2] > '\x80' if float_bytes[0 3] ! '\x00\x00\x80' return _NAN new_pos if float_bytes[3] '\xff' return _NEG_INF new_pos return _POS_INF new_pos result local_unpack '<f' float_bytes [0]return result new_pos return _SimpleDecoder wire_format.WIRETYPE_FIXED32 InnerDecode
def pretty_filesize file_bytes for mod in [u'B' u'KB' u'MB' u'GB' u'TB' u'PB'] if file_bytes < 1024.0 return u'%3.2f%s' % file_bytes mod file_bytes / 1024.0
def _check_cors_origin origin allowed_origins if isinstance allowed_origins list if origin in allowed_origins return originelif allowed_origins '*' return allowed_originselif allowed_origins origin return allowed_origins
def test_sobel_h_mask np.random.seed 0 result filters.sobel_h np.random.uniform size 10 10 np.zeros 10 10 bool assert np.all result 0
def get_script_name environ from google.appengine._internal.django.conf import settingsif settings.FORCE_SCRIPT_NAME is not None return force_unicode settings.FORCE_SCRIPT_NAME script_url environ.get 'SCRIPT_URL' u'' if not script_url script_url environ.get 'REDIRECT_URL' u'' if script_url return force_unicode script_url[ - len environ.get 'PATH_INFO' '' ] return force_unicode environ.get 'SCRIPT_NAME' u''
def get_fallback config value section 'openstack' try return config.get section value except ConfigParser.NoOptionError return False
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u''.join choice chars for x in range length
def report_ports target ports ans unans sr IP dst target / TCP dport ports timeout 5 rep '\\begin{tabular}{|r|l|l|}\n\\hline\n'for s r in ans if not r.haslayer ICMP if r.payload.flags 18 rep + r.sprintf '%TCP.sport%&open&SA\\\\\n' rep + '\\hline\n'for s r in ans if r.haslayer ICMP rep + r.sprintf '%TCPerror.dport%&closed&ICMPtype%ICMP.type%/%ICMP.code%from%IP.src%\\\\\n' elif r.payload.flags ! 18 rep + r.sprintf '%TCP.sport%&closed&TCP%TCP.flags%\\\\\n' rep + '\\hline\n'for i in unans rep + i.sprintf '%TCP.dport%&?&unanswered\\\\\n' rep + '\\hline\n\\end{tabular}\n'return rep
def _save method def save_wrapper self *args **kwargs self.__doc__ method.__doc__ret method self *args **kwargs self._save_tree return retreturn update_wrapper save_wrapper method
def iterate_structure structure iterations origin None structure numpy.asarray structure if iterations < 2 return structure.copy ni iterations - 1 shape [ ii + ni * ii - 1 for ii in structure.shape]pos [ ni * structure.shape[ii] // 2 for ii in range len shape ]slc [slice pos[ii] pos[ii] + structure.shape[ii] None for ii in range len shape ]out numpy.zeros shape bool out[slc] structure ! 0 out binary_dilation out structure iterations ni if origin is None return outelse origin _ni_support._normalize_sequence origin structure.ndim origin [ iterations * o for o in origin]return out origin
def getUntilDot text dotIndex text.rfind '.' if dotIndex < 0 return textreturn text[ dotIndex]
def getitem iterable index default None try return iterable[index]except IndexError return default
def ptb_raw_data data_path None train_path os.path.join data_path 'ptb.train.txt' valid_path os.path.join data_path 'ptb.valid.txt' test_path os.path.join data_path 'ptb.test.txt' word_to_id _build_vocab train_path train_data _file_to_word_ids train_path word_to_id valid_data _file_to_word_ids valid_path word_to_id test_data _file_to_word_ids test_path word_to_id vocabulary len word_to_id return train_data valid_data test_data vocabulary
def onlywhite line for c in line if c is not '' and c is not '' return c is '' return line
def get_path_names return _SCHEME_KEYS
def get_field_size name m field_size_re.search name return int m.group 1 if m else None
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def _root_leastsq func x0 args jac None col_deriv 0 xtol 1.49012e-08 ftol 1.49012e-08 gtol 0.0 maxiter 0 eps 0.0 factor 100 diag None **unknown_options _check_unknown_options unknown_options x cov_x info msg ier leastsq func x0 args args Dfun jac full_output True col_deriv col_deriv xtol xtol ftol ftol gtol gtol maxfev maxiter epsfcn eps factor factor diag diag sol OptimizeResult x x message msg status ier success ier in 1 2 3 4 cov_x cov_x fun info.pop 'fvec' sol.update info return sol
def cache_result default_size settings.AVATAR_DEFAULT_SIZE if not settings.AVATAR_CACHE_ENABLED def decorator func return funcreturn decoratordef decorator func def cached_func user size None prefix func.__name__cached_funcs.add prefix key get_cache_key user size or default_size prefix prefix result cache.get key if result is None result func user size or default_size cache_set key result return resultreturn cached_funcreturn decorator
def set_location node lineno col_offset def _fix node lineno col_offset if 'lineno' in node._attributes node.lineno linenoif 'col_offset' in node._attributes node.col_offset col_offsetfor child in ast.iter_child_nodes node _fix child lineno col_offset _fix node lineno col_offset return node
def dict_merge a b result dict **b for key value in a.items if isinstance value collections.Mapping value dict_merge value result.setdefault key {} result[key] valuereturn result
def ensure_user_exists keystone user_name password email tenant_name check_mode try user get_user keystone user_name except KeyError passelse return False user.id if check_mode return True None tenant get_tenant keystone tenant_name user keystone.users.create name user_name password password email email tenant_id tenant.id return True user.id
def salt_api import salt.utils.processsalt.utils.process.notify_systemd import salt.cli.apisapi salt.cli.api.SaltAPI sapi.start
def _cast_object x x _cast_none x if isinstance x six.string_types try return json.loads x except return ast.literal_eval x else return x
def _visible_to_nonstaff_users descriptor return VisibilityError if descriptor.visible_to_staff_only else ACCESS_GRANTED
def get_keywords git_refnames '$Format %d$'git_full '$Format %H$'keywords {'refnames' git_refnames 'full' git_full}return keywords
def mmwrite target a comment '' field None precision None symmetry None MMFile .write target a comment field precision symmetry
def use_c_pointer x threadstate savethread x + 1restorethread threadstate return x
def isRarFile filename archive_regex u' ?P<file>^ ?P<base> ? ?!\\.part\\d+\\.rar$ . * \\. ? ? part0*1\\. ?rar $ 'if re.search archive_regex filename return Truereturn False
def pythonversion return {'pythonversion' list sys.version_info }
def rec2gtk r formatd None rownum 0 autowin True if formatd is None formatd dict formats []for i name in enumerate r.dtype.names dt r.dtype[name]format formatd.get name if format is None format mlab.defaultformatd.get dt.type mlab.FormatObj format gtkformat_factory format i formatd[name] formatcolheaders r.dtype.namesscroll SortedStringsScrolledWindow colheaders formatd for row in r scroll.add_row row if autowin win gtk.Window win.set_default_size 800 600 win.add scroll win.show_all scroll.win winreturn scroll
def routingAreaUpdateReject a TpPd pd 3 b MessageType mesType 11 c GmmCause d ForceToStandbyAndSpareHalfOctets packet a / b / c / d return packet
def cubic x ax abs asarray x res zeros_like ax cond1 less ax 1 if cond1.any ax1 ax[cond1]res[cond1] 2.0 / 3 - 1.0 / 2 * ax1 ** 2 * 2 - ax1 cond2 ~ cond1 & less ax 2 if cond2.any ax2 ax[cond2]res[cond2] 1.0 / 6 * 2 - ax2 ** 3 return res
def attribute attrib_type def make_decorator *args **kwargs return CustomAttributeDecorator attrib_type *args **kwargs return make_decorator
def is_enabled name current_schedule __salt__['schedule.list'] show_all False return_yaml False if name in current_schedule return current_schedule[name]else return {}
def get_cluster_id_by_name cluster_list cluster_name cluster [c for c in cluster_list if c['clusterName'] cluster_name ][0]return cluster['clusterUuid'] cluster['config']['configBucket']
def gatherTextNodes iNode dounescape 0 joinWith '' gathered []gathered_append gathered.appendslice [iNode]while len slice > 0 c slice.pop 0 if hasattr c 'nodeValue' and c.nodeValue is not None if dounescape val unescape c.nodeValue else val c.nodeValuegathered_append val slice[ 0] c.childNodesreturn joinWith.join gathered
def make_parameter name excess_keyword 0 excess_positional 0 n pynodes.parameter n.append make_object_name name assert not excess_keyword or not excess_positional if excess_keyword n['excess_keyword'] 1if excess_positional n['excess_positional'] 1return n
def getExtraFillLoops loops radius greaterThanRadius 1.4 * radius extraFillLoops []centers intercircle.getCentersFromPoints intercircle.getPointsFromLoops loops greaterThanRadius greaterThanRadius for center in centers inset intercircle.getSimplifiedInsetFromClockwiseLoop center radius if intercircle.isLargeSameDirection inset center radius if euclidean.getIsInFilledRegion loops euclidean.getLeftPoint inset inset.reverse extraFillLoops.append inset return extraFillLoops
def boolean_validator value context if value is missing or value is None return Falseif isinstance value bool return valueif value.lower in ['true' 'yes' 't' 'y' '1'] return Truereturn False
def samestat s1 s2 return s1.st_ino s2.st_ino and s1.st_dev s2.st_dev
def get_unicode_from_response r warnings.warn 'Inrequests3.0 get_unicode_from_responsewillberemoved.Formoreinformation pleaseseethediscussiononissue#2266. Thiswarningshouldonlyappearonce. ' DeprecationWarning tried_encodings []encoding get_encoding_from_headers r.headers if encoding try return str r.content encoding except UnicodeError tried_encodings.append encoding try return str r.content encoding errors 'replace' except TypeError return r.content
def inputhook_glut signal.signal signal.SIGINT glut_int_handler try t clock if glut.glutGetWindow 0 glut.glutSetWindow 1 glutMainLoopEvent return 0while not stdin_ready glutMainLoopEvent used_time clock - t if used_time > 10.0 time.sleep 1.0 elif used_time > 0.1 time.sleep 0.05 else time.sleep 0.001 except KeyboardInterrupt passreturn 0
def get_ssh_gateway_config vm_ ssh_gateway config.get_cloud_config_value 'ssh_gateway' vm_ __opts__ default None search_global False if not isinstance ssh_gateway str return Nonessh_gateway_config {'ssh_gateway' ssh_gateway}ssh_gateway_config['ssh_gateway_port'] config.get_cloud_config_value 'ssh_gateway_port' vm_ __opts__ default None search_global False ssh_gateway_config['ssh_gateway_user'] config.get_cloud_config_value 'ssh_gateway_username' vm_ __opts__ default None search_global False ssh_gateway_config['ssh_gateway_key'] config.get_cloud_config_value 'ssh_gateway_private_key' vm_ __opts__ default None search_global False ssh_gateway_config['ssh_gateway_password'] config.get_cloud_config_value 'ssh_gateway_password' vm_ __opts__ default None search_global False key_filename ssh_gateway_config['ssh_gateway_key']if key_filename is not None and not os.path.isfile key_filename raise SaltCloudConfigError "Thedefinedssh_gateway_private_key'{0}'doesnotexist".format key_filename elif key_filename is None and not ssh_gateway_config['ssh_gateway_password'] raise SaltCloudConfigError 'Noauthenticationmethod.Pleasedefine ssh_gateway_passwordorssh_gateway_private_key' return ssh_gateway_config
def gcf figManager _pylab_helpers.Gcf.get_active if figManager is not None return figManager.canvas.figureelse return figure
def get_redis_from_config settings connection_class StrictRedis if settings.get u'REDIS_URL' is not None return connection_class.from_url settings[u'REDIS_URL'] kwargs {u'host' settings.get u'REDIS_HOST' u'localhost' u'port' settings.get u'REDIS_PORT' 6379 u'db' settings.get u'REDIS_DB' 0 u'password' settings.get u'REDIS_PASSWORD' None }use_ssl settings.get u'REDIS_SSL' False if use_ssl def safeint x try return int x except ValueError return 0version_info tuple safeint x for x in redis.__version__.split u'.' if not version_info > 2 10 raise RuntimeError u'UsingSSLrequiresaredis-pyversion> 2.10' kwargs[u'ssl'] use_sslreturn connection_class **kwargs
def _from_any any_pb klass _TYPE_URL_MAP[any_pb.type_url]return klass.FromString any_pb.value
def get_analysis tex_root if tex_root is None returnelif isinstance tex_root sublime.View tex_root get_tex_root tex_root elif not isinstance tex_root strbase raise ValueError 'tex_rootmustbeastringorview' result cache.cache tex_root 'analysis' lambda analyze_document tex_root return result
def supply_catalog_rheader r if r.representation 'html' catalog r.recordif catalog T current.Ttabs [ T 'EditDetails' None T 'Categories' 'item_category' T 'Items' 'catalog_item' ]rheader_tabs s3_rheader_tabs r tabs table r.tablerheader DIV TABLE TR TH '%s ' % table.name.label catalog.name TR TH '%s ' % table.organisation_id.label table.organisation_id.represent catalog.organisation_id rheader_tabs return rheaderreturn None
def combine_hemi left right lh_data nb.load left .get_data rh_data nb.load right .get_data indices np.vstack 1000000 + np.arange 0 lh_data.shape[0] [ None] 2000000 + np.arange 0 rh_data.shape[0] [ None] all_data np.hstack indices np.vstack lh_data.squeeze rh_data.squeeze filename left.split u'.' [1] + u'_combined.txt' np.savetxt filename all_data fmt u' '.join [u'%d'] + [u'%.10f'] * all_data.shape[1] - 1 return os.path.abspath filename
def no_hyphen_at_end_of_rand_name logical_line filename msg 'T108 hyphenshouldnotbespecifiedattheendofrand_name 'if RAND_NAME_HYPHEN_RE.match logical_line return 0 msg
def _validate_privileges object_type privs privileges if object_type ! 'group' _perms [_PRIVILEGES_MAP[perm] for perm in _PRIVILEGE_TYPE_MAP[object_type]]_perms.append 'ALL' if object_type not in _PRIVILEGES_OBJECTS raise SaltInvocationError 'Invalidobject_type {0}provided'.format object_type if not set privs .issubset set _perms raise SaltInvocationError 'Invalidprivilege s {0}providedforobject{1}'.format privileges object_type elif privileges raise SaltInvocationError 'Theprivilegesoptionshouldnotbesetforobject_typegroup'
def sh_prepare variables export False out []export 'export' if export else '' for k v in variables.items out.append '%s%s %s' % export k sh_string v return ';'.join out
@after.each_scenariodef screenshot_on_error scenario if scenario.failed try output_dir '{}/log'.format settings.TEST_ROOT image_name '{}/{}.png'.format output_dir scenario.name.replace '' '_' world.browser.driver.save_screenshot image_name except WebDriverException LOGGER.error 'Couldnotcaptureascreenshot'
@require_backend 'openstack' def cinderblockdeviceapi_for_test test_case return get_blockdeviceapi_with_cleanup test_case
def init_sigmoid_bias_from_marginals dataset use_y False if use_y X dataset.yelse X dataset.get_design_matrix return init_sigmoid_bias_from_array X
def snuff subprocs for proc in subprocs if proc.poll is None os.kill proc.pid signal.SIGKILL proc.wait
def NewCollection seq cls Collection return pythoncom.WrapObject policy.DefaultPolicy cls seq pythoncom.IID_IDispatch pythoncom.IID_IDispatch
def parse_http_date_safe date try return parse_http_date date except Exception pass
def apk actual predicted k 10 if len predicted > k predicted predicted[ k]score 0.0num_hits 0.0for i p in enumerate predicted if p in actual and p not in predicted[ i] num_hits + 1.0score + num_hits / i + 1.0 if not actual return 0.0return score / min len actual k
def _get_repo_tag image default_tag 'latest' if ' ' in image r_name r_tag image.rsplit ' ' 1 if not r_tag log.warning "Assumingtag'{0}'forrepo'{1}'".format default_tag image r_tag default_tagelse r_name imager_tag default_tagreturn r_name r_tag
def is_complete_edit initial_line original wanted cmds buf original[ ]for cmd in cmds ctype line col char cmdline - initial_lineif ctype 'D' if char ! '\n' buf[line] buf[line][ col] + buf[line][ col + len char ] elif line + 1 < len buf buf[line] buf[line] + buf[ line + 1 ] del buf[ line + 1 ]else del buf[line]elif ctype 'I' buf[line] buf[line][ col] + char + buf[line][col ] buf '\n'.join buf .split '\n' return len buf len wanted and all j k for j k in zip buf wanted
def _HandleLink jobs link title size age season episode flag orgcat cat pp script download star order priority NORMAL_PRIORITY rule 0 if script '' script Noneif pp '' pp Nonejobs[link] {}jobs[link]['title'] titlejobs[link]['url'] linkjobs[link]['cat'] catjobs[link]['pp'] ppjobs[link]['script'] scriptjobs[link]['prio'] str priority jobs[link]['order'] orderjobs[link]['orgcat'] orgcatjobs[link]['size'] sizejobs[link]['age'] agejobs[link]['time'] time.time jobs[link]['rule'] rulejobs[link]['season'] seasonjobs[link]['episode'] episodeif special_rss_site link nzbname Noneelse nzbname titleif download jobs[link]['status'] 'D'jobs[link]['time_downloaded'] time.localtime logging.info 'Adding%s %s toqueue' link title sabnzbd.add_url link pp pp script script cat cat priority priority nzbname nzbname elif star jobs[link]['status'] flag + '*' else jobs[link]['status'] flag
def rebase cwd rev 'master' opts '' user None password None ignore_retcode False cwd _expand_path cwd user opts _format_opts opts if any x for x in opts if x in '-i' '--interactive' raise SaltInvocationError 'Interactiverebasesarenotsupported' command ['git' 'rebase']command.extend opts if not isinstance rev six.string_types rev str rev command.extend salt.utils.shlex_split rev return _git_run command cwd cwd user user password password ignore_retcode ignore_retcode ['stdout']
def test_bootstrap_multiarg x np.vstack [[1 10] for i in range 10 ] y np.vstack [[5 5] for i in range 10 ] test_func lambda x y np.vstack x y .max axis 0 out_actual algo.bootstrap x y n_boot 2 func test_func out_wanted np.array [[5 10] [5 10]] assert_array_equal out_actual out_wanted
def detect_parquet fhandle return parquet._check_header_magic_bytes fhandle
def convert_integer_to_method_list method_int if method_int 0 return []method_map construct_method_map_from_config method_ints []for k v in method_map.items method_ints.append k method_ints.sort reverse True confirmed_methods []for m_int in method_ints if method_int / m_int 1 confirmed_methods.append m_int method_int method_int - m_int methods []for method in confirmed_methods methods.append method_map[method] return methods
def calculate_rms expectedImage actualImage if expectedImage.shape ! actualImage.shape raise ImageComparisonFailure u'imagesizesdonotmatchexpectedsize {0}actualsize{1}'.format expectedImage.shape actualImage.shape num_values expectedImage.sizeabs_diff_image abs expectedImage - actualImage histogram np.bincount abs_diff_image.ravel minlength 256 sum_of_squares np.sum histogram * np.arange len histogram ** 2 rms np.sqrt float sum_of_squares / num_values return rms
def _extract_alignment_region alignment_seq_with_flanking annotation align_stripped alignment_seq_with_flanking.strip '-' display_start int annotation['al_display_start'] if int annotation['al_start'] < int annotation['al_stop'] start int annotation['al_start'] - display_start end int annotation['al_stop'] - display_start + 1 else start display_start - int annotation['al_start'] end display_start - int annotation['al_stop'] + 1 end + align_stripped.count '-' assert 0 < start and start < end and end < len align_stripped 'Problemwithsequencestart/stop \n%s[%i %i]\n%s' % alignment_seq_with_flanking start end annotation return align_stripped[start end]
def test_is_repo_url_for_remote_urls remote_repo_url assert is_repo_url remote_repo_url is True
def e message exit_code None print_log message YELLOW BOLD if exit_code is not None exit exit_code
def test_size_hint view view.show_message usertypes.MessageLevel.info 'test1' height1 view.sizeHint .height assert height1 > 0 view.show_message usertypes.MessageLevel.info 'test2' height2 view.sizeHint .height assert height2 height1 * 2
def get_client_login_token_string http_body for response_line in http_body.splitlines if response_line.startswith 'Auth ' return response_line[5 ]return None
def author_structure user return {'user_id' user.pk 'user_login' user.get_username 'display_name' user.__str__ 'user_email' user.email}
def format_patchsets to_export revs output u'patches' outs []errs []cur_rev to_export[0]cur_master_idx revs.index cur_rev patches_to_export [[cur_rev]]patchset_idx 0for idx rev in enumerate to_export[1 ] try master_idx revs[cur_master_idx ].index rev master_idx + cur_master_idxexcept ValueError master_idx revs.index rev if master_idx cur_master_idx + 1 patches_to_export[patchset_idx].append rev cur_master_idx + 1continueelse patches_to_export.append [rev] cur_master_idx master_idxpatchset_idx + 1status 0for patchset in patches_to_export stat out err export_patchset patchset[0] patchset[ -1 ] output u'patches' n len patchset > 1 thread True patch_with_stat True outs.append out if err errs.append err status max stat status return status u'\n'.join outs u'\n'.join errs
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@with_setup setup_tmpdata teardown_tmpdata def test_download _urlopen_ref datasets.mldata.urlopendatasets.mldata.urlopen mock_mldata_urlopen {'mock' {'label' sp.ones 150 'data' sp.ones 150 4 }} try mock fetch_mldata 'mock' data_home tmpdir for n in ['COL_NAMES' 'DESCR' 'target' 'data'] assert_in n mock assert_equal mock.target.shape 150 assert_equal mock.data.shape 150 4 assert_raises datasets.mldata.HTTPError fetch_mldata 'not_existing_name' finally datasets.mldata.urlopen _urlopen_ref
def _killBackref receiver senderkey receiverkey id receiver receivers_list sendersBack.get receiverkey while senderkey in receivers_list try receivers_list.remove senderkey except breakif not receivers_list try del sendersBack[receiverkey]except KeyError passreturn True
def _auth profile None if profile credentials __salt__['config.option'] profile user credentials['keystone.user']password credentials['keystone.password']tenant credentials['keystone.tenant']auth_url credentials['keystone.auth_url']region_name credentials.get 'keystone.region_name' None service_type credentials['keystone.service_type']else user __salt__['config.option'] 'keystone.user' password __salt__['config.option'] 'keystone.password' tenant __salt__['config.option'] 'keystone.tenant' auth_url __salt__['config.option'] 'keystone.auth_url' region_name __salt__['config.option'] 'keystone.region_name' service_type __salt__['config.option'] 'keystone.service_type' kwargs {'username' user 'password' password 'tenant_name' tenant 'auth_url' auth_url 'region_name' region_name 'service_type' service_type}return suoneu.SaltNeutron **kwargs
def _plot_update_raw_proj params bools if bools is not None inds np.where bools [0]params['info']['projs'] [copy.deepcopy params['projs'][ii] for ii in inds]params['proj_bools'] bools params['projector'] _ setup_proj params['info'] add_eeg_ref False verbose False params['update_fun'] params['plot_fun']
def _reset_module_attempts studentmodule problem_state json.loads studentmodule.state problem_state['attempts'] 0studentmodule.state json.dumps problem_state studentmodule.save
def find_sockfile display None display display or os.environ.get 'DISPLAY' or ' 0.0' if '.' not in display display + '.0'cache_directory get_cache_dir return os.path.join cache_directory SOCKBASE % display
def _mri_subject_has_bem subject subjects_dir None subjects_dir get_subjects_dir subjects_dir raise_error True pattern bem_fname.format subjects_dir subjects_dir subject subject name '*-bem' fnames glob pattern return bool len fnames
def get_hash_value context builder typ value sig typing.signature types.intp typ fn context.get_function hash sig h fn builder value is_ok is_hash_used context builder h fallback ir.Constant h.type FALLBACK return builder.select is_ok h fallback
def libvlc_audio_output_device_list_get p_instance aout f _Cfunctions.get 'libvlc_audio_output_device_list_get' None or _Cfunction 'libvlc_audio_output_device_list_get' 1 1 None ctypes.POINTER AudioOutputDevice Instance ctypes.c_char_p return f p_instance aout
def update_import_job task result result_status ij ImportJob.query.filter_by task task .first if not ij returnij.result resultij.result_status result_statussave_to_db ij 'Importjobupdated'
def replace_entry line fieldn newentry start _find_start_entry line fieldn leng len line[start ].split [0] newline line[ start] + str newentry + line[ start + leng ] return newline
def string2port port_str return struct.unpack '>H' port_str [0]
def site_protected_against_xss_by_csp response allow_unsafe_inline False allow_unsafe_eval False protected Trueif not provides_csp_features response protected Falseelse vulns find_vulns response if CSP_DIRECTIVE_SCRIPT in vulns protected Falseelse if not allow_unsafe_inline and unsafe_inline_enabled response protected Falseif not allow_unsafe_eval and unsafe_eval_enabled response protected Falsereturn protected
@decoratordef rollback_open_connections fn *args **kw try fn *args **kw finally testing_reaper.rollback_all
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def check_discrete_rvs vars vars_ [var for var in vars if not isinstance var pm.model.ObservedRV ]if any [ var.dtype in pm.discrete_types for var in vars_] raise ValueError 'ModelshouldnotincludediscreteRVsforADVI.'
def _localectl_set locale '' locale_params _parse_dbus_locale if HAS_DBUS else _parse_localectl locale_params['LANG'] str locale args ''.join ['{0} "{1}"'.format k v for k v in six.iteritems locale_params ] cmd 'localectlset-locale{0}'.format args return __salt__['cmd.retcode'] cmd python_shell False 0
def get_cast cast_type return CASTS.get cast_type None
def CheckFlowCanBeStartedAsGlobal flow_name flow_cls flow.GRRFlow.GetPlugin flow_name if not flow_cls.ACL_ENFORCED or aff4.issubclass flow_cls flow.GRRGlobalFlow and flow_cls.category return Trueelse raise access_control.UnauthorizedAccess "Flow%scan'tbestartedgloballybynon-suidusers" % flow_name
def SourceTreeAndPathFromPath input_path source_group_match _path_leading_variable.match input_path if source_group_match source_tree source_group_match.group 1 output_path source_group_match.group 3 else source_tree Noneoutput_path input_pathreturn source_tree output_path
def domain_constructor **b_kwargs def deco f def wrapper *args **kwargs if 'name' in b_kwargs _b_kwargs b_kwargselse _b_kwargs dict b_kwargs name f.__name__ f_rval f *args **kwargs domain Domain lambda x x f_rval **_b_kwargs return domainwrapper.__name__ f.__name__return wrapperreturn deco
def _DatastoreExceptionFromCanonicalErrorCodeAndDetail error detail exception_class _CLOUD_DATASTORE_EXCEPTION_CLASSES.get error datastore_errors.InternalError if detail is None return exception_class else return exception_class detail
def entry_from_resource resource client loggers if 'textPayload' in resource return TextEntry.from_api_repr resource client loggers elif 'jsonPayload' in resource return StructEntry.from_api_repr resource client loggers elif 'protoPayload' in resource return ProtobufEntry.from_api_repr resource client loggers raise ValueError 'Cannotparselogentryresource.'
def encode_missing object_hash ts_data ts_meta None ts_ctype None msg '%s%s' % urllib.parse.quote object_hash urllib.parse.quote ts_data.internal if ts_meta and ts_meta ! ts_data delta ts_meta.raw - ts_data.raw msg '%sm %x' % msg delta if ts_ctype and ts_ctype ! ts_data delta ts_ctype.raw - ts_data.raw msg '%s t %x' % msg delta return msg
def exp_safe x if type x is np.ndarray return np.exp np.clip x exp_safe_MIN exp_safe_MAX else return math.exp x
def dmp_revert f g u K if not u return dup_revert f g K else raise MultivariatePolynomialError f g
def check_dna_chars_bcs header mapping_data errors has_barcodes True valid_dna_chars DNASequence.iupac_standard_characters header_fields_to_check []if has_barcodes header_fields_to_check.append 'BarcodeSequence' check_indices []for curr_field in range len header if header[curr_field] in header_fields_to_check check_indices.append curr_field correction_ix 1for curr_data in range len mapping_data for curr_ix in check_indices if len mapping_data[curr_data][curr_ix] 0 errors.append 'MissingexpectedDNAsequence DCTB %d %d' % curr_data + correction_ix curr_ix continuefor curr_nt in mapping_data[curr_data][curr_ix] if curr_nt not in valid_dna_chars errors.append 'InvalidDNAsequencedetected %s DCTB %d %d' % mapping_data[curr_data][curr_ix] curr_data + correction_ix curr_ix continuereturn errors
def test_existing_path_FileLink_repr tf NamedTemporaryFile fl display.FileLink tf.name actual repr fl expected tf.nament.assert_equal actual expected
def normalize_time_unit s s s.lower .strip if s in units return sif s in unit_aliases return unit_aliases[s]if s[ -1 ] 's' return normalize_time_unit s.rstrip 's' raise ValueError 'Donotunderstandtimeunit%s' % s
def libvlc_video_set_format_callbacks mp setup cleanup f _Cfunctions.get 'libvlc_video_set_format_callbacks' None or _Cfunction 'libvlc_video_set_format_callbacks' 1 1 1 None None MediaPlayer VideoFormatCb VideoCleanupCb return f mp setup cleanup
def _is_present name version installed_pkgs pkg_command for pkg in installed_pkgs if 'list' in pkg_command pkg pkg.replace ' ' '' .replace ' ' '' if ' ' in pkg pkg_name pkg_version _ pkg.replace ' ' '' .split '' else pkg_name pkg_version pkg.split '' elif 'freeze' in pkg_command if ' ' in pkg pkg_name pkg_version pkg.split ' ' else continueelse continueif pkg_name name and version is None or version pkg_version return Truereturn False
def _zone_config zones if zones is None zones DEFAULT_ZONESlines [ZONE_HEADER]for entry in zones entry.setdefault 'options' '' entry.setdefault 'in_options' '' entry.setdefault 'out_options' '' lines.append ZONE_FORMAT % entry file '/etc/shorewall/zones' contents ''.join lines use_sudo True
def create_pidlock pidfile pidlock _create_pidlock pidfile atexit.register pidlock.release return pidlock
def detect stream try json.loads stream return Trueexcept ValueError return False
def bilinear_kernel_1D ratio normalize True T theano.tensorhalf_kern T.arange 1 ratio + 1 dtype theano.config.floatX kern T.concatenate [half_kern half_kern[ -2 -1 ]] if normalize kern / ratioreturn kern
def upgrade_bill bill valide_days bill.account_type bill.upgrade_typestart_date datetime.datetime.now expire_date start_date + datetime.timedelta days valide_days bill.start_date start_datebill.expire_date expire_datebill.save
def test_flattener_layer_state_separation_for_softmax soft1 Softmax 5 'sf1' 0.1 soft2 Softmax 5 'sf2' 0.1 mlp MLP layers [FlattenerLayer CompositeLayer 'comp' [soft1 soft2] ] nvis 2 X np.random.rand 20 2 .astype theano.config.floatX y np.random.rand 20 10 .astype theano.config.floatX dataset DenseDesignMatrix X X y y train Train dataset mlp SGD 0.1 batch_size 5 monitoring_dataset dataset train.algorithm.termination_criterion EpochCounter 1 train.main_loop
def process_urls bot trigger urls results []for url in urls if not url.startswith bot.config.url.exclusion_char try url web.iri_to_uri url except passmatched check_callbacks bot trigger url False if matched continuetitle find_title url verify bot.config.core.verify_ssl if title results.append title get_hostname url return results
def slaveof name sentinel_host None sentinel_port None sentinel_password None **connection_args ret {'name' name 'changes' {} 'result' False 'comment' 'Failedtosetupslave'}kwargs copy.copy connection_args sentinel_master __salt__['redis.sentinel_get_master_ip'] name sentinel_host sentinel_port sentinel_password if sentinel_master['master_host'] in __salt__['network.ip_addrs'] ret['result'] Trueret['comment'] 'Minionisthemaster {0}'.format name return retfirst_master __salt__['redis.get_master_ip'] **connection_args if first_master sentinel_master ret['result'] Trueret['comment'] 'Minionalreadyslaveofmaster {0}'.format name return retif __opts__['test'] is True ret['comment'] 'Minionwillbemadeaslaveof{0} {1}'.format name sentinel_master['host'] ret['result'] Nonereturn retkwargs.update **sentinel_master __salt__['redis.slaveof'] **kwargs current_master __salt__['redis.get_master_ip'] **connection_args if current_master ! sentinel_master return retret['result'] Trueret['changes'] {'old' first_master 'new' current_master}ret['comment'] 'Minionsuccessfullyconnectedtomaster {0}'.format name return ret
def dup_to_dict f K None zero False if not f and zero return { 0 K.zero} n result len f - 1 {} for k in range 0 n + 1 if f[ n - k ] result[ k ] f[ n - k ]return result
def wait objects None timeout None count None if objects is None return get_hub .join timeout timeout result []if count is None return list iwait objects timeout for obj in iwait objects objects timeout timeout result.append obj count - 1if count < 0 breakreturn result
def colorize_ansi msg color None style None if color is None and style is None return msgescape_code _get_ansi_code color style if escape_code return '%s%s%s' % escape_code msg ANSI_RESET return msg
@builtin u'Upper-casetext' upper apply_func_to_match_groups def replace_uppercase match number file_name metadata dictionaries data functions *args **kwargs return apply_func_to_match_groups match upper
def submit_row context opts context['opts']change context['change']is_popup context['is_popup']save_as context['save_as']return {'onclick_attrib' opts.get_ordered_objects and change and 'onclick "submitOrderForm ;"' or '' 'show_delete_link' not is_popup and context['has_delete_permission'] and change or context['show_delete'] 'show_save_as_new' not is_popup and change and save_as 'show_save_and_add_another' context['has_add_permission'] and not is_popup and not save_as or context['add'] 'show_save_and_continue' not is_popup and context['has_change_permission'] 'is_popup' is_popup 'show_save' True}
def _find_files root_dir should_include paths []is_module lambda path path.endswith '.py' for dir_path dir_names file_names in os.walk root_dir new_paths [os.path.join dir_path file_name for file_name in file_names]new_paths filter is_module new_paths new_paths filter should_include new_paths paths.extend new_paths return paths
def FormulaRule formula None stopIfTrue None font None border None fill None rule Rule type 'expression' formula formula stopIfTrue stopIfTrue rule.dxf DifferentialStyle font font border border fill fill return rule
def _is_promo_preliminary end_date now datetime.datetime.now g.tz return end_date + datetime.timedelta days 1 > now
def print_datum datum logger.debug ' DCTB WxHxC %sx%sx%s' % datum.width datum.height datum.channels logger.debug ' DCTB Label %s' % datum.label if datum.HasField 'label' else 'None' logger.debug ' DCTB Encoded %s' % datum.encoded
def die s log.error s sys.exit 1
def group_type_specs_delete context group_type_id key return IMPL.group_type_specs_delete context group_type_id key
def cluster_list verbose False cmd [salt.utils.which 'pg_lsclusters' '--no-header']ret __salt__['cmd.run_all'] ''.join [pipes.quote c for c in cmd] if ret.get 'retcode' 0 ! 0 log.error 'Errorlistingclusters' cluster_dict _parse_pg_lscluster ret['stdout'] if verbose return cluster_dictreturn cluster_dict.keys
def list_local cmd 'layman--quietness 1--list-local--nocolor'out __salt__['cmd.run'] cmd python_shell False .split '\n' ret [line.split [1] for line in out if len line.split > 2 ]return ret
def latinify unicode_string default '?' pure_ascii False from unicodedata import nameconverted []for unich in iter unicode_string try ch unich.decode 'ascii' except UnicodeDecodeError what name unich if what in _UNICODE_MAP ch _UNICODE_MAP[what]else what what.split if what[0] 'LATIN' and what[2] 'LETTER' and len what[3] 1 ch what[3].lower if what[1] 'SMALL' else what[3].upper else ch defaultconverted.append chr ord ch return ''.join converted
def saveCalibrationImage i imgset dims if len imgset lastcb imgset[ -1 ].findChessboard dims subpixel False thiscb i.findChessboard dims subpixel False cbmid len lastcb.coordinates / 2 if distance lastcb.coordinates [cbmid] thiscb.coordinates [cbmid] < 30 showText i 'Movethechessboardaroundinsidethegreenrectangle' returnimgset.append i.copy global save_locationif not save_location returnfilename save_location + '_image' + str len imgset + '.png' imgset[ -1 ].save filename
def test_error_wrong_object smote 'rnd'enn 'rnd'smt SMOTEENN smote smote random_state RND_SEED assert_raises ValueError smt.fit X Y smt SMOTEENN enn enn random_state RND_SEED assert_raises ValueError smt.fit X Y
def _exception_data type value traceback sys.exc_info while traceback.tb_next traceback traceback.tb_nextcode traceback.tb_frame.f_codereturn type.__name__ value code.co_filename traceback.tb_lineno code.co_name
def _format_changes changes orchestration False if not changes return False u'' if orchestration return True _nested_changes changes if not isinstance changes dict return True u'InvalidChangesdata {0}'.format changes ret changes.get 'ret' if ret is not None and changes.get 'out' 'highstate' ctext u''changed Falsefor host hostdata in six.iteritems ret s c _format_host host hostdata ctext + u'\n' + u'\n'.join u'' * 14 + l for l in s.splitlines changed changed or c else changed Truectext _nested_changes changes return changed ctext
def parse_events logger line match log_event_pattern.match line if match groups match.groupdict groups.update {'alert_type' alert_types.get groups['alert_type'] '' 'timestamp' calendar.timegm datetime.strptime groups['timestamp'] '%Y-%m-%d%H %M %S' .timetuple 'msg_text' line} return groupselse return None
def test_can_parse_background_and_ignore_tag steps Step.many_from_lines BACKGROUND_WITH_TAGGED_SCENARIO.splitlines steps_without_tags filter lambda x not x.sentence '@wip' steps assert_equals len steps len steps_without_tags
def pair_hmm_align_unaligned_seqs seqs moltype DNA_cogent params {} seqs LoadSeqs data seqs moltype moltype aligned False try s1 s2 seqs.values except ValueError raise ValueError 'Pairwisealigningofseqsrequiresexactlytwoseqs.' try gap_open params['gap_open']except KeyError gap_open 5try gap_extend params['gap_extend']except KeyError gap_extend 2try score_matrix params['score_matrix']except KeyError score_matrix make_dna_scoring_dict match 1 transition -1 transversion -1 return local_pairwise s1 s2 score_matrix gap_open gap_extend
def test_slugify assert slugify u'Helloworld' u'hello-world' assert slugify u'\xbfC\xf3moest\xe1?' u'como-esta'
def get_old_document resource req lookup document version if version ! 'all' and version ! 'diffs' and version is not None try version int version assert version > 0 except ValueError BadRequestKeyError AssertionError abort 400 description debug_error_message 'Documentversionnumbershouldbeanintgreaterthan0' resource_def config.DOMAIN[resource]if versioned_id_field resource_def not in lookup lookup[versioned_id_field resource_def ] lookup[resource_def['id_field']]del lookup[resource_def['id_field']]lookup[config.VERSION] versiondelta app.data.find_one resource + config.VERSIONS req **lookup if not delta abort 404 old_document synthesize_versioned_document document delta resource_def else old_document document.copy return old_document
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def set_proxy_facts facts if 'common' in facts common facts['common']if 'http_proxy' in common or 'https_proxy' in common if 'no_proxy' in common and isinstance common['no_proxy'] string_types common['no_proxy'] common['no_proxy'].split ' ' elif 'no_proxy' not in common common['no_proxy'] []if 'generate_no_proxy_hosts' in common and safe_get_bool common['generate_no_proxy_hosts'] if 'no_proxy_internal_hostnames' in common common['no_proxy'].extend common['no_proxy_internal_hostnames'].split ' ' common['no_proxy'].append '.' + common['dns_domain'] common['no_proxy'].append common['hostname'] common['no_proxy'] sort_unique common['no_proxy'] facts['common'] commonreturn facts
def os_is_running pid if isinstance pid six.string_types pid int pid if HAS_PSUTIL return psutil.pid_exists pid else try os.kill pid 0 return Trueexcept OSError return False
def test_multicolumn_table_html_fill_values col1 [1 2 3]col2 [ 1.0 1.0 2.0 2.0 3.0 3.0 ]col3 [ 'a' 'a' 'a' 'b' 'b' 'b' 'c' 'c' 'c' ]buffer_output StringIO t Table [col1 col2 col3] names 'C1' 'C2' 'C3' ascii.write t buffer_output fill_values 'a' 'z' format 'html' col1 [1 2 3]col2 [ 1.0 1.0 2.0 2.0 3.0 3.0 ]col3 [ 'z' 'z' 'z' 'b' 'b' 'b' 'c' 'c' 'c' ]buffer_expected StringIO t_expected Table [col1 col2 col3] names 'C1' 'C2' 'C3' ascii.write t_expected buffer_expected format 'html' assert buffer_output.getvalue buffer_expected.getvalue
def user_exists username **kwargs if 'database' not in kwargs return Falsereturn len tsql_query query "SELECTnameFROMsysusersWHEREname '{0}'".format username **kwargs 1
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def rollback name ret {'name' name 'changes' {} 'result' True 'comment' ''}ret['changes'] __salt__['junos.rollback'] return ret
def job_file_for job return os.path.join job.expt_dir 'jobs' '%08d.pb' % job.id
def memoize timeout dynamic_timeout False cache {'timeout' timeout}def decorator func def wrapper *args **kwargs start time if not 'time' in cache or start - cache['time'] > cache['timeout'] cache['result'] func *args **kwargs cache['time'] time if dynamic_timeout and cache['time'] - start > cache['timeout'] cache['timeout'] * 2return cache['result']def clear_cache if 'time' in cache del cache['time']if 'result' in cache del cache['result']wrapper.clear_cache clear_cachereturn wrapperreturn decorator
def user_password_update user_id None name None password None profile None **connection_args kstone auth profile **connection_args if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}if _OS_IDENTITY_API_VERSION > 2 kstone.users.update user user_id password password else kstone.users.update_password user user_id password password ret 'PasswordupdatedforuserID{0}'.format user_id if name ret + ' {0} '.format name return ret
def get_taxa taxa_fname sample_ids_kept None taxa_f open taxa_fname 'U' sample_ids otu_ids otu_table lineages parse_otu_table taxa_f count_map_f float remove_empty_rows True if sample_ids_kept sam_idxs [sample_ids.index sam for sam in sample_ids_kept]otu_table otu_table[ sam_idxs]return otu_ids otu_table
def GetWebServer description None description description or '1' path LocateWebServerPath description server LoadWebServer path return server
def findCheckerFactory authType for factory in findCheckerFactories if factory.authType authType return factoryraise InvalidAuthType authType
def _git_str_subprocess gitpath if not os.path.isdir os.path.join gitpath '.git' return Nonetry cid subprocess.check_output ['git' 'describe' '--tags' '--dirty' '--always'] cwd gitpath .decode 'UTF-8' .strip date subprocess.check_output ['git' 'show' '-s' '--format %ci' 'HEAD'] cwd gitpath .decode 'UTF-8' .strip return '{} {} '.format cid date except subprocess.CalledProcessError OSError return None
def private_encrypt key message signer salt.utils.rsax931.RSAX931Signer key.exportKey 'PEM' return signer.sign message
def _ExtractProxy proxy_yaml_key proxy_config_data proxy Nonetry if proxy_yaml_key in proxy_config_data proxy_data proxy_config_data.get proxy_yaml_key original_proxy_keys list proxy_data.keys proxy ProxyConfig.Proxy proxy_data['host'] proxy_data['port'] username proxy_data.get 'username' password proxy_data.get 'password' except KeyError raise googleads.errors.GoogleAdsValueError 'Youryamlfileismissingsomeoftherequiredproxyvalues.Requiredvaluesare %s actualvaluesare%s' % _PROXY_KEYS original_proxy_keys return proxy
def _item_to_dataset iterator resource return Dataset.from_api_repr resource iterator.client
@register.tag 'get_language_info' def do_get_language_info parser token args token.contents.split if len args ! 5 or args[1] ! 'for' or args[3] ! 'as' raise TemplateSyntaxError "'%s'requires'forstringasvariable' got%r " % args[0] args[1 ] return GetLanguageInfoNode args[2] args[4]
@receiver post_delete sender Comment @receiver post_save sender Comment def update_comment_flag sender instance **kwargs for unit in get_related_units instance unit.update_has_comment if instance.language is None unit.translation.invalidate_cache 'sourcecomments'
def updateTwistedVersionInformation baseDirectory now for project in findTwistedProjects baseDirectory project.updateVersion getNextVersion project.getVersion now now
def p_badrule t pass
def _relative_to_abs_sls relative sls levels suffix re.match '^ \\.+ .* $' relative .groups level_count len levels p_comps sls.split '.' if level_count > len p_comps raise SaltRenderError 'Attemptedrelativeincludegoesbeyondtoplevelpackage' return '.'.join p_comps[ - level_count ] + [suffix]
def _extract_volume_info mgz raise_error True try import nibabel as nibexcept ImportError returnheader nib.load mgz .headervol_info dict version header['version']if version 1 version '%s#volumeinfovalid' % version else raise ValueError 'Volumeinfoinvalid.' vol_info['valid'] versionvol_info['filename'] mgzvol_info['volume'] header['dims'][ 3]vol_info['voxelsize'] header['delta'] vol_info['xras'] vol_info['yras'] vol_info['zras'] header['Mdc'].Tvol_info['cras'] header['Pxyz_c']return vol_info
@pytest.mark.parametrize 'funcname test_id' parameters ids ids def test_ctypes_in_func_gen pyi_builder monkeypatch funcname compiled_dylib test_id soname compiled_dylib.basenamesource '\nimportctypes;fromctypesimport*\ndeff \ndefg \nlib %s %% soname r \n' % funcname + _template_ctypes_test + '\ng \nf \n' __monkeypatch_resolveCtypesImports monkeypatch compiled_dylib.dirname pyi_builder.test_source source % locals test_id test_id
def out_and_err command input None shell False env None process Popen command stdout PIPE stdin PIPE stderr PIPE shell shell env env out err process.communicate input input status process.poll if status error CalledProcessError status command error.output outraise errorreturn out err
def GetAvailabilityZones region ec2 _Connect region return [z.name for z in ec2.get_all_zones ]
def gf_sqf_part f p K _ sqf gf_sqf_list f p K g [K.one]for f _ in sqf g gf_mul g f p K return g
def pip_args prefix if sys.platform 'win32' pip_path join prefix 'Scripts' 'pip-script.py' py_path join prefix 'python.exe' else pip_path join prefix 'bin' 'pip' py_path join prefix 'bin' 'python' if isfile pip_path and isfile py_path ret [py_path pip_path]pip_version subprocess.check_output ret + ['-V'] .decode 'utf-8' .split [1]major_ver pip_version.split '.' [0]if int major_ver > 6 ret.append '--disable-pip-version-check' return retelse return None
def version_agnostic children return [child.version_agnostic for child in children]
def learner_name learner return getattr learner 'name' type learner .__name__
def sosfilt sos x axis -1 zi None x np.asarray x sos n_sections _validate_sos sos use_zi zi is not None if use_zi zi np.asarray zi x_zi_shape list x.shape x_zi_shape[axis] 2x_zi_shape tuple [n_sections] + x_zi_shape if zi.shape ! x_zi_shape raise ValueError 'Invalidzishape.Withaxis %r aninputwithshape%r andansosarraywith%dsections zimusthaveshape%r got%r.' % axis x.shape n_sections x_zi_shape zi.shape zf zeros_like zi for section in range n_sections if use_zi x zf[section] lfilter sos[section 3] sos[section 3 ] x axis zi zi[section] else x lfilter sos[section 3] sos[section 3 ] x axis out x zf if use_zi else x return out
@requires_version 'scipy' '0.11' def test_module_nesting proc Popen [sys.executable '-c' run_script] stdout PIPE stderr PIPE stdout stderr proc.communicate if proc.returncode raise AssertionError stdout
def print_header line header_str ' 'header_line header_str * len line print '\n' + header_line print line print header_line
def Str1 s result Seq *tuple map Char s result.str 'Str %s ' % repr s return result
def quote_etag etag weak False if '"' in etag raise ValueError 'invalidetag' etag '"%s"' % etag if weak etag 'W/' + etag return etag
def normal_upper_bound probability mu 0 sigma 1 return inverse_normal_cdf probability mu sigma
def _format_assertmsg obj if py.builtin._istext obj or py.builtin._isbytes obj s objis_repr Falseelse s py.io.saferepr obj is_repr Trueif py.builtin._istext s t py.builtin.textelse t py.builtin.bytess s.replace t '\n' t '\n~' .replace t '%' t '%%' if is_repr s s.replace t '\\n' t '\n~' return s
def requires *dependencies def wrapper self *args **kwargs 'Injecteachdependencyfromtheregistry.'self.__wrapped_init__ *args **kwargs _process_dependencies self def wrapped cls 'Notetherequireddependenciesontheobjectforlaterinjection.\n\nThedependenciesoftheparentclassarecombinedwiththatofthe\nchildclasstocreateanewsetofdependencies.\n\n'existing_dependencies getattr cls '_dependencies' set cls._dependencies existing_dependencies.union dependencies if not hasattr cls '__wrapped_init__' cls.__wrapped_init__ cls.__init__cls.__init__ wrapperreturn clsreturn wrapped
def node return uname .node
def contiguous_regions mask mask np.asarray mask dtype bool if not mask.size return [] idx np.nonzero mask[ -1 ] ! mask[1 ] idx + 1idx idx.tolist if mask[0] idx [0] + idx if mask[ -1 ] idx.append len mask return list zip idx[ 2] idx[1 2]
def appendToBundle bundle oscAddress dataArray bundle.append createBinaryMsg oscAddress dataArray 'b'
def MIDPRICE barDs count timeperiod - 2 ** 31 return call_talib_with_hl barDs count talib.MIDPRICE timeperiod
def all_weighers if CONF.least_cost_functions is not None or CONF.compute_fill_first_cost_fn_weight is not None LOG.deprecated _ 'least_costhasbeendeprecatedinfavoroftheRAMWeigher.' return least_cost.get_least_cost_weighers return HostWeightHandler .get_all_classes
def dummy_limits d nobs nvars d.shape start1 col1 np.nonzero np.diff d axis 0 1 end1 col1_ np.nonzero np.diff d axis 0 -1 cc np.arange nvars if not np.r_[ [0] col1 ] cc .all or not np.r_[ col1_ [ nvars - 1 ] ] cc .all raise ValueError 'dummyvariableisnotsorted' start np.r_[ [0] start1 + 1 ]end np.r_[ end1 + 1 [nobs] ]return start end
def tail_avg timeseries try t timeseries[ -1 ][1] + timeseries[ -2 ][1] + timeseries[ -3 ][1] / 3 return texcept IndexError return timeseries[ -1 ][1]
def parsedotval s if type s is tuple o val sval parse_value val else o val keyvaluesplit s keys o.split u'.' if len keys > 1 r keys[0] {} rcur r[1]for key in keys[1 -1 ] rcur[key] {}rcur rcur[key]rcur[keys[ -1 ]] valreturn relse return o val
def format_number numobj num_format if numobj.national_number 0 and numobj.raw_input is not None if len numobj.raw_input > 0 return numobj.raw_inputcountry_calling_code numobj.country_codensn national_significant_number numobj if num_format PhoneNumberFormat.E164 return _prefix_number_with_country_calling_code country_calling_code num_format nsn if not _has_valid_country_calling_code country_calling_code return nsnregion_code region_code_for_country_code country_calling_code metadata PhoneMetadata.metadata_for_region_or_calling_code country_calling_code region_code.upper formatted_number _format_nsn nsn metadata num_format formatted_number _maybe_append_formatted_extension numobj metadata num_format formatted_number return _prefix_number_with_country_calling_code country_calling_code num_format formatted_number
def _compute_normalized_phase data from scipy.signal import hilbertreturn np.angle hilbert data + np.pi / 2 * np.pi
def val_to_py val if isinstance val collections.Sequence and len val 2 if val[0] 'uuid' return uuid.UUID val[1] elif val[0] 'set' return [val_to_py x for x in val[1]]elif val[0] 'map' return {val_to_py x val_to_py y for x y in val[1]}return val
def _read_data file_obj fo_encoding value_count bit_width vals []if fo_encoding parquet_thrift.Encoding.RLE seen 0while seen < value_count values encoding.read_rle_bit_packed_hybrid file_obj bit_width if values is None breakvals + valuesseen + len values elif fo_encoding parquet_thrift.Encoding.BIT_PACKED raise NotImplementedError u'Bitpackingnotyetsupported' return vals
def _add_unique_id msg unique_id uuid.uuid4 .hexmsg.update {UNIQUE_ID unique_id} LOG.debug _ 'UNIQUE_IDis%s.' % unique_id
def kmz request label model field_name None using DEFAULT_DB_ALIAS return kml request label model field_name compress True using using
def libvlc_audio_output_set p_mi psz_name f _Cfunctions.get 'libvlc_audio_output_set' None or _Cfunction 'libvlc_audio_output_set' 1 1 None ctypes.c_int MediaPlayer ctypes.c_char_p return f p_mi psz_name
def path_string s if isinstance s binary_type return selif isinstance s text_type return s.encode sys.getfilesystemencoding else raise TypeError 'Pathmustberepresentedasbytesorunicodestring'
def project_embed request project_slug project get_object_or_404 Project.objects.protected request.user slug project_slug version project.versions.get slug LATEST files version.imported_files.order_by 'path' return render_to_response 'projects/project_embed.html' {'project' project 'files' files 'settings' {'GROK_API_HOST' settings.GROK_API_HOST 'URI' request.build_absolute_uri location '/' .rstrip '/' }} context_instance RequestContext request
def is_encrypted path if path.startswith '/dev/mapper' return path.rpartition '/' [2].endswith _dmcrypt_suffix else return False
def macosx_sdk_root cflags sysconfig.get_config_var 'CFLAGS' m re.search '-isysroot\\s+ \\S+ ' cflags if m is None sysroot '/'else sysroot m.group 1 return sysroot
def get_avg_purchase_rate serial_nos serial_nos get_valid_serial_nos serial_nos return flt frappe.db.sql u'selectavg purchase_rate from`tabSerialNo`\n DCTB DCTB wherenamein %s ' % u' '.join [u'%s'] * len serial_nos tuple serial_nos [0][0]
def reset_app global bottle_appbottle_app DynamicBottle
def fgraph_of *exprs outs list map theano_code exprs ins theano.gof.graph.inputs outs ins outs theano.gof.graph.clone ins outs return theano.gof.FunctionGraph ins outs
def str_to_unicode s encoding None if not type s str return sif not encoding encoding ENCODINGfor c in [encoding u'utf-8' u'latin-1'] try return s.decode c except UnicodeDecodeError passreturn s.decode encoding u'replace'
def trustRootFromCertificates certificates certs []for cert in certificates if isinstance cert CertBase cert cert.originalelse raise TypeError 'certificatesitemsmustbetwisted.internet.ssl.CertBaseinstances' certs.append cert return OpenSSLCertificateAuthorities certs
def _function_type self if self.decorators for node in self.decorators.nodes if isinstance node CallFunc try current next node.func.infer except InferenceError continue_type _infer_decorator_callchain current if _type is not None return _typetry for infered in node.infer _type _infer_decorator_callchain infered if _type is not None return _typeif not isinstance infered Class continuefor ancestor in infered.ancestors if not isinstance ancestor Class continueif ancestor.is_subtype_of '%s.classmethod' % BUILTINS return 'classmethod'elif ancestor.is_subtype_of '%s.staticmethod' % BUILTINS return 'staticmethod'except InferenceError passreturn self._type
def fixup_indent suite kids suite.children[ -1 ]while kids node kids.pop if node.type token.INDENT breakwhile kids node kids.pop if isinstance node Leaf and node.type ! token.DEDENT if node.prefix node.set_prefix '' returnelse kids.extend node.children[ -1 ]
def _setupSyslog testCase logMessages []class fakesyslogobserver object def __init__ self prefix logMessages.append prefix def emit self eventDict logMessages.append eventDict testCase.patch syslog 'SyslogObserver' fakesyslogobserver return logMessages
def _get_tl_gs_path texpath pdflatex which 'pdflatex' path texpath if pdflatex is None return Nonetlgs_path os.path.normpath os.path.join os.path.dirname pdflatex '..' '..' 'tlpkg' 'tlgs' 'bin' return which 'gswin32c' path tlgs_path or which 'gswin64c' path tlgs_path
def get_build_platform try from sysconfig import get_platformexcept ImportError from distutils.util import get_platformplat get_platform if sys.platform 'darwin' and not plat.startswith 'macosx-' try version _macosx_vers machine os.uname [4].replace '' '_' return 'macosx-%d.%d-%s' % int version[0] int version[1] _macosx_arch machine except ValueError passreturn plat
def regionalize language if not isinstance language basestring return []if '-' in language language region language.split '-' return [ language.lower + '-' + region.upper ]main lambda tag tag in 'ar-AE' 'en-US' 'zh-CN' or tag[ 2] tag[3 ].lower a [ language + '-' + r for r in regions language.lower ]a sorted a key main reverse True return a
def make_request token headers {'Authorization' 'Bearer{}'.format token }conn httplib.HTTPSConnection HOST conn.request 'GET' '/auth/info/googleidtoken' None headers res conn.getresponse conn.close return res.read
def get_db_connection path timeout 30 okay_to_create False try connect_time time.time conn sqlite3.connect path check_same_thread False factory GreenDBConnection timeout timeout if path ! ' memory ' and not okay_to_create stat os.stat path if stat.st_size 0 and stat.st_ctime > connect_time os.unlink path raise DatabaseConnectionError path 'DBfilecreatedbyconnect?' conn.row_factory sqlite3.Rowconn.text_factory strconn.execute 'PRAGMAsynchronous NORMAL' conn.execute 'PRAGMAcount_changes OFF' conn.execute 'PRAGMAtemp_store MEMORY' conn.execute 'PRAGMAjournal_mode DELETE' conn.create_function 'chexor' 3 chexor except sqlite3.DatabaseError import tracebackraise DatabaseConnectionError path traceback.format_exc timeout timeout return conn
def enable_console_debug_logging logger logging.getLogger 'github' logger.setLevel logging.DEBUG logger.addHandler logging.StreamHandler
def reservation_get context uuid return IMPL.reservation_get context uuid
def is_gcs_uri uri try parse_gcs_uri uri return Trueexcept ValueError return False
def get_parent_context liveaction_db context getattr liveaction_db 'context' None if not context return Nonereturn context.get 'parent' None
def model_is_projection model_instance return model_instance._entity and model_instance._entity.is_projection
def reconfigure_vm session vm_ref config_spec reconfig_task session._call_method session.vim 'ReconfigVM_Task' vm_ref spec config_spec session._wait_for_task reconfig_task
def write_html_file out_table outpath page_out PAGE_HTML % 'TaxaSummaries' out_table out open outpath 'w+' out.write page_out out.close
def stddev_from_moving_average timeseries series pandas.Series [x[1] for x in timeseries] expAverage pandas.stats.moments.ewma series com 50 stdDev pandas.stats.moments.ewmstd series com 50 return abs series.iget -1 - expAverage.iget -1 > 3 * stdDev.iget -1
def getPolar angleDegrees radius 1.0 return radius * euclidean.getWiddershinsUnitPolar math.radians angleDegrees
def dict_title prj lang return _ '% language sdictionaryfor% project s' % {'language' lang 'project' prj}
def register linter linter.register_checker ExceptionsChecker linter
def unproxy_object obj if isinstance obj ArrayCollection return list obj elif isinstance obj ObjectProxy return obj._amf_objectreturn obj
def getMeldedPillarOutput loops faces []vertexes getUniqueVertexes loops addMeldedPillarByLoops faces loops return getGeometryOutputByFacesVertexes faces vertexes
@memoizeddef getColor value default None if isinstance value Color return valuevalue str value .strip .lower if value 'transparent' or value 'none' return defaultif value in COLOR_BY_NAME return COLOR_BY_NAME[value]if value.startswith '#' and len value 4 value '#' + value[1] + value[1] + value[2] + value[2] + value[3] + value[3] elif rgb_re.search value r g b [int x for x in rgb_re.search value .groups ]value '#%02x%02x%02x' % r g b else passreturn toColor value default
def connect_kms aws_access_key_id None aws_secret_access_key None **kwargs from boto.kms.layer1 import KMSConnectionreturn KMSConnection aws_access_key_id aws_access_key_id aws_secret_access_key aws_secret_access_key **kwargs
def _ensure_pinned_rows dashboard pinned_row_titles __salt__['pillar.get'] _PINNED_ROWS_PILLAR if not pinned_row_titles returnpinned_row_titles_lower []for title in pinned_row_titles pinned_row_titles_lower.append title.lower rows dashboard.get 'rows' [] pinned_rows []for i row in enumerate rows if row.get 'title' '' .lower in pinned_row_titles_lower del rows[i]pinned_rows.append row rows pinned_rows + rows
def rst_to_html in_rst stderr if not in_rst return u'' 0 orig_sys_exit sys.exitorig_sys_stderr sys.stderrreturncodes []try sys.exit returncodes.appendsys.stderr stderrpp publish_parts in_rst writer_name u'html' settings_overrides dict exit_status_level 2 report_level 2 enable_exit_status True finally sys.exit orig_sys_exitsys.stderr orig_sys_stderrreturn_value u''if u'title' in pp and pp[u'title'] return_value + u'<title>{0}</title>\n<pstyle "font 200%bold">{0}</p>\n'.format pp[u'title'] return_value + pp[u'body'].strip return return_value returncodes.pop if returncodes else 0
def has_arg_scope func key_op func.__module__ func.__name__ return key_op in _DECORATED_OPS
def _address_from_socket sock addr_type sock.recv 1 if addr_type '\x01' ipv4_addr _read_exactly sock 4 return socket.inet_ntoa ipv4_addr elif addr_type '\x04' ipv6_addr _read_exactly sock 16 return socket.inet_ntop socket.AF_INET6 ipv6_addr elif addr_type '\x03' addr_len ord sock.recv 1 return _read_exactly sock addr_len else raise RuntimeError 'Unexpectedaddrtype %r' % addr_type
def makePng img io QtCore.QBuffer qim fn.makeQImage img.transpose 1 0 2 alpha False qim.save io 'PNG' png bytes io.data .data return png
def conv_ch_coupling input_ dim name use_batch_norm True train True weight_norm True reverse False residual_blocks 5 bottleneck False use_aff True change_bottom True skip True if use_aff return conv_ch_aff_coupling input_ input_ dim dim name name use_batch_norm use_batch_norm train train weight_norm weight_norm reverse reverse residual_blocks residual_blocks bottleneck bottleneck change_bottom change_bottom skip skip else return conv_ch_add_coupling input_ input_ dim dim name name use_batch_norm use_batch_norm train train weight_norm weight_norm reverse reverse residual_blocks residual_blocks bottleneck bottleneck change_bottom change_bottom skip skip
def domain_check f symbol p f p sympify f sympify p if p.is_infinite return Falsereturn _domain_check f symbol p
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def matrix_tie_parent registry xml_parent data mtp XML.SubElement xml_parent 'matrixtieparent.BuildWrapperMtp' XML.SubElement mtp 'labelName' .text data['node']
def _strided_from_memmap filename dtype mode offset order shape strides total_buffer_len if mode 'w+' mode 'r+'if strides is None return np.memmap filename dtype dtype shape shape mode mode offset offset order order else base np.memmap filename dtype dtype shape total_buffer_len mode mode offset offset order order return as_strided base shape shape strides strides
def set_displayer config if config.quiet config.noninteractive_mode Truedisplayer display_util.NoninteractiveDisplay open os.devnull 'w' elif config.noninteractive_mode displayer display_util.NoninteractiveDisplay sys.stdout else displayer display_util.FileDisplay sys.stdout config.force_interactive zope.component.provideUtility displayer
def _check_result method_name result if result.status_code ! 200 msg 'TheserverreturnedHTTP{0}{1}.Responsebody \n[{2}]'.format result.status_code result.reason result.text.encode 'utf8' raise ApiException msg method_name result try result_json result.json except msg 'TheserverreturnedaninvalidJSONresponse.Responsebody \n[{0}]'.format result.text.encode 'utf8' raise ApiException msg method_name result if not result_json['ok'] msg 'Errorcode {0}Description {1}'.format result_json['error_code'] result_json['description'] raise ApiException msg method_name result return result_json
@register_useless@register_canonicalize@register_specialize@gof.local_optimizer [Subtensor] def local_useless_slice node if isinstance node.op Subtensor slices get_idx_list node.inputs node.op.idx_list last_slice len slices for s in slices[ -1 ] if isinstance s slice and s.start is None and s.stop is None and s.step is None or T.extract_constant s.step only_process_constants True 1 last_slice - 1else breakif last_slice < len slices subtens Subtensor slices[ last_slice] sl_ins Subtensor.collapse slices[ last_slice] lambda x isinstance x T.Variable out subtens node.inputs[0] *sl_ins copy_stack_trace node.outputs out return [out]
def str_findall arr pat flags 0 regex re.compile pat flags flags return _na_map regex.findall arr
def noise_filter image selem out None mask None shift_x False shift_y False centre_r int selem.shape[0] / 2 + shift_y centre_c int selem.shape[1] / 2 + shift_x selem_cpy selem.copy selem_cpy[ centre_r centre_c ] 0return _apply_scalar_per_pixel generic_cy._noise_filter image selem_cpy out out mask mask shift_x shift_x shift_y shift_y
@_docstring 'recording' def get_recordings_by_puid puid includes [] release_status [] release_type [] warn 'PUIDsupportwasremovedfromtheserver\nandnoPUIDswillbefound 404 ' Warning stacklevel 2 raise ResponseError cause compat.HTTPError None 404 'NotFound' None None
def keepOriginalText s startLoc t try endloc getTokensEndLoc except ParseException raise ParseFatalException 'incorrectusageofkeepOriginalText-mayonlybecalledasaparseaction' del t[ ]t + ParseResults s[startLoc endloc] return t
def setup_stubs config remote_api_stub.ConfigureRemoteApi config.app_id '/' lambda '' '' 'localhost %d' % config.api_port use_remote_datastore False if config.HasField 'cloud_sql_config' sys.modules['google.appengine.api.rdbms'] rdbms_mysqldbgoogle.appengine.api.rdbms rdbms_mysqldbconnect_kwargs dict host config.cloud_sql_config.mysql_host port config.cloud_sql_config.mysql_port user config.cloud_sql_config.mysql_user passwd config.cloud_sql_config.mysql_password if config.cloud_sql_config.mysql_socket connect_kwargs['unix_socket'] config.cloud_sql_config.mysql_socketelif os.name 'posix' and config.cloud_sql_config.mysql_host 'localhost' connect_kwargs['unix_socket'] rdbms_mysqldb.FindUnixSocket rdbms_mysqldb.SetConnectKwargs **connect_kwargs
def draw_texture tex from .program import Programprogram Program vert_draw frag_draw program['u_texture'] texprogram['a_position'] [[ -1.0 -1.0 ] [ -1.0 1.0] [1.0 -1.0 ] [1.0 1.0]]program['a_texcoord'] [[0.0 1.0] [0.0 0.0] [1.0 1.0] [1.0 0.0]]program.draw 'triangle_strip'
def test_pip_show_divider script data script.pip 'install' 'pip-test-package' '--no-index' '-f' data.packages result script.pip 'show' 'pip' 'pip-test-package' lines result.stdout.splitlines assert '---' in lines
def split_company_name_notes name name name.strip notes u''if name.endswith ' ' fpidx name.find ' ' if fpidx ! -1 notes name[fpidx ]name name[ fpidx].rstrip return name notes
def get_user_auth request user request.userprivate_key request.query_params.get 'view_only' None if user.is_anonymous auth Auth None private_key private_key else auth Auth user private_key private_key return auth
@dog_stats_api.timed 'status.service.celery.status' def celery_status _ stats celery.control.inspect .stats or {} return HttpResponse json.dumps stats indent 4 content_type 'application/json'
def getGeometryOutputByFunction manipulationFunction xmlElement geometryOutput []target evaluate.getPathsByKey 'target' xmlElement for path in target geometryOutput + getGeometryOutputByLoopFunction manipulationFunction SideLoop path xmlElement return getUnpackedLoops geometryOutput
def _apply_filters query start end locale None product None if start is None start date.today - timedelta days 90 query query.filter created__gte start if end query query.filter created__lt end if locale query query.filter locale locale if product if isinstance product Product product product.slugquery query.filter product product return query
def download_unsigned request uuid **kwargs extension get_object_or_404 Extension.objects.without_deleted uuid uuid version get_object_or_404 extension.versions.without_deleted pk kwargs['version_id'] def is_author return extension.authors.filter pk request.user.pk .exists def is_reviewer return action_allowed request 'ContentTools' 'AddonReview' if request.user.is_authenticated and is_author or is_reviewer log.info 'Downloadingunsignedadd-on %sversion%sfrom%s' % extension.pk version.pk version.file_path return _download request extension version version.file_path public False else raise PermissionDenied
def EI_empirical samples thresh improvement np.maximum samples - thresh 0 return improvement.mean
def write_fiducials fname pts coord_frame FIFF.FIFFV_COORD_UNKNOWN write_dig fname pts coord_frame
def endjob filename cat status path bytes fail_msg stages script script_output script_ret test None tr sabnzbd.api.Ttemplateif not status and fail_msg xstages {tr 'stage-fail' fail_msg }else xstages {}for stage in stages lines []for line in stages[stage] if '\n' in line or '<br/>' in line lines.extend line.replace '<br/>' '\n' .split '\n' else lines.append line xstages[tr 'stage-' + stage.lower ] linesparm {}parm['status'] statusparm['name'] filenameparm['path'] pathparm['msgid'] ''parm['stages'] xstagesparm['script'] scriptparm['script_output'] script_outputparm['script_ret'] script_retparm['cat'] catparm['size'] '%sB' % to_units bytes parm['end_time'] time.strftime time_format '%Y-%m-%d%H %M %S' time.localtime time.time .decode codepage return send_with_template 'email' parm test
def test_sys_info out StringIO sys_info fid out out out.getvalue assert_true 'numpy ' in out
def relaxed_distance rx_step res ops rx_done [] [] {} for v in tf.trainable_variables if v.name[0 2] 'RX' rx_name v.op.name[ v.name.find '/' + 1 ]if rx_name not in rx_done avg dist_loss relaxed_average rx_name rx_step res.append dist_loss rx_done[rx_name] avgops.append v.assign rx_done[rx_name] return tf.add_n res tf.group *ops
def save filename None family 'ipv4' if _conf and not filename filename _conf family log.debug 'Savingrulesto{0}'.format filename parent_dir os.path.dirname filename if not os.path.isdir parent_dir os.makedirs parent_dir cmd '{0}-save'.format _iptables_cmd family ipt __salt__['cmd.run'] cmd if len _conf_save_filters > 0 ipt _regex_iptables_save ipt out __salt__['file.write'] filename ipt return out
def respond request code redirect request.GET.get 'next' request.POST.get 'next' if redirect return HttpResponseRedirect redirect return type 'Response%d' % code HttpResponse {'status_code' code}
def get_progress opts out progress return salt.loader.raw_mod opts out 'rawmodule' mod 'output' ['{0}.progress_iter'.format out ] progress
def get_object_or_none klass *args **kwargs queryset _get_queryset klass try return queryset.get *args **kwargs except queryset.model.DoesNotExist return None
def _build_publish_data topic qos retain data {ATTR_TOPIC topic}if qos is not None data[ATTR_QOS] qosif retain is not None data[ATTR_RETAIN] retainreturn data
def build_object_spec client_factory root_folder traversal_specs object_spec client_factory.create 'ns0 ObjectSpec' object_spec.obj root_folderobject_spec.skip Falseobject_spec.selectSet traversal_specsreturn object_spec
def fake_upload_image context image instance **kwargs pass
def fermat n if n & 1 0 return [ n >> 1 2]x int sqrt n if x * x n return [x x]x + 1while True y2 x * x - n y int sqrt y2 if y * y y2 breakelse x + 1return [ x - y x + y ]
def extendedMeasurementOrder a L2PseudoLength l2pLength 18 b TpPd pd 6 c MessageType mesType 55 d ExtendedMeasurementFrequencyList packet a / b / c / d return packet
def _find_optimal rlist row_first False separator_size 2 displaywidth 80 for max_rows in range 1 len rlist + 1 col_widths list map max _col_chunks rlist max_rows row_first sumlength sum col_widths ncols len col_widths if sumlength + separator_size * ncols - 1 < displaywidth breakreturn {'num_columns' ncols 'optimal_separator_width' displaywidth - sumlength // ncols - 1 if ncols - 1 else 0 'max_rows' max_rows 'column_widths' col_widths}
def _mk_tree basedir tempfile.mkdtemp return basedir
def _run_horcmshutdown inst result utils.execute 'horcmshutdown.sh' inst return result[0]
def parse_ticket_references text return set JIRA_RE.findall text
def strlist_union a b temp cidict for elt in a temp[elt] eltfor elt in b temp[elt] eltreturn temp.values
def _get_drafts user drafts {'image' None 'video' None}if user.is_authenticated drafts['image'] Image.objects.filter creator user is_draft True drafts['video'] Video.objects.filter creator user is_draft True return drafts
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def CreateSitelinkFeedItem feed_items feed_item_id site_link_from_feed feed_items[feed_item_id]site_link_feed_item {'sitelinkText' site_link_from_feed['text'] 'sitelinkLine2' site_link_from_feed['line2'] 'sitelinkLine3' site_link_from_feed['line3'] 'scheduling' site_link_from_feed['scheduling']}if 'finalUrls' in site_link_from_feed and site_link_from_feed['finalUrls'] site_link_feed_item['sitelinkFinalUrls'] {'urls' site_link_from_feed['finalUrls']}if 'finalMobileUrls' in site_link_from_feed site_link_feed_item['sitelinkFinalMobileUrls'] {'urls' site_link_from_feed['finalMobileUrls']}site_link_feed_item['sitelinkTrackingUrlTemplate'] site_link_from_feed['trackingUrlTemplate']else site_link_feed_item['sitelinkUrl'] site_link_from_feed['url']return site_link_feed_item
def _filter source try varname re.search 'eval\\ \\w+\\ \\w+\\ \\w+ \\ \\ \\ ;' source .group 1 reverse re.search "var+%s*\\ *' .* ';" % varname source .group 1 except AttributeError raise UnpackingError 'MalformedMyObfuscatedata.' try return base64.b64decode reverse[ -1 ].encode 'utf8' .decode 'utf8' except TypeError raise UnpackingError 'MyObfuscatepayloadisnotbase64-encoded.'
def forecast_cov ma_coefs sig_u steps k len sig_u forc_covs np.zeros steps k k prior np.zeros k k for h in range steps phi ma_coefs[h]var chain_dot phi sig_u phi.T forc_covs[h] prior prior + var return forc_covs
def test_ncr_wrong_nn_obj nn 'rnd'ncr NeighbourhoodCleaningRule return_indices True random_state RND_SEED n_neighbors nn assert_raises ValueError ncr.fit_sample X Y
def python_version_tuple if hasattr sys 'version_info' return sys.version_info[ 3]return tuple string.split _sys_version [1] '.'
def pastel colour weight 2.4 rgb np.asarray mcolors.to_rgba colour [ 3] maxc max rgb if maxc < 1.0 and maxc > 0 scale 1.0 / maxc rgb rgb * scale total rgb.sum slack 0for x in rgb slack + 1.0 - x x weight - total / slack rgb [ c + x * 1.0 - c for c in rgb]return rgb
def traverse_dict_and_list data key default delimiter DEFAULT_TARGET_DELIM for each in key.split delimiter if isinstance data list try idx int each except ValueError embed_match Falsefor embedded in x for x in data if isinstance x dict try data embedded[each]embed_match Truebreakexcept KeyError passif not embed_match return defaultelse try data data[idx]except IndexError return defaultelse try data data[each]except KeyError TypeError return defaultreturn data
@handle_response_format@treeio_login_required@module_admin_required def user_edit request user_id response_format 'html' profile get_object_or_404 User pk user_id if request.POST if 'cancel' not in request.POST form UserForm request.POST instance profile if form.is_valid profile form.save return HttpResponseRedirect reverse 'core_admin_user_view' args [profile.id] else return HttpResponseRedirect reverse 'core_admin_user_view' args [profile.id] else form UserForm instance profile return render_to_response 'core/administration/user_edit' {'profile' profile 'form' form} context_instance RequestContext request response_format response_format
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def up iface iface_type None if iface_type not in ['slave'] return __salt__['cmd.run'] 'iplinkset{0}up'.format iface return None
def write_module_js output_root return _write_js output_root _list_modules
def CreateClient client gdata.docs.client.DocsClient source SampleConfig.APP_NAME client.http_client.debug SampleConfig.DEBUGtry gdata.sample_util.authorize_client client service client.auth_service source client.source scopes client.auth_scopes except gdata.client.BadAuthentication exit 'Invalidusercredentialsgiven.' except gdata.client.Error exit 'LoginError' return client
def _append_to_conf_paths option opt_str value parser _default_to parser 'conf_paths' [] if value not in parser.values.conf_paths parser.values.conf_paths.append value
def _update_email_opt_in request org email_opt_in request.POST.get 'email_opt_in' if email_opt_in is not None email_opt_in_boolean email_opt_in 'true' preferences_api.update_email_opt_in request.user org email_opt_in_boolean
def _generateSampleData mean 0.2 variance 0.2 metricMean 0.2 metricVariance 0.2 data []p {'mean' mean 'name' 'normal' 'stdev' math.sqrt variance 'variance' variance}samples _sampleDistribution p 1440 p {'mean' metricMean 'name' 'normal' 'stdev' math.sqrt metricVariance 'variance' metricVariance}metricValues _sampleDistribution p 1440 for hour in range 0 24 for minute in range 0 60 data.append [datetime.datetime 2013 2 2 hour minute 0 metricValues[ hour * 60 + minute ] samples[ hour * 60 + minute ]] return data
def extract_messages doctree for node in doctree.traverse nodes.TextElement if isinstance node nodes.term and not node.source definition_list_item node.parentif definition_list_item.line is not None node.source definition_list_item.sourcenode.line definition_list_item.line - 1 node.rawsource definition_list_item.rawsource.split '\n' 2 [0]if isinstance node nodes.caption nodes.title and not node.source node.source node.parent.sourcenode.line 0if not node.source continueif isinstance node IGNORED_NODES and 'translatable' not in node continueif isinstance node nodes.field_name and node.children[0] 'orphan' continuemsg node.rawsource.replace '\n' '' .strip if msg yield node msg
def random_port sock socket.socket socket.AF_INET socket.SOCK_STREAM sock.bind 'localhost' 0 port sock.getsockname [1]sock.close return port
def _clone_vdi session vdi_to_clone_ref vdi_ref session.call_xenapi 'VDI.clone' vdi_to_clone_ref LOG.debug 'ClonedVDI% vdi_ref sfromVDI% vdi_to_clone_ref s' {'vdi_ref' vdi_ref 'vdi_to_clone_ref' vdi_to_clone_ref} return vdi_ref
def powerlaw_sequence n exponent 2.0 return [random.paretovariate exponent - 1 for i in range n ]
def generate_hotp secret counter 4 msg struct.pack '>Q' counter digest hmac.new to_bytes secret msg hashlib.sha1 .digest ob digest[19]if PY2 ob ord ob pos ob & 15 base struct.unpack '>I' digest[pos pos + 4 ] [0] & 2147483647 token base % 1000000 return token
def _build_state_value request_handler user uri request_handler.request.urltoken xsrfutil.generate_token xsrf_secret_key user.user_id action_id str uri return uri + ' ' + token
def test_saving_state_exclude_entities hass_recorder hass hass_recorder {'exclude' {'entities' 'test.recorder'}} states _add_entities hass ['test.recorder' 'test2.recorder'] assert len states 1 assert hass.states.get 'test2.recorder' states[0]
def connectSSHTransport service hostAddress None peerAddress None transport SSHServerTransport transport.makeConnection StringTransport hostAddress hostAddress peerAddress peerAddress transport.setService service
def IN item inList if not isinstance item schema.Column return OR *[ x item for x in inList] else return item.in_ inList
def region return s3_rest_controller
def _get_pass_exec pass_exec salt.utils.which 'pass' if pass_exec return pass_execelse raise SaltRenderError 'passunavailable'
def get_quarter_names width 'wide' context 'format' locale LC_TIME return Locale.parse locale .quarters[context][width]
def filter_requirement_statements req req_pattern re.compile u'^\\s* [^\\#]+ ' m req_pattern.search req if m return m.group 0 .replace u'' u''
def set_link_color_palette palette if palette is None palette ['g' 'r' 'c' 'm' 'y' 'k']elif type palette not in list tuple raise TypeError 'palettemustbealistortuple' _ptypes [isinstance p string_types for p in palette]if False in _ptypes raise TypeError 'allpalettelistelementsmustbecolorstrings' for i in list _link_line_colors _link_line_colors.remove i _link_line_colors.extend list palette
def user_get user_id None name None profile None **connection_args kstone auth profile **connection_args ret {}if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}try user kstone.users.get user_id except keystoneclient.exceptions.NotFound msg "Couldnotfinduser'{0}'".format user_id log.error msg return {'Error' msg}ret[user.name] dict value getattr user value None for value in dir user if not value.startswith '_' and isinstance getattr user value None six.text_type dict bool str tenant_id getattr user 'tenantId' None if tenant_id ret[user.name]['tenant_id'] tenant_idreturn ret
def _add_call_item_to_queue pending_work_items work_ids call_queue while True if call_queue.full returntry work_id work_ids.get block False except queue.Empty returnelse work_item pending_work_items[work_id]if work_item.future.set_running_or_notify_cancel call_queue.put _CallItem work_id work_item.fn work_item.args work_item.kwargs block True else del pending_work_items[work_id]continue
def session return Session
def condenseSpaces s s s.replace '\n' '' s spacere.sub '' s return s.strip
def checkCompatibility old new prefs None fix True if old new return 1 '' if old > new old new new old msg 'From%sto%s ' % old new warning Falseif old[0 4] < '1.74' msg + '\n\nThereweremanychangesinversion1.74.00thatwillbreak\ncompatibilitywitholderversions.Makesureyoureadthechangelogcarefully\nbeforeusingthisversion.Donotupgradetothisversionhalfwaythroughanexperiment.\n'if fix and 'PatchComponent' not in prefs.builder['hiddenComponents'] prefs.builder['hiddenComponents'].append 'PatchComponent' warning Trueif not warning msg + '\nNoknowncompatibilityissues'return not warning msg
def systemd_command_generator command command_name 'systemctl'if command 'is_enabled' command 'is-enabled'elif command 'list' def list_command service_name return [command_name 'list-unit-files' '--type service' '--no-pager' '--full']return list_commandelif command 'set_target' def set_target_command target return [command_name 'isolate' target]return set_target_commanddef method service_name return [command_name command '%s.service' % service_name ]return method
def escape_markup text return text.replace '&' '&amp;' .replace '[' '&bl;' .replace ']' '&br;'
def makeExtension *args **kwargs return SuperFencesCodeExtension *args **kwargs
def usergroup_get name None usrgrpids None userids None **connection_args conn_args _login **connection_args try if conn_args method 'usergroup.get'params {'output' 'extend' 'filter' {}}if not name and not usrgrpids and not userids return Falseif name params['filter'].setdefault 'name' name if usrgrpids params.setdefault 'usrgrpids' usrgrpids if userids params.setdefault 'userids' userids params _params_extend params **connection_args ret _query method params conn_args['url'] conn_args['auth'] return False if len ret['result'] < 1 else ret['result'] else raise KeyErrorexcept KeyError return False
def find_executable path None if path is None dirnames os.environ['PATH'].split os.pathsep suffixes ['th']else dirnames [path]suffixes ['th' os.path.join 'bin' 'th' os.path.join 'install' 'bin' 'th' ]for dirname in dirnames dirname dirname.strip '"' for suffix in suffixes path os.path.join dirname suffix if os.path.isfile path and os.access path os.X_OK return pathreturn None
def shuffle X y idx np.argsort [random.random for i in range len y ] y np.asarray y X [X[i] for i in idx]y y[idx]return X y
def do_login sender user request **kwargs if user and user.is_authenticated token Nonetry Application get_application_model app Application.objects.get name 'GeoServer' token generate_token AccessToken.objects.get_or_create user user application app expires datetime.datetime.now + datetime.timedelta days 1 token token except u uuid.uuid1 token u.hexurl '%s%s?access_token %s' % settings.OGC_SERVER['default']['PUBLIC_LOCATION'] 'ows?service wms&version 1.3.0&request GetCapabilities' token cj cookielib.CookieJar opener urllib2.build_opener urllib2.HTTPCookieProcessor cj jsessionid Nonetry opener.open url for c in cj if c.name 'JSESSIONID' jsessionid c.valueexcept u uuid.uuid1 jsessionid u.hexrequest.session['access_token'] tokenrequest.session['JSESSIONID'] jsessionid
def repr_tree_defs data indent_str None lines []nodes data.items for i mod sub files in enumerate sorted nodes key lambda x x[0] if not files files ''else files ' %s ' % ' '.join files if indent_str is None lines.append '%s%s' % mod files sub_indent_str ''else lines.append '%s\\-%s%s' % indent_str mod files if i len nodes - 1 sub_indent_str '%s' % indent_str else sub_indent_str '%s|' % indent_str if sub lines.append repr_tree_defs sub sub_indent_str return '\n'.join lines
def parse_boolean_envvar val if not val or val.lower in {'false' '0'} return Falseelif val.lower in {'true' '1'} return Trueelse raise ValueError 'Invalidbooleanenvironmentvariable %s' % val
def get_free_space dir_name if on_win free_bytes ctypes.c_ulonglong 0 ctypes.windll.kernel32.GetDiskFreeSpaceExW ctypes.c_wchar_p dir_name None None ctypes.pointer free_bytes return free_bytes.valueelse st os.statvfs dir_name return st.f_bavail * st.f_frsize
def _get_endpoint reviewer False active settings.SIGNED_APPS_REVIEWER_SERVER_ACTIVE if reviewer else settings.SIGNED_APPS_SERVER_ACTIVE server settings.SIGNED_APPS_REVIEWER_SERVER if reviewer else settings.SIGNED_APPS_SERVER if active if not server raise ValueError 'Invalidconfig.The%sserversettingisempty.' % 'reviewer' if reviewer else '' return server + '/1.0/sign_app'
def do_mark_unsafe value return text_type value
def probvec m k random_state None parallel True if k 1 return np.ones m k random_state check_random_state random_state r random_state.random_sample size m k - 1 x np.empty m k if parallel _probvec_parallel r x else _probvec_cpu r x return x
def is_admin name groups get_user_groups name True for group in groups if group in 'S-1-5-32-544' 'S-1-5-18' return Truereturn False
def get_pressure return _sensehat.get_pressure
def get_gateway_details args if args.get u'payment_gateway' return get_payment_gateway_account args.get u'payment_gateway' if args.cart payment_gateway_account frappe.get_doc u'ShoppingCartSettings' .payment_gateway_accountreturn get_payment_gateway_account payment_gateway_account gateway_account get_payment_gateway_account {u'is_default' 1} return gateway_account
def getPrintZValue lineBlock lastZ -1 for line in lineBlock lastZ getValue line 'Z' lastZ if line.startswith 'G1' and getValue line 'X' None is not None or getValue line 'Y' None is not None breakreturn lastZ
def relu x return x * x > 0
def get_source sid source Nonequery Source.query.filter Source.filesystem_id sid source get_one_or_else query app.logger abort return source
def build_def_use graph lparams analysis reach_def_analysis graph lparams UD defaultdict list for node in graph.rpo for i ins in node.get_loc_with_ins for var in ins.get_used_vars if var not in analysis.def_to_loc continueldefs analysis.defs[node]prior_def -1 for v in ldefs.get var set if prior_def < v < i prior_def vif prior_def > 0 UD[ var i ].append prior_def else intersect analysis.def_to_loc[var].intersection analysis.R[node] UD[ var i ].extend intersect DU defaultdict list for var_loc defs_loc in UD.items var loc var_locfor def_loc in defs_loc DU[ var def_loc ].append loc return UD DU
def datetime_to_csl dt return {'date-parts' [[dt.year dt.month dt.day]]}
def _key_exists hive key use_32bit_registry False if PY2 local_hive _mbcs_to_unicode hive local_key _unicode_to_mbcs key else local_hive hivelocal_key keyregistry Registry hkey registry.hkeys[local_hive]access_mask registry.registry_32[use_32bit_registry]try handle _winreg.OpenKey hkey local_key 0 access_mask _winreg.CloseKey handle return Trueexcept WindowsError return False
def does_user_exist email server secret appscale_info.get_secret return server.does_user_exist email secret 'true'
def prob_quantize_cdf binsx binsy cdf binsx np.asarray binsx binsy np.asarray binsy nx len binsx - 1 ny len binsy - 1 probs np.nan * np.ones nx ny cdf_values cdf binsx[ None] binsy cdf_func lambda x y cdf_values[ x y ] for xind in range 1 nx + 1 for yind in range 1 ny + 1 upper xind yind lower xind - 1 yind - 1 probs[ xind - 1 yind - 1 ] prob_bv_rectangle lower upper cdf_func assert not np.isnan probs .any return probs
def lookupSenderPolicy name timeout None return getResolver .lookupSenderPolicy name timeout
@abortsdef test_require_noniterable_provided_by_key def fake_providing_function passrequire 'foo' provided_by fake_providing_function
def alertingMsToNet Facility_presence 0 UserUser_presence 0 SsVersionIndicator_presence 0 a TpPd pd 3 b MessageType mesType 1 packet a / b if Facility_presence is 1 c FacilityHdr ieiF 28 eightBitF 0 packet packet / c if UserUser_presence is 1 d UserUserHdr ieiUU 126 eightBitUU 0 packet packet / d if SsVersionIndicator_presence is 1 e SsVersionIndicatorHdr ieiSVI 127 eightBitSVI 0 packet packet / e return packet
def assert_sp_array_equal left right check_dtype True assertIsInstance left pd.SparseArray '[SparseArray]' assertIsInstance right pd.SparseArray '[SparseArray]' assert_numpy_array_equal left.sp_values right.sp_values check_dtype check_dtype assertIsInstance left.sp_index pd._sparse.SparseIndex '[SparseIndex]' assertIsInstance right.sp_index pd._sparse.SparseIndex '[SparseIndex]' if not left.sp_index.equals right.sp_index raise_assert_detail 'SparseArray.index' 'indexarenotequal' left.sp_index right.sp_index assert_attr_equal 'fill_value' left right if check_dtype assert_attr_equal 'dtype' left right assert_numpy_array_equal left.values right.values check_dtype check_dtype
def getWindowAnalyzeFileGivenText fileName gcodeText repository None if gcodeText '' return Noneif repository None repository settings.getReadRepository SkeinlayerRepository skeinWindow getWindowGivenTextRepository fileName gcodeText repository skeinWindow.updateDeiconify return skeinWindow
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def active_children _cleanup return list _current_process._children
def general return {'username' ['' 'admin' 'administrator'] 'password' ['' 'admin' 'administrator' 'password' '1234']}
def check_ref_format refname if '/.' in refname or refname.startswith '.' return Falseif '/' not in refname return Falseif '..' in refname return Falsefor i c in enumerate refname if ord refname[i i + 1 ] < 32 or c in BAD_REF_CHARS return Falseif refname[ -1 ] in '/.' return Falseif refname.endswith '.lock' return Falseif '@{' in refname return Falseif '\\' in refname return Falsereturn True
def _MatchDirective token if token.startswith '.' token token[1 ]else return None None if token 'alternateswith' return ALTERNATES_TOKEN token if token.startswith 'or' if token.strip 'or' return OR_TOKEN None else pred_str token[2 ].strip return OR_TOKEN pred_str if token 'end' return END_TOKEN None match _SECTION_RE.match token if match repeated section_name match.groups if repeated return REPEATED_SECTION_TOKEN section_name else return SECTION_TOKEN section_name if token.startswith 'if' return PREDICATE_TOKEN token[3 ].strip if token.endswith '?' return PREDICATE_TOKEN token return None None
def processinfo processname p _process if processname 'Finder' p.partition Nonep.used Noneelse p.partition _processproperty processname 'appt' p.used _processproperty processname 'pusd' p.visible _processproperty processname 'pvis' p.frontmost _processproperty processname 'pisf' p.file _processproperty processname 'file' p.filetype _processproperty processname 'asty' p.creatortype _processproperty processname 'fcrt' p.accepthighlevel _processproperty processname 'revt' p.hasscripting _processproperty processname 'hscr' return p
def _BuildArgList fdesc names numArgs max fdesc[6] len fdesc[2] names list names while None in names i names.index None names[i] 'arg%d' % i names list map MakePublicAttributeName names[1 numArgs + 1 ] name_num 0while len names < numArgs names.append 'arg%d' % len names for i in range 0 len names 5 names[i] names[i] + '\n DCTB DCTB DCTB ' return ' ' + ' '.join names
def remove_content_references content_id if not settings.FEATURES.get 'MILESTONES_APP' return Nonereturn milestones_api.remove_content_references content_id
def organization_revision_list context data_dict _check_access 'organization_revision_list' context data_dict return _group_or_org_revision_list context data_dict
@pytest.mark.usefixtures 'redirect_webengine_data' @pytest.mark.parametrize 'js_enabled expected' [ True 2.0 False 2.0 ] def test_simple_js_webengine callback_checker webengineview js_enabled expected from PyQt5.QtWebEngineWidgets import QWebEngineSettingswebengineview.settings .setAttribute QWebEngineSettings.JavascriptEnabled js_enabled webengineview.page .runJavaScript '1+1' callback_checker.callback callback_checker.check expected
def cache_dir *args if sys.platform 'darwin' base os.path.expanduser '~/Library/Caches' elif sys.platform 'win32' base os.getenv 'APPDATA' os.path.expanduser '~/AppData/Local' elif os.name 'posix' base os.getenv 'XDG_CACHE_HOME' os.path.expanduser '~/.cache' else base os.path.expanduser '~/.cache' base os.path.join base 'Orange' Orange.__version__ if sys.platform 'win32' return os.path.join base 'Cache' else return base
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def _find_pkg_data_path data_name package None if package is None module find_current_module 1 True if module is None return data_nameif not hasattr module u'__package__' or not module.__package__ if u'.' in module.__name__ package module.__name__.rpartition u'.' [0]else package module.__name__else package module.__package__else module resolve_name package rootpkgname package.partition u'.' [0]rootpkg resolve_name rootpkgname module_path os.path.dirname module.__file__ path os.path.join module_path data_name root_dir os.path.dirname rootpkg.__file__ assert _is_inside path root_dir u'attemptedtogetalocaldatafileoutsideofthe' + rootpkgname + u'tree' return path
def p_parameter_declaration_2 t pass
def sweepA fitnesses front stairs [ - fitnesses[0][1] ]fstairs [fitnesses[0]]for fit in fitnesses[1 ] idx bisect.bisect_right stairs - fit[1] if 0 < idx < len stairs fstair max fstairs[ idx] key front.__getitem__ front[fit] max front[fit] front[fstair] + 1 for i fstair in enumerate fstairs[idx ] idx if front[fstair] front[fit] del stairs[i]del fstairs[i]breakstairs.insert idx - fit[1] fstairs.insert idx fit
def CheckResponseStatus response if response.status rdf_data_store.DataStoreResponse.Status.OK return responseelif response.status rdf_data_store.DataStoreResponse.Status.AUTHORIZATION_DENIED raise access_control.UnauthorizedAccess response.status_desc response.failed_subject elif response.status rdf_data_store.DataStoreResponse.Status.TIMEOUT_ERROR raise data_store.TimeoutError response.status_desc elif response.status rdf_data_store.DataStoreResponse.Status.DATA_STORE_ERROR raise data_store.Error response.status_desc raise data_store.Error 'Unknownerror%s' % response.status_desc
def rand_base length bad chars cset set chars - set list bad if len cset 0 return ''chars [list cset [random.randrange len cset ] for i in xrange length ]chars map str chars return ''.join chars
def group_add_user group user_id None username None if user_id user get_object User id user_id else user get_object User username username if user group.user_set.add user
def xl_cell_to_rowcol_abs cell_str if not cell_str return 0 0 False False match range_parts.match cell_str col_abs match.group 1 col_str match.group 2 row_abs match.group 3 row_str match.group 4 if col_abs col_abs Trueelse col_abs Falseif row_abs row_abs Trueelse row_abs Falseexpn 0col 0for char in reversed col_str col + ord char - ord 'A' + 1 * 26 ** expn expn + 1row int row_str - 1 col - 1return row col row_abs col_abs
def read_cache_time f return struct.unpack '>LL' f.read 8
def is_holiday employee date None holiday_list get_holiday_list_for_employee employee if not date date today if holiday_list return frappe.get_all u'HolidayList' dict name holiday_list holiday_date date and True or False
def getPreview layer return 200 Headers [ 'Content-Type' 'text/html' ] Core._preview layer
def clear_zipimport_cache import sys zipimportsyspath_backup list sys.path zipimport._zip_directory_cache.clear sys.path syspath_backupsys.path_importer_cache.clear
def get_download_url_for_platform url_templates platform_info_dict os_ok Falsearchitecture_ok Falsefor url_template in url_templates os_name url_template.get 'os' None architecture url_template.get 'architecture' None if os_name if os_name.lower platform_info_dict['os'] os_ok Trueelse os_ok Falseelse os_ok Trueif architecture if architecture.lower platform_info_dict['architecture'] architecture_ok Trueelse architecture_ok Falseelse architecture_ok Trueif os_ok and architecture_ok return url_templatereturn None
def chunkize_serial iterable chunksize as_numpy False it iter iterable while True if as_numpy wrapped_chunk [[np.array doc for doc in itertools.islice it int chunksize ]]else wrapped_chunk [list itertools.islice it int chunksize ]if not wrapped_chunk[0] break yield wrapped_chunk.pop
def isUserPass password computedUserPass dictU revision if revision 5 vSalt dictU[32 40]inputHash hashlib.sha256 password + vSalt .digest if inputHash dictU[ 32] return Trueelse return Falseelif revision 3 or revision 4 if computedUserPass[ 16] dictU[ 16] return Trueelse return Falseelif revision < 3 if computedUserPass dictU return Trueelse return False
def reservation_create context uuid usage project_id resource delta expire return IMPL.reservation_create context uuid usage project_id resource delta expire
@not_implemented_for 'multigraph' def jit_data G indent None json_graph []for node in G.nodes json_node {'id' node 'name' node}json_node['data'] G.node[node]if G[node] json_node['adjacencies'] []for neighbour in G[node] adjacency {'nodeTo' neighbour}adjacency['data'] G.edge[node][neighbour]json_node['adjacencies'].append adjacency json_graph.append json_node return json.dumps json_graph indent indent
@app.route '/login' def login_view redirect_uri request.values.get 'redirect_uri' url_for 'account_view' _external True return render_template 'login.html' title 'Login' year datetime.now .year message 'Yourloginpage.' redirect_uri redirect_uri
def add_acl_group name description None group models.AclGroup.add_object name name description description group.users.add models.User.current_user return group.id
def set_gui_mode global gui_modegui_mode True
def get_tests_info input_dir msg_dir prefix suffix result []for fname in glob join input_dir prefix + '*' + suffix infile basename fname fbase splitext infile [0]pyrestr fbase.rsplit '_py' 1 [ -1 ]if pyrestr.isdigit if SYS_VERS_STR < pyrestr continueif pyrestr.startswith '_' and pyrestr[1 ].isdigit if SYS_VERS_STR > pyrestr[1 ] continuemessages glob join msg_dir fbase + '*.txt' if messages for outfile in sorted messages reverse True py_rest outfile.rsplit '_py' 1 [ -1 ][ -4 ]if py_rest.isdigit and SYS_VERS_STR > py_rest breakelse outfile join msg_dir fbase + '.txt' result.append infile outfile return result
def format_execution_status instance start_timestamp getattr instance 'start_timestamp' None end_timestamp getattr instance 'end_timestamp' None if instance.status LIVEACTION_STATUS_RUNNING and start_timestamp start_timestamp instance.start_timestampstart_timestamp parse_isotime start_timestamp start_timestamp calendar.timegm start_timestamp.timetuple now int time.time elapsed_seconds now - start_timestamp instance.status '%s %sselapsed ' % instance.status elapsed_seconds elif instance.status in LIVEACTION_COMPLETED_STATES and start_timestamp and end_timestamp start_timestamp parse_isotime start_timestamp start_timestamp calendar.timegm start_timestamp.timetuple end_timestamp parse_isotime end_timestamp end_timestamp calendar.timegm end_timestamp.timetuple elapsed_seconds end_timestamp - start_timestamp instance.status '%s %sselapsed ' % instance.status elapsed_seconds return instance
def get_lexer_for_filename _fn code None **options matches []fn basename _fn for modname name _ filenames _ in LEXERS.itervalues for filename in filenames if fnmatch.fnmatch fn filename if name not in _lexer_cache _load_lexers modname matches.append _lexer_cache[name] for cls in find_plugin_lexers for filename in cls.filenames if fnmatch.fnmatch fn filename matches.append cls if sys.version_info > 3 and isinstance code bytes code code.decode 'latin1' def get_rating cls d cls.analyse_text code return dif code matches.sort key get_rating if matches return matches[ -1 ] **options raise ClassNotFound 'nolexerforfilename%rfound' % _fn
def combine_images im1 im2 alpha return 1 - alpha * im1 + alpha * im2
def arg_string func return inspect.formatargspec *inspect.getargspec func
def auto_complete request queryset fields None object_list []limit request.GET.get 'limit' 10 query request.GET.get 'term' '' if fields q_object Q for field in fields q_object | Q **{field query} queryset queryset.filter q_object for obj in queryset[ limit] object_list.append {'text' obj.__unicode__ 'id' obj.pk} return HttpResponse json.dumps object_list mimetype 'application/json'
def set_rollback rollback using None return get_connection using .set_rollback rollback
def assert_python_failure *args **env_vars return _assert_python False *args **env_vars
def union_all graphs rename None name None graphs_names zip_longest graphs rename U gname next graphs_names for H hname in graphs_names U nx.union U H gname hname name name gname Nonereturn U
def getDateTime value None if value is None return datetime.datetime.today if isinstance value datetime.datetime return valueif isinstance value datetime.date return datetime.datetime.fromordinal value.toordinal if isinstance value int float return datetime.datetime.fromtimestamp value if isinstance value str raise NotImplementedError "Stringsaren'tcurrentlyimplemented" if hasattr value '__getitem__' return datetime.datetime *tuple value [ 6] return datetime.datetime.fromtimestamp value.ticks
def _patch_config_section_desc monkeypatch stubs symbol section_desc {'general' 'General/miscellaneousoptions.' 'ui' 'Generaloptionsrelatedtotheuserinterface.' 'searchengines' 'Definitionsofsearchengines...'}monkeypatch.setattr symbol section_desc
def _extract_id_token id_token if type id_token bytes segments id_token.split '.' else segments id_token.split u'.' if len segments ! 3 raise VerifyJwtTokenError 'Wrongnumberofsegmentsintoken {0}'.format id_token return json.loads _helpers._from_bytes _helpers._urlsafe_b64decode segments[1]
def loadavg try load_avg os.getloadavg except AttributeError raise salt.exceptions.CommandExecutionError 'status.loadavagisnotavailableonyourplatform' return {'1-min' load_avg[0] '5-min' load_avg[1] '15-min' load_avg[2]}
def setegid gid gid parse_gid gid if gid ! os.getgid os.setegid gid
def do_striptags value if hasattr value '__html__' value value.__html__ return Markup unicode value .striptags
def facility_user_signup request if getattr request 'is_logged_in' False return HttpResponseRedirect reverse 'homepage' if settings.DISABLE_SELF_ADMIN raise PermissionDenied _ 'Pleasecontactacoachoradministratortoreceivelogininformationtothisinstallation.' if settings.CENTRAL_SERVER raise Http404 _ 'Youmaynotsignupasafacilityuseronthecentralserver.' title _ 'Signupforanaccount' return _facility_user request new_user True title title
def db_get name **connection_args dbc _connect **connection_args if dbc is None return []cur dbc.cursor qry 'SELECTDEFAULT_CHARACTER_SET_NAME DEFAULT_COLLATION_NAMEFROMINFORMATION_SCHEMA.SCHEMATAWHERESCHEMA_NAME % dbname s;'args {'dbname' name}_execute cur qry args if cur.rowcount rows cur.fetchall return {'character_set' rows[0][0] 'collate' rows[0][1]}return {}
def save_minions jid minions syndic_id None pass
def _dict_deep_update d u for k v in u.items if isinstance v collections.Mapping r _dict_deep_update d.get k {} v d[k] relse d[k] u[k]return d
def getStartingAddress packet return ord packet[8] << 8 + ord packet[9]
def _parse_pre_yarn_counters counters_str counters {}for group_match in _PRE_YARN_COUNTER_GROUP_RE.finditer counters_str group_name _pre_yarn_history_unescape group_match.group 'group_name' group_counters {}for counter_match in _PRE_YARN_COUNTER_RE.finditer group_match.group 'counter_list_str' counter_name _pre_yarn_history_unescape counter_match.group 'counter_name' amount int counter_match.group 'amount' group_counters[counter_name] amountcounters[group_name] group_countersreturn counters
def environ_add_path env key path old env.get key if old env[key] path + ' ' + old else env[key] path
def check_derivative fun jac x0 bounds - np.inf np.inf args kwargs {} J_to_test jac x0 *args **kwargs if issparse J_to_test J_diff approx_derivative fun x0 bounds bounds sparsity J_to_test args args kwargs kwargs J_to_test csr_matrix J_to_test abs_err J_to_test - J_diff i j abs_err_data find abs_err J_diff_data np.asarray J_diff[ i j ] .ravel return np.max np.abs abs_err_data / np.maximum 1 np.abs J_diff_data else J_diff approx_derivative fun x0 bounds bounds args args kwargs kwargs abs_err np.abs J_to_test - J_diff return np.max abs_err / np.maximum 1 np.abs J_diff
def free_swap out sh 'free-b' lines out.split '\n' for line in lines if line.startswith 'Swap' _ total used free line.split nt collections.namedtuple 'free' 'totalusedfree' return nt int total int used int free raise ValueError "can'tfind'Swap'in'free'output \n%s" % '\n'.join lines
def _count_replacement codon_set G from math import floorif len codon_set 1 return 0 0 elif len codon_set 2 codons list codon_set return floor G[codons[0]][codons[1]] else codons list codon_set return _prim G
def pairwise iterable it iter iterable try first next it except StopIteration returnfor second in it yield first second first second
def get_fixed_timezone offset if isinstance offset timedelta offset offset.seconds // 60 sign '-' if offset < 0 else '+' hhmm '%02d%02d' % divmod abs offset 60 name sign + hhmm return FixedOffset offset name
def is_short w return is_short_syllable w[ -3 ] and len [ch for ch in w[ -3 ] if ch in VOWELS ] 0
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
@genericdef inspect_object obj raise TryNext
def norm_l1_tf Z shape n_orient if Z.shape[0] n_positions Z.shape[0] // n_orient Z_ np.sqrt np.sum np.abs Z ** 2.0 .reshape n_orient -1 order 'F' axis 0 Z_ Z_.reshape n_positions -1 order 'F' .reshape *shape l1_norm 2.0 * Z_.sum axis 2 .sum axis 1 - np.sum Z_[ 0 ] axis 1 - np.sum Z_[ -1 ] axis 1 l1_norm l1_norm.sum else l1_norm 0.0return l1_norm
def _get_method name func def method self *args **kw return func self *args **kw method.__name__ namereturn method
def destroy instance_id call None if call 'function' raise SaltCloudSystemExit 'Thedestroyactionmustbecalledwith-d --destroy -aor--action.' instance_data show_instance instance_id call 'action' name instance_data['instance_name']__utils__['cloud.fire_event'] 'event' 'destroyinginstance' 'salt/cloud/{0}/destroying'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] params {'action' 'TerminateInstances' 'zone' _get_specified_zone provider get_configured_provider 'instances.1' instance_id}result query params __utils__['cloud.fire_event'] 'event' 'destroyedinstance' 'salt/cloud/{0}/destroyed'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def is_encrypted path if path.startswith '/dev/mapper' return path.rpartition '/' [2].endswith _dmcrypt_suffix else return False
def test_proxy _test_function_names gl.proxy _test_constant_names gl._constants
def build_averaged_flowgrams mapping sff_fp min_coverage 50 out_fp None l len mapping flowgrams header lazy_parse_sff_handle open sff_fp header['#ofReads'] lheader['IndexLength'] 'NA'if out_fp out_filename out_fpelse fd out_filename mkstemp dir '/tmp/' prefix 'prefix_dereplicated' suffix '.sff.txt' close fd outhandle open out_filename 'w' write_sff_header header outhandle seqs {}sample_keys sample_mapped_keys mapping min_coverage for ave_f id in _average_flowgrams mapping flowgrams sample_keys outhandle.write ave_f.createFlowHeader + '\n' ave_f.Bases ave_f.toSeq seqs[id] ave_f.Basesouthandle.close return out_filename seqs
def get_referent_by_identifier category value try identifier Identifier.find_one Q 'category' 'eq' category & Q 'value' 'eq' value except NoResultsFound raise HTTPError http.NOT_FOUND if identifier.referent.url return redirect identifier.referent.url raise HTTPError http.NOT_FOUND
def start_subprocess cmd return subprocess.Popen cmd stdout DEVNULL stderr DEVNULL
def ApplyPluginToMultiTypeCollection plugin output_collection for chunk in plugin.Start yield chunk for stored_type_name in sorted output_collection.ListStoredTypes stored_cls rdfvalue.RDFValue.classes[stored_type_name]def GetValues for timestamp value in output_collection.ScanByType stored_type_name _ timestamp yield value for chunk in plugin.ProcessValues stored_cls GetValues yield chunk for chunk in plugin.Finish yield chunk
def unwrap url url url.strip if url[ 1] '<' and url[ -1 ] '>' url url[1 -1 ].strip if url[ 4] 'URL ' url url[4 ].strip return url
def sm_volume_delete context volume_id return IMPL.sm_volume_delete context volume_id
def unpack_session item _init_globals session _SESSION_HANDLER.get item[1] if session and session.conn_time item[2] return sessionreturn None
def fix_method_name name if keyword.iskeyword name or name in RESERVED_WORDS return name + '_' else return name
def _extract_attached_to disk users disk.get 'users' [] if not users return Noneif len users > 1 raise GCEVolumeException 'Volumeisattachedtomorethanoneinstance {}'.format disk return unicode users[0].split '/' [ -1 ]
def unwrap_function func max_depth 10 iteration 0wrapped getattr func '__wrapped__' None while wrapped and iteration < max_depth func wrappedwrapped getattr func '__wrapped__' None iteration + 1return func
def _generate_faux_mime_message parser response content if not isinstance content six.binary_type content content.encode 'utf-8' content_type response['content-type']if not isinstance content_type six.binary_type content_type content_type.encode 'utf-8' faux_message ''.join ['Content-Type ' content_type '\nMIME-Version 1.0\n\n' content] if six.PY2 return parser.parsestr faux_message else return parser.parsestr faux_message.decode 'utf-8'
@jit nopython True cache True def min_ratio_test_no_tie_breaking tableau pivot test_col argmins num_candidates ratio_min np.infnum_argmins 0for k in range num_candidates i argmins[k]if tableau[ i pivot ] < TOL_PIV continueratio tableau[ i test_col ] / tableau[ i pivot ] if ratio > ratio_min + TOL_RATIO_DIFF continueelif ratio < ratio_min - TOL_RATIO_DIFF ratio_min rationum_argmins 1else num_argmins + 1argmins[ num_argmins - 1 ] ireturn num_argmins
def pygraphviz_layout G prog 'neato' root None args '' try import pygraphvizexcept ImportError raise ImportError 'requirespygraphviz' 'http //pygraphviz.github.io/' if root is not None args + '-Groot %s' % root A to_agraph G A.layout prog prog args args node_pos {}for n in G node pygraphviz.Node A n try xx yy node.attr['pos'].split ' ' node_pos[n] float xx float yy except print 'nopositionfornode' n node_pos[n] 0.0 0.0 return node_pos
def test_has_release assert_equals lettuce.release 'kryptonite'
def noneTest vm prompt Prompt installPexpect vm prompt vm.sendline 'echo'
def get_vf_num_by_pci_address pci_addr VIRTFN_RE re.compile 'virtfn \\d+ ' virtfns_path '/sys/bus/pci/devices/%s/physfn/virtfn*' % pci_addr vf_num Nonetry for vf_path in glob.iglob virtfns_path if re.search pci_addr os.readlink vf_path t VIRTFN_RE.search vf_path vf_num t.group 1 breakexcept Exception passif vf_num is None raise exception.PciDeviceNotFoundById id pci_addr return vf_num
def validate_overlap_for doc doctype fieldname value None existing get_overlap_for doc doctype fieldname value if existing frappe.throw _ u'This{0}conflictswith{1}for{2}{3}' .format doc.doctype existing.name doc.meta.get_label fieldname if not value else fieldname value or doc.get fieldname OverlapError
def get_configured_provider return config.is_provider_configured __opts__ __active_provider_name__ or __virtualname__ 'user' 'password' 'url'
def network_in_use_on_host context network_id host None return IMPL.network_in_use_on_host context network_id host
def local_merge model main.model cfg gitcfg.current view MergeView cfg model qtutils.active_window view.show view.raise_ return view
def set_inactdays name inactdays pre_info info name if inactdays pre_info['inact'] return Truecmd 'chage-I{0}{1}'.format inactdays name __salt__['cmd.run'] cmd python_shell False post_info info name if post_info['inact'] ! pre_info['inact'] return post_info['inact'] inactdays return False
def libvlc_media_list_player_event_manager p_mlp f _Cfunctions.get 'libvlc_media_list_player_event_manager' None or _Cfunction 'libvlc_media_list_player_event_manager' 1 class_result EventManager ctypes.c_void_p MediaListPlayer return f p_mlp
def install_requirement virtualenv_path requirement pip_path os.path.join virtualenv_path 'bin/pip' cmd [pip_path 'install' requirement]env get_env_for_subprocess_command exit_code stdout stderr run_command cmd cmd env env if exit_code ! 0 raise Exception 'Failedtoinstallrequirement"%s" %s' % requirement stdout return True
def git_wrapper path path os.path.abspath path if path not in _wrapper_cache if hasattr Repo 'commits' _wrapper_cache[path] _GitWrapperLegacy path else _wrapper_cache[path] _GitWrapper path return _wrapper_cache[path]
def _should_index collection rights rights_manager.get_collection_rights collection.id return rights.status ! rights_manager.ACTIVITY_STATUS_PRIVATE
def initRepeat container func n return container func for _ in xrange n
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def create_attachments note formset errors []for form in formset if not form.is_valid errors.append form.errors continuedata form.cleaned_dataif not data continueattachment data['attachment']attachment_name _save_attachment attachment '%s/%s' % settings.REVIEWER_ATTACHMENTS_PATH attachment.name note.attachments.create description data.get 'description' filepath attachment_name mimetype attachment.content_type return errors
def binop_return_dtype op left right if is_comparison op if left ! right raise TypeError "Don'tknowhowtocompute{left}{op}{right}.\nComparisonsareonlysupportedbetweenFactorsofequaldtypes.".format left left op op right right return bool_dtypeelif left ! float64_dtype or right ! float64_dtype raise TypeError "Don'tknowhowtocompute{left}{op}{right}.\nArithmeticoperatorsareonlysupportedbetweenFactorsofdtype'float64'.".format left left.name op op right right.name return float64_dtype
def _permutation_test_score estimator X y groups cv scorer avg_score []for train test in cv.split X y groups X_train y_train _safe_split estimator X y train X_test y_test _safe_split estimator X y test train estimator.fit X_train y_train avg_score.append scorer estimator X_test y_test return np.mean avg_score
def alterWiddershinsSupportedPath alongAway close alongAway.bottomPoints []alongAway.minimumY getMinimumYByPath alongAway.loop for point in alongAway.loop if point.y - alongAway.minimumY < close alongAway.addToBottomPoints point ascendingYPoints alongAway.loop[ ]ascendingYPoints.sort compareYAscending overhangWiddershinsLeft OverhangWiddershinsLeft alongAway overhangWiddershinsRight OverhangWiddershinsRight alongAway for point in ascendingYPoints alterWiddershinsSupportedPathByPoint alongAway overhangWiddershinsLeft overhangWiddershinsRight point
def ansi_highlight classified_text colors default_ansi result []for kind text in classified_text opener closer colors.get kind '' '' result + [opener text closer]return ''.join result
def roc_auc_score y_true y_score average 'macro' sample_weight None def _binary_roc_auc_score y_true y_score sample_weight None if len np.unique y_true ! 2 raise ValueError 'Onlyoneclasspresentiny_true.ROCAUCscoreisnotdefinedinthatcase.' fpr tpr tresholds roc_curve y_true y_score sample_weight sample_weight return auc fpr tpr reorder True return _average_binary_score _binary_roc_auc_score y_true y_score average sample_weight sample_weight
def set_data_dir directory None create False save False if directory is None directory _data_pathif _data_path is None raise IOError 'defaultpathcannotbedetermined pleasesetitmanually directory! None ' if not op.isdir directory if not create raise IOError 'directory"%s"doesnotexist perhapstrycreate Truetocreateit?' % directory os.mkdir directory config.update data_path directory if save save_config data_path directory
def quantize_amount_to_string amount return '%i%%' % int amount * 100.0
def p_storage_class_specifier t pass
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def launchd attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'launchd' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def _get_cpu_policy_constraints flavor image_meta flavor_policy image_policy _get_flavor_image_meta 'cpu_policy' flavor image_meta if flavor_policy fields.CPUAllocationPolicy.DEDICATED cpu_policy flavor_policyelif flavor_policy fields.CPUAllocationPolicy.SHARED if image_policy fields.CPUAllocationPolicy.DEDICATED raise exception.ImageCPUPinningForbidden cpu_policy flavor_policyelif image_policy fields.CPUAllocationPolicy.DEDICATED cpu_policy image_policyelse cpu_policy fields.CPUAllocationPolicy.SHAREDreturn cpu_policy
def _get_timezone_name timezone try return timezone.zoneexcept AttributeError local_now datetime.now timezone return timezone.tzname local_now
def getXIntersectionIfExists beginComplex endComplex y if y > beginComplex.imag y > endComplex.imag return NoneendMinusBeginComplex endComplex - beginComplex return y - beginComplex.imag / endMinusBeginComplex.imag * endMinusBeginComplex.real + beginComplex.real
def set_virt_type self vtype if vtype '<<inherit>>' self.virt_type '<<inherit>>'returnif vtype.lower not in ['qemu' 'kvm' 'xenpv' 'xenfv' 'vmware' 'vmwarew' 'openvz' 'auto'] raise CX _ 'invalidvirttype %s ' % vtype self.virt_type vtype
def process_fastq_single_end_read_file_no_barcode fastq_read_f sample_id store_unassigned False max_bad_run_length 0 phred_quality_threshold 2 min_per_read_length_fraction 0.75 rev_comp False seq_max_N 0 start_seq_id 0 filter_bad_illumina_qual_digit False log_f None histogram_f None phred_offset None fake_barcodes cycle ['@' 'AAAAAAAAAAAA' '+' 'CCCCCCCCCCCC'] barcode_to_sample_id {'AAAAAAAAAAAA' sample_id}for e in process_fastq_single_end_read_file fastq_read_f fake_barcodes barcode_to_sample_id store_unassigned store_unassigned max_bad_run_length max_bad_run_length phred_quality_threshold phred_quality_threshold min_per_read_length_fraction min_per_read_length_fraction rev_comp rev_comp rev_comp_barcode False seq_max_N seq_max_N start_seq_id start_seq_id filter_bad_illumina_qual_digit filter_bad_illumina_qual_digit log_f log_f histogram_f histogram_f barcode_correction_fn None max_barcode_errors 0 strict_header_match False phred_offset phred_offset yield e
def remove_chars string repl if type string str return string.translate maketrans '' '' repl elif type string unicode return string.translate dict [ ord s None for s in repl]
def from_1D_to_2D constant if isinstance constant np.ndarray and constant.ndim 1 return np.mat constant .Telse return constant
def read_buffer request return HttpResponse request.read 99999
def mon_is **kwargs return ceph_cfg.mon_is **kwargs
def save_cert domain master result __salt__['cmd.run'] 'icinga2pkisave-cert--key/etc/icinga2/pki/{0}.key--cert/etc/icinga2/pki/{0}.cert--trustedcert/etc/icinga2/pki/trusted-master.crt--host{1}'.format domain master return result
def identify_user g.remote_addr request.environ.get u'HTTP_X_FORWARDED_FOR' u'' if not g.remote_addr g.remote_addr request.environ.get u'REMOTE_ADDR' u'UnknownIPAddress' authenticators p.PluginImplementations p.IAuthenticator if authenticators for item in authenticators item.identify if g.user breakif not getattr g u'user' None _identify_user_default if g.user and not getattr g u'userobj' None g.userobj model.User.by_name g.user if g.user g.author g.userelse g.author g.remote_addrg.author unicode g.author
def deep_dict obj return json.loads json.dumps obj
def publish_collection_and_update_user_profiles committer_id collection_id rights_manager.publish_collection committer_id collection_id contribution_time_msec utils.get_current_time_in_millisecs collection_summary get_collection_summary_by_id collection_id contributor_ids collection_summary.contributor_idsfor contributor in contributor_ids user_services.update_first_contribution_msec_if_not_set contributor contribution_time_msec
def clipped_relu x z 20.0 return ClippedReLU z x
def _deep_deannotate element values None cloned util.column_dict def clone elem if values or elem not in cloned newelem elem._deannotate values values clone True newelem._copy_internals clone clone if not values cloned[elem] newelemreturn newelemelse return cloned[elem]if element is not None element clone element return element
def is_code line indent_depth 4 if line.startswith u'' * indent_depth return len line - len line.lstrip u'' return 0
@lower_setattr_generic types.Record def record_setattr context builder sig args attr typ valty sig.args target val argscontext.sentry_record_alignment typ attr offset typ.offset attr elemty typ.typeof attr dptr cgutils.get_record_member builder target offset context.get_data_type elemty val context.cast builder val valty elemty align None if typ.aligned else 1 context.pack_value builder elemty val dptr align align
def vector_as_matrix v return [[v_i] for v_i in v]
def read_packet data local_sock remote_addr opcode unpack '!H' data[0 2] if opcode < 1 or opcode > 6 logging.warn 'Unknownrequestid%dfrom%s' % opcode remote_addr local_sock.sendto ERRORPacket 0 'Unknownrequest' .marshall remote_addr return Noneif REQUESTS[opcode][REQ_CLASS] is None if opcode ! TFTP_OPCODE_ERROR logging.warn 'Unsupportedrequest%d %s from%s' % opcode REQUESTS[opcode][REQ_NAME] remote_addr local_sock.sendto ERRORPacket 2 'Unsupportedrequest' .marshall remote_addr return Nonetry return REQUESTS[opcode][REQ_CLASS] data local_sock remote_addr except return None
def games_gen year week None home None away None kind 'REG' started False infos _search_schedule year week home away kind started if not infos return Nonedef gen for info in infos g nflgame.game.Game info['eid'] if g is None continue yield g return gen
def text charp if not charp return ''return native ffi.string charp
def _Cycle value unused_context args return args[ value - 1 % len args ]
def list_shared_folders_users try return __salt__['group.info'] _shared_folders_group ['members']except KeyError return []
def addGeometryList elementNode faces for face in faces faceElement xml_simple_reader.ElementNode face.addToAttributes faceElement.attributes faceElement.localName 'face'faceElement.parentNode elementNodeelementNode.childNodes.append faceElement
def _sysv_enabled name for match in glob.glob '/etc/rc%s.d/S*%s' % _runlevel name if re.match 'S\\d{ 2}%s' % name os.path.basename match return Truereturn False
def _process_os_dir directory files template_linters options summary_results out for current_file in sorted files key lambda s s.lower full_path os.path.join directory current_file _process_file full_path template_linters options summary_results out
def mahalanobis u v VI u _validate_vector u v _validate_vector v VI np.atleast_2d VI delta u - v m np.dot np.dot delta VI delta return np.sqrt m
def get_diagonal_subtensor_view x i0 i1 i0 int i0 i1 int i1 if x.shape[i0] < x.shape[i1] raise NotImplementedError 'isthisallowed?' idx [slice None ] * x.ndim idx[i0] slice x.shape[i1] - 1 None None xview x.__getitem__ tuple idx strides list xview.strides if x.shape[i1] ! 1 strides[i1] - strides[i0]xview.strides stridesreturn xview
def get_sans_from_csr csr typ OpenSSL.crypto.FILETYPE_PEM return _get_sans_from_cert_or_req csr OpenSSL.crypto.load_certificate_request typ
def markdown_set_field_escaped obj field escaped if escaped markdown_escape_field obj field else markdown_unescape_field obj field
def _mask_border_keypoints image_shape keypoints distance rows image_shape[0]cols image_shape[1]mask distance - 1 < keypoints[ 0] & keypoints[ 0] < rows - distance + 1 & distance - 1 < keypoints[ 1] & keypoints[ 1] < cols - distance + 1 return mask
@with_setup step_runner_environ def test_undefined_behave_as_step_doesnt_pass runnable_step Step.from_string 'GivenIhaveastepwhichcallsthe"undefinedstep"stepwithbehave_as' assert_raises AssertionError runnable_step.run True assert_false runnable_step.passed
def ipv6_addr addr return __ip_addr addr socket.AF_INET6
def _orm_deannotate element return sql_util._deep_deannotate element values '_orm_adapt' 'parententity'
def fix_keys data new_data []if isinstance data list for n in xrange len data if isinstance data[n] dict new {}for key in data[n] new[unicoder key ] data[n][key]else new data[n]new_data.append new return new_data
def getBottomPath path bottom 999999999.9for point in path bottom min bottom point.z return bottom
def arma2ar ar ma nobs 100 return arma_impulse_response ma ar nobs nobs
def _get_installed_models table_list from django.db import modelsall_models []for app in models.get_apps for model in models.get_models app all_models.append model return set [m for m in all_models if m._meta.db_table in table_list ]
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def getPluginFileNamesFromDirectoryPath directoryPath fileInDirectory os.path.join directoryPath '__init__.py' fullPluginFileNames getPythonFileNamesExceptInit fileInDirectory pluginFileNames []for fullPluginFileName in fullPluginFileNames pluginBasename os.path.basename fullPluginFileName pluginBasename getUntilDot pluginBasename pluginFileNames.append pluginBasename return pluginFileNames
def toDicts articles uArticles toUnicode articles return dict [ x x for x in articles] dict [ x x for x in uArticles]
def nova_import_no_db_in_virt logical_line filename if 'nova/virt' in filename and not filename.endswith 'fake.py' if logical_line.startswith 'fromnovaimportdb' yield 0 'N307 nova.dbimportnotallowedinnova/virt/*'
def _ask_user_to_confirm_new_names config new_domains certname old_domains if config.renew_with_new_domains returnmsg 'Confirmthatyouintendtoupdatecertificate{0}toincludedomains{1}.Notethatitpreviouslycontaineddomains{2}.'.format certname new_domains old_domains obj zope.component.getUtility interfaces.IDisplay if not obj.yesno msg 'Updatecert' 'Cancel' default True raise errors.ConfigurationError 'Specifiedmismatchedcertnameanddomains.'
def getmodulename path info getmoduleinfo path if info return info[0]
def _handle_existing_loggers existing child_loggers disable_existing root logging.rootfor log in existing logger root.manager.loggerDict[log]if log in child_loggers logger.level logging.NOTSETlogger.handlers []logger.propagate Trueelse logger.disabled disable_existing
def create_users n_users for i in range 0 n_users user Profile user.username 'user_%s' % i user.save
def create_volume_service test service VolumeService FilePath test.mktemp FilesystemStoragePool FilePath test.mktemp reactor Clock service.startService test.addCleanup service.stopService return service
def run_fasta_checks input_fasta_fp mapping_fp tree_fp None tree_subset False tree_exact_match False same_seq_lens False all_ids_found False suppress_barcode_checks False suppress_primer_checks False fasta_report {} sample_ids barcodes linkerprimerseqs get_mapping_details mapping_fp suppress_barcode_checks suppress_primer_checks fasta_labels get_fasta_labels input_fasta_fp total_seq_count len fasta_labels fasta_report['duplicate_labels'] fasta_report['duplicate_ids'] get_dup_labels_perc fasta_labels fasta_report['invalid_labels'] fasta_report['nosample_ids_map'] check_labels_sampleids fasta_labels sample_ids total_seq_count fasta_report['invalid_seq_chars'] fasta_report['barcodes_detected'] fasta_report['linkerprimers_detected'] fasta_report['barcodes_at_start'] check_fasta_seqs input_fasta_fp barcodes linkerprimerseqs total_seq_count if same_seq_lens fasta_report['same_seq_lens'] check_fasta_seqs_lens input_fasta_fp else fasta_report['same_seq_lens'] Falseif all_ids_found fasta_report['all_ids_found'] check_all_ids fasta_labels sample_ids else fasta_report['all_ids_found'] Falseif tree_subset fasta_report['tree_subset'] check_tree_subset fasta_labels tree_fp else fasta_report['tree_subset'] Falseif tree_exact_match fasta_report['tree_exact_match'] check_tree_exact_match fasta_labels tree_fp else fasta_report['tree_exact_match'] Falsereturn fasta_report
def refine_Relational expr assumptions return ask Q.is_true expr assumptions
@after.each_scenariodef screenshot_on_error scenario if scenario.failed try output_dir '{}/log'.format settings.TEST_ROOT image_name '{}/{}.png'.format output_dir scenario.name.replace '' '_' world.browser.driver.save_screenshot image_name except WebDriverException LOGGER.error 'Couldnotcaptureascreenshot'
def noisy_max logits lap_scale return_clean_votes False labels labels_from_probs logits labels_shape np.shape labels labels labels.reshape labels_shape[0] labels_shape[1] result np.zeros int labels_shape[1] if return_clean_votes clean_votes np.zeros int labels_shape[1] 10 for i in xrange int labels_shape[1] label_counts np.bincount labels[ i] minlength 10 if return_clean_votes clean_votes[i] label_countslabel_counts np.asarray label_counts dtype np.float32 for item in xrange 10 label_counts[item] + np.random.laplace loc 0.0 scale float lap_scale result[i] np.argmax label_counts result np.asarray result dtype np.int32 if return_clean_votes return result clean_votes labels else return result
def trace_cls name **kwargs def decorator cls if profiler and 'profiler' in CONF and CONF.profiler.enabled trace_decorator profiler.trace_cls name kwargs return trace_decorator cls return clsreturn decorator
def _check_touch name atime mtime if not os.path.exists name return None 'File{0}issettobecreated'.format name stats __salt__['file.stats'] name follow_symlinks False if atime is not None if str atime ! str stats['atime'] return None 'Timessettobeupdatedonfile{0}'.format name if mtime is not None if str mtime ! str stats['mtime'] return None 'Timessettobeupdatedonfile{0}'.format name return True 'File{0}existsandhasthecorrecttimes'.format name
def Handle environ error logservice.LogsBuffer request_environment.current_request.Init error environ response {'error' 0 'response_code' 200}try request_id environ[BACKGROUND_REQUEST_ID]_pending_background_threads.RunBackgroundThread request_id return responseexcept exception sys.exc_info tb exception[2].tb_nextif tb tb tb.tb_nextmessage ''.join traceback.format_exception exception[0] exception[1] tb logging.error message response['response_code'] 500response['error'] 1return responsefinally request_environment.current_request.Clear response['logs'] error.parse_logs
def make_url_parser global_conf directory base_python_name index_names None hide_extensions None ignore_extensions None **constructor_conf if index_names is None index_names global_conf.get 'index_names' 'index' 'Index' 'main' 'Main' index_names converters.aslist index_names if hide_extensions is None hide_extensions global_conf.get 'hide_extensions' '.pyc' 'bak' 'py~' hide_extensions converters.aslist hide_extensions if ignore_extensions is None ignore_extensions global_conf.get 'ignore_extensions' ignore_extensions converters.aslist ignore_extensions return URLParser {} directory base_python_name index_names index_names hide_extensions hide_extensions ignore_extensions ignore_extensions **constructor_conf
def uifftn inarray dim None if dim is None dim inarray.ndimoutarray np.fft.ifftn inarray axes range - dim 0 return outarray * np.sqrt np.prod inarray.shape[ - dim ]
def EmblCdsFeatureIterator handle alphabet Alphabet.generic_protein return EmblScanner debug 0 .parse_cds_features handle alphabet
def nativeString s if not isinstance s bytes unicode raise TypeError '%risneitherbytesnorunicode' % s if _PY3 if isinstance s bytes return s.decode 'ascii' else s.encode 'ascii' elif isinstance s unicode return s.encode 'ascii' else s.decode 'ascii' return s
def api_level cmd name if cmd in _api_table return _api_table[cmd][1]if name 'queue' and cmd in _api_queue_table return _api_queue_table[cmd][1]if name 'config' and cmd in _api_config_table return _api_config_table[cmd][1]return 4
def disjoint sets sets list sets n len sets disjoint_sets [None] * 2 ** n for i in range 2 ** n key setkey i n included [s for s inc in zip sets key if inc]excluded [s for s inc in zip sets key if not inc ]if any included s reduce set.intersection included else s set s reduce set.difference excluded s disjoint_sets[i] sreturn disjoint_sets
def remove_function_outliers function if function.startswith 'block' return 'block'return _ruby_anon_func.sub '_<anon>' function
def _invert_selem selem inverted selem[ slice None None -1 * selem.ndim ]return inverted
def _req_body_property def getter self body self.environ['wsgi.input'].read self.environ['wsgi.input'] StringIO body return bodydef setter self value self.environ['wsgi.input'] StringIO value self.environ['CONTENT_LENGTH'] str len value return property getter setter doc 'Getandsettherequestbodystr'
def test_hsl_to_rgb_part_2 assert hsl_to_rgb 360 100 50 255 0 0 assert hsl_to_rgb 420 100 50 255 255 0 assert hsl_to_rgb 480 100 50 0 255 0 assert hsl_to_rgb 540 100 50 0 255 255 assert hsl_to_rgb 600 100 50 0 0 255 assert hsl_to_rgb 660 100 50 255 0 255
def _minpoly_mul x dom *a mp _minpoly_op_algebraic_element Mul a[0] a[1] x dom p a[0] * a[1] for px in a[2 ] mp _minpoly_op_algebraic_element Mul p px x dom mp1 mp p p * px return mp
def collect_glib_translations prog global _glib_translationsif _glib_translations is None _glib_translations collect_glib_share_files 'locale' names [ os.sep + prog + '.mo' os.sep + prog + '.po' ]namelen len names[0] return [ src dst for src dst in _glib_translations if src[ - namelen ] in names ]
def delete_versions project version_data current_versions []if 'tags' in version_data for version in version_data['tags'] current_versions.append version['identifier'] if 'branches' in version_data for version in version_data['branches'] current_versions.append version['identifier'] to_delete_qs project.versions.all to_delete_qs to_delete_qs.exclude identifier__in current_versions to_delete_qs to_delete_qs.exclude uploaded True to_delete_qs to_delete_qs.exclude active True to_delete_qs to_delete_qs.exclude slug__in NON_REPOSITORY_VERSIONS if to_delete_qs.count ret_val {obj.slug for obj in to_delete_qs}log.info ' SyncVersions DeletedVersions [%s]' % ''.join ret_val to_delete_qs.delete return ret_valelse return set
def freeze_login_details mc_kwargs mm_kwargs for cls kwargs in Musicmanager mm_kwargs Mobileclient mc_kwargs freeze_method_kwargs cls u'login' **kwargs
def test_syntax_error_with_non_ascii_chars testdir testdir.makepyfile u'\n#-*-coding UTF-8-*-\n\n\u2603\n' result testdir.runpytest result.stdout.fnmatch_lines ['*ERRORcollecting*' '*SyntaxError*' '*1errorin*']
def checkout_branch branch choose_potential_branch N_ u'CheckoutBranch' N_ u'Checkout' if not branch returncmds.do cmds.CheckoutBranch branch
def create_path *args return os.path.join *args
def get_alarm name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile alarms conn.describe_alarms alarm_names [name] if len alarms 0 return Noneif len alarms > 1 log.error "multiplealarmsmatchedname'{0}'".format name return _metric_alarm_to_dict alarms[0]
def CheckInstalledLibrary name desired dependencies PACKAGES[name][1][desired]if dependencies for dep_name dep_version in dependencies AllowInstalledLibrary dep_name dep_version CheckInstalledVersion name desired explicit True
def alignValue value align if value % align ! 0 return value + align - value % align else return value
def selNSGA2 individuals k nd 'standard' if nd 'standard' pareto_fronts sortNondominated individuals k elif nd 'log' pareto_fronts sortLogNondominated individuals k else raise Exception 'selNSGA2 Thechoiceofnon-dominatedsortingmethod"{0}"isinvalid.'.format nd for front in pareto_fronts assignCrowdingDist front chosen list chain *pareto_fronts[ -1 ] k k - len chosen if k > 0 sorted_front sorted pareto_fronts[ -1 ] key attrgetter 'fitness.crowding_dist' reverse True chosen.extend sorted_front[ k] return chosen
def _parse_pattern source info branches [parse_sequence source info ]while source.match '|' branches.append parse_sequence source info if len branches 1 return branches[0]return Branch branches
def print_range range_list return '{}->{}'.format range_list[0] range_list[ -1 ]
def is_unbound_method fn is_bound is_bound_method fn if not is_bound and inspect.isroutine fn spec getargspec fn has_self len spec.args > 0 and spec.args[0] 'self' if PY2 and inspect.ismethod fn return Trueelif inspect.isfunction fn and has_self return Truereturn False
def list_policies ret {}cmd __execute_kadmin 'list_policies' if cmd['retcode'] ! 0 or cmd['stderr'] ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retret {'policies' []}for i in cmd['stdout'].splitlines [1 ] ret['policies'].append i return ret
def getPlugins interface package None if package is None import twisted.plugins as packageallDropins getCache package for key dropin in iteritems allDropins for plugin in dropin.plugins try adapted interface plugin None except log.err else if adapted is not None yield adapted
def s3_get_utc_offset offset Nonesession current.sessionrequest current.requestlogged_in current.auth.is_logged_in if logged_in offset session.auth.user.utc_offsetif offset offset offset.strip if not offset offset request.post_vars.get '_utc_offset' None if offset offset int offset utcstr offset < 0 and '+' or '-' hours abs int offset / 60 minutes abs int offset % 60 offset '%s%02d%02d' % utcstr hours minutes if logged_in session.auth.user.utc_offset offsetif not offset offset current.deployment_settings.L10n.utc_offsetsession.s3.utc_offset offsetreturn offset
def runscope registry xml_parent data runscope XML.SubElement xml_parent 'com.runscope.jenkins.Runscope.RunscopeBuilder' runscope.set 'plugin' 'runscope' mapping [ 'test-trigger-url' 'triggerEndPoint' None 'access-token' 'accessToken' None 'timeout' 'timeout' 60 ]convert_mapping_to_xml runscope data mapping fail_required True
def run_pyflakes no_warnings False files list_files '.py' rval {}for filepath in files output rc run_shell_command 'pyflakes' + filepath output output.decode sys.getdefaultencoding if u'pyflakes notfound' in output raise RuntimeError "Couldn'trun'pyflakes" + filepath + "'.Errorcodereturned " + str rc + 'Outputwas ' + output output _filter output no_warnings if output is not None rval[filepath] outputreturn rval
def _do_scale_test scaled row_sum scaled.sum axis 1 col_sum scaled.sum axis 0 if issparse scaled row_sum np.asarray row_sum .squeeze col_sum np.asarray col_sum .squeeze assert_array_almost_equal row_sum np.tile row_sum.mean 100 decimal 1 assert_array_almost_equal col_sum np.tile col_sum.mean 100 decimal 1
def _parse_exchange_token_response content resp {}content _helpers._from_bytes content try resp json.loads content except Exception resp _helpers.parse_unique_urlencoded content if resp and 'expires' in resp resp['expires_in'] resp.pop 'expires' return resp
def _GetSystemStats request system_service_pb.GetSystemStatsRequest response system_service_pb.GetSystemStatsResponse apiproxy_stub_map.MakeSyncCall 'system' 'GetSystemStats' request response return response
def getencoder encoding return lookup encoding .encode
def triplet anchor positive negative margin 0.2 return Triplet margin anchor positive negative
def extract_option_object option @optiondef opt passreturn opt.__click_params__[0]
def getMirrorPath path close 0.001 * getPathLength path for pointIndex in xrange len path - 1 -1 -1 point path[pointIndex]flipPoint complex - point.real point.imag if abs flipPoint - path[ -1 ] > close path.append flipPoint return path
def _netbios_getnode import win32wnet netbiosncb netbios.NCB ncb.Command netbios.NCBENUMncb.Buffer adapters netbios.LANA_ENUM adapters._pack if win32wnet.Netbios ncb ! 0 returnadapters._unpack for i in range adapters.length ncb.Reset ncb.Command netbios.NCBRESETncb.Lana_num ord adapters.lana[i] if win32wnet.Netbios ncb ! 0 continuencb.Reset ncb.Command netbios.NCBASTATncb.Lana_num ord adapters.lana[i] ncb.Callname '*'.ljust 16 ncb.Buffer status netbios.ADAPTER_STATUS if win32wnet.Netbios ncb ! 0 continuestatus._unpack bytes status.adapter_address[ 6]if len bytes ! 6 continuereturn int.from_bytes bytes 'big'
def flushErrors *errorTypes warnings.warn 'log.flushErrorsisdeprecatedsinceTwisted2.5.Ifyouneedtoflusherrorsfromwithinaunittest useTestCase.flushLoggedErrorsinstead.' category DeprecationWarning stacklevel 2 return _flushErrors *errorTypes
def preprocess_options args search_for i 0while i < len args arg args[i]if arg.startswith '--' try option val arg[2 ].split ' ' 1 except ValueError option val arg[2 ] None try cb takearg search_for[option]except KeyError i + 1else del args[i]if takearg and val is None if i > len args or args[i].startswith '-' msg 'Option%sexpectsavalue' % option raise ArgumentPreprocessingError msg val args[i]del args[i]elif not takearg and val is not None msg "Option%sdoesn'texpectsavalue" % option raise ArgumentPreprocessingError msg cb option val else i + 1
def serial proxy if proxy return {'serial' _get_grain proxy 'serial_number' }
def _make_seg w_prime w per_topic_postings measure gamma backtrack num_docs context_vectors {}if isinstance w_prime np.ndarray for w_j in w for w_i in w_prime if w_i w_j not in backtrack backtrack[ w_i w_j ] measure[0] [[ w_i w_j ]] per_topic_postings num_docs measure[1] [0]if w_j not in context_vectors context_vectors[w_j] backtrack[ w_i w_j ] ** gamma else context_vectors[w_j] + backtrack[ w_i w_j ] ** gamma else for w_j in w if w_prime w_j not in backtrack backtrack[ w_prime w_j ] measure[0] [[ w_prime w_j ]] per_topic_postings num_docs measure[1] [0]context_vectors[w_j] backtrack[ w_prime w_j ] ** gamma return context_vectors backtrack
def strip_non_float_chars s return re.sub '[^-+0123456789.]+' '' six.text_type s
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
def _coerce_to_type x dtype Noneif is_timedelta64_dtype x x to_timedelta x .view np.int64 dtype np.timedelta64elif is_datetime64_dtype x x to_datetime x .view np.int64 dtype np.datetime64return x dtype
def generate_lines text for line in text.splitlines True yield line while True yield ''
def deprecated version replacement None def deprecationDecorator function '\nDecoratorthatmarksC{function}asdeprecated.\n'warningString getDeprecationWarningString function version None replacement @wraps function def deprecatedFunction *args **kwargs warn warningString DeprecationWarning stacklevel 2 return function *args **kwargs _appendToDocstring deprecatedFunction _getDeprecationDocstring version replacement deprecatedFunction.deprecatedVersion versionreturn deprecatedFunctionreturn deprecationDecorator
def _invalidate_star_import_cache_module module only_main False try t modules _time_caches['star_import_cache_validity'][module]except KeyError passelse del _time_caches['star_import_cache_validity'][module]
def monomial_divides A B return all a < b for a b in zip A B
def _calculate_normals rr tris rr rr.astype np.float64 r1 rr[tris[ 0] ]r2 rr[tris[ 1] ]r3 rr[tris[ 2] ]tri_nn _fast_cross_3d r2 - r1 r3 - r1 size np.sqrt np.sum tri_nn * tri_nn axis 1 size[ size 0 ] 1.0tri_nn / size[ np.newaxis]npts len rr nn np.zeros npts 3 for verts in tris.T for idx in range 3 nn[ idx] + np.bincount verts.astype np.int32 tri_nn[ idx] minlength npts size np.sqrt np.sum nn * nn axis 1 size[ size 0 ] 1.0nn / size[ np.newaxis]return nn
def experience s3.filter FS 'person_id$human_resource.type' 1 return s3db.hrm_experience_controller
def _count_nans_per_row_sparse X weights items_per_row 1 if X.ndim 1 else X.shape[1] counts np.ones X.shape[0] * items_per_row nnz_per_row np.bincount X.indices minlength len counts counts - nnz_per_rowif weights is not None counts * weightsreturn np.sum counts
def host_list **connection_args conn_args _login **connection_args try if conn_args method 'host.get'params {'output' 'extend'}ret _query method params conn_args['url'] conn_args['auth'] return ret['result']else raise KeyErrorexcept KeyError return False
def iter_ret opts ret if not opts['ext_job_cache'] raise StopIterationget_load '{0}.get_load'.format opts['ext_job_cache'] get_jid '{0}.get_jid'.format opts['ext_job_cache'] get_jids '{0}.get_jids'.format opts['ext_job_cache'] if get_load not in ret raise StopIterationelse get_load ret[get_load]if get_jid not in ret raise StopIterationelse get_jid ret[get_jid]if get_jids not in ret raise StopIterationelse get_jids ret[get_jids]for jid in get_jids jids {}jids['load'] get_load jid jids['ret'] get_jid jid jids['jid'] jid yield jids
def _extract_inventory body schema data util.extract_json body schema inventory_data copy.copy INVENTORY_DEFAULTS inventory_data.update data return inventory_data
def center_loss features label alfa nrof_classes nrof_features features.get_shape [1]centers tf.get_variable 'centers' [nrof_classes nrof_features] dtype tf.float32 initializer tf.constant_initializer 0 trainable False label tf.reshape label [ -1 ] centers_batch tf.gather centers label diff 1 - alfa * centers_batch - features centers tf.scatter_sub centers label diff loss tf.nn.l2_loss features - centers_batch return loss centers
def test_freeze_with_pip script result script.pip 'freeze' '--all' assert 'pip ' in result.stdout
def _fork_win32 args cwd None if args[0] u'git-dag' args [sys.executable] + args args[0] _win32_find_exe args[0] if PY3 argv [decode arg for arg in args]else argv [encode arg for arg in args]DETACHED_PROCESS 8return subprocess.Popen argv cwd cwd creationflags DETACHED_PROCESS .pid
def cuts_from_string cube string member_converters None role_member_converters None if not string return []cuts []dim_cuts CUT_STRING_SEPARATOR.split string for dim_cut in dim_cuts cut cut_from_string dim_cut cube member_converters role_member_converters cuts.append cut return cuts
def get_dns_hosts context network_ref hosts []for fixedip in objects.FixedIPList.get_by_network context network_ref if fixedip.allocated hosts.append _host_dns fixedip return '\n'.join hosts
def check_shared axs x_shared y_shared shared [axs[0]._shared_x_axes axs[0]._shared_y_axes]for i1 ax1 i2 ax2 i3 name shared in zip enumerate axs enumerate axs enumerate zip u'xy' [x_shared y_shared] if i2 < i1 continueassert shared[i3].joined ax1 ax2 shared[ i1 i2 ] u'axes%iand%iincorrectly%ssharing%saxis' % i1 i2 u'not' if shared[ i1 i2 ] else u'' name
def number_of_cliques G nodes None cliques None if cliques is None cliques list find_cliques G if nodes is None nodes list G.nodes if not isinstance nodes list v nodesnumcliq len [1 for c in cliques if v in c ] else numcliq {}for v in nodes numcliq[v] len [1 for c in cliques if v in c ] return numcliq
def check_magic magic if magic ! 779314790 raise RuntimeError 'Thisfiledoesnotseemstobeansfffile.'
def _get_server_id servers identity for server in servers['items'] if identity in server['properties']['name'] server['id'] return server['id']return None
def find_sample_file filename return find_file filename path os.path.join neutron.__path__[0] '..' 'etc'
def get_redaction_policy return LOG_REDACTION_FILE.get
def convert in_file in_format out_file out_format in_kwargs None out_kwargs None if in_kwargs is None in_kwargs {}if out_kwargs is None out_kwargs {}qresults parse in_file in_format **in_kwargs return write qresults out_file out_format **out_kwargs
def fake_input inputs it iter inputs def mock_input prompt '' try return next it except StopIteration raise EOFError 'Nomoreinputsgiven' return patch 'builtins.input' mock_input
def full_process s force_ascii False if s is None return u''if force_ascii s asciidammit s string_out StringProcessor.replace_non_letters_non_numbers_with_whitespace s string_out StringProcessor.to_lower_case string_out string_out StringProcessor.strip string_out return string_out
def checkout_with_ecommerce_service user course_key course_mode processor course_id unicode course_key try api ecommerce_api_client user result api.baskets.post {'products' [{'sku' course_mode.sku}] 'checkout' True 'payment_processor_name' processor} return result.get 'payment_data' except SlumberBaseException params {'username' user.username 'mode' course_mode.slug 'course_id' course_id}log.exception 'Failedtocreateorderfor% username s% mode smodeof% course_id s' params raisefinally audit_log 'checkout_requested' course_id course_id mode course_mode.slug processor_name processor user_id user.id
def force_global_eggs_after_local_site_packages egginsert getattr sys '__egginsert' 0 for i path in enumerate sys.path if i > egginsert and path.startswith sys.prefix egginsert isys.__egginsert egginsert + 1
def get_members mailchimp list_id status mc_get_members mailchimp.listMembersmembers set for page in itertools.count response mc_get_members id list_id status status start page limit BATCH_SIZE data response.get 'data' [] if not data breakmembers.update d['email'] for d in data return members
def make_remotestatepersister test_case clock Clock control_amp_service client make_loopback_control_client test_case reactor clock persistence_service control_amp_service.configuration_servicereturn RemoteStatePersister client client lambda persistence_service.get .persistent_state
def urlsplit absolute_uri match SPLIT_MATCH absolute_uri if match g match.groups return g[1] g[3] g[4] g[6] g[8]
def _applyConstraints blockVectorV factYBY blockVectorBY blockVectorY gramYBV np.dot blockVectorBY.T blockVectorV tmp cho_solve factYBY gramYBV blockVectorV - np.dot blockVectorY tmp
def do_test_bloom test_logs for data in test_logs address data['address']b bloom.bloom_insert 0 decode_hex address for t in data['topics'] b bloom.bloom_insert b decode_hex t topics [decode_int_from_hex x for x in data['topics']]log pb.Log decode_hex address topics '' log_bloom bloom.b64 bloom.bloom_from_list log.bloomables assert encode_hex log_bloom encode_hex_from_int b assert str_to_bytes data['bloom'] encode_hex log_bloom
def pypackable name pytype format size items _formatinfo format return type Packable name pytype Packable {'_format_' format '_size_' size '_items_' items}
def teensy_config choice return {'1' 'powershell_down.ino' '2' 'wscript.ino' '3' 'powershell_reverse.ino' '4' 'beef.ino' '5' 'java_applet.ino' '6' 'gnome_wget.ino'}.get choice 'ERROR'
def addCylinder faces inradius sides topOverBottom vertexes polygonBottom euclidean.getComplexPolygonByComplexRadius complex inradius.x inradius.y sides polygonTop polygonBottomif topOverBottom < 0.0 polygonTop [complex ]elif topOverBottom ! 1.0 polygonTop euclidean.getComplexPathByMultiplier topOverBottom polygonTop bottomTopPolygon [triangle_mesh.getAddIndexedLoop polygonBottom vertexes - inradius.z triangle_mesh.getAddIndexedLoop polygonTop vertexes inradius.z ]triangle_mesh.addPillarByLoops faces bottomTopPolygon
@utils.service_type 'monitor' def do_backup_list cs args backups cs.backups.list columns ['ID' 'ServiceManageID' 'Status' 'Name' 'Size' 'ObjectCount' 'Container']utils.print_list backups columns
def banner if not any _ in sys.argv for _ in '--version' '--pickled-options' _ BANNERif not getattr LOGGER_HANDLER 'is_tty' False or '--disable-coloring' in sys.argv _ re.sub '\x1b.+?m' '' _ elif IS_WIN coloramainit dataToStdout _ forceOutput True
def p_type_qualifier t pass
def require_tool tool_name path os.environ.get 'PATH' if not path return Falsefor searchdir in path.split os.pathsep executable1 os.path.normpath os.path.join searchdir tool_name executables [executable1]if sys.platform.startswith 'win' executables.append executable1 + '.exe' for executable in executables if os.path.isfile executable return Truereturn False
def get_current_url environ root_only False strip_querystring False host_only False trusted_hosts None tmp [environ['wsgi.url_scheme'] ' //' get_host environ trusted_hosts ]cat tmp.appendif host_only return uri_to_iri ''.join tmp + '/' cat url_quote wsgi_get_bytes environ.get 'SCRIPT_NAME' '' .rstrip '/' cat '/' if not root_only cat url_quote wsgi_get_bytes environ.get 'PATH_INFO' '' .lstrip '/' if not strip_querystring qs get_query_string environ if qs cat '?' + qs return uri_to_iri ''.join tmp
def test_module_scope_is_updated_on_patch expected_attrs from gooey.gui import image_repositorytesting_icons 'config_icon.png' 'success_icon.png' try make_user_files *testing_icons old_icon image_repository.config_iconimage_repository.patch_images tempfile.tempdir new_icon image_repository.config_iconassert old_icon ! new_icon finally cleanup_temp *testing_icons
def s3_auth_on_login form s3_clear_session
def is_frozen G try return G.frozenexcept AttributeError return False
def deprecated version replacement None def deprecationDecorator function '\nDecoratorthatmarksC{function}asdeprecated.\n'warningString getDeprecationWarningString function version None replacement @wraps function def deprecatedFunction *args **kwargs warn warningString DeprecationWarning stacklevel 2 return function *args **kwargs _appendToDocstring deprecatedFunction _getDeprecationDocstring version replacement deprecatedFunction.deprecatedVersion versionreturn deprecatedFunctionreturn deprecationDecorator
def check_firefox_version expected_firefox_ver 'MozillaFirefox' + str MINIMUM_FIREFOX_VERSION firefox_ver_string subprocess.check_output 'firefox--version' shell True .strip firefox_version_regex re.compile 'MozillaFirefox \\d+.\\d+ ' try firefox_ver float firefox_version_regex.search firefox_ver_string .group 1 except AttributeError firefox_ver 0.0debian_location 'https //s3.amazonaws.com/vagrant.testeng.edx.org/'debian_package 'firefox-mozilla-build_42.0-0ubuntu1_amd64.deb'debian_path '{location}{package}'.format location debian_location package debian_package if firefox_ver < MINIMUM_FIREFOX_VERSION raise Exception 'Requiredfirefoxversionnotfound.\nExpected {expected_version};Actual {actual_version}.\n\nAsthevagrantuserindevstack runthefollowing \n\n DCTB $sudowget-O/tmp/firefox_42.deb{debian_path}\n DCTB $sudoapt-getremovefirefox\n\n DCTB $sudogdebi-nq/tmp/firefox_42.deb\n\nConfirmthenewversion \n DCTB $firefox--version\n DCTB {expected_version}'.format actual_version firefox_ver expected_version expected_firefox_ver debian_path debian_path
def getargspec f spec getfullargspec f return ArgSpec spec.args spec.varargs spec.varkw spec.defaults
def generate_sub_created_events src_dir_path for root directories filenames in os.walk src_dir_path for directory in directories yield DirCreatedEvent os.path.join root directory for filename in filenames yield FileCreatedEvent os.path.join root filename
def getComplexByFloatList floatList valueComplex if len floatList > 0 valueComplex complex euclidean.getFloatFromValue floatList[0] valueComplex.imag if len floatList > 1 valueComplex complex valueComplex.real euclidean.getFloatFromValue floatList[1] return valueComplex
@block_user_agents@login_required@permission_required 'wiki.delete_document' @check_readonly@process_document_pathdef delete_document request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug prevent document.children.exists first_revision document.revisions.all [0]if request.method 'POST' form DocumentDeletionForm data request.POST if form.is_valid DocumentDeletionLog.objects.create locale document.locale slug document.slug user request.user reason form.cleaned_data['reason'] document.delete return redirect document else form DocumentDeletionForm context {'document' document 'form' form 'request' request 'revision' first_revision 'prevent' prevent}return render request 'wiki/confirm_document_delete.html' context
def rotate_90_counterclockwise request fileobjects transpose_image request fileobjects 2
def FitLine xs inter slope fit_xs np.sort xs fit_ys inter + slope * fit_xs return fit_xs fit_ys
def comparable_formats return [u'png'] + list converter
def is_html ct_headers url allow_xhtml False if not ct_headers ext os.path.splitext _rfc3986.urlsplit url [2] [1]html_exts ['.htm' '.html']if allow_xhtml html_exts + ['.xhtml']return ext in html_exts ct split_header_words ct_headers [0][0][0]html_types ['text/html']if allow_xhtml html_types + ['text/xhtml' 'text/xml' 'application/xml' 'application/xhtml+xml']return ct in html_types
def _tweet_for_template tweet https False data json.loads tweet.raw_json parsed_date parsedate data['created_at'] date datetime *parsed_date[0 6] if settings.CC_SHOW_REPLIES replies _get_tweets limit 0 reply_to tweet https https else replies Noneif 'from_user' in data user_data datafrom_user data['from_user']else user_data data['user']from_user user_data['screen_name']if https img bleach.clean user_data['profile_image_url_https'] else img bleach.clean user_data['profile_image_url'] return {'profile_img' img 'user' from_user 'text' bleach.clean data['text'] 'id' tweet.pk 'date' date 'reply_count' len replies if replies else 0 'replies' replies 'reply_to' tweet.reply_to and tweet.reply_to.pk 'hidden' tweet.hidden}
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
@ThrowsWebAppException error_code IMAGE_DECODE_ERROR def read_image base64_image enc_data base64.b64decode base64_image file_like cStringIO.StringIO enc_data im Image.open file_like im im.convert 'L' return im
@_docstring 'series' def search_series query '' limit None offset None strict False **fields return _do_mb_search 'series' query fields limit offset strict
def _gen_starting_points shape ny nx shapexfirst 0yfirst 1xlast nx - 1 ylast ny - 1 x y 0 0 i 0direction u'right'for i in xrange nx * ny yield x y if direction u'right' x + 1if x > xlast xlast - 1direction u'up'elif direction u'up' y + 1if y > ylast ylast - 1direction u'left'elif direction u'left' x - 1if x < xfirst xfirst + 1direction u'down'elif direction u'down' y - 1if y < yfirst yfirst + 1direction u'right'
def _flush_dscl_cache __salt__['cmd.run'] ['dscacheutil' '-flushcache'] python_shell False
def applicationInformation a TpPd pd 6 b MessageType mesType 56 c ApduIDAndApduFlags e ApduData packet a / b / c / e return packet
def post_form_view request return post_form_response
def step_runner_environ from lettuce import registryregistry.clear @step 'Ihaveadefinedstep' def have_a_defined_step *args **kw assert True@step 'otherstepfails' def and_another *args **kw assert False 'Itshouldfail'@step 'defineastep' def define_a_step *args **kw assert True@step u'WhenIhaveastepthatraisesanexception' def raises_exception step raise Exception @step 'Ihaveastepwhichcallsthe" .* "stepwithbehave_as' def runs_some_other_step_with_behave_as step something_else step.behave_as 'When% i_do_something_else s' % {'i_do_something_else' something_else}
def _passive_handler store **kwargs def wrapper cls funcs ['on_request' 'on_inject_request' 'on_response' 'on_inject_response']for func in funcs f _passive_handler_func getattr cls func setattr cls func f return handler store passive True **kwargs cls return wrapper
def migration_get_all_by_filters context filters return IMPL.migration_get_all_by_filters context filters
def is_form_post environ content_type environ.get 'CONTENT_TYPE' '' .lower if ';' in content_type content_type content_type.split ';' 1 [0]return content_type in 'application/x-www-form-urlencoded' 'multipart/form-data'
def sanitize_illegal_chars_for_xml s warnings.warn u'reviewboard.reviews.markdown_utils.sanitize_illegal_chars_for_xmlisdeprecated.Pleaseusedjblets.markdown.sanitize_illegal_chars_for_xml.' DeprecationWarning return djblets_markdown.sanitize_illegal_chars_for_xml s
def bitcount num num num - num >> 1 & 6148914691236517205 num num & 3689348814741910323 + num >> 2 & 3689348814741910323 num num + num >> 4 & 1085102592571150095 return int num * 72340172838076673 >> 56
def set_restart_delay seconds if seconds % 30 ! 0 msg 'Invalidvaluepassedforseconds.\nMustbeamultipleof30.\nPassed {0}'.format seconds raise SaltInvocationError msg cmd 'systemsetup-setwaitforstartupafterpowerfailure{0}'.format seconds salt.utils.mac_utils.execute_return_success cmd return salt.utils.mac_utils.confirm_updated seconds get_restart_delay
def __parse_xml_metadata xml_dic xml_node for child in xml_node.getchildren if child.get 'Name' 'cl.exe' xml_dic['compiler_version'] child.get 'Version' elif child.get 'Name' 'VisualStudio' xml_dic['visual_studio_version'] child.get 'Version' elif child.get 'Name' 'VisualStudioEdition' xml_dic['visual_studio_edition'] child.get 'Value' elif child.get 'Name' 'OperatingSystem' xml_dic['target_os'] child.get 'Version' elif child.get 'Name' 'Microsoft.Build.AppxPackage.dll' xml_dic['appx_dll_version'] child.get 'Version' elif child.get 'Name' 'ProjectGUID' xml_dic['proj_guid'] child.get 'Value' elif child.get 'Name' 'OptimizingToolset' xml_dic['opti_tool'] child.get 'Value' elif child.get 'Name' 'TargetRuntime' xml_dic['target_run'] child.get 'Value' return xml_dic
@register.inclusion_tag u'breadcrumbs.html' def feincms_breadcrumbs page include_self True ancs page.get_ancestors bc [ anc.get_absolute_url anc.short_title for anc in ancs]if include_self bc.append None page.short_title return {u'trail' bc}
def folder_size pth ignore None if not os.path.isdir pth raise exc.FolderNotFoundignore coerce_to_list ignore def get_size total root names paths [os.path.realpath os.path.join root nm for nm in names]for pth in paths[ -1 ] if not os.path.exists pth paths.remove pth elif os.path.isdir pth paths.remove pth elif match_pattern pth ignore paths.remove pth total[0] + sum os.stat pth .st_size for pth in paths total [0]os.path.walk pth get_size total return total[0]
def get_test_fname fname path os.path.dirname __file__ full_path os.path.join path 'test' fname return full_path
def _InitNinjaFlavor params target_list target_dicts for qualified_target in target_list spec target_dicts[qualified_target]if spec.get 'msvs_external_builder' continuepath_to_ninja spec.get 'msvs_path_to_ninja' 'ninja.exe' spec['msvs_external_builder'] 'ninja'if not spec.get 'msvs_external_builder_out_dir' gyp_file _ _ gyp.common.ParseQualifiedTarget qualified_target gyp_dir os.path.dirname gyp_file configuration '$ Configuration 'if params.get 'target_arch' 'x64' configuration + '_x64'spec['msvs_external_builder_out_dir'] os.path.join gyp.common.RelativePath params['options'].toplevel_dir gyp_dir ninja_generator.ComputeOutputDir params configuration if not spec.get 'msvs_external_builder_build_cmd' spec['msvs_external_builder_build_cmd'] [path_to_ninja '-C' '$ OutDir ' '$ ProjectName ']if not spec.get 'msvs_external_builder_clean_cmd' spec['msvs_external_builder_clean_cmd'] [path_to_ninja '-C' '$ OutDir ' '-tclean' '$ ProjectName ']
def _consolidate sets k G nx.Graph nodes {i s for i s in enumerate sets }G.add_nodes_from nodes G.add_edges_from u v for u v in combinations nodes 2 if len nodes[u] & nodes[v] > k for component in nx.connected_components G yield set.union *[nodes[n] for n in component]
def access_settings service groupId settings group service.groups g group.get groupUniqueId groupId .execute print '\nGrouppropertiesforgroup%s\n' % g['name'] pprint.pprint g if not settings.keys print '\nGiveaccessparameterstoupdategroupaccesspermissions\n' returnbody {}for key in settings.iterkeys if settings[key] is not None body[key] settings[key]g1 group.update groupUniqueId groupId body body .execute print '\nUpdatedAccessPermissionstothegroup\n' pprint.pprint g1
def _ImageHeaderFactory stream from docx.image import SIGNATURESdef read_32 stream stream.seek 0 return stream.read 32 header read_32 stream for cls offset signature_bytes in SIGNATURES end offset + len signature_bytes found_bytes header[offset end]if found_bytes signature_bytes return cls.from_stream stream raise UnrecognizedImageError
def bytes_chr i raise Exception 'Shouldbeoverriden'
def _PresentatableKindStats kind_ent count kind_ent.countentity_bytes kind_ent.entity_bytestotal_bytes kind_ent.bytesaverage_bytes entity_bytes / count return {'kind_name' kind_ent.kind_name 'count' utils.FormatThousands kind_ent.count 'entity_bytes_str' utils.GetPrettyBytes entity_bytes 'entity_bytes' entity_bytes 'total_bytes_str' utils.GetPrettyBytes total_bytes 'total_bytes' total_bytes 'average_bytes_str' utils.GetPrettyBytes average_bytes }
def enable_site site_name if not is_site_enabled site_name run_as_root 'a2ensite%s' % _site_config_filename site_name
def get_meter_columns metaquery None need_timestamp False **kwargs columns ['f message' 'f recorded_at']columns.extend 'f %s' % k for k v in kwargs.items if v is not None if metaquery columns.extend 'f r_%s' % k for k v in metaquery.items if v is not None source kwargs.get 'source' if source columns.append 'f s_%s' % source if need_timestamp columns.extend ['f rts' 'f timestamp'] return columns
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def send query query json.loads query if query.get '_color' query['data'] json.dumps {'xy' xy_color query['_color'] } conn httplib.HTTPConnection query.get 'host' conn.request query.get 'method' query.get 'url' query.get 'data'
def _check_ironic_client_enabled if ironic_client is None common.raise_feature_not_supported
def MailItemPropertyFromString xml_string return atom.CreateClassFromXMLString MailItemProperty xml_string
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def grep pattern file command 'grep"%s">/dev/null' % pattern ret cat_file_to_cmd file command ignore_status True return not ret
def filterListValue value regex if isinstance value list and regex retVal filter lambda _ re.search regex _ re.I value else retVal valuereturn retVal
def skip_if_not_available modules None datasets None configurations None if modules is None modules []if datasets is None datasets []if configurations is None configurations []for module in modules try import_module module except Exception raise SkipTestif module 'bokeh' ConnectionError import_module 'requests.exceptions' .ConnectionErrorsession import_module 'bokeh.session' .Session try session.execute 'get' session.base_url except ConnectionError raise SkipTestif datasets and not hasattr config 'data_path' raise SkipTestfor dataset in datasets if not os.path.exists os.path.join config.data_path dataset raise SkipTestfor configuration in configurations if not hasattr config configuration raise SkipTest
def from_links container toc TOC link_path XPath u'//h a[@href]' seen_titles seen_dests set set for spinepath in container.spine_items name container.abspath_to_name spinepath root container.parsed name for a in link_path root href a.get u'href' if not href or not href.strip continuedest container.href_to_name href base name frag href.rpartition u'#' [ -1 ] or None if dest frag in seen_dests continueseen_dests.add dest frag text elem_to_toc_text a if text in seen_titles continueseen_titles.add text toc.add text dest frag frag verify_toc_destinations container toc for child in toc if not child.dest_exists toc.remove child return toc
def in6_addrtomac addr mask inet_pton socket.AF_INET6 ' ffff ffff ffff ffff' x in6_and mask inet_pton socket.AF_INET6 addr ifaceid inet_ntop socket.AF_INET6 x [2 ]return in6_ifaceidtomac ifaceid
def allocate_ids model size **kwargs return allocate_ids_async model size **kwargs .get_result
def process_files f1 f2 f get_contents f1 f2 if not len f[0].strip and not len f[1].strip return True True f remove_shbang *f f remove_encoding *f f remove_licence_future *f f remove_first_comment *f f replace_PatchStim *f f replace_xrange *f f replace_myWin_win *f f remove_semicolon *f f remove_win_close *f f remove_core_quit *f f flatten_content *f return f
def do_pprint value verbose False return pformat value verbose verbose
def spearman v1 v2 v1 v2 array v1 array v2 if not v1.size v2.size > 1 raise ValueError "Oneormorevectorsisn'tlongenoughtocorrelateortheyhaveunequallengths." return spearmanr v1 v2 [0]
@must_have_addon SHORT_NAME 'node' @must_be_addon_authorizer SHORT_NAME def box_folder_list node_addon **kwargs folder_id request.args.get 'folder_id' return node_addon.get_folders folder_id folder_id
def _arr2img ar return Image.frombytes 'L' ar.shape[1] ar.shape[0] ar.astype numpy.ubyte .tostring
def DEMA ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.DEMA timeperiod
def getInclination end start if end None or start None return 0.0endMinusStart end - start return math.atan2 endMinusStart.z abs endMinusStart.dropAxis
def check_installation if can_import 'requests' import requestsrequests_version requests.__version__else requests_version 'no'if can_import 'OpenSSL' import OpenSSLopenssl_version OpenSSL.__version__else openssl_version 'no'if can_import 'cryptography' import cryptographycryptography_version cryptography.__version__else cryptography_version 'no'if can_import 'pyasn1' import pyasn1pyasn1_version pyasn1.__version__else pyasn1_version 'no'if can_import 'ndg.httpsclient' from ndg import httpsclientndg_version httpsclient.__date__else ndg_version 'no'sys.stdout.write '*CheckingPythonversion %s.%s.%s\n' % sys.version_info[ 3] sys.stdout.write '*Operatingsystem %s\n' % sys.platform sys.stdout.write '*Checkingifrequestscanbeimported %s\n' % requests_version sys.stdout.write '*CheckingifpyOpenSSLisinstalled %s\n' % openssl_version sys.stdout.write '*Checkingifcryptographyisinstalled %s\n' % cryptography_version sys.stdout.write '*Checkingifpyasn1isinstalled %s\n' % pyasn1_version sys.stdout.write '*Checkingifndg.httpsclientisinstalled %s\n' % ndg_version
def _tps distsq out np.zeros_like distsq mask distsq > 0 valid distsq[mask]out[mask] valid * np.log valid return out
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def p_direct_declarator_6 t pass
def warn msg stacklevel 3 if isinstance msg compat.string_types warnings.warn msg exc.SAWarning stacklevel stacklevel else warnings.warn msg stacklevel stacklevel
def expect_types __funcname _qualified_name **named for name type_ in iteritems named if not isinstance type_ type tuple raise TypeError "expect_types expectedatypeortupleoftypesforargument'{name}' butgot{type_}instead.".format name name type_ type_ def _expect_type type_ _template "% funcname s expectedavalueoftype{type_or_types}forargument'% argname s' butgot% actual sinstead."if isinstance type_ tuple template _template.format type_or_types 'or'.join map _qualified_name type_ else template _template.format type_or_types _qualified_name type_ return make_check exc_type TypeError template template pred lambda v not isinstance v type_ actual compose _qualified_name type funcname __funcname return preprocess **valmap _expect_type named
def _is_indirect member doc d member in doc e 'indirectdoctest' in doc if not d and not e return Trueelse return False
def getFrontOverWidthAddXListYList front loopLists numberOfLines xIntersectionIndexLists width yList frontOverWidth getFrontOverWidthAddYList front numberOfLines xIntersectionIndexLists width yList for loopListIndex in xrange len loopLists loopList loopLists[loopListIndex]addXIntersectionIndexesFromLoops frontOverWidth loopList loopListIndex xIntersectionIndexLists width yList return frontOverWidth
def check_newlines fname bytes_to_read 52428800 CHUNK_SIZE 2 ** 20 f open fname 'r' for chunk in f.read CHUNK_SIZE if f.tell > bytes_to_read breakif chunk.count '\r' f.close return Truef.close return False
def validate_local_ip local_ip if not ip_lib.IPWrapper .get_device_by_ip local_ip LOG.error _LE "Tunnelingcan'tbeenabledwithinvalidlocal_ip'%s'.IPcouldn'tbefoundonthishost'sinterfaces." local_ip raise SystemExit 1
def RGS_rank rgs rgs_size len rgs rank 0D RGS_generalized rgs_size for i in range 1 rgs_size n len rgs[ i + 1 ] m max rgs[0 i] rank + D[ n m + 1 ] * rgs[i] return rank
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
@pytest.mark.parametrize u'testframe' totest_frames def test_cirs_altaz_moonish testframe moon CIRS MOONDIST_CART obstime testframe.obstime moonaa moon.transform_to testframe assert 1000 * u.km < np.abs moonaa.distance - moon.distance .to u.km < 7000 * u.km moon2 moonaa.transform_to moon assert_allclose moon.cartesian.xyz moon2.cartesian.xyz
def _negotiate_value response if hasattr _negotiate_value 'regex' regex _negotiate_value.regexelse regex re.compile ' ? .* *\\s*Negotiate\\s* [^ ]* ?' re.I _negotiate_value.regex regexauthreq response.headers.get 'www-authenticate' None if authreq match_obj regex.search authreq if match_obj return match_obj.group 1 return None
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def is_server_resolvable socket_timeout socket.getdefaulttimeout socket.setdefaulttimeout 1 try socket.gethostbyname 'server' return Trueexcept socket.error return Falsefinally socket.setdefaulttimeout socket_timeout
def get_cms_block_link block page return u'//{}/{}/{}'.format settings.CMS_BASE page block.location
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def skel_setup environment inventory for key value in environment.iteritems if key 'version' continuefor _key _value in value.iteritems if _key not in inventory logger.debug 'Key%saddedtoinventory' _key inventory[_key] {}if _key.endswith 'container' if 'hosts' not in inventory[_key] inventory[_key]['hosts'] []else if 'children' not in inventory[_key] inventory[_key]['children'] []if 'hosts' not in inventory[_key] inventory[_key]['hosts'] []if 'belongs_to' in _value for assignment in _value['belongs_to'] if assignment not in inventory logger.debug 'Createdgroup%s' assignment inventory[assignment] {}if 'children' not in inventory[assignment] inventory[assignment]['children'] []if 'hosts' not in inventory[assignment] inventory[assignment]['hosts'] []
def _match_label_with_color label colors bg_label bg_color if bg_color is None bg_color 0 0 0 bg_color _rgb_vector [bg_color] unique_labels mapped_labels np.unique label return_inverse True bg_label_rank_list mapped_labels[ label.flat bg_label ]if len bg_label_rank_list > 0 bg_label_rank bg_label_rank_list[0]mapped_labels[ mapped_labels < bg_label_rank ] + 1mapped_labels[ label.flat bg_label ] 0else mapped_labels + 1color_cycle itertools.cycle colors color_cycle itertools.chain bg_color color_cycle return mapped_labels color_cycle
def approx_hessian point vars None model None from numdifftools import Jacobianmodel modelcontext model if vars is None vars model.cont_varsvars inputvars vars point Point point model model bij DictToArrayBijection ArrayOrdering vars point dlogp bij.mapf model.fastdlogp vars def grad_logp point return np.nan_to_num dlogp point '\nFindthejacobianofthegradientfunctionatthecurrentposition\nthisshouldbetheHessian;invertittofindtheapproximate\ncovariancematrix.\n'return - Jacobian grad_logp bij.map point
def ytdl_is_updateable from zipimport import zipimporterreturn isinstance globals .get u'__loader__' zipimporter or hasattr sys u'frozen'
def _open_shelve shelffn withclosing False import shelveshelf shelve.open shelffn protocol 2 if withclosing return contextlib.closing shelf else return shelf
def get_modified_time storage name try modified_time storage.modified_time name except OSError return 0except NotImplementedError return Noneif modified_time and timezone.is_naive modified_time if getattr settings 'USE_TZ' False default_timezone timezone.get_default_timezone return timezone.make_aware modified_time default_timezone return modified_time
def is_valid_mpls_labels labels if not isinstance labels list tuple return Falsefor label in labels if not is_valid_mpls_label label return Falsereturn True
def no_prefix name return name.startswith 'E' and not name.startswith 'EVENT'
def copy_model_instance obj exclude None exclude exclude or initial dict f.name getattr obj f.name for f in obj._meta.fields if not isinstance f AutoField and f.name not in exclude and f not in obj._meta.parents.values return obj.__class__ **initial
def validate_connection_status value if value.lower not in ['planned' 'connected'] raise ValidationError 'Invalidconnectionstatus {} ;mustbeeither"planned"or"connected".'.format value
def het_arch resid maxlag None autolag None store False regresults False ddof 0 return acorr_lm resid ** 2 maxlag maxlag autolag autolag store store regresults regresults
def assure_image fnc @wraps fnc def _wrapped self img *args **kwargs if not isinstance img Image img self._manager.get img return fnc self img *args **kwargs return _wrapped
def right_join left right left_vars right_vars indices right_join_indices left right left_vars right_vars return join_table_by_indices left right indices
def parse_set_inter source info items [parse_set_diff source info ]while source.match '&&' items.append parse_set_diff source info if len items 1 return items[0]return SetInter info items
def choose_package file_type file_name if not file_type return Nonefile_type file_type.lower file_name file_name.lower if 'apk' in file_name return 'apk'elif 'zip' in file_type return 'apk'else return 'apk'
def skip_without_tool tool_id def method_wrapper method def get_tool_ids api_test_case index api_test_case.galaxy_interactor.get 'tools' data dict in_panel False tools index.json tool_ids [itemgetter 'id' _ for _ in tools]return tool_idsdef wrapped_method api_test_case *args **kwargs if tool_id not in get_tool_ids api_test_case from nose.plugins.skip import SkipTestraise SkipTest return method api_test_case *args **kwargs wrapped_method.__name__ method.__name__return wrapped_methodreturn method_wrapper
def load_smbclient_auth_file path lineno 0domain Noneusername Nonepassword Nonefor line in open path lineno + 1line line.strip if line.startswith '#' or line '' continueparts line.split ' ' 1 if len parts ! 2 raise AuthFileSyntaxError path lineno 'No" "presentinline' k v parts[0].strip parts[1].strip if k 'username' username velif k 'password' password velif k 'domain' domain velse raise AuthFileSyntaxError path lineno 'Unknownoption%s' % repr k return domain username password
def _get_journal if 'systemd.journald' in __context__ return __context__['systemd.journald']__context__['systemd.journald'] systemd.journal.Reader __context__['systemd.journald'].seek_tail __context__['systemd.journald'].get_previous return __context__['systemd.journald']
def root_test return True
def callWithLogger logger func *args **kw try lp logger.logPrefix except KeyboardInterrupt raiseexcept lp ' buggylogPrefixmethod 'err system lp try return callWithContext {'system' lp} func *args **kw except KeyboardInterrupt raiseexcept err system lp
def _step_ids_for_job steps job_key step_ids []for step in steps if step.name.startswith job_key step_ids.append step.id return step_ids
def find_release_date_source xblock if xblock.category 'chapter' return xblockparent_location modulestore .get_parent_location xblock.location revision ModuleStoreEnum.RevisionOption.draft_preferred if not parent_location return xblockparent modulestore .get_item parent_location if parent.start ! xblock.start return xblockelse return find_release_date_source parent
def part rebulk Rebulk .regex_defaults flags re.IGNORECASE abbreviations [dash] validator {'__parent__' seps_surround} prefixes ['pt' 'part']def validate_roman match '\nValidatearomanmatchifsurroundedbyseparators\n parammatch \n typematch \n return \n rtype \n'if int_coercable match.raw return Truereturn seps_surround match rebulk.regex build_or_pattern prefixes + '-? ?P<part>' + numeral + ' ' prefixes prefixes validate_all True private_parent True children True formatter parse_numeral validator {'part' compose validate_roman lambda m 0 < m.value < 100 } return rebulk
def _choose_random_tests tests ratio seed rnd random.Random rnd.seed seed if isinstance tests unittest.TestSuite tests _flatten_suite tests tests rnd.sample tests int len tests * ratio tests sorted tests key lambda case case.id return unittest.TestSuite tests
def GetSecretsManagerForSecret secret global _user_secrets_managerif _user_secrets_manager is not None and _user_secrets_manager.HasSecret secret return _user_secrets_managerreturn GetSharedSecretsManager
def test_type_constructor_overloads global calledimport clrclr.AddReference 'IronPythonTest' import IronPythonTest.interop.net.type.clrtype as IPTcalled Falseclass MyType type def __clrtype__ self global calledcalled Truereturn IPT.SanityConstructorOverloadsclass X object __metaclass__ MyTypedef __init__ self *args **kwargs passAreEqual called True temp X Assert str temp .startswith '<first' str temp
def is_lyrics_content_ok title text keywords LYRICS_TEXTS[google.slugify title ]return all x in text.lower for x in keywords
def nearest_roads client points params {'points' convert.location_list points }return client._get '/v1/nearestRoads' params base_url _ROADS_BASE_URL accepts_clientid False extract_body _roads_extract .get 'snappedPoints' []
@pytest.mark.parametrize 'text expected' [ 'one<tw>o' 'one|two' '<one>two' '|onetwo' '|onetwo' '|onetwo' ] def test_rl_backward_word text expected lineedit bridge lineedit.set_aug_text text bridge.rl_backward_word assert lineedit.aug_text expected
def clear_uuids apps schema_editor Document apps.get_model u'wiki' u'Document' Document.objects.exclude uuid__isnull True .update uuid None
def get_partial_date_formats warnings.warn "'django.utils.translation.get_partial_date_formats'isdeprecated.Pleaseupdateyourcodetousethenewi18nawareformatting." PendingDeprecationWarning from google.appengine._internal.django.conf import settingsyear_month_format ugettext 'YEAR_MONTH_FORMAT' month_day_format ugettext 'MONTH_DAY_FORMAT' if year_month_format 'YEAR_MONTH_FORMAT' year_month_format settings.YEAR_MONTH_FORMATif month_day_format 'MONTH_DAY_FORMAT' month_day_format settings.MONTH_DAY_FORMATreturn year_month_format month_day_format
def binary_crossentropy y_true y_pred y_true tf.cast y_true tf.float32 y_pred logit tf.cast y_pred tf.float32 return tf.reduce_mean tf.nn.sigmoid_cross_entropy_with_logits y_pred y_true
def _deprecated_configs agentConfig deprecated_checks {}deprecated_configs_enabled [v for k v in OLD_STYLE_PARAMETERS if len [l for l in agentConfig if l.startswith k ] > 0 ]for deprecated_config in deprecated_configs_enabled msg 'Configuring%sindatadog.confisnotsupportedanymore.Pleaseuseconf.d' % deprecated_config deprecated_checks[deprecated_config] {'error' msg 'traceback' None}log.error msg return deprecated_checks
@core_helperdef url_for_static_or_external *args **kw def fix_arg arg url urlparse.urlparse str arg url_is_relative url.scheme '' and url.netloc '' and not url.path.startswith '/' if url_is_relative return '/' + url.geturl return url.geturl if args args fix_arg args[0] + args[1 ] if kw.get 'qualified' False kw['protocol'] kw['host'] get_site_protocol_and_host my_url _routes_default_url_for *args **kw return _local_url my_url locale 'default' **kw
def safe_max_abs A ia if np.sum ia return np.max np.abs A[ia] else return 0.0
def format_in_original_format numobj region_calling_from if numobj.raw_input is not None and _has_unexpected_italian_leading_zero numobj or not _has_formatting_pattern_for_number numobj return numobj.raw_inputif numobj.country_code_source is None return format_number numobj PhoneNumberFormat.NATIONAL formatted_number _format_original_allow_mods numobj region_calling_from num_raw_input numobj.raw_inputif formatted_number is not None and num_raw_input normalized_formatted_number _normalize_diallable_chars_only formatted_number normalized_raw_input _normalize_diallable_chars_only num_raw_input if normalized_formatted_number ! normalized_raw_input formatted_number num_raw_inputreturn formatted_number
def complex_accuracy result re im re_acc im_acc resultif not im if not re return INFreturn re_accif not re return im_accre_size fastlog re im_size fastlog im absolute_error max re_size - re_acc im_size - im_acc relative_error absolute_error - max re_size im_size return - relative_error
def libvlc_media_player_set_pause mp do_pause f _Cfunctions.get 'libvlc_media_player_set_pause' None or _Cfunction 'libvlc_media_player_set_pause' 1 1 None None MediaPlayer ctypes.c_int return f mp do_pause
def get_complex_part expr no prec options workprec preci 0while 1 res evalf expr workprec options value accuracy res[no 2]if not value or accuracy > prec or - value[2] > prec return value None accuracy None workprec + max 30 2 ** i i + 1
def dup_sturm f K if not K.has_Field raise DomainError "can'tcomputeSturmsequenceover%s" % K f dup_sqf_part f K sturm [f dup_diff f 1 K ]while sturm[ -1 ] s dup_rem sturm[ -2 ] sturm[ -1 ] K sturm.append dup_neg s K return sturm[ -1 ]
def ifloordiv a b a // breturn a
def list_ profile 'splunk' client _get_splunk profile searches [x['name'] for x in client.saved_searches]return searches
def scp_to ip_address keyname local_file remote_file key_file '{}/{}.key'.format KEY_DIRECTORY keyname remote_location '{} {}'.format ip_address remote_file scp_cmd ['scp' '-i' key_file local_file remote_location]subprocess.check_call scp_cmd
def draw_figure canvas figure loc 0 0 figure_canvas_agg FigureCanvasAgg figure figure_canvas_agg.draw figure_x figure_y figure_w figure_h figure.bbox.bounds figure_w figure_h int figure_w int figure_h photo tk.PhotoImage master canvas width figure_w height figure_h canvas.create_image loc[0] + figure_w / 2 loc[1] + figure_h / 2 image photo tkagg.blit photo figure_canvas_agg.get_renderer ._renderer colormode 2 return photo
@hook 'after_request' def security_headers json_header True response.headers['Server'] 'Server'response.headers['X-Content-Type-Options'] 'nosniff'response.headers['X-Frame-Options'] 'DENY'response.headers['X-XSS-Protection'] '1;mode block'response.headers['Pragma'] 'no-cache'response.headers['Cache-Control'] 'no-cache'response.headers['Expires'] '0'if json_header response.content_type 'application/json;charset UTF-8'
def bull_graph create_using None description ['adjacencylist' 'BullGraph' 5 [[2 3] [1 3 4] [1 2 5] [2] [3]]]G make_small_undirected_graph description create_using return G
def loadapp conf_file global_conf None allow_modify_pipeline True global_conf global_conf or {} ctx loadcontext loadwsgi.APP conf_file global_conf global_conf if ctx.object_type.name 'pipeline' app ctx.app_context.create func getattr app 'modify_wsgi_pipeline' None if func and allow_modify_pipeline func PipelineWrapper ctx return ctx.create
def group_types_get_by_name_or_id context group_type_list return IMPL.group_types_get_by_name_or_id context group_type_list
def _get_ttl return __opts__.get 'couchbase.ttl' 24 * 60 * 60
def buildPackage *args **options o options title version desc o['Title'] o['Version'] o['Description'] pm PackageMaker title version desc apply pm.build list args options
def ip_to_cidr ip prefix None net netaddr.IPNetwork ip if prefix is not None net netaddr.IPNetwork str net.ip + '/' + str prefix return str net
def _get_changed_filenames unstaged_files subprocess.check_output ['git' 'diff' '--name-only'] .splitlines staged_files subprocess.check_output ['git' 'diff' '--cached' '--name-only' '--diff-filter ACM'] .splitlines return unstaged_files + staged_files
def get_dist Y W domain return np.bincount Y weights W minlength len domain.class_var.values
def no_backend test_func backend if settings.DATABASES[DEFAULT_DB_ALIAS]['ENGINE'].rsplit '.' [ -1 ] backend return pass_testelse return test_func
def migrate_drafts_metadata_key schema drafts DraftRegistration.find Q 'registration_schema' 'eq' schema total_drafts drafts.count logger.info 'Examining{}draftsforimproperkey'.format total_drafts draft_count 0for draft in drafts draft_count + 1if draft.registration_metadata.get 'recommended-methods' {} .get 'value' {} .get 'undefined' {} draft.registration_metadata['recommended-methods']['value']['procedure'] draft.registration_metadata['recommended-methods']['value'].pop 'undefined' draft.save logger.info '{}/{}Migratedkeyfor{}'.format draft_count total_drafts draft._id else logger.info '{}/{}Keyalreadycorrectfor{}.Nochange.'.format draft_count drafts.count draft._id
def expand_key k dims def inds i ind rv []if ind - 0.9 > 0 rv.append ind - 0.9 rv.append ind if ind + 0.9 < dims[i] - 1 rv.append ind + 0.9 return rvshape []for i ind in enumerate k[1 ] num 1if ind > 0 num + 1if ind < dims[i] - 1 num + 1shape.append num seq list product [k[0]] *[inds i ind for i ind in enumerate k[1 ] ] return reshapelist shape seq
def _sanity_check_generate_control is_server client_control_file kernels upload_kernel_config if is_server and client_control_file raise model_logic.ValidationError {'tests' 'Youcannotrunservertestsatthesametimeasdirectlysupplyingaclient-sidecontrolfile.'} if kernels kernel_error model_logic.ValidationError {'kernel' 'Thekernelparametermustbeasequenceofdictionariescontainingatleastthe"version"key got %r ' % kernels } try iter kernels except TypeError raise kernel_errorfor kernel_info in kernels if not isinstance kernel_info dict or 'version' not in kernel_info raise kernel_errorif upload_kernel_config and not is_server raise model_logic.ValidationError {'upload_kernel_config' 'Cannotuseupload_kernel_configwithclientsidetests'}
def get_vmlinux vmlinux '/boot/vmlinux-%s' % os.uname [2] if os.path.isfile vmlinux return vmlinuxvmlinux '/lib/modules/%s/build/vmlinux' % os.uname [2] if os.path.isfile vmlinux return vmlinuxreturn None
def delete_cache_cluster name wait 600 region None key None keyid None profile None **args return _delete_resource name name_param 'CacheClusterId' desc 'cachecluster' res_type 'cache_cluster' wait wait status_param 'CacheClusterStatus' region region key key keyid keyid profile profile **args
def filter_pathname val return os.path.splitext os.path.basename val or u'' [0]
def one_hot_action action size 19 categorical np.zeros size size categorical[action] 1return categorical
def get_jid jid ret {}for returner_ in __opts__[CONFIG_KEY] ret.update _mminion .returners['{0}.get_jid'.format returner_ ] jid return ret
def getBeveledRectangle bevel bottomLeft bottomRight complex - bottomLeft.real bottomLeft.imag rectangle [bottomLeft bottomRight - bottomLeft - bottomRight ]if bevel < 0.0 return rectanglebeveledRectangle []for pointIndex point in enumerate rectangle begin rectangle[ pointIndex + len rectangle - 1 % len rectangle ]end rectangle[ pointIndex + 1 % len rectangle ]addAlongWay point bevel begin beveledRectangle addAlongWay point bevel end beveledRectangle return beveledRectangle
def normal_ordered_form expr independent False recursive_limit 10 _recursive_depth 0 if _recursive_depth > recursive_limit warnings.warn 'Toomanyrecursions aborting' return exprif isinstance expr Add return _normal_ordered_form_terms expr recursive_limit recursive_limit _recursive_depth _recursive_depth independent independent elif isinstance expr Mul return _normal_ordered_form_factor expr recursive_limit recursive_limit _recursive_depth _recursive_depth independent independent else return expr
def _FormatAsEnvironmentBlock envvar_dict block ''nul '\x00'for key value in envvar_dict.iteritems block + key + ' ' + value + nul block + nulreturn block
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp.xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def get_class lookup_view if isinstance lookup_view str mod_name func_name get_mod_func lookup_view if func_name ! '' lookup_view getattr __import__ mod_name {} {} ['*'] func_name if not callable lookup_view raise AttributeError "'%s.%s'isnotacallable." % mod_name func_name return lookup_view
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def handle_errors errors format_error_func filename errors list sorted errors key str if not errors returnerror_msg u'\n'.join format_error_func error for error in errors raise ConfigurationError u'TheComposefile{file_msg}isinvalidbecause \n{error_msg}'.format file_msg u"'{}'".format filename if filename else u'' error_msg error_msg
@bdd.when bdd.parsers.parse 'Ispawnanewwindow' def invoke_with quteproc quteproc.log_summary 'Createanewwindow' quteproc.send_ipc [] target_arg 'window' quteproc.wait_for category 'init' module 'app' function '_open_startpage' message 'Openingstartpage'
def prefer_xmodules identifier entry_points from_xmodule [entry_point for entry_point in entry_points if entry_point.dist.key 'xmodule' ]if from_xmodule return default_select identifier from_xmodule else return default_select identifier entry_points
def identify_landmark gcs_uri max_results 4 batch_request [{'image' {'source' {'gcs_image_uri' gcs_uri}} 'features' [{'type' 'LANDMARK_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service.images .annotate body {'requests' batch_request} response request.execute return response['responses'][0].get 'landmarkAnnotations' None
def copy_cache cache if cache is None return Noneelif type cache is dict return {}return LRUCache cache.capacity
def arcsin x return Arcsin x
def constr_unpack constraints vector values []offset 0for constr in constraints rows cols constr.sizeval np.zeros rows cols for col in range cols val[ col] vector[offset offset + rows ]offset + rowsvalues.append val return values
def cdao_to_obo s return 'obo %s' % cdao_elements[s[len 'cdao ' ]]
def get_popularity obj region None return _property_value_by_region obj region region property 'popularity'
def concat_multi_values models attribute return u';'.join getattr m attribute for m in models if getattr m attribute None is not None
def get_intersection cx1 cy1 cos_t1 sin_t1 cx2 cy2 cos_t2 sin_t2 line1_rhs sin_t1 * cx1 - cos_t1 * cy1 line2_rhs sin_t2 * cx2 - cos_t2 * cy2 a b sin_t1 - cos_t1 c d sin_t2 - cos_t2 ad_bc a * d - b * c if ad_bc 0.0 raise ValueError 'Givenlinesdonotintersect' a_ b_ d - b c_ d_ - c a a_ b_ c_ d_ [ k / ad_bc for k in [a_ b_ c_ d_]]x a_ * line1_rhs + b_ * line2_rhs y c_ * line1_rhs + d_ * line2_rhs return x y
def _launch_reaper id pid from subprocess import Popen PIPEme __file__if me.endswith '.pyc' me me[ -1 ]myloc os.path.dirname me if not myloc myloc os.getcwd reaper_cmd os.path.join myloc 'run_on_me_or_pid_quit' Popen [reaper_cmd str pid me '--free' str id ] stdout open '/dev/null' 'w'
def encode_extension_av data quote default_extension_quote if not data return ''return quote data
@then u'anundefined-stepsnippetshouldexistfor"{step}"' def step_undefined_step_snippet_should_exist_for context step undefined_step_snippet make_undefined_step_snippet step context.execute_steps u'Thenthecommandoutputshouldcontain \n"""\n{undefined_step_snippet}\n"""\n'.format undefined_step_snippet text_indent undefined_step_snippet 4
def get_module_version module_name mod __import__ module_name fromlist [module_name.rpartition '.' [ -1 ]] return getattr mod '__version__' getattr mod 'VERSION' None
def test_feature_finder_finds_all_feature_files_within_a_dir ff FeatureLoader cjoin files ff.find_feature_files assert_equals sorted files sorted [cjoin '1st_feature_dir' 'one_more.feature' cjoin '1st_feature_dir' 'some.feature' cjoin '1st_feature_dir' 'more_features_here' 'another.feature' cjoin '2nd_feature_dir' 'before_and_after_all.feature' cjoin '2nd_feature_dir' 'with_defined_steps.feature' cjoin '3rd_feature_dir' 'my_steps_are_anywhere.feature' ]
def security_hash request form *args data []for bf in form if form.empty_permitted and not form.has_changed value bf.data or '' else value bf.field.clean bf.data or '' if isinstance value basestring value value.strip data.append bf.name value data.extend args data.append settings.SECRET_KEY pickled pickle.dumps data pickle.HIGHEST_PROTOCOL return md5_constructor pickled .hexdigest
def is_valid_endpoint_url endpoint_url parts urlsplit endpoint_url hostname parts.hostnameif hostname is None return Falseif len hostname > 255 return Falseif hostname[ -1 ] '.' hostname hostname[ -1 ]allowed re.compile '^ ?!- [A-Z\\d-]{1 63} ?<!- \\. * ?!- [A-Z\\d-]{1 63} ?<!- $' re.IGNORECASE return allowed.match hostname
def _generate_hypercube samples dimensions rng if dimensions > 30 return np.hstack [_generate_hypercube samples dimensions - 30 rng _generate_hypercube samples 30 rng ] out astype sample_without_replacement 2 ** dimensions samples random_state rng dtype '>u4' copy False out np.unpackbits out.view '>u1' .reshape -1 32 [ - dimensions ]return out
def get_flavor_by_flavor_id flavorid ctxt None read_deleted 'yes' if ctxt is None ctxt context.get_admin_context read_deleted read_deleted return objects.Flavor.get_by_flavor_id ctxt flavorid read_deleted
def require_change_password self if 'desktop.auth.backend.AllowFirstUserDjangoBackend' in desktop.conf.AUTH.BACKEND.get and self.first_login and desktop.conf.AUTH.CHANGE_DEFAULT_PASSWORD.get return True
def enhance_info_description info line_length 50 paragraphs info['description'].split '\n\n' lines [paragraph.replace '\n' '' for paragraph in paragraphs]text '\n'.join lines info['files'] [ info['file'] + '.' + info['ext'] ]regex '[tT]he ? file|image [\\w\\/]+\\.\\w+ 'for name in re.findall regex text if name not in info['files'] info['files'].append name folder '_'.join info['source'].split sep [ -1 ] + '_' text re.sub ' [tT]he ? file|image [\\w\\/]+\\.\\w+ ' '\\1 ref `\\2<$folder$\\2>`' text text text.replace '$folder$' folder lines text.split '\n' paragraphs [textwrap.wrap line line_length for line in lines]info['enhanced_description'] paragraphs
def after point if not point return Trueelse return not before point
def get_expr_vars operator if operator.type lo.VARIABLE return [ operator.data operator.size ]else vars_ []for arg in operator.args vars_ + get_expr_vars arg return vars_
def partition_suite suite classes bins for test in suite if isinstance test unittest.TestSuite partition_suite test classes bins else for i in range len classes if isinstance test classes[i] bins[i].addTest test breakelse bins[ -1 ].addTest test
def guess_sys_stdout_encoding return getattr sys.stdout 'encoding' None or getattr __stdout__ 'encoding' None or locale.getpreferredencoding or sys.getdefaultencoding or 'ascii'
def getMinimum firstComplex secondComplex return complex min firstComplex.real secondComplex.real min firstComplex.imag secondComplex.imag
def modNull s titlesRefs namesRefs charactersRefs return s
def certificate_create context values return IMPL.certificate_create context values
def is_google_instance global __IS_ON_GOOGLEif __IS_ON_GOOGLE is None __IS_ON_GOOGLE fetch GOOGLE_METADATA_URL google True .ok return __IS_ON_GOOGLE
def addYIntersectionPathToList pathIndex pointIndex y yIntersection yIntersectionPaths if yIntersection None returnyIntersectionPath YIntersectionPath pathIndex pointIndex yIntersection yIntersectionPath.yMinusCenter yIntersection - y yIntersectionPaths.append yIntersectionPath
def type return s3_rest_controller 'impact' 'type'
def write_incron_file user path return __salt__['cmd.retcode'] _get_incron_cmdstr path runas user python_shell False 0
def log_request_headers debug False h [ '%s %s' % k v for k v in cherrypy.serving.request.header_list]cherrypy.log '\nRequestHeaders \n' + '\n'.join h 'HTTP'
def sab_sanitize_foldername name CH_ILLEGAL '\\/<>?*|"'CH_LEGAL '++{}!@#`'FL_ILLEGAL CH_ILLEGAL + ' \x92"' FL_LEGAL CH_LEGAL + "-''" uFL_ILLEGAL FL_ILLEGAL.decode 'latin-1' uFL_LEGAL FL_LEGAL.decode 'latin-1' if not name return nameif isinstance name unicode illegal uFL_ILLEGALlegal uFL_LEGALelse illegal FL_ILLEGALlegal FL_LEGALlst []for ch in name.strip if ch in illegal ch legal[illegal.find ch ]lst.append ch else lst.append ch name ''.join lst name name.strip '.' if not name name 'unknown'return name
def arbitrary_transformation deployment uuid uuid4 return deployment.transform ['nodes' uuid] Node uuid uuid
def is_initialized cr cr.execute "SELECTrelnameFROMpg_classWHERErelkind 'r'ANDrelname 'ir_module_module'" return len cr.fetchall > 0
def error xml try ET.XML xml except ET.ParseError return sys.exc_value
def getStartsWithCurlyEqualRoundSquare word return word.startswith '{' or word.startswith ' ' or word.startswith ' ' or word.startswith '['
def create_decimal128_context opts _CTX_OPTIONS.copy opts['traps'] []return decimal.Context **opts
def service_delete service_id None name None profile None **connection_args kstone auth profile **connection_args if name service_id service_get name name profile profile **connection_args [name]['id']kstone.services.delete service_id return 'KeystoneserviceID"{0}"deleted'.format service_id
def structure_tensor image sigma 1 mode 'constant' cval 0 image _prepare_grayscale_input_2D image imx imy _compute_derivatives image mode mode cval cval Axx ndi.gaussian_filter imx * imx sigma mode mode cval cval Axy ndi.gaussian_filter imx * imy sigma mode mode cval cval Ayy ndi.gaussian_filter imy * imy sigma mode mode cval cval return Axx Axy Ayy
def StartMap operation_key job_name handler_spec reader_spec writer_spec mapper_params mapreduce_params None start_transaction True queue_name None shard_count MAPREDUCE_DEFAULT_SHARDS if not mapreduce_params mapreduce_params {}mapreduce_params[DatastoreAdminOperation.PARAM_DATASTORE_ADMIN_OPERATION] str operation_key mapreduce_params['done_callback'] '%s/%s' % config.BASE_PATH MapreduceDoneHandler.SUFFIX if queue_name is not None mapreduce_params['done_callback_queue'] queue_namemapreduce_params['force_writes'] 'True'def tx operation DatastoreAdminOperation.get operation_key job_id control.start_map job_name handler_spec reader_spec mapper_params output_writer_spec writer_spec mapreduce_parameters mapreduce_params base_path config.MAPREDUCE_PATH shard_count shard_count transactional True queue_name queue_name transactional_parent operation operation.status DatastoreAdminOperation.STATUS_ACTIVEoperation.active_jobs + 1operation.active_job_ids list set operation.active_job_ids + [job_id] operation.put config _CreateDatastoreConfig return job_idif start_transaction return db.run_in_transaction tx else return tx
def _getinfos_cert spec infos {}fullinfos {}try cert spec.get 'fullvalue' spec['value'] .decode 'base64' except Exception return {}for hashtype in ['md5' 'sha1'] infos[ '%shash' % hashtype ] hashlib.new hashtype cert .hexdigest proc subprocess.Popen ['openssl' 'x509' '-noout' '-text' '-inform' 'DER'] stdin subprocess.PIPE stdout subprocess.PIPE proc.stdin.write cert proc.stdin.close try newinfos _CERTINFOS.search proc.stdout.read .groupdict newfullinfos {}for field in newinfos if len newinfos[field] > utils.MAXVALLEN newfullinfos[field] newinfos[field]newinfos[field] newinfos[field][ utils.MAXVALLEN]infos.update newinfos fullinfos.update newfullinfos except Exception passres {}if infos res['infos'] infosif fullinfos res['fullinfos'] fullinfosreturn res
def test_regression_3938 vega SkyCoord 279.23473479 * u.deg 38.78368896 * u.deg capella SkyCoord 79.17232794 * u.deg 45.99799147 * u.deg sirius SkyCoord 101.28715533 * u.deg -16.71611586 * u.deg targets [vega capella sirius]combined_coords SkyCoord targets time Time u'2012-01-0100 00 00' location EarthLocation u'10d' u'45d' 0 aa AltAz location location obstime time combined_coords.transform_to aa
def get_review_request_fieldset fieldset_id return fieldset_registry.get u'fieldset_id' fieldset_id
def cprint stream *args **kwds if isinstance stream basestring stream kwds.get 'stream' 'stdout' err stream 'stderr' stream getattr sys stream else err kwds.get 'stderr' False if hasattr stream 'isatty' and stream.isatty if _WIN for arg in args if isinstance arg basestring stream.write arg else kwds WIN[arg]winset stderr err **kwds else for arg in args if isinstance arg basestring stream.write arg else stream.write ANSI[arg] else for arg in args if isinstance arg basestring stream.write arg
def say_hello name None if name is None name u'Stranger'return u'Hithere %s!' % name
@lru_cache def is_mock_available try import unittest.mockreturn Trueexcept ImportError passtry import mockif not hasattr mock.patch 'dict' raise ImportError if 'new_callable' not in inspect.getargspec mock.patch .args raise ImportError return Trueexcept ImportError return False
def etree_strip_namespaces element retval etree.Element element.tag.rpartition '}' [ -1 ] retval.text element.textfor a in element.attrib retval.attrib[a.rpartition '}' [ -1 ]] element.attrib[a]for e in element retval.append etree_strip_namespaces e return retval
def test_main3 import tempfilewfn 'tmp_weights.tfl'if os.path.exists wfn os.unlink wfn arglist '-e2-otmp_weights.tfl-v-v-v-v-membedding_attentiontrain5000'arglist arglist.split '' tf.reset_default_graph ts2s CommandLine arglist arglist assert os.path.exists wfn arglist '-itmp_weights.tfl-v-v-v-v-membedding_attentionpredict1234567890'arglist arglist.split '' tf.reset_default_graph ts2s CommandLine arglist arglist assert len ts2s.prediction_results[0][0] 10
def test_find_number_0 r find_number 'sss' assert r is None
def load_notebook resources None verbose False hide_banner False load_timeout 5000 html js _load_notebook_html resources verbose hide_banner load_timeout publish_display_data {'text/html' html} publish_display_data {'application/javascript' js}
def _set_labels node apiserver_url labels url '{0}/api/v1/nodes/{1}'.format apiserver_url node data [{'op' 'replace' 'path' '/metadata/labels' 'value' labels}]ret _kpatch url data if ret.get 'status' 404 return "Node{0}doesn'texist".format node return ret
def build_desired_iface_config module module.custom_desired_config {'addr_family' None 'auto' True 'config' {} 'name' module.params.get 'name' }for _attr in ['vlan_aware' 'pvid' 'ports' 'stp'] build_bridge_attr module _attr build_addr_method module build_address module build_vids module build_alias_name module build_vrr module for _attr in ['mtu' 'mstpctl_treeprio'] build_generic_attr module _attr
def adagrad loss_or_grads params learning_rate 1.0 epsilon 1e-06 grads get_or_compute_grads loss_or_grads params updates OrderedDict for param grad in zip params grads value param.get_value borrow True accu theano.shared np.zeros value.shape dtype value.dtype broadcastable param.broadcastable accu_new accu + grad ** 2 updates[accu] accu_newupdates[param] param - learning_rate * grad / T.sqrt accu_new + epsilon return updates
def Value typecode_or_type *args **kwds from multiprocessing.sharedctypes import Valuereturn Value typecode_or_type *args **kwds
def processXMLElementByFunction manipulationFunction xmlElement geometryOutput getGeometryOutputByFunction manipulationFunction xmlElement processXMLElementByGeometry geometryOutput xmlElement
def set_scroll_commands widget hbar vbar if vbar widget['yscrollcommand'] vbar 'set' vbar['command'] widget 'yview' if hbar widget['xscrollcommand'] hbar 'set' hbar['command'] widget 'xview' widget.vbar vbarwidget.hbar hbar
def sobel image mask None assert_nD image 2 out np.sqrt sobel_h image mask ** 2 + sobel_v image mask ** 2 out / np.sqrt 2 return out
def apply_template_on_contents contents template context defaults saltenv if template in salt.utils.templates.TEMPLATE_REGISTRY context_dict defaults if defaults else {} if context context_dict.update context contents salt.utils.templates.TEMPLATE_REGISTRY[template] contents from_str True to_str True context context_dict saltenv saltenv grains __opts__['grains'] pillar __pillar__ salt __salt__ opts __opts__ ['data'].encode 'utf-8' else ret {}ret['result'] Falseret['comment'] 'Specifiedtemplateformat{0}isnotsupported'.format template return retreturn contents
def killprocs pattern sh 'pkill-9-f%s' % pattern while True try pids co ['pgrep' '-f' pattern] except CalledProcessError pids ''if pids sh 'pkill-9-f%s' % pattern time.sleep 0.5 else break
def _random_name size 6 return 'cloud-test-' + ''.join random.choice string.ascii_lowercase + string.digits for x in range size
def simultaneous_ci q_crit var groupnobs pairindices None ng len groupnobs if pairindices is None pairindices np.triu_indices ng 1 gvar var / groupnobs d12 np.sqrt gvar[pairindices[0]] + gvar[pairindices[1]] d np.zeros ng ng d[pairindices] d12d d + d.conj .T sum1 np.sum d12 sum2 np.sum d axis 0 if ng > 2 w ng - 1.0 * sum2 - sum1 / ng - 1.0 * ng - 2.0 else w sum1 * np.ones 2 1 / 2.0 return q_crit / np.sqrt 2 * w
def nthhost value query '' try vtype ipaddr value 'type' if vtype 'address' v ipaddr value 'cidr' elif vtype 'network' v ipaddr value 'subnet' value netaddr.IPNetwork v except return Falseif not query return Falsetry nth int query if value.size > nth return value[nth]except ValueError return Falsereturn False
def _construct_machine_label_header_sql machine_labels machine_labels sorted machine_labels if_clauses []for label in machine_labels if_clauses.append 'IF FIND_IN_SET "%s" tko_test_attributes_host_labels.value "%s" NULL ' % label label return 'CONCAT_WS " " %s ' % ' '.join if_clauses
def MakeSandboxOnProdResponse return '{"status" 21007}'
def Matrix data typecode None copy 1 savespace 0 if isinstance data type '' raise TypeError 'numerixMatrixdoesnotsupportNumericmatrixstringnotation.Usenestedlists.' a fromlist data type typecode if a.rank 0 a.shape 1 1 elif a.rank 1 a.shape 1 + a.shape a.__class__ _Matrixreturn a
def _attempt_nocopy_reshape context builder aryty ary newnd newshape newstrides ll_intp context.get_value_type types.intp ll_intp_star ll_intp.as_pointer ll_intc context.get_value_type types.intc fnty lc.Type.function ll_intc [ll_intp ll_intp_star ll_intp_star ll_intp ll_intp_star ll_intp_star ll_intp ll_intc] fn builder.module.get_or_insert_function fnty name 'numba_attempt_nocopy_reshape' nd ll_intp aryty.ndim shape cgutils.gep_inbounds builder ary._get_ptr_by_name 'shape' 0 0 strides cgutils.gep_inbounds builder ary._get_ptr_by_name 'strides' 0 0 newnd ll_intp newnd newshape cgutils.gep_inbounds builder newshape 0 0 newstrides cgutils.gep_inbounds builder newstrides 0 0 is_f_order ll_intc 0 res builder.call fn [nd shape strides newnd newshape newstrides ary.itemsize is_f_order] return res
def remove_protocol_from_tool_shed_url tool_shed_url return util.remove_protocol_from_url tool_shed_url
def get_redirect_route regex_route handler defaults None if defaults is None defaults {}name regex_route.replace '/' '_' return RedirectRoute regex_route handler name strict_slash True defaults defaults
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _getModelCheckpointDir experimentDir checkpointLabel checkpointDir os.path.join getCheckpointParentDir experimentDir checkpointLabel + g_defaultCheckpointExtension checkpointDir os.path.abspath checkpointDir return checkpointDir
def decorator_from_middleware middleware_class return make_middleware_decorator middleware_class
def build_heap seq n len seq - 1 for i in range n // 2 -1 -1 max_heapify seq i n
def getheader filename *args **kwargs mode closed _get_file_mode filename hdulist extidx _getext filename mode *args **kwargs try hdu hdulist[extidx]header hdu.headerfinally hdulist._close closed closed return header
@sopel.module.require_privmsg@sopel.module.require_admin@sopel.module.commands u'msg' @sopel.module.priority u'low' @sopel.module.example u'.msg#YourPantsDoesanyoneelsesmellneurotoxin?' def msg bot trigger if trigger.group 2 is None return channel _sep message trigger.group 2 .partition u'' message message.strip if not channel or not message returnbot.msg channel message
def s3_key_to_uri s3_key return 's3 //%s/%s' % s3_key.bucket.name s3_key.name
def _cumulative_sum xs cumsum 0for x in xs cumsum + x yield cumsum
def subsector return s3_rest_controller
def regexp_tokenize text pattern gaps False discard_empty True flags re.UNICODE | re.MULTILINE | re.DOTALL tokenizer RegexpTokenizer pattern gaps discard_empty flags return tokenizer.tokenize text
def month_weekdays year_int month_int cal calendar.Calendar return [d for d in cal.itermonthdates year_int month_int if d.weekday < 5 and d.year year_int ]
def get_declarative_base name 'base' base_class object bases not isinstance base_class tuple and base_class or base_class class_dict {'__init__' _kwarg_init_constructor '_validate_required' _validate_required '__pre_publish__' _pre_publish_validator '_declarative_artifact_type' True 'update' _update}return ArtifactTypeMetaclass name bases class_dict
def get_course_milestones course_id if not settings.FEATURES.get 'MILESTONES_APP' return []return milestones_api.get_course_milestones course_id
def idz_estrank eps A A np.asfortranarray A m n A.shape n2 w idz_frmi m ra np.empty n * n2 + n + 1 * n2 + 1 dtype 'complex128' order 'F' k ra _id.idz_estrank eps A w ra return k
def asint value if value is None return valuereturn int value
def indent_text text indent regex re.compile ' \\\\* """|\'\'\' ' res []in_quote Nonefor line in text.splitlines if in_quote res.append line else res.append indent + line while line match regex.search line if match if len match.group 1 % 2 0 if not in_quote in_quote match.group 2 [0]elif in_quote match.group 2 [0] in_quote Noneline line[match.end ]else breakreturn '\n'.join res
@bp.route '/' def home nodes Node.query.order_by Node.id.desc .all home_nodes filter lambda o o.on_home nodes home_node_ids map lambda o o.id home_nodes if len home_node_ids topics Topic.query.filter Topic.node_id.in_ home_node_ids .order_by Topic.id.desc .limit 16 topics fill_topics topics else topics Noneblog Node.query.filter_by urlname 'blog' .first if blog blogs Topic.query.filter_by node_id blog.id .order_by Topic.id.desc .limit 2 else blogs Nonereturn render_template 'index.html' topics topics nodes nodes[ 16] blog blog blogs blogs
@pytest.mark.skip reason 'https //github.com/mozilla/addons-server/issues/2462' def test_login base_url selenium user page Home selenium base_url .open assert not page.logged_in page.login user['email'] user['password'] assert page.logged_in
def to_yaml a *args **kw transformed yaml.dump a Dumper AnsibleDumper allow_unicode True **kw return to_text transformed
def libvlc_video_get_scale p_mi f _Cfunctions.get 'libvlc_video_get_scale' None or _Cfunction 'libvlc_video_get_scale' 1 None ctypes.c_float MediaPlayer return f p_mi
def unmimify infile outfile decode_base64 0 if type infile type '' ifile open infile if type outfile type '' and infile outfile import os d f os.path.split infile os.rename infile os.path.join d ' ' + f else ifile infileif type outfile type '' ofile open outfile 'w' else ofile outfilenifile File ifile None unmimify_part nifile ofile decode_base64 ofile.flush
def get_uid_gid username groupname None try uid default_grp pwd.getpwnam username [2 4]except KeyError raise KeyError "Couldn'tgetuseridforuser%s" % username if groupname is None gid default_grpelse try gid grp.getgrnam groupname [2]except KeyError raise KeyError "Couldn'tgetgroupidforgroup%s" % groupname return uid gid
def vrrp_shutdown app instance_name shutdown_request vrrp_event.EventVRRPShutdownRequest instance_name app.send_event vrrp_event.VRRP_MANAGER_NAME shutdown_request
def cache_return func _cache []def wrap if not _cache _cache.append func return _cache[0]return wrap
def create_global_secondary_index table_name global_index region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile table Table table_name connection conn return table.create_global_secondary_index global_index
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def fletcher_checksum data offset c0 0c1 0pos 0length len data data bytearray data data[offset offset + 2 ] [0] * 2 while pos < length tlen min length - pos _MODX for d in data[pos pos + tlen ] c0 + dc1 + c0c0 % 255c1 % 255pos + tlenx length - offset - 1 * c0 - c1 % 255 if x < 0 x + 255y 510 - c0 - x if y > 255 y - 255data[offset] xdata[ offset + 1 ] yreturn x << 8 | y & 255
def asksaveasfilename **options return SaveAs **options .show
def DisplayAdUnitTree root_ad_unit ad_unit_tree depth 0 print '%s%s %s ' % GenerateTab depth root_ad_unit['name'] root_ad_unit['id'] if root_ad_unit['id'] in ad_unit_tree for child in ad_unit_tree[root_ad_unit['id']] DisplayAdUnitTree child ad_unit_tree depth + 1
def get_default_encoding_file return default_encoding_file
def enable_enhanced_monitoring stream_name metrics region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r _execute_with_retries conn 'enable_enhanced_monitoring' StreamName stream_name ShardLevelMetrics metrics if 'error' not in r r['result'] Truereturn r
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def update_security_group security_group name None description None profile None conn _auth profile return conn.update_security_group security_group name description
def plot_day_summary2_ochl ax opens closes highs lows ticksize 4 colorup u'k' colordown u'r' return plot_day_summary2_ohlc ax opens highs lows closes ticksize colorup colordown
def get_duplicates fields cnt {}for field in fields try cnt[field] + 1except KeyError cnt[field] 1return [key for key in cnt.keys if cnt[key] > 1 ]
def get_dirs dirs {u'XDG_CACHE_DIR' os.environ.get u'XDG_CACHE_HOME' or os.path.expanduser '~/.cache' u'XDG_CONFIG_DIR' os.environ.get u'XDG_CONFIG_HOME' or os.path.expanduser '~/.config' u'XDG_DATA_DIR' os.environ.get u'XDG_DATA_HOME' or os.path.expanduser '~/.local/share' }dirs.update _get_user_dirs dirs[u'XDG_CONFIG_DIR'] return dirs
def _get_possible_outcomes m bits size max m.shape nqubits int math.log size 2 + 0.1 output_matrices []for i in range 1 << len bits output_matrices.append zeros 2 ** nqubits 1 bit_masks []for bit in bits bit_masks.append 1 << bit for i in range 2 ** nqubits trueness 0for j in range len bit_masks if i & bit_masks[j] trueness + j + 1 output_matrices[trueness][i] m[i]return output_matrices
def test_not_found_exception exception_app request response sanic_endpoint_test exception_app uri '/404' assert response.status 404
def release_hosts host_filter_data username None hosts models.Host.query_objects host_filter_data reservations.release hosts_to_release [h.hostname for h in hosts] username username
def notify_about_host_update context event_suffix host_payload host_identifier host_payload.get 'host_name' if not host_identifier LOG.warning _LW 'NohostnamespecifiedforthenotificationofHostAPI.%sanditwillbeignored' event_suffix returnnotifier rpc.get_notifier service 'api' host host_identifier notifier.info context 'HostAPI.%s' % event_suffix host_payload
def _clear_context for key in list __context__ try if key.startswith 'systemd._systemctl_status.' or key in 'systemd.systemd_services' __context__.pop key except AttributeError continue
def setup_client webtest.WebCase.PORT cherrypy.server.socket_portwebtest.WebCase.HOST cherrypy.server.socket_hostif cherrypy.server.ssl_certificate CPWebCase.scheme 'https'
def _compile_multi_match_regex strings return re.compile '|'.join re.escape s for s in strings
def unquote_header_value value is_filename False if value and value[0] value[ -1 ] '"' value value[1 -1 ]if not is_filename or value[ 2] ! '\\\\' return value.replace '\\\\' '\\' .replace '\\"' '"' return value
def _execute_pillar pillar_name run_type groups __salt__['pillar.get'] pillar_name data {}for group in groups data[group] {}commands groups[group]for command in commands if isinstance command dict plugin next six.iterkeys command args command[plugin]else plugin commandargs ''command_key _format_dict_key args plugin data[group][command_key] run_type plugin args return data
def stop_version module None version None rpc stop_version_async module version rpc.get_result
def constant_time_compare actual expected actual_len len actual expected_len len expected result actual_len ^ expected_len if expected_len > 0 for i in xrange actual_len result | ord actual[i] ^ ord expected[ i % expected_len ] return result 0
def make_step net step_size 1.5 end 'inception_4c/output' jitter 32 clip True src net.blobs['data']dst net.blobs[end] ox oy np.random.randint - jitter jitter + 1 2 src.data[0] np.roll np.roll src.data[0] ox -1 oy -2 net.forward end end dst.diff[ ] dst.datanet.backward start end g src.diff[0]src.data[ ] + step_size / np.abs g .mean * g src.data[0] np.roll np.roll src.data[0] - ox -1 - oy -2 if clip bias net.transformer.mean['data']src.data[ ] np.clip src.data - bias 255 - bias
def _handle_topomap_bads ch_name params for type in 'mag' 'grad' 'eeg' 'seeg' 'hbo' 'hbr' if type in params['types'] types np.where np.array params['types'] type [0]breakcolor_ind np.where np.array params['info']['ch_names'] [types] ch_name [0]if len color_ind > 0 sensors params['fig_selection'].axes[1].collections[0]this_color sensors._edgecolors[color_ind][0]if all this_color [1.0 0.0 0.0 1.0] sensors._edgecolors[color_ind] [0.0 0.0 0.0 1.0]else sensors._edgecolors[color_ind] [1.0 0.0 0.0 1.0]params['fig_selection'].canvas.draw
def IsInTransaction return isinstance _GetConnection datastore_rpc.TransactionalConnection
def is_router_interface_port port return _is_owner_router_interface port['device_owner']
def shorten_key_ids key_id_list short []for key in key_id_list short.append key[ -8 ] return short
def make_segments x y points np.array [x y] .T.reshape -1 1 2 segments np.concatenate [points[ -1 ] points[1 ]] axis 1 return segments
def site_activity return s3_rest_controller
def parse_querystring environ source environ.get 'QUERY_STRING' '' if not source return []if 'paste.parsed_querystring' in environ parsed check_source environ['paste.parsed_querystring']if check_source source return parsedparsed cgi.parse_qsl source keep_blank_values True strict_parsing False environ['paste.parsed_querystring'] parsed source return parsed
def get_batch_notification_listener transport targets endpoints allow_requeue False batch_size 1 batch_timeout None return oslo_messaging.get_batch_notification_listener transport targets endpoints executor 'threading' allow_requeue allow_requeue batch_size batch_size batch_timeout batch_timeout
def get_diff_renderer *args **kwargs return _diff_renderer_class *args **kwargs
def vxlan_in_use segmentation_id namespace None ip_wrapper IPWrapper namespace namespace interfaces ip_wrapper.netns.execute ['ip' '-d' 'link' 'list'] check_exit_code True return 'vxlanid%s' % segmentation_id in interfaces
def _check_firstset info reverse fs if not fs or None in fs return Nonemembers set case_flags NOCASEfor i in fs if isinstance i Character and not i.positive return Nonecase_flags | i.case_flagsmembers.add i.with_flags case_flags NOCASE if case_flags FULLCASE | IGNORECASE return Nonefs SetUnion info list members case_flags case_flags & ~ FULLCASE zerowidth True fs fs.optimise info reverse in_set True return fs
def _chop seq how_much return seq[_B how_much ]
def volume_type_destroy context id return IMPL.volume_type_destroy context id
def test_cirs_to_altaz from .. import EarthLocation ra dec dist randomly_sample_sphere 200 cirs CIRS ra ra dec dec obstime u'J2000' crepr SphericalRepresentation lon ra lat dec distance dist cirscart CIRS crepr obstime cirs.obstime representation CartesianRepresentation loc EarthLocation lat 0 * u.deg lon 0 * u.deg height 0 * u.m altazframe AltAz location loc obstime Time u'J2005' cirs2 cirs.transform_to altazframe .transform_to cirs cirs3 cirscart.transform_to altazframe .transform_to cirs assert_allclose cirs.ra cirs2.ra assert_allclose cirs.dec cirs2.dec assert_allclose cirs.ra cirs3.ra assert_allclose cirs.dec cirs3.dec
@when u'weupdatetable' def step_update_table context context.cli.sendline u"updateasetx 'yyy'wherex 'xxx';"
def _load_function pickled_func globals code_info func_info doc pickle.loads pickled_func func function code *code_info globals *func_info func.func_doc docreturn func
def ORIG k n return _XXX k n _ORIG
def slugify_unicode s chars []for char in str smart_text s cat unicodedata.category char [0]if cat in u'LN' or char in u'-_~' chars.append char elif cat u'Z' chars.append u'' return re.sub u'[-\\s]+' u'-' u''.join chars .strip .lower
def makeiter obj return obj if hasattr obj '__iter__' else [obj]
def qqplot_2samples data1 data2 xlabel None ylabel None line None ax None check_data1 isinstance data1 ProbPlot check_data2 isinstance data2 ProbPlot if not check_data1 and not check_data2 data1 ProbPlot data1 data2 ProbPlot data2 fig data1.qqplot xlabel xlabel ylabel ylabel line line other data2 ax ax return fig
def get_formatted_string string_type string fallback case if string is not None if case.formatted string return stringelse string case.convert fallback question u'Doyouwishtouse%sasthe%s?' % string string_type if not get_confirmation question string input u'Pleaseinputa%s ' % string_type while not case.formatted string print u"'%s'isnotavalid%s." % string string_type string input u'Pleaseinputavalid%s ' % string_type return string
def decodeerror arguments errn arguments['errn']err_a1 errnif 'errs' in arguments err_a2 arguments['errs']else err_a2 MacOS.GetErrorString errn if 'erob' in arguments err_a3 arguments['erob']else err_a3 Nonereturn err_a1 err_a2 err_a3
def get_autoconfig_client client_cache _AUTOCONFIG_CLIENT try return client_cache.clientexcept AttributeError configured_client hdfs_config.get_configured_hdfs_client if configured_client 'webhdfs' client_cache.client hdfs_webhdfs_client.WebHdfsClient elif configured_client 'snakebite' client_cache.client hdfs_snakebite_client.SnakebiteHdfsClient elif configured_client 'snakebite_with_hadoopcli_fallback' client_cache.client luigi.contrib.target.CascadingClient [hdfs_snakebite_client.SnakebiteHdfsClient hdfs_hadoopcli_clients.create_hadoopcli_client ] elif configured_client 'hadoopcli' client_cache.client hdfs_hadoopcli_clients.create_hadoopcli_client else raise Exception 'Unknownhdfsclient' + configured_client return client_cache.client
def _GetTypeName x if type x is types.InstanceType return x.__class__.__name__else return type x .__name__
@_api_version 1.21 @_client_version '1.5.0' def remove_network network_id response _client_wrapper 'remove_network' network_id _clear_context return response
def pg word body return html_header % word + body + html_trailer
def get_egl_path if not sys.platform.startswith 'win' return Nonereturn os.path.join distutils.sysconfig.get_python_lib 'PyQt5\\libEGL.dll'
def get_type_class typ try return _type_map[typ]except KeyError return types.Buffer
def ConvertKeys keys def ChangeApp key app_id if key.app app_id return keyreturn datastore.Key.from_path namespace key.namespace _app app_id *key.to_path app_id datastore.Key.from_path 'kind' 'name' .app return [ChangeApp key app_id for key in keys]
def test_adagard_max_scaling try AdaGrad -1.0 allows_null Trueexcept AssertionError allows_null Falseassert not allows_null def one_case dataset_type model_type cost model dataset sgd state prepare_adagrad_test dataset_type model_type sgd.train dataset dataset for param in model.get_params assert not np.any np.isnan param.get_value one_case 'zeros' 'zeros' one_case 'arange' 'zeros' one_case 'zeros' 'random' one_case 'arange' 'random'
def inter_community_non_edges G partition return inter_community_edges nx.complement G partition
@require_context@require_instance_exists_using_uuid@pick_context_manager_reader_allow_asyncdef virtual_interface_get_by_instance context instance_uuid vif_refs _virtual_interface_query context .filter_by instance_uuid instance_uuid .order_by asc 'created_at' asc 'id' .all return vif_refs
def crontab attrs None where None return _osquery_cmd table 'crontab' attrs attrs where where
def nomethod cls context.status '405MethodNotAllowed'header 'Content-Type' 'text/html' header 'Allow' ' '.join [method for method in ['GET' 'HEAD' 'POST' 'PUT' 'DELETE'] if hasattr cls method ] return output 'methodnotallowed'
def test_will_not_fix AreEqual com_obj.mByte '123' System.Byte 123 AreEqual com_obj.mChar '123' System.SByte 123 AreEqual com_obj.mFloat '123' 123.0 AreEqual com_obj.mBstr object 'System.Object' AreEqual type com_obj.mIDispatch object object AreEqual com_obj.mByte None System.Byte 0 AreEqual com_obj.mFloat None 0.0 AreEqual com_obj.mBstr 3.14 '3.14'
def merge_translations source_stream *translation_streams **kwargs source tuple source_stream streams [synchronize source t key lambda m m.merge_key unused kwargs.get 'unused' for t in translation_streams]for messages in zip source *streams yield match_to_source *messages
def task_reserved request add_request requests.__setitem__ add_reserved_request reserved_requests.add add_request request.id request add_reserved_request request
def mon_active **kwargs return ceph_cfg.mon_active **kwargs
def _check_permission request owner_name error_msg allow_root False if request.user.username ! owner_name if allow_root and request.user.is_superuser returnaccess_warn request error_msg raise PopupException _ 'Permissiondenied.Youarenottheowner.'
def _verify_source_estimate_compat a b compat Falseif len a.vertices len b.vertices if all np.array_equal av vv for av vv in zip a.vertices b.vertices compat Trueif not compat raise ValueError 'CannotcombineSourceEstimatesthatdonothavethesamevertices.Considerusingstc.expand .' if a.subject ! b.subject raise ValueError 'sourceestimatesdonothavethesamesubjectnames %rand%r' % a.subject b.subject
def _reloader_stat_loop extra_files None interval 1 from itertools import chainmtimes {}while 1 for filename in chain _iter_module_files extra_files or try mtime os.stat filename .st_mtimeexcept OSError continueold_time mtimes.get filename if old_time is None mtimes[filename] mtimecontinueelif mtime > old_time _log 'info' '*Detectedchangein%r reloading' % filename sys.exit 3 time.sleep interval
def test_user_columns_flag script data virtualenv virtualenv.system_site_packages Truescript.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' script.pip 'install' '-f' data.find_links '--no-index' '--user' 'simple2 2.0' result script.pip 'list' '--user' '--format columns' assert 'Package' in result.stdout assert 'Version' in result.stdout assert 'simple2 2.0 ' not in result.stdout assert 'simple22.0' in result.stdout str result
def due_in_minutes timestamp diff datetime.strptime timestamp '%d/%m/%Y%H %M %S' - dt_util.now .replace tzinfo None return str int diff.total_seconds / 60
def corpus_ribes list_of_references hypotheses alpha 0.25 beta 0.1 corpus_best_ribes 0.0for references hypothesis in zip list_of_references hypotheses corpus_best_ribes + sentence_ribes references hypothesis alpha beta return corpus_best_ribes / len hypotheses
def package_delete context data_dict model context['model']user context['user']id _get_or_bust data_dict 'id' entity model.Package.get id if entity is None raise NotFound_check_access 'package_delete' context data_dict rev model.repo.new_revision rev.author userrev.message _ u'RESTAPI DeletePackage %s' % entity.name for item in plugins.PluginImplementations plugins.IPackageController item.delete entity item.after_delete context data_dict entity.delete dataset_memberships model.Session.query model.Member .filter model.Member.table_id id .filter model.Member.state 'active' .all for membership in dataset_memberships membership.delete model.repo.commit
@pytest.fixture autouse True def change_qapp_name qapp old_name qapp.applicationName qapp.setApplicationName 'qute_test' yield qapp.setApplicationName old_name
def numeric_assortativity_coefficient G attribute nodes None a numeric_mixing_matrix G attribute nodes return numeric_ac a
def info return _nodetool 'info'
def utf8 value if value is None or isinstance value six.binary_type return valueif not isinstance value six.text_type value six.text_type value return value.encode 'utf-8'
def start_app runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user res __salt__['cmd.run_all'] [__context__['rabbitmqctl'] 'start_app'] runas runas python_shell False _check_response res return res['stdout']
def _check_sets result expected msg path type_ if result ! expected if result > expected diff result - expected msg 'extra%sinresult %r' % _s type_ diff diff elif result < expected diff expected - result msg 'resultismissing%s %r' % _s type_ diff diff else in_result result - expected in_expected expected - result msg '%sonlyinresult %s\n%sonlyinexpected %s' % _s type_ in_result in_result _s type_ in_expected in_expected raise AssertionError '%s%ssdonotmatch\n%s' % _fmt_msg msg type_ _fmt_path path
def rax_find_image module rax_module image exit True cs rax_module.cloudserverstry UUID image except ValueError try image cs.images.find human_id image except cs.exceptions.NotFound cs.exceptions.NoUniqueMatch try image cs.images.find name image except cs.exceptions.NotFound cs.exceptions.NoUniqueMatch if exit module.fail_json msg 'Nomatchingimagefound %s ' % image else return Falsereturn rax_module.utils.get_id image
def remove_tenant_user request project None user None domain None client keystoneclient request admin True roles client.roles.roles_for_user user project for role in roles remove_tenant_user_role request user user role role.id project project domain domain
def methods_via_query_allowed handler_method def redirect_if_needed self *args **kwargs real_verb self.request.get '_method' None if not real_verb and 'X-HTTP-Method-Override' in self.request.environ real_verb self.request.environ['X-HTTP-Method-Override']if real_verb logging.debug 'RedirectedfromPOST.Detectedmethodoverride %s' real_verb method real_verb.upper if method 'HEAD' self.head *args **kwargs elif method 'PUT' self.put *args **kwargs elif method 'DELETE' self.delete *args **kwargs elif method 'TRACE' self.trace *args **kwargs elif method 'OPTIONS' self.head *args **kwargs elif method 'POST' self.post *args **kwargs elif method 'GET' self.get *args **kwargs else self.error 405 else handler_method self *args **kwargs return redirect_if_needed
def tenant_absent name profile None **connection_args ret {'name' name 'changes' {} 'result' True 'comment' 'Tenant/project"{0}"isalreadyabsent'.format name }tenant __salt__['keystone.tenant_get'] name name profile profile **connection_args if 'Error' not in tenant if __opts__.get 'test' ret['result'] Noneret['comment'] 'Tenant/project"{0}"willbedeleted'.format name return ret__salt__['keystone.tenant_delete'] name name profile profile **connection_args ret['comment'] 'Tenant/project"{0}"hasbeendeleted'.format name ret['changes']['Tenant/Project'] 'Deleted'return ret
def image_fig data h w x_range y_range plot_size fig figure x_range x_range y_range y_range plot_width plot_size plot_height plot_size toolbar_location None fig.image_rgba [data] x [0] y [0] dw [w] dh [h] fig.axis.visible Nonefig.min_border 0return fig
def mktemp suffix '' prefix template dir None if dir is None dir gettempdir names _get_candidate_names for seq in range TMP_MAX name next names file _os.path.join dir prefix + name + suffix if not _exists file return fileraise FileExistsError _errno.EEXIST 'Nousabletemporaryfilenamefound'
def _base_fact atom if isinstance atom Not return atom.argelse return atom
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
def str_wrap arr width **kwargs kwargs['width'] widthtw textwrap.TextWrapper **kwargs return _na_map lambda s '\n'.join tw.wrap s arr
def find predicate seq for element in seq if predicate element return elementreturn None
def normal_denom fa fd ga gd DE dn ds splitfactor fd DE en es splitfactor gd DE p dn.gcd en h en.gcd en.diff DE.t .quo p.gcd p.diff DE.t a dn * h c a * h if c.div en [1] raise NonElementaryIntegralExceptionca c * ga ca cd ca.cancel gd include True ba a * fa - dn * derivation h DE * fd ba bd ba.cancel fd include True return a ba bd ca cd h
def inerasable msg if color_enabled return _CLEAR_LINE + msg return msg
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def cleanHost host protocol True ssl False username None password None if not ' //' in host and protocol host 'https //' if ssl else 'http //' + host if not protocol host host.split ' //' 1 [ -1 ]if protocol and username and password try auth re.findall '^ ? .+?// .+? .+? @ ? .+ $' host if auth log.error 'Cleanhosterror authalreadydefinedinurl %s pleaseremoveBasicAuthfromurl.' host else host host.replace ' //' ' //%s %s@' % username password 1 except passhost host.rstrip '/' if protocol host + '/'return host
def eGetSS Handle pIOType pChannel pValue x1 if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pv ctypes.c_double pValue ec staticLib.eGetSS Handle pIOType pChannel ctypes.byref pv x1 if ec ! 0 raise LabJackException ec return pv.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def parse_filename_page_ranges args pairs []pdf_filename Nonedid_page_range Falsefor arg in args + [None] if PageRange.valid arg if not pdf_filename raise ValueError 'Thefirstargumentmustbeafilename notapagerange.' pairs.append pdf_filename PageRange arg did_page_range Trueelse if pdf_filename and not did_page_range pairs.append pdf_filename PAGE_RANGE_ALL pdf_filename argdid_page_range Falsereturn pairs
def is_invalid_token platform version return False
def get_version_from_pkg_info package_name try pkg_info_file open 'PKG-INFO' 'r' except IOError OSError return Nonetry pkg_info email.message_from_file pkg_info_file except email.MessageError return Noneif pkg_info.get 'Name' None ! package_name return Nonereturn pkg_info.get 'Version' None
def load_ctypes_library name try return cdll.LoadLibrary name except OSError name find_library name if name is None raisereturn cdll.LoadLibrary name
def shear x intensity 0.1 is_random False row_index 0 col_index 1 channel_index 2 fill_mode 'nearest' cval 0.0 if is_random shear np.random.uniform - intensity intensity else shear intensityshear_matrix np.array [[1 - np.sin shear 0] [0 np.cos shear 0] [0 0 1]] h w x.shape[row_index] x.shape[col_index] transform_matrix transform_matrix_offset_center shear_matrix h w x apply_transform x transform_matrix channel_index fill_mode cval return x
def save_db_model new_model model_name event_id None save_to_db new_model 'Model%ssaved' % model_name return new_model
def get_hosts service_instance datacenter_name None host_names None cluster_name None get_all_hosts False properties ['name']if not host_names host_names []if cluster_name properties.append 'parent' if datacenter_name start_point get_datacenter service_instance datacenter_name if cluster_name cluster get_cluster start_point cluster_name else start_point get_root_folder service_instance hosts get_mors_with_properties service_instance vim.HostSystem container_ref start_point property_list properties filtered_hosts []for h in hosts name_condition get_all_hosts or h['name'] in host_names cluster_condition not datacenter_name or not cluster_name or isinstance h['parent'] vim.ClusterComputeResource and h['parent'].name cluster_name if name_condition and cluster_condition filtered_hosts.append h['object'] return filtered_hosts
def Coin name p S.Half return rv name BernoulliDistribution p 'H' 'T'
def _check_valid_version npm_version distutils.version.LooseVersion salt.modules.cmdmod.run 'npm--version' output_loglevel 'quiet' valid_version distutils.version.LooseVersion '1.2' if npm_version < valid_version raise CommandExecutionError "'npm'isnotrecentenough {0}<{1} .PleaseUpgrade.".format npm_version valid_version
def find_parameters obj fields None if fields is None fields [k for k in obj.__dict__.keys if not k.startswith '_' ]params []for field in fields data getattr obj field if isinstance data basestring for match in Template.pattern.finditer data name match.group 'named' or match.group 'braced' if name is not None params.append name return params
def atrm *args if not salt.utils.which 'at' return "'at.atrm'isnotavailable."if not args return {'jobs' {'removed' [] 'tag' None}}if args[0] 'all' if len args > 1 opts list list map str [j['job'] for j in atq args[1] ['jobs']] ret {'jobs' {'removed' opts 'tag' args[1]}}else opts list list map str [j['job'] for j in atq ['jobs']] ret {'jobs' {'removed' opts 'tag' None}}else opts list list map str [i['job'] for i in atq ['jobs'] if i['job'] in args ] ret {'jobs' {'removed' opts 'tag' None}}output _cmd 'at' '-d' ''.join opts if output is None return "'at.atrm'isnotavailable."return ret
@spm_face.requires_spm_datadef test_read_spm_ctf data_path spm_face.data_path raw_fname op.join data_path 'MEG' 'spm' 'SPM_CTF_MEG_example_faces1_3D.ds' raw read_raw_ctf raw_fname extras raw._raw_extras[0]assert_equal extras['n_samp'] raw.n_times assert_false extras['n_samp'] extras['n_samp_tot']
def getScaleTetragrid elementNode prefix scaleDefaultVector3 Vector3 1.0 1.0 1.0 scale getCumulativeVector3Remove scaleDefaultVector3.copy elementNode prefix if scale scaleDefaultVector3 return Nonereturn [[scale.x 0.0 0.0 0.0] [0.0 scale.y 0.0 0.0] [0.0 0.0 scale.z 0.0] [0.0 0.0 0.0 1.0]]
def _check_dladm return salt.utils.which 'dladm'
def nnls A b A b map asarray_chkfinite A b if len A.shape ! 2 raise ValueError 'expectedmatrix' if len b.shape ! 1 raise ValueError 'expectedvector' m n A.shapeif m ! b.shape[0] raise ValueError 'incompatibledimensions' w zeros n dtype double zz zeros m dtype double index zeros n dtype int x rnorm mode _nnls.nnls A m n b w zz index if mode ! 1 raise RuntimeError 'toomanyiterations' return x rnorm
def hosts hostnames zone 'net' addresses [gethostbyname name for name in hostnames]return '%s %s' % zone ' '.join addresses
def vat_number_check_digit vat_number normalized_vat_number smart_str vat_number .zfill 10 total 0for i in range 0 10 2 total + int normalized_vat_number[i] for i in range 1 11 2 quotient remainder divmod int normalized_vat_number[i] * 2 10 total + quotient + remainder return smart_unicode 10 - total % 10 % 10
def getBracketValuesDeleteEvaluator bracketBeginIndex bracketEndIndex evaluators evaluatedExpressionValueEvaluators getBracketEvaluators bracketBeginIndex bracketEndIndex evaluators bracketValues []for evaluatedExpressionValueEvaluator in evaluatedExpressionValueEvaluators bracketValues.append evaluatedExpressionValueEvaluator.value del evaluators[ bracketBeginIndex + 1 bracketEndIndex + 1 ]return bracketValues
def wrap_elemwise numpy_ufunc array_wrap False def wrapped *args **kwargs dsk [arg for arg in args if hasattr arg '_elemwise' ]if len dsk > 0 if array_wrap return dsk[0]._elemwise __array_wrap__ numpy_ufunc *args **kwargs else return dsk[0]._elemwise numpy_ufunc *args **kwargs else return numpy_ufunc *args **kwargs wrapped.__name__ numpy_ufunc.__name__wrapped.__doc__ skip_doctest numpy_ufunc.__doc__ return wrapped
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def test_intersect_2 old 20 20 20 20 20 new 58 4 20 18 answer [ 0 slice 0 20 1 slice 0 20 2 slice 0 18 2 slice 18 20 3 slice 0 2 3 slice 2 20 4 slice 0 2 4 slice 2 20 ]cross list intersect_chunks old_chunks old new_chunks new assert answer cross
def squeeze_nxn input_ n_factor 2 if isinstance input_ float int return input_shape input_.get_shape .as_list batch_size shape[0]height shape[1]width shape[2]channels shape[3]if height % n_factor ! 0 raise ValueError 'Heightnotdivisibleby%d.' % n_factor if width % n_factor ! 0 raise ValueError 'Widthnotdivisibleby%d.' % n_factor res tf.reshape input_ [batch_size height // n_factor n_factor width // n_factor n_factor channels] res tf.transpose res [0 1 3 5 2 4] res tf.reshape res [batch_size height // n_factor width // n_factor channels * n_factor * n_factor ] return res
def metadef_tag_delete context namespace_name name session None session session or get_session return metadef_tag_api.delete context namespace_name name session
def test_mapping_inverse RS Rotation2D & Scale M RS | Mapping [2 0 1] | RS m M 12.1 13.2 14.3 15.4 assert_allclose 0 1 2 m.inverse *m 0 1 2 atol 1e-08
def minimum_spanning_edges G algorithm 'kruskal' weight 'weight' keys True data True return _spanning_edges G minimum True algorithm algorithm weight weight keys keys data data
def dup_inner_gcd f g K if not K.is_Exact try exact K.get_exact except DomainError return [K.one] f g f dup_convert f K exact g dup_convert g K exact h cff cfg dup_inner_gcd f g exact h dup_convert h exact K cff dup_convert cff exact K cfg dup_convert cfg exact K return h cff cfg elif K.has_Field if K.is_QQ and query 'USE_HEU_GCD' try return dup_qq_heu_gcd f g K except HeuristicGCDFailed passreturn dup_ff_prs_gcd f g K else if K.is_ZZ and query 'USE_HEU_GCD' try return dup_zz_heu_gcd f g K except HeuristicGCDFailed passreturn dup_rr_prs_gcd f g K
def addFacesGivenBinary stlData triangleMesh vertexIndexTable numberOfVertexes len stlData - 84 / 50 vertexes []for vertexIndex in xrange numberOfVertexes byteIndex 84 + vertexIndex * 50 vertexes.append getVertexGivenBinary byteIndex + 12 stlData vertexes.append getVertexGivenBinary byteIndex + 24 stlData vertexes.append getVertexGivenBinary byteIndex + 36 stlData addFacesGivenVertexes triangleMesh vertexIndexTable vertexes
def GetArgument kwargs name die_fn if name in kwargs return kwargs[name]else print >>sys.stderr '%sargumentrequired' % name die_fn
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def inttobits anint width None remains anintretreverse []while remains retreverse.append remains & 1 remains remains >> 1 retreverse.reverse ret retreverseif None ! width ret_head [0] * width - len ret ret ret_head + ret return ret
def pr_realm entity if not entity return []s3db current.s3dbatable s3db.pr_affiliationrtable s3db.pr_rolequery atable.deleted ! True & atable.role_id rtable.id & atable.pe_id entity & rtable.deleted ! True & rtable.role_type OU rows current.db query .select rtable.pe_id realm [row.pe_id for row in rows]return realm
def CDLCONCEALBABYSWALL barDs count return call_talib_with_ohlc barDs count talib.CDLCONCEALBABYSWALL
def _format_mappings properties result mappings [{'virtualName' m['virtual'] 'deviceName' m['device']} for m in _properties_get_mappings properties if block_device.is_swap_or_ephemeral m['virtual'] ]block_device_mapping [_format_block_device_mapping bdm for bdm in properties.get 'block_device_mapping' [] ]for bdm in block_device_mapping for i in range len mappings if bdm['deviceName'] mappings[i]['deviceName'] del mappings[i]breakmappings.append bdm mappings [bdm for bdm in mappings if not bdm.get 'noDevice' False ]if mappings result['blockDeviceMapping'] mappings
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def _losetup_list_parse output devices []for line in output.splitlines parts line.split u' ' 2 if len parts ! 3 continue device_file _ backing_file partsdevice_file FilePath device_file.strip .encode 'utf-8' left_bracket_offset backing_file.find ' ' backing_file backing_file[ left_bracket_offset + 1 ]right_bracket_offset backing_file.rfind ' ' backing_file backing_file[ right_bracket_offset]expected_suffix_list [' deleted ']for suffix in expected_suffix_list offset backing_file.rfind suffix if offset > -1 backing_file backing_file[ offset]backing_file backing_file.rstrip backing_file FilePath backing_file.encode 'utf-8' devices.append device_file backing_file return devices
def AbelianGroup *cyclic_orders groups []degree 0order 1for size in cyclic_orders degree + sizeorder * sizegroups.append CyclicGroup size G DirectProduct *groups G._is_abelian TrueG._degree degreeG._order orderreturn G
def kill_listen_processes namespace if _kill_listen_processes namespace force False try wait_until_no_listen_pids_namespace namespace except PidsInNamespaceException _kill_listen_processes namespace force True wait_until_no_listen_pids_namespace namespace
def local_import_aux name reload_force False app 'welcome' items name.replace '/' '.' name 'applications.%s.modules.%s' % app items module __import__ name for item in name.split '.' [1 ] module getattr module item if reload_force reload module return module
def _restoreMergedOptions for option in RESTORE_MERGED_OPTIONS conf[option] mergedOptions[option]
def create_hadoopcli_client version hdfs_config.get_configured_hadoop_version if version 'cdh4' return HdfsClient elif version 'cdh3' return HdfsClientCdh3 elif version 'apache1' return HdfsClientApache1 else raise ValueError 'Error UnknownversionspecifiedinHadoopversionconfigurationparameter'
def HBox *args **kwargs return Row *args **kwargs
def product_simplify s from sympy.concrete.products import Productterms Mul.make_args s p_t []o_t []for term in terms if isinstance term Product p_t.append term else o_t.append term used [False] * len p_t for method in range 2 for i p_term1 in enumerate p_t if not used[i] for j p_term2 in enumerate p_t if not used[j] and i ! j if isinstance product_mul p_term1 p_term2 method Product p_t[i] product_mul p_term1 p_term2 method used[j] Trueresult Mul *o_t for i p_term in enumerate p_t if not used[i] result Mul result p_term return result
def name_fixer p if isinstance p unicode return pelif isinstance p str try return p.decode 'utf-8' except try return p.decode codepage except return p.decode 'cp1252' 'replace' .replace '?' '!' else return p
def gps_bearing lat1 lon1 lat2 lon2 lat1 math.radians lat1 lat2 math.radians lat2 lon1 math.radians lon1 lon2 math.radians lon2 dLat lat2 - lat1 dLon lon2 - lon1 y math.sin dLon * math.cos lat2 x math.cos lat1 * math.sin lat2 - math.sin lat1 * math.cos lat2 * math.cos dLon bearing math.degrees math.atan2 y x if bearing < 0 bearing + 360.0return bearing
def autocomplete query url 'http //autocomplete.wunderground.com/aq?query {}'.format query return requests.get url .json ['RESULTS']
def py2encode s return s.encode 'utf-8' if PY2 and type s is unicode else s
def canonical_path request lang getattr request 'locale' settings.LANGUAGE_CODE url getattr request 'path' '/' return {'canonical_path' re.sub '^/' + lang '' url }
def ansible_group_init ansible_inv group_name ansible_inv[group_name] {}ansible_inv[group_name]['hosts'] []ansible_inv[group_name]['vars'] {}
def list_to_scope scope if isinstance scope unicode_type or scope is None return scopeelif isinstance scope set tuple list return u''.join [unicode_type s for s in scope] else raise ValueError u'Invalidscope %s mustbestring tuple set orlist.' % scope
def wholelist *field_list return Role Role.wholelist field_list
def _unquote_slashes match matched match.group 0 if matched ';;' return ';'elif matched ';_' return '/'else return matched
def node_state id_ states_int {0 'RUNNING' 1 'REBOOTING' 2 'TERMINATED' 3 'PENDING' 4 'UNKNOWN' 5 'STOPPED' 6 'SUSPENDED' 7 'ERROR' 8 'PAUSED'}states_str {'running' 'RUNNING' 'rebooting' 'REBOOTING' 'starting' 'STARTING' 'terminated' 'TERMINATED' 'pending' 'PENDING' 'unknown' 'UNKNOWN' 'stopping' 'STOPPING' 'stopped' 'STOPPED' 'suspended' 'SUSPENDED' 'error' 'ERROR' 'paused' 'PAUSED' 'reconfiguring' 'RECONFIGURING'}return states_str[id_] if isinstance id_ string_types else states_int[id_]
def deepfirst seq if not isinstance seq list tuple return seqelse return deepfirst seq[0]
def val2array value withNone True withScalar True length 2 if value is None if withNone return Noneelse raise ValueError 'Invalidparameter.Noneisnotacceptedasvalue.' value numpy.array value float if numpy.product value.shape 1 if withScalar return numpy.repeat value length else msg 'Invalidparameter.Singlenumbersarenotaccepted.Shouldbetuple/list/arrayoflength%s'raise ValueError msg % str length elif value.shape[ -1 ] length return numpy.array value float else msg 'Invalidparameter.Shouldbelength%sbutgotlength%s.'raise ValueError msg % str length str len value
def track_closed cls class TrackingClosed cls def __init__ self *a **kw super TrackingClosed self .__init__ *a **kw self.closed Falsedef close self super TrackingClosed self .close self.closed Truereturn TrackingClosed
def sample_hi_given samples i W_list b_list beta 1.0 hi_mean hi_given samples i W_list b_list beta hi_sample theano_rng.binomial size samples[i].get_value .shape n 1 p hi_mean dtype floatX return hi_sample
def reissue_receipt receipt time_ calendar.timegm time.gmtime receipt_obj Receipt receipt data receipt_obj.receipt_decoded data.update {'exp' time_ + settings.WEBAPPS_RECEIPT_EXPIRY_SECONDS 'iat' time_ 'nbf' time_} return sign data
def ValidatePropertyInteger name value if not -9223372036854775808 < value < 9223372036854775807 raise OverflowError '%disoutofboundsforint64' % value
def samples_to_file samples rate file_out fmt '' dtype 'int16' file_fmt data_fmt _get_pyo_codes fmt dtype file_out if type samples np.ndarray samples samples.tolist if type samples ! list raise TypeError 'samplesshouldbealistornp.array' try pyo.savefile samples path file_out sr int rate channels 1 fileformat file_fmt sampletype data_fmt except Exception msg 'couldnotsave`{0}`;permissionsorotherissue?'raise IOError msg.format file_out
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def list_route methods None **kwargs methods [u'get'] if methods is None else methods def decorator func func.bind_to_methods methodsfunc.detail Falsefunc.kwargs kwargsreturn funcreturn decorator
def getAroundsFromPath path radius thresholdRatio 0.9 radius abs radius points getPointsFromPath path radius thresholdRatio return getAroundsFromPathPoints points radius thresholdRatio 0.9
def import_vul_csv_part2 job_id request.post_vars.jobif not job_id return "ErrorNoJobID'sprovided"output s3_rest_controller 'vulnerability' 'data' csv_stylesheet 'data.xsl' totalRecords output[0]totalErrors output[1]totalIgnored output[2]from gluon.serializers import json as jsonsresponse.headers['Content-Type'] 'application/json'return jsons {'totalRecords' totalRecords 'totalErrors' totalErrors 'totalIgnored' totalIgnored}
def identification_field_factory label error_required return forms.CharField label label widget forms.TextInput attrs attrs_dict max_length 75 error_messages {u'required' error_required}
def media_type_matches lhs rhs lhs _MediaType lhs rhs _MediaType rhs return lhs.match rhs
def write_wcsconfig_h paths h_file io.StringIO h_file.write u"\n/*ThebundledversionhasWCSLIB_VERSION*/\n#defineHAVE_WCSLIB_VERSION1\n\n/*WCSLIBlibraryversionnumber.*/\n#defineWCSLIB_VERSION{0}\n\n/*64-bitintegerdatatype.*/\n#defineWCSLIB_INT64{1}\n\n/*Windowsneedssomeotherdefinestopreventinclusionofwcsset \nwhichconflictswithwcslib'swcsset .Theseneedtobeset\noncodethat*uses*astropy.wcs inadditiontoastropy.wcsitself.\n*/\n#ifdefined _WIN32 ||defined _MSC_VER ||defined __MINGW32__ ||defined __MINGW64__ \n\n#ifndefYY_NO_UNISTD_H\n#defineYY_NO_UNISTD_H\n#endif\n\n#ifndef_CRT_SECURE_NO_WARNINGS\n#define_CRT_SECURE_NO_WARNINGS\n#endif\n\n#ifndef_NO_OLDNAMES\n#define_NO_OLDNAMES\n#endif\n\n#ifndefNO_OLDNAMES\n#defineNO_OLDNAMES\n#endif\n\n#ifndef__STDC__\n#define__STDC__1\n#endif\n\n#endif\n".format WCSVERSION determine_64_bit_int content h_file.getvalue .encode u'ascii' for path in paths setup_helpers.write_if_different path content
def vhosts cmd '{0}-S'.format _detect_os ret {}namevhost ''out __salt__['cmd.run'] cmd for line in out.splitlines if not line continuecomps line.split if 'isaNameVirtualHost' in line namevhost comps[0]ret[namevhost] {}else if comps[0] 'default' ret[namevhost]['default'] {}ret[namevhost]['default']['vhost'] comps[2]ret[namevhost]['default']['conf'] re.sub '\\ |\\ ' '' comps[3] if comps[0] 'port' ret[namevhost][comps[3]] {}ret[namevhost][comps[3]]['vhost'] comps[3]ret[namevhost][comps[3]]['conf'] re.sub '\\ |\\ ' '' comps[4] ret[namevhost][comps[3]]['port'] comps[1]return ret
def printTraceback tb log.msg 'PerspectiveBrokerTraceback ' log.msg tb
def test_suggested_cased_column_names_with_alias cased_completer complete_event text u'SELECTu.id u.fromusersu'position len u'SELECTu.id u.' result set cased_completer.get_completions Document text text cursor_position position complete_event assert set result set cased_users_cols
def _read_arraydesc f arraydesc {'arrstart' _read_long f }if arraydesc['arrstart'] 8 _skip_bytes f 4 arraydesc['nbytes'] _read_long f arraydesc['nelements'] _read_long f arraydesc['ndims'] _read_long f _skip_bytes f 8 arraydesc['nmax'] _read_long f arraydesc['dims'] []for d in range arraydesc['nmax'] arraydesc['dims'].append _read_long f elif arraydesc['arrstart'] 18 warnings.warn 'Usingexperimental64-bitarrayread' _skip_bytes f 8 arraydesc['nbytes'] _read_uint64 f arraydesc['nelements'] _read_uint64 f arraydesc['ndims'] _read_long f _skip_bytes f 8 arraydesc['nmax'] 8arraydesc['dims'] []for d in range arraydesc['nmax'] v _read_long f if v ! 0 raise Exception 'ExpectedazeroinARRAY_DESC' arraydesc['dims'].append _read_long f else raise Exception 'UnknownARRSTART %i' % arraydesc['arrstart'] return arraydesc
def ecommerce_api_client user session None jwt_auth configuration_helpers.get_value 'JWT_AUTH' settings.JWT_AUTH return EdxRestApiClient configuration_helpers.get_value 'ECOMMERCE_API_URL' settings.ECOMMERCE_API_URL configuration_helpers.get_value 'ECOMMERCE_API_SIGNING_KEY' settings.ECOMMERCE_API_SIGNING_KEY user.username user.profile.name if hasattr user 'profile' else None user.email tracking_context create_tracking_context user issuer jwt_auth['JWT_ISSUER'] expires_in jwt_auth['JWT_EXPIRATION'] session session
def onBaseAppReady isBootstrap INFO_MSG 'onBaseAppReady isBootstrap %s appID %s bootstrapGroupIndex %s bootstrapGlobalIndex %s' % isBootstrap os.getenv 'KBE_COMPONENTID' os.getenv 'KBE_BOOTIDX_GROUP' os.getenv 'KBE_BOOTIDX_GLOBAL'
def generate_json_file results_dir relative_links True results_data parse_results_dir results_dir relative_links json_path os.path.join results_dir 'status.json' json_file open json_path 'w' json.dump results_data json_file json_file.close return json_path
def TriangleCollection mode 'raw' *args **kwargs return RawTriangleCollection *args **kwargs
def ErrorToString ErrorCode if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pString ctypes.create_string_buffer 256 staticLib.ErrorToString ctypes.c_long ErrorCode ctypes.byref pString return pString.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def _get_reparse_data path if sys.getwindowsversion .major < 6 raise SaltInvocationError 'SymlinksareonlysupportedonWindowsVistaorlater.' path os.path.normpath path if not _is_reparse_point path return NonefileHandle Nonetry fileHandle win32file.CreateFileW path 2147483648 1 None 3 2097152 | 33554432 reparseData win32file.DeviceIoControl fileHandle 589992 None 16384 finally if fileHandle win32file.CloseHandle fileHandle return reparseData
def debounce seconds 1 def decorator func func.timer None@wraps func def wrapper *args **kwargs def call func *args **kwargs func.timer Noneif func.timer func.timer.cancel func.timer Timer seconds call func.timer.start return wrapperreturn decorator
def get_valid_utf8_str str_or_unicode if isinstance str_or_unicode unicode str_or_unicode _len utf8_encoder str_or_unicode 'replace' valid_utf8_str _len utf8_decoder str_or_unicode 'replace' return valid_utf8_str.encode 'utf-8'
def rfind s *args return _apply s.rfind args
@register.inclusion_tag u'admin/includes/quick_blog.html' takes_context True def quick_blog context context[u'form'] BlogPostForm return context
def get_instructions xmltree instructions xmltree.find 'instructions' if instructions is not None instructions.tag 'div'xmltree.remove instructions return etree.tostring instructions encoding 'unicode' return None
def this_is_a_testfile filename return TESTFILE_RE.match osp.basename filename
def DrawBox vMin vMax glBegin GL_LINE_LOOP glVertex3f vMin[0] vMin[1] vMin[2] glVertex3f vMax[0] vMin[1] vMin[2] glVertex3f vMax[0] vMax[1] vMin[2] glVertex3f vMin[0] vMax[1] vMin[2] glEnd glBegin GL_LINE_LOOP glVertex3f vMin[0] vMin[1] vMax[2] glVertex3f vMax[0] vMin[1] vMax[2] glVertex3f vMax[0] vMax[1] vMax[2] glVertex3f vMin[0] vMax[1] vMax[2] glEnd glBegin GL_LINES glVertex3f vMin[0] vMin[1] vMin[2] glVertex3f vMin[0] vMin[1] vMax[2] glVertex3f vMax[0] vMin[1] vMin[2] glVertex3f vMax[0] vMin[1] vMax[2] glVertex3f vMax[0] vMax[1] vMin[2] glVertex3f vMax[0] vMax[1] vMax[2] glVertex3f vMin[0] vMax[1] vMin[2] glVertex3f vMin[0] vMax[1] vMax[2] glEnd
def check_response method @functools.wraps method def wrapped self *args **kwargs response method self *args **kwargs status response.status_codeif status > 400 if response.status_code 429 self.handle_429 resp *args **kwargs return method self *args **kwargs .json msg_args response response.text response.headers msg 'Badapiresponse %r%r%r' % msg_args raise BadAPIResponse response msg return response.json return wrapped
def getCSVelement v v cstr v if not v return u''if u' ' in v or u'\n' in v or u'"' in v if u'"' in v v v.replace u'"' u'""' return u'"' + v + u'"' else return v or u''
def _next_version version if hasattr version 'base_version' if version.base_version parts version.base_version.split '.' else parts []else parts []for part in version if part.startswith '*' breakparts.append part parts [int p for p in parts]if len parts < 3 parts + [0] * 3 - len parts major minor micro parts[ 3]return '{0}.{1}.{2}'.format major minor + 1 0
def get_maker engine autocommit True expire_on_commit False return sqlalchemy.orm.sessionmaker bind engine autocommit autocommit expire_on_commit expire_on_commit
def _restore_path_envvar original if original os.environ['PATH'] original
def void_output func argtypes errcheck True if argtypes func.argtypes argtypesif errcheck func.restype c_intfunc.errcheck check_errcodeelse func.restype Nonereturn func
def SVG_path path transform None simplify False if transform is not None path path.transformed transform vc_tuples [ vertices if path_code ! Path.CLOSEPOLY else [] PATH_DICT[path_code] for vertices path_code in path.iter_segments simplify simplify ]if not vc_tuples return np.zeros 0 2 [] else vertices codes zip *vc_tuples vertices np.array list itertools.chain *vertices .reshape -1 2 return vertices list codes
def _inputs_swap_needed mode shape1 shape2 if mode 'valid' ok1 ok2 True True for d1 d2 in zip shape1 shape2 if not d1 > d2 ok1 Falseif not d2 > d1 ok2 Falseif not ok1 or ok2 raise ValueError "For'valid'mode onemustbeatleastaslargeastheotherineverydimension" return not ok1 return False
def isnumeric obj try float obj return Trueexcept return False
@not_implemented_for 'directed' def is_biconnected G bcc list biconnected_components G if not bcc return Falsereturn len bcc[0] len G
def find_in_path fname path None if path is None path os.environ.get 'PATH' '' for dir in path.split os.pathsep fpath os.path.join dir fname if os.path.isfile fpath return fpathelse return None
def _check_type_compatible alphabets dna rna nucl protein False False False False for alpha in alphabets a _get_base_alphabet alpha if isinstance a DNAAlphabet dna Truenucl Trueif rna or protein return Falseelif isinstance a RNAAlphabet rna Truenucl Trueif dna or protein return Falseelif isinstance a NucleotideAlphabet nucl Trueif protein return Falseelif isinstance a ProteinAlphabet protein Trueif nucl return Falsereturn True
def generate_objects_info_packs repo for pack in repo.object_store.packs yield 'P' + pack.data.filename.encode sys.getfilesystemencoding + '\n'
def _include_in_cluster context cluster model partial_rename filters filters _clean_filters filters if filters and not is_valid_model_filters model filters return Nonequery get_session .query model if hasattr model 'deleted' query query.filter_by deleted False for field in {'cluster_name' 'host'}.intersection filters value filters.pop field query query.filter _filter_host getattr model field value if partial_rename and isinstance cluster six.string_types cluster func.replace getattr model field value cluster query query.filter_by **filters result query.update {'cluster_name' cluster} synchronize_session False return result
def error_codes *errnames ans {getattr errno x None for x in errnames}ans.discard None return ans
def _retrieve_users return __salt__['users.config']
def get_pci_requests_from_flavor flavor pci_requests []if 'extra_specs' in flavor and 'pci_passthrough alias' in flavor['extra_specs'] pci_requests _translate_alias_to_requests flavor['extra_specs']['pci_passthrough alias'] return objects.InstancePCIRequests requests pci_requests
def _CopyQueryOptionsToProtocolBuffer query offset limit number_found_accuracy cursor cursor_type ids_only returned_fields snippeted_fields returned_expressions sort_options params if offset params.set_offset offset params.set_limit limit params.set_matched_count_accuracy number_found_accuracy if cursor params.set_cursor cursor.encode 'utf-8' params.set_cursor_type cursor_type if ids_only params.set_keys_only ids_only if returned_fields or snippeted_fields or returned_expressions field_spec_pb params.mutable_field_spec for field in returned_fields field_spec_pb.add_name field.encode 'utf-8' for snippeted_field in snippeted_fields expression u'snippet %s %s ' % _QuoteString query snippeted_field _CopyFieldExpressionToProtocolBuffer FieldExpression name snippeted_field expression expression.encode 'utf-8' field_spec_pb.add_expression for expression in returned_expressions _CopyFieldExpressionToProtocolBuffer expression field_spec_pb.add_expression if sort_options is not None _CopySortOptionsToProtocolBuffer sort_options params
def isgeneratorfunction object return bool isfunction object or ismethod object and object.func_code.co_flags & CO_GENERATOR
def enable_merge_strategies *merge_strategies return _EnableMergeStrategies *merge_strategies
def pro_cv_seq m n c if not isscalar m and isscalar n and isscalar c raise ValueError 'Argumentsmustbescalars.' if n ! floor n or m ! floor m raise ValueError 'Modesmustbeintegers.' if n - m > 199 raise ValueError 'Differencebetweennandmistoolarge.' maxL n - m + 1 return specfun.segv m n c 1 [1][ maxL]
def is_bsd return platform.system in 'Darwin' 'FreeBSD' 'OpenBSD'
def adapt_obj obj blob sqlite3.Binary cPickle.dumps obj if len blob > config.max_blob_size warnings.warn 'largeobjectsstoredinSQLite' + LARGE_BLOB_WARNING.format type obj len blob warnings.filterwarnings 'ignore' 'largeobjects.*' return blob
def contract_creation_exceptions return {sa.Column ['.'.join [table 'project_id'] for table in get_tables ] sa.Index get_tables }
def _get_self_href response data jsonutils.loads response.body for link in data['versions'][0]['links'] if link['rel'] 'self' return link['href']return ''
def set_output fp import commands browsercommands.OUT browser.OUT fp
def test_nearmiss_fit_single_class ratio 'auto'nm2 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS y_single_class np.zeros X.shape[0] assert_warns UserWarning nm2.fit X y_single_class
def is_hidden_folder folder def is_hidden filepath name ek os.path.basename ek os.path.abspath filepath return name.startswith u'.' or has_hidden_attribute filepath def has_hidden_attribute filepath try attrs ctypes.windll.kernel32.GetFileAttributesW ctypes.c_wchar_p unicode filepath assert attrs ! -1 result bool attrs & 2 except AttributeError AssertionError result Falsereturn resultif ek os.path.isdir folder if is_hidden folder return Truereturn False
def remote_user_auth_view request t Template 'Usernameis{{user}}.' c RequestContext request {} return HttpResponse t.render c
def s3_image_get context image_id return IMPL.s3_image_get context image_id
def safe_add x y if x is not None and y is not None return x + y elif x is not None return xelif y is not None return yelse return None
def test_threading_limit db folder_sync_engine monkeypatch from inbox.models import Message ThreadMAX_THREAD_LENGTH 10monkeypatch.setattr 'inbox.mailsync.backends.imap.generic.MAX_THREAD_LENGTH' MAX_THREAD_LENGTH namespace_id folder_sync_engine.namespace_idmsg MockRawMessage [] for i in range 3 * MAX_THREAD_LENGTH m Message m.namespace_id namespace_idm.received_date datetime.datetime.utcnow m.references []m.size 0m.body ''m.from_addr [ 'KarimHamidou' 'karim@nilas.com' ]m.to_addr [ 'EbenFreeman' 'eben@nilas.com' ]m.snippet ''m.subject 'uniquesubject'db.session.add m folder_sync_engine.add_message_to_thread db.session m msg db.session.commit new_threads db.session.query Thread .filter Thread.subject 'uniquesubject' .all assert len new_threads 3 assert all len thread.messages MAX_THREAD_LENGTH for thread in new_threads
def import_string dotted_path try module_path class_name dotted_path.rsplit u'.' 1 except ValueError msg u"%sdoesn'tlooklikeamodulepath" % dotted_path six.reraise ImportError ImportError msg sys.exc_info [2] module import_module module_path try return getattr module class_name except AttributeError msg u'Module"%s"doesnotdefinea"%s"attribute/class' % dotted_path class_name six.reraise ImportError ImportError msg sys.exc_info [2]
def test_setup_stubs request_data None app_id 'myapp' application_root '/tmp/root' trusted False blobstore_path '/dev/null' datastore_consistency None datastore_path ' memory ' datastore_require_indexes False datastore_auto_id_policy datastore_stub_util.SCATTERED images_host_prefix 'http //localhost 8080' logs_path ' memory ' mail_smtp_host '' mail_smtp_port 25 mail_smtp_user '' mail_smtp_password '' mail_enable_sendmail False mail_show_mail_body False matcher_prospective_search_path '/dev/null' search_index_path None taskqueue_auto_run_tasks False taskqueue_default_http_server 'http //localhost 8080' uaserver_path 'localhost' user_login_url '/_ah/login?continue %s' user_logout_url '/_ah/login?continue %s' xmpp_path 'localhost' apiproxy_stub_map.apiproxy apiproxy_stub_map.APIProxyStubMap if datastore_consistency is None datastore_consistency datastore_stub_util.PseudoRandomHRConsistencyPolicy setup_stubs request_data app_id application_root trusted blobstore_path datastore_consistency datastore_path datastore_require_indexes datastore_auto_id_policy images_host_prefix logs_path mail_smtp_host mail_smtp_port mail_smtp_user mail_smtp_password mail_enable_sendmail mail_show_mail_body matcher_prospective_search_path search_index_path taskqueue_auto_run_tasks taskqueue_default_http_server uaserver_path user_login_url user_logout_url xmpp_path
def __format_columns column_names sort_field dataset []if sort_field is not None sort_name sort_fieldelse sort_name 'name'if sort_name.startswith '!' sort_name sort_name[1 ]sort_order 'desc'else sort_order 'asc'for fieldname in column_names fieldorder 'none'if fieldname sort_name fieldorder sort_orderdataset.append [fieldname fieldorder] return dataset
def _vode_banded_jac_wrapper jacfunc ml jac_params def jac_wrapper t y jac asarray jacfunc t y *jac_params padded_jac vstack jac zeros ml jac.shape[1] return padded_jacreturn jac_wrapper
def test_sensitivity_specificity_unused_pos_label assert_warns_message UserWarning "Notethatpos_label setto2 isignoredwhenaverage! 'binary' got'macro' .Youmayuselabels [pos_label]tospecifyasinglepositiveclass." sensitivity_specificity_support [1 2 1] [1 2 2] pos_label 2 average 'macro'
def is_fits origin filepath fileobj *args **kwargs if fileobj is not None pos fileobj.tell sig fileobj.read 30 fileobj.seek pos return sig FITS_SIGNATURE elif filepath is not None if filepath.lower .endswith '.fits' '.fits.gz' '.fit' '.fit.gz' '.fts' '.fts.gz' return Trueelif isinstance args[0] HDUList TableHDU BinTableHDU GroupsHDU return Trueelse return False
def _chinese_remainder_reconstruction_univariate hp hq p q n hp.degree x hp.ring.gens[0]hpq hp.ring.zerofor i in range n + 1 hpq[ i ] crt [p q] [hp.coeff x ** i hq.coeff x ** i ] symmetric True [0]hpq.strip_zero return hpq
def moderator_required function None def decorator request *args **kwargs group get_object_or_404 Group slug kwargs['slug'] if request.user.is_anonymous return HttpResponseRedirect reverse 'django.contrib.auth.views.login' if GroupMember.objects.is_moderator group request.user return function request *args **kwargs else raise Http404return decorator
def _generate_communities degree_sequence community_sizes mu max_iters result [set for _ in community_sizes]n len degree_sequence free list range n for i in range max_iters v free.pop c random.choice range len community_sizes s round degree_sequence[v] * 1 - mu if s < community_sizes[c] result[c].add v else free.append v if len result[c] > community_sizes[c] free.append result[c].pop if not free return resultmsg 'Couldnotassigncommunities;tryincreasingmin_community'raise nx.ExceededMaxIterations msg
def override_bytes_from_content_type listing_dict logger None listing_dict['content_type'] swift_bytes extract_swift_bytes listing_dict['content_type'] if swift_bytes is not None try listing_dict['bytes'] int swift_bytes except ValueError if logger logger.exception _ 'Invalidswift_bytes'
def _maybe_reset_index data if data.index.equals Index lrange 1 len data + 1 data data.reset_index drop True return data
def get_contact_objects current_user contact objects dict CONTACT_OBJECTS for key in objects if hasattr contact key manager getattr contact key try manager manager.filter status__hidden False except passobjects[key]['objects'] Object.filter_permitted current_user manager return objects
def _get_django_vars import refrom django.test.testcases import TransactionTestCasecamelcase re.compile u' [a-z][A-Z]|[A-Z][a-z] ' def insert_underscore m u'Insertanappropriateunderscoreintothename.' a b m.group 0 if b.islower return u'_{}{}'.format a b else return u'{}_{}'.format a b def pep8 name u'ReplacecamelcasenamewithPEP8equivalent.'return str camelcase.sub insert_underscore name .lower class Dummy TransactionTestCase u'Adummytestcaseforgatheringcurrentassertionhelpers.'def nop u'Adummytesttogetaninitializedtestcase.'passdummy_test Dummy u'nop' new_names {}for assert_name in [at for at in dir dummy_test if at.startswith u'assert' and u'_' not in at ] pepd pep8 assert_name new_names[pepd] getattr dummy_test assert_name return new_names
def ccx_dummy_request factory RequestFactory request factory.get 'ccx_coach_dashboard' request.user MagicMock return request
@must_be_valid_project@must_have_permission WRITE @must_not_be_registrationdef remove_pointer_from_folder auth node pointer_id **kwargs if pointer_id is None raise HTTPError http.BAD_REQUEST pointer_id node.pointing_at pointer_id pointer Pointer.load pointer_id if pointer is None raise HTTPError http.BAD_REQUEST try node.rm_pointer pointer auth auth except ValueError raise HTTPError http.BAD_REQUEST node.save
def cleanup _lib.RAND_cleanup
def _BooleanAttribute value if value in ['true' '1'] return Trueelif value in ['false' '0'] return Falseelse return None
def serialize_for_reading element return etree.tostring element encoding u'unicode' pretty_print True
def make_pkg_resources global_conf egg resource_name '' if pkg_resources is None raise NotImplementedError 'Thisfunctionrequirespkg_resources.' return PkgResourcesParser egg resource_name
def regularize_layer_params_weighted layers penalty tags {'regularizable' True} **kwargs return sum coeff * apply_penalty layer.get_params **tags penalty **kwargs for layer coeff in layers.items
def create_variable name shape initializer tf.contrib.layers.xavier_initializer_conv2d variable tf.Variable initializer shape shape name name return variable
def last_focused_window try return get 'last-focused-main-window' except KeyError return window_by_index -1
def parse_cachecontrol header directives {}for directive in header.split ' ' key sep val directive.strip .partition ' ' if key directives[key.lower ] val if sep else None return directives
def _i18n_cache_key_suffix request cache_key if settings.USE_I18N or settings.USE_L10N cache_key + u'.%s' % get_language_from_request request if settings.USE_TZ tz_name force_text get_current_timezone_name errors u'ignore' cache_key + u'.%s' % tz_name.encode u'ascii' u'ignore' .decode u'ascii' .replace u'' u'_' return cache_key
def isdata object return not inspect.ismodule object or inspect.isclass object or inspect.isroutine object or inspect.isframe object or inspect.istraceback object or inspect.iscode object
@csrf_exemptdef checkout_cancel _request context {'payment_support_email' configuration_helpers.get_value 'payment_support_email' settings.PAYMENT_SUPPORT_EMAIL }return render_to_response 'commerce/checkout_cancel.html' context
def ms_attacks exploit return {'1' 'dll_hijacking' '2' 'unc_embed' '3' 'exploit/windows/fileformat/ms15_100_mcl_exe' '4' 'exploit/windows/fileformat/ms14_017_rtf' '5' 'exploit/windows/fileformat/ms11_006_createsizeddibsection' '6' 'exploit/windows/fileformat/ms10_087_rtf_pfragments_bof' '7' 'exploit/windows/fileformat/adobe_flashplayer_button' '8' 'exploit/windows/fileformat/adobe_cooltype_sing' '9' 'exploit/windows/fileformat/adobe_flashplayer_newfunction' '10' 'exploit/windows/fileformat/adobe_collectemailinfo' '11' 'exploit/windows/fileformat/adobe_geticon' '12' 'exploit/windows/fileformat/adobe_jbig2decode' '13' 'exploit/windows/fileformat/adobe_pdf_embedded_exe' '14' 'exploit/windows/fileformat/adobe_utilprintf' '15' 'custom/exe/to/vba/payload' '16' 'exploit/windows/fileformat/adobe_u3d_meshdecl' '17' 'exploit/windows/fileformat/adobe_pdf_embedded_exe_nojs' '18' 'exploit/windows/fileformat/foxit_title_bof' '19' 'exploit/windows/fileformat/apple_quicktime_pnsize' '20' 'exploit/windows/fileformat/nuance_pdf_launch_overflow' '21' 'exploit/windows/fileformat/adobe_reader_u3d' '22' 'exploit/windows/fileformat/ms12_027_mscomctl_bof'}.get exploit 'INVALID'
def test_spans_override_sentiment en_tokenizer text u'goodstuffbadstuff'tokens en_tokenizer text tokens.vocab[tokens[0].text].sentiment 3.0tokens.vocab[tokens[2].text].sentiment -2.0 doc get_doc tokens.vocab [t.text for t in tokens] doc.user_span_hooks[u'sentiment'] lambda span 10.0 assert doc[ 2].sentiment 10.0 assert doc[ -2 ].sentiment 10.0 assert doc[ -1 ].sentiment 10.0
def AddBatchJob client batch_job_service client.GetService 'BatchJobService' version 'v201605' batch_job_operations [{'operand' {} 'operator' 'ADD'}]return batch_job_service.mutate batch_job_operations ['value'][0]
def _parse_params term keys ['key' 'type' 'section' 'file' 're' 'default']params {}for k in keys params[k] ''thiskey 'key'for idp phrase in enumerate term.split for k in keys if '%s ' % k in phrase thiskey kif idp 0 or not params[thiskey] params[thiskey] phraseelse params[thiskey] + '' + phrase rparams [params[x] for x in keys if params[x]]return rparams
def _eapply func e cond None if not isinstance e Expr return eif _is_Expr e or not e.args return func e return e.func *[ _eapply func ei if cond is None or cond ei else ei for ei in e.args]
def parseFilePaths page if page for regex in FILE_PATH_REGEXES for match in re.finditer regex page absFilePath match.group 'result' .strip page page.replace absFilePath '' if isWindowsDriveLetterPath absFilePath absFilePath posixToNtSlashes absFilePath if absFilePath not in kb.absFilePaths kb.absFilePaths.add absFilePath
def test_correctness model MLP layers [Linear dim 10 layer_name 'linear' irange 1.0 Softmax n_classes 2 layer_name 'softmax' irange 1.0 ] batch_size 10 nvis 10 cost LpPenalty variables model.get_params p 2 penalty cost.expr model None penalty_function theano.function inputs [] outputs penalty p penalty_function actual_p 0for param in model.get_params actual_p + numpy.sum param.get_value ** 2 assert numpy.allclose p actual_p
def new data None return SHA224Hash .new data
def binned_binom_proportion x success bins 10 range None conf 0.68269 interval u'wilson' x np.ravel x success np.ravel success .astype np.bool if x.shape ! success.shape raise ValueError u'sizesofxandsuccessmustmatch' n bin_edges np.histogram x bins bins range range k bin_edges np.histogram x[success] bins bin_edges bin_ctr bin_edges[ -1 ] + bin_edges[1 ] / 2.0 bin_halfwidth bin_ctr - bin_edges[ -1 ] valid n > 0 bin_ctr bin_ctr[valid]bin_halfwidth bin_halfwidth[valid]n n[valid]k k[valid]p k / n bounds binom_conf_interval k n conf conf interval interval perr np.abs bounds - p return bin_ctr bin_halfwidth p perr
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
def test_enn_fit_sample_with_indices enn EditedNearestNeighbours return_indices True random_state RND_SEED X_resampled y_resampled idx_under enn.fit_sample X Y X_gt np.array [[ -0.10903849 -0.12085181 ] [0.01936241 0.17799828] [2.59928271 0.93323465] [1.92365863 0.82718767] [0.25738379 0.95564169] [0.78318102 2.59153329] [0.52726792 -0.38735648 ]] y_gt np.array [0 0 1 1 2 2 2] idx_gt np.array [4 11 0 3 1 8 15] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt assert_array_equal idx_under idx_gt
def _fit_eval rd B B2 fwd_svd None fwd_data None whitener None if fwd_svd is None fwd _dipole_forwards fwd_data whitener rd[np.newaxis ] [0] uu sing vv linalg.svd fwd overwrite_a True full_matrices False else uu sing vv fwd_svdgof _dipole_gof uu sing vv B B2 [0]return 1.0 - gof
def is_reserved_with_trailing_underscore name if name.endswith u'_' and not name.endswith u'__' return is_reserved_name name[ -1 ] return False
def cosh x return Cosh x
def _getDeprecationDocstring version replacement None doc 'Deprecatedin%s' % getVersionString version if replacement doc '%s;%s' % doc _getReplacementString replacement return doc + '.'
def _logistic x x np.array x if x.ndim 0 y np.reshape x 1 1 1 elif x.ndim 1 y np.reshape x len x 1 1 elif x.ndim 2 y np.reshape x x.shape[0] 1 x.shape[1] elif x.ndim 3 y xelse raise NotImplementedErrortmp np.c_[ np.zeros y.shape[ -1 ] y.shape[1] 1 y.T ].Tevaluated np.reshape np.exp y - logsumexp tmp axis 0 x.shape return evaluated
def camelcase_to_snakecase string_to_convert s1 re.sub ' . [A-Z][a-z]+ ' '\\1_\\2' string_to_convert return re.sub ' [a-z0-9] [A-Z] ' '\\1_\\2' s1 .lower
def unpack_unicode data pos lenlen 2 nchars unpack '<' + 'BH'[ lenlen - 1 ] data[pos pos + lenlen ] [0]if not nchars return UNICODE_LITERAL '' pos + lenlenoptions BYTES_ORD data[pos] pos + 1if options & 8 pos + 2if options & 4 pos + 4if options & 1 rawstrg data[pos pos + 2 * nchars ]strg unicode rawstrg 'utf_16_le' else strg unicode data[pos pos + nchars ] 'latin_1' return strg
def get_interface_type interface if interface.upper .startswith 'ET' return 'ethernet'elif interface.upper .startswith 'VL' return 'svi'elif interface.upper .startswith 'LO' return 'loopback'elif interface.upper .startswith 'MG' return 'management'elif interface.upper .startswith 'MA' return 'management'elif interface.upper .startswith 'PO' return 'portchannel'else return 'unknown'
def qnwunif n a b n a b list map np.asarray [n a b] nodes weights qnwlege n a b weights weights / np.prod b - a return nodes weights
def sigmoid_cutoff x cutoff y tf.sigmoid x if cutoff < 1.01 return yd cutoff - 1.0 / 2.0 return tf.minimum 1.0 tf.maximum 0.0 cutoff * y - d
def bufferData target data usage if isinstance data int size datadata ctypes.c_voidp 0 else if not data.flags['C_CONTIGUOUS'] or not data.flags['ALIGNED'] data data.copy 'C' data_ datasize data_.nbytesdata data_.ctypes.data if isinstance data int size datadata Noneelse size data.nbytesGL.glBufferData target size data usage
def DisMaxParser fieldboosts schema tiebreak 0.0 **kwargs from whoosh.qparser import pluginsmfp plugins.MultifieldPlugin list fieldboosts.keys fieldboosts fieldboosts group syntax.DisMaxGroup pins [plugins.WhitespacePlugin plugins.PlusMinusPlugin plugins.PhrasePlugin mfp]return QueryParser None schema plugins pins **kwargs
@step 'Iwillcancelallalerts' def i_cancel_all_alerts step world.browser.execute_script 'window.confirm function {returnfalse;};window.alert function {return;}'
def addSubmenus craftTypeName menu pluginFileName pluginPath profileRadioVar submenu settings.Tkinter.Menu menu tearoff 0 menu.add_cascade label pluginFileName.capitalize menu submenu settings.ToolDialog .addPluginToMenu submenu pluginPath submenu.add_separator pluginModule skeinforge_profile.getCraftTypePluginModule pluginFileName profilePluginSettings settings.getReadRepository pluginModule.getNewRepository isSelected craftTypeName pluginFileName for profileName in profilePluginSettings.profileList.value value isSelected and profileName profilePluginSettings.profileListbox.value ProfileMenuRadio pluginFileName submenu profileName profileRadioVar value
def disable_enhanced_monitoring stream_name metrics region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r _execute_with_retries conn 'disable_enhanced_monitoring' StreamName stream_name ShardLevelMetrics metrics if 'error' not in r r['result'] Truereturn r
def _fastq_generic2 in_handle out_handle mapping truncate_char truncate_msg from Bio.SeqIO.QualityIO import FastqGeneralIteratorcount 0null chr 0 for title seq old_qual in FastqGeneralIterator in_handle count + 1qual old_qual.translate mapping if null in qual raise ValueError 'Invalidcharacterinqualitystring' if truncate_char in qual qual qual.replace truncate_char chr 126 import warningswarnings.warn truncate_msg BiopythonWarning out_handle.write '@%s\n%s\n+\n%s\n' % title seq qual return count
@utils.synchronized 'safe_set_attr' def set_safe_attr instance attr val if not instance or not attr return Falseold_val getattr instance attr None if val is None and old_val is None return Falseelif val old_val return Falseelse setattr instance attr val return True
def makeTerm node title 'Node' term 'xterm' display None cmd 'bash' title '"%s %s"' % title node.name if not node.inNamespace title + ' root 'cmds {'xterm' ['xterm' '-title' title '-display'] 'gterm' ['gnome-terminal' '--title' title '--display']}if term not in cmds error 'invalidterminaltype %s' % term return display tunnel tunnelX11 node display if display is None return []term node.popen cmds[term] + [display '-e' 'envTERM ansi%s' % cmd ] return [tunnel term] if tunnel else [term]
def get_event node sock_dir None transport 'zeromq' opts None listen True io_loop None keep_loop False raise_errors False sock_dir sock_dir or opts['sock_dir'] if transport in 'zeromq' 'tcp' if node 'master' return MasterEvent sock_dir opts listen listen io_loop io_loop keep_loop keep_loop raise_errors raise_errors return SaltEvent node sock_dir opts listen listen io_loop io_loop keep_loop keep_loop raise_errors raise_errors elif transport 'raet' import salt.utils.raeteventreturn salt.utils.raetevent.RAETEvent node sock_dir sock_dir listen listen opts opts
@commands u't' u'time' @example u'.tAmerica/New_York' def f_time bot trigger if trigger.group 2 zone get_timezone bot.db bot.config trigger.group 2 .strip None None if not zone bot.say u'Couldnotfindtimezone%s.' % trigger.group 2 .strip returnelse zone get_timezone bot.db bot.config None trigger.nick trigger.sender time format_time bot.db bot.config zone trigger.nick trigger.sender bot.say time
def get_storage_path global _storage_pathif _storage_path is None storage_path config.get 'ckan.storage_path' ofs_impl config.get 'ofs.impl' ofs_storage_dir config.get 'ofs.storage_dir' if storage_path _storage_path storage_pathelif ofs_impl 'pairtree' and ofs_storage_dir log.warn 'Pleaseuseconfigoptionckan.storage_pathinsteadof\nofs.storage_dir' _storage_path ofs_storage_dirreturn _storage_pathelif ofs_impl log.critical 'Weonlysupportlocalfilestorageformversion2.2\nofckanpleasespecifyckan.storage_pathinyour\nconfigforyouruploads' _storage_path Falseelse log.critical 'Pleasespecifyackan.storage_pathinyourconfig\nforyouruploads' _storage_path Falsereturn _storage_path
def upload_package conn module remotepath None if remotepath is None remotepath conn.modules['distutils.sysconfig'].get_python_lib localpath os.path.dirname module.__file__ upload_dir conn localpath remotepath ['.py' '.pyd' '.dll' '.so' '.zip']
def get_next_exploration_ids_to_complete_by_user user_id collection_id completed_exploration_ids get_completed_exploration_ids user_id collection_id collection get_collection_by_id collection_id if completed_exploration_ids return collection.get_next_exploration_ids completed_exploration_ids else return collection.init_exploration_ids
def set_salt_view options _get_options ret None new_doc {}new_doc['views'] get_valid_salt_views new_doc['language'] 'javascript'_response _request 'PUT' options['url'] + options['db'] + '/_design/salt' 'application/json' json.dumps new_doc if 'error' in _response log.warning 'Unabletosetthesaltdesigndocument {0}'.format _response['error'] return Falsereturn True
def format msg *attr if DISABLE_COLOR_SUPPORT return msgif RESET in msg return ''.join [format comp *attr for comp in msg.split RESET ] encodings []for text_attr in attr text_attr encoding stem.util.str_tools._to_camel_case text_attr None encoding FG_ENCODING.get text_attr encoding encoding BG_ENCODING.get text_attr encoding encoding ATTR_ENCODING.get text_attr encoding if encoding encodings.append encoding if encodings prefix suffix CSI % ';'.join encodings RESET if Attr.READLINE_ESCAPE in attr prefix '\x01%s\x02' % prefix suffix '\x01%s\x02' % suffix return prefix + msg + suffix else return msg
def writeFileText fileName fileText writeMode 'w+' try file open fileName writeMode file.write fileText file.close except IOError print 'Thefile' + fileName + 'cannotbewrittento.'
@_docstring 'releases' browse True def browse_releases artist None track_artist None label None recording None release_group None release_status [] release_type [] includes [] limit None offset None valid_includes VALID_BROWSE_INCLUDES['releases']params {'artist' artist 'track_artist' track_artist 'label' label 'recording' recording 'release-group' release_group}return _browse_impl 'release' includes valid_includes limit offset params release_status release_type
def sin mat target None if not target target materr_code _cudamat.apply_sin mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def detach_lb kwargs None call None if call ! 'function' raise SaltCloudSystemExit 'Thedetach_lbfunctionmustbecalledwith-for--function.' if not kwargs or 'name' not in kwargs log.error 'Aload-balancernamemustbespecified.' return Falseif 'member' not in kwargs log.error 'Anodenamenamemustbespecified.' return Falseconn get_conn lb_conn get_lb_conn conn lb lb_conn.get_balancer kwargs['name'] member_list lb_conn.balancer_list_members lb remove_member Nonefor member in member_list if member.id kwargs['member'] remove_member memberbreakif not remove_member log.error 'Thespecifiedmember{0}wasnotamemberofLB{1}.'.format kwargs['member'] kwargs['name'] return False__utils__['cloud.fire_event'] 'event' 'detachload_balancer' 'salt/cloud/loadbalancer/detaching' args kwargs sock_dir __opts__['sock_dir'] transport __opts__['transport'] result lb_conn.balancer_detach_member lb remove_member __utils__['cloud.fire_event'] 'event' 'detachedload_balancer' 'salt/cloud/loadbalancer/detached' args kwargs sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def rands nchars return ''.join np.random.choice RANDS_CHARS nchars
def resetwarnings util.warn util.langhelpers.warn testing_warnwarnings.filterwarnings 'ignore' category sa_exc.SAPendingDeprecationWarning warnings.filterwarnings 'error' category sa_exc.SADeprecationWarning warnings.filterwarnings 'error' category sa_exc.SAWarning
def each_cy_in_setup top_dir for dir_path f in each_setup_in_pkg top_dir text f.read match RE_CYTHON.findall text if match for cy_file in match if '.' in cy_file parts cy_file.split '.' cy_file parts[ -1 ]path os.path.join dir_path *parts[ -1 ] else path dir_pathfull_path os.path.join path cy_file yield full_path
def process_file_data cls name func file_attr cls_path os.path.abspath inspect.getsourcefile cls data_file_path os.path.join os.path.dirname cls_path file_attr def _raise_ve *args raise ValueError '%sdoesnotexist' % file_attr if os.path.exists data_file_path is False test_name mk_test_name name 'error' add_test cls test_name _raise_ve None else data json.loads open data_file_path .read for i elem in enumerate data if isinstance data dict key value elem data[elem] test_name mk_test_name name key i elif isinstance data list value elemtest_name mk_test_name name value i if isinstance value dict add_test cls test_name func **value else add_test cls test_name func value
def may_inject context view context.get 'view' return bool view and bool getattr view 'xtheme_injection' True
def resetCounter technique kb.counters[technique] 0
def xframe_options_sameorigin view_func def wrapped_view *args **kwargs resp view_func *args **kwargs if resp.get 'X-Frame-Options' None is None resp['X-Frame-Options'] 'SAMEORIGIN'return respreturn wraps view_func assigned available_attrs view_func wrapped_view
def num_ok_for_type number proposed_type if proposed_type 'long' return Trueif proposed_type 'float' return Trueif number > eval proposed_type + '.MinValue' and number < eval proposed_type + '.MaxValue' return Trueif eval proposed_type + '.MinValue' < number and eval proposed_type + '.MaxValue' > number return Truereturn False
def fancy_logging from log_buffer import FixedBufferHandlerBUFFER_SIZE 1500 * 200 buffer_handler FixedBufferHandler BUFFER_SIZE _formatter formatter.Formatter LOG_FORMAT DATE_FORMAT buffer_handler.setLevel logging.DEBUG buffer_handler.setFormatter _formatter root_logger logging.getLogger root_logger.addHandler buffer_handler
def expm_frechet_kronform A method None check_finite True if check_finite A np.asarray_chkfinite A else A np.asarray A if len A.shape ! 2 or A.shape[0] ! A.shape[1] raise ValueError 'expectedasquarematrix' n A.shape[0]ident np.identity n cols []for i in range n for j in range n E np.outer ident[i] ident[j] F expm_frechet A E method method compute_expm False check_finite False cols.append vec F return np.vstack cols .T
def text charp if not charp return ''return native ffi.string charp
@lru_cache def get_git_hash return _shell_command ['/usr/bin/git' 'rev-parse' '--verify' '--short' 'HEAD'] .strip
def do_with parser token bits list token.split_contents if len bits ! 4 or bits[2] ! 'as' raise TemplateSyntaxError "%rexpectedformatis'valueasname'" % bits[0] var parser.compile_filter bits[1] name bits[3]nodelist parser.parse 'endwith' parser.delete_first_token return WithNode var name nodelist
def condition_input args kwargs ret []for arg in args if six.PY3 and isinstance arg six.integer_types and salt.utils.jid.is_jid str arg or six.PY2 and isinstance arg long ret.append str arg else ret.append arg if isinstance kwargs dict and kwargs kw_ {'__kwarg__' True}for key val in six.iteritems kwargs kw_[key] valreturn ret + [kw_] return ret
def dhcp_configuration_from_querystring querystring option u'DhcpConfiguration' key_needle re.compile u'{0}.[0-9]+.Key'.format option re.UNICODE response_values {}for key value in querystring.items if key_needle.match key values []key_index key.split u'.' [1]value_index 1while True value_key u'{0}.{1}.Value.{2}'.format option key_index value_index if value_key in querystring values.extend querystring[value_key] else breakvalue_index + 1response_values[value[0]] valuesreturn response_values
def generate_signed_message method headers_dict body_dict access_key secret_key message signing_format_message method headers_dict body_dict hashed hmac.new secret_key.encode 'utf-8' message sha256 signature binascii.b2a_base64 hashed.digest .rstrip '\n' authorization_header 'SSI{} {}'.format access_key signature message + '\n'return message signature authorization_header
def NOPTRACE v context.defaults['noptrace'] asbool v
def gridsize_expand ndim if ndim 1 fname 'ptx.gridsize.1d'restype types.int32elif ndim 2 fname 'ptx.gridsize.2d'restype types.UniTuple types.int32 2 elif ndim 3 fname 'ptx.gridsize.3d'restype types.UniTuple types.int32 3 else raise ValueError 'argumentcanonlybe1 2or3' return ir.Intrinsic fname typing.signature restype types.intp args [ndim]
def get_task_output_description task_output output_description 'n/a'if isinstance task_output RemoteTarget output_description '[SSH]{0} {1}'.format task_output._fs.remote_context.host task_output.path elif isinstance task_output S3Target output_description '[S3]{0}'.format task_output.path elif isinstance task_output FileSystemTarget output_description '[FileSystem]{0}'.format task_output.path elif isinstance task_output PostgresTarget output_description '[DB]{0} {1}'.format task_output.host task_output.table else output_description 'tobedetermined'return output_description
def _is_bad_fname fname if fname.endswith ' whitened ' fname fname[ -11 ]if not fname.endswith tuple VALID_EXTENSIONS + ['bem' 'custom'] return 'red'else return ''
def create_verifier_for_ecc signature hash_method public_key return public_key.verifier signature ec.ECDSA hash_method
def item_category table s3db.supply_item_categorys3.filter table.can_be_asset True field table.can_be_assetfield.readable field.writable Falsefield.default Truereturn s3_rest_controller 'supply' 'item_category'
def capa_render_template template context return get_template template .render_unicode **context
def assoc_recurrence_memo base_seq cache []def decorator f @wraps f def g n m L len cache if n < L return cache[n][m]for i in range L n + 1 F_i0 base_seq i F_i_cache [F_i0]cache.append F_i_cache for j in range 1 i + 1 F_ij f i j cache F_i_cache.append F_ij return cache[n][m]return greturn decorator
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
@decorators.api_view ['POST'] @decorators.permission_classes permissions.IsAdminUser @decorators.renderer_classes JSONRenderer def index_search request data request.DATA['data']version_pk data['version_pk']commit data.get 'commit' version Version.objects.get pk version_pk project_scale 1page_scale 1utils.index_search_request version version page_list data['page_list'] commit commit project_scale project_scale page_scale page_scale return Response {'indexed' True}
def removeListFromDictionary dictionary keys for key in keys removeElementFromDictionary dictionary key
def identity_key *args **kwargs if args if len args 1 class_ args[0]try row kwargs.pop 'row' except KeyError ident kwargs.pop 'ident' elif len args 2 class_ ident argselif len args 3 class_ ident argselse raise sa_exc.ArgumentError 'expecteduptothreepositionalarguments got%s' % len args if kwargs raise sa_exc.ArgumentError 'unknownkeywordarguments %s' % ' '.join kwargs mapper class_mapper class_ if 'ident' in locals return mapper.identity_key_from_primary_key util.to_list ident return mapper.identity_key_from_row row instance kwargs.pop 'instance' if kwargs raise sa_exc.ArgumentError 'unknownkeywordarguments %s' % ' '.join kwargs.keys mapper object_mapper instance return mapper.identity_key_from_instance instance
def create_scenario actions logs None keys [str i for i in range len actions ]key_provider create_mock_key_provider keys digest_provider MockDigestProvider actions logs digest_validator Mock def validate bucket key public_key digest_data digest_str if '_invalid' in digest_data raise DigestError 'invaliderror' digest_validator.validate validatereturn key_provider digest_provider digest_validator
def unquote_to_bytes string if not string string.splitreturn ''if isinstance string str string string.encode 'utf-8' bits string.split '%' if len bits 1 return stringres [bits[0]]append res.appendglobal _hextobyteif _hextobyte is None _hextobyte { a + b .encode bytes [int a + b 16 ] for a in _hexdig for b in _hexdig}for item in bits[1 ] try append _hextobyte[item[ 2]] append item[2 ] except KeyError append '%' append item return ''.join res
def _dmp_simplify_gcd f g u K df dmp_degree f u dg dmp_degree g u if df > 0 and dg > 0 return Noneif not df or dg F dmp_LC f K G dmp_LC g K elif not df F dmp_LC f K G dmp_content g u K else F dmp_content f u K G dmp_LC g K v u - 1 h dmp_gcd F G v K cff [dmp_quo cf h v K for cf in f]cfg [dmp_quo cg h v K for cg in g]return [h] cff cfg
def pformat obj verbose False try from pretty import prettyreturn pretty obj verbose verbose except ImportError from pprint import pformatreturn pformat obj
def gradient_percentile image selem out None mask None shift_x False shift_y False p0 0 p1 1 return _apply percentile_cy._gradient image selem out out mask mask shift_x shift_x shift_y shift_y p0 p0 p1 p1
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def test_no_data_interpolation Chart chart Chart interpolate 'cubic' q chart.render_pyquery assert q '.text-overlaytext' .text 'Nodata'
def reset_template_info_cache _template_info_cache.clear
def open_project path return open_project_with_extensions settings.SUPPORTED_EXTENSIONS
def ProcessMotion vf_time last_pos Nonefor event in pygame.event.get if event.type pygame.QUIT or event.type pygame.KEYDOWN return sys.exit 0 if vf_time.IsActive if event.type pygame.MOUSEMOTION if event.buttons[0] last_pos event.poselif event.type pygame.MOUSEBUTTONUP if event.button 1 vf_time.Stop elif event.type pygame.MOUSEBUTTONDOWN if event.button 1 pos PixelsToDimensions event.pos x y posif x > iphone_dims[0] - target_box_width - target_box_padding and x < iphone_dims[0] - target_box_padding and y > target_box_padding and y < iphone_dims[1] - target_box_padding vf_time.Start pos if last_pos vf_time.AdjustTime PixelsToDimensions last_pos
def _get_cibpath cibpath os.path.join __opts__['cachedir'] 'pcs' __env__ log.trace 'cibpath {0}'.format cibpath return cibpath
def make_cache_key *args **kwargs path request.pathargs str hash frozenset request.args.items return path + args .encode 'ascii' 'ignore'
def s_metric G normalized True if normalized raise nx.NetworkXError 'Normalizationnotimplemented' return float sum [ G.degree u * G.degree v for u v in G.edges ]
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def aws_provisioner access_key secret_access_token keyname region zone security_groups instance_type 'm3.large' session_token None conn connect_to_region region aws_access_key_id access_key aws_secret_access_key secret_access_token security_token session_token if conn is None raise ValueError 'Invalidregion {}'.format region return AWSProvisioner _connection conn _keyname keyname _security_groups security_groups _zone zone _default_size instance_type
def which program def is_exe fpath return os.path.isfile fpath and os.access fpath os.X_OK fpath fname os.path.split program if fpath if is_exe program return programelse for path in os.environ['PATH'].split os.pathsep exe_file os.path.join path program if is_exe exe_file return exe_file
def calc_syndrome codeword n sym 0for i in range 1 n if codeword[i] sym ^ iextra_parity calc_parity_vector codeword if extra_parity codeword[0] if sym 0 return 0 sym else return 2 sym else if sym > n passelse codeword[sym] ^ 1return 1 sym
def decipher_bifid5 msg key msg key _ _prep msg.upper key.upper None bifid5 key padded_key key bifid5 return decipher_bifid msg '' key
def access_message user_profile message_id try message Message.objects.select_related .get id message_id except Message.DoesNotExist raise JsonableError _ 'Invalidmessage s ' try user_message UserMessage.objects.select_related .get user_profile user_profile message message except UserMessage.DoesNotExist user_message Noneif user_message is None if message.recipient.type ! Recipient.STREAM raise JsonableError _ 'Invalidmessage s ' stream Stream.objects.get id message.recipient.type_id if not stream.is_public raise JsonableError _ 'Invalidmessage s ' if stream.realm ! user_profile.realm raise JsonableError _ 'Invalidmessage s ' return message user_message
def pool_health_monitor_create request **kwargs body {'health_monitor' {'type' kwargs['type'] 'delay' kwargs['delay'] 'timeout' kwargs['timeout'] 'max_retries' kwargs['max_retries'] 'http_method' kwargs['http_method'] 'url_path' kwargs['url_path'] 'expected_codes' kwargs['expected_codes'] 'admin_state_up' kwargs['admin_state_up']}}mon quantumclient request .create_health_monitor body .get 'health_monitor' body {'health_monitor' {'id' mon['id']}}quantumclient request .associate_health_monitor kwargs['pool_id'] body return PoolMonitor mon
def _default_content_type_rewriter state if not 'Content-Type' in state.headers state.headers['Content-Type'] 'text/html'
def document_action section resource_name event_emitter action_model service_model include_signature True operation_model service_model.operation_model action_model.request.operation ignore_params get_resource_ignore_params action_model.request.params example_return_value 'response'if action_model.resource example_return_value xform_name action_model.resource.type example_resource_name xform_name resource_name if service_model.service_name resource_name example_resource_name resource_nameexample_prefix '%s %s.%s' % example_return_value example_resource_name action_model.name document_model_driven_resource_method section section method_name action_model.name operation_model operation_model event_emitter event_emitter method_description operation_model.documentation example_prefix example_prefix exclude_input ignore_params resource_action_model action_model include_signature include_signature
def test_smote_fit_single_class smote SMOTEENN random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning smote.fit X y_single_class
def addXIntersections loop xIntersections y for pointIndex in xrange len loop pointFirst loop[pointIndex]pointSecond loop[ pointIndex + 1 % len loop ]xIntersection getXIntersectionIfExists pointFirst pointSecond y if xIntersection ! None xIntersections.append xIntersection
def pci_device_get_all_by_node context node_id return IMPL.pci_device_get_all_by_node context node_id
def set_level request level if not hasattr request '_messages' return Falserequest._messages.level levelreturn True
def _import module reload 'False' from sympy.external import import_moduletry namespace namespace_default translations import_commands MODULES[module]except KeyError raise NameError "'%s'modulecan'tbeusedforlambdification" % module if namespace ! namespace_default if reload namespace.clear namespace.update namespace_default else returnfor import_command in import_commands if import_command.startswith 'import_module' module eval import_command if module is not None namespace.update module.__dict__ continueelse try exec_ import_command {} namespace continueexcept ImportError passraise ImportError "can'timport'%s'with'%s'command" % module import_command for sympyname translation in translations.items namespace[sympyname] namespace[translation]if 'Abs' not in namespace namespace['Abs'] abs
def get_trace_db_by_live_action liveaction trace_db Nonecreated Falsetrace_context liveaction.context.get TRACE_CONTEXT None if trace_context trace_context _get_valid_trace_context trace_context trace_db get_trace trace_context trace_context ignore_trace_tag True if not trace_db trace_db TraceDB trace_tag trace_context.trace_tag created Truereturn created trace_db parent_context executions.get_parent_context liveaction_db liveaction if not trace_context and parent_context parent_execution_id parent_context.get 'execution_id' None if parent_execution_id trace_db get_trace_db_by_action_execution action_execution_id parent_execution_id if not trace_db raise StackStormDBObjectNotFoundError 'Notracefoundforexecution%s' % parent_execution_id return created trace_db execution ActionExecution.get liveaction__id str liveaction.id if execution trace_db get_trace_db_by_action_execution action_execution execution if not trace_db trace_db TraceDB trace_tag 'execution-%s' % str liveaction.id created Truereturn created trace_db
def libvlc_media_player_get_nsobject p_mi f _Cfunctions.get 'libvlc_media_player_get_nsobject' None or _Cfunction 'libvlc_media_player_get_nsobject' 1 None ctypes.c_void_p MediaPlayer return f p_mi
def step_1b w if w.endswith 'y' and w.endswith 'edly' 'ingly' w w[ -2 ]if w.endswith 'ed' 'ing' if w.endswith 'ied' return len w 4 and w[ -1 ] or w[ -2 ] if w.endswith 'eed' return R1 w .endswith 'eed' and w[ -1 ] or w for suffix in 'ed' 'ing' if w.endswith suffix and has_vowel w[ - len suffix ] w w[ - len suffix ]if w.endswith 'at' 'bl' 'iz' return w + 'e' if is_double_consonant w[ -2 ] return w[ -1 ]if is_short w return w + 'e' return w
def send_messages messages if not messages returnconn mail.get_connection fail_silently True conn.open for msg in messages conn.send_messages [msg]
def splitpasswd user global _passwdprogif _passwdprog is None import re_passwdprog re.compile '^ [^ ]* .* $' re.S match _passwdprog.match user if match return match.group 1 2 return user None
def linear_lm resid exog func None from scipy import statsif func is None func lambda x np.power x 2 exog_aux np.column_stack exog func exog[ 1 ] nobs k_vars exog.shapels OLS resid exog_aux .fit ftest ls.f_test np.eye k_vars - 1 k_vars * 2 - 1 k_vars lm nobs * ls.rsquared lm_pval stats.chi2.sf lm k_vars - 1 return lm lm_pval ftest
def hash_digest text text_encoded text.encode 'utf8' hash_result hashlib.md5 text_encoded return hash_result.hexdigest
def as_template value if isinstance value Template return valueelif isinstance value collections.Mapping return MappingTemplate value elif value is int return Integer elif isinstance value int return Integer value elif isinstance value type and issubclass value BASESTRING return String elif isinstance value BASESTRING return String value elif value is float return Number elif value is None return Template elif value is dict return TypeTemplate collections.Mapping elif value is list return TypeTemplate collections.Sequence elif isinstance value type return TypeTemplate value else raise ValueError u'cannotconverttotemplate {0!r}'.format value
def convertToPix vertices pos units win unit2pixFunc _unit2PixMappings.get units if unit2pixFunc return unit2pixFunc vertices pos win else msg 'Theunittype[{0}]isnotregisteredwithPsychoPy'raise ValueError msg.format units
def path_getrootdir path drive _ os.path.splitdrive path if drive return drive + os.path.sep return os.path.sep
def replication func func.replication Truereturn func
def assert_http_server test host port path '' expected_response 'hi' d query_http_server host port path d.addCallback test.assertEqual expected_response return d
def pollard_pm1 n B 10 a 2 retries 0 seed 1234 n int n if n < 4 or B < 3 raise ValueError 'pollard_pm1shouldreceiven>3andB>2' prng random.Random seed + B for i in range retries + 1 aM afor p in sieve.primerange 2 B + 1 e int math.log B p aM pow aM pow p e n g igcd aM - 1 n if 1 < g < n return int g a prng.randint 2 n - 2
def AbortAdminOperation operation_key _status DatastoreAdminOperation.STATUS_ABORTED _status_info '' operation DatastoreAdminOperation.get operation_key operation.status _statusoperation.status_info _status_infooperation.put config _CreateDatastoreConfig for job in operation.active_job_ids logging.info 'AbortingJob%s' job model.MapreduceControl.abort job config _CreateDatastoreConfig
def import_object name if isinstance name unicode_type and str is not unicode_type name name.encode 'utf-8' if name.count '.' 0 return __import__ name None None parts name.split '.' obj __import__ '.'.join parts[ -1 ] None None [parts[ -1 ]] 0 try return getattr obj parts[ -1 ] except AttributeError raise ImportError 'Nomodulenamed%s' % parts[ -1 ]
def cout *args cprint 'stdout' *args
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def add_intercept panel name 'intercept' panel panel.copy panel[name] 1.0return panel.consolidate
def rax_slugify value return 'rax_%s' % re.sub '[^\\w-]' '_' value .lower .lstrip '_'
def nsecs_to_timeval ns ns int ns return ns / 10 ** 9 ns % 10 ** 9 / 1000
def files_in_dir directory file_patterns [] files []for file_pattern in file_patterns files.extend glob.glob os.path.join directory file_pattern return files
def test_image_less_than_mask image np.ones 5 5 mask np.ones 5 5 * 2 assert_close reconstruction image mask 1
def random_name size 6 chars string.ascii_uppercase + string.digits return 'test-' + ''.join random.choice chars for x in range size
def time2isoz t None if t is None t time.time year mon mday hour min sec time.gmtime t [ 6]return '%04d-%02d-%02d%02d %02d %02dZ' % year mon mday hour min sec
def _redefines_import node current nodewhile current and not isinstance current.parent astroid.ExceptHandler current current.parentif not current or not is_import_error current.parent return Falsetry_block current.parent.parentfor import_node in try_block.nodes_of_class astroid.From astroid.Import for name alias in import_node.names if alias if alias node.name return Trueelif name node.name return Truereturn False
def russellrao u v u _validate_vector u v _validate_vector v if u.dtype bool ntt u & v .sum else ntt u * v .sum return float len u - ntt / float len u
def CDLSTALLEDPATTERN barDs count return call_talib_with_ohlc barDs count talib.CDLSTALLEDPATTERN
def is_classic_task tup name func tuptry is_classic callable func and func not in _internals and not name.startswith '_' and not inspect.isclass func and issubclass func Exception except ValueError TypeError is_classic Falsereturn is_classic
@register.inclusion_tag 'schedule/_daily_table.html' takes_context True def daily_table context day width width_slot height start 8 end 20 increment 30 user context['request'].usercontext['addable'] CHECK_PERMISSION_FUNC None user width_occ width - width_slot day_part day.get_time_slot day.start + datetime.timedelta hours start day.start + datetime.timedelta hours end occurrences day_part.get_occurrences occurrences _cook_occurrences day_part occurrences width_occ height slots _cook_slots day_part increment width height context['occurrences'] occurrencescontext['slots'] slotscontext['width'] widthcontext['width_slot'] width_slotcontext['width_occ'] width_occcontext['height'] heightreturn context
def refresh_pillar try ret __salt__['event.fire'] {} 'pillar_refresh' except KeyError log.error 'Eventmodulenotavailable.Modulerefreshfailed.' ret Falsereturn ret
def psea2HEC pseq seq []for ss in pseq if ss 'a' n 'H'elif ss 'b' n 'E'elif ss 'c' n 'C'seq.append n return seq
def get_contrast_change_value label return _get_array_element 'contrastchange' label 0.8 1.3
def aaq_languages request return {'AAQ_LANGUAGES' QuestionLocale.objects.locales_list }
def check_geoserver_is_up url '%sweb/' % ogc_server_settings.LOCATION resp content http_client.request url 'GET' msg 'CannotconnecttotheGeoServerat%s\nPleasemakesureyouhavestartedit.' % ogc_server_settings.LOCATION assert resp['status'] '200' msg
def _intOrDefault value default None if value try return int value except TypeError ValueError passreturn default
def wait_for_assertion assertion_expression timeout 5 start_time time.time while time.time - start_time < timeout try return assertion_expression except AssertionError time.sleep 0.1 return assertion_expression
def _assert_valid_categorical_missing_value value label_types LabelArray.SUPPORTED_SCALAR_TYPESif not isinstance value label_types raise TypeError 'Categoricaltermsmusthavemissingvaluesoftype{types}.'.format types 'or'.join [t.__name__ for t in label_types]
def retry_assertion timeout_sec retry_interval_sec 0.1 def retry_assertion_decorator func 'Decorator'@functools.wraps func def retry_assertion_wrap *args **kwargs 'Thewrapper'num_attempts 0start_time time.time while True num_attempts + 1try result func *args **kwargs except AssertionError now time.time if now < start_time start_time nowif now - start_time > timeout_sec logging.exception "Exceededretrytimeoutof%ssecin%sattemptswithfunc%r.Caller'sstack \n%s" timeout_sec num_attempts func ''.join traceback.format_stack raiselogging.debug 'Attempt%sfailed;retrying%rin%ssec.' num_attempts func retry_interval_sec time.sleep retry_interval_sec else logging.debug '%rsucceededatattempt%s' func num_attempts return resultreturn retry_assertion_wrapreturn retry_assertion_decorator
def _eventlet_stop client server conn try try client.wait finally conn.close except greenlet.GreenletExit passexcept Exception greenthread.kill server *sys.exc_info
def spawn_raw function *args **kwargs if not callable function raise TypeError 'functionmustbecallable' hub get_hub if kwargs function _functools_partial function *args **kwargs g greenlet function hub hub.loop.run_callback g.switch else g greenlet function hub hub.loop.run_callback g.switch *args return g
def _ text return text
def Application name uid None gid None ret components.Componentized for comp in MultiService sob.Persistent ret name Process uid gid ret.addComponent comp ignoreClass 1 IService ret .setName name return ret
def get_enabled jail None ret []service _cmd jail prf _get_jail_path jail if jail else '' for svc in __salt__['cmd.run'] '{0}-e'.format service .splitlines ret.append os.path.basename svc for svc in get_all jail if svc in ret continueif not os.path.exists '{0}/etc/rc.conf.d/{1}'.format prf svc continueif enabled svc jail jail ret.append svc return sorted ret
@salt.utils.decorators.which_bin 'unrar' 'rar' def unrar rarfile dest excludes None template None runas None trim_output False if isinstance excludes string_types excludes [entry.strip for entry in excludes.split ' ' ]cmd [salt.utils.which_bin 'unrar' 'rar' 'x' '-idp' '{0}'.format rarfile ]if excludes is not None for exclude in excludes cmd.extend ['-x' '{0}'.format exclude ] cmd.append '{0}'.format dest files __salt__['cmd.run'] cmd template template runas runas python_shell False .splitlines return _trim_files files trim_output
def _check_entry first nent if first > nent raise IOError 'Couldnotreaddata perhapsthisisacorruptfile'
def merge dict1 dict2 for key val2 in dict2.items if val2 is not None val1 dict1.get key if isinstance val2 dict if val1 is None val1 {}if isinstance val1 Alias val1 val1 val2 elif isinstance val1 tuple alias others val1others others.copy merge others val2 val1 alias others else val1 val1.copy merge val1 val2 else val1 val2dict1[key] val1
def load_theme_plugins if not pkg_resources return []theme_paths []for plugin in pkg_resources.iter_entry_points 'sphinx_themes' func_or_path plugin.load try path func_or_path except Exception path func_or_pathif isinstance path string_types theme_paths.append path else raise ThemeError 'Plugin%rdoesnotresponsecorrectly.' % plugin.module_name return theme_paths
def dup_l1_norm f K if not f return K.zeroelse return sum dup_abs f K
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def _is_leading_zero_possible country_code region_code region_code_for_country_code country_code metadata PhoneMetadata.metadata_for_region_or_calling_code country_code region_code if metadata is None return Falsereturn metadata.leading_zero_possible
def _offset a if np.mod a 2 0 return -0.5 else return 0.0
def getOverlapRatio loop pointTable numberOfOverlaps 0for point in loop if point in pointTable numberOfOverlaps + 1return float numberOfOverlaps / float len loop
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def create_xmpp_user password uaserver username_regex re.compile '\\A .* @' username username_regex.match hermes_constants.USER_EMAIL .groups [0]xmpp_user '{0}@{1}'.format username appscale_info.get_login_ip xmpp_pass appscale_utils.encrypt_password xmpp_user password does_user_exist uaserver.does_user_exist xmpp_user appscale_info.get_secret if does_user_exist 'true' logging.debug 'XMPPUser{0}alreadyexists sonotcreatingitagain.'.format xmpp_user return Trueelif uaserver.commit_new_user xmpp_user xmpp_pass hermes_constants.ACCOUNT_TYPE appscale_info.get_secret 'true' logging.info 'XMPPusernameis{0}'.format xmpp_user return Trueelse logging.error 'ErrorwhilecreatinganXMPPuser.' return False
def test_multi_render Chart datas chart Chart chart make_data chart datas svg chart.render for i in range 2 assert svg chart.render
def all_matches names pattern matches {}for item name in names.items m re.match pattern name re.IGNORECASE if m and m.groupdict matches[item] m.groupdict else return Nonereturn matches
def libvlc_media_player_event_manager p_mi f _Cfunctions.get 'libvlc_media_player_event_manager' None or _Cfunction 'libvlc_media_player_event_manager' 1 class_result EventManager ctypes.c_void_p MediaPlayer return f p_mi
def get_temperature return _sensehat.get_temperature
def before_categorize f f.before Truereturn f
def close_swift_conn src try src.nuke_from_orbit except Exception pass
def getLineWithValueString character line splitLine valueString roundedValueString character + valueString indexOfValue getIndexOfStartingWithSecond character splitLine if indexOfValue -1 return line + '' + roundedValueString word splitLine[indexOfValue]return line.replace word roundedValueString
def _assert_poles_close P1 P2 rtol 1e-08 atol 1e-08 P2 P2.copy for p1 in P1 found Falsefor p2_idx in range P2.shape[0] if np.allclose [np.real p1 np.imag p1 ] [np.real P2[p2_idx] np.imag P2[p2_idx] ] rtol atol found Truenp.delete P2 p2_idx breakif not found raise ValueError "Can'tfindpole" + str p1 + 'in' + str P2
def check_message_extractors dist name value assert name 'message_extractors' if not isinstance value dict raise DistutilsSetupError 'thevalueofthe"message_extractors"parametermustbeadictionary'
def staff_member_required view_func @wraps view_func def _checklogin request *args **kwargs if request.user.is_active and request.user.is_staff return view_func request *args **kwargs assert hasattr request 'session' "TheDjangoadminrequiressessionmiddlewaretobeinstalled.EdityourMIDDLEWARE_CLASSESsettingtoinsert'django.contrib.sessions.middleware.SessionMiddleware'."defaults {'template_name' 'admin/login.html' 'authentication_form' AdminAuthenticationForm 'extra_context' {'title' _ 'Login' 'app_path' request.get_full_path REDIRECT_FIELD_NAME request.get_full_path }}return login request **defaults return _checklogin
def start_tomcat run_as_root '/etc/init.d/tomcatstart'
def push cwd remote None ref None opts '' user None password None identity None ignore_retcode False saltenv 'base' **kwargs kwargs salt.utils.clean_kwargs **kwargs if kwargs salt.utils.invalid_kwargs kwargs cwd _expand_path cwd user command ['git' 'push']command.extend _format_opts opts if not isinstance remote six.string_types remote str remote if not isinstance ref six.string_types ref str ref command.extend [remote ref] return _git_run command cwd cwd user user password password identity identity ignore_retcode ignore_retcode saltenv saltenv ['stdout']
def test_debug_file_logging caplog info_logger_with_file debug_file debug_messages [file_handler stream_handler] info_logger_with_file.handlersassert isinstance file_handler logging.FileHandler assert isinstance stream_handler logging.StreamHandler assert stream_handler.level logging.INFO assert file_handler.level logging.DEBUG create_log_records assert debug_file.exists assert debug_file.readlines cr False debug_messages + ['']
def sstr expr **settings p StrPrinter settings s p.doprint expr return s
def picklechops chops value zlib.compress dumps chops encoded base64.encodestring value return encoded.strip
@register_specialize@gof.local_optimizer [T.Elemwise] def local_alloc_unary node if isinstance node.op T.Elemwise and len node.inputs 1 a node.inputs[0]if a.owner and isinstance a.owner.op T.Alloc x a.owner.inputs[0]shp a.owner.inputs[1 ]v node.op x copy_stack_trace node.outputs[0] v ret T.alloc T.cast v node.outputs[0].dtype *shp copy_stack_trace [node.outputs[0] a] ret return [ret]
def set_runner_scenario testcase scenario_name clear_tracker True scenarios testcase.runner_scenariostestcase.scenario scenarios[scenario_name]set_pidlockfile_scenario testcase testcase.scenario['pidlockfile_scenario_name'] if clear_tracker testcase.mock_tracker.clear
def gen_combos challbs return tuple i for i _ in enumerate challbs
def fix_ampersands value from django.utils.html import fix_ampersandsreturn fix_ampersands value
def make_color_tuple color R color[1 3]G color[3 5]B color[5 7]R int R 16 G int G 16 B int B 16 return R G B
@js_defined 'window.jQuery' def disable_jquery_animations page page.browser.execute_script 'jQuery.fx.off true;'
def _ipaddress_match ipname host_ip ip ipaddress.ip_address _to_unicode ipname .rstrip return ip host_ip
def ipdb_breakpoint x import ipdbipdb.set_trace
def get_changed_packages blob_name1 blob_name2 package_list changed_files check_output 'git' 'diff' '--name-only' blob_name1 blob_name2 changed_files changed_files.split '\n' result set for filename in changed_files file_root rootname filename if file_root in package_list result.add file_root return sorted result
def lang_set languages strict False return set Language l strict strict for l in languages
def head_account url token http_conn None headers None service_token None if http_conn parsed conn http_connelse parsed conn http_connection url method 'HEAD'req_headers {'X-Auth-Token' token}if service_token req_headers['X-Service-Token'] service_tokenif headers req_headers.update headers conn.request method parsed.path '' req_headers resp conn.getresponse body resp.read http_log url method {'headers' req_headers} resp body if resp.status < 200 or resp.status > 300 raise ClientException.from_response resp 'AccountHEADfailed' body resp_headers resp_header_dict resp return resp_headers
def get_activation name try return globals [name]except raise ValueError 'Invalidactivationfunction.'
def parse_mapping_file_to_dict *args **kwargs mapping_data header comments parse_mapping_file *args **kwargs return mapping_file_to_dict mapping_data header comments
@bdd.then 'nocrashshouldhappen' def no_crash time.sleep 0.5
def load_collectors_from_entry_point path collectors {}for ep in pkg_resources.iter_entry_points path try mod ep.load except Exception logger.error 'Failedtoimportentry_point %s.%s' ep.name traceback.format_exc else collectors.update get_collectors_from_module mod return collectors
def greater_equal x y return tf.greater_equal x y
def _parse_settings_bond_6 opts iface bond_def bond {'mode' '6'}for binding in ['miimon' 'downdelay' 'updelay'] if binding in opts try int opts[binding] bond.update {binding opts[binding]} except ValueError _raise_error_iface iface binding ['integer'] else _log_default_iface iface binding bond_def[binding] bond.update {binding bond_def[binding]} if 'use_carrier' in opts if opts['use_carrier'] in _CONFIG_TRUE bond.update {'use_carrier' '1'} elif opts['use_carrier'] in _CONFIG_FALSE bond.update {'use_carrier' '0'} else valid _CONFIG_TRUE + _CONFIG_FALSE _raise_error_iface iface 'use_carrier' valid else _log_default_iface iface 'use_carrier' bond_def['use_carrier'] bond.update {'use_carrier' bond_def['use_carrier']} return bond
def get_all_node_subscriptions user node user_subscriptions None if not user_subscriptions user_subscriptions get_all_user_subscriptions user for subscription in user_subscriptions if subscription and subscription.owner node yield subscription
def jellyToAOT obj return AOTJellier .jelly obj
def std data return np.std data
def ensure_vlan_bridge session vif cluster None create_vlan True vlan_num vif['network'].get_meta 'vlan' bridge vif['network']['bridge']vlan_interface CONF.vmware.vlan_interfacenetwork_ref network_util.get_network_with_the_name session bridge cluster if network_ref and network_ref['type'] 'DistributedVirtualPortgroup' return network_refif not network_ref vswitch_associated _get_associated_vswitch_for_interface session vlan_interface cluster network_util.create_port_group session bridge vswitch_associated vlan_num if create_vlan else 0 cluster network_ref network_util.get_network_with_the_name session bridge cluster elif create_vlan vswitch_associated _get_associated_vswitch_for_interface session vlan_interface cluster _get_pg_info network_util.get_vlanid_and_vswitch_for_portgroup pg_vlanid pg_vswitch _get_pg_info session bridge cluster if pg_vswitch ! vswitch_associated raise exception.InvalidVLANPortGroup bridge bridge expected vswitch_associated actual pg_vswitch if pg_vlanid ! vlan_num raise exception.InvalidVLANTag bridge bridge tag vlan_num pgroup pg_vlanid return network_ref
def disconnect_all signal Any sender Any for receiver in liveReceivers getAllReceivers sender signal disconnect receiver signal signal sender sender
def build_arg_parser parser argparse.ArgumentParser description 'StandardArgumentsfortalkingtovCenter' parser.add_argument '-s' '--host' required True action 'store' help 'vSphereservicetoconnectto' parser.add_argument '-o' '--port' type int default 443 action 'store' help 'Porttoconnecton' parser.add_argument '-u' '--user' required True action 'store' help 'Usernametousewhenconnectingtohost' parser.add_argument '-p' '--password' required False action 'store' help 'Passwordtousewhenconnectingtohost' return parser
def plot_matches im1 im2 locs1 locs2 matchscores show_below True im3 appendimages im1 im2 if show_below im3 vstack im3 im3 imshow im3 cols1 im1.shape[1]for i m in enumerate matchscores if m > 0 plot [locs1[i][1] locs2[m][1] + cols1 ] [locs1[i][0] locs2[m][0]] 'c' axis 'off'
def _DoubleDecoder local_unpack struct.unpackdef InnerDecode buffer pos new_pos pos + 8 double_bytes buffer[pos new_pos]if double_bytes[7] in '\x7f\xff' and double_bytes[6] > '\xf0' and double_bytes[0 7] ! '\x00\x00\x00\x00\x00\x00\xf0' return _NAN new_pos result local_unpack '<d' double_bytes [0]return result new_pos return _SimpleDecoder wire_format.WIRETYPE_FIXED64 InnerDecode
def repost only_actual False allow_negative_stock False allow_zero_rate False only_bin False frappe.db.auto_commit_on_many_writes 1if allow_negative_stock existing_allow_negative_stock frappe.db.get_value u'StockSettings' None u'allow_negative_stock' frappe.db.set_value u'StockSettings' None u'allow_negative_stock' 1 for d in frappe.db.sql u'selectdistinctitem_code warehousefrom\n DCTB DCTB selectitem_code warehousefromtabBin\n DCTB DCTB union\n DCTB DCTB selectitem_code warehousefrom`tabStockLedgerEntry` a' try repost_stock d[0] d[1] allow_zero_rate only_actual only_bin frappe.db.commit except frappe.db.rollback if allow_negative_stock frappe.db.set_value u'StockSettings' None u'allow_negative_stock' existing_allow_negative_stock frappe.db.auto_commit_on_many_writes 0
def update_num_gildings update_trophy True user_id None query select [gold_table.c.paying_id sa_count gold_table.c.trans_id ] .where gold_table.c.trans_id.like 'X%' .group_by gold_table.c.paying_id .order_by sa_count gold_table.c.trans_id .desc if user_id query query.where gold_table.c.paying_id str user_id rows ENGINE.execute query total_updated 0for paying_id count in rows try a Account._byID int paying_id data True a.num_gildings counta._commit total_updated + 1if update_trophy and a.pref_public_server_seconds add_to_trophy_queue a 'gilding' except g.log.debug 'update_num_gildings paying_id%sisinvalid' % paying_id g.log.debug 'update_num_gildings updated%saccounts' % total_updated
def p_equality_expression_3 t pass
def inst_tops days 5 retry_count 3 pause 0.001 if ct._check_lhb_input days is True ct._write_head df _inst_tops days pageNo 1 retry_count retry_count pause pause df['code'] df['code'].map lambda x str x .zfill 6 return df
def enable_print sys.stdout sys.__stdout__sys.stderr sys.__stderr__
def get_gif api_key gif_id url 'http //api.giphy.com/v1/gifs/{}?api_key {}'.format gif_id api_key r urlopen url return json.loads r.read .decode 'utf-8'
@binding.ffi_callback 'int char* int int void* ' name 'Cryptography_pem_password_cb' def _pem_password_cb buf size writing userdata_handle ud _ffi.from_handle userdata_handle ud.called + 1if not ud.password ud.exception TypeError 'Passwordwasnotgivenbutprivatekeyisencrypted.' return -1 elif len ud.password < size pw_buf _ffi.buffer buf size pw_buf[ len ud.password ] ud.passwordreturn len ud.password else ud.exception ValueError 'Passwordslongerthan{0}bytesarenotsupportedbythisbackend.'.format size - 1 return 0
def lower_bound w_dyad assert is_dyad_weight w_dyad md get_max_denom w_dyad lb1 len bin md - 3 lb2 sum 1 if e ! 0 else 0 for e in w_dyad - 1 return max lb1 lb2
def left_join left right left_vars right_vars indices left_join_indices left right left_vars right_vars return join_table_by_indices left right indices
def formstyle_table form fields *args **kwargs def render_row row_id label widget comment hidden False row []_class 'hide' if hidden else None row.append TR TD label _class 'w2p_fl' TD '' _id row_id + '1' _class _class row.append TR widget TD comment _class 'w2p_fc' _id row_id _class _class return tuple row if args hidden kwargs.get 'hidden' False return render_row form fields args[0] args[1] hidden hidden else parent TABLE for row_id label widget comment in fields rows render_row row_id label widget comment parent.append rows[0] parent.append rows[1] return parent
def ignore_code code for ignore in options.ignore if code.startswith ignore return True
def execute_external_command command cmd_input None result ''P Popen [command] stdout PIPE stdin PIPE stderr PIPE shell True result err P.communicate cmd_input if err and config.Option.get 'debug' 'on' warning_msg err return decode_string_escape result
def parse_html html parser Parser parser.feed html parser.close document parser.rootdocument.finalize if len document.children 1 if not isinstance document.children[0] six.string_types document document.children[0]return document
def paired_euclidean_distances X Y X Y check_paired_arrays X Y return row_norms X - Y
def run_pending default_scheduler.run_pending
def _project_im_rois im_rois im_scale_factor rois im_rois * im_scale_factor return rois
def disks if salt.utils.is_freebsd return _freebsd_geom elif salt.utils.is_linux return _linux_disks else log.trace 'DiskgraindoesnotsupportOS'
def _getInstallFunction platform try if platform.isLinux try from twisted.internet.epollreactor import installexcept ImportError from twisted.internet.pollreactor import installelif platform.getType 'posix' and not platform.isMacOSX from twisted.internet.pollreactor import installelse from twisted.internet.selectreactor import installexcept ImportError from twisted.internet.selectreactor import installreturn install
def install_ssl_options_conf options_ssl if not os.path.isfile options_ssl shutil.copyfile constants.os_constant 'MOD_SSL_CONF_SRC' options_ssl
def WSGIServer server_address wsgi_app from . import wsgiserverwsgiserver.ssl_adapters {'builtin' 'web.wsgiserver.ssl_builtin.BuiltinSSLAdapter' 'pyopenssl' 'web.wsgiserver.ssl_pyopenssl.pyOpenSSLAdapter'}server wsgiserver.CherryPyWSGIServer server_address wsgi_app server_name 'localhost' def create_ssl_adapter cert key import typescherrypy types.ModuleType 'cherrypy' cherrypy.wsgiserver wsgiserversys.modules['cherrypy'] cherrypysys.modules['cherrypy.wsgiserver'] wsgiserverfrom wsgiserver.ssl_pyopenssl import pyOpenSSLAdapteradapter pyOpenSSLAdapter cert key del sys.modules['cherrypy']del sys.modules['cherrypy.wsgiserver']return adapterif server.ssl_adapter is None and getattr server 'ssl_certificate' None and getattr server 'ssl_private_key' None server.ssl_adapter create_ssl_adapter server.ssl_certificate server.ssl_private_key server.nodelay not sys.platform.startswith 'java' return server
def is_beta version return bool amo.VERSION_BETA.search version
def str2time s suffixes 'S' 1 'M' 60 'H' 60 * 60 'D' 60 * 60 * 24 'W' 60 * 60 * 24 * 7 'Y' 60 * 60 * 24 * 365 if _PY3 and isinstance s bytes s s.decode 'ascii' if isinstance s str s s.upper .strip for suff mult in suffixes if s.endswith suff return int float s[ -1 ] * mult try s int s except ValueError raise ValueError 'Invalidtimeintervalspecifier ' + s return s
def plot_evoked_topo evoked layout None layout_scale 0.945 color None border 'none' ylim None scalings None title None proj False vline [0.0] fig_facecolor 'k' fig_background None axis_facecolor 'k' font_color 'w' merge_grads False show True return _plot_evoked_topo evoked evoked layout layout layout_scale layout_scale color color border border ylim ylim scalings scalings title title proj proj vline vline fig_facecolor fig_facecolor fig_background fig_background axis_facecolor axis_facecolor font_color font_color merge_grads merge_grads show show
def cinder_docstring_start_space physical_line pos max [physical_line.find i for i in DOCSTRING_TRIPLE] if pos ! -1 and len physical_line > pos + 1 if physical_line[ pos + 3 ] '' return pos 'CINDERN401 onelinedocstringshouldnotstartwithaspace'
def _scalar_tester norm_instance vals scalar_result [norm_instance float v for v in vals]assert_array_almost_equal scalar_result norm_instance vals
@cacheitdef _remove_multiple_delta expr from sympy.solvers import solveif expr.is_Add return expr.func *list map _remove_multiple_delta expr.args if not expr.is_Mul return expreqs []newargs []for arg in expr.args if isinstance arg KroneckerDelta eqs.append arg.args[0] - arg.args[1] else newargs.append arg if not eqs return exprsolns solve eqs dict True if len solns 0 return S.Zeroelif len solns 1 for key in solns[0].keys newargs.append KroneckerDelta key solns[0][key] expr2 expr.func *newargs if expr ! expr2 return _remove_multiple_delta expr2 return expr
def scrub_user_tags tagcount rdict {}tagdict dict tagcount for t in tagdict if not t continuealltags t.split u' ' for tag in alltags if tag if not tag in rdict rdict[tag] 0rdict[tag] + tagdict[t]rlist []for tag in rdict rlist.append [tag rdict[tag]] return rlist
def get_preconditioner diags_x zeros 3 nx diags_x[0 ] 1 / hx / hx diags_x[1 ] -2 / hx / hx diags_x[2 ] 1 / hx / hx Lx spdiags diags_x [ -1 0 1] nx nx diags_y zeros 3 ny diags_y[0 ] 1 / hy / hy diags_y[1 ] -2 / hy / hy diags_y[2 ] 1 / hy / hy Ly spdiags diags_y [ -1 0 1] ny ny J1 kron Lx eye ny + kron eye nx Ly J1_ilu spilu J1 M LinearOperator shape nx * ny nx * ny matvec J1_ilu.solve return M
def _init_libcrypto libcrypto _load_libcrypto libcrypto.RSA_new.argtypes libcrypto.RSA_new.restype c_void_plibcrypto.RSA_free.argtypes c_void_p libcrypto.RSA_size.argtype c_void_plibcrypto.BIO_new_mem_buf.argtypes c_char_p c_int libcrypto.BIO_new_mem_buf.restype c_void_plibcrypto.BIO_free.argtypes c_void_p libcrypto.PEM_read_bio_RSAPrivateKey.argtypes c_void_p c_void_p c_void_p c_void_p libcrypto.PEM_read_bio_RSAPrivateKey.restype c_void_plibcrypto.PEM_read_bio_RSA_PUBKEY.argtypes c_void_p c_void_p c_void_p c_void_p libcrypto.PEM_read_bio_RSA_PUBKEY.restype c_void_plibcrypto.RSA_private_encrypt.argtypes c_int c_char_p c_char_p c_void_p c_int libcrypto.RSA_public_decrypt.argtypes c_int c_char_p c_char_p c_void_p c_int try if libcrypto.OPENSSL_init_crypto OPENSSL_INIT_NO_LOAD_CONFIG | OPENSSL_INIT_ADD_ALL_CIPHERS | OPENSSL_INIT_ADD_ALL_DIGESTS None ! 1 raise OSError 'FailedtoinitializeOpenSSLlibrary OPENSSL_init_cryptofailed ' except AttributeError libcrypto.OPENSSL_no_config libcrypto.OPENSSL_add_all_algorithms_noconf return libcrypto
def _timestamp_to_json value if isinstance value datetime.datetime if value.tzinfo not in None UTC value value.replace tzinfo None - value.utcoffset value '%s%s+00 00' % value.date .isoformat value.time .isoformat return value
def test_config_change_initial config_stub basedir download_stub data_tmpdir tmpdir create_blocklist tmpdir blocked_hosts BLOCKLIST_HOSTS name 'blocked-hosts' line_format 'one_per_line' config_stub.data {'content' {'host-block-lists' None 'host-blocking-enabled' True 'host-blocking-whitelist' None}}host_blocker adblock.HostBlocker host_blocker.read_hosts for str_url in URLS_TO_CHECK assert not host_blocker.is_blocked QUrl str_url
def _unpickle_app_v2 cls kwargs kwargs[u'set_as_current'] Falsereturn cls **kwargs
def format_string f val grouping False percents list _percent_re.finditer f new_f _percent_re.sub '%s' f if isinstance val tuple new_val list val i 0for perc in percents starcount perc.group 'modifiers' .count '*' new_val[i] format perc.group new_val[i] grouping False *new_val[ i + 1 i + 1 + starcount ] del new_val[ i + 1 i + 1 + starcount ]i + 1 + starcount val tuple new_val elif operator.isMappingType val for perc in percents key perc.group 'key' val[key] format perc.group val[key] grouping else val format percents[0].group val grouping return new_f % val
def is_independent_set G nodes return G.subgraph nodes .number_of_edges 0
def _fa items s if atomp items return itemsif len s 0 return items[0]lst [0] * s[0] stride s[0]for i in range s[0] lst[i] _fa items[i stride] s[1 ] return lst
def NormalProbability ys jitter 0.0 n len ys xs np.random.normal 0 1 n xs.sort if jitter ys Jitter ys jitter else ys np.array ys ys.sort return xs ys
def getEnumeratorKeys enumerator keys if len keys 1 return keys[0]return getEnumeratorKeysExceptForOneArgument enumerator keys
def test_GPU_nstreams_limit if not cuda_available raise SkipTest 'Optionalpackagecudanotavailable' seed 12345R MRG_RandomStreams seed seed use_cuda True def eval_uniform size nstreams if theano.config.mode 'FAST_COMPILE' mode 'FAST_RUN'else mode copy.copy theano.compile.get_default_mode mode.check_py_code Falseout R.uniform size size nstreams nstreams dtype 'float32' f theano.function [] out mode mode return f eval_uniform 10 2 ** 20 assert_raises ValueError eval_uniform 10 2 ** 20 + 1
def make_color_table in_class for name value in color_templates setattr in_class name in_class._base % value
@task @timeitdef send_group_email announcement_id try announcement Announcement.objects.get pk announcement_id except Announcement.DoesNotExist returngroup announcement.groupusers User.objects.filter groups__in [group] plain_content bleach.clean announcement.content_parsed tags [] strip True .strip email_kwargs {'content' plain_content 'content_html' announcement.content_parsed 'domain' Site.objects.get_current .domain}text_template 'announcements/email/announcement.ltxt'html_template 'announcements/email/announcement.html'@safe_translationdef _make_mail locale user subject _ 'Newannouncementfor{group}' .format group group.name mail make_mail subject subject text_template text_template html_template html_template context_vars email_kwargs from_email settings.TIDINGS_FROM_ADDRESS to_email user.email return mailmessages []for u in users locale u.profile.locale or settings.LANGUAGE_CODE messages.append _make_mail locale u send_messages messages
def http_time_to_posix http_time if http_time is not None return email_utils.mktime_tz email_utils.parsedate_tz http_time
@memoize 'media.fetch_size' time 3600 def _fetch_image_size url referer request _initialize_request url referer if not request return Noneparser ImageFile.Parser response Nonetry response urllib2.urlopen request while True chunk response.read 1024 if not chunk breakparser.feed chunk if parser.image return parser.image.sizeexcept urllib2.URLError return Nonefinally if response response.close
def fixed_ips_by_virtual_interface context vif_id return IMPL.fixed_ips_by_virtual_interface context vif_id
@login_required@require_http_methods ['GET' 'POST'] @mobile_template 'users/{mobile/}' def change_email request template if request.method 'POST' form EmailChangeForm request.user request.POST u request.userif form.is_valid and u.email ! form.cleaned_data['email'] EmailChange.objects.filter user request.user .delete email_change EmailChange.objects.create_profile user request.user email form.cleaned_data['email'] EmailChange.objects.send_confirmation_email email_change form.cleaned_data['email'] return render request template + 'change_email_done.html' {'email' form.cleaned_data['email']} else form EmailChangeForm request.user initial {'email' request.user.email} return render request template + 'change_email.html' {'form' form}
def s_bit_field value width endian '<' format 'binary' signed False full_range False fuzzable True name None bit_field primitives.bit_field value width None endian format signed full_range fuzzable name blocks.CURRENT.push bit_field
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def get_expected_key_error_user_message preference_key preference_value return u"Invaliduserpreferencekey'{preference_key}'.".format preference_key preference_key
@condition etag_func lambda r ETAG.strip '"' def etag_view_unquoted request return HttpResponse FULL_RESPONSE
def list_ports zone permanent True cmd '--zone {0}--list-ports'.format zone if permanent cmd + '--permanent'return __firewall_cmd cmd .split
@receiver got_request_exception def record_request_exception sender **kwargs logging.exception 'Uncaughtexceptionfrom{sender}'.format sender sender
def url_equal url_1 url_2 parse_result_1 urlparse url_1 parse_result_2 urlparse url_2 return parse_result_1[ 4] parse_result_2[ 4] and parse_qs parse_result_1[5] parse_qs parse_result_2[5]
def _RunningAvgLoss loss running_avg_loss summary_writer step decay 0.999 if running_avg_loss 0 running_avg_loss losselse running_avg_loss running_avg_loss * decay + 1 - decay * loss running_avg_loss min running_avg_loss 12 loss_sum tf.Summary loss_sum.value.add tag 'running_avg_loss' simple_value running_avg_loss summary_writer.add_summary loss_sum step sys.stdout.write 'running_avg_loss %f\n' % running_avg_loss return running_avg_loss
@expect_downsample_frequency@templated_docstring frequency PIPELINE_DOWNSAMPLING_FREQUENCY_DOC def select_sampling_indices dates frequency return changed_locations _dt_to_period[frequency] dates include_first True
def item return s3_rest_controller
def get_info_filename base_path base_file os.path.basename base_path return CONF.libvirt.image_info_filename_pattern % {'image' base_file}
def _determinePickleModule try import cPicklereturn cPickleexcept ImportError import picklereturn pickle
def resizeWindow win w h timeout 2.0 QtGui.QApplication.processEvents QtTest.QTest.qWaitForWindowShown win win.resize w h start time.time while True w1 h1 win.width win.height if w h w1 h1 returnQtTest.QTest.qWait 10 if time.time - start > timeout raise TimeoutError 'Windowresizefailed requested%dx%d got%dx%d ' % w h w1 h1
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def MessageSetItemEncoder field_number start_bytes ''.join [TagBytes 1 wire_format.WIRETYPE_START_GROUP TagBytes 2 wire_format.WIRETYPE_VARINT _VarintBytes field_number TagBytes 3 wire_format.WIRETYPE_LENGTH_DELIMITED ] end_bytes TagBytes 1 wire_format.WIRETYPE_END_GROUP local_EncodeVarint _EncodeVarintdef EncodeField write value write start_bytes local_EncodeVarint write value.ByteSize value._InternalSerialize write return write end_bytes return EncodeField
def _workout_filename filename if os.path.isfile filename or filename '/' if filename '/' filename Nonereturn filenameelse return _workout_filename os.path.dirname filename
def _log_rescale baseline mode 'mean' if baseline is not None valid_modes 'logratio' 'ratio' 'zscore' 'mean' 'percent' 'zlogratio' if mode not in valid_modes raise Exception 'modeshouldbeanyof %s' % valid_modes msg 'Applyingbaselinecorrection mode %s ' % mode else msg 'Nobaselinecorrectionapplied'return msg
def test_zero_image_one_mask result reconstruction np.zeros 10 10 np.ones 10 10 assert_close result 0
def p_expression_binop t if t[2] '+' t[0] t[1] + t[3] elif t[2] '-' t[0] t[1] - t[3] elif t[2] '*' t[0] t[1] * t[3] elif t[2] '/' t[0] t[1] / t[3]
def rsa_decrypt data rsa_priv_key_str key RSA.importKey rsa_priv_key_str cipher PKCS1_OAEP.new key return cipher.decrypt data
def utf8_barebyte_encoding t return t.encode 'utf8'
def update_static_names names_file files if os.path.exists names_file names json.load open names_file else names {}base os.path.dirname names_file for path in files name os.path.relpath path base mangled_name generate_static_name name base names[name] mangled_nameif not os.path.islink path mangled_path os.path.join base mangled_name shutil.move path mangled_path if os.path.exists path os.unlink path os.symlink mangled_name path json_enc json.JSONEncoder indent 2 sort_keys True open names_file 'w' .write json_enc.encode names return names
def initialize_container path_to_container opf_name 'metadata.opf' extra_entries [] rootfiles ''for path mimetype _ in extra_entries rootfiles + u'<rootfilefull-path "{0}"media-type "{1}"/>'.format path mimetype CONTAINER u'<?xmlversion "1.0"?>\n<containerversion "1.0"xmlns "urn oasis names tc opendocument xmlns container">\n<rootfiles>\n<rootfilefull-path "{0}"media-type "application/oebps-package+xml"/>\n{extra_entries}\n</rootfiles>\n</container>\n'.format opf_name extra_entries rootfiles .encode 'utf-8' zf ZipFile path_to_container 'w' zf.writestr 'mimetype' 'application/epub+zip' compression ZIP_STORED zf.writestr 'META-INF/' '' 493 zf.writestr 'META-INF/container.xml' CONTAINER for path _ data in extra_entries zf.writestr path data return zf
@require_GET@allow_CORS_GET@process_document_path@prevent_indexingdef toc request document_slug None document_locale None query {'locale' request.LANGUAGE_CODE 'current_revision__isnull' False}if document_slug is not None query['slug'] document_slugquery['locale'] document_localeelif 'title' in request.GET query['title'] request.GET['title']elif 'slug' in request.GET query['slug'] request.GET['slug']else return HttpResponseBadRequest document get_object_or_404 Document **query toc_html document.get_toc_html if toc_html toc_html '<ol>' + toc_html + '</ol>' return HttpResponse toc_html
def test_chimecho session media_root chimecho session.query tables.PokemonSpecies .filter_by identifier u'chimecho' .one accessor media.PokemonSpeciesMedia media_root chimecho male accessor.sprite 'platinum' back True frame 2 female accessor.sprite 'platinum' back True female True frame 2 assert male ! female
def set_ key value profile None conn salt.utils.memcached.get_conn profile time profile.get 'expire' DEFAULT_EXPIRATION return salt.utils.memcached.set_ conn key value time time
def list_share_files cookie tokens uk shareid dirname page 1 if not dirname return list_share_single_file cookie tokens uk shareid url ''.join [const.PAN_URL 'share/list?channel chunlei&clienttype 0&web 1&num 50' '&t ' util.timestamp '&page ' str page '&dir ' encoder.encode_uri_component dirname '&t ' util.latency '&shareid ' shareid '&order time&desc 1' '&uk ' uk '&_ ' util.timestamp '&bdstoken ' tokens['bdstoken']] req net.urlopen url headers {'Cookie' cookie.header_output 'Referer' const.SHARE_REFERER} if req content req.datainfo json.loads content.decode if info['errno'] 0 return info['list']return list_share_single_file cookie tokens uk shareid
def job_id conf return hashlib.sha1 json.dumps conf sort_keys True .encode u'utf-8' .hexdigest
def _generate_weighted_edges A if A.format 'csr' return _csr_gen_triples A if A.format 'csc' return _csc_gen_triples A if A.format 'dok' return _dok_gen_triples A return _coo_gen_triples A.tocoo
def unquote_keys data if isinstance data dict for key value in data.items if isinstance value dict unquote_keys value if key.startswith '%24' k parse.unquote key data[k] data.pop key return data
def _get_window_registry window if window is None raise TypeError 'windowisNonewithscopewindow!' try if window 'current' app get 'app' win app.activeWindow elif window 'last-focused' win last_focused_window else win window_registry[window]except KeyError NoWindow win Nonetry return win.registryexcept AttributeError raise RegistryUnavailableError 'window'
@pytest.yield_fixture scope u'module' autouse True def ctx builtins.__xonsh_shell__ Shell {u'PATH' []} yield del builtins.__xonsh_shell__
def test_obstime b1950 Time u'B1950' scale u'utc' j1975 Time u'J1975' scale u'utc' fk4_50 FK4 ra 1 * u.deg dec 2 * u.deg obstime b1950 fk4_75 FK4 ra 1 * u.deg dec 2 * u.deg obstime j1975 icrs_50 fk4_50.transform_to ICRS icrs_75 fk4_75.transform_to ICRS assert icrs_50.ra.degree ! icrs_75.ra.degree assert icrs_50.dec.degree ! icrs_75.dec.degree
def _compute_subcorr G phi_sig Ug Sg Vg linalg.svd G full_matrices False tmp np.dot Ug.T.conjugate phi_sig Uc Sc Vc linalg.svd tmp full_matrices False X np.dot np.dot Vg.T np.diag 1.0 / Sg Uc return Sc[0] X[ 0] / linalg.norm X[ 0]
def simple def build 'Buildslossgraph.'x tf.get_variable 'x' shape [] dtype tf.float32 initializer tf.ones_initializer return tf.square x name 'x_squared' return build
def _append_param_insert_pk_returning compiler stmt c values kw if c.default is not None if c.default.is_sequence if compiler.dialect.supports_sequences and not c.default.optional or not compiler.dialect.sequences_optional proc compiler.process c.default **kw values.append c proc compiler.returning.append c elif c.default.is_clause_element values.append c compiler.process c.default.arg.self_group **kw compiler.returning.append c else values.append c _create_insert_prefetch_bind_param compiler c elif c is stmt.table._autoincrement_column or c.server_default is not None compiler.returning.append c elif not c.nullable _warn_pk_with_no_anticipated_value c
def zipline_root environ None if environ is None environ os.environroot environ.get 'ZIPLINE_ROOT' None if root is None root expanduser '~/.zipline' return root
def _read_dictionary_page file_obj schema_helper page_header column_metadata raw_bytes _read_page file_obj page_header column_metadata io_obj io.BytesIO raw_bytes values encoding.read_plain io_obj column_metadata.type page_header.dictionary_page_header.num_values schema_element schema_helper.schema_element column_metadata.path_in_schema[ -1 ] return convert_column values schema_element if schema_element.converted_type is not None else values
def strip_irc string return IRC_COLOR_RE.sub '' string
def _setup_canned_roles cls roles methods collection_type util.duck_type_collection cls if collection_type in __interfaces canned_roles decorators __interfaces[collection_type]for role name in canned_roles.items roles.setdefault role name for method decorator in decorators.items fn getattr cls method None if fn and method not in methods and not hasattr fn '_sa_instrumented' setattr cls method decorator fn
def get_related_models_recursive model seen set queue _get_related_models model for rel_mod in queue rel_app_label rel_model_name rel_mod._meta.app_label rel_mod._meta.model_name if rel_app_label rel_model_name in seen continueseen.add rel_app_label rel_model_name queue.extend _get_related_models rel_mod return seen - { model._meta.app_label model._meta.model_name }
@receiver [models.signals.post_delete models.signals.post_save] sender ExtensionVersion dispatch_uid 'extension_version_change' def update_extension_status_and_manifest_fields sender instance **kw instance.extension.update_status_according_to_versions if instance.status STATUS_PUBLIC instance.extension.update_manifest_fields_from_latest_public_version
def event_return events opts _get_options {} opts['skip'] Truefor event in events log.trace 'Carbonreturnerreceivedevent {0}'.format event metric_base event['tag']saltdata event['data'].get 'data' _send saltdata metric_base opts
def mutNodeReplacement individual pset if len individual < 2 return individual index random.randrange 1 len individual node individual[index]if node.arity 0 term random.choice pset.terminals[node.ret] if isclass term term term individual[index] termelse prims [p for p in pset.primitives[node.ret] if p.args node.args ]individual[index] random.choice prims return individual
def GetUserAgent product_tokens []product_tokens.append 'Google-remote_api/1.0' product_tokens.append appengine_rpc.GetPlatformToken python_version '.'.join str i for i in sys.version_info product_tokens.append 'Python/%s' % python_version return ''.join product_tokens
def _get_num_interval config num_pre num_post post int num_post if num_post else 0 pre int num_pre if num_pre is not None else _get_last_snapshot config ['id'] return pre post
def sample_mem current_rss mem_rss _mem_sample.append current_rss return current_rss
def _register_lltd_specific_class *attr_types def _register cls for attr_type in attr_types SPECIFIC_CLASSES[attr_type] clstype_fld LLTDAttribute.fields_desc[0].copy type_fld.default attr_types[0]cls.fields_desc [type_fld] + cls.fields_desc return clsreturn _register
def addPillarByLoops faces indexedLoops if len indexedLoops < 1 returnif len indexedLoops[ -1 ] < 1 addFacesByConvexLoops faces indexedLoops returnaddFacesByLoopReversed faces indexedLoops[0] addFacesByConvexLoops faces indexedLoops addFacesByLoop faces indexedLoops[ -1 ]
def is_throttled address return bool find_containing_network g.throttles address
def partition_list_osd return ceph_cfg.partition_list_osd
def positive_integer value try value int value except Exception raise argparse.ArgumentTypeError "Invalidintvalue '{}'".format value if value < 0 raise argparse.ArgumentTypeError "Invalidpositiveintvalue '{}'".format value return value
def escape2null text parts []start 0while 1 found text.find '\\' start if found -1 parts.append text[start ] return ''.join parts parts.append text[start found] parts.append '\x00' + text[ found + 1 found + 2 ] start found + 2
def specialize_entry entry cname entry.is_fused_specialized Trueentry.name get_fused_cname cname entry.name if entry.is_cmethod entry.cname entry.nameif entry.is_inherited entry.cname StringEncoding.EncodedString '%s.%s' % Naming.obj_base_cname entry.cname else entry.cname get_fused_cname cname entry.cname if entry.func_cname entry.func_cname get_fused_cname cname entry.func_cname
def blocks device args None fsdump dump device args return fsdump['blocks']
def weighted_objective fn def weighted y_true y_pred weights mask None score_array fn y_true y_pred if mask is not None mask K.cast mask K.floatx score_array * maskscore_array / K.mean mask ndim K.ndim score_array weight_ndim K.ndim weights score_array K.mean score_array axis list range weight_ndim ndim if weights is not None score_array * weightsscore_array / K.mean K.cast K.not_equal weights 0 K.floatx return K.mean score_array return weighted
def gce_credentials_from_config gce_credentials_config None if gce_credentials_config is not None credentials ServiceAccountCredentials.from_p12_keyfile_buffer service_account_email gce_credentials_config['client_email'] file_buffer BytesIO gce_credentials_config['private_key'] scopes [u'https //www.googleapis.com/auth/compute'] else credentials GoogleCredentials.get_application_default return credentials
def addSubmenus craftTypeName menu pluginFileName pluginPath profileRadioVar submenu settings.Tkinter.Menu menu tearoff 0 menu.add_cascade label pluginFileName.capitalize menu submenu settings.ToolDialog .addPluginToMenu submenu pluginPath submenu.add_separator pluginModule skeinforge_profile.getCraftTypePluginModule pluginFileName profilePluginSettings settings.getReadRepository pluginModule.getNewRepository isSelected craftTypeName pluginFileName for profileName in profilePluginSettings.profileList.value value isSelected and profileName profilePluginSettings.profileListbox.value ProfileMenuRadio pluginFileName submenu profileName profileRadioVar value
def clf gcf .clf draw_if_interactive
@get '/admin/<taskid>/list' def task_list taskid None tasks {}for key in DataStore.tasks if is_admin taskid or DataStore.tasks[key].remote_addr request.remote_addr tasks[key] dejsonize scan_status key ['status']logger.debug '[%s]Listedtaskpool %s ' % taskid 'admin' if is_admin taskid else request.remote_addr return jsonize {'success' True 'tasks' tasks 'tasks_num' len tasks }
def urlsafe_encrypt key plaintext blocksize 16 def pad text '\nPadstexttobeencrypted\n'pad_length blocksize - len text % blocksize sr random.StrongRandom pad ''.join chr sr.randint 1 255 for i in range pad_length - 1 return text + chr 0 + pad init_vector Random.get_random_bytes 16 cypher AES.new key AES.MODE_CBC init_vector padded cypher.encrypt pad str plaintext return base64.urlsafe_b64encode init_vector + padded
def get_base_url response if response not in _baseurl_cache text response.body_as_unicode [0 4096]_baseurl_cache[response] html.get_base_url text response.url response.encoding return _baseurl_cache[response]
def file_list_emptydirs load _init return []
def ComputeMD5Base64 byte_str hasher hashlib.md5 hasher.update byte_str return base64.b64encode hasher.digest
@pytest.mark.parametrize u'testframe' totest_frames def test_cirs_icrs_moonish testframe moonish CIRS MOONDIST_CART obstime testframe.obstime moonicrs moonish.transform_to ICRS assert 0.97 * u.au < moonicrs.distance < 1.03 * u.au
def _check_arity_and_homogeneity sig args arity return_type None assert len args arity assert len sig.args arity ty sig.args[0]if return_type is None return_type tyif not all arg ty for arg in sig.args and sig.return_type return_type import inspectfname inspect.currentframe .f_back.f_code.co_namemsg '{0}calledwithinvalidtypes {1}'.format fname sig assert False msg
def avg_darknesses training_data digit_counts defaultdict int darknesses defaultdict float for image digit in zip training_data[0] training_data[1] digit_counts[digit] + 1darknesses[digit] + sum image avgs defaultdict float for digit n in digit_counts.iteritems avgs[digit] darknesses[digit] / n return avgs
def getFilename aggregationInfo inputFile inputFile resource_filename 'nupic.datafiles' inputFile a defaultdict lambda 0 aggregationInfo outputDir os.path.dirname inputFile outputFile 'agg_%s' % os.path.splitext os.path.basename inputFile [0] noAggregation TruetimePeriods 'yearsmonthsweeksdayshoursminutessecondsmillisecondsmicroseconds'for k in timePeriods.split if a[k] > 0 noAggregation FalseoutputFile + '_%s_%d' % k a[k] if noAggregation return inputFileoutputFile + '.csv'outputFile os.path.join outputDir outputFile return outputFile
def test_prewitt_v_vertical i j np.mgrid[ -5 6 -5 6]image j > 0 .astype float result filters.prewitt_v image j[ np.abs i 5 ] 10000assert np.all result[ j 0 ] 1 assert_allclose result[ np.abs j > 1 ] 0 atol 1e-10
def remove_fc_zone terminate_connection def decorator self *args **kwargs conn_info terminate_connection self *args **kwargs if not conn_info LOG.warning _LW "Driverdidn'treturnconnectioninfofromterminate_connectioncall." return Nonevol_type conn_info.get 'driver_volume_type' None if vol_type 'fibre_channel' if 'initiator_target_map' in conn_info['data'] zm create_zone_manager if zm LOG.debug 'remove_fc_zoneconnectioninfo % conninfo s.' {'conninfo' conn_info} zm.delete_connection conn_info return conn_inforeturn decorator
def test_random_state_none ratio 'auto'ee EasyEnsemble ratio ratio random_state None X_resampled y_resampled ee.fit_sample X Y
def _make_money currency_code value return MoneyMaker currency_code value
def patch_crypto_be_discovery if sys.platform 'win32' or sys.platform 'darwin' and is_frozen from cryptography.hazmat import backendstry from cryptography.hazmat.backends.commoncrypto.backend import backend as be_ccexcept ImportError be_cc Nonetry from cryptography.hazmat.backends.openssl.backend import backend as be_osslexcept ImportError be_ossl Nonebackends._available_backends_list [be for be in be_cc be_ossl if be is not None ]
@expect_element invalid_data_behavior {'warn' 'raise' 'ignore'} def winsorise_uint32 df invalid_data_behavior column *columns columns list column + columns mask df[columns] > UINT32_MAX if invalid_data_behavior ! 'ignore' mask | df[columns].isnull else df[columns] np.nan_to_num df[columns] mv mask.valuesif mv.any if invalid_data_behavior 'raise' raise ValueError '%dvaluesoutofboundsforuint32 %r' % mv.sum df[mask.any axis 1 ] if invalid_data_behavior 'warn' warnings.warn 'Ignoring%dvaluesbecausetheyareoutofboundsforuint32 %r' % mv.sum df[mask.any axis 1 ] stacklevel 3 df[mask] 0return df
def _check_footer_magic_bytes file_obj file_obj.seek -4 2 magic file_obj.read 4 return magic 'PAR1'
def BadXML2Node xml return NodeBuilder xml .getDom
def insert_text_to cursor text fmt while True index text.find chr 8 if index -1 breakcursor.insertText text[ index] fmt if cursor.positionInBlock > 0 cursor.deletePreviousChar text text[ index + 1 ]cursor.insertText text fmt
def isValid text return any word in text.upper for word in WORDS
def block_device_mapping_create context values return IMPL.block_device_mapping_create context values
def complement sequence if isinstance sequence Seq return sequence.complement elif isinstance sequence MutableSeq return sequence.toseq .complement if 'U' in sequence or 'u' in sequence and 'T' in sequence or 't' in sequence raise ValueError 'MixedRNA/DNAfound' elif 'U' in sequence or 'u' in sequence ttable _rna_complement_tableelse ttable _dna_complement_tablereturn sequence.translate ttable
def pimap iterable function *args **kwargs from multiprocessing import Poolglobal workerdef worker x return function x *args **kwargs return Pool processes None .imap worker iterable
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _get_result obj method key axis if isinstance key dict key key[axis]if method 'indexer' method 'ix'key obj._get_axis axis [key]try xp getattr obj method .__getitem__ _axify obj key axis except xp getattr obj method .__getitem__ key return xp
def test_ast_good_assoc can_compile u' assocxyz '
def _iterate_coronal_slices array limits None shape array.shape[2]for ind in range shape if limits and ind not in limits continue yield ind np.flipud np.rot90 array[ ind]
def create_asyncio_eventloop loop None if is_windows from prompt_toolkit.eventloop.asyncio_win32 import Win32AsyncioEventLoop as AsyncioEventLoopelse from prompt_toolkit.eventloop.asyncio_posix import PosixAsyncioEventLoop as AsyncioEventLoopreturn AsyncioEventLoop loop
def _repack_options options return dict [ str x _normalize y for x y in six.iteritems salt.utils.repack_dictlist options ]
@receiver post_save sender User def user_signup_handler sender **kwargs if 'created' in kwargs and kwargs['created'] site configuration_helpers.get_value 'SITE_NAME' if site user_signup_source UserSignupSource user kwargs['instance'] site site user_signup_source.save log.info u'user{}originatedfromawhitelabeled"Microsite"'.format kwargs['instance'].id
def remove_image_permissions apps schema_editor ContentType apps.get_model u'contenttypes.ContentType' Permission apps.get_model u'auth.Permission' image_content_type ContentType.objects.get model u'image' app_label u'wagtailimages' Permission.objects.filter content_type image_content_type codename__in u'add_image' u'change_image' u'delete_image' .delete
def default_stream_factory total_content_length filename content_type content_length None if total_content_length > 1024 * 500 return TemporaryFile 'wb+' return BytesIO
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def _get_row_dict row_len model idx {}if row_len 3 idx['query'] 0idx['midline'] 1idx['hit'] 2 idx['qannot'] idx['hannot'] None None elif row_len 4 if 'protein2' in model idx['query'] 0idx['midline'] 1idx['hit'] 2idx['hannot'] 3idx['qannot'] Noneelif '2protein' in model idx['query'] 1idx['midline'] 2idx['hit'] 3idx['hannot'] Noneidx['qannot'] 0else raise ValueError 'Unexpectedmodel ' + model elif row_len 5 idx['qannot'] 0idx['query'] 1idx['midline'] 2idx['hit'] 3idx['hannot'] 4else raise ValueError 'Unexpectedrowcountinalignmentblock %i' % row_len return idx
def get_boot_options module command 'showboot'body execute_show_command command module [0]boot_options_raw_text body.split 'BootVariablesonnextreload' [1]if 'kickstart' in boot_options_raw_text kick_regex 'kickstartvariable bootflash / \\S+ 'sys_regex 'systemvariable bootflash / \\S+ 'kick re.search kick_regex boot_options_raw_text .group 1 sys re.search sys_regex boot_options_raw_text .group 1 retdict dict kick kick sys sys else nxos_regex 'NXOSvariable bootflash / \\S+ 'nxos re.search nxos_regex boot_options_raw_text .group 1 retdict dict sys nxos command 'showinstallallstatus'retdict['status'] execute_show_command command module [0]return retdict
def continued_fraction_iterator x from sympy.functions import floorwhile True i floor x yield i x - iif not x breakx 1 / x
def find_repo repo_name path os.path.abspath os.path.join os.path.dirname sql.__file__ repo_name if not os.path.isdir path raise exception.MigrationNotProvided sql.__name__ path return path
def config_control result Truecomment '' changed not_changed_reason config_changed if not changed return changed not_changed_reason try_commit commit if not try_commit.get 'result' result Falsecomment 'Unabletocommitthechanges {reason}.\nWilltrytorollbacknow!'.format reason try_commit.get 'comment' try_rollback rollback if not try_rollback.get 'result' comment + '\nCannotrollback!{reason}'.format reason try_rollback.get 'comment' return result comment
def create_application return webapp.WSGIApplication [ '.*/worker_callback' handlers.MapperWorkerCallbackHandler '.*/controller_callback' handlers.ControllerCallbackHandler '.*/kickoffjob_callback' handlers.KickOffJobHandler '.*/command/start_job' handlers.StartJobHandler '.*/command/cleanup_job' handlers.CleanUpJobHandler '.*/command/abort_job' handlers.AbortJobHandler '.*/command/list_configs' status.ListConfigsHandler '.*/command/list_jobs' status.ListJobsHandler '.*/command/get_job_detail' status.GetJobDetailHandler '/[^/]+ ? / ?' RedirectHandler '.+/ [a-zA-Z0-9]+ ? \\. ? css|js ? ' status.ResourceHandler ] debug True
def _get_count_from_last_line filename file_type last_line _get_report_contents filename last_line_only True if file_type is 'python_complexity' regex '\\d+.\\d+'else regex '^\\d+'try return float re.search regex last_line .group 0 except AttributeError ValueError return None
def progress_iter progress widgets [progressbar.Percentage '' progressbar.Bar '' progressbar.Timer 'Returns [' progressbar.Counter '/{0}]'.format progress['minion_count'] ]bar progressbar.ProgressBar widgets widgets maxval progress['minion_count'] bar.start return bar
def instance_group_get_all context return IMPL.instance_group_get_all context
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def _is_pair obj return isinstance obj tuple and len obj 2
def test_input_validation assert_raises ValueError DataSpecsMapping VectorSpace dim 10 'features' 'targets' assert_raises AssertionError DataSpecsMapping 'features' 'targets' VectorSpace dim 10
def default_list brand brand globals .get brand if not brand return Nonebase general base['username'] list set base['username'] + brand['username'] base['password'] list set base['password'] + brand['password'] return base
def condense_floating_points css return re.sub ' |\\s 0+\\. \\d+ ' '\\1.\\2' css
def get_module_list app_name return get_file_items os.path.join os.path.dirname get_module app_name .__file__ u'modules.txt'
def download_all recommended False restart True to_download _get_available recommended restart for name in to_download download name return list_downloads
def create_gs_key filename rpc None rpc create_gs_key_async filename rpc return rpc.get_result
@register.tag 'cache' def do_cache parser token nodelist parser.parse 'endcache' parser.delete_first_token tokens token.contents.split if len tokens < 3 raise TemplateSyntaxError u"'%r'tagrequiresatleast2arguments." % tokens[0] return CacheNode nodelist tokens[1] tokens[2] tokens[3 ]
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def GetAuditLogEntries offset now token for fd in GetAuditLogFiles offset now token for event in fd.GenerateItems if now - offset < event.timestamp < now yield event
def DeclareKeyFlags flag_values FLAGS for flag_name in DECLARED_KEY_FLAGS gflags.DECLARE_key_flag flag_name flag_values flag_values
def test_open_docs old_tab webbrowser.open_new_tabtry webbrowser.open_new_tab lambda x assert_true 'martinos' in x open_docs open_docs 'tutorials' 'dev' open_docs 'examples' 'stable' assert_raises ValueError open_docs 'foo' assert_raises ValueError open_docs 'api' 'foo' finally webbrowser.open_new_tab old_tab
def getPolarByRadians angleRadians radius 1.0 return radius * euclidean.getWiddershinsUnitPolar angleRadians
def scharr image mask None out np.sqrt scharr_h image mask ** 2 + scharr_v image mask ** 2 out / np.sqrt 2 return out
def _get_version_from_git pre_version git_dir _get_git_directory if git_dir if pre_version try return _run_shell_command 'git--git-dir ' + git_dir + 'describe--exact-match' throw_on_error True .replace '-' '.' except Exception sha _run_shell_command 'git--git-dir ' + git_dir + 'log-n1--pretty format %h' return '%s.a%s.g%s' % pre_version _get_revno git_dir sha else return _run_shell_command 'git--git-dir ' + git_dir + 'describe--always' .replace '-' '.' return None
def collect_stats bin_dir bucket if not os.path.isfile '%s/cbstats' % bin_dir returncli '%s/cbstats' % bin_dir try ts time.time stats subprocess.check_output [cli 'localhost 11211' '-b' bucket 'all'] except subprocess.CalledProcessError returnfor stat in stats.splitlines metric stat.split ' ' [0].lstrip '' value stat.split ' ' [1].lstrip ' DCTB ' if metric in KEYS print 'couchbase.%s%i%sbucket %s' % metric ts value bucket
def is_valid_stream_id entry return is_valid_circuit_id entry
def get_entity_converter id_resolver None id_resolver id_resolver or _IdentityIdResolver return _EntityConverter id_resolver
def _compute_fixed_length_solns model t0 k0 results {}for integrator in ['dopri5' 'dop853' 'vode' 'lsoda'] discrete_soln model.solve t0 k0 h 1.0 T 1000.0 integrator integrator atol 1e-14 rtol 1e-11 results[integrator] discrete_solnreturn results
def get_variables x collection None if collection is None collection tf.all_variables node_dict {node.name node for node in collection}output set [] nodes set [x] while nodes node nodes.pop if isinstance node RandomVariable node node.value candidate_node node_dict.get node.name None if candidate_node and candidate_node ! x output.add candidate_node nodes.update node.op.inputs return list output
def make_hybi00_frame buf return '\x00%s\xff' % buf
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def _filter_apis_desc desc apis return [api for api in apis if api['description'] desc ]
def _synchronous_switch_listener dbapi_conn connection_rec dbapi_conn.execute 'PRAGMAsynchronous OFF'
def messages request return {'messages' get_messages request }
def dict_merge a b result dict **b for key value in a.items if isinstance value collections.Mapping value dict_merge value result.setdefault key {} result[key] valuereturn result
def relay_ip_list name addresses None server _DEFAULT_SERVER ret {'name' name 'changes' {} 'comment' str 'result' None}current_addresses __salt__['win_smtp_server.get_relay_ip_list'] server server if addresses if addresses[0] 'None' addresses[0] Noneelif addresses is None addresses [None]if addresses current_addresses ret['comment'] 'RelayIpListalreadycontainstheprovidedaddresses.'ret['result'] Trueelif __opts__['test'] ret['comment'] 'RelayIpListwillbechanged.'ret['changes'] {'old' current_addresses 'new' addresses}else ret['comment'] 'SetRelayIpListtocontaintheprovidedaddresses.'ret['changes'] {'old' current_addresses 'new' addresses}ret['result'] __salt__['win_smtp_server.set_relay_ip_list'] addresses addresses server server return ret
def test_class_name AreEqual SWF.TextBox.__name__ 'TextBox' AreEqual SWF.TextBox .__class__.__name__ 'TextBox'
def initialize_subtask_info entry action_name total_num subtask_id_list task_progress {'action_name' action_name 'attempted' 0 'failed' 0 'skipped' 0 'succeeded' 0 'total' total_num 'duration_ms' int 0 'start_time' time }entry.task_output InstructorTask.create_output_for_success task_progress entry.task_state PROGRESSnum_subtasks len subtask_id_list subtask_status {subtask_id SubtaskStatus.create subtask_id .to_dict for subtask_id in subtask_id_list}subtask_dict {'total' num_subtasks 'succeeded' 0 'failed' 0 'status' subtask_status}entry.subtasks json.dumps subtask_dict entry.save_now return task_progress
def get_all_queues redis_conn _connect prefix _get_queue_name_prefix return [q for q in rq.Queue.all connection redis_conn if q.name.startswith prefix ]
def force_shutdown func request.environ.get 'werkzeug.server.shutdown' if func is None raise RuntimeError 'NotrunningwiththeWerkzeugServer' func
def _find_columns clause cols util.column_set traverse clause {} {u'column' cols.add} return cols
def get_log_transform otu_table if otu_table.nnz 0 raise ValueError 'AllvaluesintheOTUtablearezero!' def h s_v s_id s_md return np.log10 s_v return otu_table.transform h axis 'sample' inplace False
def get_makeopts return get_var 'MAKEOPTS'
def test_logarithmic_bad_interpolation line Line logarithmic True interpolate 'cubic' line.add '_' [0.001 1e-08 1] q line.render_pyquery assert len q '.y.axis.guides' 41
@register_opt 'fast_compile' @local_optimizer [tensor.Alloc] def local_gpua_alloc2 node try get_context None except ContextNotDefined returnif isinstance node.op tensor.Alloc and all c ! 'output' and isinstance c.op tensor.Join and all i.owner and i.owner.op in [host_from_gpu tensor.alloc] for i in c.inputs[1 ] for c idx in node.outputs[0].clients return [host_from_gpu gpu_alloc None *node.inputs ]
def cli_pip_test venv_name 'flocker-client' package_source PackageSource return sequence [run_from_args ['source' '{}/bin/activate'.format venv_name ] run 'test`flocker-ca--version` {}'.format quote _get_wheel_version package_source ]
def test_pdf2 r S3Request prefix 'gis' name 'hierarchy' from s3.s3export import S3Exporterexporter S3Exporter .pdfreturn exporter r.resource request r method 'list' pdf_title T 'PDFTestCardII' pdf_table_autogrow 'B' pdf_header header pdf_footer footer
def register_scheme_map scheme_map for k v in scheme_map.items if k not in SCHEME_TO_CLS_MAP LOG.debug 'Registeringscheme%swith%s' k v SCHEME_TO_CLS_MAP[k] v
def check_if_project_is_out_of_owner_limits project current_memberships None current_private_projects None current_public_projects None if project.owner is None return {'can_be_updated' False 'reason' ERROR_PROJECT_WITHOUT_OWNER}if current_memberships is None current_memberships project.memberships.count if project.is_private max_memberships project.owner.max_memberships_private_projectsif current_private_projects is None current_projects project.owner.owned_projects.filter is_private True .count else current_projects current_private_projectsmax_projects project.owner.max_private_projectselse max_memberships project.owner.max_memberships_public_projectsif current_public_projects is None current_projects project.owner.owned_projects.filter is_private False .count else current_projects current_public_projectsmax_projects project.owner.max_public_projectsif max_memberships is not None and current_memberships > max_memberships return Trueif max_projects is not None and current_projects > max_projects return Truereturn False
def predicative adjective w adjective.lower if w in adjective_predicative return adjective_predicative[w]if w.endswith 'ari' return w + 'o' if w.endswith 'ali' 'ili' 'esi' 'nti' 'ori' return w[ -1 ] + 'e' if w.endswith 'isti' return w[ -1 ] + 'a' if w.endswith 'che' 'ghe' return w[ -2 ] + 'a' if w.endswith 'chi' 'ghi' return w[ -2 ] + 'o' if w.endswith 'i' return w[ -1 ] + 'o' if w.endswith 'e' return w[ -1 ] + 'a' return adjective
def wigner_9j j_1 j_2 j_3 j_4 j_5 j_6 j_7 j_8 j_9 prec None imin 0imax min j_1 + j_9 j_2 + j_6 j_4 + j_8 sumres 0for kk in range imin int imax + 1 sumres sumres + 2 * kk + 1 * racah j_1 j_2 j_9 j_6 j_3 kk prec * racah j_4 j_6 j_8 j_2 j_5 kk prec * racah j_1 j_4 j_9 j_8 j_7 kk prec return sumres
def safe_get_bool fact return bool strtobool str fact
def get_tree base exclude coverage the_coverage tree {}runs coverage.data.executed_files for path in runs if not _skip_file path exclude and not os.path.isdir path _graft path tree return tree
def get_request_kwargs timeout useragent return {'headers' {'User-Agent' useragent} 'cookies' cj 'timeout' timeout 'allow_redirects' True}
def ignore_not_sysadmin key data errors context user context.get 'user' ignore_auth context.get 'ignore_auth' if ignore_auth or user and authz.is_sysadmin user returndata.pop key
def get_mat_product_viewer W1 W2 prod np.dot W1 W2 pv make_viewer prod.T return pv
def approx_error a_orig w_approx assert all v > 0 for v in a_orig assert is_weight w_approx assert len a_orig len w_approx w_orig np.array a_orig dtype float / sum a_orig return float max abs v1 - v2 for v1 v2 in zip w_orig w_approx
def _norm_along_axis x axis return np.sqrt np.einsum 'ij ij->i' x x
def lpr_ma_data year None year du.get_year if year is None else year lab ct.SHIBOR_TYPE['LPR_Tendency']lab lab.encode 'utf-8' if ct.PY3 else lab try df pd.read_excel ct.SHIBOR_DATA_URL % ct.P_TYPE['http'] ct.DOMAINS['shibor'] ct.PAGES['dw'] 'LPR_Tendency' year lab year skiprows [0] df.columns ct.LPR_MA_COLSdf['date'] df['date'].map lambda x x.date df['date'] df['date'].astype np.datetime64 return dfexcept return None
def metric_handler name return stats[name]
def has_multiple_pks model if not hasattr model '_sa_class_manager' raise TypeError 'modelmustbeasqlalchemymappedmodel' return len model._sa_class_manager.mapper.primary_key > 1
def _find_vm name data quiet False for hv_ in data if not isinstance data[hv_] dict continueif name in data[hv_].get 'vm_info' {} ret {hv_ {name data[hv_]['vm_info'][name]}}if not quiet __jid_event__.fire_event {'data' ret 'outputter' 'nested'} 'progress' return retreturn {}
def test_install_from_wheel script data result script.pip 'install' 'has.script 1.0' '--no-index' '--find-links ' + data.find_links expect_error False dist_info_folder script.site_packages / 'has.script-1.0.dist-info' assert dist_info_folder in result.files_created dist_info_folder result.files_created result.stdout script_file script.bin / 'script.py' assert script_file in result.files_created
def _name_to_index cursor table_name return dict [ d[0] i for i d in enumerate get_table_description cursor table_name ]
def correlation X Y condition None **kwargs return covariance X Y condition **kwargs / std X condition **kwargs * std Y condition **kwargs
def volume_get_all_by_project context project_id marker limit sort_key sort_dir return IMPL.volume_get_all_by_project context project_id marker limit sort_key sort_dir
def generate_aliases fieldfile **kwargs from easy_thumbnails.files import generate_all_aliasesgenerate_all_aliases fieldfile include_global False
def assert_tol_equal a b rtol 1e-07 atol 0 err_msg '' verbose True def compare x y return np.allclose x y rtol rtol atol atol a b np.asanyarray a np.asanyarray b header 'Notequaltotolerancertol %g atol %g' % rtol atol np.testing.utils.assert_array_compare compare a b err_msg str err_msg verbose verbose header header
def login_fresh return session.get '_fresh' False
def _anomalyScoreMovingAverage anomalyScores windowSize 10 verbosity 0 historicalValues []total 0.0averagedRecordList []for record in anomalyScores if not isinstance record list tuple or len record ! 3 if verbosity > 1 print 'Malformedrecord ' record continue avg historicalValues total MovingAverage.compute historicalValues total record[2] windowSize averagedRecordList.append [record[0] record[1] avg] if verbosity > 2 print 'Aggregatinginputrecord ' record print 'Result ' [record[0] record[1] avg] return averagedRecordList historicalValues total
def running name sig None return status name .get name False
def makepatch original modified patch {}for key original_value in original.iteritems modified_value modified.get key None if modified_value is None patch[key] Noneelif original_value ! modified_value if type original_value type {} patch[key] makepatch original_value modified_value else patch[key] modified_valueelse passfor key in modified if key not in original patch[key] modified[key]return patch
def convert_y_domain mpl_plot_bounds mpl_max_y_bounds mpl_y_dom [mpl_plot_bounds[1] mpl_plot_bounds[1] + mpl_plot_bounds[3] ]plotting_height mpl_max_y_bounds[1] - mpl_max_y_bounds[0] y0 mpl_y_dom[0] - mpl_max_y_bounds[0] / plotting_height y1 mpl_y_dom[1] - mpl_max_y_bounds[0] / plotting_height return [y0 y1]
def _if_match_passes target_etag etags if not target_etag return Falseelif etags ['*'] return Trueelif target_etag.startswith 'W/' return Falseelse return target_etag in etags
def unicode_string string if isinstance string six.text_type return stringtry return string.decode 'utf8' except UnicodeDecodeError return '[BASE64-DATA]' + base64.b64encode string + '[/BASE64-DATA]'
def require_admin handler @require_logindef require_admin_wrapper_fn request *args **kwargs if settings.CENTRAL_SERVER and request.user.is_authenticated or getattr request 'is_admin' False return handler request *args **kwargs facility_user_id kwargs.get 'facility_user_id' if request.session.get 'facility_user' and facility_user_id request.session.get 'facility_user' .id return handler request *args **kwargs raise PermissionDenied _ 'Youmustbeloggedinasanadmintoaccessthispage.' return require_admin_wrapper_fn
def _process_timestamp ts if ts is None return Noneelif ts.tzinfo is None return dt_util.UTC.localize ts else return dt_util.as_utc ts
def save_instance form instance commit True from django.db import modelsopts instance.__class__._metaif form.errors raise ValueError "The%scouldnotbechangedbecausethedatadidn'tvalidate." % opts.object_name clean_data form.clean_datafor f in opts.fields if not f.editable or isinstance f models.AutoField continuesetattr instance f.name clean_data[f.name] if commit instance.save for f in opts.many_to_many setattr instance f.attname clean_data[f.name] return instance
def sineTimeScaling sfreq smag timeScaling if timeScaling.size % 2 ! 0 raise ValueError 'Timescalingarraydoesnothaveanevensize' L sfreq.shape[0]maxInTime max timeScaling[ 2] maxOutTime max timeScaling[1 2] outL int L * maxOutTime / maxInTime inFrames L - 1 * timeScaling[ 2] / maxInTime outFrames outL * timeScaling[1 2] / maxOutTime timeScalingEnv interp1d outFrames inFrames fill_value 0 indexes timeScalingEnv np.arange outL ysfreq sfreq[round indexes[0] ]ysmag smag[round indexes[0] ]for l in indexes[1 ] ysfreq np.vstack ysfreq sfreq[round l ] ysmag np.vstack ysmag smag[round l ] return ysfreq ysmag
def _filter_running runnings ret dict tag value for tag value in six.iteritems runnings if not value['result'] or value['changes'] return ret
def notify notificationName message if sabnzbd.FOUNDATION pool Foundation.NSAutoreleasePool.alloc .init nc Foundation.NSDistributedNotificationCenter.defaultCenter nc.postNotificationName_object_ notificationName message del pool
def _insert node path itemid if len path 1 node.files[path[0]] itemidelse dirname path[0]rest path[1 ]if dirname not in node.dirs node.dirs[dirname] Node {} {} _insert node.dirs[dirname] rest itemid
@task base BaseInstructorTask def rescore_problem entry_id xmodule_instance_args action_name ugettext_noop 'rescored' update_fcn partial rescore_problem_module_state xmodule_instance_args def filter_fcn modules_to_update 'Filterthatmatchesproblemswhicharemarkedasbeingdone'return modules_to_update.filter state__contains '"done" true' visit_fcn partial perform_module_state_update update_fcn filter_fcn return run_main_task entry_id visit_fcn action_name
def ismethoddescriptor object return hasattr object '__get__' and not hasattr object '__set__' and not ismethod object and not isfunction object and not isclass object
def repartition df divisions None force False token tokenize df divisions if isinstance df _Frame tmp 'repartition-split-' + token out 'repartition-merge-' + token dsk repartition_divisions df.divisions divisions df._name tmp out force force return new_dd_object merge df.dask dsk out df._meta divisions elif isinstance df pd.Series pd.DataFrame name 'repartition-dataframe-' + token from .utils import shard_df_on_indexdfs shard_df_on_index df divisions[1 -1 ] dsk dict name i df for i df in enumerate dfs return new_dd_object dsk name df divisions raise ValueError 'DatamustbeDataFrameorSeries'
def load_obj load_path if isinstance load_path str load_path os.path.expandvars os.path.expanduser load_path if load_path.endswith '.gz' import gzipload_path gzip.open load_path 'rb' else load_path open load_path 'rb' fname load_path.namelogger.debug 'deserializingobjectfrom %s' fname try return pickle_load load_path except AttributeError msg 'Problemsdeserializing %s.Itspossibletheinterfaceforthisobjecthaschangedsincebeingserialized.Youmayneedtoremoveandrecreateit.' % load_path logger.error msg raise AttributeError msg
def get_template_dir_prefix template_path '/templates/head' if feconf.IS_MINIFIED or not feconf.DEV_MODE else '/templates/dev/head' return '%s%s' % get_asset_dir_prefix template_path
def get_plural_num_pos match plural_str match.group 0 .strip if plural_str not in _PLURAL_NUM_POS first_arg_num _check_plural_arg_is_num match.group 2 .strip second_arg_num _check_plural_arg_is_num match.group 3 .strip if first_arg_num second_arg_num first_arg_num second_arg_num Nonepos Noneif first_arg_num is False or second_arg_num is True pos 2elif second_arg_num is False or first_arg_num is True pos 1else pos prompt_user 'Ambiguous %swhichisthenumber? [1]2 ' % plural_str default 1 _PLURAL_NUM_POS[plural_str] int pos return _PLURAL_NUM_POS[plural_str]
def florentine_families_graph G nx.Graph G.add_edge 'Acciaiuoli' 'Medici' G.add_edge 'Castellani' 'Peruzzi' G.add_edge 'Castellani' 'Strozzi' G.add_edge 'Castellani' 'Barbadori' G.add_edge 'Medici' 'Barbadori' G.add_edge 'Medici' 'Ridolfi' G.add_edge 'Medici' 'Tornabuoni' G.add_edge 'Medici' 'Albizzi' G.add_edge 'Medici' 'Salviati' G.add_edge 'Salviati' 'Pazzi' G.add_edge 'Peruzzi' 'Strozzi' G.add_edge 'Peruzzi' 'Bischeri' G.add_edge 'Strozzi' 'Ridolfi' G.add_edge 'Strozzi' 'Bischeri' G.add_edge 'Ridolfi' 'Tornabuoni' G.add_edge 'Tornabuoni' 'Guadagni' G.add_edge 'Albizzi' 'Ginori' G.add_edge 'Albizzi' 'Guadagni' G.add_edge 'Bischeri' 'Guadagni' G.add_edge 'Guadagni' 'Lamberteschi' return G
def matrix_multiply_elementwise A B if A.shape ! B.shape raise ShapeError shape A.shapereturn classof A B ._new shape[0] shape[1] lambda i j A[ i j ] * B[ i j ]
def notrace *args **kwds def decorator func return funcarg0 len args and args[0] or None if callable arg0 or type arg0 in classmethod staticmethod return decorator arg0 else return decorator
def formatargvalues args varargs varkw locals formatarg str formatvarargs lambda name '*' + name formatvarkw lambda name '**' + name formatvalue lambda value ' ' + repr value join joinseq def convert name locals locals formatarg formatarg formatvalue formatvalue return formatarg name + formatvalue locals[name] specs []for i in range len args specs.append strseq args[i] convert join if varargs specs.append formatvarargs varargs + formatvalue locals[varargs] if varkw specs.append formatvarkw varkw + formatvalue locals[varkw] return ' ' + string.join specs ' ' + ' '
def pickleModule module return unpickleModule module.__name__
def _process_rules_list rules match_rule if isinstance match_rule policy.RuleCheck rules.append match_rule.match elif isinstance match_rule policy.AndCheck for rule in match_rule.rules _process_rules_list rules rule return rules
def _reindent_stats tokens find_stmt 1level 0stats []for t in tokens token_type t[0]sline t[2][0]line t[4]if token_type tokenize.NEWLINE find_stmt 1elif token_type tokenize.INDENT find_stmt 1level + 1elif token_type tokenize.DEDENT find_stmt 1level - 1elif token_type tokenize.COMMENT if find_stmt stats.append sline -1 elif token_type tokenize.NL passelif find_stmt find_stmt 0if line stats.append sline level return stats
def _maybeCleanupScopeIndex family packed if sys.platform.startswith 'freebsd' and packed[ 2] '\xfe\x80' return packed[ 2] + '\x00\x00' + packed[4 ] return packed
def _update_property_value properties key value for prop in properties if prop['key'] key prop.update {'value' value}
def discretize_oversample_1D model x_range factor 10 x np.arange x_range[0] - 0.5 * 1 - 1 / factor x_range[1] + 0.5 * 1 + 1 / factor 1.0 / factor values model x values np.reshape values x.size // factor factor return values.mean axis 1 [ -1 ]
def _get_placeholder_cache_version_key placeholder lang site_id prefix get_cms_setting 'CACHE_PREFIX' key '{prefix}|placeholder_cache_version|id {id}|lang {lang}|site {site}'.format prefix prefix id placeholder.pk lang str lang site site_id if len key > 250 key '{prefix}|{hash}'.format prefix prefix hash hashlib.md5 key.encode 'utf-8' .hexdigest return key
def generate_example_rst app example_dir os.path.abspath os.path.join app.builder.srcdir '..' '..' 'examples' generated_dir os.path.abspath os.path.join app.builder.srcdir 'examples' try plot_gallery eval app.builder.config.plot_gallery except TypeError plot_gallery bool app.builder.config.plot_gallery if not os.path.exists example_dir os.makedirs example_dir if not os.path.exists generated_dir os.makedirs generated_dir seen_backrefs set generate_dir_rst '.' example_dir generated_dir plot_gallery seen_backrefs
@register.filter is_safe True def safeseq value return [mark_safe force_unicode obj for obj in value]
def get_one_version kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theget_cluster_idfunctionmustbecalledwith-for--function.' if kwargs is None kwargs {} server user password _get_xml_rpc auth ' '.join [user password] return server.one.system.version auth [1]
def _caa_request mbid imageid None size None entitytype 'release' path [entitytype mbid]if imageid and size path.append '%s-%s' % imageid size elif imageid path.append imageid url compat.urlunparse 'http' hostname '/%s' % '/'.join path '' '' '' musicbrainz._log.debug 'GETrequestfor%s' % url httpHandler compat.HTTPHandler debuglevel 0 handlers [httpHandler]opener compat.build_opener *handlers req musicbrainz._MusicbrainzHttpRequest 'GET' url None if musicbrainz._useragent ! '' req.add_header 'User-Agent' musicbrainz._useragent musicbrainz._log.debug 'requestingwithUA%s' % musicbrainz._useragent resp musicbrainz._safe_read opener req None if imageid return respelse return json.loads resp
def libvlc_media_player_retain p_mi f _Cfunctions.get 'libvlc_media_player_retain' None or _Cfunction 'libvlc_media_player_retain' 1 None None MediaPlayer return f p_mi
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def require_valid_intent intent if intent not in feconf.VALID_MODERATOR_ACTIONS raise Exception 'Unrecognizedemailintent %s' % intent
@task name 'geonode.tasks.email.send_queued_notifications' queue 'email' def send_queued_notifications *args try from notification.engine import send_allexcept ImportError returnif not args and getattr settings 'NOTIFICATION_LOCK_LOCATION' None send_all settings.NOTIFICATION_LOCK_LOCATION else send_all *args
def test_scenario_outline2_fr_from_string lang Language 'fr' scenario Scenario.from_string OUTLINED_SCENARIO2 language lang assert_equals scenario.name 'Ajouter2nombres' assert_equals scenario.outlines [{u'input_1' u'20' u'input_2' u'30' u'bouton' u'add' u'output' u'50'} {u'input_1' u'2' u'input_2' u'5' u'bouton' u'add' u'output' u'7'} {u'input_1' u'0' u'input_2' u'40' u'bouton' u'add' u'output' u'40'}]
def mlevel level if level and not isinstance level numbers.Integral return LOG_LEVELS[level.upper ]return level
def reduce_memmap a m _get_backing_memmap a if m is not None return _reduce_memmap_backed a m else return loads dumps np.asarray a protocol HIGHEST_PROTOCOL
def fitbinnedgmm distfn freq binedges start fixed None weightsoptimal True if not fixed is None raise NotImplementedErrornobs np.sum freq if weightsoptimal weights freq / float nobs else weights np.ones len freq freqnormed freq / float nobs def gmmobjective params 'negativeloglikelihoodfunctionofbinneddata\n\ncorrespondstomultinomial\n'prob np.diff distfn.cdf binedges *params momcond freqnormed - prob return np.dot momcond * weights momcond return optimize.fmin gmmobjective start
def outer a b out None n a.sizem b.sizeret_shape n m if out is None return core.tensordot_core a b None n m 1 ret_shape if out.size ! n * m raise ValueError 'Outputarrayhasaninvalidsize' if out.flags.c_contiguous return core.tensordot_core a b out n m 1 ret_shape else out[ ] core.tensordot_core a b None n m 1 ret_shape return out
def freespace path s os.statvfs path return s.f_bavail * s.f_bsize
def plot_harris_points image filtered_coords figure gray imshow image plot [p[1] for p in filtered_coords] [p[0] for p in filtered_coords] '*' axis 'off' show
def format_size size for unit in 'B' 'KB' 'MB' 'GB' 'TB' if size < 2048 return '%.f%s' % size unit size / 1024.0
def slashappend s if s and not s.endswith '/' return s + '/' else return s
def get_fifo_rate previous_stock_queue qty if qty > 0 total sum f[0] for f in previous_stock_queue return sum flt f[0] * flt f[1] for f in previous_stock_queue / flt total if total else 0.0 else available_qty_for_outgoing outgoing_cost 0 0 qty_to_pop abs qty while qty_to_pop and previous_stock_queue batch previous_stock_queue[0]if 0 < batch[0] < qty_to_pop available_qty_for_outgoing + flt batch[0] outgoing_cost + flt batch[0] * flt batch[1] qty_to_pop - batch[0]previous_stock_queue.pop 0 else available_qty_for_outgoing + flt qty_to_pop outgoing_cost + flt qty_to_pop * flt batch[1] batch[0] - qty_to_popqty_to_pop 0return outgoing_cost / available_qty_for_outgoing
def convert_to_response_dict http_response operation_model response_dict {'headers' http_response.headers 'status_code' http_response.status_code}if response_dict['status_code'] > 300 response_dict['body'] http_response.contentelif operation_model.has_streaming_output response_dict['body'] StreamingBody http_response.raw response_dict['headers'].get 'content-length' else response_dict['body'] http_response.contentreturn response_dict
@jit nopython True def searchsorted a v lo -1 hi len a while lo < hi - 1 m lo + hi // 2 if v < a[m] hi melse lo mreturn hi
def text_finder registry xml_parent data finder XML.SubElement xml_parent 'hudson.plugins.textfinder.TextFinderPublisher' if 'fileset' in data XML.SubElement finder 'fileSet' .text data['fileset']XML.SubElement finder 'regexp' .text data['regexp']check_output str data.get 'also-check-console-output' False .lower XML.SubElement finder 'alsoCheckConsoleOutput' .text check_outputsucceed_if_found str data.get 'succeed-if-found' False .lower XML.SubElement finder 'succeedIfFound' .text succeed_if_foundunstable_if_found str data.get 'unstable-if-found' False .lower XML.SubElement finder 'unstableIfFound' .text unstable_if_found
def part_range_filter partition_iterator lb ub for state in partition_iterator f lpart pstack stateif lpart > lb and lpart < ub yield state
def get_human_readable_user_ids user_ids users_settings get_users_settings user_ids usernames []for ind user_settings in enumerate users_settings if user_settings is None logging.error 'Userid%snotknowninlistofuser_ids%s' % user_ids[ind] user_ids raise Exception 'Usernotfound.' elif user_settings.user_id feconf.SYSTEM_COMMITTER_ID usernames.append 'admin' elif user_settings.username usernames.append user_settings.username else usernames.append '[Awaitinguserregistration %s]' % user_settings.truncated_email return usernames
def _responds result_type data None msg '' return {'result' result_type_map[result_type] 'message' msg 'data' {} if not data else data }
def get_evennia_pids server_pidfile os.path.join settings.GAME_DIR 'server.pid' portal_pidfile os.path.join settings.GAME_DIR 'portal.pid' server_pid portal_pid None None if os.path.exists server_pidfile f open server_pidfile 'r' server_pid f.read f.close if os.path.exists portal_pidfile f open portal_pidfile 'r' portal_pid f.read f.close if server_pid and portal_pid return int server_pid int portal_pid return None None
def test_create_tuple a1 Angle 1 30 0 unit u.degree assert a1.value 1.5 a1 Angle 1 30 0 unit u.hourangle assert a1.value 1.5
def test_sensitivity_specificity_score_binary y_true y_pred _ make_prediction binary True sen spe sup sensitivity_specificity_support y_true y_pred average None assert_allclose sen [0.88 0.68] rtol R_TOL assert_allclose spe [0.68 0.88] rtol R_TOL assert_array_equal sup [25 25] for kwargs my_assert in [ {} assert_no_warnings {'average' 'binary'} assert_no_warnings ] sen my_assert sensitivity_score y_true y_pred **kwargs assert_allclose sen 0.68 rtol R_TOL spe my_assert specificity_score y_true y_pred **kwargs assert_allclose spe 0.88 rtol R_TOL
def sort_key s global sort_keytry from gluon.contrib.pyuca import unicode_collatorunicode_sort_key unicode_collator.sort_keysort_key lambda s unicode_sort_key to_unicode s 'utf-8' if isinstance s str else s except sort_key lambda s to_unicode s 'utf-8' if isinstance s str else s .lower return sort_key s
def dictfilter d None **kw d kw if d is None else dict d **kw if kw else d return {k v for k v in items d if v is not None }
def _unpack_septets seq padding 0 msgbytes r _consume_bytes seq len seq / 2 msgbytes.reverse asbinary ''.join map _to_binary msgbytes if padding ! 0 asbinary asbinary[ - padding ]chars []while len asbinary > 7 chars.append int asbinary[ -7 ] 2 asbinary asbinary[ -7 ]return ''.join map chr chars
@with_open_mode 'rb' @with_sizes 'medium' def read_seek_blockwise f f.seek 0 while f.read 1000 f.seek 1000 1
def tanh X return np.tanh X out X
def gen_data_files *dirs **kwargs results []optional kwargs.pop u'optional' False def filter_illegal_extensions f return os.path.splitext f [1] ! u'.pyc' for src_dir in dirs if not os.path.isdir src_dir if optional continueelse raise RuntimeError u'{dir s}doesnotexist cannotcontinue'.format dir src_dir for root dirs files in os.walk src_dir results.append root filter filter_illegal_extensions map lambda f os.path.join root f files return results
def copy_column_constraints func def _column_cp self table_name column_old column_new *args **opts try constraint self._find_foreign_constraints table_name column_old [0]refs self._lookup_constraint_references table_name constraint if refs is not None ftable fcolumn refsif ftable and fcolumn fk_sql self.foreign_key_sql table_name column_new ftable fcolumn get_logger .debug 'ForeignkeySQL ' + fk_sql self.add_deferred_sql fk_sql except IndexError passexcept DryRunError passtry reverse self._lookup_reverse_constraint table_name column_old for cname rtable rcolumn in reverse fk_sql self.foreign_key_sql rtable rcolumn table_name column_new self.add_deferred_sql fk_sql except DryRunError passreturn func self table_name column_old column_new *args **opts return _column_cp
@real_memoizedef is_netbsd return sys.platform.startswith 'netbsd'
def render_formset_errors formset **kwargs renderer_cls get_formset_renderer **kwargs return renderer_cls formset **kwargs .render_errors
def new_service name restart True out __mgmt name 'service' 'new' if restart if out 'success' return __firewall_cmd '--reload' return out
def _install_remote download_config read_config rewrite_config create_folders check_dependencies tools_nuget tools_binskim tools_binscope tools_rpcclient generate_secret autostart
def gradient image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._gradient image selem out out mask mask shift_x shift_x shift_y shift_y
def needs_values func @wraps func def assure_data_present self *args **kwargs self.read return func self *args **kwargs return assure_data_present
def setDebugging on Deferred.debug bool on
def parse_resource resource error_msg 'Resourcesshouldbedefinedas'"'/buckets/<bid>/collections/<cid>'or'<bid>/<cid>'."'withvalidcollectionandbucketids.'from kinto.views import NameGeneratorid_generator NameGenerator parts resource.split '/' if len parts 2 bucket collection partselif len parts 5 _ _ bucket _ collection partselse raise ValueError error_msg if bucket '' or collection '' raise ValueError error_msg if not id_generator.match bucket or not id_generator.match collection raise ValueError error_msg return {'bucket' bucket 'collection' collection}
def onReuqestLogin loginName password clientType datas INFO_MSG 'onReuqestLogin loginName %s clientType %s' % loginName clientType errorno KBEngine.SERVER_SUCCESSif len loginName > 64 errorno KBEngine.SERVER_ERR_NAMEif len password > 64 errorno KBEngine.SERVER_ERR_PASSWORDreturn errorno loginName password clientType datas
def dmp_trunc f p u K return dmp_strip [dmp_rem c p u - 1 K for c in f] u
@check_login_required@check_local_site_accessdef submitter request username grid None template_name u'datagrids/datagrid.html' local_site None if local_site try user local_site.users.get username username except User.DoesNotExist raise Http404else user get_object_or_404 User username username if grid is None or grid u'review-requests' datagrid_cls UserPageReviewRequestDataGridelif grid u'reviews' datagrid_cls UserPageReviewsDataGridelse raise Http404datagrid datagrid_cls request user local_site local_site datagrid.tabs [ UserPageReviewRequestDataGrid.tab_title local_site_reverse u'user' local_site local_site args [username] UserPageReviewsDataGrid.tab_title local_site_reverse u'user-grid' local_site local_site args [username u'reviews'] ]return datagrid.render_to_response template_name
def _usablePyOpenSSL version major minor int part for part in version.split '.' [ 2] return major minor > 0 12
def onFinish pass
def get_value_generators_js all_value_generators value_generators_domain.Registry.get_all_generator_classes value_generators_js ''for _ generator_cls in all_value_generators.iteritems value_generators_js + generator_cls.get_js_template return value_generators_js
def write_global name obj cache_path _global_cache_path _write cache_path name obj
def _VerifyExtensionHandle message extension_handle if not isinstance extension_handle _FieldDescriptor raise KeyError 'HasExtension expectsanextensionhandle got %s' % extension_handle if not extension_handle.is_extension raise KeyError '"%s"isnotanextension.' % extension_handle.full_name if not extension_handle.containing_type raise KeyError '"%s"ismissingacontaining_type.' % extension_handle.full_name if extension_handle.containing_type is not message.DESCRIPTOR raise KeyError 'Extension"%s"extendsmessagetype"%s" butthismessageisoftype"%s".' % extension_handle.full_name extension_handle.containing_type.full_name message.DESCRIPTOR.full_name
def generate_relationship base direction return_fn attrname local_cls referred_cls **kw if return_fn is backref return return_fn attrname **kw elif return_fn is relationship return return_fn referred_cls **kw else raise TypeError 'Unknownrelationshipfunction %s' % return_fn
def is_successful_upgrade upgrade_response if upgrade_response.get_code ! 101 return Falseheaders upgrade_response.get_headers upgrade_value _ headers.iget 'Upgrade' None connection_value _ headers.iget 'Connection' None sec_websocket_accept_value _ headers.iget 'Sec-WebSocket-Accept' None if upgrade_value and connection_value and sec_websocket_accept_value return Truereturn False
def infer_class cls for attr value in cls.__dict__.items if type value is type infer_class setattr cls attr infer_method_signature cls.__name__ value return cls
def show_weights model_path rescale 'individual' border False out None pv get_weights_report.get_weights_report model_path model_path rescale rescale border border if out is None pv.show else pv.save out
@partial.partialdef login_analytics strategy auth_entry *args **kwargs event_name Noneif auth_entry AUTH_ENTRY_LOGIN event_name 'edx.bi.user.account.authenticated'elif auth_entry in [AUTH_ENTRY_ACCOUNT_SETTINGS] event_name 'edx.bi.user.account.linked'if event_name is not None and hasattr settings 'LMS_SEGMENT_KEY' and settings.LMS_SEGMENT_KEY tracking_context tracker.get_tracker .resolve_context analytics.track kwargs['user'].id event_name {'category' 'conversion' 'label' None 'provider' kwargs['backend'].name} context {'ip' tracking_context.get 'ip' 'GoogleAnalytics' {'clientId' tracking_context.get 'client_id' }}
def get_current_thread_object_dict rval dict threading._active_limbo_lock.acquire rval.update threading._active rval.update threading._limbo threading._active_limbo_lock.release return rval
def _passive_handler_func f def func self input f self input return inputreturn func
def dot inp matrix if 'int' in inp.dtype and inp.ndim 2 return matrix[inp.flatten ]elif 'int' in inp.dtype return matrix[inp]elif 'float' in inp.dtype and inp.ndim 3 shape0 inp.shape[0]shape1 inp.shape[1]shape2 inp.shape[2]return TT.dot inp.reshape shape0 * shape1 shape2 matrix else return TT.dot inp matrix
def simplegesture name point_list g Gesture g.add_stroke point_list g.normalize g.name namereturn g
@handle_response_format@treeio_login_required@module_admin_required def group_edit request group_id response_format 'html' group get_object_or_404 Group pk group_id if request.POST if 'cancel' not in request.POST form GroupForm request.POST instance group if form.is_valid group form.save return HttpResponseRedirect reverse 'core_admin_group_view' args [group.id] else return HttpResponseRedirect reverse 'core_admin_group_view' args [group.id] else form GroupForm instance group return render_to_response 'core/administration/group_edit' {'group' group 'form' form} context_instance RequestContext request response_format response_format
def _ignore_CTRL_C_other pass
@LiquidTags.register 'blockdiag' def blockdiag_parser preprocessor tag markup m DOT_BLOCK_RE.search markup if m diagram m.group 'diagram' .strip code markupoutput diag code diagram if output return '<spanclass "blockdiag"style "align center;"><imgsrc "data image/png;base64 %s"></span>' % base64.b64encode output else raise ValueError 'Errorprocessinginput.Expectedsyntax {0}'.format SYNTAX
def fail_on_pylint arg if 'pylint' in arg paver.easy.sh 'exit1' else return
def update_profile_picture_data_url user_id profile_picture_data_url user_settings get_user_settings user_id strict True user_settings.profile_picture_data_url profile_picture_data_url_save_user_settings user_settings
def select_item x t return SelectItem x t
def malt_demo nx False dg DependencyGraph u'PierreNNP2NMOD\nVinkenNNP8SUB\n 2P\n61CD5NMOD\nyearsNNS6AMOD\noldJJ2NMOD\n 2P\nwillMD0ROOT\njoinVB8VC\ntheDT11NMOD\nboardNN9OBJ\nasIN9VMOD\naDT15NMOD\nnonexecutiveJJ15NMOD\ndirectorNN12PMOD\nNov.NNP9VMOD\n29CD16NMOD\n..9VMOD\n' tree dg.tree tree.pprint if nx import networkxfrom matplotlib import pylabg dg.nx_graph g.info pos networkx.spring_layout g dim 1 networkx.draw_networkx_nodes g pos node_size 50 networkx.draw_networkx_labels g pos dg.nx_labels pylab.xticks [] pylab.yticks [] pylab.savefig u'tree.png' pylab.show
def _ModifiedEncoder wire_type encode_value compute_value_size modify_value def SpecificEncoder field_number is_repeated is_packed if is_packed tag_bytes TagBytes field_number wire_format.WIRETYPE_LENGTH_DELIMITED local_EncodeVarint _EncodeVarintdef EncodePackedField write value write tag_bytes size 0for element in value size + compute_value_size modify_value element local_EncodeVarint write size for element in value encode_value write modify_value element return EncodePackedFieldelif is_repeated tag_bytes TagBytes field_number wire_type def EncodeRepeatedField write value for element in value write tag_bytes encode_value write modify_value element return EncodeRepeatedFieldelse tag_bytes TagBytes field_number wire_type def EncodeField write value write tag_bytes return encode_value write modify_value value return EncodeFieldreturn SpecificEncoder
def itemgetter_tuple items if len items 0 return lambda a if len items 1 return lambda gettable gettable[items[0]] return operator.itemgetter *items
def _run_task_hook hooks method task queue_name if hooks is not None try getattr hooks method task queue_name except NotImplementedError return Falsereturn Truereturn False
def generate_java_test target source env target_name str target[0] main_class str source[0] test_jar str source[1] jars []for jar in source[1 ] jars.append os.path.abspath str jar test_class_names _get_all_test_class_names_in_jar test_jar return _generate_java_test target_name main_class jars '' ''.join test_class_names env
def text_concat *args **kwargs separator text_value kwargs.get u'separator' u'' values filter None [text_value v for v in args] return separator.join values
def rosen x x asarray x r numpy.sum 100.0 * x[1 ] - x[ -1 ] ** 2.0 ** 2.0 + 1 - x[ -1 ] ** 2.0 axis 0 return r
def expand_degeneracies raw_primers expanded_primers []for raw_primer in raw_primers primer_seq DNASequence raw_primer.strip for expanded_primer in primer_seq.nondegenerates expanded_primers.append str expanded_primer return expanded_primers
def _is_ignorable_404 uri for start in settings.IGNORABLE_404_STARTS if uri.startswith start return Truefor end in settings.IGNORABLE_404_ENDS if uri.endswith end return Truereturn False
def reconstructor fn fn.__sa_reconstructor__ Truereturn fn
def UTOF val return val
def write_libraries dir libraries files [open os.path.join dir k 'w' for k _ in libraries]for f _ v in zip files libraries v.write_markdown_to_file f for f _ v in zip files libraries v.write_other_members f f.close
def _drop_log_stats drop_log ignore 'IGNORED' if not isinstance drop_log list or not isinstance drop_log[0] list raise ValueError 'drop_logmustbealistoflists' perc 100 * np.mean [ len d > 0 for d in drop_log if not any r in ignore for r in d ] return perc
@real_memoizedef is_netbsd return sys.platform.startswith 'netbsd'
def _prefix_commands command which prefixes list env.command_prefixes cwd env.cwd if which 'remote' else env.lcwd redirect '>/dev/null' if not win32 else '' if cwd prefixes.insert 0 'cd%s%s' % cwd redirect glue '&&'prefix glue.join prefixes + glue if prefixes else '' return prefix + command
@remote_data@pytest.mark.skipif u'notHAS_JPLEPHEM' @pytest.mark.parametrize u'time' Time u'1960-01-1200 00' Time u'1980-03-2500 00' Time u'2010-10-1300 00' def test_get_sun_consistency time sun_jpl_gcrs get_body u'sun' time ephemeris u'de432s' builtin_get_sun get_sun time sep builtin_get_sun.separation sun_jpl_gcrs assert sep < 0.1 * u.arcsec
def _ret_top_ids segmented_topics top_ids set for s_i in segmented_topics for id in chain.from_iterable s_i if isinstance id np.ndarray for i in id top_ids.add i else top_ids.add id return top_ids
def rev_parse committish repo_dir None head read_ref committish repo_dir repo_dir if head debug2 'resolvedfromref commit %s\n' % head.encode 'hex' return headpL PackIdxList repo 'objects/pack' repo_dir repo_dir if len committish 40 try hash committish.decode 'hex' except TypeError return Noneif pL.exists hash return hashreturn None
def _get_adapter_name_and_ip_address network_adapters mac_address adapter_name Noneip_address Nonefor network_adapter in network_adapters if network_adapter['mac-address'] mac_address.lower adapter_name network_adapter['name']ip_address network_adapter['ip-address']breakreturn adapter_name ip_address
def trace_to_dataframe trace chains None varnames None hide_transformed_vars True var_shapes trace._straces[0].var_shapesif varnames is None varnames var_shapes.keys flat_names {v create_flat_names v shape for v shape in var_shapes.items if not hide_transformed_vars and v.endswith '_' }var_dfs []for v shape in var_shapes.items if v in varnames if not hide_transformed_vars or not v.endswith '_' vals trace.get_values v combine True chains chains flat_vals vals.reshape vals.shape[0] -1 var_dfs.append pd.DataFrame flat_vals columns flat_names[v] return pd.concat var_dfs axis 1
def bool_or_str *text def bool_or_value obj if obj in text return objelse return asbool obj return bool_or_value
def _new_versions quay conda sconda set conda squay set quay if quay else set return sconda - squay
def get_sys cmd ''if salt.utils.which 'localectl' cmd 'localectl|grepKeymap|sed-e"s/ / /"-e"s/^[ DCTB ]*//"'elif 'RedHat' in __grains__['os_family'] cmd 'grepLAYOUT/etc/sysconfig/keyboard|grep-vE"^#"'elif 'Debian' in __grains__['os_family'] cmd 'grepXKBLAYOUT/etc/default/keyboard|grep-vE"^#"'elif 'Gentoo' in __grains__['os_family'] cmd 'grep"^keymap"/etc/conf.d/keymaps|grep-vE"^#"'out __salt__['cmd.run'] cmd python_shell True .split ' ' ret out[1].replace '"' '' return ret
def string_to_tokentype s if isinstance s _TokenType return sif not s return Tokennode Tokenfor item in s.split '.' node getattr node item return node
def get_handle global __handle__if not __handle__ __handle__ FT_Library error FT_Init_FreeType byref __handle__ if error raise RuntimeError hex error return __handle__
def heldout_score clf X_test y_test score np.zeros n_estimators dtype np.float64 for i y_pred in enumerate clf.staged_decision_function X_test score[i] clf.loss_ y_test y_pred return score
def CreateExtensionSetting client feed_items campaign_feed feed_item_ids platform_restrictions None campaign_extension_setting_service client.GetService 'CampaignExtensionSettingService' 'v201609' extension_feed_items [{CreateSitelinkFeedItem feed_items feed_item_id } for feed_item_id in feed_item_ids]extension_setting {'extensions' extension_feed_items}if platform_restrictions extension_setting['platformRestrictions'] platform_restrictionscampaign_extension_setting {'campaignId' campaign_feed['campaignId'] 'extensionType' 'SITELINK' 'extensionSetting' extension_setting}operation {'operand' campaign_extension_setting 'operator' 'ADD'}campaign_extension_setting_service.mutate [operation]
def getDecoders decoder_paths import_base os.path.commonprefix decoder_paths .split os.path.sep [ -1 ]decoders {}for path in decoder_paths import_path path.split os.path.sep [len import_base ]for f in glob.iglob '%s/*.py' % path name os.path.splitext os.path.basename f [0]if name ! '__init__' decoders[name] '.'.join import_path + [name] return decoders
def render s context None if context is None context {}t get_env .from_string s return t.render context
def ssl_potential try import sslexcept ImportError return []return [p[9 ] for p in dir ssl if p.startswith 'PROTOCOL_' ]
def check_is_admin roles context None init target {'project_id' ''}if context is None credentials {'roles' roles}else credentials context.to_dict return _ENFORCER.enforce 'context_is_admin' target credentials
def T layer return tf.get_default_graph .get_tensor_by_name '%s 0' % layer
def createKeyPair type bits pkey crypto.PKey pkey.generate_key type bits return pkey
def blend_image img bgcolor u'#ffffff' canvas QImage img.size QImage.Format_RGB32 canvas.fill QColor bgcolor overlay_image img canvas return canvas
def find_gating_milestones course_key content_key None relationship None user None return [m for m in milestones_api.get_course_content_milestones course_key content_key relationship user if GATING_NAMESPACE_QUALIFIER in m.get 'namespace' ]
@then u'weseethenamedquerysaved' def step_see_named_query_saved context _expect_exact context u'Saved.' timeout 1
def p_enum_specifier_2 t pass
def _bootstrap_deb root arch flavor repo_url None static_qemu None pkgs None exclude_pkgs None if repo_url is None repo_url 'http //ftp.debian.org/debian/'deb_args ['debootstrap' '--foreign' '--arch' _cmd_quote arch '--include'] + pkgs + ['--exclude'] + exclude_pkgs + [_cmd_quote flavor _cmd_quote root _cmd_quote repo_url ] __salt__['cmd.run'] deb_args python_shell False __salt__['cmd.run'] 'cp{qemu}{root}/usr/bin/'.format qemu _cmd_quote static_qemu root _cmd_quote root env {'DEBIAN_FRONTEND' 'noninteractive' 'DEBCONF_NONINTERACTIVE_SEEN' 'true' 'LC_ALL' 'C' 'LANGUAGE' 'C' 'LANG' 'C' 'PATH' '/sbin /bin /usr/bin'}__salt__['cmd.run'] 'chroot{root}/debootstrap/debootstrap--second-stage'.format root _cmd_quote root env env __salt__['cmd.run'] 'chroot{root}dpkg--configure-a'.format root _cmd_quote root env env
def rc_params fail_on_error False fname matplotlib_fname if not os.path.exists fname message u'couldnotfindrcfile;returningdefaults'ret RcParams [ key default for key default _ in six.iteritems defaultParams if key not in _all_deprecated ] warnings.warn message return retreturn rc_params_from_file fname fail_on_error
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def review_branch branch choose_ref N_ u'SelectBranchtoReview' N_ u'Review' if not branch returnmerge_base gitcmds.merge_base_parent branch difftool.diff_commits qtutils.active_window merge_base branch
def humanReadableMask mask s []for k v in _FLAG_TO_HUMAN if k & mask s.append v return s
def _inspect_environment app_version os.environ['CURRENT_VERSION_ID'].rsplit '.' 1 [0]conf_version int os.environ.get 'CURRENT_CONFIGURATION_VERSION' '0' development os.environ.get 'SERVER_SOFTWARE' '' .startswith 'Development/' return app_version conf_version development
def check_cycle reg assignments return check_cycle_ reg assignments []
@register u'quoted-insert' def quoted_insert event event.cli.quoted_insert True
def cpu_affinity_by_task pid vcpu_pid cmd "cat/proc/%s/task/%s/status|grepCpus_allowed |awk'{print$2}'" % pid vcpu_pid output system_output cmd ignore_status False return output
def mlarr *args **kwargs arr np.array *args **kwargs arr.shape matdims arr return arr
def _rotateLeft x n return x << n | x >> 32 - n
def truncatewords value arg from django.utils.text import truncate_wordstry length int arg except ValueError return valuereturn truncate_words value length
def snapshot_absent name force False recursive False return _absent name 'snapshot' force recursive
def _get_transformed_points_tps new_points source_points coefficients num_points batch_size to_transform new_points.dimshuffle 0 'x' 1 2 stacked_transform T.tile to_transform 1 num_points 1 1 r_2 T.sum stacked_transform - source_points.dimshuffle 'x' 1 0 'x' ** 2 axis 2 log_r_2 T.log r_2 distances T.switch T.isnan log_r_2 r_2 * log_r_2 0.0 upper_array T.concatenate [T.ones batch_size 1 new_points.shape[2] dtype theano.config.floatX new_points] axis 1 right_mat T.concatenate [upper_array distances] axis 1 new_value T.batched_dot coefficients right_mat return new_value
def _check_for_unit_changes name contextkey 'systemd._check_for_unit_changes.{0}'.format name if contextkey not in __context__ if _untracked_custom_unit_found name or _unit_file_changed name systemctl_reload __context__[contextkey] True
def formList tables ['irs_ireport' 'rms_req' 'cr_shelter' 'pr_person' 'pr_image']xml TAG.forms for tablename in tables xml.append TAG.form get_name tablename _url 'http //' + request.env.http_host + URL f 'create' args tablename response.headers['Content-Type'] 'text/xml'response.view 'xforms.xml'return xml
def getMinimumByPaths elementNode return euclidean.getMinimumByVector3Paths elementNode.xmlObject.getTransformedPaths
def new_entry_id entry cache {} s entry['link'] + entry['title'] .encode 'ascii' 'ignore' return hashlib.md5 s .hexdigest
def _parse_sv8_int fileobj limit 9 num 0for i in xrange limit c fileobj.read 1 if len c ! 1 raise EOFErrorc bytearray c num num << 7 | c[0] & 127 if not c[0] & 128 return num i + 1 if limit > 0 raise ValueErrorreturn 0 0
def cluster_get context id None is_up None get_services False services_summary False read_deleted 'no' name_match_level None **filters return IMPL.cluster_get context id is_up get_services services_summary read_deleted name_match_level **filters
def assert_before lst item1 item2 assert_less lst.index item1 lst.index item2 '{0!r}appearsbefore{1!r}'.format item1 item2
def _quoteAndEscape string assert type string in types.StringTypes return pprint.pformat string
def delete_object url **kwargs client SimpleClient url url client.retry_request 'DELETE' **kwargs
def thread try thread_id int g['stuff'] print_thread g['message_threads'][thread_id] g['original_name'] g['full_name'] except Exception debug_option printNicely red 'Nosuchthread.'
def pkg_resources_get_default_cache egg_cache compat.getenv 'PYTHON_EGG_CACHE' if egg_cache is not None return egg_cacheif os.name ! 'nt' return os.path.expanduser '~/.python-eggs' app_data 'ApplicationData'app_homes [ 'APPDATA' None 'USERPROFILE' app_data 'HOMEDRIVE' 'HOMEPATH' app_data 'HOMEPATH' app_data 'HOME' None 'WINDIR' app_data ]for keys subdir in app_homes dirname ''for key in keys if key in os.environ dirname os.path.join dirname compat.getenv key else breakelse if subdir dirname os.path.join dirname subdir return os.path.join dirname 'Python-Eggs' else raise RuntimeError 'PleasesetthePYTHON_EGG_CACHEenviromentvariable'
def get_rect_xmin data return min data[0][0] data[1][0] data[2][0] data[3][0]
def get_scaling_policy_arn as_group scaling_policy_name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile policies conn.get_all_policies as_group as_group for policy in policies if policy.name scaling_policy_name return policy.policy_arnlog.error 'Couldnotconvert {0}'.format as_group return None
def parse_s3_uri uri components urlparse uri if components.scheme not in 's3' 's3n' or '/' not in components.path raise ValueError 'InvalidS3URI %s' % uri return components.netloc components.path[1 ]
def map_relation_type relation_type if isinstance relation_type ProductCrossSellType return relation_typeattr_name force_ascii relation_type .upper try return getattr ProductCrossSellType attr_name except AttributeError raise LookupError 'UnknownProductCrossSellType%r' % relation_type
def TimeFromTicks ticks return Time *time.localtime ticks [3 6]
def getADB TOOLSDIR try if len settings.ADB_BINARY > 0 and isFileExists settings.ADB_BINARY return settings.ADB_BINARYelse adb 'adb'if platform.system 'Darwin' adb_dir os.path.join TOOLSDIR 'adb/mac/' subprocess.call ['chmod' '777' adb_dir] adb os.path.join TOOLSDIR 'adb/mac/adb' elif platform.system 'Linux' adb_dir os.path.join TOOLSDIR 'adb/linux/' subprocess.call ['chmod' '777' adb_dir] adb os.path.join TOOLSDIR 'adb/linux/adb' elif platform.system 'Windows' adb os.path.join TOOLSDIR 'adb/windows/adb.exe' return adbexcept PrintException '[ERROR]GettingADBLocation' return 'adb'
def getEvaluatedLinkValue word xmlElement if word '' return Noneif getStartsWithCurlyEqualRoundSquare word return getEvaluatedExpressionValue word xmlElement return word
def set_enabled_equivalencies equivalencies context _UnitContext get_current_unit_registry get_current_unit_registry .set_enabled_equivalencies equivalencies return context
def delete_ip call None kwargs None global netconnif not netconn netconn get_conn NetworkManagementClient if kwargs.get 'resource_group' is None kwargs['resource_group'] config.get_cloud_config_value 'resource_group' {} __opts__ search_global True return netconn.public_ip_addresses.delete kwargs['resource_group'] kwargs['ip_name']
def unfreeze name quiet False path None data _do_names name 'unfreeze' path path if data and not quiet __jid_event__.fire_event {'data' data 'outputter' 'lxc_resume'} 'progress' return data
def gcdex_diophantine a b c s g a.half_gcdex b q c.exquo g s q * s if not s.is_zero and b.degree > b.degree q s s.div b t c - s * a .exquo b return s t
def prompt_async message u'' **kwargs kwargs[u'return_asyncio_coroutine'] Truereturn prompt message **kwargs
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def unique values values com._asarray_tuplesafe values f lambda htype caster _unique_object values htype caster return _hashtable_algo f values
def strpdate string format whence datetime.strptime string format return whence.date
def response_status_message status return '%s%s' % status http.responses.get int status
def get_inheritance obj_name obj_type 'file' dacl Dacl obj_name obj_type inherited win32security.INHERITED_ACEfor i in range 0 dacl.dacl.GetAceCount ace dacl.dacl.GetAce i if ace[0][1] & inherited inherited return Truereturn False
@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @common_exceptions_400@require_level 'staff' @require_post_params unique_student_identifier 'emailorusernameofstudentforwhomtogetprogressurl' def get_student_progress_url request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id user get_student_from_identifier request.POST.get 'unique_student_identifier' progress_url reverse 'student_progress' kwargs {'course_id' course_id.to_deprecated_string 'student_id' user.id} response_payload {'course_id' course_id.to_deprecated_string 'progress_url' progress_url}return JsonResponse response_payload
def clear_mappers mapperlib._CONFIGURE_MUTEX.acquire try while _mapper_registry try mapper b _mapper_registry.popitem mapper.dispose except KeyError passfinally mapperlib._CONFIGURE_MUTEX.release
def p_fused_definition s pos ctx if ctx.level not in 'module' 'module_pxd' error pos 'Fusedtypedefinitionnotallowedhere' s.next name p_ident s s.expect ' ' s.expect_newline s.expect_indent types []while s.sy ! 'DEDENT' if s.sy ! 'pass' types.append p_c_base_type s else s.next s.expect_newline s.expect_dedent if not types error pos 'Needatleastonetype' return Nodes.FusedTypeNode pos name name types types
def xxinv mul factor matrices mul.as_coeff_matrices for i X Y in enumerate zip matrices[ -1 ] matrices[1 ] try if X.is_square and Y.is_square and X Y.inverse I Identity X.rows return newmul factor * matrices[ i] + [I] + matrices[ i + 2 ] except ValueError passreturn mul
def _run_horcmgr inst result utils.execute 'env' 'HORCMINST %s' % inst 'horcmgr' '-check' return result[0]
def check_array_instances evaluator instance if not settings.dynamic_array_additions return instance.var_argsai _ArrayInstance evaluator instance from jedi.evaluate import paramreturn param.Arguments evaluator [AlreadyEvaluated [ai] ]
def bfs_tree G source reverse False T nx.DiGraph T.add_node source T.add_edges_from bfs_edges G source reverse reverse return T
def waitUntilAllDisconnected reactor protocols lc Nonedef _check if not True in [x.transport.connected for x in protocols] lc.stop lc task.LoopingCall _check lc.clock reactorreturn lc.start 0.01 now True
def deinstall name portpath _check_portname name old __salt__['pkg.list_pkgs'] result __salt__['cmd.run_all'] ['make' 'deinstall' 'BATCH yes'] cwd portpath python_shell False __context__.pop 'pkg.list_pkgs' None new __salt__['pkg.list_pkgs'] return salt.utils.compare_dicts old new
def validate_scale_values scale if len scale < 2 raise exceptions.PlotlyError 'Youmustinputalistofscalevaluesthathasatleasttwovalues.' if scale[0] ! 0 or scale[ -1 ] ! 1 raise exceptions.PlotlyError 'Thefirstandlastnumberinyourscalemustbe0.0and1.0respectively.' if not all x < y for x y in zip scale scale[1 ] raise exceptions.PlotlyError "'scale'mustbealistthatcontainsastrictlyincreasingsequenceofnumbers."
def _fix_multiple_roots node real_nodes [x for x in node if not isinstance x SKIPPED_ELEMENT_TYPES ]if len real_nodes > 1 data_node etree.Element 'data' for child in node data_node.append child node.append data_node
def lesser_equal x y return tf.less_equal x y
@register u'redraw-current-line' def redraw_current_line event pass
def set_expire name expire pre_info info name if expire pre_info['expire'] return Trueif __grains__['kernel'] 'FreeBSD' cmd ['pw' 'user' 'mod' name '-e' expire]else cmd ['usermod' '-e' expire name]__salt__['cmd.run'] cmd python_shell False post_info info name if post_info['expire'] ! pre_info['expire'] return post_info['expire'] expire
def regenerate_user_certificates student course_key course None forced_grade None template_file None insecure False xqueue XQueueCertInterface if insecure xqueue.use_https Falsegenerate_pdf not has_html_certificates_enabled course_key course return xqueue.regen_cert student course_key course course forced_grade forced_grade template_file template_file generate_pdf generate_pdf
def get_enrollments user_id return _data_api .get_course_enrollments user_id
def connect_to_region region_name **kw_params for region in regions if region.name region_name return region.connect **kw_params return None
@fixturedef io_loop loop ioloop.IOLoop loop.make_current return loop
def pick_channels_regexp ch_names regexp r re.compile regexp return [k for k name in enumerate ch_names if r.match name ]
def get_correct_indentation_diff code filename code_buffer StringIO code output_buffer StringIO reindenter reindent.Reindenter code_buffer reindenter.run reindenter.write output_buffer reindent_output output_buffer.getvalue output_buffer.close if code ! reindent_output diff_generator difflib.unified_diff code.splitlines True reindent_output.splitlines True fromfile filename tofile filename + ' reindented ' diff_tuple map clean_diff_line_for_python_bug_2142 diff_generator diff ''.join diff_tuple return diffelse return None
def create_palette light_color color palette QPalette palette.setColor QPalette.Inactive QPalette.Light saturated light_color 50 palette.setColor QPalette.Inactive QPalette.Midlight saturated light_color 90 palette.setColor QPalette.Inactive QPalette.Button light_color palette.setColor QPalette.Active QPalette.Light saturated color 50 palette.setColor QPalette.Active QPalette.Midlight saturated color 90 palette.setColor QPalette.Active QPalette.Button color palette.setColor QPalette.ButtonText QColor '#515151' return palette
def cubehelix_palette n_colors 6 start 0 rot 0.4 gamma 1.0 hue 0.8 light 0.85 dark 0.15 reverse False as_cmap False cdict mpl._cm.cubehelix gamma start rot hue cmap mpl.colors.LinearSegmentedColormap 'cubehelix' cdict x np.linspace light dark n_colors pal cmap x [ 3].tolist if reverse pal pal[ -1 ]if as_cmap x_256 np.linspace light dark 256 if reverse x_256 x_256[ -1 ]pal_256 cmap x_256 cmap mpl.colors.ListedColormap pal_256 return cmapelse return pal
def get_default_currency company get_default_company if company return frappe.db.get_value u'Company' company u'default_currency'
def oauth_token_info_from_body http_body token Nonetoken_secret Nonefor pair in http_body.split '&' if pair.startswith 'oauth_token ' token urllib.unquote pair[len 'oauth_token ' ] if pair.startswith 'oauth_token_secret ' token_secret urllib.unquote pair[len 'oauth_token_secret ' ] return token token_secret
def _generate_url arg stable url BASE_URLif stable url + 'stable/'else url + 'devel/'if arg is None return urlelif type arg is str url + 'search.html?'url + urlencode {'q' arg} url + '&check_keywords yes&area default'else try func argfunc_name func.__name__func_module func.__module__if not func_module.startswith 'statsmodels.' return ValueError 'Functionmustbefromstatsmodels' url + 'generated/'url + func_module + '.' + func_name + '.html' except return ValueError 'Inputnotunderstood' return url
def extract_auth_vars request if request.META.get 'HTTP_X_SENTRY_AUTH' '' .startswith 'Sentry' return request.META['HTTP_X_SENTRY_AUTH']elif request.META.get 'HTTP_AUTHORIZATION' '' .startswith 'Sentry' return request.META['HTTP_AUTHORIZATION']else args [ '%s %s' % i for i in request.GET.items if i[0].startswith 'sentry_' and i[0] ! 'sentry_data' ]if args return 'Sentry%s' % ' '.join args return None
def newAction parent text slot None shortcut None icon None tip None checkable False enabled True a QAction text parent if icon is not None a.setIcon newIcon icon if shortcut is not None if isinstance shortcut list tuple a.setShortcuts shortcut else a.setShortcut shortcut if tip is not None a.setToolTip tip a.setStatusTip tip if slot is not None a.triggered.connect slot if checkable a.setCheckable True a.setEnabled enabled return a
def auto_decode data for bom encoding in BOMS if data.startswith bom return data[len bom ].decode encoding for line in data.split '\n' [ 2] if line[0 1] '#' and ENCODING_RE.search line encoding ENCODING_RE.search line .groups [0].decode 'ascii' return data.decode encoding return data.decode locale.getpreferredencoding False
def remove_tap module brew_path tap failed changed msg False False '' if not a_valid_tap tap failed Truemsg 'notavalidtap %s' % tap elif already_tapped module brew_path tap if module.check_mode module.exit_json changed True rc out err module.run_command [brew_path 'untap' tap] if not already_tapped module brew_path tap changed Truemsg 'successfullyuntapped %s' % tap else failed Truemsg 'failedtountap %s' % tap else msg 'alreadyuntapped %s' % tap return failed changed msg
def mock_streams which both which 'both' stdout which 'stdout' or both stderr which 'stderr' or both def mocked_streams_decorator func @wraps func def inner_wrapper *args **kwargs if both sys.stdall StringIO fake_stdout CarbonCopy cc sys.stdall fake_stderr CarbonCopy cc sys.stdall else fake_stdout fake_stderr StringIO StringIO if stdout my_stdout sys.stdout sys.stdout fake_stdout if stderr my_stderr sys.stderr sys.stderr fake_stderr try func *args **kwargs finally if stdout sys.stdout my_stdoutif stderr sys.stderr my_stderrif both del sys.stdallreturn inner_wrapperreturn mocked_streams_decorator
def push_mirrors config git_dir log logging.getLogger 'gitosis.mirror.push_mirrors' repository_dir os.path.abspath util.getRepositoryDir config git_dir os.path.abspath git_dir git_name get_git_name repository_dir git_dir log.info "Updating%s'smirrors." % git_name for remote in get_mirrors config git_name log.info 'Updating%s.' % remote repository.mirror git_dir remote
def auth_backends request return {u'auth_backends' get_enabled_auth_backends }
def notify_new_suggestion unit suggestion user mails []subscriptions Profile.objects.subscribed_new_suggestion unit.translation.subproject.project unit.translation.language user for subscription in subscriptions mails.append subscription.notify_new_suggestion unit.translation suggestion unit send_mails mails
def detect_config_path try proc subprocess.Popen ['nginx' '-V'] stderr subprocess.PIPE except OSError error_exit 'Accesslogfileorformatwasnotsetandnginxconfigfilecannotbedetected.' + 'PerhapsnginxisnotinyourPATH?' stdout stderr proc.communicate version_output stderr.decode 'utf-8' conf_path_match re.search '--conf-path \\S* ' version_output if conf_path_match is not None return conf_path_match.group 1 prefix_match re.search '--prefix \\S* ' version_output if prefix_match is not None return prefix_match.group 1 + '/conf/nginx.conf' return '/etc/nginx/nginx.conf'
def list_extractors age_limit return sorted filter lambda ie ie.is_suitable age_limit gen_extractors key lambda ie ie.IE_NAME.lower
def normalize_keys_upper data return dict key.upper val for key val in data.items
def lowstate_file_refs chunks refs {}for chunk in chunks saltenv 'base'crefs []for state in chunk if state '__env__' saltenv chunk[state]elif state 'saltenv' saltenv chunk[state]elif state.startswith '__' continuecrefs.extend salt_refs chunk[state] if crefs if saltenv not in refs refs[saltenv] []refs[saltenv].append crefs return refs
def libvlc_video_set_adjust_float p_mi option value f _Cfunctions.get 'libvlc_video_set_adjust_float' None or _Cfunction 'libvlc_video_set_adjust_float' 1 1 1 None None MediaPlayer ctypes.c_uint ctypes.c_float return f p_mi option value
def roots_sh_legendre n mu False x w roots_legendre n x x + 1 / 2 w / 2if mu return x w 1.0 else return x w
def attempt_read_and_call uhandle method **keywds line safe_readline uhandle passed not _fails_conditions * line **keywds if passed method line else uhandle.saveline line return passed
def cuckoo_analysis target options submit_job target options def read_cuckoo_output return CuckooTests.cuckoo.stderr.readline .rstrip def is_completion line return None ! re.search '.*Task#[0-9]{3} analysis.*completed' line def is_error line if re.search '.*ERROR Analysisfailed ' line ! None raise Exception 'Cuckooanalysisfailed' line read_cuckoo_output while not is_completion line and not is_error line line read_cuckoo_output return latest_analysis_results
def has_html_certificates_enabled course_key course None if not settings.FEATURES.get 'CERTIFICATES_HTML_VIEW' False return Falseif not course if not isinstance course_key CourseKey try course_key CourseKey.from_string course_key except InvalidKeyError log.warning 'Unabletoparsecourse_key"%s"' course_key exc_info True return Falsetry course CourseOverview.get_from_id course_key except log.warning 'UnabletoloadCourseOverviewobjectforcourse_key"%s"' unicode course_key exc_info True return course.cert_html_view_enabled if course else False
def task_doctest return {'actions' ['py.test--doctest-modulesnikola/'] 'verbosity' 2}
def boykov_kolmogorov G s t capacity 'capacity' residual None value_only False cutoff None R boykov_kolmogorov_impl G s t capacity residual cutoff R.graph['algorithm'] 'boykov_kolmogorov'return R
def has_plugin_permission user plugin_type permission_type from cms.plugin_pool import plugin_poolplugin_class plugin_pool.get_plugin plugin_type codename get_model_permission_codename plugin_class.model action permission_type return user.has_perm codename
def register_vcs_handler vcs method def decorate f 'StorefinHANDLERS[vcs][method].'if vcs not in HANDLERS HANDLERS[vcs] {}HANDLERS[vcs][method] freturn freturn decorate
def render_subcommand args if args.subcommand 'delete' return 'delete' + args.delete_subcommand if args.subcommand in 'wal-prefetch' 'wal-push' 'wal-fetch' return Nonereturn args.subcommand
def _check_mayavi_version min_version '4.3.0' if not check_version 'mayavi' min_version raise RuntimeError 'Needmayavi> %s' % min_version
def sanitize_filename filename if isinstance filename str unicode filename re.sub u'[\\\\/\\*]' u'-' filename filename re.sub u'[ "<>|?]' u'' filename filename re.sub u'\u2122' u'' filename filename filename.strip u'.' return filenamereturn u''
def _parse_snapshot_description snapshot unix_time False ret dict tree ElementTree.fromstring snapshot.getXMLDesc for node in tree if node.tag 'name' ret['name'] node.textelif node.tag 'creationTime' ret['created'] not unix_time and datetime.datetime.fromtimestamp float node.text .isoformat '' or float node.text elif node.tag 'state' ret['running'] node.text 'running' ret['current'] snapshot.isCurrent 1 return ret
def rand *shape return backend.id_srand np.prod shape .reshape shape
def stripTags s intag [False]def chk c if intag[0] intag[0] c ! '>' return Falseelif c '<' intag[0] Truereturn Falsereturn Truereturn ''.join c for c in s if chk c
def _on_property_usage prop_name stacklevel stacklevel + 1deprecated_to_new_props {'slavename' 'workername'}if prop_name in deprecated_to_new_props reportDeprecatedWorkerNameUsage "Property'{old_name}'isdeprecated use'{new_name}'instead.".format old_name prop_name new_name deprecated_to_new_props[prop_name] stacklevel stacklevel
def _format_number is_negative intpart fracpart exp spec sign _format_sign is_negative spec if fracpart or spec['alt'] fracpart spec['decimal_point'] + fracpart if exp ! 0 or spec['type'] in 'eE' echar {'E' 'E' 'e' 'e' 'G' 'E' 'g' 'e'}[spec['type']]fracpart + '{0}{1 +}'.format echar exp if spec['type'] '%' fracpart + '%'if spec['zeropad'] min_width spec['minimumwidth'] - len fracpart - len sign else min_width 0intpart _insert_thousands_sep intpart spec min_width return _format_align sign intpart + fracpart spec
@_replaceIf _PY3 passthru @_replaceIf not _shouldEnableNewStyle _ensureOldClass def _oldStyle cls _ensureOldClass cls _bases cls.__bases__ + object return type cls.__name__ _bases cls.__dict__
def assure_check fnc @wraps fnc def _wrapped self check *args **kwargs if not isinstance check CloudMonitorCheck check self._check_manager.get check return fnc self check *args **kwargs return _wrapped
def item_category table s3db.supply_item_categorys3.filter table.can_be_asset True field table.can_be_assetfield.readable field.writable Falsefield.default Truereturn s3_rest_controller 'supply' 'item_category'
def formstyle_foundation form fields *args **kwargs def render_row row_id label widget comment hidden False if hasattr widget 'element' submit widget.element 'input' _type 'submit' if submit submit.add_class 'smallprimarybutton' _class 'form-rowrowhide' if hidden else 'form-rowrow' hints DIV render_tooltip label comment _class 'inline-tooltip' controls DIV label DIV widget hints _class 'controls' _class 'small-12columns' return DIV controls _class _class _id row_id if args row_id formlabel fields widget comment argshidden kwargs.get 'hidden' False return render_row row_id label widget comment hidden else parent TAG[''] for row_id label widget comment in fields parent.append render_row row_id label widget comment return parent
def _generateMetricsSubstitutions options tokenReplacements options['loggedMetrics'] ['.*'] metricList optimizeMetricLabel _generateMetricSpecs options metricListString ' \n'.join metricList metricListString _indentLines metricListString 2 indentFirstLine False permOptimizeSettingStr 'minimize "%s"' % optimizeMetricLabel loggedMetricsListAsStr '[%s]' % ' '.join [ "'%s'" % ptrn for ptrn in options['loggedMetrics']] tokenReplacements['\\$LOGGED_METRICS'] loggedMetricsListAsStrtokenReplacements['\\$METRICS'] metricListStringtokenReplacements['\\$PERM_OPTIMIZE_SETTING'] permOptimizeSettingStr
def generateRSAKey bits implementations ['openssl' 'python'] for implementation in implementations if implementation 'openssl' and cryptomath.m2cryptoLoaded return OpenSSL_RSAKey.generate bits elif implementation 'python' return Python_RSAKey.generate bits raise ValueError 'Noacceptableimplementations'
def _evalf func points derivatives False method 'RK4' ann func.annihilatora ann.orderR ann.parent.baseK R.get_field if method 'Euler' meth _eulerelse meth _rk4dmf []for j in ann.listofpoly dmf.append K.new j.rep red [ - dmf[i] / dmf[a] for i in range a ]y0 func.y0if len y0 < a raise TypeError 'NotEnoughInitialConditions' x0 func.x0sol [meth red x0 points[0] y0 a ]for i j in enumerate points[1 ] sol.append meth red points[i] j sol[ -1 ] a if not derivatives return [sympify i[0] for i in sol]else return sympify sol
@image_comparison baseline_images [u'tight_layout1'] def test_tight_layout1 fig plt.figure ax fig.add_subplot 111 example_plot ax fontsize 24 plt.tight_layout
def _readline_workaround if not sys.platform.startswith 'win32' returntry import readlineexcept ImportError pass
def reflection_matrix point normal normal unit_vector normal[ 3] M numpy.identity 4 M[ 3 3] - 2.0 * numpy.outer normal normal M[ 3 3] 2.0 * numpy.dot point[ 3] normal * normal return M
def dict_to_protobuf pb_klass_or_instance values type_callable_map REVERSE_TYPE_CALLABLE_MAP strict True if isinstance pb_klass_or_instance Message instance pb_klass_or_instanceelse instance pb_klass_or_instance return _dict_to_protobuf instance values type_callable_map strict
def __LoadModule path name 'module' try if sys.version_info[0] < 3 import impreturn imp.load_source name path elif sys.version_info[1] < 5 from importlib.machinery import SourceFileLoaderreturn SourceFileLoader name path .load_module else import importlib.utilspec importlib.util.spec_from_file_location name path rv importlib.util.module_from_spec spec spec.loader.exec_module rv return rvexcept return None
def do_upper s return soft_unicode s .upper
def build_vocab data counter collections.Counter data count_pairs sorted counter.items key lambda x - x[1] x[0] words _ list zip *count_pairs word_to_id dict zip words range len words return word_to_id
def blended_transform_factory x_transform y_transform if isinstance x_transform Affine2DBase and isinstance y_transform Affine2DBase return BlendedAffine2D x_transform y_transform return BlendedGenericTransform x_transform y_transform
def _get_params mapper_spec allowed_keys None if 'output_writer' not in mapper_spec.params message "Outputwriter'sparametersshouldbespecifiedinoutput_writersubdictionary."if allowed_keys raise errors.BadWriterParamsError message params mapper_spec.paramsparams dict str n v for n v in params.iteritems else if not isinstance mapper_spec.params.get 'output_writer' dict raise errors.BadWriterParamsError 'Outputwriterparametersshouldbeadictionary' params mapper_spec.params.get 'output_writer' params dict str n v for n v in params.iteritems if allowed_keys params_diff set params.keys - allowed_keys if params_diff raise errors.BadWriterParamsError 'Invalidoutput_writerparameters %s' % ' '.join params_diff return params
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def image_shape img if hasattr img 'shape' return img.shape[1] img.shape[0] return img.width img.height
def isHexEncodedString subject return re.match '\\A[0-9a-fA-Fx]+\\Z' subject is not None
def get_complete_url backend_name if not any provider.Registry.get_enabled_by_backend_name backend_name raise ValueError 'Providerwithbackend%snotenabled' % backend_name return _get_url 'social complete' backend_name
def main_for_service reactor service service.startService stop Deferred reactor.addSystemEventTrigger 'before' 'shutdown' _chain_stop_result service stop return stop
def target def prep r if r.interactive if r.component_name 'collection' record r.recordtable s3db.dc_collectiontable.location_id.default record.location_idtable.template_id.default record.template_idreturn Trues3.prep prepreturn s3_rest_controller rheader s3db.dc_rheader
def equateRectangularDotY point returnValue point.y returnValue
def test_editable_list_special_pks app db admin setup class Model1 db.Model def __init__ self id None val1 None self.id idself.val1 val1id db.Column db.String 20 primary_key True val1 db.Column db.String 20 db.create_all view CustomModelView Model1 db.session column_editable_list ['val1'] admin.add_view view db.session.add Model1 '1-1' 'test1' db.session.add Model1 '1-5' 'test2' db.session.commit client app.test_client rv client.post '/admin/model1/ajax/update/' data {'list_form_pk' '1-1' 'val1' 'change-success-1'} data rv.data.decode 'utf-8' ok_ 'Recordwassuccessfullysaved.' data rv client.get '/admin/model1/' data rv.data.decode 'utf-8' ok_ 'change-success-1' in data
def set_cuda_disabled global cuda_available cuda_warning_is_displayedcuda_available False
def _wikify_one language pat page_title pat.group 2 if pat.group 1 page_name pat.group 1 .rstrip '|' else page_name page_titleif ' ' in page_name and not page_name.startswith 'http' parts page_name.split ' ' 2 if page_name page_title page_title parts[1]link "<ahref '%s'>%s</a>" % pageurl page_name language page_title return link
def finder_for_path path result Nonepkgutil.get_importer path loader sys.path_importer_cache.get path finder _finder_registry.get type loader if finder module _dummy_modulemodule.__file__ os.path.join path u'' module.__loader__ loaderresult finder module return result
def _verify_alphabet sequence letters sequence.alphabet.lettersif not letters raise ValueError 'Alphabetdoesnotdefineletters.' for letter in sequence if letter not in letters return Falsereturn True
def test_install_wheel_with_root script data root_dir script.scratch_path / 'root' result script.pip 'install' 'simple.dist 0.1' '--root' root_dir '--no-index' '--find-links ' + data.find_links assert Path 'scratch' / 'root' in result.files_created
def truediv a b return a / b
def mayContainTextNodes node try return node.mayContainTextNodesexcept AttributeError passresult Trueif node.nodeType ! 1 result Falseelif node.namespaceURI ! NS['SVG'] result Trueelif node.nodeName in ['rect' 'circle' 'ellipse' 'line' 'polygon' 'polyline' 'path' 'image' 'stop'] result Falseelif node.nodeName in ['g' 'clipPath' 'marker' 'mask' 'pattern' 'linearGradient' 'radialGradient' 'symbol'] result Falsefor child in node.childNodes if mayContainTextNodes child result Truenode.mayContainTextNodes resultreturn result
def track_state_change entity_ids from_state None to_state None def track_state_change_decorator action 'Decoratortotrackstatechanges.'event.track_state_change HASS entity_ids functools.partial action HASS from_state to_state return actionreturn track_state_change_decorator
def _synthesize_stim_channel events n_samples onset events[ 0]stim_channel np.zeros n_samples int for onset duration trigger in events stim_channel[onset onset + duration ] triggerreturn stim_channel
def ln label label_len len label + 2 chunk 70 - label_len // 2 out '%s%s%s' % '-' * chunk label '-' * chunk pad 70 - len out if pad > 0 out out + '-' * pad return out
def _xr_to_keyset line tkns [elm for elm in line.strip .split ' ' 1 if elm]if len tkns 1 return "'{0}' ".format tkns[0] else key val tknsreturn "'{0}' '{1}' ".format key.strip val.strip
def test_represent_xgate circuit XGate 0 * Qubit '00' answer represent circuit nqubits 2 assert Matrix [0 1 0 0] answer
def format_code entry code ''for line in entry.split '\n' code + '\n{G>>>{n%s' % line return code.strip
def _prog shell_cmd if not util.exe_exists shell_cmd plug_util.path_surgery shell_cmd if not util.exe_exists shell_cmd return Nonereturn os.path.basename shell_cmd
def display_options options settings table []for idx opt in enumerate options.keys tmp []tmp.append idx + 1 tmp.append options[opt].display tmp.append options[opt].getStr tmp.append options[opt].type tmp.append options[opt].required table.append tmp if len table > 0 config.pptable [settings] + table else Msg ' DCTB Modulehasnooptions.' print color.B_YELLOW + '0' + color.B_GREEN + ' ' + color.B_WHITE + 'Back' + color.END return table
def loadMeshes filename ext os.path.splitext filename [1].lower if ext '.stl' return stl.loadScene filename if ext '.obj' return obj.loadScene filename if ext '.dae' return dae.loadScene filename if ext '.amf' return amf.loadScene filename print 'Error Unknownmodelextension %s' % ext return []
def get_exps_unresolved_answers_for_default_rule exp_ids def _get_explorations_states_tuples_by_ids exp_ids "Returnsalistofall exp_id state_name tuplesforthegiven\nexp_ids.\nE.g.-[\n 'eid1' 'Introduction' \n 'eid1' 'End' \n 'eid2' 'Introduction' \n 'eid3' 'Introduction' \n]\nwhenexp_ids ['eid1' 'eid2' 'eid3'].\n"explorations exp_services.get_multiple_explorations_by_id exp_ids strict False return [ exploration.id state_name for exploration in explorations.values for state_name in exploration.states]explorations_states_tuples _get_explorations_states_tuples_by_ids exp_ids exploration_states_answers_list get_top_state_rule_answers_multi explorations_states_tuples [exp_domain.DEFAULT_RULESPEC_STR] exps_answers_mapping {}for ind statewise_answers in enumerate exploration_states_answers_list exp_id explorations_states_tuples[ind][0]if exp_id not in exps_answers_mapping exps_answers_mapping[exp_id] {'count' 0 'unresolved_answers' []}for answer in statewise_answers exps_answers_mapping[exp_id]['count'] + answer['count']answer['state'] explorations_states_tuples[ind][1]exps_answers_mapping[exp_id]['unresolved_answers'].extend statewise_answers for exp_id in exps_answers_mapping exps_answers_mapping[exp_id]['unresolved_answers'] sorted exps_answers_mapping[exp_id]['unresolved_answers'] key lambda a a['count'] reverse True return exps_answers_mapping
def generate_test_cases for p in sickbeard.providers.__all__ provider sickbeard.providers.getProviderModule p .providerif provider.supports_backlog and provider.provider_type u'torrent' and provider.public generated_class type str provider.name BaseParser.TestCase {u'provider' provider} globals [generated_class.__name__] generated_classdel generated_class
def make_union *transformers **kwargs n_jobs kwargs.pop 'n_jobs' 1 if kwargs raise TypeError 'Unknownkeywordarguments "{}"'.format list kwargs.keys [0] return FeatureUnion _name_estimators transformers n_jobs n_jobs
def get_theme_path theme return theme
def test_merge_duplicate_keys merge_log_err packages {'pack_1' {'input_select' {'ib1' None}}}config {config_util.CONF_CORE {config_util.CONF_PACKAGES packages} 'input_select' {'ib1' None}}config_util.merge_packages_config config packages assert merge_log_err.call_count 1 assert len config 2 assert len config['input_select'] 1
def attach_userstory_statuses queryset as_field 'userstory_statuses_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json projects_userstorystatus \nORDERBYprojects_userstorystatus.order\n \nFROMprojects_userstorystatus\nWHEREprojects_userstorystatus.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def c_moves_n client return 'north'
def foo pass
def is_not a b return a is not b
def recursively_remove_key obj key_to_remove if isinstance obj list for item in obj recursively_remove_key item key_to_remove elif isinstance obj dict if key_to_remove in obj del obj[key_to_remove]for key unused_value in obj.items recursively_remove_key obj[key] key_to_remove
def _exit_status retcode ret {0 'Successfulcompletion.' 1 'Anerroroccurred.' 2 'Usageerror.'}[retcode]return ret
def _init_externals if __version__ 'git' sys.path.insert 0 osp.join osp.dirname __file__ 'ext' 'gitdb' try import gitdbexcept ImportError raise ImportError "'gitdb'couldnotbefoundinyourPYTHONPATH"
def test_api_create_invalid_membership_no_email_no_user client user f.UserFactory.create role f.RoleFactory.create client.login role.project.owner url reverse 'memberships-list' data {'role' role.pk 'project' role.project.pk}response client.json.post url json.dumps data assert response.status_code 400 response.dataassert user.memberships.count 0
def compare_region_length r1 r2 r1 r1 r2 r2 s1 r1[1] - r1[0] s2 r2[1] - r2[0] return int s2 - s1
def check_stats_permission request addon for_contributions False if addon.public_stats and not for_contributions returnif not request.user.is_authenticated raise PermissionDeniedif not for_contributions if addon.has_author request.user or acl.action_allowed request 'Stats' 'View' returnelif addon.has_author request.user or acl.action_allowed request 'RevenueStats' 'View' returnraise PermissionDenied
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def is_unedited_config_file content template_content None content content.encode u'latin-1' content re.sub '\njquery_url\\s* \\s*[^\n]+' '' content buffer io.BytesIO content buffer.seek 0 raw_cfg configobj.ConfigObj buffer interpolation True for v in six.itervalues raw_cfg if len v breakelse return Trueknown_configs set [u'7d4b4f1120304b286d71f205975b1286' u'5df7e409425e5bfe7ed041513fda3288' u'8355f99a01b3bdfd8761ef45d5d8b7e5' u'4ea5a84de146dc3fcea2a5b93735e634'] md5 hashlib.md5 md5.update content digest md5.hexdigest return digest in known_configs
def create_task **kwargs owner kwargs.pop 'owner' None if not owner owner UserFactory.create project kwargs.pop 'project' None if project is None project ProjectFactory.create owner owner defaults {'project' project 'owner' owner 'status' TaskStatusFactory.create project project 'milestone' MilestoneFactory.create project project 'user_story' UserStoryFactory.create project project owner owner }defaults.update kwargs return TaskFactory.create **defaults
def numToString num numDigits if not isinstance num int return -1 'Badnumber' strNum str num if numDigits < len strNum return -1 'Baddigitnumber' for i in range numDigits - len strNum strNum '0' + strNum return 0 strNum
def get_qiime_project_dir current_file_path abspath __file__ current_dir_path dirname current_file_path return dirname current_dir_path
def versioned_hmac secret body global_version GLOBAL_TOKEN_VERSION assert global_version < GLOBAL_TOKEN_VERSION "Invalidversionsigningversion'%s'!" % global_version return hmac.new secret body hashlib.sha256 .hexdigest
def parse_request_uri uri if uri '*' return None None uri i uri.find ' //' if i > 0 and '?' not in uri[ i] scheme remainder uri[ i].lower uri[ i + 3 ] authority path remainder.partition '/' [ 2]path '/' + path return scheme authority path if uri.startswith '/' return None None uri else return None uri None
def get_change_summary model1 model2 changes get_changes_between_models model1 model2 ['search_text'] change_descriptions []for field delta in changes.items change_descriptions.append _ "% field schangedfrom'% old_value s'to'% new_value s'" % {'field' field 'old_value' delta[0] 'new_value' delta[1]} return '\n'.join change_descriptions
def calibration prob outcome n_bins 10 prob np.array prob outcome np.array outcome c 0.0judgement_bins np.arange n_bins + 1 / n_bins bin_num np.digitize prob judgement_bins for j_bin in np.unique bin_num in_bin bin_num j_bin predicted_prob np.mean prob[in_bin] true_bin_prob np.mean outcome[in_bin] c + np.sum in_bin * predicted_prob - true_bin_prob ** 2 return c / len prob
def align_down alignment x a alignmentreturn x // a * a
def decipher_kid_rsa msg key n d keyreturn msg * d % n
def render_icon icon **kwargs attrs {u'class' add_css_class u'glyphiconglyphicon-{icon}'.format icon icon kwargs.get u'extra_classes' u'' }title kwargs.get u'title' if title attrs[u'title'] titlereturn render_tag u'span' attrs attrs
def exec_command_stdout *command_args **kwargs encoding kwargs.pop 'encoding' None kwargs['universal_newlines'] encoding is None stdout subprocess.check_output command_args **kwargs return stdout if encoding is None else stdout.decode encoding
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_spontaneous_environment *args try env _spontaneous_environments.get args except TypeError return Environment *args if env is not None return env_spontaneous_environments[args] env Environment *args env.shared Truereturn env
def inv a try return np.linalg.inv a except linalg.LinAlgError return np.linalg.pinv a
def test_import_raises nt.assert_raises ImportError import_item 'IPython.foobar'
def salt_call import salt.cli.callif '' in sys.path sys.path.remove '' client salt.cli.call.SaltCall _install_signal_handlers client client.run
def getUnifiedOutput outputs if len outputs < 1 return {'trianglemesh' {'vertex' [] 'face' []}}if len outputs < 2 return outputs[0]return {'union' {'shapes' outputs}}
@RegisterWithArgChecks name 'neighbor.out_filter.get' req_args [neighbors.IP_ADDRESS] def get_neighbor_out_filter neigh_ip_address core CORE_MANAGER.get_core_service ret core.peer_manager.get_by_addr neigh_ip_address .out_filtersreturn ret
def get_exponential_symbol locale LC_NUMERIC return Locale.parse locale .number_symbols.get 'exponential' u'E'
def convert in_file in_format out_file out_format in_kwargs None out_kwargs None if in_kwargs is None in_kwargs {}if out_kwargs is None out_kwargs {}qresults parse in_file in_format **in_kwargs return write qresults out_file out_format **out_kwargs
@docfillerdef mat_reader_factory file_name appendmat True **kwargs byte_stream _open_file file_name appendmat mjv mnv get_matfile_version byte_stream if mjv 0 return MatFile4Reader byte_stream **kwargs elif mjv 1 return MatFile5Reader byte_stream **kwargs elif mjv 2 raise NotImplementedError 'PleaseuseHDFreaderformatlabv7.3files' else raise TypeError 'Didnotrecognizeversion%s' % mjv
def get_hwclock_seconds utc True cmd '/sbin/hwclock--debug'if utc cmd + '--utc'hwclock_output utils.system_output cmd ignore_status True match re.search ' [0-9]+ secondssince.+ -?[0-9.]+ seconds$' hwclock_output re.DOTALL if match seconds int match.group 1 + float match.group 2 logging.debug 'hwclockseconds %f' % seconds return secondsraise ValueError 'Unabletoreadthehardwareclock--' + hwclock_output
def ec2_vol_id_to_uuid ec2_id ctxt context.get_admin_context int_id ec2_id_to_id ec2_id return get_volume_uuid_from_int_id ctxt int_id
def image_from_data data if isinstance data QImage return datai QImage if not i.loadFromData data raise NotImage u'Notavalidimage' return i
def get_repository_dir name if name 'spinnaker' return os.path.abspath os.path.join os.path.dirname __file__ '..' else return name
def isInline beginComplex centerComplex endComplex centerBeginComplex beginComplex - centerComplex centerEndComplex endComplex - centerComplex centerBeginLength abs centerBeginComplex centerEndLength abs centerEndComplex if centerBeginLength < 0.0 or centerEndLength < 0.0 return FalsecenterBeginComplex / centerBeginLengthcenterEndComplex / centerEndLengthreturn euclidean.getDotProduct centerBeginComplex centerEndComplex < -0.999
def test_logo logo data.logo assert_equal logo.ndim 3 assert_equal logo.shape[2] 4
def qUri s return resolve_uri s namespaces NAMESPACES xml_style True
def add_or_update_enrollment_attr user_id course_id attributes for attribute in attributes _ENROLLMENT_ATTRIBUTES.append {'namespace' attribute['namespace'] 'name' attribute['name'] 'value' attribute['value']}
def laguerre n monic False if n < 0 raise ValueError 'nmustbenonnegative.' if n 0 n1 n + 1 else n1 n x w mu0 roots_laguerre n1 mu True if n 0 x w [] [] hn 1.0kn -1 ** n / _gam n + 1 p orthopoly1d x w hn kn lambda x exp - x 0 inf monic lambda x eval_laguerre n x return p
def wait_for_master topology def get_master try return topology.select_server writable_server_selector 0 except ConnectionFailure return Nonereturn wait_until get_master 'findmaster'
def open_cover_tilt hass entity_id None data {ATTR_ENTITY_ID entity_id} if entity_id else None hass.services.call DOMAIN SERVICE_OPEN_COVER_TILT data
def build_name registry xml_parent data bsetter XML.SubElement xml_parent 'org.jenkinsci.plugins.buildnamesetter.BuildNameSetter' XML.SubElement bsetter 'template' .text data['name']
def gen_arg_type fn mod fn.modulefnty fn.type.pointeeconsts [lc.MetaDataString.get mod str a for a in fnty.args]name lc.MetaDataString.get mod 'kernel_arg_type' return lc.MetaData.get mod [name] + consts
def invalidate_generated_certificates course_id enrolled_students certificate_statuses certificates GeneratedCertificate.objects.filter user__in enrolled_students course_id course_id status__in certificate_statuses certificates.update status CertificateStatuses.unavailable verify_uuid '' download_uuid '' download_url '' grade ''
def get_spec_tests spec_test_dir print 'pystache spectests using%s' % _get_parser_info cases []spec_test_dir os.path.abspath spec_test_dir spec_paths glob.glob os.path.join spec_test_dir '*.%s' % file_extension for path in spec_paths new_cases _read_spec_tests path cases.extend new_cases spec_test_count len cases class CheckSpecTestsFound unittest.TestCase def runTest self if spec_test_count > 0 returnraise Exception 'Spectestsnotfound--\nin%s\nConsulttheREADMEfileonhowtoaddtheMustachespectests.' % repr spec_test_dir case CheckSpecTestsFound cases.append case return cases
def _clear_plugins global plugin_storeplugin_store {'imread' [] 'imsave' [] 'imshow' [] 'imread_collection' [] 'imshow_collection' [] '_app_show' []}
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def get_rendition_upload_to instance filename return instance.get_upload_to filename
def Dispatch dispatch userName None resultCLSID None typeinfo None UnicodeToString None clsctx pythoncom.CLSCTX_SERVER assert UnicodeToString is None 'thisisdeprecatedandwillgoaway' dispatch userName dynamic._GetGoodDispatchAndUserName dispatch userName clsctx return __WrapDispatch dispatch userName resultCLSID typeinfo clsctx clsctx
@command 'mv\\s* %s\\s+%s ' % WORD WORD def playlist_rename playlists_ a b '' playlists_.split '' while a not in g.userpl a a + '' + b.pop 0 .strip if not b and a not in g.userpl g.message util.F 'noplmatchforrename' g.content g.content or content.playlists_display returnb '-'.join b g.userpl[b] Playlist b g.userpl[b].songs list g.userpl[a].songs playlist_remove a g.message util.F 'plrenamed' % a b playlists.save
def write_conditional_formatting worksheet wb worksheet.parentfor range_string rules in iteritems worksheet.conditional_formatting.cf_rules cf Element 'conditionalFormatting' {'sqref' range_string} for rule in rules if rule.dxf is not None if rule.dxf ! DifferentialStyle rule.dxfId len wb._differential_styles wb._differential_styles.append rule.dxf cf.append rule.to_tree yield cf
@dual_decoratordef enforce_ids_param position 1 @decoratordef wrapper function *args **kw if not isinstance args[position] list tuple or not all [isinstance e basestring for e in args[position]] raise ValueError u'Invalidparamtypeinposition%s;expectedids didyoupassdictionaries? ' % position return function *args **kw return wrapper
def load_class_by_alias_or_classname namespace name if not name LOG.error _LE 'Aliasorclassnameisnotset' raise ImportError _ 'Classnotfound.' try mgr _SilentDriverManager namespace name class_to_load mgr.driverexcept RuntimeError e1_info sys.exc_info try class_to_load importutils.import_class name except ImportError ValueError LOG.error _LE 'Errorloadingclassbyalias' exc_info e1_info LOG.error _LE 'Errorloadingclassbyclassname' exc_info True raise ImportError _ 'Classnotfound.' return class_to_load
def maximum_flow G s t capacity 'capacity' flow_func None **kwargs if flow_func is None if kwargs raise nx.NetworkXError 'Youhavetoexplicitlysetaflow_funcifyouneedtopassparametersviakwargs.' flow_func default_flow_funcif not callable flow_func raise nx.NetworkXError 'flow_funchastobecallable.' R flow_func G s t capacity capacity value_only False **kwargs flow_dict build_flow_dict G R return R.graph['flow_value'] flow_dict
def boxcox x lmbda None alpha None x np.asarray x if x.size 0 return xif any x < 0 raise ValueError 'Datamustbepositive.' if lmbda is not None return special.boxcox x lmbda lmax boxcox_normmax x method 'mle' y boxcox x lmax if alpha is None return y lmax else interval _boxcox_conf_interval x lmax alpha return y lmax interval
def secgroup_allocate call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thesecgroup_allocatefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}path kwargs.get 'path' None data kwargs.get 'data' None if data if path log.warning "Boththe'data'and'path'argumentswereprovided.'data'willtakeprecedence." elif path data salt.utils.fopen path mode 'r' .read else raise SaltCloudSystemExit "Thesecgroup_allocatefunctionrequireseither'data'orafile'path'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.secgroup.allocate auth data ret {'action' 'secgroup.allocate' 'allocated' response[0] 'secgroup_id' response[1] 'error_code' response[2]}return ret
def add_level_messages storage storage.add constants.INFO 'Agenericinfomessage' storage.add 29 'Somecustomlevel' storage.add constants.DEBUG 'Adebuggingmessage' extra_tags 'extra-tag' storage.add constants.WARNING 'Awarning' storage.add constants.ERROR 'Anerror' storage.add constants.SUCCESS 'Thiswasatriumph.'
def encode_entrance_exam_and_student_input usage_key student None assert isinstance usage_key UsageKey if student is not None task_input {'entrance_exam_url' unicode usage_key 'student' student.username}task_key_stub '{student}_{entranceexam}'.format student student.id entranceexam unicode usage_key else task_input {'entrance_exam_url' unicode usage_key }task_key_stub '_{entranceexam}'.format entranceexam unicode usage_key task_key hashlib.md5 task_key_stub .hexdigest return task_input task_key
def isUnsavedPath path tag '<Unsaved>'length len tag if path.startswith tag and len path length or path[length] in '\\/' return Trueelse return False
def create_figure fig Figure a fig.add_subplot 111 t np.arange 0.0 3.0 0.01 s np.sin 2 * np.pi * t a.plot t s return fig
def _declare_function context builder name sig cargs mangler mangle_c mod builder.moduleif sig.return_type types.void llretty lc.Type.void else llretty context.get_value_type sig.return_type llargs [context.get_value_type t for t in sig.args]fnty Type.function llretty llargs mangled mangler name cargs fn mod.get_or_insert_function fnty mangled fn.calling_convention target.CC_SPIR_FUNCreturn fn
@step 'Iseetheresultwithwordscount' def see_result _step strong_css '.your_wordsstrong'target_text set [world.css_text strong_css i for i in range 2 ] assert set ['text1' 'text2'] target_text
def getCarving fileName return getFromGNUTriangulatedSurfaceText archive.getFileText fileName trianglemesh.TriangleMesh
def fuse_selections dsk head1 head2 merge dsk2 dict for k v in dsk.items try if istask v and v[0] head1 and v[1] in dsk and istask dsk[v[1]] and dsk[v[1]][0] head2 dsk2[k] merge v dsk[v[1]] else dsk2[k] vexcept TypeError dsk2[k] vreturn dsk2
@register u'beginning-of-history' def beginning_of_history event event.current_buffer.go_to_history 0
def create_diff object_a object_b changes _create_diffs_for pvector [] object_a object_b return Diff changes changes
def _format_jid local None domain None resource None result []if local result.append local result.append u'@' if domain result.append domain if resource result.append u'/' result.append resource return u''.join result
def init_logging options log_file options['log_basename'] + '.log' log_dir options['log_dir']log_config {'version' 1 'disable_existing_loggers' True 'formatters' {'timestamped' {'format' '% asctime s% message s' 'datefmt' '%H %M %S'}} 'handlers' {'console' {'level' 'WARNING' 'class' 'logging.StreamHandler' 'formatter' 'timestamped'} 'file' {'level' 'DEBUG' 'class' 'logging.FileHandler' 'formatter' 'timestamped' 'filename' os.path.join log_dir log_file 'mode' 'w'}} 'loggers' {'' {'level' 'DEBUG' 'handlers' ['console' 'file']}}}logging.config.dictConfig log_config
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
def find_selection text return _setup text .find_selection text
def get_globalLock_ratio name try result get_rate NAME_PREFIX + 'globalLock_lockTime' / get_rate NAME_PREFIX + 'globalLock_totalTime' * 100 except ZeroDivisionError result 0return result
def lang_istrusted cursor lang query "SELECTlanpltrustedFROMpg_languageWHERElanname '%s'" % lang cursor.execute query return cursor.fetchone [0]
def test_gemini_v1_2 table parse_single_table get_pkg_data_filename u'data/gemini.xml' assert table is not None
def import_object_ns name_space import_str *args **kwargs import_value '%s.%s' % name_space import_str try return import_class import_value *args **kwargs except ImportError return import_class import_str *args **kwargs
def train_mlp train os.path.join pylearn2.__path__[0] 'train_extensions/tests/live_monitor_test.yaml'
def test_ee_fit ratio 'auto'ee EasyEnsemble ratio ratio random_state RND_SEED ee.fit X Y assert_equal ee.min_c_ 0 assert_equal ee.maj_c_ 1 assert_equal ee.stats_c_[0] 2 assert_equal ee.stats_c_[2] 3 assert_equal ee.stats_c_[1] 5
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def set bot update args job_queue chat_data chat_id update.message.chat_idtry due int args[0] if due < 0 update.message.reply_text 'Sorrywecannotgobacktofuture!' returnjob Job alarm due repeat False context chat_id chat_data['job'] jobjob_queue.put job update.message.reply_text 'Timersuccessfullyset!' except IndexError ValueError update.message.reply_text 'Usage /set<seconds>'
def default_billship_handler request order_form if not request.session.get u'free_shipping' settings.clear_cache set_shipping request _ u'Flatrateshipping' settings.SHOP_DEFAULT_SHIPPING_VALUE
def assert_not_almost_equal first second places 7 msg None values True if round second - first places 0 extra 'within%rplaces' % places _report_inequality_failure first second msg values ' ' extra
def currentTimeMillis return time.time * 1000
def _makeUsageErrorStr errorString usageString return 'ERROR %s %s ' % errorString usageString
def log_buffer_lines return logs_buffer .lines
def buffer_to_bytes buf if not isinstance buf bytes buf bytes buf return buf
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def no_real_wabs_credentials if parse_boolean_envvar os.getenv 'WALE_WABS_INTEGRATION_TESTS' is not True return Truefor e_var in 'WABS_ACCOUNT_NAME' 'WABS_ACCESS_KEY' if os.getenv e_var is None return Truereturn False
def make_hotp secret counter key base64.b32decode secret counter_encoded struct.pack '>q' counter hmac_result hmac.HMAC key counter_encoded hashlib.sha1 .digest offset ord hmac_result[ -1 ] & 15 truncated_hash hmac_result[offset offset + 4 ] code_bits struct.unpack '>L' truncated_hash htop code_bits & 2147483647 % 1000000 return '%06d' % htop
def default_credentials if HAS_GOOGLE_AUTH credentials _ google.auth.default return credentialselif HAS_OAUTH2CLIENT return oauth2client.client.GoogleCredentials.get_application_default else raise EnvironmentError 'Noauthenticationlibraryisavailable.Pleaseinstalleithergoogle-authoroauth2client.'
def sort_version_list version_list reverse version_list.sort reverse reverse key lambda s StrictVersion s return version_list
def JsonDumpForScriptContext dump_object js_state_json json.dumps dump_object return js_state_json.replace '<' '\\\\x3c' .replace '>' '\\\\x3e'
def collect_list option opt_str value parser assert value is None value []for arg in parser.rargs if arg[ 1] '-' breakvalue.append arg del parser.rargs[ len value ]setattr parser.values option.dest value
def validate_host host allowed_hosts for pattern in allowed_hosts pattern pattern.lower match pattern u'*' or pattern.startswith u'.' and host.endswith pattern or host pattern[1 ] or pattern host if match return Truereturn False
def set_gc_state state if gc.isenabled state returnif state gc.enable else gc.disable
def ParseRate rate if rate '0' return 0.0elements rate.split '/' if len elements ! 2 raise MalformedQueueConfiguration 'Rate"%s"isinvalid.' % rate number unit elementstry number float number except ValueError raise MalformedQueueConfiguration 'Rate"%s"isinvalid "%s"isnotanumber.' % rate number if unit not in 'smhd' raise MalformedQueueConfiguration 'Rate"%s"isinvalid "%s"isnotoneofs m h d.' % rate unit if unit 's' return numberif unit 'm' return number / 60 if unit 'h' return number / 60 * 60 if unit 'd' return number / 24 * 60 * 60
def get_file filename return os.path.join TEST_DIR filename
def CreateCMakeTargetBaseName qualified_target _ gyp_target_name gyp_target_toolset gyp.common.ParseQualifiedTarget qualified_target cmake_target_base_name gyp_target_nameif gyp_target_toolset and gyp_target_toolset ! 'target' cmake_target_base_name + '_' + gyp_target_toolset return StringToCMakeTargetName cmake_target_base_name
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def printProgressByNumber layerIndex numberOfLayers procedureName printProgressByString '%slayercount%sof%s...' % procedureName.capitalize layerIndex + 1 numberOfLayers
def _unpack keydata parts []while keydata dlen struct.unpack '>I' keydata[ 4] [0] data keydata keydata[4 dlen + 4 ] keydata[ 4 + dlen ] parts.append data return parts
def create_pairs x digit_indices pairs []labels []n min [len digit_indices[d] for d in range 10 ] - 1 for d in range 10 for i in range n z1 z2 digit_indices[d][i] digit_indices[d][ i + 1 ] pairs + [[x[z1] x[z2]]]inc random.randrange 1 10 dn d + inc % 10 z1 z2 digit_indices[d][i] digit_indices[dn][i] pairs + [[x[z1] x[z2]]]labels + [1 0]return np.array pairs np.array labels
@frappe.whitelist def get_html_and_style doc name None print_format None meta None no_letterhead None trigger_print False if isinstance doc basestring and isinstance name basestring doc frappe.get_doc doc name if isinstance doc basestring doc frappe.get_doc json.loads doc print_format get_print_format_doc print_format meta meta or frappe.get_meta doc.doctype return {u'html' get_html doc name name print_format print_format meta meta no_letterhead no_letterhead trigger_print trigger_print u'style' get_print_style print_format print_format }
def remove_feature feature remove_payload False image None restart False cmd ['DISM' '/Quiet' '/Image {0}'.format image if image else '/Online' '/Disable-Feature' '/FeatureName {0}'.format feature ]if remove_payload cmd.append '/Remove' if not restart cmd.append '/NoRestart' return __salt__['cmd.run_all'] cmd
def fail_when_undefined value if isinstance value jinja2.Undefined value return value
def get_ifname_by_pci_address pci_addr pf_interface False dev_path _get_sysfs_netdev_path pci_addr pf_interface try dev_info os.listdir dev_path return dev_info.pop except Exception raise exception.PciDeviceNotFoundById id pci_addr
def _trim_front strings trimmed stringswhile len strings > 0 and all [ x[0] '' for x in trimmed] trimmed [x[1 ] for x in trimmed]return trimmed
def S_ISDIR mode return S_IFMT mode S_IFDIR
@deprecateddef script_resolve_name script_name name if not name return roslib.names.get_ros_namespace if roslib.names.is_global name return nameelif roslib.names.is_private name return ns_join roslib.names.make_caller_id script_name name[1 ] return roslib.names.get_ros_namespace + name
def make_identifier name if isinstance name bytes identifier name.decode 'utf-8' else identifier nameidentifier identifier.lower identifier identifier.replace u'+' u'plus' identifier re.sub u'[_\xe2\x80\x93]+' u'-' identifier identifier re.sub u"['./;\xe2\x80\x99 ]" u'' identifier identifier identifier.replace u'\xc3\xa9' u'e' if identifier.startswith 'route-' identifier 'kalos-' + identifier if not identifier.replace u'-' u'' .isalnum raise ValueError identifier return identifier
def project_hazard_help_fields options table current.s3db.project_hazardkeys dict options .keys rows current.db table.id.belongs keys .select table.id table.comments T current.Ttranslated lambda string T string if string else '' tooltips {}for row in rows tooltips[row.id] translated row.comments return tooltips
def get_fallback_locale doc request translated_locales doc.translations.values_list 'locale' flat True .exclude current_revision None accept_header request.META.get 'HTTP_ACCEPT_LANGUAGE' or '' header_locales parse_accept_lang_header accept_header all_accepted_locales []all_accepted_locales.append request.LANGUAGE_CODE all_accepted_locales.extend header_locales for locale in all_accepted_locales if locale settings.WIKI_DEFAULT_LANGUAGE return Noneelif locale in translated_locales return localeelif settings.NON_SUPPORTED_LOCALES.get locale in translated_locales return settings.NON_SUPPORTED_LOCALES[locale]for fallback in FALLBACK_LOCALES.get locale [] if fallback in translated_locales return fallbackreturn None
def _set_qresult_hits qresult hit_rows for hit_row in hit_rows hit_id remainder hit_row.split '' 1 if hit_id not in qresult frag HSPFragment hit_id qresult.id hsp HSP [frag] hit Hit [hsp] qresult.append hit return qresult
def getProfileName name repository if repository.getProfileDirectory None return namereturn os.path.join repository.getProfileDirectory name
def condense_multidimensional_zeros css css css.replace ' 0000;' ' 0;' css css.replace ' 000;' ' 0;' css css.replace ' 00;' ' 0;' css css.replace 'background-position 0;' 'background-position 00;' return css
def detectencoding_unicode input final False prefix '@charset"'if input.startswith prefix pos input.find '"' len prefix if pos > 0 return input[len prefix pos] True elif final or not prefix.startswith input return 'utf-8' False return None False
def light_palette color n_colors 6 reverse False as_cmap False input 'rgb' color _color_to_rgb color input light set_hls_values color l 0.95 colors [color light] if reverse else [light color] return blend_palette colors n_colors as_cmap
def parallel targets threads []for target in targets if isinstance target tuple or isinstance target list t InterruptedThread *target else t InterruptedThread target threads.append t t.start return [t.join for t in threads]
def _apply_functions tokens local_dict global_dict result []symbol Nonefor tok in tokens if tok[0] NAME symbol tokresult.append tok elif isinstance tok ParenthesisGroup if symbol and _token_callable symbol local_dict global_dict result[ -1 ] AppliedFunction symbol tok symbol Noneelse result.extend tok else symbol Noneresult.append tok return result
def _get_objects obj_type lst_objs FakeRetrieveResult for key in _db_content[obj_type] lst_objs.add_object _db_content[obj_type][key] return lst_objs
def collection_exists collection_name **kwargs if not isinstance collection_name six.string_types raise ValueError 'Collectionnamemustbeastring' return collection_name in collection_list **kwargs
def signin_failure request message template_name 'authopenid/signin.html' redirect_field_name REDIRECT_FIELD_NAME openid_form OpenidSigninForm auth_form AuthenticationForm extra_context None **kwargs return render template_name {'msg' message 'form1' openid_form 'form2' auth_form redirect_field_name request.REQUEST.get redirect_field_name '' } context_instance _build_context request extra_context
def prelu x W return PReLUFunction x W
def get_matching_for_product shop_product provide_category skippable_classes None collected set matcher ProductCampaignMatcher shop_product for item in get_provide_objects provide_category if skippable_classes objects item._meta.model.objects.not_instance_of *skippable_classes .all else objects item._meta.model.objects.all for obj in objects if matcher.matches obj collected.add obj.pk return collected
def set_hls_values color h None l None s None rgb mplcol.colorConverter.to_rgb color vals list colorsys.rgb_to_hls *rgb for i val in enumerate [h l s] if val is not None vals[i] valrgb colorsys.hls_to_rgb *vals return rgb
def _FixPath path if fixpath_prefix and path and not os.path.isabs path and not path[0] '$' path os.path.join fixpath_prefix path path path.replace '/' '\\' path _NormalizedSource path if path and path[ -1 ] '\\' path path[ -1 ]return path
def use_metaclass meta *bases if not bases bases object return meta 'HackClass' bases {}
def get_absolute_url path return u'http //testserver/{}'.format path.lstrip u'/'
def save_cover_data_to data path bgcolor '#ffffff' resize_to None return_data False compression_quality 90 minify_to None grayscale False fmt os.path.splitext path [1]if return_data path Noneif isinstance data Image data data.imgreturn _save_cover_data_to data path bgcolor bgcolor resize_to resize_to compression_quality compression_quality minify_to minify_to grayscale grayscale data_fmt fmt
@click.command 'set-nginx-port' @click.argument 'site' @click.argument 'port' type int def set_nginx_port site port from bench.config.site_config import set_nginx_portset_nginx_port site port
@_docstring 'artists' browse True def browse_artists recording None release None release_group None includes [] limit None offset None valid_includes VALID_BROWSE_INCLUDES['artists']params {'recording' recording 'release' release 'release-group' release_group}return _browse_impl 'artist' includes valid_includes limit offset params
def directory path use_sudo False owner '' group '' mode '' func use_sudo and run_as_root or run if not is_dir path func 'mkdir-p"% path s"' % locals if owner and _owner path use_sudo ! owner or group and _group path use_sudo ! group func 'chown% owner s % group s"% path s"' % locals if mode and _mode path use_sudo ! mode func 'chmod% mode s"% path s"' % locals
def index_hydrate params container cli_type key value if 'IndexField' not in params params['IndexField'] {}if 'IndexFieldType' not in params['IndexField'] raise RuntimeError 'Youmustpassthe--typeoption.' _type params['IndexField']['IndexFieldType']_type ''.join [i.capitalize for i in _type.split '-' ] if _type 'Latlon' _type 'LatLon'if key.split SEP [ -1 ] 'DefaultValue' value DEFAULT_VALUE_TYPE_MAP.get _type lambda x x value if _type + 'Options' not in params['IndexField'] params['IndexField'][ _type + 'Options' ] {}params['IndexField'][ _type + 'Options' ][key.split SEP [ -1 ]] value
def _ScrubPostComment op_args _ScrubForClass Comment op_args['comment']
def makeSetup **args distutils.core._setup_stop_after 'commandline'args.setdefault 'script_args' ['install'] try return setuptools.setup **args finally distutils.core_setup_stop_after None
def get_mor_by_property service_instance object_type property_value property_name 'name' container_ref None object_list get_mors_with_properties service_instance object_type property_list [property_name] container_ref container_ref for obj in object_list obj_id str obj.get 'object' '' .strip '\'"' if obj[property_name] property_value or property_value obj_id return obj['object']return None
def destroy instance_id call None if call 'function' raise SaltCloudSystemExit 'Thedestroyactionmustbecalledwith-d --destroy -aor--action.' instance_data show_instance instance_id call 'action' name instance_data['instance_name']__utils__['cloud.fire_event'] 'event' 'destroyinginstance' 'salt/cloud/{0}/destroying'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] params {'action' 'TerminateInstances' 'zone' _get_specified_zone provider get_configured_provider 'instances.1' instance_id}result query params __utils__['cloud.fire_event'] 'event' 'destroyedinstance' 'salt/cloud/{0}/destroyed'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def _get_app_revision environ None if environ is None environ os.environif 'CURRENT_VERSION_ID' in environ return environ['CURRENT_VERSION_ID'].split '.' [1]
def phabricator registry xml_parent data root XML.SubElement xml_parent 'com.uber.jenkins.phabricator.PhabricatorNotifier' if 'comment-on-success' in data XML.SubElement root 'commentOnSuccess' .text str data.get 'comment-on-success' .lower if 'uberalls-enabled' in data XML.SubElement root 'uberallsEnabled' .text str data.get 'uberalls-enabled' .lower if 'comment-file' in data XML.SubElement root 'commentFile' .text data.get 'comment-file' if 'comment-size' in data XML.SubElement root 'commentSize' .text str data.get 'comment-size' if 'comment-with-console-link-on-failure' in data XML.SubElement root 'commentWithConsoleLinkOnFailure' .text str data.get 'comment-with-console-link-on-failure' .lower
def fnmatchcase name pat try re_pat _cache[pat]except KeyError res translate pat if len _cache > _MAXCACHE _cache.clear _cache[pat] re_pat re.compile res return re_pat.match name is not None
def read_element_unicode stream size return _read stream size .decode 'utf-8'
def radius_neighbors_graph X radius mode 'connectivity' metric 'minkowski' p 2 metric_params None include_self False n_jobs 1 if not isinstance X RadiusNeighborsMixin X NearestNeighbors radius radius metric metric p p metric_params metric_params n_jobs n_jobs .fit X else _check_params X metric p metric_params query _query_include_self X include_self return X.radius_neighbors_graph query radius mode
def vrrp_list app instance_name None list_request vrrp_event.EventVRRPListRequest instance_name list_request.dst vrrp_event.VRRP_MANAGER_NAMEreturn app.send_request list_request
def _compute_phasediff cross_correlation_max return np.arctan2 cross_correlation_max.imag cross_correlation_max.real
def WrapEnum ob resultCLSID None if type ob ! pythoncom.TypeIIDs[pythoncom.IID_IEnumVARIANT] ob ob.QueryInterface pythoncom.IID_IEnumVARIANT return EnumVARIANT ob resultCLSID
def getWindowAnalyzeFileGivenText fileName gcodeText repository None if gcodeText '' return Noneif repository None repository settings.getReadRepository SkeinlayerRepository skeinWindow getWindowGivenTextRepository fileName gcodeText repository skeinWindow.updateDeiconify return skeinWindow
@require_GET@ensure_valid_course_keydef get_course_lti_endpoints request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id try course get_course course_key depth 2 except ValueError return HttpResponse status 404 anonymous_user AnonymousUser anonymous_user.known Falselti_descriptors modulestore .get_items course.id qualifiers {'category' 'lti'} lti_noauth_modules [get_module_for_descriptor anonymous_user request descriptor FieldDataCache.cache_for_descriptor_descendents course_key anonymous_user descriptor course_key course course for descriptor in lti_descriptors]endpoints [{'display_name' module.display_name 'lti_2_0_result_service_json_endpoint' module.get_outcome_service_url service_name 'lti_2_0_result_rest_handler' + '/user/{anon_user_id}' 'lti_1_1_result_service_xml_endpoint' module.get_outcome_service_url service_name 'grade_handler' } for module in lti_noauth_modules]return HttpResponse json.dumps endpoints content_type 'application/json'
def save_model model_file_name model liblinear.save_model model_file_name.encode model
def sos2zpk sos sos np.asarray sos n_sections sos.shape[0]z np.empty n_sections * 2 np.complex128 p np.empty n_sections * 2 np.complex128 k 1.0for section in range n_sections zpk tf2zpk sos[section 3] sos[section 3 ] z[ 2 * section 2 * section + 1 ] zpk[0]p[ 2 * section 2 * section + 1 ] zpk[1]k * zpk[2]return z p k
def htmlify_validation validation for msg in validation['messages'] msg['message'] linkify_escape msg['message'] for key in 'description' 'signing_help' if key in msg if not isinstance msg[key] list tuple msg[key] [msg[key]]msg[key] [linkify_escape text for text in msg[key]]
def is_str string return isinstance string base
def init_params_bi options params OrderedDict params['Wemb'] norm_weight options['n_words_src'] options['dim_word'] params get_layer options['encoder'] [0] options params prefix 'encoder' nin options['dim_word'] dim options['dim'] params get_layer options['encoder'] [0] options params prefix 'encoder_r' nin options['dim_word'] dim options['dim'] return params
def resolve_transport transport None if isinstance transport string_t try transport TRANSPORT_ALIASES[transport]except KeyError if u'.' not in transport and u' ' not in transport from kombu.utils.text import fmatch_bestalt fmatch_best transport TRANSPORT_ALIASES if alt raise KeyError u'Nosuchtransport {0}.Didyoumean{1}?'.format transport alt raise KeyError u'Nosuchtransport {0}'.format transport else if callable transport transport transport return symbol_by_name transport return transport
def _binary_replace old new old_isbin not salt.utils.istextfile old new_isbin not salt.utils.istextfile new if any old_isbin new_isbin if all old_isbin new_isbin return 'Replacebinaryfile'elif old_isbin return 'Replacebinaryfilewithtextfile'elif new_isbin return 'Replacetextfilewithbinaryfile'return ''
def Internaldate2epoch resp from calendar import timegmmo InternalDate.match resp if not mo return Nonemon Mon2num[mo.group 'mon' ]zonen mo.group 'zonen' day int mo.group 'day' year int mo.group 'year' hour int mo.group 'hour' min int mo.group 'min' sec int mo.group 'sec' zoneh int mo.group 'zoneh' zonem int mo.group 'zonem' zone zoneh * 60 + zonem * 60 if zonen '-' zone - zone tt year mon day hour min sec -1 -1 -1 return timegm tt - zone
def _check_image_id image_id if image_id and len image_id > models.Image.id.property.columns[0].type.length raise exception.ImageNotFound
def backward_induction ddp T v_term None n ddp.num_statesvs np.empty T + 1 n sigmas np.empty T n dtype int if v_term is None v_term np.zeros n vs[T ] v_termfor t in range T 0 -1 ddp.bellman_operator vs[t ] Tv vs[ t - 1 ] sigma sigmas[ t - 1 ] return vs sigmas
def prefixes seq n len seq for i in range n yield seq[ i + 1 ]
def get_flag var fallback expected True warn True val get_config_var var if val is None if warn logger.debug "Configvariable'%s'isunset PythonABItagmaybeincorrect" var return fallback return val expected
@ratelimit @requires_auth 'item' @pre_eventdef put resource payload None **lookup return put_internal resource payload concurrency_check True skip_validation False **lookup
def symrand dim_or_eigv if isinstance dim_or_eigv int dim dim_or_eigvd random dim * 2 - 1 elif isinstance dim_or_eigv ndarray and len dim_or_eigv.shape 1 dim dim_or_eigv.shape[0]d dim_or_eigvelse raise TypeError 'inputtypenotsupported.' v random_rot dim h dot dot v.T.conj diag d v h 0.5 * h.T + h return h
def function_absent name FunctionName region None key None keyid None profile None ret {'name' FunctionName 'result' True 'comment' '' 'changes' {}}r __salt__['boto_lambda.function_exists'] FunctionName region region key key keyid keyid profile profile if 'error' in r ret['result'] Falseret['comment'] 'Failedtodeletefunction {0}.'.format r['error']['message'] return retif r and not r['exists'] ret['comment'] 'Function{0}doesnotexist.'.format FunctionName return retif __opts__['test'] ret['comment'] 'Function{0}issettoberemoved.'.format FunctionName ret['result'] Nonereturn retr __salt__['boto_lambda.delete_function'] FunctionName region region key key keyid keyid profile profile if not r['deleted'] ret['result'] Falseret['comment'] 'Failedtodeletefunction {0}.'.format r['error']['message'] return retret['changes']['old'] {'function' FunctionName}ret['changes']['new'] {'function' None}ret['comment'] 'Function{0}deleted.'.format FunctionName return ret
def mask_email ref pepno None if ref.hasattr 'refuri' and ref['refuri'].startswith 'mailto ' if ref['refuri'][8 ] in non_masked_addresses replacement ref[0]else replacement_text ref.astext .replace '@' '&#32;&#97;t&#32;' replacement nodes.raw '' replacement_text format 'html' if pepno is None return replacementelse ref['refuri'] + '?subject PEP%%20%s' % pepno ref[ ] [replacement]return refelse return ref
def convert_type ty default None guessed_type Falseif ty is None and default is not None if isinstance default tuple ty tuple map type default else ty type default guessed_type Trueif isinstance ty tuple return Tuple ty if isinstance ty ParamType return tyif ty is text_type or ty is str or ty is None return STRINGif ty is int return INTif ty is bool and not guessed_type return BOOLif ty is float return FLOATif guessed_type return STRINGif __debug__ try if issubclass ty ParamType raise AssertionError 'Attemptedtouseanuninstantiatedparametertype %s .' % ty except TypeError passreturn FuncParamType ty
def Shutdown dev_process GlobalProcess if not dev_process.IsMaster returnif os.name 'nt' import ctypesfor child in dev_process.Children logging.debug 'windowskill' + str child.process.pid ctypes.windll.kernel32.TerminateProcess int child.process._handle -1 else PosixShutdown dev_process.child_api_server.Quit
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def unbuckleBasis basis maximumUnbuckling normal normalDot basis.dot normal dotComplement math.sqrt 1.0 - normalDot * normalDot unbuckling maximumUnbucklingif dotComplement > 0.0 unbuckling min 1.0 / dotComplement maximumUnbuckling basis.setToVector3 basis * unbuckling
def keep_query *keep_params **additional_params if not keep_params and not additional_params keep_params '*' params additional_params.copy qs_keys request.httprequest.args.keys for keep_param in keep_params for param in fnmatch.filter qs_keys keep_param if param not in additional_params and param in qs_keys params[param] request.httprequest.args.getlist param return werkzeug.urls.url_encode params
def auto_threaded interface reactor sync threadpool return interface_decorator 'auto_threaded' interface _threaded_method sync reactor threadpool
@environmentfilterdef do_sort environment value reverse False case_sensitive False attribute None if not case_sensitive def sort_func item if isinstance item basestring item item.lower return itemelse sort_func Noneif attribute is not None getter make_attrgetter environment attribute def sort_func item processor sort_func or lambda x x return processor getter item return sorted value key sort_func reverse reverse
def munge_title_to_name name if isinstance name unicode name substitute_ascii_equivalents name name re.sub '[. /]' '-' name name re.sub '[^a-zA-Z0-9-_]' '' name .lower name re.sub '-+' '-' name name name.strip '-' max_length model.PACKAGE_NAME_MAX_LENGTH - 5 if len name > max_length year_match re.match '.*?[_-] ? \\d{2 4}[-/] ?\\d{2 4} $' name if year_match year year_match.groups [0]name '%s-%s' % name[ max_length - len year - 1 ] year else name name[ max_length]name _munge_to_length name model.PACKAGE_NAME_MIN_LENGTH model.PACKAGE_NAME_MAX_LENGTH return name
def getInsideness path loop if len path < 2 return 0.0pathLength euclidean.getPathLength path if pathLength < 0.0 return 0.0incrementRatio 0.017increment incrementRatio * pathLength oldPoint path[0]numberOfPointsInside float euclidean.isPointInsideLoop loop oldPoint for point in path[1 ] segment point - oldPoint distance abs segment numberOfPosts int math.ceil distance / increment if numberOfPosts > 0 segmentIncrement segment / float numberOfPosts for post in xrange numberOfPosts postPoint oldPoint + float post * segmentIncrement numberOfPointsInside + float euclidean.isPointInsideLoop loop postPoint oldPoint pointreturn incrementRatio * numberOfPointsInside
def check_passwd guess passwd m sha1 salt passwd[ salt_len * 2 ]m.update unicode2bytes guess + unicode2bytes salt crypted_guess bytes2NativeString salt + m.hexdigest return crypted_guess bytes2NativeString passwd
def store_and_queue identity text store_message INCOMING identity text connection lookup_connections BACKEND_NAME [identity] [0]receive text connection
def stride_repeat x n axis 0 if axis not in [0 1] raise ValueError u'axismustbe0or1' x np.asarray x if x.ndim ! 1 raise ValueError u'only1-dimensionalarrayscanbeused' if n 1 if axis 0 return np.atleast_2d x else return np.atleast_2d x .Tif n < 1 raise ValueError u'ncannotbelessthan1' n int n if axis 0 shape n x.size strides 0 x.strides[0] else shape x.size n strides x.strides[0] 0 return np.lib.stride_tricks.as_strided x shape shape strides strides
def _strip_named_query txt if named_query_regex.match txt txt named_query_regex.sub '' txt return txt
def Lock from multiprocessing.synchronize import Lockreturn Lock
def getLinkedElementNode idSuffix parentNode target linkedElementNode xml_simple_reader.ElementNode euclidean.overwriteDictionary target.attributes ['id' 'name' 'quantity'] linkedElementNode.attributes linkedElementNode.addSuffixToID idSuffix tagKeys target.getTagKeys tagKeys.append 'disjoin' tagKeys.sort tags ' '.join tagKeys linkedElementNode.attributes['tags'] tagslinkedElementNode.setParentAddToChildNodes parentNode linkedElementNode.addToIdentifierDictionaries return linkedElementNode
def _add_inc_data name chunksize points DATASETS[name]ndim points.shape[1]opts Nonenmin ndim + 2 if name 'some-points' opts 'QJPp'elif name 'pathological-1' nmin 12chunks [points[ nmin]]for j in xrange nmin len points chunksize chunks.append points[j j + chunksize ] new_name '%s-chunk-%d' % name chunksize assert new_name not in INCREMENTAL_DATASETS INCREMENTAL_DATASETS[new_name] chunks opts
def MakeRenewedExpiredResponse return kVerifyResponseRenewedExpired
def _curry_callable obj *args **kwargs if isinstance obj types.MethodType return invoke_member obj.im_self obj.im_func.__name__ + args kwargs elif isinstance obj types.BuiltinMethodType if not obj.__self__ return obj args kwargs else return invoke_member obj.__self__ obj.__name__ + args kwargs elif isinstance obj types.ObjectType and hasattr obj '__call__' return obj args kwargs elif isinstance obj types.FunctionType types.BuiltinFunctionType types.ClassType types.UnboundMethodType return obj args kwargs else raise ValueError 'objmustbecallable'
def opt_string2dict opt_string opt_dict {}for item in opt_string.split '-' item item.strip if '' in item opt value item.split '' 1 opt_dict[ '-%s' % opt ] valueelif item ! '' opt_dict[ '-%s' % item ] Nonefor key value in opt_dict.iteritems if value and value.isdigit opt_dict[key] int value return opt_dict
def version_date return version.DATE.split '' [0]
def dmp_true_LT f u K monom []while u monom.append len f - 1 f u f[0] u - 1 if not f monom.append 0 else monom.append len f - 1 return tuple monom dup_LC f K
def cache_subnet_group_exists name region None key None keyid None profile None return bool describe_cache_subnet_groups name name region region key key keyid keyid profile profile
def regularize_network_params layer penalty tags {'regularizable' True} **kwargs return apply_penalty get_all_params layer **tags penalty **kwargs
def test_allknn_fit_single_class allknn AllKNN random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning allknn.fit X y_single_class
def pportInitOut state global ctrlRegif state 0 ctrlReg ctrlReg & ~ 4 else ctrlReg ctrlReg | 4 port.DlPortWritePortUchar ctrlRegAdrs ctrlReg
def ensure_ca_filesystem ca_dir ca_folder if not os.path.exists ca_path genrootca_sh_path os.path.abspath os.path.join os.path.dirname __file__ 'CA' 'genrootca.sh' start os.getcwd fileutils.ensure_tree ca_dir os.chdir ca_dir utils.execute 'sh' genrootca_sh_path os.chdir start
def _init_signals import signalimport threadimport sysprev_handler signal.getsignal signal.SIGINT def thread_interrupt_handler signum frame thread.do_terminate_threads if callable prev_handler prev_handler signum frame raise KeyboardInterrupt try signal.signal signal.SIGINT thread_interrupt_handler except ValueError print >>sys.stderr 'Failedtosetupthread-interrupthandler.Thisisusuallynotcritical'
def _get_service name services _available_services name name.lower if name in services return services[name]for service in six.itervalues services if service['file_path'].lower name return service basename ext os.path.splitext service['file_name'] if basename.lower name return serviceraise CommandExecutionError 'Servicenotfound {0}'.format name
def interpolate_inverse from_value to_value current_value ease_out_degree t 0.0 if from_value - to_value 0 else - float current_value - from_value / float from_value - to_value return inverse_ease_out t ease_out_degree
def encode_password s if isinstance s unicode s s.encode 'utf-8' x base64.b64encode os.urandom 32 return 'pbkdf2 sha256 10000 %s %s' % x pbkdf2 s[ 1024] x
def swapon name priority None ret {}on_ swaps if name in on_ ret['stats'] on_[name]ret['new'] Falsereturn retif __grains__['kernel'] 'SunOS' if __grains__['virtual'] ! 'zone' __salt__['cmd.run'] 'swap-a{0}'.format name python_shell False else return Falseelse cmd 'swapon{0}'.format name if priority cmd + '-p{0}'.format priority __salt__['cmd.run'] cmd python_shell False on_ swaps if name in on_ ret['stats'] on_[name]ret['new'] Truereturn retreturn ret
def instance_destroy context instance_uuid constraint None update_cells True rv IMPL.instance_destroy context instance_uuid constraint if update_cells try cells_rpcapi.CellsAPI .instance_destroy_at_top context rv except Exception LOG.exception _ 'Failedtonotifycellsofinstancedestroy' return rv
def snowflake_time id return datetime.datetime.utcfromtimestamp int id >> 22 + DISCORD_EPOCH / 1000
def get_unique_constraints table context list_of_constraints []for contraint in table.constraints if isinstance contraint sqlalchemy.UniqueConstraint columns [column.name for column in contraint.columns]list_of_constraints.append columns return list_of_constraints
def mv_mixture_rvs prob size dist nvars **kwargs if len prob ! len dist raise ValueError 'Youmustprovideasmanyprobabilitiesasdistributions' if not np.allclose np.sum prob 1 raise ValueError 'probdoesnotsumto1' if kwargs is None kwargs {} * len prob idx _make_index prob size sample np.empty size nvars for i in range len prob sample_idx idx[... i]sample_size sample_idx.sum sample[sample_idx] dist[i].rvs size int sample_size return sample
def snake s s re.sub ' ?< [^A-Z] \\B [A-Z] ' '\\1' s return '_'.join s.lower .split
def cast_items exporter fmt itemsize shape None bytelen exporter.nbytesif shape if prod shape * itemsize ! bytelen return None shape elif shape [] if exporter.ndim 0 or itemsize ! bytelen return None shape else n r divmod bytelen itemsize shape [n]if r ! 0 return None shape mem exporter.tobytes byteitems [mem[i i + itemsize ] for i in range 0 len mem itemsize ]items []for v in byteitems item struct.unpack fmt v [0]if item ! item return 'nan' shape items.append item return items shape if shape ! [] else items[0] shape
@removals.remove message 'keystoneclientauthpluginsaredeprecated.Usekeystoneauth.' version '2.1.0' removal_version '3.0.0' def get_available_plugin_classes mgr stevedore.ExtensionManager namespace PLUGIN_NAMESPACE propagate_map_exceptions True invoke_on_load False return dict mgr.map lambda ext ext.entry_point.name ext.plugin
def ave_seqs_per_sample matrix seqs_per_samp sampleIDs ave_ser {}temp_dict {}for i sid in enumerate sampleIDs temp_dict[sid] {}for j seq in enumerate seqs_per_samp try temp_dict[sid][seq].append matrix[i][j] except KeyError temp_dict[sid][seq] []temp_dict[sid][seq].append matrix[i][j] for sid in sampleIDs ave_ser[sid] []keys sorted temp_dict[sid].keys for k in keys ave_ser[sid].append mean array temp_dict[sid][k] 0 return ave_ser
def get_names_from_csr csr typ OpenSSL.crypto.FILETYPE_PEM return _get_names_from_cert_or_req csr OpenSSL.crypto.load_certificate_request typ
def contains_metastrings s if s.find _table_names_key > 0 or s.find _columns > 0 or s.find _data > 0 or s.find _rowid > 0 return 1else return 0
def _scrub_request http_request if http_request and http_request.uri and http_request.uri.path and http_request.uri.path.endswith 'ClientLogin' http_request._body_parts []http_request.add_form_inputs {'form_data' 'clientloginrequesthasbeenscrubbed'} else http_request._body_parts []return http_request
def framework_info filename is_framework STRICT_FRAMEWORK_RE.match filename if not is_framework return Nonereturn is_framework.groupdict
def share_config dbdriver dbtype dbhost dbuser dbpasswd testdb global DBDRIVER DBTYPE DBHOST DBUSER DBPASSWD TESTDB DBSCHEMAglobal SYSTEM SQL_FILEDBDRIVER dbdriverDBTYPE dbtypeDBHOST dbhostDBUSER dbuserDBPASSWD dbpasswdTESTDB testdb
def compute_epipole F U S V linalg.svd F e V[ -1 ]return e / e[2]
def is_inf builder val pos_inf lc.Constant.real val.type float '+inf' neg_inf lc.Constant.real val.type float '-inf' isposinf builder.fcmp lc.FCMP_OEQ val pos_inf isneginf builder.fcmp lc.FCMP_OEQ val neg_inf return builder.or_ isposinf isneginf
def libvlc_video_set_key_input p_mi on f _Cfunctions.get 'libvlc_video_set_key_input' None or _Cfunction 'libvlc_video_set_key_input' 1 1 None None MediaPlayer ctypes.c_uint return f p_mi on
def _masked_rec_array_to_mgr data index columns dtype copy fill_value data.fill_valuefdata ma.getdata data if index is None index _get_names_from_index fdata if index is None index _default_index len data index _ensure_index index if columns is not None columns _ensure_index columns arrays arr_columns _to_arrays fdata columns new_arrays []for fv arr col in zip fill_value arrays arr_columns mask ma.getmaskarray data[col] if mask.any arr fv _maybe_upcast arr fill_value fv copy True arr[mask] fvnew_arrays.append arr arrays arr_columns _reorder_arrays new_arrays arr_columns columns if columns is None columns arr_columnsmgr _arrays_to_mgr arrays arr_columns index columns if copy mgr mgr.copy return mgr
def _samme_proba estimator n_classes X proba estimator.predict_proba X proba[ proba < np.finfo proba.dtype .eps ] np.finfo proba.dtype .epslog_proba np.log proba return n_classes - 1 * log_proba - 1.0 / n_classes * log_proba.sum axis 1 [ np.newaxis]
def log_normalize a axis None a_lse logsumexp a axis a - a_lse[ np.newaxis]
def track cls cls._no_instance_tracking Falsereturn cls
@skip 'silverlight' 'multiple_execute' 'win32' def test_c1cs if not has_csc returnc1cs get_local_filename 'c1.cs' outp sys.exec_prefixcompileAndRef 'c1' c1cs '/d BAR1' import Fooclass c1Child Foo.Bar passo c1Child AreEqual o.Method 'Inbar1' compileAndRef 'c1_b' c1cs import Fooclass c2Child Foo.Bar passo c2Child AreEqual o.Method 'Inbar2'
def html_ify text t cgi.escape text t _ITALIC.sub '<em>' + '\\1' + '</em>' t t _BOLD.sub '<b>' + '\\1' + '</b>' t t _MODULE.sub "<spanclass 'module'>" + '\\1' + '</span>' t t _URL.sub "<ahref '" + '\\1' + "'>" + '\\1' + '</a>' t t _CONST.sub '<code>' + '\\1' + '</code>' t return t
def test_config_alterations_kwargs class LineConfig Config no_prefix Trueshow_legend Falsefill Truepretty_print Truex_labels ['a' 'b' 'c']config LineConfig line1 Line config line1.add '_' [1 2 3] l1 line1.render line1.stroke Falsel1bis line1.render assert l1 ! l1bis line2 Line config line2.add '_' [1 2 3] l2 line2.render assert l1 l2 assert l1bis ! l2 line3 Line config title 'Title' line3.add '_' [1 2 3] l3 line3.render assert l3 ! l2 l2bis line2.render assert l2 l2bis
@bdd.given bdd.parsers.parse 'Irun{command}' def run_command_given quteproc command quteproc.send_cmd command
def encode_int v if not is_numeric v or v < 0 or v > TT256 raise Exception 'Integerinvalidoroutofrange %r' % v return int_to_big_endian v
def fftsurr x detrend detrend_none window window_none if cbook.iterable window x window * detrend x else x window detrend x z np.fft.fft x a 2.0 * np.pi * 1j phase a * np.random.rand len x z z * np.exp phase return np.fft.ifft z .real
def _available name ret avail Falseif 'service.available' in __salt__ avail __salt__['service.available'] name elif 'service.get_all' in __salt__ avail name in __salt__['service.get_all'] if not avail ret['result'] Falseret['comment'] 'Thenamedservice{0}isnotavailable'.format name return avail
def error xml try ET.XML xml except ET.ParseError return sys.exc_value
def _ValidateMatch regex value message matcher regex.match value if not matcher raise validation.ValidationError message return matcher
def exif_orientation im try exif im._getexif except Exception exif Noneif exif orientation exif.get 274 if orientation 2 im im.transpose Image.FLIP_LEFT_RIGHT elif orientation 3 im im.transpose Image.ROTATE_180 elif orientation 4 im im.transpose Image.FLIP_TOP_BOTTOM elif orientation 5 im im.transpose Image.ROTATE_270 .transpose Image.FLIP_LEFT_RIGHT elif orientation 6 im im.transpose Image.ROTATE_270 elif orientation 7 im im.transpose Image.ROTATE_90 .transpose Image.FLIP_LEFT_RIGHT elif orientation 8 im im.transpose Image.ROTATE_90 return im
def org_site_has_inv row tablename 'org_facility' if not current.deployment_settings.has_module 'inv' return Falseif hasattr row tablename row row[tablename]try id row.idexcept AttributeError return Nones3db current.s3dbitable s3db.inv_inv_itemstable s3db[tablename]query itable.deleted ! True & stable.id id & itable.site_id stable.site_id & itable.quantity > 0 inv current.db query .select itable.id limitby 0 1 .first if inv return Trueelse return False
def push_note device None title None body None spb _SaltPushbullet device res spb.push_note title body return res
def render_require_js_path_overrides path_overrides html '<scripttype "text/javascript">\n function require {{\nrequire.config {{\npaths {{\n{overrides}\n}}\n}} ;\n}} .call this require||RequireJS.require ;\n</script>'new_paths []for module in path_overrides actual_url staticfiles_storage.url path_overrides[module] path actual_url.replace '.js' '' .replace django_settings.STATIC_URL '' new_paths.append "'{module}' '{path}'".format module module path path return html.format overrides ' \n'.join new_paths
def get_pokemon_inventory_size _inventory.retrieve_inventories_size return _inventory.pokemon_inventory_size
def update_rollout_dict spec rollout_dict if should_skip_env_spec_for_tests spec logger.info u'Skippingtestsfor{}'.format spec.id return Falseif spec.nondeterministic logger.info u'Skippingtestsfornondeterministicenv{}'.format spec.id return Falselogger.info u'Generatingrolloutfor{}'.format spec.id try observations_hash actions_hash rewards_hash dones_hash generate_rollout_hash spec except logger.warn u'Exception{}thrownwhilegeneratingrolloutfor{}.Rolloutnotadded.'.format sys.exc_info [0] spec.id return Falserollout {}rollout[u'observations'] observations_hashrollout[u'actions'] actions_hashrollout[u'rewards'] rewards_hashrollout[u'dones'] dones_hashexisting rollout_dict.get spec.id if existing differs Falsefor key new_hash in rollout.items differs differs or existing[key] ! new_hash if not differs logger.debug u'Hashesmatchwithexistingfor{}'.format spec.id return Falseelse logger.warn u'Gotnewhashfor{}.Overwriting.'.format spec.id rollout_dict[spec.id] rolloutreturn True
def tensor5 name None dtype None if dtype is None dtype config.floatXtype TensorType dtype False False False False False return type name
def _rewrite1 f x recursive True fac po g _split_mul f x g _rewrite_single g x recursive if g return fac po g[0] g[1]
def test_ecl_geo gcrs GCRS 10 * u.deg 20 * u.deg distance 1.5 * R_earth gecl gcrs.transform_to GeocentricTrueEcliptic assert quantity_allclose gecl.distance gcrs.distance
def expandService service_element uris sortedURIs service_element if not uris uris [None]expanded []for uri in uris type_uris getTypeURIs service_element expanded.append type_uris uri service_element return expanded
def _unchanged name msg return {'name' name 'result' True 'comment' msg 'changes' {}}
def date_validator optdict name value return optik_ext.check_date None name value
def build_entrypoints prefix entrypoints result []for entrypoint_id rel_class_name in entrypoints if ' ' in rel_class_name sep '.'else sep ' 'result.append '%s %s%s%s' % entrypoint_id prefix sep rel_class_name return result
@render_to 'distributed/loadtesting/load_test.html' def load_test request nusers None username uuid.uuid4 .hex[ 12]if not Facility.objects.count fac Facility.objects.create name 'fac' fac Facility.objects.all [0] user _ FacilityUser.get_or_initialize username username facility fac user.set_password username user.save return {'pct_videos' request.GET.get 'pct_videos' 0.3 'username' username}
def audio_loop audioclip nloops None duration None if duration is not None nloops int duration / audioclip.duration + 1 return concatenate_audioclips nloops * [audioclip] .set_duration duration else return concatenate_audioclips nloops * [audioclip]
def get_password vm_ return config.get_cloud_config_value 'password' vm_ __opts__ default config.get_cloud_config_value 'passwd' vm_ __opts__ search_global False search_global False
def allow_serial_nos_with_different_item sle_serial_no sle allow_serial_nos Falseif sle.voucher_type u'StockEntry' and sle.actual_qty > 0 stock_entry frappe.get_doc u'StockEntry' sle.voucher_no if stock_entry.purpose in u'Repack' u'Manufacture' for d in stock_entry.get u'items' if d.serial_no and d.s_warehouse if sle.is_cancelled u'No' else d.t_warehouse serial_nos get_serial_nos d.serial_no if sle_serial_no in serial_nos allow_serial_nos Truereturn allow_serial_nos
def suid_bin attrs None where None return _osquery_cmd table 'suid_bin' attrs attrs where where
def virtual_interface_get_all context return IMPL.virtual_interface_get_all context
def get_autocommit using None return get_connection using .get_autocommit
def test_grad X T.matrix y X.sum G T.grad y [X] assert isinstance G list G T.grad y X assert not isinstance G list
def _build_text_msg message _LOGGER.debug 'Buildingplaintextemail' return MIMEText message
def list_nodes_full call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodes_fullfunctionmustbecalledwith-for--function.' return get_resources_vms includeConfig True
def func name return name
def _bcsys dev name value None log_lvl None log_msg None return _sysfs_attr [_bcpath dev name] value log_lvl log_msg
def parse_process_statistics statistics if statistics is None statistics DEFAULT_STATISTICSstatistics util.listify statistics statistics [_tuplize_statistic _ for _ in statistics]for statistic in statistics if statistic[0] not in STATISTIC_TYPES raise Exception 'Unknownstatistictypeencountered%s' % statistic[0] if statistic[1] not in PROCESS_COLUMNS raise Exception 'Unknownprocesscolumnencountered%s' % statistic[1] return statistics
def manual_search session task artist input_ u'Artist ' .strip name input_ u'Album ' if task.is_album else u'Track ' .strip if task.is_album _ _ prop autotag.tag_album task.items artist name return propelse return autotag.tag_item task.item artist name
def collapse_spaces string indentation False replace '' p []for x in string.splitlines n indentation and len x - len x.lstrip or 0 p.append x[ n] + RE_SPACES.sub replace x[n ] .strip return '\n'.join p
def get_recursive_filelist args files []for arg in args if os.path.isfile arg files.append arg continueif os.path.isdir arg newfiles listFiles arg recurse 1 return_folders 1 files.extend newfiles return [f for f in files if not os.path.islink f ]
def init_handler resource event trigger agent None global TRUNK_SKELETONmanager trunk_manager.TrunkManager agent.int_br handler ovsdb_handler.OVSDBHandler manager TRUNK_SKELETON OVSTrunkSkeleton handler
def lastsave host None port None db None password None server _connect host port db password return int server.lastsave .strftime '%s'
def stringify_dict dct_or_tuples encoding 'utf-8' keys_only True d {}for k v in dict dct_or_tuples .iteritems k k.encode encoding if isinstance k unicode else k if not keys_only v v.encode encoding if isinstance v unicode else v d[k] vreturn d
def notify_event_callbacks service resource_type operation payload if operation in _SUBSCRIBERS if resource_type in _SUBSCRIBERS[operation] for cb in _SUBSCRIBERS[operation][resource_type] subst_dict {'cb_name' cb.__name__ 'service' service 'resource_type' resource_type 'operation' operation 'payload' payload}LOG.debug 'Invokingcallback% cb_name sforevent% service s% resource_type s% operation sfor% payload s' subst_dict cb service resource_type operation payload
def test_imap_missing_trash constants monkeypatch folder_base [ '\\HasNoChildren' '/' u'INBOX' '\\Noselect' '\\HasChildren' '/' u'SKIP' '\\HasNoChildren' '\\Drafts' '/' u'Drafts' '\\HasNoChildren' '\\Sent' '/' u'Sent' '\\HasNoChildren' '\\Sent' '/' u'SentItems' '\\HasNoChildren' '\\Junk' '/' u'Spam' '\\HasNoChildren' '/' u'reference' ]check_missing_generic 'trash' folder_base localized_folder_names['trash'] 'imap' constants monkeypatch
def _systemctl_status name contextkey 'systemd._systemctl_status.%s' % name if contextkey in __context__ return __context__[contextkey]__context__[contextkey] __salt__['cmd.run_all'] _systemctl_cmd 'status' name python_shell False redirect_stderr True ignore_retcode True return __context__[contextkey]
def try_to_serve_304 dispatch_result request etag if not etag returnqs_etag request.line.uri.querystring.get 'etag' if qs_etag and qs_etag ! etag raise Response 410 headers_etag request.headers.get 'If-None-Match' if not headers_etag returnif headers_etag ! etag returnraise Response 304
def selTournament individuals k tournsize chosen []for i in xrange k aspirants selRandom individuals tournsize chosen.append max aspirants key attrgetter 'fitness' return chosen
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def find_apple_crash_report_referenced_images binary_images threads image_map {}for image in binary_images image_map[image['image_addr']] image['uuid']to_load set for thread in threads if 'backtrace' not in thread continuefor frame in thread['backtrace']['contents'] img_uuid image_map.get frame['object_addr'] if img_uuid is not None to_load.add img_uuid return list to_load
def normalize_form_dict form attr_list assert isinstance form forms.Form res {}for attr in attr_list res[attr] form.cleaned_data.get attr return res
def process_message_notification request messages_path if not messages_path returnglobal _MESSAGES_CACHEglobal _MESSAGES_MTIMEif _MESSAGES_CACHE is None or _MESSAGES_MTIME ! os.path.getmtime messages_path _MESSAGES_CACHE _get_processed_messages messages_path _MESSAGES_MTIME os.path.getmtime messages_path for msg in _MESSAGES_CACHE msg.send_message request
def get_incoming_shape incoming if isinstance incoming tf.Tensor return incoming.get_shape .as_list elif type incoming in [np.array list tuple] return np.shape incoming else raise Exception 'Invalidincominglayer.'
def set_api_sub_params params api_params dict for param in params.keys param_value params.get param None if param_value api_params[pc param ] param_valuereturn api_params
def build_profile_map parsed_ini_config parsed_config copy.deepcopy parsed_ini_config profiles {}final_config {}for key values in parsed_config.items if key.startswith 'profile' try parts shlex.split key except ValueError continueif len parts 2 profiles[parts[1]] valueselif key 'default' profiles[key] valueselse final_config[key] valuesfinal_config['profiles'] profilesreturn final_config
def test_locale_html testfield Mock this_lang translation.get_language testfield.locale this_langs helpers.locale_html testfield assert not s 'nospecialHTMLattributesforsitelanguage'testfield.locale 'de's helpers.locale_html testfield assert s 'lang "de"dir "ltr"' for lang in settings.RTL_LANGUAGES testfield.locale langs helpers.locale_html testfield assert s 'lang "%s"dir "rtl"' % testfield.locale
def _translate_keys cons pool cons['pool']info {'id' cons['id'] 'console_type' pool['console_type']}return dict console info
def decrypt_string s key '' key + ''s base64.urlsafe_b64decode s a []for i in xrange len s try a.append chr ord s[i] - ord key[ i % len key ] % 256 except raise DecryptionError s ''.join a s decode_utf8 s return s
def set_socket_inherit sock inherit try if iswindows import win32api win32conif inherit flags win32con.HANDLE_FLAG_INHERITelse flags 0win32api.SetHandleInformation sock.fileno win32con.HANDLE_FLAG_INHERIT flags else import fcntlfd sock.fileno flags fcntl.fcntl fd fcntl.F_GETFD & ~ fcntl.FD_CLOEXEC if not inherit flags flags | fcntl.FD_CLOEXEC fcntl.fcntl fd fcntl.F_SETFD flags except import tracebacktraceback.print_exc
def _VarintBytes value pieces []_EncodeVarint pieces.append value return ''.join pieces
def _get_commit_message_for_suggestion suggestion_author_username commit_message return '%s%s %s' % feconf.COMMIT_MESSAGE_ACCEPTED_SUGGESTION_PREFIX suggestion_author_username commit_message
def create_ma deg_f deg_g row1 row2 col_num if deg_g - deg_f > 1 print 'Reversedegrees' returnm zeros deg_f - deg_g + 2 col_num for i in range deg_f - deg_g + 1 m[i ] rotate_r row1 i m[ deg_f - deg_g + 1 ] row2return m
def get_mapping_types mapping_types None if mapping_types is None values _search_mapping_types.values else values [_search_mapping_types[name] for name in mapping_types]values.sort key lambda cls cls.get_mapping_type_name return values
def test_nvidia_driver2 a numpy.random.rand 10000 .astype 'float32' cuda.shared_constructor a assert theano.sandbox.cuda.use.device_number is not None
def _compute_diff configured expected diff {'add' {} 'update' {} 'remove' {}}configured_users set configured.keys expected_users set expected.keys add_usernames expected_users - configured_users remove_usernames configured_users - expected_users common_usernames expected_users & configured_users add dict username expected.get username for username in add_usernames remove dict username configured.get username for username in remove_usernames update {}for username in common_usernames user_configuration configured.get username user_expected expected.get username if user_configuration user_expected continueupdate[username] {}for field field_value in six.iteritems user_expected if user_configuration.get field ! field_value update[username][field] field_valuediff.update {'add' add 'update' update 'remove' remove} return diff
def validate_xml content schema_content xml_schema_doc etree.parse schema_content xml_schema etree.XMLSchema xml_schema_doc xml etree.parse StringIO.StringIO content try xml_schema.assertValid xml except etree.DocumentInvalid return xml_schema.error_logreturn ''
def _blockdevice_volume_from_datasetid volumes dataset_id for volume in volumes if volume.dataset_id dataset_id return volume
def _str_extract_noexpand arr pat flags 0 from pandas import DataFrame Indexregex re.compile pat flags flags groups_or_na _groups_or_na_fun regex if regex.groups 1 result np.array [groups_or_na val [0] for val in arr] dtype object name _get_single_group_name regex else if isinstance arr Index raise ValueError 'onlyoneregexgroupissupportedwithIndex' name Nonenames dict zip regex.groupindex.values regex.groupindex.keys columns [names.get 1 + i i for i in range regex.groups ]if arr.empty result DataFrame columns columns dtype object else result DataFrame [groups_or_na val for val in arr] columns columns index arr.index dtype object return result name
def key_text_to_keyinfo keytext if keytext.startswith '"' return keyseq_to_keyinfo keytext[1 -1 ] else return keyname_to_keyinfo keytext
def job_delete_by_id job_id Job.objects.get pk job_id .delete return job_get_by_id job_id is None
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
@register u'previous-history' def previous_history event event.current_buffer.history_backward count event.arg
def FindWebServer options server_desc server_desc options.server or server_desc if server_desc and not isinstance server_desc unicode server_desc server_desc.decode 'mbcs' server GetWebServer server_desc return server.adsPath
def dealarm_shell tube tube.clean tube.sendline 'whichpython||echo' if tube.recvline .startswith '/' tube.sendline 'execpython-c"importsignal os;signal.alarm 0 ;os.execl \'$SHELL\' \'\' "' return tubetube.sendline 'whichperl||echo' if tube.recvline .startswith '/' tube.sendline 'execperl-e"alarm0;exec\'${SHELL -/bin/sh}\'"' return tubereturn None
def _dirs_are_unequal dir1 dir2 dircmps [filecmp.dircmp dir1 dir2 ]while len dircmps dircmp dircmps.pop if dircmp.left_only or dircmp.right_only logger.error 'Thefollowingfilesanddirectoriesareonlypresentinonedirectory' if dircmp.left_only logger.error dircmp.left_only else logger.error dircmp.right_only return Trueelif dircmp.common_funny or dircmp.funny_files logger.error 'Thefollowingfilesanddirectoriescouldnotbecompared ' if dircmp.common_funny logger.error dircmp.common_funny else logger.error dircmp.funny_files return Trueelif dircmp.diff_files logger.error 'Thefollowingfilesdiffer ' logger.error dircmp.diff_files return Truefor subdir in dircmp.subdirs.itervalues dircmps.append subdir return False
def list_custom_images call None if call ! 'function' raise SaltCloudSystemExit 'Thelist_vlansfunctionmustbecalledwith-for--function.' ret {}conn get_conn 'SoftLayer_Account' response conn.getBlockDeviceTemplateGroups for image in response if 'globalIdentifier' not in image continueret[image['name']] {'id' image['id'] 'name' image['name'] 'globalIdentifier' image['globalIdentifier']}if 'note' in image ret[image['name']]['note'] image['note']return ret
def start_standalone config args logger.info 'Startstandalonemode' global standalonefrom glances.standalone import GlancesStandalonestandalone GlancesStandalone config config args args standalone.serve_forever
def wait_for_scrub path http httplib2.Http wait_for 300check_every 15for _ in xrange wait_for / check_every time.sleep check_every response content http.request path 'HEAD' if response['x-image-meta-status'] 'deleted' and response['x-image-meta-deleted'] 'True' breakelse continueelse self.fail 'imagewasneverscrubbed'
def train_student dataset nb_teachers assert input.create_dir_if_needed FLAGS.train_dir stdnt_dataset prepare_student_data dataset nb_teachers save True stdnt_data stdnt_labels stdnt_test_data stdnt_test_labels stdnt_datasetif FLAGS.deeper ckpt_path FLAGS.train_dir + '/' + str dataset + '_' + str nb_teachers + '_student_deeper.ckpt' else ckpt_path FLAGS.train_dir + '/' + str dataset + '_' + str nb_teachers + '_student.ckpt' assert deep_cnn.train stdnt_data stdnt_labels ckpt_path ckpt_path_final ckpt_path + '-' + str FLAGS.max_steps - 1 student_preds deep_cnn.softmax_preds stdnt_test_data ckpt_path_final precision metrics.accuracy student_preds stdnt_test_labels print 'Precisionofstudentaftertraining ' + str precision return True
def _clean_ccx_key block_location if isinstance block_location CCXBlockUsageLocator clean_key block_location.to_block_locator else clean_key block_locationreturn clean_key.version_agnostic .for_branch None
def split_repeated_headers kvset headers defaultdict list for key value in kvset headers[key] value.split '\x00' return dict headers
def expand_tabs file0 str_file_contents open file0 'rb' .read str_pep_contents str_file_contents.replace ' DCTB ' 4 * '' open file0 'wb' .write str_pep_contents return None
def get_block_device_mapping image bdm_dict dict bdm getattr image 'block_device_mapping' for device_name in bdm.keys bdm_dict[device_name] {'size' bdm[device_name].size 'snapshot_id' bdm[device_name].snapshot_id 'volume_type' bdm[device_name].volume_type 'encrypted' bdm[device_name].encrypted 'delete_on_termination' bdm[device_name].delete_on_termination}return bdm_dict
def getsourcelines object lines lnum findsource object if ismodule object return lines 0 else return getblock lines[lnum ] lnum + 1
def _expand_node node ret {}ret.update node.__dict__ try del ret['extra']['boot_disk']except Exception passzone ret['extra']['zone']ret['extra']['zone'] {}ret['extra']['zone'].update zone.__dict__ return ret
def onlyif_cmds_exist *commands for cmd in commands if not which cmd return skip "Thistestrunsonlyifcommand'{0}'isinstalled".format cmd return null_deco
def parse_userinfo userinfo if '@' in userinfo or userinfo.count ' ' > 1 raise InvalidURI "' 'or'@'charactersinausernameorpasswordmustbeescapedaccordingtoRFC2396." user _ passwd _partition userinfo ' ' if not user raise InvalidURI 'Theemptystringisnotvalidusername.' user unquote_plus user passwd unquote_plus passwd return user passwd
def connect_to_region region_name **kw_params for region in regions if region.name region_name return region.connect **kw_params return None
def _codeToMessage code try return RESPONSES.get int code except ValueError AttributeError return None
def parse_commit_range repo committishs committishs to_bytes committishs return iter [parse_commit repo committishs ]
def sm_volume_get context volume_id return IMPL.sm_volume_get context volume_id
def _parse_imap reply if not reply or len reply < 2 return False [] stack []pdata []for dline in reply[1] while True if isinstance dline str unicode m IMAP_TOKEN.match dline else print 'WARNING UnparsedIMAPresponsedata %s' % dline m Noneif m token m.group 0 dline dline[len token ]if token[ 1] '"' pdata.append token[1 -1 ] elif token[ 1] ' ' stack.append pdata pdata.append [] pdata pdata[ -1 ]elif token[ 1] ' ' pdata stack.pop -1 elif token[ 1] not in '' ' DCTB ' '\n' '\r' pdata.append token else breakreturn reply[0].upper 'OK' pdata
def getNewDerivation elementNode return GridDerivation elementNode
def _api_test_pushbullet name output kwargs logging.info 'SendingPushbulletnotification' res sabnzbd.notifier.send_pushbullet 'SABnzbd' T 'TestNotification' 'other' force True test kwargs return report output error res
def _functions expr x from sympy import Functionreturn set e.func for e in expr.atoms Function if x in e.free_symbols
def fail_acquire_settings log_printer settings_names_dict section if not isinstance settings_names_dict dict raise TypeError 'Thesettings_names_dictparameterhastobeadictionary.' required_settings settings_names_dict.keys if len required_settings ! 0 msg 'Duringexecution wefoundthatsomerequiredsettingswerenotprovided.Theyare \n'for name setting in settings_names_dict.items msg + '{} from{} -{}'.format name setting[1] setting[0] log_printer.err msg raise AssertionError
def set_virt_file_size self num if num is None or num '' self.virt_file_size 0returnif num '<<inherit>>' self.virt_file_size '<<inherit>>'returnif isinstance num basestring and num.find ' ' ! -1 tokens num.split ' ' for t in tokens self.set_virt_file_size t self.virt_file_size numreturntry inum int num if inum ! float num raise CX _ 'invalidvirtfilesize %s ' % num if inum > 0 self.virt_file_size inumreturnraise CX _ 'invalidvirtfilesize %s ' % num except raise CX _ 'invalidvirtfilesize %s ' % num
def epydoc a b ab[0]b[1]
def Parser file asf Asf file if not len asf.audio or len asf.video return asfaudio AsfAudio for key in audio._keys if key in asf._keys if not getattr audio key None setattr audio key getattr asf key return audio
def grains if not GRAINS_CACHE return _grains DETAILS['host'] DETAILS['protocol'] DETAILS['port'] return GRAINS_CACHE
def getTransformedByList floatList point return floatList[0] * point.x + floatList[1] * point.y + floatList[2] * point.z + floatList[3]
def active_log_format name log_format server _DEFAULT_SERVER ret {'name' name 'changes' {} 'comment' str 'result' None}current_log_format __salt__['win_smtp_server.get_log_format'] server if log_format current_log_format ret['comment'] 'LogPluginClsidalreadycontainstheidoftheprovidedlogformat.'ret['result'] Trueelif __opts__['test'] ret['comment'] 'LogPluginClsidwillbechanged.'ret['changes'] {'old' current_log_format 'new' log_format}else ret['comment'] 'SetLogPluginClsidtocontaintheidoftheprovidedlogformat.'ret['changes'] {'old' current_log_format 'new' log_format}ret['result'] __salt__['win_smtp_server.set_log_format'] log_format server return ret
def win_hibernate try subprocess.Popen 'rundll32powrprof.dll SetSuspendStateHibernate' time.sleep 10 except logging.error T 'Failedtohibernatesystem' logging.info 'Traceback ' exc_info True
def mutual_info_classif X y discrete_features 'auto' n_neighbors 3 copy True random_state None check_classification_targets y return _estimate_mi X y discrete_features True n_neighbors copy random_state
def get_lineno node lineno Nonewhile lineno is None and node node node.parentlineno node.linereturn lineno
def delete_vm options cmd 'salt-cloud-d{0}-y'.format options.delete_vm print 'RunningCMD {0}'.format cmd sys.stdout.flush proc NonBlockingPopen cmd shell True stdout subprocess.PIPE stderr subprocess.PIPE stream_stds True proc.poll_and_read_until_finish interval 0.5 proc.communicate
def read_package_file package relative_path binary False if relative_path is None return Falsepackage_dir _get_package_dir package if os.path.exists package_dir and _regular_file_exists package relative_path return _read_regular_file package relative_path binary if int sublime.version > 3000 result _read_zip_file package relative_path binary if result is not False return resultreturn False
def getManipulatedGeometryOutput geometryOutput xmlElement scalePoints matrix.getConnectionVertexes geometryOutput 'scale.' xmlElement return geometryOutput
def is_groebner G ring for i in range len G for j in range i + 1 len G s spoly G[i] G[j] s s.rem G if s return Falsereturn True
def _item_to_sink iterator log_sink_pb resource MessageToDict log_sink_pb return Sink.from_api_repr resource iterator.client
def _can_have_arbitrary_unit value return np.all np.logical_or np.equal value 0.0 ~ np.isfinite value
def test_image_overlay data [[[1 0 0 1] [0 0 0 0] [0 0 0 0]] [[1 1 0 0.5] [0 0 1 1] [0 0 1 1]]]m folium.Map io plugins.ImageOverlay data [[0 -180 ] [90 180]] mercator_project True io.add_to m m._repr_html_ out m._parent.render url 'data image/png;base64 iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAYAAACddGYaAAAAF0lEQVR42mP4z8AARFDw/z/DeiA5H4QBV60H6ABl9ZIAAAAASUVORK5CYII 'assert io.url url tmpl Template "\nvar{{this.get_name }} L.imageOverlay \n'{{this.url}}' \n{{this.bounds}} \n{{this.options}}\n .addTo {{this._parent.get_name }} ;\n" assert tmpl.render this io in out bounds m.get_bounds assert bounds [[0 -180 ] [90 180]] bounds
def create_package project name sourcefolder None if sourcefolder is None sourcefolder project.rootpackages name.split '.' parent sourcefolderfor package in packages[ -1 ] parent parent.get_child package made_packages parent.create_folder packages[ -1 ] made_packages.create_file '__init__.py' return made_packages
def mime_decode_header line newline ''pos 0while 1 res mime_head.search line pos if res is None breakmatch res.group 1 match ''.join match.split '_' newline newline + line[pos res.start 0 ] + mime_decode match pos res.end 0 return newline + line[pos ]
def all return MIGRATIONS.values
def _handle_exception if sys.stderr einfo sys.exc_info try traceback.print_exception einfo[0] einfo[1] einfo[2] None sys.stderr except IOError passfinally del einfo
def get_top_rated_exploration_summaries limit return _get_exploration_summaries_from_models exp_models.ExpSummaryModel.get_top_rated limit
def render_placeholder context placeholder_name default_layout None template_name None global_type False renderer PlaceholderRenderer context placeholder_name default_layout default_layout template_name template_name global_type global_type return renderer.render
def csviter obj delimiter None headers None encoding None encoding obj.encoding if isinstance obj TextResponse else encoding or 'utf-8' def _getrow csv_r return [str_to_unicode field encoding for field in csv_r.next ]lines StringIO body_or_str obj unicode False if delimiter csv_r csv.reader lines delimiter delimiter else csv_r csv.reader lines if not headers headers _getrow csv_r while True row _getrow csv_r if len row ! len headers log.msg 'ignoringrow%d length %d shouldbe %d ' % csv_r.line_num len row len headers log.WARNING continueelse yield dict zip headers row
def match_metric regex if _TRAFFICCTL cmd _traffic_ctl 'metric' 'match' regex else cmd _traffic_ctl '-m' regex log.debug 'Running %s' cmd return _subprocess cmd
def nzb_redirect wdir nzbname pp script cat priority files []for root _dirs names in os.walk wdir for name in names files.append os.path.join root name for file_ in files if os.path.splitext file_ [1].lower ! '.nzb' return Noneif len files ! 1 nzbname Nonefor file_ in files dirscanner.ProcessSingleFile os.path.split file_ [1] file_ pp script cat priority priority keep False dup_check False nzbname nzbname return files
def _osbornei e d def f rv if not isinstance rv TrigonometricFunction return rva rv.args[0].xreplace {d S.One} if rv.func is sin return sinh a / I elif rv.func is cos return cosh a elif rv.func is tan return tanh a / I elif rv.func is cot return coth a * I elif rv.func is sec return 1 / cosh a elif rv.func is csc return I / sinh a else raise NotImplementedError 'unhandled%s' % rv.func return bottom_up e f
def getGeometryOutputByLoop elementNode sideLoop sideLoop.rotate elementNode return getGeometryOutputByManipulation elementNode sideLoop
def get_config_status cmd 'Get-DscConfigurationStatus|Select-Object-PropertyHostName Status MetaData @{Name "StartDate";Expression {Get-Date $_.StartDate -Formatg}} Type Mode RebootRequested NumberofResources'return _pshell cmd
def _SortChunksByFile chunks chunks_by_file defaultdict list for chunk in chunks filepath chunk[u'range'][u'start'][u'filepath']chunks_by_file[filepath].append chunk return chunks_by_file
def escape_markdown text escape_chars '\\*_`\\['return re.sub ' [%s] ' % escape_chars '\\\\\\1' text
@memory.cachedef load_data dtype np.float32 order 'F' print 'Loadingdataset...' data fetch_mldata 'MNISToriginal' X check_array data['data'] dtype dtype order order y data['target']X X / 255 print 'Creatingtrain-testsplit...' n_train 60000X_train X[ n_train]y_train y[ n_train]X_test X[n_train ]y_test y[n_train ]return X_train X_test y_train y_test
def priority value def decorator target target.priority valuereturn targetreturn decorator
def iirpeak w0 Q return _design_notch_peak_filter w0 Q 'peak'
def studio_help_links page return page.q css '.support.list-actionsa' .results
def write_translations_file app lang full_dict None app_messages None if not app_messages app_messages get_messages_for_app app if not app_messages returntpath frappe.get_pymodule_path app u'translations' frappe.create_folder tpath write_csv_file os.path.join tpath lang + u'.csv' app_messages full_dict or get_full_dict lang
def pr_add_to_role role_id pe_id atable current.s3db.pr_affiliationquery atable.role_id role_id & atable.pe_id pe_id affiliation current.db query .select atable.id limitby 0 1 .first if affiliation is None atable.insert role_id role_id pe_id pe_id pr_rebuild_path pe_id clear True return
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def get_source_line node while node if node.source or node.line return node.source node.line node node.parentreturn None None
def guess_zip_filename zf files zf.namelist if len files 1 return files[0]else for e in files if posixpath.splitext e [0].lower 'hosts' return eraise FileNotFoundError 'Nohostsfilefoundinzip'
def save_subs_to_store subs subs_id item language 'en' filedata json.dumps subs indent 2 filename subs_filename subs_id language return save_to_store filedata filename 'application/json' item.location
def get_non_supported lang lang lang.lower langs dict k.lower v for k v in settings.NON_SUPPORTED_LOCALES.items if lang in langs if langs[lang] is None return settings.LANGUAGE_CODEreturn langs[lang]return None
def _handlers module_name handlers_module try_import '%s.handlers' % module_name if handlers_module is None return []if not hasattr handlers_module '__path__' raise HandlerError 'Module%smustbeadirectory.' % handlers_module.__name__ files find_python_files handlers_module.__path__[0] module_names [ '%s.%s' % handlers_module.__name__ file for file in files]modules [try_import mod_name for mod_name in module_names]return [get_class mod BaseHandler for mod in modules if mod]
def render_to_link_list link_list return render_to_js_vardef 'tinyMCELinkList' link_list
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def generate_localized_events generator if 'i18n_subsites' in generator.settings['PLUGINS'] if not os.path.exists generator.settings['OUTPUT_PATH'] os.makedirs generator.settings['OUTPUT_PATH'] for e in events if 'lang' in e.metadata localized_events[e.metadata['lang']].append e else log.debug 'event%scontainsnolangattribute' % e.metadata['title']
def bounds_overlap bound1 bound2 x1 y1 w1 h1 bound1 x2 y2 w2 h2 bound2if x1 + w1 < x2 return Falseif x2 + w2 < x1 return Falseif y1 + h1 < y2 return Falseif y2 + h2 < y1 return Falsereturn True
def validipaddr address try octets address.split '.' if len octets ! 4 return Falsefor x in octets if not 0 < int x < 255 return Falseexcept ValueError return Falsereturn True
def cities2table filename rel_name dbname verbose False setup False import sqlite3records _str2records filename rel_name connection sqlite3.connect dbname cur connection.cursor if setup cur.execute u'CREATETABLEcity_table\n Citytext Countrytext Populationint ' table_name u'city_table'for t in records cur.execute u'insertinto%svalues ? ? ? ' % table_name t if verbose print u'insertingvaluesinto%s ' % table_name t connection.commit if verbose print u'Committingupdateto%s' % dbname cur.close
def extract_documentation content language docstyle docstyle_definition DocstyleDefinition.load language docstyle return extract_documentation_with_markers content docstyle_definition
def provide_session func @wraps func def wrapper *args **kwargs needs_session Falsearg_session u'session'func_params func.__code__.co_varnamessession_in_args arg_session in func_params and func_params.index arg_session < len args if not arg_session in kwargs or session_in_args needs_session Truesession settings.Session kwargs[arg_session] sessionresult func *args **kwargs if needs_session session.expunge_all session.commit session.close return resultreturn wrapper
def load_rsa_private_key *names loader _guess_loader names[ -1 ] serialization.load_pem_private_key serialization.load_der_private_key return jose.ComparableRSAKey loader load_vector *names password None backend default_backend
def fallback_humanize date fallback_format None use_fallback False date arrow.get date .to 'local' if not fallback_format fallback_format '%Y/%m/%d%H %M %S'if use_fallback return date.datetime.strftime fallback_format try lang encode locale.getdefaultlocale clock date.humanize locale lang except if not dg['humanize_unsupported'] dg['humanize_unsupported'] TrueprintNicely light_magenta 'Humanizeddatedisplaymethoddoesnotsupportyour$LC_ALL.' clock date.datetime.strftime fallback_format return clock
def _determine_notification_info notification_arn notification_arn_from_pillar notification_types notification_types_from_pillar pillar_arn_list copy.deepcopy __salt__['config.option'] notification_arn_from_pillar {} pillar_arn Noneif len pillar_arn_list > 0 pillar_arn pillar_arn_list[0]pillar_notification_types copy.deepcopy __salt__['config.option'] notification_types_from_pillar {} arn notification_arn if notification_arn else pillar_arn types notification_types if notification_types else pillar_notification_types return arn types
@ssl_required@anonymous_csrf@mobile_template 'users/{mobile/}pw_reset_confirm.html' def password_reset_confirm request template uidb36 None token None try uid_int base36_to_int uidb36 except ValueError raise Http404user get_object_or_404 User id uid_int context {}if default_token_generator.check_token user token context['validlink'] Trueif request.method 'POST' form SetPasswordForm user request.POST if form.is_valid form.save return HttpResponseRedirect reverse 'users.pw_reset_complete' else form SetPasswordForm None else context['validlink'] Falseform Nonecontext['form'] formreturn render request template context
def color_name data bits ret ['#']for i in range 3 ret.append '%02X' % data[i] << 8 - bits[i] return ''.join ret
def freeze_region clip t 0 region None outside_region None mask None if region is not None x1 y1 x2 y2 regionfreeze clip.fx crop *region .to_ImageClip t t .set_duration clip.duration .set_position x1 y1 return CompositeVideoClip [clip freeze] elif outside_region is not None x1 y1 x2 y2 outside_regionanimated_region clip.fx crop *outside_region .set_position x1 y1 freeze clip.to_ImageClip t t .set_duration clip.duration return CompositeVideoClip [freeze animated_region] elif mask is not None freeze clip.to_ImageClip t t .set_duration clip.duration .set_mask mask return CompositeVideoClip [clip freeze]
def binipdisplay s if len s % 4 ! 0 raise EnvironmentErrorol []for i in range len s / 4 s1 s[ 4]s s[4 ]ip []for j in s1 ip.append str ord j ol.append string.join ip '.' return ol
def create_modulestore_instance engine contentstore doc_store_config options i18n_service None fs_service None user_service None signal_handler None class_ load_function engine if issubclass class_ ModuleStoreDraftAndPublished options['branch_setting_func'] lambda ModuleStoreEnum.Branch.draft_preferred return class_ doc_store_config doc_store_config contentstore contentstore signal_handler signal_handler **options
def apply_grover oracle nqubits iterations None if nqubits < 0 raise QuantumError "Grover'salgorithmneedsnqubits>0 received%rqubits" % nqubits if iterations is None iterations floor sqrt 2 ** nqubits * pi / 4 v OracleGate nqubits oracle iterated superposition_basis nqubits for iter in range iterations iterated grover_iteration iterated v iterated qapply iterated return iterated
def dictfetchmany cursor number return cursor.dictfetchmany number
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def Product sequence return reduce lambda x y x * y sequence
def print_tb tb limit None file None if file is None file sys.stderrif limit is None if hasattr sys 'tracebacklimit' limit sys.tracebacklimitn 0while tb is not None and limit is None or n < limit f tb.tb_framelineno tb.tb_linenoco f.f_codefilename co.co_filenamename co.co_name_print file 'File"%s" line%d in%s' % filename lineno name linecache.checkcache filename line linecache.getline filename lineno f.f_globals if line _print file '' + line.strip tb tb.tb_nextn n + 1
def points_at_corner_index contour index return [contour[ i + 1 ] for i in index]
def recapitalize text text force_unicode text .lower capsRE re.compile ' ? ^| ?< [\\.\\?\\!] [a-z] ' text capsRE.sub lambda x x.group 1 .upper text return text
def bootstrap_sample data return [random.choice data for _ in data]
@login_required@require_http_methods 'GET' 'DELETE' def orphan_handler request course_key_string course_usage_key CourseKey.from_string course_key_string if request.method 'GET' if has_studio_read_access request.user course_usage_key return JsonResponse [unicode item for item in modulestore .get_orphans course_usage_key ] else raise PermissionDenied if request.method 'DELETE' if request.user.is_staff deleted_items _delete_orphans course_usage_key request.user.id commit True return JsonResponse {'deleted' deleted_items} else raise PermissionDenied
def exec_statement statement statement textwrap.dedent statement cmd ['-c' statement]return __exec_python_cmd cmd
def test_functions_as_bound_methods callable_attrs filter callable getattr t a None for a in dir t if not a.startswith '__' or a.endswith '__' for attr in callable_attrs assert isinstance attr MethodType assert attr.__self__ is t or attr.__self__ is type t
def get_accessible_discussion_xblocks course user include_all False all_xblocks modulestore .get_items course.id qualifiers {'category' 'discussion'} include_orphans False return [xblock for xblock in all_xblocks if has_required_keys xblock and include_all or has_access user 'load' xblock course.id ]
def canvass return s3_rest_controller
def dmp_pow f n u K if not u return dup_pow f n K if not n return dmp_one u K if n < 0 raise ValueError "can'traisepolynomialtoanegativepower" if n 1 or dmp_zero_p f u or dmp_one_p f u K return fg dmp_one u K while True n m n // 2 n if m & 1 g dmp_mul g f u K if not n breakf dmp_sqr f u K return g
@receiver user_logged_in @receiver user_logged_out def enforce_single_login sender request user signal **kwargs if settings.FEATURES.get 'PREVENT_CONCURRENT_LOGINS' False if signal user_logged_in key request.session.session_keyelse key Noneif user user_profile __ UserProfile.objects.get_or_create user user defaults {'name' user.username} if user_profile user.profile.set_login_session key
def glibc_version_string process_namespace ctypes.CDLL None try gnu_get_libc_version process_namespace.gnu_get_libc_versionexcept AttributeError return Nonegnu_get_libc_version.restype ctypes.c_char_pversion_str gnu_get_libc_version if not isinstance version_str str version_str version_str.decode 'ascii' return version_str
def cloneParasite individual clone individual.__class__ list seq for seq in individual clone.fitness.values individual.fitness.valuesreturn clone
def connect_on_app_finalize callback _on_app_finalizers.add callback return callback
def check_course_access course_key user None ip_address None url None if not settings.FEATURES.get 'EMBARGO' return Truecourse_is_restricted RestrictedCourse.is_restricted_course course_key if not course_is_restricted return Trueif user is not None and has_course_author_access user course_key return Trueif ip_address is not None user_country_from_ip _country_code_from_ip ip_address if not CountryAccessRule.check_country_access course_key user_country_from_ip log.info u"Blockinguser%sfromaccessingcourse%sat%sbecausetheuser'sIPaddress%sappearstobelocatedin%s." getattr user 'id' '<NotAuthenticated>' course_key url ip_address user_country_from_ip return Falseif user is not None user_country_from_profile _get_user_country_from_profile user if not CountryAccessRule.check_country_access course_key user_country_from_profile log.info u"Blockinguser%sfromaccessingcourse%sat%sbecausetheuser'sprofilecountryis%s." user.id course_key url user_country_from_profile return Falsereturn True
def cheby1 N rp Wn btype 'low' analog False output 'ba' return iirfilter N Wn rp rp btype btype analog analog output output ftype 'cheby1'
def cmoment X n condition None **kwargs mu expectation X condition **kwargs return moment X n mu condition **kwargs
def resolve_etag_is_at_header req metadata alternate_etag Nonemetadata HeaderKeyDict metadata if 'X-Backend-Etag-Is-At' in req.headers names list_from_csv req.headers['X-Backend-Etag-Is-At'] for name in names if name in metadata alternate_etag metadata[name]breakreturn alternate_etag
def merge_and_compress_summaries vals_and_weights vals_and_weights [x for x in vals_and_weights if x]if not vals_and_weights return it merge_sorted *[zip x y for x y in vals_and_weights] vals []weights []vals_append vals.appendweights_append weights.append val weight prev_val prev_weight next it for val weight in it if val prev_val prev_weight + weightelse vals_append prev_val weights_append prev_weight prev_val prev_weight val weight if val prev_val vals_append prev_val weights_append prev_weight return vals weights
def env_to_bool input if isinstance input str if input 'False' return Falseelse return Trueelse return input
def test_simple_concurrency pool make_pool 1 1 for i in range 3 pool.put FakeTarPartition 1 pool.join
def _InitColorize output_file color Falseif options.options.colorize is not None and curses and options.options.color 'yes' or options.options.color 'auto' and output_file.isatty try curses.setupterm if curses.tigetnum 'colors' > 0 color Trueexcept Exception passif not color return []directives []normal unicode curses.tigetstr 'sgr0' 'ascii' fg_color unicode curses.tigetstr 'setaf' or curses.tigetstr 'setf' or '' 'ascii' for directive in options.options.colorize regexp color_index directive.split ' ' color unicode curses.tparm fg_color int color_index 'ascii' directives.append ColorDirective re.compile regexp color normal return directives
def test_LogitLocator_set_params loc mticker.LogitLocator loc.set_params minor True assert loc.minor
def _get_contract_head_file_path config return os.path.join _get_root_versions_dir config CONTRACT_HEAD_FILENAME
def create_new_event_transaction_id new_id uuid4 get_cache 'event_transaction' ['id'] new_idreturn new_id
def _find_prefix filename if not is_venv return sys.prefixfilename os.path.abspath filename prefixes [os.path.abspath sys.prefix base_prefix]possible_prefixes []for prefix in prefixes common os.path.commonprefix [prefix filename] if common prefix possible_prefixes.append prefix possible_prefixes.sort key lambda p len p reverse True return possible_prefixes[0]
def _unimplemented func @functools.wraps func def wrapper *args **kwargs try func *args **kwargs except TypingError raise unittest._ExpectedFailure sys.exc_info raise unittest._UnexpectedSuccess
def validate_iops iops iops integer iops if int iops 0 return iopsif int iops < 1000 raise ValueError 'DBInstanceIops ifset mustbegreaterthan1000.' return iops
def display_graph g format u'svg' include_asset_exists False try import IPython.display as displayexcept ImportError raise NoIPython u"IPythonisnotinstalled.Can'tdisplaygraph." if format u'svg' display_cls display.SVGelif format in u'jpeg' u'png' display_cls partial display.Image format format embed True out BytesIO _render g out format include_asset_exists include_asset_exists return display_cls data out.getvalue
def canonicalTitle title lang None imdbIndex None isUnicode isinstance title unicode articlesDicts linguistics.articlesDictsForLang lang try if title.split ' ' [ -1 ].lower in articlesDicts[isUnicode] return titleexcept IndexError passif isUnicode _format u'%s%s %s'else _format '%s%s %s'ltitle title.lower if imdbIndex imdbIndex ' %s ' % imdbIndex else imdbIndex ''spArticles linguistics.spArticlesForLang lang for article in spArticles[isUnicode] if ltitle.startswith article lart len article title _format % title[lart ] imdbIndex title[ lart] if article[ -1 ] '' title title[ -1 ]breakreturn title
def binarize X threshold 0.0 copy True X check_array X accept_sparse ['csr' 'csc'] copy copy if sparse.issparse X if threshold < 0 raise ValueError 'Cannotbinarizeasparsematrixwiththreshold<0' cond X.data > threshold not_cond np.logical_not cond X.data[cond] 1X.data[not_cond] 0X.eliminate_zeros else cond X > threshold not_cond np.logical_not cond X[cond] 1X[not_cond] 0return X
def ensure_dict param default_value default_key None if not param param default_valueif not isinstance param dict if param default_value paramreturn {default_key param} default_value return param default_value
def _handleTextNotes s ssplit s.split ' ' 1 if len ssplit 1 return sreturn u'%s<notes>%s</notes>' % ssplit[0] ssplit[1]
def two_step_backprop mlp raise NotImplementedError 'TODO implementthisfunction.'
@step u'notethat"{remark}"' def step_note_that context remark log getattr context 'log' None if log log.info u'NOTE %s;' % remark
def SetProperties msg propDict newProps []for key val in propDict.iteritems if type key in [str unicode] newProps.append mapi.PS_PUBLIC_STRINGS key if newProps newIds msg.GetIDsFromNames newProps mapi.MAPI_CREATE newIdNo 0newProps []for key val in propDict.iteritems if type key in [str unicode] type_val type val if type_val in [str unicode] tagType mapitags.PT_UNICODEelif type_val IntType tagType mapitags.PT_I4elif type_val TimeType tagType mapitags.PT_SYSTIMEelse raise ValueError 'Thetypeofobject%s %s cannotbewritten' % repr val type_val key mapitags.PROP_TAG tagType mapitags.PROP_ID newIds[newIdNo] newIdNo newIdNo + 1 newProps.append key val msg.SetProps newProps
@decorators.which_bin ['lsblk' 'df'] def fstype device if salt.utils.which 'lsblk' lsblk_out __salt__['cmd.run'] 'lsblk-ofstype{0}'.format device .splitlines if len lsblk_out > 1 fs_type lsblk_out[1].strip if fs_type return fs_typeif salt.utils.which 'df' df_out __salt__['cmd.run'] 'df-T{0}'.format device .splitlines if len df_out > 1 fs_type df_out[1]if fs_type return fs_typereturn ''
def _getargs func import typesif sys.version_info > 3 0 if isinstance func types.MethodType func func.__func__co func.__code__else if isinstance func types.MethodType func func.im_funcco func.func_codereturn co.co_varnames[ co.co_argcount]
def box on None ax gca on _string_to_bool on if on is None on not ax.get_frame_on ax.set_frame_on on
def call_status *args **kwargs res dict devices _get_lights for dev_id in 'id' not in kwargs and sorted devices.keys or _get_devices kwargs res[dev_id] {'on' devices[dev_id]['state']['on'] 'reachable' devices[dev_id]['state']['reachable']}return res
@permission_required 'users.add_userban' def ban_user request username User get_user_model user get_object_or_404 User username username if request.method 'POST' form UserBanForm data request.POST if form.is_valid ban UserBan user user by request.user reason form.cleaned_data['reason'] is_active True ban.save return redirect user else if user.active_ban return redirect user form UserBanForm try common_reasons json.loads config.COMMON_REASONS_TO_BAN_USERS except TypeError ValueError common_reasons ['Spam']else if not common_reasons common_reasons ['Spam']return render request 'users/ban_user.html' {'form' form 'detail_user' user 'common_reasons' common_reasons}
def calcHA1 pszAlg pszUserName pszRealm pszPassword pszNonce pszCNonce preHA1 None if preHA1 and pszUserName or pszRealm or pszPassword raise TypeError 'preHA1isincompatiblewiththepszUserName pszRealm andpszPasswordarguments' if preHA1 is None m algorithms[pszAlg] m.update pszUserName m.update ' ' m.update pszRealm m.update ' ' m.update pszPassword HA1 m.digest else HA1 preHA1.decode 'hex' if pszAlg 'md5-sess' m algorithms[pszAlg] m.update HA1 m.update ' ' m.update pszNonce m.update ' ' m.update pszCNonce HA1 m.digest return HA1.encode 'hex'
def setup_index page_info if page_info.basename u'' index_txt_path os.path.join page_info.basepath u'index.txt' if os.path.exists index_txt_path page_info.index open index_txt_path u'r' .read .splitlines
def get_client_ip request if 'HTTP_X_REAL_IP' in request.META if request.META['REMOTE_ADDR'] not in atc_api_settings.PROXY_IPS raise ValueError 'HTTP_X_REAL_IPsetbynon-proxy' return request.META['HTTP_X_REAL_IP']else return request.META['REMOTE_ADDR']
def sectorize position x y z normalize position x y z x // SECTOR_SIZE y // SECTOR_SIZE z // SECTOR_SIZE return x 0 z
def setup_test_template_loader templates_dict use_cached_loader False if hasattr loader RESTORE_LOADERS_ATTR raise Exception 'loader.%salreadyexists' % RESTORE_LOADERS_ATTR def test_template_loader template_name template_dirs None 'Acustomtemplateloaderthatloadstemplatesfromadictionary.'try return templates_dict[template_name] 'test %s' % template_name except KeyError raise TemplateDoesNotExist template_name if use_cached_loader template_loader cached.Loader 'test_template_loader' template_loader._cached_loaders test_template_loader else template_loader test_template_loadersetattr loader RESTORE_LOADERS_ATTR loader.template_source_loaders loader.template_source_loaders template_loader return template_loader
def sqrtdenest expr max_iter 3 expr expand_mul sympify expr for i in range max_iter z _sqrtdenest0 expr if expr z return exprexpr zreturn expr
def getHypersearchWinningModelID jobID cjDAO ClientJobsDAO.get jobResults cjDAO.jobGetFields jobID ['results'] [0]print 'Hypersearchjobresults %r' % jobResults jobResults json.loads jobResults return jobResults['bestModel']
@handle_response_format@treeio_login_required@module_admin_required def perspective_add request response_format 'html' if request.POST if 'cancel' not in request.POST perspective Perspective form PerspectiveForm request.user.profile request.POST instance perspective if form.is_valid perspective form.save perspective.set_user_from_request request return HttpResponseRedirect reverse 'core_admin_perspective_view' args [perspective.id] else return HttpResponseRedirect reverse 'core_admin_index_perspectives' else form PerspectiveForm request.user.profile return render_to_response 'core/administration/perspective_add' {'form' form.as_ul } context_instance RequestContext request response_format response_format
def _CanMergeLineIntoIfStatement lines limit if len lines[1].tokens 1 and lines[1].last.is_multiline_string return Trueif lines[0].lineno ! lines[1].lineno return Falseif lines[1].last.total_length > limit return Falsereturn style.Get 'JOIN_MULTIPLE_LINES'
def command_output cmd shell False proc subprocess.Popen cmd stdout subprocess.PIPE stderr subprocess.PIPE close_fds platform.system ! 'Windows' shell shell stdout stderr proc.communicate if proc.returncode raise subprocess.CalledProcessError returncode proc.returncode cmd ''.join cmd return stdout
def get_image_model_string return getattr settings u'WAGTAILIMAGES_IMAGE_MODEL' u'wagtailimages.Image'
def QTEV type uuid hostname clock name None timestamp None return Event u'task-{0}'.format type uuid uuid hostname hostname clock clock name name timestamp timestamp or time
def getArcPath elementNode begin elementNode.getPreviousVertex Vector3 end evaluate.getVector3FromElementNode elementNode largeArcFlag evaluate.getEvaluatedBoolean True elementNode 'largeArcFlag' radius lineation.getComplexByPrefix elementNode 'radius' complex 1.0 1.0 sweepFlag evaluate.getEvaluatedBoolean True elementNode 'sweepFlag' xAxisRotation math.radians evaluate.getEvaluatedFloat 0.0 elementNode 'xAxisRotation' arcComplexes svg_reader.getArcComplexes begin.dropAxis end.dropAxis largeArcFlag radius sweepFlag xAxisRotation path []if len arcComplexes < 1 return []incrementZ end.z - begin.z / float len arcComplexes z begin.zfor pointIndex in xrange len arcComplexes pointComplex arcComplexes[pointIndex]z + incrementZpath.append Vector3 pointComplex.real pointComplex.imag z if len path > 0 path[ -1 ] endreturn path
def _do_extrapolate fill_value return isinstance fill_value string_types and fill_value 'extrapolate'
@register u'insert-comment' def insert_comment event buff event.current_bufferif event.arg ! 1 def change line return line[1 ] if line.startswith u'#' else line else def change line return u'#' + line buff.document Document text u'\n'.join map change buff.text.splitlines cursor_position 0 buff.accept_action.validate_and_handle event.cli buff
def address_type address return len address 4 and _TYPE_A or _TYPE_AAAA
def vb_start_vm name None timeout 10000 **kwargs start_time time.time timeout_in_seconds timeout / 1000 max_time start_time + timeout_in_seconds vbox vb_get_box machine vbox.findMachine name session _virtualboxManager.getSessionObject vbox log.info 'Startingmachine%sinstate%s' name vb_machinestate_to_str machine.state try args machine session progress wait_for _start_machine timeout timeout_in_seconds func_args args if not progress progress machine.launchVMProcess session '' '' time_left max_time - time.time progress.waitForCompletion time_left * 1000 finally _virtualboxManager.closeMachineSession session time_left max_time - time.time vb_wait_for_session_state session timeout time_left log.info 'Startedmachine%s' name return vb_xpcom_to_attribute_dict machine 'IMachine'
def treeapply tree join leaf identity for typ in join if isinstance tree typ return join[typ] *map partial treeapply join join leaf leaf tree return leaf tree
def trailing n n int n if not n return 0low_byte n & 255 if low_byte return small_trailing[low_byte]z bitcount n - 1 if isinstance z SYMPY_INTS if n 1 << z return zt 0p 8while not n & 1 while not n & 1 << p - 1 n >> pt + pp * 2p // 2return t
def read_raw_ctf directory system_clock 'truncate' preload False verbose None return RawCTF directory system_clock preload preload verbose verbose
def test_x_2d assert_equal lae_a.X.ndim 2 assert_equal lae_b.X.ndim 2
def remove_zone_slave service master_device_id service.data.get 'master' slaves_ids service.data.get 'slaves' slaves [device for device in DEVICES if device.entity_id in slaves_ids ]master next [device for device in DEVICES if device.entity_id master_device_id ].__iter__ None if master is None _LOGGER.warning 'Unabletofindmasterwithentity_id ' + master_device_id elif not slaves _LOGGER.warning 'Unabletofindslavestoremove' else _LOGGER.info 'Removingslavesfromzonewithmaster' + str master.device.config.name master.device.remove_zone_slave [slave.device for slave in slaves]
def is_consistent_type theType name *constructionArgs assert theType.__name__ name assert isinstance theType type instance theType *constructionArgs assert type instance is theType return True
@register.inclusion_tag 'zinnia/tags/dummy.html' def get_popular_entries number 5 template 'zinnia/tags/entries_popular.html' return {'template' template 'entries' Entry.published.filter comment_count__gt 0 .order_by '-comment_count' '-publication_date' [ number]}
def to_7L1M value return value & 127 value >> 7 & 1
def in_reactor f def wrap *args **kwargs from twisted.internet import reactor deferresult []def async d defer.maybeDeferred f *args **kwargs @d.addErrbackdef eb f f.printTraceback @d.addBothdef do_stop r result.append r reactor.stop reactor.callWhenRunning async reactor.run return result[0]wrap.__doc__ f.__doc__wrap.__name__ f.__name__wrap._orig freturn wrap
def retract_bindings fstruct bindings fs_class u'default' if fs_class u'default' fs_class _default_fs_class fstruct fstruct new_bindings copy.deepcopy fstruct bindings bindings.update new_bindings inv_bindings dict id val var for var val in bindings.items _retract_bindings fstruct inv_bindings fs_class set return fstruct
def _clear_context for key in list __context__ try if key.startswith 'systemd._systemctl_status.' or key in 'systemd.systemd_services' __context__.pop key except AttributeError continue
def generate_timestamp return int time.time
def isident s first string.uppercase + '_' body string.digits + first if not s return Falseif s[0] not in first return Falseif not all c in body for c in s[1 ] return Falsereturn True
def local_align_primer_seq primer sequence sw_scorer equality_scorer_ambigs query_primer primerquery_sequence str sequence alignment pair_hmm_align_unaligned_seqs [query_primer query_sequence] primer_hit str alignment.Seqs[0] target_hit str alignment.Seqs[1] insertions primer_hit.count '-' deletions target_hit.count '-' mismatches 0for i in range len target_hit if sw_scorer target_hit[i] primer_hit[i] -1 and target_hit[i] ! '-' and primer_hit[i] ! '-' mismatches + 1try hit_start query_sequence.index target_hit.replace '-' '' except ValueError raise ValueError 'substringnotfound querystring%s target_hit%s' % query_sequence target_hit mismatch_count insertions + deletions + mismatches return mismatch_count hit_start
def thetagrids *args **kwargs ax gca if not isinstance ax PolarAxes raise RuntimeError 'rgridsonlydefinedforpolaraxes' if len args 0 lines ax.xaxis.get_ticklines labels ax.xaxis.get_ticklabels else lines labels ax.set_thetagrids *args **kwargs draw_if_interactive return silent_list 'Line2Dthetagridline' lines silent_list 'Textthetagridlabel' labels
def create_module_bookmark_actions parent bookmarks actions []for key url title in bookmarks create_act Trueif key 'winpython' if not programs.is_module_installed key create_act Falseif create_act act create_bookmark_action parent url title actions.append act return actions
def ProfileListEntryFromString xml_string return atom.CreateClassFromXMLString ProfileListEntry xml_string
def _set_term_title *args **kw pass
def is_nose_class cls return any name in [u'setUp' u'tearDown'] for name _ in inspect.getmembers cls
def get_location vm_ None return __opts__.get 'location' config.get_cloud_config_value 'location' vm_ or get_configured_provider __opts__ default DEFAULT_LOCATION search_global False
def _copy master_fd master_read _read stdin_read _read fds [master_fd STDIN_FILENO]while True rfds wfds xfds select fds [] [] if master_fd in rfds data master_read master_fd if not data fds.remove master_fd else os.write STDOUT_FILENO data if STDIN_FILENO in rfds data stdin_read STDIN_FILENO if not data fds.remove STDIN_FILENO else _writen master_fd data
def CreateCMakeTargetFullName qualified_target gyp_file gyp_target_name gyp_target_toolset gyp.common.ParseQualifiedTarget qualified_target cmake_target_full_name gyp_file + ' ' + gyp_target_name if gyp_target_toolset and gyp_target_toolset ! 'target' cmake_target_full_name + '_' + gyp_target_toolset return StringToCMakeTargetName cmake_target_full_name
def flow_from_clientsecrets filename scope message None try client_type client_info clientsecrets.loadfile filename if client_type in [clientsecrets.TYPE_WEB clientsecrets.TYPE_INSTALLED] return OAuth2WebServerFlow client_info['client_id'] client_info['client_secret'] scope None client_info['auth_uri'] client_info['token_uri'] except clientsecrets.InvalidClientSecretsError if message sys.exit message else raiseelse raise UnknownClientSecretsFlowError 'ThisOAuth2.0flowisunsupported "%s"' * client_type
def get_installed_extension name user None host None port None maintenance_db None password None runas None return installed_extensions user user host host port port maintenance_db maintenance_db password password runas runas .get name None
def dup_sqf_list_include f K all False coeff factors dup_sqf_list f K all all if factors and factors[0][1] 1 g dup_mul_ground factors[0][0] coeff K return [ g 1 ] + factors[1 ] else g dup_strip [coeff] return [ g 1 ] + factors
def mcycles_to_seconds mcycles if mcycles is None return 0return quota.megacycles_to_cpu_seconds mcycles
def length_prefix length offset if length < 56 return chr offset + length else length_string int_to_big_endian length return chr offset + 56 - 1 + len length_string + length_string
def depart_snippet_literal self node self.depart_literal_block node
def get_affected_nodes db addon_class query db['node'].find {'.'.join '__backrefs' 'addons' addon_class.__name__.lower 'owner' '0' {'$exists' False}} return Node.load node['_id'] for node in query
def gf_frobenius_map f g b p K m gf_degree g if gf_degree f > m f gf_rem f g p K if not f return []n gf_degree f sf [f[ -1 ]]for i in range 1 n + 1 v gf_mul_ground b[i] f[ n - i ] p K sf gf_add sf v p K return sf
@nottestdef slow_test f f.slow_test Truereturn f
def _count_elements mapping iterable mapping_get mapping.getfor elem in iterable mapping[elem] mapping_get elem 0 + 1
def guess_spatial_dimensions image if image.ndim 2 return 2if image.ndim 3 and image.shape[ -1 ] ! 3 return 3if image.ndim 3 and image.shape[ -1 ] 3 return Noneif image.ndim 4 and image.shape[ -1 ] 3 return 3else raise ValueError 'Expected2D 3D or4Darray got%iD.' % image.ndim
def parse_repl_named_char source saved_pos source.posif source.match '{' name source.get_while ALPHA | set '' if source.match '}' try value unicodedata.lookup name return ord value except KeyError raise error 'undefinedcharactername' source.string source.pos source.pos saved_posreturn None
@must_be_logged_indef user_choose_mailing_lists auth **kwargs user auth.userjson_data escape_html request.get_json if json_data for list_name subscribe in json_data.items if list_name settings.OSF_HELP_LIST update_osf_help_mails_subscription user user subscribe subscribe else update_mailchimp_subscription user list_name subscribe else raise HTTPError http.BAD_REQUEST data dict message_long "Mustprovideadictionaryoftheformat{'mailinglistname' Boolean}" user.save all_mailing_lists {}all_mailing_lists.update user.mailchimp_mailing_lists all_mailing_lists.update user.osf_mailing_lists return {'message' 'Successfullyupdatedmailinglists' 'result' all_mailing_lists} 200
def count_unbalanced_brackets line count 0for opening closing in [u' ' u'[]' u'{}'] count + abs line.count opening - line.count closing return count
@with_setup prepare_stdout def test_output_of_table_with_success_colorless runner Runner join_path 'pt-br' 'success' 'table.feature' verbosity 3 no_color True runner.run assert_stdout_lines u'\nFuncionalidade featureburra comtabela#tests/functional/language_specific_features/pt-br/success/table.feature 3\nComoumprogramador#tests/functional/language_specific_features/pt-br/success/table.feature 4\nEuquerotestarstepscomtabelas#tests/functional/language_specific_features/pt-br/success/table.feature 5\nParaverooutputempt-br#tests/functional/language_specific_features/pt-br/success/table.feature 6\n\nCen\xe1rio Fazernada comtabelas #tests/functional/language_specific_features/pt-br/success/table.feature 8\nDadoqueeubrincocomosseguintesitens #tests/functional/language_specific_features/pt-br/success/table_steps.py 6\n|id|description|\n|12|somedesc|\n|64|anotherdesc|\n\n1feature 1passed \n1scenario 1passed \n1step 1passed \n'
def verify_and_update_password password user if _pwd_context.identify user.password ! 'plaintext' password get_hmac password verified new_password _pwd_context.verify_and_update password user.password if verified and new_password user.password encrypt_password password _datastore.put user return verified
def setLoggerClass loggingClass assert issubclass loggingClass ILogger 'loggingClassmustsubclassILogger'global _LoggerClass_LoggerClass loggingClass
def add_taps module brew_path taps failed unchanged added msg False 0 0 '' for tap in taps failed changed msg add_tap module brew_path tap if failed breakif changed added + 1else unchanged + 1if failed msg 'added %d unchanged %d error ' + msg msg msg % added unchanged elif added changed Truemsg 'added %d unchanged %d' % added unchanged else msg 'added %d unchanged %d' % added unchanged return failed changed msg
def check_pg_name name if not regex_pg_name.match name raise ValidationError 'Invalidcharactersintablename%r' % name if len name > 63 raise ValidationError 'Tablename%ristoolong' % name
def render_final_params runner_parameters action_parameters params action_context G _create_graph action_context [G.add_node name value value for name value in six.iteritems params ]_process_defaults G [action_parameters runner_parameters] _validate G context _resolve_dependencies G context _cast_params_from context context [action_parameters runner_parameters] return _split_params runner_parameters action_parameters context
def is_modified kev fflags kev.fflagsreturn fflags & select.KQ_NOTE_EXTEND or fflags & select.KQ_NOTE_WRITE
def abs mat target None if not target target materr_code _cudamat.apply_abs mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def colorize image hue saturation 1 hsv color.rgb2hsv image hsv[ 1] saturationhsv[ 0] huereturn color.hsv2rgb hsv
def replication_group_exists name region None key None keyid None profile None return bool describe_replication_groups name name region region key key keyid keyid profile profile
def create_ca_file anchor_list filename try f open filename 'w' for a in anchor_list s a.output fmt 'PEM' f.write s f.close except return Nonereturn filename
def set_descriptor dev desc desc_type desc_index wIndex None wValue desc_index | desc_type << 8 bmRequestType util.build_request_type util.CTRL_OUT util.CTRL_TYPE_STANDARD util.CTRL_RECIPIENT_DEVICE dev.ctrl_transfer bmRequestType bmRequestType bRequest 7 wValue wValue wIndex wIndex data_or_wLength desc
def getLoopsLoopsIntersections loops otherLoops loopsLoopsIntersections []for loop in loops addLoopLoopsIntersections loop loopsLoopsIntersections otherLoops return loopsLoopsIntersections
def sqlors left lst if isinstance lst iters lst list lst ln len lst if ln 0 return SQLQuery '1 2' if ln 1 lst lst[0]if isinstance lst iters return SQLQuery [' '] + sum [[left sqlparam x 'OR'] for x in lst] [] + ['1 2 '] else return left + sqlparam lst
def get_file_device_path fname fname os.path.realpath fname mtab_dict {}try for ent in get_mtab mtab_dict[ent.mnt_dir] ent.mnt_fsnameexcept passfdir os.path.dirname fname if fdir in mtab_dict match Trueelse match Falsechrootfs Falsewhile not match if fdir os.path.sep chrootfs Truebreakfdir os.path.realpath os.path.join fdir os.path.pardir if fdir in mtab_dict match Trueelse match Falseif fdir ! os.path.sep fname fname[len fdir ]if chrootfs return ' ' fname else return mtab_dict[fdir] fname
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def variation a axis 0 a axis _chk_asarray a axis return a.std axis / a.mean axis
def _argus_phi chi return _norm_cdf chi - chi * _norm_pdf chi - 0.5
def pairwise_kernels X Y None metric 'linear' filter_params False n_jobs 1 **kwds from ..gaussian_process.kernels import Kernel as GPKernelif metric 'precomputed' X _ check_pairwise_arrays X Y precomputed True return Xelif isinstance metric GPKernel func metric.__call__elif metric in PAIRWISE_KERNEL_FUNCTIONS if filter_params kwds dict k kwds[k] for k in kwds if k in KERNEL_PARAMS[metric] func PAIRWISE_KERNEL_FUNCTIONS[metric]elif callable metric func partial _pairwise_callable metric metric **kwds else raise ValueError 'Unknownkernel%r' % metric return _parallel_pairwise X Y func n_jobs **kwds
def add_links_plan scheme links force_replace False links_to_add list links links_to_remove [conflicting_single_link scheme link for link in links]links_to_remove [_f for _f in links_to_remove if _f]if not force_replace links_to_add links_to_remove remove_duplicates links_to_add links_to_remove return links_to_add links_to_remove
def create_epic **kwargs owner kwargs.pop 'owner' None if not owner owner UserFactory.create project kwargs.pop 'project' None if project is None project ProjectFactory.create owner owner defaults {'project' project 'owner' owner}defaults.update kwargs return EpicFactory **defaults
def _GetGoogleStorageFileMetadata blob_key try gs_info datastore.Get datastore.Key.from_path file_service_stub.GS_INFO_KIND blob_key namespace '' return gs_info['size'] gs_info['content_type'] gs_info['storage_key'] except datastore_errors.EntityNotFoundError return None None None
def call_c library expanduser '~/.image.so' sauce join dirname __file__ 'image.c' if not exists library or getmtime sauce > getmtime library build 'cc-fPIC-shared-o%s%s' % library sauce os.system build + '>/dev/null2>&1' image_c ctypes.cdll.LoadLibrary library image_c.init return image_c.rgb_to_ansi
def lookup_casstype_simple casstype shortname trim_if_startswith casstype apache_cassandra_type_prefix try typeclass _casstypes[shortname]except KeyError typeclass mkUnrecognizedType casstype return typeclass
def block_device_mapping_get_all_by_instance context instance_uuid return IMPL.block_device_mapping_get_all_by_instance context instance_uuid
def DeriveIDFromPath path invalid_chars re.compile '[^a-zA-Z0-9]' components path.split '/' return '_' + '-'.join [invalid_chars.sub lambda x '_%02X' % ord x.group 0 x for x in components if x]
def _mask_filter_result result mask if mask is None result[0 ] 0result[ -1 ] 0result[ 0] 0result[ -1 ] 0return resultelse mask binary_erosion mask EROSION_SELEM border_value 0 return result * mask
@db_api.api_context_manager.readerdef _ensure_rc_cache ctx global _RC_CACHEif _RC_CACHE is not None return_RC_CACHE rc_cache.ResourceClassCache ctx
def config_dict_changed module current_config module.custom_current_config.get 'config' desired_config module.custom_desired_config.get 'config' return current_config ! desired_config
def pportD4 state global dataRegif state 0 dataReg dataReg & ~ 16 else dataReg dataReg | 16 port.DlPortWritePortUchar baseAddress dataReg
def _ip_sort ip idx '001'if ip '127.0.0.1' idx '200'if ip ' 1' idx '201'elif ' ' in ip idx '100'return '{0}___{1}'.format idx ip
def register_api_routes application register log.info 'installingapplicationroutes ' methods inspect.getmembers application methods filter lambda n not n[0].startswith '_' methods for method func in dict methods .iteritems pieces method.split '_' verb path pieces[0] pieces[1 ] args inspect.getargspec func .args[1 ]args [ '<%s>' % arg for arg in args]args '/'.join args args '' if len args 0 else '/' + args path.insert 0 application._namespace path '/'.join path + args log.info '%6s %s' % verb path register.route path method verb name method func
def pkill pattern user None signal 15 full False killed []for proc in psutil.process_iter name_match pattern in ''.join _get_proc_cmdline proc if full else pattern in _get_proc_name proc user_match True if user is None else user _get_proc_username proc if name_match and user_match try proc.send_signal signal killed.append _get_proc_pid proc except psutil.NoSuchProcess passif not killed return Noneelse return {'killed' killed}
@register.inclusion_tag u'reviews/comment_issue.html' takes_context True def comment_issue context review_request comment comment_type issue_status BaseComment.issue_status_to_string comment.issue_status user context.get u'user' None return {u'comment' comment u'comment_type' comment_type u'issue_status' issue_status u'review' comment.get_review u'interactive' comment.can_change_issue_status user }
def meanabs x1 x2 axis 0 x1 np.asanyarray x1 x2 np.asanyarray x2 return np.mean np.abs x1 - x2 axis axis
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def getStringFromCharacterSplitLine character splitLine indexOfCharacter getIndexOfStartingWithSecond character splitLine if indexOfCharacter < 0 return Nonereturn splitLine[indexOfCharacter][1 ]
def event_handlers all_handlers defaultdict list for plugin in find_plugins if plugin.listeners for event handlers in plugin.listeners.items all_handlers[event] + handlersreturn all_handlers
def _compute_lwork routine *args **kwargs wi routine *args **kwargs if len wi < 2 raise ValueError '' info wi[ -1 ]if info ! 0 raise ValueError 'Internalworkarraysizecomputationfailed %d' % info lwork [w.real for w in wi[ -1 ]]dtype getattr routine 'dtype' None if dtype _np.float32 or dtype _np.complex64 lwork _np.nextafter lwork _np.inf dtype _np.float32 lwork _np.array lwork _np.int64 if _np.any _np.logical_or lwork < 0 lwork > _np.iinfo _np.int32 .max raise ValueError 'Toolargeworkarrayrequired--computationcannotbeperformedwithstandard32-bitLAPACK.' lwork lwork.astype _np.int32 if lwork.size 1 return lwork[0]return lwork
def requires_load_dynamic meth meth support.cpython_only meth return unittest.skipIf not hasattr imp 'load_dynamic' 'imp.load_dynamic required' meth
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def get_lang_js fortype name return u'\n\n$.extend frappe._messages %s ' % json.dumps get_dict fortype name
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def event_source_mapping_exists UUID None EventSourceArn None FunctionName None region None key None keyid None profile None desc describe_event_source_mapping UUID UUID EventSourceArn EventSourceArn FunctionName FunctionName region region key key keyid keyid profile profile if 'error' in desc return descreturn {'exists' bool desc.get 'event_source_mapping' }
def close_room room socketio flask.current_app.extensions['socketio']socketio.server.close_room room namespace flask.request.namespace
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def spectral_radius_bound X log2_exponent if X.type.ndim ! 2 raise TypeError 'spectral_radius_boundrequiresamatrixargument' X if not isinstance log2_exponent integer_types raise TypeError 'spectral_radius_boundrequiresanintegerexponent' log2_exponent if log2_exponent < 0 raise ValueError 'spectral_radius_boundrequiresastrictlypositiveexponent' log2_exponent XX Xfor i in xrange log2_exponent XX tensor.dot XX XX return tensor.pow trace XX 2 ** - log2_exponent
def match_device device match re.match ' ^/dev/x{0 1}[a-z]{0 1}d{0 1} [a-z]+ [0-9]*$' device if not match return Nonereturn match.groups
def rename_files container file_map overlap set file_map .intersection set file_map.itervalues if overlap raise ValueError u'Circularrenamedetected.Thefiles%sarebothrenametargetsanddestinations' % u' '.join overlap for name dest in file_map.iteritems if container.exists dest if name ! dest and name.lower dest.lower continueraise ValueError u'Cannotrename{0}to{1}as{1}alreadyexists'.format name dest if len tuple file_map.itervalues ! len set file_map.itervalues raise ValueError u'Cannotrename thesetofdestinationfilescontainsduplicates' link_map {}for current_name new_name in file_map.iteritems container.rename current_name new_name if new_name ! container.opf_name link_map[current_name] new_namereplace_links container link_map replace_in_opf True
def attach_epics queryset as_field 'epics_attr' model queryset.modelsql 'SELECTjson_agg row_to_json t \nFROM SELECT"epics_epic"."id"AS"id" \n"epics_epic"."ref"AS"ref" \n"epics_epic"."subject"AS"subject" \n"epics_epic"."color"AS"color" \n SELECTrow_to_json p \nFROM SELECT"projects_project"."id"AS"id" \n"projects_project"."name"AS"name" \n"projects_project"."slug"AS"slug"\n p\n AS"project"\nFROM"epics_relateduserstory"\nINNERJOIN"epics_epic"ON"epics_epic"."id" "epics_relateduserstory"."epic_id"\nINNERJOIN"projects_project"ON"projects_project"."id" "epics_epic"."project_id"\nWHERE"epics_relateduserstory"."user_story_id" {tbl}.id\nORDERBY"projects_project"."name" "epics_epic"."ref" t'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def modify_group group params immediate False changed {}new_params dict params for key in new_params.keys if key in group param group[key]new_value new_params[key]try old_value param.valueexcept ValueError old_value param._valueif old_value ! new_value if not param.is_modifiable raise NotModifiableError 'Parameter%sisnotmodifiable.' % key changed[key] {'old' old_value 'new' new_value}set_parameter param new_value immediate del new_params[key]return changed new_params
def test_keypoints_censure_scale_range_error assert_raises ValueError CENSURE min_scale 1 max_scale 2
def _SetMustSplitOnFirstLeaf node def FindFirstLeaf node if isinstance node pytree.Leaf return nodereturn FindFirstLeaf node.children[0] pytree_utils.SetNodeAnnotation FindFirstLeaf node pytree_utils.Annotation.MUST_SPLIT True
def get_vdi_for_vm_safely session vm_ref userdevice '0' vbd_refs _vm_get_vbd_refs session vm_ref for vbd_ref in vbd_refs vbd_rec _vbd_get_rec session vbd_ref if vbd_rec['userdevice'] userdevice vdi_ref vbd_rec['VDI']vdi_rec _vdi_get_rec session vdi_ref return vdi_ref vdi_rec raise exception.NovaException _ 'NoprimaryVDIfoundfor%s' % vm_ref
def dynamic_import import_string lastdot import_string.rfind '.' if lastdot -1 return __import__ import_string {} {} [] module_name attr import_string[ lastdot] import_string[ lastdot + 1 ] parent_module __import__ module_name {} {} [attr] return getattr parent_module attr
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def import_set dset in_stream headers True dset.wipe if is_py3 rows csv.reader in_stream.splitlines delimiter ' DCTB ' else rows csv.reader in_stream.splitlines delimiter ' DCTB ' encoding DEFAULT_ENCODING for i row in enumerate rows if not row continueif i 0 and headers dset.headers rowelse dset.append row
def win_standby try subprocess.Popen 'rundll32powrprof.dll SetSuspendStateStandby' time.sleep 10 except logging.error T 'Failedtostandbysystem' logging.info 'Traceback ' exc_info True
def writeFileMessageEnd end fileName fileText message suffixFileName getUntilDot fileName + end writeFileText suffixFileName fileText print message + getSummarizedFileName suffixFileName
@register.inclusion_tag 'test_incl_tag_use_l10n.html' takes_context True def inclusion_tag_use_l10n context return {}
def _is_metadata_of group parent_group if group._v_depth < parent_group._v_depth return Falsecurrent groupwhile current._v_depth > 1 parent current._v_parentif parent parent_group and current._v_name 'meta' return Truecurrent current._v_parentreturn False
def get_from_identity session key passive instance session.identity_map.get key if instance is not None state attributes.instance_state instance if state.expired if not passive & attributes.SQL_OK return attributes.PASSIVE_NO_RESULTelif not passive & attributes.RELATED_OBJECT_OK return instancetry state._load_expired state passive except orm_exc.ObjectDeletedError session._remove_newly_deleted [state] return Nonereturn instanceelse return None
def save_load jid load minions None serv _get_serv ret None serv.set jid json.dumps load _append_list serv 'jids' jid
def list_services zone None permanent True if zone cmd '--zone {0}--list-services'.format zone else cmd '--list-services'if permanent cmd + '--permanent'return __firewall_cmd cmd .split
def is_user_lockable request try field getattr User 'USERNAME_FIELD' 'username' kwargs {field request.POST.get USERNAME_FORM_FIELD }user User.objects.get **kwargs except User.DoesNotExist return Trueif hasattr user 'nolockout' return not user.nolockout elif hasattr settings 'AUTH_PROFILE_MODULE' try profile user.get_profile if hasattr profile 'nolockout' return not profile.nolockout except SiteProfileNotAvailable ObjectDoesNotExist AttributeError return Truereturn True
def rst_add_mathjax content _ ext os.path.splitext os.path.basename content.source_path if ext ! '.rst' returnif 'class "math"' in content._content content._content + "<scripttype 'text/javascript'>%s</script>" % rst_add_mathjax.mathjax_script
def clause_is_present clause search for elem in surface_selectables search if clause elem return Trueelse return False
def mkdir dir_path return os.system 'mkdir-p' + dir_path
def getKex kexAlgorithm if kexAlgorithm not in _kexAlgorithms raise error.ConchError 'Unsupportedkeyexchangealgorithm %s' % kexAlgorithm return _kexAlgorithms[kexAlgorithm]
def parent_dir_action parent fn action cmd_action parent cmds.OpenParentDir fn hotkeys.SECONDARY_ACTION action.setIcon icons.folder return action
def parse_parameter_list lines parameters num_params for line_num in range len lines line lines[line_num]line_floats_res line_floats_re.findall line line_floats [float val for val in line_floats_res]if len line_floats num_params parameters['parameterlist'] line.strip if 'SEsforparameters ' in lines[ line_num + 1 ] SEs_line lines[ line_num + 2 ]parameters['SEs'] SEs_line.strip breakreturn parameters
def page_from_href href return page_from_reference Reference.decode href
def get_event_source_status event_source lambda_arn target_function boto_session dry False event_source_obj ctx funk get_event_source event_source lambda_arn target_function boto_session dry False return event_source_obj.status funk
def check_version v check try return LooseVersion v > LooseVersion check except TypeError return True
def item_category table s3db.supply_item_categorys3.filter table.can_be_asset True field table.can_be_assetfield.readable field.writable Falsefield.default Truereturn s3_rest_controller 'supply' 'item_category'
def get_free_space dir_name if on_win free_bytes ctypes.c_ulonglong 0 ctypes.windll.kernel32.GetDiskFreeSpaceExW ctypes.c_wchar_p dir_name None None ctypes.pointer free_bytes return free_bytes.valueelse st os.statvfs dir_name return st.f_bavail * st.f_frsize
def personas_reviewer_required f @login_required@functools.wraps f def wrapper request *args **kw if _view_on_get request or acl.check_personas_reviewer request return f request *args **kw raise PermissionDeniedreturn wrapper
def blocks_are_equivalent block1 block2 if block1.__class__ ! block2.__class__ return Falseif set block1.fields ! set block2.fields return Falsefor field_name in block1.fields if field_name in 'parent' 'children' continueif getattr block1 field_name ! getattr block2 field_name return Falseif block1.has_children ! block2.has_children return Falseif block1.has_children if len block1.children ! len block2.children return Falsefor child_id1 child_id2 in zip block1.children block2.children if child_id1 child_id2 continuechild1 block1.runtime.get_block child_id1 child2 block2.runtime.get_block child_id2 if not blocks_are_equivalent child1 child2 return Falsereturn True
@context.quietfunc@with_devicedef logcat stream False if stream return process ['logcat'] else return process ['logcat' '-d'] .recvall
def _check_queue queue kwargs if queue _wait kwargs.get '__pub_jid' else conflict running concurrent kwargs.get 'concurrent' False if conflict __context__['retcode'] 1return conflict
def _require_permission code name content_type from django.contrib.auth.models import Permissioncriteria {'codename' code 'name' name 'content_type' content_type}permission Permission.objects.get_or_create **criteria [0]return permission
def test_incomplete_list_comprehension assert ParserWithRecovery load_grammar u ' 1fordef' .module.statements []
def consistencygroup_update context consistencygroup_id values return IMPL.consistencygroup_update context consistencygroup_id values
def _makeLatitude value return base.Coordinate value Angles.LATITUDE
def read_keyval path if os.path.isdir path path os.path.join path 'keyval' keyval {}if os.path.exists path for line in open path line re.sub '#.*' '' line .rstrip if not re.search '^[-\\.\\w]+ ' line raise ValueError 'Invalidformatline %s' % line key value line.split ' ' 1 if re.search '^\\d+$' value value int value elif re.search '^ \\d+\\. ?\\d+$' value value float value keyval[key] valuereturn keyval
def agent_check_warn consul_url None checkid None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not checkid raise SaltInvocationError 'Requiredargument"checkid"ismissing.' if 'note' in kwargs query_params['note'] kwargs['note']function 'agent/check/warn/{0}'.format checkid res _query consul_url consul_url function function query_params query_params method 'GET' if res['res'] ret['res'] Trueret['message'] 'Check{0}markedaswarning.'.format checkid else ret['res'] Falseret['message'] 'Unabletoupdatecheck{0}.'.format checkid return ret
def __get_location conn vm_ location config.get_cloud_config_value 'location' vm_ __opts__ return conn.ex_get_zone location
@hypothesis.given strategies.binary def test_content_disposition_directly s try cd rfc6266.parse_headers s cd.filename except SyntaxError UnicodeDecodeError rfc6266.Error pass
def resolve_reverse packed_ip flags 0 waiter Waiter core.dns_resolve_reverse packed_ip flags waiter.switch_args result _type ttl addr waiter.get if result ! core.DNS_ERR_NONE raise DNSError result return ttl addr
def get_cached_http return _CACHED_HTTP
def test_angsep from ..angle_utilities import angular_separationfor conv in np.deg2rad lambda x u.Quantity x u'deg' lambda x Angle x u'deg' for lon1 lat1 lon2 lat2 corrsep in zip coords correct_seps angsep angular_separation conv lon1 conv lat1 conv lon2 conv lat2 assert np.fabs angsep - conv corrsep < conv correctness_margin
def dup_to_tuple f return tuple f
def get_test_file name return os.path.join TEST_DATA name
def subplot_plot style_list ['g+-' 'r*-' 'b.-' 'yo-']for num in range 4 x np.linspace 0.0 2 + num num 10 * num + 1 y np.sin 5 - num * np.pi * x plt.subplot 2 2 num + 1 plt.plot x y style_list[num] plt.grid True plt.show return
def copy_or_rename_transcript new_name old_name item delete_old False user None filename 'subs_{0}.srt.sjson'.format old_name content_location StaticContent.compute_location item.location.course_key filename transcripts contentstore .find content_location .datasave_subs_to_store json.loads transcripts new_name item item.sub new_nameitem.save_with_metadata user if delete_old remove_subs_from_store old_name item
def board_ids p Popen ['/u/tang/bin/get_num_gpu_boards'] stdout PIPE nBoards int p.stdout.read return range nBoards
def remove_docker_files for filename in ['dev.yml' 'docker-compose.yml' '.dockerignore'] os.remove os.path.join PROJECT_DIRECTORY filename shutil.rmtree os.path.join PROJECT_DIRECTORY 'compose'
def filldoc docdict unindent_params True if unindent_params docdict unindent_dict docdict def decorate f f.__doc__ docformat f.__doc__ docdict return freturn decorate
def UnsetVariable output variable_name output.write 'unset ' output.write variable_name output.write ' \n'
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def close_review_request review_request review_request_id description if review_request.status ReviewRequest.SUBMITTED logging.warning u'Reviewrequest#%sisalreadysubmitted.' review_request_id returnif not review_request.public review_request.publish review_request.submitter review_request.close ReviewRequest.SUBMITTED description description logging.debug u'Reviewrequest#%sissetto%s.' review_request_id review_request.status
def GetQueryNodeText node return GetQueryNodeTextUnicode node .encode 'utf-8'
def make_runner_scenarios pidlockfile_scenarios make_pidlockfile_scenarios scenarios {'simple' {'pidlockfile_scenario_name' 'simple'} 'pidfile-locked' {'pidlockfile_scenario_name' 'exist-other-pid-locked'}}for scenario in scenarios.values if 'pidlockfile_scenario_name' in scenario pidlockfile_scenario pidlockfile_scenarios.pop scenario['pidlockfile_scenario_name'] scenario['pid'] pidlockfile_scenario['pid']scenario['pidfile_path'] pidlockfile_scenario['path']scenario['pidfile_timeout'] 23scenario['pidlockfile_scenario'] pidlockfile_scenarioreturn scenarios
def p_statement_assign p names[p[1]] p[3]
def load_macros module_name def _import module module_name module_name '__import__amodule avoidingrecursions'if module ! module_name __import__ module for module in CORE_MACROS _import module if module_name.startswith 'hy.core' returnfor module in EXTRA_MACROS _import module
def _get_binding_info hostheader '' ipaddress '*' port 80 ret '{0} {1} {2}'.format ipaddress port hostheader.replace '' '' return ret
def get_value_by_key attrs *args for search_attr_key in args for attr_key attr_value in attrs.iteritems if attr_key.lower search_attr_key return attr_valuereturn None
def test_tl_fit tl TomekLinks random_state RND_SEED tl.fit X Y assert_equal tl.min_c_ 0 assert_equal tl.maj_c_ 1 assert_equal tl.stats_c_[0] 7 assert_equal tl.stats_c_[1] 13
@blueprint.route '/visualize-network' methods ['POST'] def visualize_network framework flask.request.args.get 'framework' if not framework raise werkzeug.exceptions.BadRequest 'frameworknotprovided' fw frameworks.get_framework_by_id framework ret fw.get_network_visualization flask.request.form['custom_network'] return ret
def relative_distance a_str b_str set_a set a_str.split '' set_b set b_str.split '' if min len set_a len set_b in 0 1 return difflib.SequenceMatcher None a_str b_str .quick_ratio return 1.0 * len set_a.intersection set_b / max len set_a len set_b
def _getAPI node base ''if node.hasAttribute 'base' base node.getAttribute 'base' + '.' return base + node.childNodes[0].nodeValue
def get_city_lat_long request if 'X-AppEngine-City' in request.headers return request.headers['X-AppEngine-CityLatLong']return None
def with_rw_directory func @wraps func def wrapper self path tempfile.mktemp prefix func.__name__ os.mkdir path keep Falsetry return func self path except Exception log.info 'Test%s.%sfailed outputisat%r\n' type self .__name__ func.__name__ path keep Trueraisefinally import gcgc.collect if not keep rmtree path return wrapper
def secure_required view_func def _wrapped_view request *args **kwargs if not request.is_secure if getattr settings 'USERENA_USE_HTTPS' userena_settings.DEFAULT_USERENA_USE_HTTPS request_url request.build_absolute_uri request.get_full_path secure_url request_url.replace 'http //' 'https //' return HttpResponsePermanentRedirect secure_url return view_func request *args **kwargs return wraps view_func assigned available_attrs view_func _wrapped_view
def f_classif X y X y check_X_y X y ['csr' 'csc' 'coo'] args [X[safe_mask X y k ] for k in np.unique y ]return f_oneway *args
def track_seen event db conn db_init db conn if event.chan[ 1] '#' and not re.findall '^s/.*/.*/$' event.content.lower db.execute 'insertorreplaceintoseen_user name time quote chan host values name time quote chan host ' {'name' event.nick.lower 'time' time.time 'quote' event.content 'chan' event.chan 'host' event.mask} db.commit
@task ignore_result False def run_indexing index index_name ids indexer INDEXER_MAP[index_name]indexer.run_indexing ids ES index index
def list_with_level course level return ROLES[level] course.id .users_with_role
def _add_node_class_names names for _name in names setattr GenericNodeVisitor 'visit_' + _name _call_default_visit setattr GenericNodeVisitor 'depart_' + _name _call_default_departure setattr SparseNodeVisitor 'visit_' + _name _nop setattr SparseNodeVisitor 'depart_' + _name _nop
def random_identifier return '%016x' % random.randint 0 2 ** 64 - 1
def inject_coursetalk_keys_into_context context course_key show_coursetalk_widget models.CourseTalkWidgetConfiguration.is_enabled if show_coursetalk_widget context[u'show_coursetalk_widget'] Truecontext[u'platform_key'] models.CourseTalkWidgetConfiguration.get_platform_key context[u'course_review_key'] get_coursetalk_course_key course_key
def initialized return DETAILS.get 'initialized' False
def p_compound_statement_4 t pass
def amap fn *args return np.array list map fn *args
def extract_dependencies reg assignments return sorted [k for k v in assignments.items if v reg ]
def association_proxy target_collection attr **kw return AssociationProxy target_collection attr **kw
def firebase_get path response content _get_http .request path method 'GET' return json.loads content
def test_senn_multiclass_error y np.linspace 0 1 20 sm SMOTEENN random_state RND_SEED assert_warns UserWarning sm.fit X y y np.array [0] * 3 + [1] * 2 + [2] * 15 sm SMOTEENN random_state RND_SEED assert_warns UserWarning sm.fit X y
def _fix_up_media_upload method_desc root_desc path_url parameters media_upload method_desc.get 'mediaUpload' {} accept media_upload.get 'accept' [] max_size _media_size_to_long media_upload.get 'maxSize' '' media_path_url Noneif media_upload media_path_url _media_path_url_from_info root_desc path_url parameters['media_body'] MEDIA_BODY_PARAMETER_DEFAULT_VALUE.copy parameters['media_mime_type'] MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE.copy if 'body' in parameters parameters['body']['required'] Falsereturn accept max_size media_path_url
def make_pattern pat if pat is None return Noneif isinstance pat six.binary_type pat pat.decode 'utf8' if isinstance pat six.text_type pat re.compile pat if hasattr pat 'search' return pat.searchif hasattr pat '__call__' return patraise ValueError 'Cannotmakecallablepatternobjectoutof%r' % pat
def AsIter arg if isinstance arg basestring rslt [arg]elif isinstance arg collections.Iterable rslt argelif not arg rslt []else rslt [arg]return tuple rslt
def _populate_unknown_statuses set_tasks visited set for task in set_tasks['still_pending_not_ext'] _depth_first_search set_tasks task visited
@not_implemented_for 'undirected' 'multigraph' def overall_reciprocity G n_all_edge G.number_of_edges n_overlap_edge n_all_edge - G.to_undirected .number_of_edges * 2 if n_all_edge 0 raise NetworkXError 'Notdefinedforemptygraphs' return float n_overlap_edge / float n_all_edge
def attach_tags objs if objs obj_dict {obj.id obj for obj in objs}m2m_name Tag._get_m2m_name objs[0] field_name getattr objs[0] m2m_name .query_field_nameqs Tag.objects.not_blocked .filter **{ '%s__in' % field_name obj_dict.keys } .values_list '%s__id' % field_name 'tag_text' for obj tags in sorted_groupby qs lambda x x[0] setattr obj_dict[obj] '%s_list' % m2m_name [t[1] for t in tags]
def make_tag target **attrs target_id target.idtarget_type object_class target.type_name default_time int time.mktime datetime.datetime 2010 1 1 .timetuple all_attrs {'tagger' 'TestAuthor<test@nodomain.com>' 'tag_time' default_time 'tag_timezone' 0 'message' 'Testmessage.' 'object' target_type target_id 'name' 'TestTag'}all_attrs.update attrs return make_object Tag **all_attrs
def find predicate seq for element in seq if predicate element return elementreturn None
def get_list_for db participant_id if participant_id is None return db.all '\nSELECTc.*\nFROMcommunitiesc\nORDERBYnmembersDESC slug\n' else return db.all '\nSELECTc.*\nFROMcurrent_community_membersccm\nJOINcommunitiescONc.slug ccm.slug\nWHEREccm.is_memberANDccm.participant %s\nORDERBYc.nmembersASC c.slug\n' participant_id
def try_polynomial func z abuckets bbuckets sift func.ap _mod1 sift func.bq _mod1 a0 abuckets[S 0 ]b0 bbuckets[S 0 ]a0.sort b0.sort al0 [x for x in a0 if x < 0 ]bl0 [x for x in b0 if x < 0 ]if bl0 return ooif not al0 return Nonea al0[ -1 ]fac 1res S 1 for n in Tuple *list range - a fac * zfac / n + 1 for a in func.ap fac * a + n for b in func.bq fac / b + n res + facreturn res
def task_install_ssh_key return sequence [sudo_from_args ['cp' '.ssh/authorized_keys' '/root/.ssh/authorized_keys'] ]
@pytest.fixture scope u'session' def celery_worker_pool return u'solo'
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _CheckEnum value name values None if value not in values raise ValueError '%s %rmustbein%s' % name value values return value
def get_jobs server _connect jobs server.get_jobs if jobs return jobsreturn {}
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def update_and_define_min_max config minimum_default maximum_default minimum_value minimum_defaultmaximum_value maximum_defaultif config.get CONF_MINIMUM minimum_value config.get CONF_MINIMUM if config.get CONF_MAXIMUM maximum_value config.get CONF_MAXIMUM return minimum_value maximum_value
def most_common d return sorted iteritems d key operator.itemgetter 1 reverse True
def social_auth_user backend uid user *args **kwargs social_user UserSocialAuth.get_social_auth backend.name uid user return {'social_user' social_user 'user' user 'new_association' False}
def _sort_messages messages sort_by messages list messages if sort_by 'message' messages.sort elif sort_by 'location' messages.sort key lambda m m.locations return messages
def find_file_in_dirs path dirs if os.path.isabs path return pathfor d in dirs if d '.' f pathelse d os.path.expanduser d f os.path.join d path if os.path.exists f return freturn path
def inv_item_packs try item_id request.args[0]except raise HTTP 400 current.xml.json_message False 400 'Novalueprovided!' table s3db.inv_inv_itemptable db.supply_item_packquery table.id item_id & table.item_id ptable.item_id records db query .select ptable.id ptable.name ptable.quantity output records.json response.headers['Content-Type'] 'application/json'return output
@csrf_protect@never_cachedef login request template_name 'registration/login.html' redirect_field_name REDIRECT_FIELD_NAME authentication_form AuthenticationForm redirect_to request.REQUEST.get redirect_field_name '' if request.method 'POST' form authentication_form data request.POST if form.is_valid if not redirect_to or '' in redirect_to redirect_to settings.LOGIN_REDIRECT_URLelif '//' in redirect_to and re.match '[^\\?]*//' redirect_to redirect_to settings.LOGIN_REDIRECT_URLauth_login request form.get_user if request.session.test_cookie_worked request.session.delete_test_cookie return HttpResponseRedirect redirect_to else form authentication_form request request.session.set_test_cookie current_site get_current_site request return render_to_response template_name {'form' form redirect_field_name redirect_to 'site' current_site 'site_name' current_site.name} context_instance RequestContext request
def scale_image data width 60 height 80 compression_quality 70 as_png False preserve_aspect_ratio True img image_from_data data if preserve_aspect_ratio scaled nwidth nheight fit_image img.width img.height width height if scaled img img.scaled nwidth nheight Qt.KeepAspectRatio Qt.SmoothTransformation elif img.width ! width or img.height ! height img img.scaled width height Qt.IgnoreAspectRatio Qt.SmoothTransformation fmt u'PNG' if as_png else u'JPEG' w h img.width img.height return w h image_to_data img compression_quality compression_quality fmt fmt
def test_option_w_ignore pyi_builder monkeypatch def MyEXE *args **kwargs args list args args.append [ 'Wignore' '' 'OPTION' ] return EXE *args **kwargs import PyInstallerEXE PyInstaller.building.build_main.EXEmonkeypatch.setattr 'PyInstaller.building.build_main.EXE' MyEXE pyi_builder.test_source "\nimportsys\nassert'ignore'insys.warnoptions\n"
def virtualenv_exists directory return is_file posixpath.join directory 'bin' 'python'
def init_logging options log_file options['log_basename'] + '.log' log_dir options['log_dir']log_config {'version' 1 'disable_existing_loggers' True 'formatters' {'timestamped' {'format' '% asctime s% message s' 'datefmt' '%H %M %S'}} 'handlers' {'console' {'level' 'WARNING' 'class' 'logging.StreamHandler' 'formatter' 'timestamped'} 'file' {'level' 'DEBUG' 'class' 'logging.FileHandler' 'formatter' 'timestamped' 'filename' os.path.join log_dir log_file 'mode' 'w'}} 'loggers' {'' {'level' 'DEBUG' 'handlers' ['console' 'file']}}}logging.config.dictConfig log_config
@should_dump_tracemallocdef stop_tracemalloc_dump cancel_thread SAVE_TRACEMALLOC_PTR dump_tracemalloc
def time_openpyxl start_time clock workbook openpyxl.workbook.Workbook worksheet workbook.activefor row in range row_max // 2 for col in range col_max colletter get_column_letter col + 1 worksheet.cell '%s%s' % colletter row * 2 + 1 .value 'Row %dCol %d' % row col for col in range col_max colletter get_column_letter col + 1 worksheet.cell '%s%s' % colletter row * 2 + 2 .value row + col workbook.save 'openpyxl.xlsx' elapsed clock - start_time print_elapsed_time 'openpyxl' elapsed
def device portnumber enum comm.CommPortIdentifier.getPortIdentifiers ports []while enum.hasMoreElements el enum.nextElement if el.getPortType comm.CommPortIdentifier.PORT_SERIAL ports.append el return ports[portnumber].getName
def _format_firewall_stdout cmd_ret ret_dict {'success' True 'rulesets' {}}for line in cmd_ret['stdout'].splitlines if line.startswith 'Name' continueif line.startswith '---' continueruleset_status line.split ret_dict['rulesets'][ruleset_status[0]] bool ruleset_status[1] return ret_dict
def parse_graftpoints graftpoints grafts {}for l in graftpoints raw_graft l.split None 1 commit raw_graft[0]if len raw_graft 2 parents raw_graft[1].split else parents []for sha in [commit] + parents check_hexsha sha 'Invalidgraftpoint' grafts[commit] parentsreturn grafts
def _fix_region region region region or '' .lower return _ALIAS_TO_REGION.get region or region
@auth.s3_requires_membership 1 def ticket import tracebackfrom gluon.restricted import RestrictedErrorif len request.args ! 2 session.error T 'Invalidticket' redirect URL r request app request.args[0]ticket request.args[1]e RestrictedError e.load request app ticket return dict app app ticket ticket traceback s3base.Traceback e.traceback code e.code layer e.layer
def _ToTimeZone t tzinfo if pytz is None return t.replace tzinfo None elif tzinfo if not t.tzinfo t pytz.utc.localize t return tzinfo.normalize t.astimezone tzinfo elif t.tzinfo return pytz.utc.normalize t.astimezone pytz.utc .replace tzinfo None else return t
def rundeck registry xml_parent data p XML.SubElement xml_parent 'org.jenkinsci.plugins.rundeck.RundeckNotifier' mappings [ 'job-id' 'jobId' None 'options' 'options' '' 'node-filters' 'nodeFilters' '' 'tag' 'tag' '' 'wait-for-rundeck' 'shouldWaitForRundeckJob' False 'fail-the-build' 'shouldFailTheBuild' False ]helpers.convert_mapping_to_xml p data mappings fail_required True
def detachAcceptMsTerminated a TpPd pd 3 b MessageType mesType 6 packet a / b return packet
def group_type_get context id inactive False expected_fields None return IMPL.group_type_get context id inactive expected_fields
def has_dataproviders cls if not hasattr cls _DATAPROVIDER_CLASS_MAP_KEY setattr cls _DATAPROVIDER_CLASS_MAP_KEY {} else existing_dataproviders getattr cls _DATAPROVIDER_CLASS_MAP_KEY copied_dataproviders copy.deepcopy existing_dataproviders setattr cls _DATAPROVIDER_CLASS_MAP_KEY copied_dataproviders dataproviders getattr cls _DATAPROVIDER_CLASS_MAP_KEY for attr_key attr_value in cls.__dict__.iteritems if callable attr_value and not attr_key.startswith '__' and getattr attr_value _DATAPROVIDER_METHOD_NAME_KEY None name getattr attr_value _DATAPROVIDER_METHOD_NAME_KEY dataproviders[name] attr_valuereturn cls
def standard_team team team team.lower for variants in teams for variant in variants if team variant.lower return variants[0]return None
def FormatNumberAsString num for suffix in ['b' 'KB' 'MB' 'GB'] if num < 1024.0 return '%3.2f%s' % num suffix num / 1024.0return '%3.1f%s' % num 'TB'
def esummary **keywds cgi 'https //eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi'variables {}variables.update keywds return _open cgi variables
def iter_format_modules lang if check_for_language lang format_locations ['django.conf.locale.%s']if settings.FORMAT_MODULE_PATH format_locations.append settings.FORMAT_MODULE_PATH + '.%s' format_locations.reverse locale to_locale lang locales [locale]if '_' in locale locales.append locale.split '_' [0] for location in format_locations for loc in locales try yield import_module '.formats' location % loc except ImportError pass
def Go if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' ec staticLib.Go if ec ! 0 raise LabJackException ec else raise LabJackException 'FunctiononlysupportedforWindows'
def _generate_user_id user return '{0}_user_id'.format user.name .lower
def _fake_click fig ax point xform 'ax' button 1 kind 'press' if xform 'ax' x y ax.transAxes.transform_point point elif xform 'data' x y ax.transData.transform_point point else raise ValueError 'unknowntransform' if kind 'press' func partial fig.canvas.button_press_event x x y y button button elif kind 'release' func partial fig.canvas.button_release_event x x y y button button elif kind 'motion' func partial fig.canvas.motion_notify_event x x y y try func guiEvent None except Exception func
def _toDOMname CSSname def _doCSStoDOMname2 m return m.group 0 [1].capitalize return _reCSStoDOMname.sub _doCSStoDOMname2 CSSname
def nt_search seq subseq pattern ''for nt in subseq value IUPACData.ambiguous_dna_values[nt]if len value 1 pattern + valueelse pattern + '[%s]' % value pos -1 result [pattern]l len seq while True pos + 1s seq[pos ]m re.search pattern s if not m breakpos + int m.start 0 result.append pos return result
def EnsureModuleForTypelibInterface typelib_ob progressInstance None bForDemand bForDemandDefault bBuildHidden 1 tla typelib_ob.GetLibAttr guid tla[0]lcid tla[1]major tla[3]minor tla[4]if bForDemand demandGeneratedTypeLibraries[ str guid lcid major minor ] typelib_obtry return GetModuleForTypelib guid lcid major minor except ImportError passreturn MakeModuleForTypelibInterface typelib_ob progressInstance bForDemand bBuildHidden
def get_billable_traffic campaign start end promote.get_traffic_dates campaign return get_promo_traffic campaign start end
def add_quote db chan target sender message try query qtable.insert .values chan chan nick target.lower add_nick sender.lower msg message time time.time db.execute query db.commit except IntegrityError return 'Messagealreadystored doingnothing.'return 'Quoteadded.'
@_FFI.callback u'Value ExternContext* Value* ' def extern_clone_val context_handle val c _FFI.from_handle context_handle item c.from_value val return c.to_value item type_id val.type_id
def _homebrew_bin ret __salt__['cmd.run'] 'brew--prefix' output_loglevel 'trace' ret + '/bin/brew'return ret
def _TestUpdateFriend tester user_cookie request_dict validator tester.validator user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict actual_dict tester.SendRequest 'update_friend' user_cookie request_dict op_dict tester._DeriveNotificationOpDict user_id device_id request_dict friend_dict request_dict['friend']friend_dict['friend_id'] friend_dict.pop 'user_id' friend_dict['user_id'] user_idvalidator.ValidateUpdateDBObject Friend **friend_dict invalidate {'users' [friend_dict['friend_id']]}validator.ValidateNotification 'update_friend' user_id op_dict invalidate tester._CompareResponseDicts 'update_friend' user_id request_dict {} actual_dict return actual_dict
@js_defined 'window.jQuery' def enable_jquery_animations page page.browser.execute_script 'jQuery.fx.off false;'
def step_2 w for suffix rules in suffixes2 if w.endswith suffix for A B in rules if w.endswith A return R1 w .endswith A and w[ - len A ] + B or w if w.endswith 'li' and R1 w [ -3 -2 ] in VALID_LI return w[ -2 ]return w
def table_lines_from_stats stats old_stats columns lines []for m_type in columns new stats[m_type]format strif isinstance new float format lambda num '%.3f' % num old old_stats.get m_type if old is not None diff_str diff_string old new old format old else old diff_str 'NC' 'NC' lines + m_type.replace '_' '' format new old diff_str return lines
def modClearNameRefs s titlesRefs namesRefs charactersRefs return re_nameRef.sub '\\1' s
def _parse_json s def _obj_hook pairs 'convertjsonobjecttopythonobject'o JsonDict for k v in pairs.iteritems o[str k ] vreturn oreturn json.loads s object_hook _obj_hook
def _build_national_number_for_parsing number index_of_phone_context number.find _RFC3966_PHONE_CONTEXT if index_of_phone_context > 0 phone_context_start index_of_phone_context + len _RFC3966_PHONE_CONTEXT if number[phone_context_start] _PLUS_SIGN phone_context_end number.find U_SEMICOLON phone_context_start if phone_context_end > 0 national_number number[phone_context_start phone_context_end]else national_number number[phone_context_start ]else national_number U_EMPTY_STRINGindex_of_rfc3996_prefix number.find _RFC3966_PREFIX index_of_national_number index_of_rfc3996_prefix + len _RFC3966_PREFIX if index_of_rfc3996_prefix > 0 else 0 national_number + number[index_of_national_number index_of_phone_context]else national_number _extract_possible_number number index_of_isdn national_number.find _RFC3966_ISDN_SUBADDRESS if index_of_isdn > 0 national_number national_number[ index_of_isdn]return national_number
def check_name name safe_chars regexp re.compile '[^{0}]'.format safe_chars if regexp.search name raise SaltCloudException '{0}containscharactersnotsupportedbythiscloudprovider.Validcharactersare {1}'.format name safe_chars
def use_powerline_prompt cls @propertydef prompt self try powerline self.powerlineexcept AttributeError powerline PDBPowerline powerline.setup self self.powerline powerlinereturn PowerlineRenderResult powerline.render side u'left' @prompt.setterdef prompt self _ pass@prompt.deleterdef prompt self passif not hasattr cls u'__class__' old_cls clsclass cls cls object __module__ cls.__module____doc__ cls.__doc__cls.__name__ old_cls.__name__cls.prompt promptreturn cls
def check_issues issues after None issues closed_issues issues after if after else all_issues issues issues sorted issues key ISSUES_SORT_KEY have_warnings Falsefor section issue_group in groupby issues key ISSUES_BY_SECTION for issue in issue_group have_warnings | check_issue issue after return have_warnings
def test_zoom_output_shape x np.arange 12 .reshape 3 4 ndimage.zoom x 2 output np.zeros 6 8
def clone name new_name linked False template False runas None args [_sdecode name '--name' _sdecode new_name ]if linked args.append '--linked' if template args.append '--template' return prlctl 'clone' args runas runas
def select_request_microversion test_min_version cfg_min_version test_version api_version_request.APIVersionRequest test_min_version cfg_version api_version_request.APIVersionRequest cfg_min_version max_version cfg_version if cfg_version > test_version else test_version return max_version.get_string
def which program def is_exe fpath return os.path.isfile fpath and os.access fpath os.X_OK fpath fname os.path.split program if fpath if is_exe program return programelse for path in os.environ['PATH'].split os.pathsep exe_file os.path.join path program if is_exe exe_file return exe_file
def runModel gymName plot False print 'Creatingmodelfrom%s...' % gymName model createModel getModelParamsFromName gymName inputData '%s/%s.csv' % DATA_DIR gymName.replace '' '_' runIoThroughNupic inputData model gymName plot
def bspline x n ax - abs asarray x funclist condfuncs _bspline_piecefunctions n condlist [func ax for func in condfuncs]return piecewise ax condlist funclist
def _mul_args f args Mul.make_args f gs []for g in args if g.is_Pow and g.exp.is_Integer n g.expbase g.baseif n < 0 n - n base 1 / base gs + [base] * n else gs.append g return gs
def collection_list **kwargs return _query 'admin/collections?action LIST&wt json' **kwargs ['collections']
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _find_chocolatey context salt if 'chocolatey._path' in context return context['chocolatey._path']choc_defaults ['C \\Chocolatey\\bin\\chocolatey.bat' 'C \\ProgramData\\Chocolatey\\bin\\chocolatey.exe']choc_path salt['cmd.which'] 'chocolatey.exe' if not choc_path for choc_dir in choc_defaults if salt['cmd.has_exec'] choc_dir choc_path choc_dirif not choc_path err 'Chocolateynotinstalled.Usechocolatey.bootstraptoinstalltheChocolateypackagemanager.'raise CommandExecutionError err context['chocolatey._path'] choc_pathreturn choc_path
def concatenate_events events first_samps last_samps if not isinstance events list raise ValueError 'eventsmustbealistofarrays' if not len events len last_samps and len events len first_samps raise ValueError 'events first_samps andlast_sampsmustallhavethesamelengths' first_samps np.array first_samps last_samps np.array last_samps n_samps np.cumsum last_samps - first_samps + 1 events_out events[0]for e f n in zip events[1 ] first_samps[1 ] n_samps[ -1 ] e2 e.copy e2[ 0] - fe2[ 0] + n + first_samps[0] events_out np.concatenate events_out e2 axis 0 return events_out
def _check_minute_range m if np.any m 60.0 warn IllegalMinuteWarning m u'Treatingas0min +1hr/deg' elif np.any m < -60.0 or np.any m > 60.0 raise IllegalMinuteError m
def getQuadraticPoint along begin controlPoint end oneMinusAlong 1.0 - along segmentBegin oneMinusAlong * begin + along * controlPoint segmentEnd oneMinusAlong * controlPoint + along * end return oneMinusAlong * segmentBegin + along * segmentEnd
def loadShapeTexture filename texID data texw texh loadImage load_data_file 'jfa/' + filename gl.glActiveTexture gl.GL_TEXTURE0 gl.glBindTexture gl.GL_TEXTURE_2D texID gl.glTexImage2D gl.GL_TEXTURE_2D 0 gl.GL_LUMINANCE texw texh 0 gl.GL_LUMINANCE gl.GL_UNSIGNED_BYTE data gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_MIN_FILTER gl.GL_NEAREST gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_MAG_FILTER gl.GL_NEAREST gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_WRAP_S gl.GL_REPEAT gl.glTexParameteri gl.GL_TEXTURE_2D gl.GL_TEXTURE_WRAP_T gl.GL_REPEAT checkGLError return texw texh
def invert_permutation_indices indices inverted [0] * len indices for i index in enumerate indices inverted[index] ireturn inverted
def test_shallow_copy original_header fits.Header [ 'a' 1 'b' 1 ] copied_header copy.copy original_header original_header['c'] 100assert 'c' not in copied_header copied_header['a'] 0assert original_header['a'] 1
def load_ipython_extension ipython if not ipython.find_line_magic 'sql' ipython.run_line_magic 'load_ext' 'sql' ipython.register_magic_function pgcli_line_magic 'line' 'pgcli'
def get_backend return rcParams['backend']
def serve_mogilefs_file request key None mimetype mimetypes.guess_type key [0] or 'application/x-octet-stream' client mogilefs.Client settings.MOGILEFS_DOMAIN settings.MOGILEFS_TRACKERS if hasattr settings 'SERVE_WITH_PERLBAL' and settings.SERVE_WITH_PERLBAL path cache.get key if not path path client.get_paths key cache.set key path 60 if path response HttpResponse content_type mimetype response['X-REPROXY-URL'] path[0]else response HttpResponseNotFound else file_data client[key]if file_data response HttpResponse file_data mimetype mimetype else response HttpResponseNotFound return response
def request_done request_id try _REQUESTS.pop request_id .request_done request_id except KeyError pass
def _SimpleEncoder wire_type encode_value compute_value_size def SpecificEncoder field_number is_repeated is_packed if is_packed tag_bytes TagBytes field_number wire_format.WIRETYPE_LENGTH_DELIMITED local_EncodeVarint _EncodeVarintdef EncodePackedField write value write tag_bytes size 0for element in value size + compute_value_size element local_EncodeVarint write size for element in value encode_value write element return EncodePackedFieldelif is_repeated tag_bytes TagBytes field_number wire_type def EncodeRepeatedField write value for element in value write tag_bytes encode_value write element return EncodeRepeatedFieldelse tag_bytes TagBytes field_number wire_type def EncodeField write value write tag_bytes return encode_value write value return EncodeFieldreturn SpecificEncoder
def parse_request_data_and_get_user request course_key certificate_exception parse_request_data request user certificate_exception.get 'user_name' '' or certificate_exception.get 'user_email' '' if not user raise ValueError _ 'Studentusername/emailfieldisrequiredandcannotbeempty.Kindlyfillinusername/emailandthenpress"AddtoExceptionList"button.' db_user get_student user course_key return certificate_exception db_user
def setup app app.add_role 'rfc' rfclink return
def make_dependencies package_name package_version distribution dependencies DEPENDENCIES[package_name][distribution.name]if package_name in 'node' 'cli' 'docker-plugin' dependencies + Dependency package 'clusterhq-python-flocker' compare ' ' version package_version return dependencies
def p_dimitem_double p p[0] p[1] eval p[3] eval p[5]
def parse_ext_value val if len val 3 charset langtag coded valelse charset coded vallangtag Nonedecoded urllib.parse.unquote coded charset errors 'strict' if charset 'iso-8859-1' for c in decoded if 127 < ord c < 159 raise InvalidISO8859Error c return LangTagged decoded langtag
def get_token host port headers auth_data url api_url host port '/Users/AuthenticateByName' r requests.post url headers headers data auth_data return r.json .get 'AccessToken'
def _isnull_old obj if is_scalar obj return lib.checknull_old obj elif isinstance obj ABCMultiIndex raise NotImplementedError 'isnullisnotdefinedforMultiIndex' elif isinstance obj ABCSeries np.ndarray ABCIndexClass return _isnull_ndarraylike_old obj elif isinstance obj ABCGeneric return obj._constructor obj._data.isnull func _isnull_old elif isinstance obj list or hasattr obj '__array__' return _isnull_ndarraylike_old np.asarray obj else return obj is None
def utf8tounicode arg if PY2 and isinstance arg str return arg.decode 'utf-8' return arg
def get url conn urlopen url resp conn.read conn.close return resp
def compute_log_ais_weights batch_size free_energy_fn sample_fn betas log_ais_w numpy.zeros batch_size dtype floatX for i in range len betas - 1 bp bp1 betas[i] betas[ i + 1 ] log_ais_w + free_energy_fn bp - free_energy_fn bp1 sample_fn bp1 if i % 1000.0 0 logging.info 'Temperature%f' % bp1 return log_ais_w
def assert_true_instance logical_line if asse_trueinst_re.match logical_line yield 0 'G316 assertTrue isinstance a b sentencesnotallowed'
def chop_parts value prec re im re_acc im_acc valueif re and re not in _infs_nan and fastlog re < - prec + 4 re re_acc None None if im and im not in _infs_nan and fastlog im < - prec + 4 im im_acc None None if re and im delta fastlog re - fastlog im if re_acc < 2 and delta - re_acc < - prec + 4 re re_acc None None if im_acc < 2 and delta - im_acc > prec - 4 im im_acc None None return re im re_acc im_acc
def test_init_with_header original_header fits.Header [ 'a' 10 ] new_header fits.Header original_header copy True original_header['a'] 20assert new_header['a'] 10 new_header['a'] 0assert original_header['a'] 20
def break_down_cookie cookie cookie_a cookie.split ';' cookie_name cookie_a[0].split ' ' [0]cookie_text '{0};${1}'.format cookie_a[0].split ' ' [1] cookie_a[1].lstrip return {cookie_name cookie_text}
def image_get request image_id return glanceclient request .images.get image_id
def pixel_scale pixscale if pixscale.unit.is_equivalent si.arcsec / astrophys.pix pixscale_val pixscale.to si.radian / astrophys.pix .valueelif pixscale.unit.is_equivalent astrophys.pix / si.arcsec pixscale_val 1 / pixscale .to si.radian / astrophys.pix .valueelse raise UnitsError u'Thepixelscalemustbeinangle/pixelorpixel/angle' return [ astrophys.pix si.radian lambda px px * pixscale_val lambda rad rad / pixscale_val ]
def compactionstats return _nodetool 'compactionstats'
def getKeys repository repositoryClass repository.__class__if repositoryClass list or repositoryClass tuple return range len repository if repositoryClass dict return repository.keys return None
def gating_enabled default None def wrap f def function_wrapper course *args if not course.enable_subsection_gating return defaultreturn f course *args return function_wrapperreturn wrap
def has_method obj name return callable getattr obj name None
def SignComponentContent component_filename output_filename component rdf_client.ClientComponent.FromSerializedString open component_filename 'rb' .read EPrint 'Openedcomponent%s.' % component.summary.name if component.build_system.system 'Windows' _SignWindowsComponent component output_filename returnraise RuntimeError 'ComponentsigningisnotimplementedforOS%s.' % component.build_system.system
def db_repair name table None **connection_args ret []if table is None tables db_tables name **connection_args for table in tables log.info "Repairingtable'{0}'indb'{1}'..".format name table ret.append __repair_table name table **connection_args else log.info "Repairingtable'{0}'indb'{1}'..".format name table ret __repair_table name table **connection_args return ret
def _hex_to_octets addr return '{0} {1} {2} {3}'.format int addr[6 8] 16 int addr[4 6] 16 int addr[2 4] 16 int addr[0 2] 16
def generate_git_command hotfix_hash git_string 'gittag-ahotfix-{iso_date}-m"Hotfixfor{msg_date}"{hotfix_hash}'.format iso_date date.today .isoformat msg_date date.today .strftime '%b%d %Y' hotfix_hash hotfix_hash return git_string
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def extension_elements_to_elements extension_elements schemas res []if isinstance schemas list passelif isinstance schemas dict schemas schemas.values else return resfor extension_element in extension_elements for schema in schemas inst extension_element_to_element extension_element schema.ELEMENT_FROM_STRING schema.NAMESPACE if inst res.append inst breakreturn res
def get_network_state physical_network vlan_id session db.get_session try state session.query l2network_models_v2.NetworkState .filter_by physical_network physical_network vlan_id vlan_id .one return stateexcept exc.NoResultFound return None
def lazy_related_operation function model *related_models **kwargs models [model] + [resolve_relation model rel for rel in related_models] model_keys make_model_tuple m for m in models apps model._meta.appsreturn apps.lazy_model_operation partial function **kwargs *model_keys
def build_xmlrpc xml_string fuzzed_parameters handler XmlRpcWriteHandler fuzzed_parameters xml.sax.parseString xml_string handler return handler.fuzzed_xml_string
def monthly_activity request project None subproject None lang None user None activity get_json_stats request 31 1 project subproject lang user serie []labels []for pos item in enumerate activity serie.append item[1] if pos % 5 0 labels.append pgettext 'Formatstringformonthlyactivitychart' '{day}/{month}' .format day item[0].day month item[0].month year item[0].year else labels.append '' return JsonResponse data {'series' [serie] 'labels' labels}
def create_local_servicepair test def create_service path FilePath test.mktemp path.createDirectory pool FilesystemStoragePool path service VolumeService FilePath test.mktemp pool reactor Clock service.startService test.addCleanup service.stopService return serviceto_service create_service from_service create_service remote LocalVolumeManager to_service return ServicePair from_service from_service to_service to_service remote remote origin_remote remote
def iter_strides_f_contig arr shape None shape arr.shape if shape is None else shape itemsize arr.itemsize yield itemsize sum 1for s in shape[ -1 ] sum * s yield sum * itemsize
def bonus rebulk Rebulk .regex_defaults flags re.IGNORECASE rebulk.regex 'x \\d+ ' name 'bonus' private_parent True children True formatter int validator {'__parent__' lambda match seps_surround } conflict_solver lambda match conflicting match if conflicting.name in ['video_codec' 'episode'] and 'bonus-conflict' not in conflicting.tags else '__default__' rebulk.rules BonusTitleRule return rebulk
def set_ key value profile None conn salt.utils.memcached.get_conn profile time profile.get 'expire' DEFAULT_EXPIRATION return salt.utils.memcached.set_ conn key value time time
def roots_hermitenorm n mu False m int n if n < 1 or n ! m raise ValueError 'nmustbeapositiveinteger.' mu0 np.sqrt 2.0 * np.pi if n < 150 an_func lambda k 0.0 * k bn_func lambda k np.sqrt k f cephes.eval_hermitenormdf lambda n x n * cephes.eval_hermitenorm n - 1 x return _gen_roots_and_weights m mu0 an_func bn_func f df True mu else nodes weights _roots_hermite_asy m nodes * sqrt 2 weights * sqrt 2 if mu return nodes weights mu0 else return nodes weights
def get_display_sleep ret salt.utils.mac_utils.execute_return_result 'systemsetup-getdisplaysleep' return salt.utils.mac_utils.parse_return ret
def build_api_url slug if len slug.split u'/' ! 2 raise ValueError u'InvalidGitHubslug {0}'.format slug return RELEASES_BASE.format slug
def singularityintegrate f x if not f.has SingularityFunction return Noneif f.func SingularityFunction x sympify f.args[0] a sympify f.args[1] n sympify f.args[2] if n.is_positive or n.is_zero return SingularityFunction x a n + 1 / n + 1 elif n -1 or n -2 return SingularityFunction x a n + 1 if f.is_Mul or f.is_Pow expr f.rewrite DiracDelta expr integrate expr x return expr.rewrite SingularityFunction return None
def DispatchEx clsid machine None userName None resultCLSID None typeinfo None UnicodeToString None clsctx None assert UnicodeToString is None 'thisisdeprecatedandwillgoaway'if clsctx is None clsctx pythoncom.CLSCTX_SERVERif machine is not None clsctx clsctx & ~ pythoncom.CLSCTX_INPROC if machine is None serverInfo Noneelse serverInfo machine if userName is None userName clsiddispatch pythoncom.CoCreateInstanceEx clsid None clsctx serverInfo pythoncom.IID_IDispatch [0]return Dispatch dispatch userName resultCLSID typeinfo clsctx clsctx
def copy_path filename absolute True if filename is None returnif absolute filename core.abspath filename set_clipboard filename
def array_encoding_disabled array return array.dtype not in BINARY_ARRAY_TYPES
def plan_rechunk old_chunks new_chunks itemsize threshold DEFAULT_THRESHOLD block_size_limit DEFAULT_BLOCK_SIZE_LIMIT ndim len new_chunks steps []if ndim < 1 or not all new_chunks return steps + [new_chunks] block_size_limit / itemsizelargest_old_block _largest_block_size old_chunks largest_new_block _largest_block_size new_chunks block_size_limit max [block_size_limit largest_old_block largest_new_block] graph_size_threshold threshold * _number_of_blocks old_chunks + _number_of_blocks new_chunks current_chunks old_chunksfirst_pass Truewhile True graph_size estimate_graph_size current_chunks new_chunks if graph_size < graph_size_threshold breakif first_pass chunks current_chunkselse chunks find_split_rechunk current_chunks new_chunks graph_size * threshold chunks memory_limit_hit find_merge_rechunk chunks new_chunks block_size_limit if chunks current_chunks or chunks new_chunks breaksteps.append chunks current_chunks chunksif not memory_limit_hit breakfirst_pass Falsereturn steps + [new_chunks]
def find_file path tgt_env 'base' **kwargs fnd {'path' '' 'rel' ''}if os.path.isabs path or tgt_env not in envs return fndfor repo in init env_root _env_root repo tgt_env if env_root is None continueif repo['mountpoint'] and not path.startswith repo['mountpoint'] + os.path.sep continuerepo_path path[len repo['mountpoint'] ].lstrip os.path.sep if repo['root'] repo_path os.path.join repo['root'] repo_path full os.path.join env_root repo_path if os.path.isfile full fnd['rel'] pathfnd['path'] fulltry fnd['stat'] list os.stat full except Exception passreturn fndreturn fnd
def listener_dict_to_tuple listener if 'instance_protocol' not in listener instance_protocol listener['elb_protocol'].upper else instance_protocol listener['instance_protocol'].upper listener_tuple [listener['elb_port'] listener['instance_port'] listener['elb_protocol'] instance_protocol]if 'certificate' in listener listener_tuple.append listener['certificate'] return tuple listener_tuple
def DNSServiceConstructFullName service None regtype _NO_DEFAULT domain _NO_DEFAULT _NO_DEFAULT.check regtype _NO_DEFAULT.check domain _global_lock.acquire try fullName _DNSServiceConstructFullName service regtype domain finally _global_lock.release return fullName.value.decode 'utf-8'
def generate_random_graph node_num edge_num self_loops False multi_edges False g Graph.Graph if not multi_edges if self_loops max_edges node_num * node_num else max_edges node_num * node_num - 1 if edge_num > max_edges raise GraphError "inconsistentargumentsto'generate_random_graph'" nodes range node_num for node in nodes g.add_node node while 1 head random.choice nodes tail random.choice nodes if head tail and not self_loops continueif g.edge_by_node head tail is not None and not multi_edges continueg.add_edge head tail if g.number_of_edges > edge_num breakreturn g
def get_packages dname pkgname None results None ignore None parent None parent parent or '' prefix []if parent prefix [parent]bname os.path.basename dname ignore ignore or [] if bname in ignore return []if results is None results []if pkgname is None pkgname []subfiles os.listdir dname abssubfiles [os.path.join dname x for x in subfiles]if '__init__.py' in subfiles results.append prefix + pkgname + [bname] for subdir in filter os.path.isdir abssubfiles get_packages subdir pkgname pkgname + [bname] results results ignore ignore parent parent res ['.'.join result for result in results]return res
def normalize_data_query_time dt time tz return pd.Timestamp datetime.datetime.combine dt.date time tz tz .tz_convert 'utc'
def get_courses courses [c for c in modulestore .get_courses if isinstance c CourseDescriptor ]courses sorted courses key lambda course course.location.course return courses
def sdm_nf_buchberger_reduced f G O K h sdm_zero g fwhile g g sdm_nf_buchberger g G O K if g h sdm_add h [sdm_LT g ] O K g g[1 ]return h
def __do_query_into_hash conn sql_str mod sys._getframe .f_code.co_namelog.debug '{0}<-- {1} '.format mod sql_str rtn_results []try cursor conn.cursor except MySQLdb.MySQLError log.error "{0} Can'tgetcursorforSQL->{1}".format mod sql_str cursor.close log.debug '{0}-->'.format mod return rtn_resultstry _execute cursor sql_str except MySQLdb.MySQLError log.error '{0} trytoexecute SQL->{1}'.format mod sql_str cursor.close log.debug '{0}-->'.format mod return rtn_resultsqrs cursor.fetchall for row_data in qrs col_cnt 0row {}for col_data in cursor.description col_name col_data[0]row[col_name] row_data[col_cnt]col_cnt + 1rtn_results.append row cursor.close log.debug '{0}-->'.format mod return rtn_results
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def GetAttribute node attr return node.attrib.get attr ''
def state_str state if state is None return 'None'else return '<%sat0x%x>' % state.class_.__name__ id state.obj
def ixor a b a ^ breturn a
def _interpolate_bads_meg inst mode 'accurate' verbose None picks_meg pick_types inst.info meg True eeg False exclude [] picks_good pick_types inst.info meg True eeg False exclude 'bads' meg_ch_names [inst.info['ch_names'][p] for p in picks_meg]bads_meg [ch for ch in inst.info['bads'] if ch in meg_ch_names ]if len bads_meg 0 picks_bad []else picks_bad pick_channels inst.info['ch_names'] bads_meg exclude [] if len picks_meg 0 or len picks_bad 0 returninfo_from pick_info inst.info picks_good info_to pick_info inst.info picks_bad mapping _map_meg_channels info_from info_to mode mode _do_interp_dots inst mapping picks_good picks_bad
def test_clrtype_returns_existing_clr_types global calledif is_netstandard clr.AddReference 'System.Data.Common' else clr.AddReference 'System.Data' types [System.Byte System.Int16 System.UInt32 System.Int32 System.Int64 System.Double System.Data.CommandType System.Boolean System.Char System.Decimal System.IntPtr System.Object System.String System.Collections.BitArray System.Collections.Generic.List[System.Char]]if not is_netstandard types.append System.Data.Common.DataAdapter for x in types called Falseclass MyType type def __clrtype__ self global calledcalled Truereturn xclass X object __metaclass__ MyTypeAreEqual called True
def axis name None cols None values None units None ax {}cNameOrder ['name' 'units' 'title']if name is not None ax['name'] nameif values is not None ax['values'] valuesif units is not None ax['units'] unitsif cols is not None ax['cols'] []for c in cols if type c ! list and type c ! tuple c [c]col {}for i in range 0 len c col[cNameOrder[i]] c[i]ax['cols'].append col return ax
def predict classifier pickle.load open 'best_model.pkl' predict_model theano.function inputs [classifier.input] outputs classifier.y_pred dataset 'mnist.pkl.gz'datasets load_data dataset test_set_x test_set_y datasets[2]test_set_x test_set_x.get_value predicted_values predict_model test_set_x[ 10] print 'Predictedvaluesforthefirst10examplesintestset ' print predicted_values
def test_lone_hat sol re.compile '^' AreEqual sol.match 'bazbar' 1 2 None AreEqual sol.match 'foobar' 1 2 None
def apply_colormap image colormap contig True image numpy.take colormap image axis 1 image numpy.rollaxis image 0 image.ndim if contig image numpy.ascontiguousarray image return image
def _AnalyzeSolutionSpace initial_state count 0seen set p_queue []node _StateNode initial_state False None heapq.heappush p_queue _QueueItem _OrderedPenalty 0 count node count + 1prev_penalty 0while p_queue item p_queue[0]penalty item.ordered_penalty.penaltynode item.state_nodeif not node.state.next_token breakheapq.heappop p_queue if count > 10000 node.state.ignore_stack_for_comparison Trueif node.state in seen continueprev_penalty penaltyseen.add node.state count _AddNextStateToQueue penalty node False count p_queue count _AddNextStateToQueue penalty node True count p_queue if not p_queue return False_ReconstructPath initial_state heapq.heappop p_queue .state_node return True
def ok_ pred msg None msg msg or '%r! True' % pred assert pred msg
def from_text rdclass rdtype ttl *text_rdatas return from_text_list rdclass rdtype ttl text_rdatas
def identify_table soup htmldict numtable if soup is None or soup.name ! 'table' return Falseelif 'table_id' not in htmldict return numtable 1 table_id htmldict['table_id']if isinstance table_id six.string_types return 'id' in soup.attrs and soup['id'] table_id elif isinstance table_id int return table_id numtable return False
def libvlc_media_new_fd p_instance fd f _Cfunctions.get 'libvlc_media_new_fd' None or _Cfunction 'libvlc_media_new_fd' 1 1 class_result Media ctypes.c_void_p Instance ctypes.c_int return f p_instance fd
def group_snapshot_destroy context group_snapshot_id return IMPL.group_snapshot_destroy context group_snapshot_id
def _validate_servicetype_ref data valid_values None svc_type_id datasvctype_mgr servicetype_db.ServiceTypeManager.get_instance try svctype_mgr.get_service_type context.get_admin_context svc_type_id except servicetype_db.ServiceTypeNotFound return _ "Theservicetype'%s'doesnotexist" % svc_type_id
@monkey sphinx.environment.BuildEnvironment def resolve_toctree old_resolve self docname *args **kwargs navbar kwargs.pop 'navbar' None if docname self.config.master_doc and not navbar return resolve_content_toctree self docname *args **kwargs toc old_resolve self docname *args **kwargs if toc is None return Nonenavbarify toc[0] navbar navbar return toc
def aware_datetime *args **kwargs tz kwargs.pop 'tz' None return make_aware datetime.datetime *args **kwargs tz tz
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def _sort_and_fill_taxa_summaries taxa_summaries master_taxa []for ts in taxa_summaries master_taxa + ts[1]master_taxa sorted set master_taxa result []for ts in taxa_summaries samples ts[0]orig_taxa ts[1]orig_data ts[2]data []for taxa in master_taxa try taxa_index orig_taxa.index taxa data.append orig_data[taxa_index] except ValueError data.append [0.0] * len samples result.append samples master_taxa array data return result
def parse_filters_kwargs request client_keywords None filters {}kwargs {}client_keywords client_keywords or {} for param in request.GET param_value PARAM_MAPPING.get request.GET[param] request.GET[param] if param in client_keywords kwargs[param] param_valueelse filters[param] param_valuereturn filters kwargs
def test_import_nothing modnames loaded_vispy_modules 'os' 2 assert_equal modnames set
def list_test_cases class_ return _list_testloader .loadTestsFromTestCase class_
def compressor request return gzip_compressor request
def test_scenario_description string '\nasdasdasdasd\n8fg6f8g23o83g\ndfjdsfjsdScenario NAMEOFSCENARIOjdkasbdkajsb\nFsdad\nScenario NAMEOFSCENARIO\ndasodnasndjasdasd\n'class ScenarioFake name 'NAMEOFSCENARIO'description core.ScenarioDescription ScenarioFake __file__ string core.Language assert_equals description.file core.fs.relpath __file__ assert_not_equals description.file __file__ assert_equals description.line 6
def text2string content try return ast.literal_eval content + '\n' except Exception return content + '\n'
def test_ast_good_get can_compile u' getxy '
def test_init_pytables_with_labels rng np.random.RandomState [34 22 89] X rng.randn 2 3 y rng.randint low 0 high 5 size 2 ds DenseDesignMatrixPyTables X X y y X_labels len np.unique X .flat y_labels np.max y + 1
def remove_css_class css_classes css_class remove set split_css_classes css_class classes_list [c for c in split_css_classes css_classes if c not in remove ]return u''.join classes_list
def vpprint expr **settings pp VectorPrettyPrinter settings use_unicode pp._settings['use_unicode']from sympy.printing.pretty.pretty_symbology import pretty_use_unicodeuflag pretty_use_unicode use_unicode try return pp.doprint expr finally pretty_use_unicode uflag
def test_iforest_sparse rng check_random_state 0 X_train X_test y_train y_test train_test_split boston.data[ 50] boston.target[ 50] random_state rng grid ParameterGrid {'max_samples' [0.5 1.0] 'bootstrap' [True False]} for sparse_format in [csc_matrix csr_matrix] X_train_sparse sparse_format X_train X_test_sparse sparse_format X_test for params in grid sparse_classifier IsolationForest n_estimators 10 random_state 1 **params .fit X_train_sparse sparse_results sparse_classifier.predict X_test_sparse dense_classifier IsolationForest n_estimators 10 random_state 1 **params .fit X_train dense_results dense_classifier.predict X_test assert_array_equal sparse_results dense_results assert_array_equal sparse_results dense_results
def _netstat_route_sunos ret []cmd 'netstat-finet-rn|tail-n+5'out __salt__['cmd.run'] cmd python_shell True for line in out.splitlines comps line.split ret.append {'addr_family' 'inet' 'destination' comps[0] 'gateway' comps[1] 'netmask' '' 'flags' comps[2] 'interface' comps[5] if len comps > 6 else '' } cmd 'netstat-finet6-rn|tail-n+5'out __salt__['cmd.run'] cmd python_shell True for line in out.splitlines comps line.split ret.append {'addr_family' 'inet6' 'destination' comps[0] 'gateway' comps[1] 'netmask' '' 'flags' comps[2] 'interface' comps[5] if len comps > 6 else '' } return ret
def aggregate_host_add context aggregate_id host IMPL.aggregate_host_add context aggregate_id host
def update_configuration_schema schema default_update_configuration_schema for plugin in plugins.PluginImplementations plugins.IConfigurer if hasattr plugin 'update_config_schema' schema plugin.update_config_schema schema return schema
def pre_event f @wraps f def decorated *args **kwargs method request.methodif method 'HEAD' method 'GET'event_name 'on_pre_' + method resource args[0] if args else None gh_params rh_params if method in 'GET' 'PATCH' 'DELETE' 'PUT' gh_params resource request kwargs rh_params request kwargs elif method in 'POST' gh_params resource request rh_params request getattr app event_name *gh_params if resource getattr app event_name + '_' + resource *rh_params combined_args kwargsif len args > 1 combined_args.update args[1].items r f resource **combined_args return rreturn decorated
def search_fields_to_dict fields if not fields return {}try int list dict fields .values [0] except TypeError ValueError fields dict zip fields [1] * len fields return fields
def chomp_commit_offset version if version is None return versionelse return str version .split '+' [0]
def _int64_feature value if not isinstance value list value [value]return tf.train.Feature int64_list tf.train.Int64List value value
def source_gdb_script script_contents to_string False fd filename tempfile.mkstemp f os.fdopen fd 'w' f.write script_contents f.close gdb.execute 'source%s' % filename to_string to_string os.remove filename
def url_prefix_join prefix fragment prefix + prefix[ -1 ] ! '/' and '/' or '' return urlparse.urljoin prefix fragment
def combine_hemi left right lh_data nb.load left .get_data rh_data nb.load right .get_data indices np.vstack 1000000 + np.arange 0 lh_data.shape[0] [ None] 2000000 + np.arange 0 rh_data.shape[0] [ None] all_data np.hstack indices np.vstack lh_data.squeeze rh_data.squeeze filename left.split u'.' [1] + u'_combined.txt' np.savetxt filename all_data fmt u' '.join [u'%d'] + [u'%.10f'] * all_data.shape[1] - 1 return os.path.abspath filename
def get_email_preferences_for_exploration user_id exploration_id exploration_user_model user_models.ExplorationUserDataModel.get user_id exploration_id if exploration_user_model is None return user_domain.UserExplorationPrefs.create_default_prefs else return user_domain.UserExplorationPrefs exploration_user_model.mute_feedback_notifications exploration_user_model.mute_suggestion_notifications
def add_html_component page menu_index boilerplate None page.wait_for_component_menu click_css page 'button>span.large-html-icon' menu_index require_notification False page.wait_for_element_visibility '.new-component-html' 'HTMLcomponentmenuisvisible' component_css 'button[data-category html]'if boilerplate component_css + '[data-boilerplate {}]'.format boilerplate else component_css + ' not [data-boilerplate] 'page.wait_for_element_visibility component_css 'HTMLcomponent{}isvisible'.format boilerplate click_css page component_css 0
def create_dock title parent stretch True dock QtWidgets.QDockWidget parent dock.setWindowTitle title dock.setObjectName title titlebar DockTitleBarWidget dock title stretch stretch dock.setTitleBarWidget titlebar dock.setAutoFillBackground True if hasattr parent u'dockwidgets' parent.dockwidgets.append dock return dock
def _es_down_template request *args **kwargs return 'search/mobile/down.html' if request.MOBILE else 'search/down.html'
def _non_dominated_front_arr iterable key lambda x x allowequality True items list iterable fits list map key items l len items x array fits a tile x l 1 1 b a.transpose 1 0 2 if allowequality ndom sum a < b axis 2 else ndom sum a < b axis 2 ndom array ndom dtype bool res set for ii in range l res.add ii for ij in list res if ii ij continueif not ndom[ ij ii ] res.remove ii breakelif not ndom[ ii ij ] res.remove ij return set [items[i] for i in res]
def gethostname return os.environ.get 'HTTP_HOST' 'www.appspot.com'
def memoize timeout dynamic_timeout False cache {'timeout' timeout}def decorator func def wrapper *args **kwargs start time if not 'time' in cache or start - cache['time'] > cache['timeout'] cache['result'] func *args **kwargs cache['time'] time if dynamic_timeout and cache['time'] - start > cache['timeout'] cache['timeout'] * 2return cache['result']def clear_cache if 'time' in cache del cache['time']if 'result' in cache del cache['result']wrapper.clear_cache clear_cachereturn wrapperreturn decorator
def test_advset_subtensor1 shp 10 shared cuda.shared_constructorxval numpy.arange shp[0] dtype 'float32' .reshape shp + 1 idxs numpy.array [0 2 5 7 3] dtype 'int32' yval numpy.ones len idxs dtype 'float32' * 10 x shared xval name 'x' y T.tensor dtype 'float32' broadcastable False * len shp name 'y' expr T.advanced_set_subtensor1 x y idxs f theano.function [y] expr mode mode_with_gpu assert sum [isinstance node.op cuda.GpuAdvancedIncSubtensor1 for node in f.maker.fgraph.toposort ] 1 rval f yval rep xval.copy rep[idxs] yvalutt.assert_allclose rval rep
def wrap_with_license block view frag context license getattr block 'license' None if license context {'license' license}frag.content + block.runtime.render_template 'license_wrapper.html' context return frag
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
def _do_prim_curr rr coils pc np.empty len rr * 3 len coils for ci c in enumerate coils pc[ ci] np.sum c['w'] * _bem_inf_fields rr c['rmag'] c['cosmag'] 2 .ravel return pc
def get_random_int upper_bound assert upper_bound > 0 and isinstance upper_bound int generator random.SystemRandom return generator.randrange 0 upper_bound
def user_generator gendesc libs def imp context builder sig args func context.declare_function builder.module gendesc status retval context.call_conv.call_function builder func gendesc.restype gendesc.argtypes args env None return status retval imp.libs tuple libs return imp
def escape_xml_illegal_chars val replacement '' return _illegal_xml_chars_re.sub replacement val
def _compare_replication current desired region key keyid profile if desired is not None and desired.get 'Role' desired deepcopy desired desired['Role'] _get_role_arn desired['Role'] region region key key keyid keyid profile profile return __utils__['boto3.json_objs_equal'] current desired
def quota_class_get context class_name resource return IMPL.quota_class_get context class_name resource
def qprogress s global _last_prognow time.time if now - _last_prog > 0.1 progress s _last_prog now
def _section_analytics course access section_data {'section_key' 'instructor_analytics' 'section_display_name' _ 'Analytics' 'access' access 'course_id' unicode course.id }return section_data
def _fprime score x k_params alpha x_arr np.asarray x params x_arr[ k_params].ravel fprime_arr np.append score params alpha return matrix fprime_arr 1 2 * k_params
def expand_column_list_from_order_by collist order_by cols_already_present set [ col.element if col._order_by_label_element is not None else col for col in collist] return [col for col in chain *[unwrap_order_by o for o in order_by] if col not in cols_already_present ]
def parse_backup_info_file content reader records.RecordsReader cStringIO.StringIO content version reader.read if version ! '1' raise IOError 'Unsupportedversion' return datastore.Entity.FromPb record for record in reader
def get_image_list releaseid return _caa_request releaseid
def _zstat_generic value1 value2 std_diff alternative diff 0 zstat value1 - value2 - diff / std_diff if alternative in ['two-sided' '2-sided' '2s'] pvalue stats.norm.sf np.abs zstat * 2 elif alternative in ['larger' 'l'] pvalue stats.norm.sf zstat elif alternative in ['smaller' 's'] pvalue stats.norm.cdf zstat else raise ValueError 'invalidalternative' return zstat pvalue
def tree_to_treesegment canvas t make_node TextWidget make_leaf TextWidget **attribs tree_attribs {}node_attribs {}leaf_attribs {}loc_attribs {}for key value in list attribs.items if key[ 5] 'tree_' tree_attribs[key[5 ]] valueelif key[ 5] 'node_' node_attribs[key[5 ]] valueelif key[ 5] 'leaf_' leaf_attribs[key[5 ]] valueelif key[ 4] 'loc_' loc_attribs[key[4 ]] valueelse raise ValueError 'Badattribute %s' % key return _tree_to_treeseg canvas t make_node make_leaf tree_attribs node_attribs leaf_attribs loc_attribs
def update_url url debug if not url return urloriginal_url urlurl url.replace ' //raw.github.com/' ' //raw.githubusercontent.com/' url url.replace ' //nodeload.github.com/' ' //codeload.github.com/' url re.sub '^ https //codeload.github.com/[^/]+/[^/]+/ zipball /.* $' '\\1zip\\2' url if url 'https //sublime.wbond.net/repositories.json' or url 'https //sublime.wbond.net/channel.json' url 'https //packagecontrol.io/channel_v3.json'if debug and url ! original_url console_write u'\nFixedURLfrom%sto%s\n' original_url url return url
def leaks url 'http //localhost 8080/manager' timeout 180 return _wget 'findleaks' {'statusLine' 'true'} url timeout timeout ['msg']
def getClass obj if hasattr obj '__class__' return obj.__class__else return type obj
def _validate_ui_config obj_type ui_config reference_dict UI_CONFIG_SPECS[obj_type]assert set ui_config.keys < set reference_dict.keys for key value in ui_config.iteritems schema_utils.normalize_against_schema value reference_dict[key]
def Reader database return open_database database
def endpoint_type bmAttributes return bmAttributes & _ENDPOINT_TRANSFER_TYPE_MASK
def const_eval expr c test_expr expr _CONST_OPCODES return unsafe_eval c
def param_init_lstm options params prefix 'lstm' W numpy.concatenate [ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ] axis 1 params[_p prefix 'W' ] WU numpy.concatenate [ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ortho_weight options['dim_proj'] ] axis 1 params[_p prefix 'U' ] Ub numpy.zeros 4 * options['dim_proj'] params[_p prefix 'b' ] b.astype config.floatX return params
def assert_element_text_is output path text assert_element_text_matches output path re.escape text
def mapping_decoder mapping_blocks decoder None decoder decoder or ModbusTypeDecoder for block in mapping_blocks.itervalues for mapping in block.itervalues mapping['address'] int mapping['address'] mapping['size'] int mapping['size'] mapping['type'] decoder.parse mapping['type']
def set_random_state estimator random_state 0 if isinstance estimator DBSCAN returnif 'random_state' in estimator.get_params estimator.set_params random_state random_state
def get_credit_requests_for_user username return CreditRequest.credit_requests_for_user username
def _blockdevicevolume_from_dataset_id dataset_id size attached_to None return BlockDeviceVolume size size attached_to attached_to dataset_id dataset_id blockdevice_id u'block-{0}'.format dataset_id
def triangle_code X centroids X_sqr T.sqr X .sum axis 1 .dimshuffle 0 'x' c_sqr T.sqr centroids .sum axis 1 .dimshuffle 'x' 0 c_sqr.name 'c_sqr'Xc T.dot X centroids.T Xc.name 'Xc'sq_dists c_sqr + X_sqr - 2.0 * Xc sq_dists_safe T.clip sq_dists 0.0 1e+30 Z T.sqrt sq_dists_safe Z.name 'Z'mu Z.mean axis 1 mu.name 'mu'mu mu.dimshuffle 0 'x' mu.name 'mu_broadcasted'rval T.clip mu - Z 0.0 1e+30 rval.name 'triangle_code'return rval
def do_unpickle data return loads to_str data
def check_minus_one result func cargs if result -1 raise GEOSException 'ErrorencounteredinGEOSCfunction"%s".' % func.__name__ else return result
def bandpass_pre_cache lows 80 100 120 highs 1200 3000 8000 bands 2000 8000 rate 44100 for low in lows for high in highs _butter 6 low high rate rate for band in bands _butter 6 band rate rate
def get_valid_filename s s force_unicode s .strip .replace '' '_' return re.sub ' ?u [^-\\w.]' '' s
def votes_visible user return c.user_is_loggedin and c.user.name user.name or user.pref_public_votes or c.user_is_admin
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def get_product_images product return list product.images.all
def posix_time_to_http posix_time if posix_time return email_utils.formatdate posix_time usegmt True
def getOrderedNestedRings nestedRings insides []orderedNestedRings []for loopIndex in xrange len nestedRings nestedRing nestedRings[loopIndex]otherLoops []for beforeIndex in xrange loopIndex otherLoops.append nestedRings[beforeIndex].boundary for afterIndex in xrange loopIndex + 1 len nestedRings otherLoops.append nestedRings[afterIndex].boundary if isPathEntirelyInsideLoops otherLoops nestedRing.boundary insides.append nestedRing else orderedNestedRings.append nestedRing for outside in orderedNestedRings outside.getFromInsideSurroundings insides return orderedNestedRings
def import_by_name name prefixes [None] tried []for prefix in prefixes try if prefix prefixed_name '.'.join [prefix name] else prefixed_name name obj parent modname _import_by_name prefixed_name return prefixed_name obj parent modname except ImportError tried.append prefixed_name raise ImportError 'nomodulenamed%s' % 'or'.join tried
def forecast location params None url '{}/{}'.format api location headers {'Accept-Encoding' 'gzip'}r requests.get url params params headers headers if r.status_code ! 200 raise WeatherException 'Yourkeyisinvalidorforecast.ioisdown' r r.json if 'error' in r raise WeatherException 'Errorgettingweather {}'.format r['error'] r['error'] return r
def fork try pid fd os.forkpty except AttributeError OSError passelse if pid CHILD try os.setsid except OSError passreturn pid fd master_fd slave_fd openpty pid os.fork if pid CHILD os.setsid os.close master_fd os.dup2 slave_fd STDIN_FILENO os.dup2 slave_fd STDOUT_FILENO os.dup2 slave_fd STDERR_FILENO if slave_fd > STDERR_FILENO os.close slave_fd tmp_fd os.open os.ttyname STDOUT_FILENO os.O_RDWR os.close tmp_fd else os.close slave_fd return pid master_fd
def _NoBlankLinesBeforeCurrentToken text cur_token prev_token cur_token_lineno cur_token.linenoif cur_token.is_comment cur_token_lineno - cur_token.value.count u'\n' num_newlines text.count u'\n' if not prev_token.is_comment else 0 return prev_token.lineno + num_newlines cur_token_lineno - 1
def is_rhel distribution return distribution.startswith 'rhel-'
def _SerializeAggregateMetrics obj if isinstance obj metric.AggregatedMetric return {'start_time' obj.start_time 'end_time' obj.end_time 'group_key' obj.group_key 'machines' list obj.machines 'data' obj.counter_data}elif isinstance obj metric.AggregatedMetric.AggregatedCounter logging.info 'description %r' % obj.description return {'description' obj.description 'is_average' obj.is_average 'machine_data' obj.machine_data 'cluster_total' obj.cluster_total 'cluster_avg' obj.cluster_avg}else raise web.HTTPError 400 'ExpectedinstanceofAggregatedMetricorAggregatedCounter got%r' % obj
def to_img arr os return Image.fromarray arr.reshape os os * 255.0
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def get_all_exploration_summaries return _get_exploration_summaries_from_models exp_models.ExpSummaryModel.get_all
def dump_data_every_thread func delay_minutes save_thread_ptr try func except KeyboardInterrupt passsave_thread threading.Timer delay_minutes * 60 dump_data_every_thread args func delay_minutes save_thread_ptr save_thread.name 'ProfilingDumpData'save_thread.daemon Truesave_thread.start if save_thread_ptr save_thread_ptr.pop 0 save_thread_ptr.append save_thread
def create_equity_curve all_holdings curve pd.DataFrame all_holdings curve.set_index 'datetime' inplace True curve['returns'] curve['equity'].pct_change curve.iloc[ 0 3 ] 0curve['networth'] 1.0 + curve['returns'] .cumprod return curve
def exception msg *args error msg exc_info 1 *args
def SQLiteFileLock *args **kwds from . import sqlitelockfilereturn _fl_helper sqlitelockfile.SQLiteLockFile 'lockfile.sqlitelockfile' *args **kwds
def get_member_refids group exclude None members get_members group if len members 0 return []if exclude is None exclude []return [r.FnGetRefId for r in members if r.FnGetRefId not in exclude ]
def read_cifar10 filename_queue class CIFAR10Record object passresult CIFAR10Record label_bytes 1result.height 32result.width 32result.depth 3image_bytes result.height * result.width * result.depth record_bytes label_bytes + image_bytes reader tf.FixedLengthRecordReader record_bytes record_bytes result.key value reader.read filename_queue record_bytes tf.decode_raw value tf.uint8 result.label tf.cast tf.strided_slice record_bytes [0] [label_bytes] tf.int32 depth_major tf.reshape tf.strided_slice record_bytes [label_bytes] [ label_bytes + image_bytes ] [result.depth result.height result.width] result.uint8image tf.transpose depth_major [1 2 0] return result
def tablespace_list user None host None port None maintenance_db None password None runas None ret {}query 'SELECTspcnameas"Name" pga.rolnameas"Owner" spcaclas"ACL" spcoptionsas"Opts" pg_tablespace_location pgts.oid as"Location"FROMpg_tablespacepgts pg_rolespgaWHEREpga.oid pgts.spcowner'rows __salt__['postgres.psql_query'] query runas runas host host user user port port maintenance_db maintenance_db password password for row in rows ret[row['Name']] rowret[row['Name']].pop 'Name' return ret
def write_dau_pack16 fid kind data data_size 2data np.array data dtype '>i2' .T_write fid data kind data_size FIFF.FIFFT_DAU_PACK16 '>i2'
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def strip_between a b string p '%s.*?%s' % a b p re.compile p re.DOTALL | re.I return re.sub p '' string
def read_string buffer offset length int_struct.unpack_from buffer offset [0]offset + int_struct.sizeif length < 0 return None offset else index offsetoffset + lengthreturn buffer[index index + length ].decode 'utf-8' offset
def setup_axes fig rect tr Affine2D .scale np.pi / 180.0 1.0 + PolarAxes.PolarTransform extreme_finder angle_helper.ExtremeFinderCycle 20 20 lon_cycle 360 lat_cycle None lon_minmax None lat_minmax 0 np.inf grid_locator1 angle_helper.LocatorDMS 12 grid_locator2 grid_finder.MaxNLocator 5 tick_formatter1 angle_helper.FormatterDMS grid_helper GridHelperCurveLinear tr extreme_finder extreme_finder grid_locator1 grid_locator1 grid_locator2 grid_locator2 tick_formatter1 tick_formatter1 ax1 axisartist.Subplot fig rect grid_helper grid_helper ax1.axis[ ].toggle ticklabels False fig.add_subplot ax1 ax1.set_aspect 1.0 ax1.set_xlim -5 12 ax1.set_ylim -5 10 return ax1
def key_value_to_tree data tree {}for flatkey value in six.iteritems data t treekeys flatkey.split __opts__['pepa_delimiter'] for key in keys if key keys[ -1 ] t[key] valueelse t t.setdefault key {} return tree
def precedence state try return PRECEDENCE_LOOKUP[state]except KeyError return NONE_PRECEDENCE
def test_hard_sigmoid def ref_hard_sigmoid x '\nReferencehardsigmoidwithslopeandshiftvaluesfromtheano see\nhttps //github.com/Theano/Theano/blob/master/theano/tensor/nnet/sigm.py\n'x x * 0.2 + 0.5 z 0.0 if x < 0 else 1.0 if x > 1 else x return zhard_sigmoid np.vectorize ref_hard_sigmoid x K.placeholder ndim 2 f K.function [x] [activations.hard_sigmoid x ] test_values get_standard_values result f [test_values] [0]expected hard_sigmoid test_values assert_allclose result expected rtol 1e-05
def default_deadline_for_credit_eligibility return datetime.datetime.now pytz.UTC + datetime.timedelta days getattr settings 'CREDIT_ELIGIBILITY_EXPIRATION_DAYS' 365
@collect_authdef auth_login auth campaign request.args.get 'campaign' next_url request.args.get 'next' data login_and_register_handler auth login True campaign campaign next_url next_url if data['status_code'] http.FOUND return redirect data['next_url']
def config_name_from_full_name full_name projects _ configs result full_name.split '/' if projects ! 'projects' or configs ! 'configs' raise ValueError 'Unexpectedformatofresource' full_name 'Expected"projects/{proj}/configs/{cfg}"' return result
def parse_btrfs rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--name' dest 'name' action 'store' parser.add_argument '--data' dest 'data' action 'store' parser.add_argument '--metadata' dest 'metadata' action 'store' parser.add_argument '--label' dest 'label' action 'store' parser.add_argument '--noformat' dest 'noformat' action 'store_true' parser.add_argument '--useexisting' dest 'useexisting' action 'store_true' parser.add_argument '--subvol' dest 'subvol' action 'store_true' args clean_args vars parser.parse_args rules parser Nonereturn args
def getFabmetheusPath subName '' return getJoinedPath os.path.dirname os.path.dirname os.path.abspath __file__ subName
def undo_logger_setup root_logger.removeHandler handler for logger in _extra_loggers logger.setLevel logging.NOTSET
def _api_test_windows name output kwargs logging.info 'Sendingtestnotification' res sabnzbd.notifier.send_windows 'SABnzbd' T 'TestNotification' 'other' return report output error res
@get '/scan/<taskid>/stop' def scan_stop taskid if taskid not in DataStore.tasks or DataStore.tasks[taskid].engine_process is None or DataStore.tasks[taskid].engine_has_terminated logger.warning '[%s]InvalidtaskIDprovidedtoscan_stop ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} DataStore.tasks[taskid].engine_stop logger.debug '[%s]Stoppedscan' % taskid return jsonize {'success' True}
def addNegatives derivation negatives paths portionDirections getSpacedPortionDirections derivation.interpolationDictionary for path in paths loopLists getLoopListsByPath derivation 1.000001 path portionDirections geometryOutput triangle_mesh.getPillarsOutput loopLists negatives.append geometryOutput
def get_default_object_values return json.loads utils.get_file_contents feconf.OBJECT_DEFAULT_VALUES_FILE_PATH
def jcal2jd year month day year int year month int month day int day jd 367 * year x ipart month - 9 / 7.0 jd - ipart 7 * year + 5001 + x / 4.0 jd + ipart 275 * month / 9.0 jd + dayjd + 1729777 - 2400000.5 jd - 0.5return MJD_0 jd
def _add_call_item_to_queue pending_work_items work_ids call_queue while True if call_queue.full returntry work_id work_ids.get block False except queue.Empty returnelse work_item pending_work_items[work_id]if work_item.future.set_running_or_notify_cancel call_queue.put _CallItem work_id work_item.fn work_item.args work_item.kwargs block True else del pending_work_items[work_id]continue
def quota_usage_get context project_id resource return IMPL.quota_usage_get context project_id resource
def mackinnoncrit N 1 regression 'c' nobs inf reg regressionif reg not in ['c' 'ct' 'nc' 'ctt'] raise ValueError 'regressionkeyword%snotunderstood' % reg if nobs is inf return eval 'tau_' + reg + '_2010[' + str N - 1 + ' 0]' else return polyval eval 'tau_' + reg + '_2010[' + str N - 1 + ' -1].T' 1.0 / nobs
def critical_block_end registry xml_parent data cbs XML.SubElement xml_parent 'org.jvnet.hudson.plugins.exclusion.CriticalBlockEnd' cbs.set 'plugin' 'Exclusion'
def verifyHostKey transport host pubKey fingerprint actualHost transport.factory.options['host']actualKey keys.Key.fromString pubKey kh KnownHostsFile.fromPath FilePath transport.factory.options['known-hosts'] or os.path.expanduser '~/.ssh/known_hosts' ui ConsoleUI lambda _open '/dev/tty' 'r+b' return kh.verifyHostKey ui actualHost host actualKey
def prepare_bearer_headers token headers None headers headers or {} headers[u'Authorization'] u'Bearer%s' % token return headers
def _sakurai n A scipy.sparse.eye n n d0 array r_[ 5 6 * ones n - 2 5 ] d1 -4 * ones n d2 ones n B scipy.sparse.spdiags [d2 d1 d0 d1 d2] [ -2 -1 0 1 2] n n k arange 1 n + 1 w_ex sort 1.0 / 16.0 * pow cos 0.5 * k * pi / n + 1 4 return A B w_ex
def fnmatchcase name pat try re_pat _cache[pat]except KeyError res translate pat if len _cache > _MAXCACHE _cache.clear _cache[pat] re_pat re.compile res return re_pat.match name is not None
def getRegInfo disp host info {} sync True iq Iq 'get' NS_REGISTER to host for i in info.keys iq.setTagData i info[i] if sync resp disp.SendAndWaitForResponse iq _ReceivedRegInfo disp.Dispatcher resp host return respelse disp.SendAndCallForResponse iq _ReceivedRegInfo {'agent' host}
def _get_descending_key gettime time.time now_descending int _FUTURE_TIME - gettime * 100 request_id_hash os.environ.get 'REQUEST_ID_HASH' if not request_id_hash request_id_hash str random.getrandbits 32 return '%d%s' % now_descending request_id_hash
def ignore_missing key data errors context value data.get key if value is missing or value is None data.pop key None raise StopOnError
def _maybe_schedule_rebuild form if 'title' in form.changed_data or 'slug' in form.changed_data schedule_rebuild_kb
def cache_translations_for_tree root_objects languages None all_objects {}def walk object_list for object in object_list all_objects[object.pk] objectwalk object.get_children walk root_objects cache_translations list all_objects.values languages languages
def _create_new_course request org number run fields org_data get_organization_by_short_name org if not org_data and organizations_enabled return JsonResponse {'error' _ 'Youmustlinkthiscoursetoanorganizationinordertocontinue.Organizationyouselecteddoesnotexistinthesystem youwillneedtoaddittothesystem' } status 400 store_for_new_course modulestore .default_modulestore.get_modulestore_type new_course create_new_course_in_store store_for_new_course request.user org number run fields add_organization_course org_data new_course.id return JsonResponse {'url' reverse_course_url 'course_handler' new_course.id 'course_key' unicode new_course.id }
def get_home_dir home os.getenv 'HOME' if home is None home os.path.expanduser '~' if home '~' home os.getenv 'USERPROFILE' assert home is not None return home
def list_public_ip_blocks module driver network_domain try blocks driver.ex_list_public_ip_blocks network_domain return blocksexcept DimensionDataAPIException e get_exception module.fail_json msg 'ErrorretrevingPublicIPBlocks %s' % e
def _download_and_uncompress_dataset dataset_dir filename _DATA_URL.split '/' [ -1 ]filepath os.path.join dataset_dir filename if not os.path.exists filepath def _progress count block_size total_size sys.stdout.write '\r>>Downloading%s%.1f%%' % filename float count * block_size / float total_size * 100.0 sys.stdout.flush filepath _ urllib.request.urlretrieve _DATA_URL filepath _progress print statinfo os.stat filepath print 'Successfullydownloaded' filename statinfo.st_size 'bytes.' tarfile.open filepath 'r gz' .extractall dataset_dir
def RecursiveDownload dir_obj target_dir max_depth 10 depth 1 overwrite False max_threads 10 if not isinstance dir_obj aff4.AFF4Volume returnthread_pool threadpool.ThreadPool.Factory 'Downloader' max_threads thread_pool.Start for sub_file_entry in dir_obj.OpenChildren path_elements [target_dir]sub_target_dir u'/'.join path_elements try if isinstance sub_file_entry aff4.AFF4Stream args sub_file_entry.urn sub_target_dir sub_file_entry.token overwrite thread_pool.AddTask target CopyAFF4ToLocal args args name 'Downloader' elif 'Container' in sub_file_entry.behaviours if depth > max_depth continuetry os.makedirs sub_target_dir except OSError passRecursiveDownload sub_file_entry sub_target_dir overwrite overwrite depth depth + 1 except IOError logging.exception 'Unabletodownload%s' sub_file_entry.urn finally sub_file_entry.Close if depth < 1 thread_pool.Stop
def get_temp_dir temp get_environ_variable 'TMP' if temp None temp get_environ_variable 'TEMP' if temp None or '' in temp and os.name 'nt' temp 'C \\temp'if temp None or '' in temp and os.name 'posix' temp '/tmp'return temp
def tree_hash fo hashes []hashes.extend fo while len hashes > 1 new_hashes []while True if len hashes > 1 first hashes.pop 0 second hashes.pop 0 new_hashes.append hashlib.sha256 first + second .digest elif len hashes 1 only hashes.pop 0 new_hashes.append only else breakhashes.extend new_hashes return hashes[0]
def _by_srid things srs True ret {}for thing in tup things if getattr thing 'sr_id' None is not None ret.setdefault thing.sr_id [] .append thing if srs _srs Subreddit._byID ret.keys return_dict True if ret else {} return ret _srs else return ret
def get_window window Nx fftbins True sym not fftbins try beta float window except TypeError ValueError args if isinstance window tuple winstr window[0]if len window > 1 args window[1 ]elif isinstance window string_types if window in _needs_param raise ValueError "The'" + window + "'windowneedsoneormoreparameters--passatuple." else winstr windowelse raise ValueError '%saswindowtypeisnotsupported.' % str type window try winfunc _win_equiv[winstr]except KeyError raise ValueError 'Unknownwindowtype.' params Nx + args + sym else winfunc kaiserparams Nx beta sym return winfunc *params
def _numpy_true_div x y out numpy.true_divide x y if x.dtype in tensor.discrete_dtypes and y.dtype in tensor.discrete_dtypes out theano._asarray out dtype config.floatX return out
def file_hash load fnd gitfs salt.utils.gitfs.GitFS __opts__ gitfs.init_remotes __opts__['gitfs_remotes'] PER_REMOTE_OVERRIDES PER_REMOTE_ONLY return gitfs.file_hash load fnd
@when u'weuseanamedquery' def step_use_named_query context context.cli.sendline u'\\nfoo'
def _linear_2eq_order1_type3 x y t r eq C1 C2 C3 C4 get_numbered_constants eq num 4 F Integral r['a'] t G Integral r['b'] t sol1 exp F * C1 * exp G + C2 * exp - G sol2 exp F * C1 * exp G - C2 * exp - G return [Eq x t sol1 Eq y t sol2 ]
@cmddef test install sh '%s%s' % PYTHON TSCRIPT
@require_POST@permission_required 'kbforums.sticky_thread' def sticky_thread request document_slug thread_id doc get_document document_slug request thread get_object_or_404 Thread pk thread_id document doc thread.is_sticky not thread.is_sticky log.info 'User%ssetis_sticky %sonKBthreadwithid %s' % request.user thread.is_sticky thread.id thread.save return HttpResponseRedirect reverse 'wiki.discuss.posts' args [document_slug thread_id]
def get_storage_plugin config storage_name getattr config 'STORAGE' 'Shelf' extra_storage_plugins_dir getattr config 'BOT_EXTRA_STORAGE_PLUGINS_DIR' None spm SpecificPluginManager config 'storage' StoragePluginBase CORE_STORAGE extra_storage_plugins_dir storage_pluginfo spm.get_candidate storage_name log.info "FoundStorageplugin '%s'\nDescription %s" % storage_pluginfo.name storage_pluginfo.description storage_plugin spm.get_plugin_by_name storage_name return storage_plugin
def resolve_ssl_version candidate if candidate is None return PROTOCOL_SSLv23if isinstance candidate str res getattr ssl candidate None if res is None res getattr ssl 'PROTOCOL_' + candidate return resreturn candidate
def region_code_for_number numobj country_code numobj.country_coderegions COUNTRY_CODE_TO_REGION_CODE.get country_code None if regions is None return Noneif len regions 1 return regions[0]else return _region_code_for_number_from_list numobj regions
def getNewRepository return FillRepository
def profileTP tpClass tpDim nRuns tp tpClass numberOfCols tpDim data numpy.random.randint 0 2 [tpDim nRuns] .astype 'float32' for i in xrange nRuns d data[ i]tp.compute d True
def nt_quote_arg arg result []needquote Falsenb 0needquote '' in arg or ' DCTB ' in arg if needquote result.append '"' for c in arg if c '\\' nb + 1elif c '"' result.append '\\' * nb * 2 + '\\"' nb 0else if nb result.append '\\' * nb nb 0result.append c if nb result.append '\\' * nb if needquote result.append '\\' * nb result.append '"' return ''.join result
def make_subreddit_traffic_report subreddits None num None if subreddits subreddit_summary traffic.PageviewsBySubreddit.last_month subreddits else subreddit_summary traffic.PageviewsBySubreddit.top_last_month num report []for srname data in subreddit_summary if srname _DefaultSR.name name _ '[frontpage]' url Noneelif srname in Subreddit._specials name '[%s]' % srname url Noneelse name '/r/%s' % srname url name + '/about/traffic' report.append name url data return report
def v6_int_to_packed address try return address.to_bytes 16 'big' except Exception raise ValueError 'AddressnegativeortoolargeforIPv6'
def get_parametrized_fixture_keys item scopenum assert scopenum < scopenum_function try cs item.callspecexcept AttributeError passelse for argname param_index in cs.indices.items if cs._arg2scopenum[argname] ! scopenum continueif scopenum 0 key argname param_index elif scopenum 1 key argname param_index item.fspath elif scopenum 2 key argname param_index item.fspath item.cls yield key
def ATOM atom return etree.XML atom atom_parser
def get_model_by_resource_ref db_api ref ref_obj ResourceReference.from_string_reference ref ref result db_api.query name ref_obj.name pack ref_obj.pack .first return result
def multiple_choice_validator optdict name value choices optdict['choices']values optik_ext.check_csv None name value for value in values if not value in choices msg 'option%s invalidvalue %r shouldbein%s'raise optik_ext.OptionValueError msg % name value choices return values
def recho text return text[ -1 ]
def decode_tbs byts flag_size 4 byts bytes byts val flags consumed decode_fvwi byts flag_size flag_size extra {}byts byts[consumed ]if flags & 8 and flag_size > 3 extra[8] Trueif flags & 2 x consumed2 decint byts byts byts[consumed2 ]extra[2] xconsumed + consumed2if flags & 4 extra[4] ord byts[0] byts byts[1 ]consumed + 1if flags & 1 x consumed2 decint byts byts byts[consumed2 ]extra[1] xconsumed + consumed2return val extra consumed
def configure_cluster cluster dataset_backend_configuration provider logging_config None return sequence [configure_control_node cluster provider logging_config parallel [sequence [configure_node cluster node certnkey dataset_backend_configuration provider logging_config ] for certnkey node in zip cluster.certificates.nodes cluster.agent_nodes ] ]
def ckan_after_request response response check_session_cookie response response set_cors_headers_for_response response return response
def calculate_group_counts messages user_email res defaultdict int for msg in messages participants _get_participants msg [user_email] if len participants > MIN_GROUP_SIZE res[' '.join participants ] + 1return res
def get_completed_exercises user exercises_by_user ExerciseLog.objects.filter user user complete True .values_list 'exercise_id' flat True return exercises_by_user
def get_mongo_application return Application name MONGO_APPLICATION image DockerImage.from_string MONGO_IMAGE + u' latest'
def whitelist allow_guest False xss_safe False def innerfn fn global whitelisted guest_methods xss_safe_methodswhitelisted.append fn if allow_guest guest_methods.append fn if xss_safe xss_safe_methods.append fn return fnreturn innerfn
def lshift a b return a << b
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def show_security_rule call None kwargs None global netconnif not netconn netconn get_conn NetworkManagementClient if kwargs is None kwargs {}if kwargs.get 'resource_group' is None kwargs['resource_group'] config.get_cloud_config_value 'resource_group' {} __opts__ search_global True rule netconn.security_rules.get resource_group_name kwargs['resource_group'] network_security_group_name kwargs['security_group'] security_rule_name kwargs['name'] return make_safe rule
def lagged_groups x lag groupidx out0 []out_lagged []for l u in groupidx if l + lag < u out0.append x[ l + lag u] out_lagged.append x[l u - lag ] if out0 [] raise ValueError 'allgroupsareemptytakinglags' return np.vstack out0 np.vstack out_lagged
def resource_view_list context data_dict model context['model']id _get_or_bust data_dict 'id' resource model.Resource.get id if not resource raise NotFoundcontext['resource'] resource_check_access 'resource_view_list' context data_dict q model.Session.query model.ResourceView .filter_by resource_id id resource_views [resource_view for resource_view in q.order_by model.ResourceView.order .all if datapreview.get_view_plugin resource_view.view_type ]return model_dictize.resource_view_list_dictize resource_views context
def ppcc_max x brack 0.0 1.0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats.pearsonr xvals yvals return 1 - r return optimize.brent tempfunc brack brack args osm_uniform osr dist.ppf
def get_organizations if not organizations_enabled return []from organizations import api as organizations_apitry return organizations_api.get_organizations except DatabaseError return []
def juggle_axes xs ys zs zdir if zdir u'x' return zs xs ys elif zdir u'y' return xs zs ys elif zdir[0] u'-' return rotate_axes xs ys zs zdir else return xs ys zs
def output_opts conf opts names [opt.name for opt in opts if not opt.secret ]output_opt_info conf names
def manual_search session task artist input_ u'Artist ' .strip name input_ u'Album ' if task.is_album else u'Track ' .strip if task.is_album _ _ prop autotag.tag_album task.items artist name return propelse return autotag.tag_item task.item artist name
def init mpstate return CmdlongModule mpstate
def get_inner_objects vim base_obj path inner_type properties_to_collect None all False client_factory vim.client.factorybase_type base_obj._typetraversal_spec vutil.build_traversal_spec client_factory 'inner' base_type path False [] object_spec vutil.build_object_spec client_factory base_obj [traversal_spec] property_spec vutil.build_property_spec client_factory type_ inner_type properties_to_collect properties_to_collect all_properties all property_filter_spec vutil.build_property_filter_spec client_factory [property_spec] [object_spec] options client_factory.create 'ns0 RetrieveOptions' options.maxObjects CONF.vmware.maximum_objectsreturn vim.RetrievePropertiesEx vim.service_content.propertyCollector specSet [property_filter_spec] options options
def hwaddr_interfaces ret {}ifaces _get_interfaces for face in ifaces if 'hwaddr' in ifaces[face] ret[face] ifaces[face]['hwaddr']return {'hwaddr_interfaces' ret}
def format_power power if not isinstance power Fraction if power % 1.0 ! 0.0 frac Fraction.from_float power power frac.limit_denominator 10 if power.denominator 1 power int power.numerator else power int power return six.text_type power
def de_dupe_version_table apps schema_editor db_alias schema_editor.connection.aliasVersion apps.get_model u'reversion' u'Version' keep_version_ids Version.objects.using db_alias .order_by .values_list u'revision_id' u'content_type_id' u'object_id' .annotate max_pk models.Max u'pk' .values_list u'max_pk' flat True if keep_version_ids.count Version.objects.using db_alias .all .count returndelete_version_ids list Version.objects.using db_alias .exclude pk__in keep_version_ids .values_list u'pk' flat True Version.objects.using db_alias .filter pk__in delete_version_ids .delete
@open_file 1 mode 'wb' def write_edgelist G path comments '#' delimiter '' data True encoding 'utf-8' for line in generate_edgelist G delimiter data line + '\n'path.write line.encode encoding
def libvlc_set_fullscreen p_mi b_fullscreen f _Cfunctions.get 'libvlc_set_fullscreen' None or _Cfunction 'libvlc_set_fullscreen' 1 1 None None MediaPlayer ctypes.c_int return f p_mi b_fullscreen
def reload_routes import gluon.rewritegluon.rewrite.load redirect URL 'site'
def ffmpeg_movie_from_frames filename folder fps digits 6 s '%' + '%02d' % digits + 'd.png' cmd [get_setting 'FFMPEG_BINARY' '-y' '-f' 'image2' '-r' '%d' % fps '-i' os.path.join folder folder + '/' + s '-b' '%dk' % bitrate '-r' '%d' % self.fps filename]subprocess_call cmd
def mvn_nloglike_obs x sigma sigmainv np.linalg.inv sigma cholsigmainv np.linalg.cholesky sigmainv .Tx_whitened np.dot cholsigmainv x logdetsigma np.log np.linalg.det sigma sigma2 1.0llike 0.5 * np.log sigma2 - 2.0 * np.log np.diagonal cholsigmainv + x_whitened ** 2 / sigma2 + np.log 2 * np.pi return llike
def div_expr lh_op rh_op return lo.LinOp lo.DIV lh_op.size [lh_op] rh_op
def evaluate_quadratic J g s diag None if s.ndim 1 Js J.dot s q np.dot Js Js if diag is not None q + np.dot s * diag s else Js J.dot s.T q np.sum Js ** 2 axis 0 if diag is not None q + np.sum diag * s ** 2 axis 1 l np.dot s g return 0.5 * q + l
def pvector_field item_type optional False initial return _sequence_field CheckedPVector 'PVector' item_type optional initial
def str_join arr sep return _na_map sep.join arr
def to_encodable_string obj encoding if isinstance obj DataToken obj obj.get_value if isinstance obj unicode obj obj.encode encoding errors 'ignore' else obj str obj return obj
def make_default_short_help help max_length 45 words help.split total_length 0result []done Falsefor word in words if word[ -1 ] '.' done Truenew_length result and 1 + len word or len word if total_length + new_length > max_length result.append '...' done Trueelse if result result.append '' result.append word if done breaktotal_length + new_lengthreturn ''.join result
def test_scharr_mask np.random.seed 0 result filters.scharr np.random.uniform size 10 10 np.zeros 10 10 bool assert_allclose result 0
def match_dhcp_options vpc_conn tags None options None dhcp_options vpc_conn.get_all_dhcp_options for dopts in dhcp_options if not tags or get_resource_tags vpc_conn dopts.id tags if not options or dopts.options options return True dopts return False None
def kegg_link target_db source_db option None if option and option not in ['turtle' 'n-triple'] raise Exception 'Invalidoptionargforkeggconvrequest.' if isinstance source_db list source_db '+'.join source_db if option resp _q 'link' target_db source_db option else resp _q 'link' target_db source_db return resp
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def FileCheck path path PathCheck path if not os.path.isfile path raise ValueError _ 'Notafile %s' % path return path
def update_autoscaler gce autoscaler params as_policy _gen_gce_as_policy params['policy'] if autoscaler.policy ! as_policy autoscaler.policy as_policyautoscaler gce.ex_update_autoscaler autoscaler if autoscaler return Truereturn False
@pytest.mark.skipif 'notHAS_BEAUTIFUL_SOUP' def test_rename_cols table_in ['<table>' '<tr><th>A</th><th>B</th></tr>' '<tr><td>1</td><td>2</td></tr>' '</table>']dat Table.read table_in format 'ascii.html' names ['B' 'A'] assert dat.colnames ['B' 'A'] assert len dat 1 dat Table.read table_in format 'ascii.html' names ['B' 'A'] include_names ['A'] assert dat.colnames ['A'] assert len dat 1 assert np.all dat['A'] 2
def ListClientLogs client obj_store auth_credentials request callback def _OnListClientLogs log_urls logging.info 'LISTCLIENTLOGS admin %s clientuser_id %d start %s end %s filter %s num_logs %d' % auth_credentials request['user_id'] ClientLog._IsoDate request['start_timestamp'] ClientLog._IsoDate request['end_timestamp'] request.get 'filter' None len log_urls response {'log_urls' log_urls}callback response ClientLog.ListClientLogs request['user_id'] request['start_timestamp'] request['end_timestamp'] request.get 'filter' None _OnListClientLogs
def _list_keys user None gnupghome None secret False gpg _create_gpg user gnupghome _keys gpg.list_keys secret return _keys
def get_available_formats ret ''for formats in IRC_FORMATTING_DICT ret + formats + ' ' return ret[ -2 ]
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def _leading_space_count line i 0while i < len line and line[i] u'' i + 1return i
def _generation_hash_value_factory x if x is None return xtransform lambda y y if isinstance x bytes transform ordreturn tuple transform i for i in x
def test_read_bin_lush_matrix_ubyte_3tensor path example_bin_lush_path + 'ubyte_3tensor.lushbin' result read_bin_lush_matrix path assert str result.dtype 'uint8' assert len result.shape 3 if result.shape ! 2 3 4 raise AssertionError 'ubyte_3tensor.lushbinstoresa3-tensorofshape 2 3 4 butread_bin_lush_matrixthinksithasshape' + str result.shape for i in xrange 1 3 for j in xrange 1 4 for k in xrange 1 5 assert result[ i - 1 j - 1 k - 1 ] i + 3 * j + 12 * k
def createLogger obj if inspect.isclass obj myClass objelse myClass obj.__class__logger logging.getLogger '.'.join ['com.numenta' myClass.__module__ myClass.__name__] return logger
def listicons icondir ICONDIR root Tk import globlist glob.glob os.path.join icondir '*.gif' list.sort images []row column 0for file in list name os.path.splitext os.path.basename file [0]image PhotoImage file file master root images.append image label Label root image image bd 1 relief 'raised' label.grid row row column column label Label root text name label.grid row row + 1 column column column column + 1 if column > 10 row row + 2 column 0root.images images
def getVector3Paths complexPaths z 0.0 vector3Paths []for complexPath in complexPaths vector3Paths.append getVector3Path complexPath z return vector3Paths
def has_forum_access uname course_id rolename try role Role.objects.get name rolename course_id course_id except Role.DoesNotExist return Falsereturn role.users.filter username uname .exists
def get_os_info filepath '/etc/os-release' if os.path.isfile filepath os_name os_version get_systemd_os_info filepath filepath if os_name return os_name os_version return get_python_os_info
@xfail_py3@xfail wxPython_fail reason 'UnsupportedwxPythonversion' @importorskip 'wx.lib.pubsub' def test_wx_lib_pubsub_protocol_default pyi_builder pyi_builder.test_script 'pyi_hooks/wx_lib_pubsub.py'
def tar_backup_files file_paths target backup_file_location targetif not rename backup_file_location '{0}{1}'.format backup_file_location BACKUP_ROLLBACK_SUFFIX logging.warning "'{0}'notfound.Skippingfilerename...".format backup_file_location tar tarfile.open backup_file_location 'w' for name in file_paths tar.add name tar.close return backup_file_location
def is_safe_url url host None if url is not None url url.strip if not url return Falseurl url.replace u'\\' u'/' if url.startswith u'///' return Falseurl_info urlparse url if not url_info.netloc and url_info.scheme return Falseif unicodedata.category url[0] [0] u'C' return Falsereturn not url_info.netloc or url_info.netloc host and not url_info.scheme or url_info.scheme in [u'http' u'https']
def preflow_push G s t capacity 'capacity' residual None global_relabel_freq 1 value_only False R preflow_push_impl G s t capacity residual global_relabel_freq value_only R.graph['algorithm'] 'preflow_push'return R
def mac_set_relative_dylib_deps libname distname from PyInstaller.lib.macholib import utilfrom PyInstaller.lib.macholib.MachO import MachOif os.path.basename libname in _BOOTLOADER_FNAMES returnparent_dir ''if os.path.dirname distname parent_level len os.path.dirname distname .split os.sep parent_dir parent_level * os.pardir + os.sep def match_func pth '\nForsystemlibrariesisstillusedabsolutepath.Itisunchanged.\n'if not util.in_system_path pth return os.path.join '@loader_path' parent_dir os.path.basename pth dll MachO libname dll.rewriteLoadCommands match_func try f open dll.filename 'rb+' for header in dll.headers f.seek 0 dll.write f f.seek 0 2 f.flush f.close except Exception pass
def getProfileBaseName repository if repository.getProfileDirectory None return repository.baseNamereturn os.path.join repository.getProfileDirectory repository.baseName
def service_get_all_by_topic context topic return IMPL.service_get_all_by_topic context topic
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg 'address' metavar '<address>' help _ 'IPAddress.' def do_remove_fixed_ip cs args server _find_server cs args.server server.remove_fixed_ip args.address
@frappe.whitelist def get_incoming_rate args from erpnext.stock.stock_ledger import get_previous_sleif isinstance args basestring args json.loads args in_rate 0if args.get u'serial_no' or u'' .strip in_rate get_avg_purchase_rate args.get u'serial_no' else valuation_method get_valuation_method args.get u'item_code' previous_sle get_previous_sle args if valuation_method u'FIFO' if not previous_sle return 0.0previous_stock_queue json.loads previous_sle.get u'stock_queue' u'[]' or u'[]' in_rate get_fifo_rate previous_stock_queue args.get u'qty' or 0 if previous_stock_queue else 0 elif valuation_method u'MovingAverage' in_rate previous_sle.get u'valuation_rate' or 0 return in_rate
def parse_ancient_function_plugin logger line res line.split res[3] {'metric_type' 'gauge'}
@register.simple_tag takes_context True def avatar context user size service_id None service avatar_services.for_user user service_id if service is None logging.error u'Couldnotgetasuitableavatarserviceforuser%s.' user return mark_safe u'' return service.render request context[u'request'] user user size size
def reader_macroexpand char tree compiler load_macros compiler.module_name reader_macro _hy_reader[compiler.module_name].get char if reader_macro is None try reader_macro _hy_reader[None][char]except KeyError raise HyTypeError char "`{0}'isnotadefinedreadermacro.".format char expr reader_macro tree return replace_hy_obj wrap_value expr tree
def os_version attrs None where None return _osquery_cmd table 'os_version' attrs attrs where where
def ebConnection reason log.startLogging sys.stdout log.err reason return reason
def attach_role_points queryset as_field 'role_points_attr' model queryset.modelsql 'SELECTFORMAT \'{{%%s}}\' \nSTRING_AGG format \n\'"%%s" %%s\' \nTO_JSON userstories_rolepoints.role_id \nTO_JSON userstories_rolepoints.points_id \n \' \' \n json\nFROMuserstories_rolepoints\nWHEREuserstories_rolepoints.user_story_id {tbl}.id'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def tracer pid tpid int status pid ['TracerPid'] return tpid if tpid > 0 else None
def _get_contrast_indices effect_idx n_factors binrepr np.binary_repr effect_idx n_factors return np.array [int i for i in binrepr] dtype int
def addGeometryList elementNode faces for face in faces faceElement xml_simple_reader.ElementNode face.addToAttributes faceElement.attributes faceElement.localName 'face'faceElement.parentNode elementNodeelementNode.childNodes.append faceElement
def _onpick_sensor event fig ax pos ch_names show_names if event.mouseevent.key 'control' and fig.lasso is not None for ind in event.ind fig.lasso.select_one ind returnif show_names returnind event.ind[0]ch_name ch_names[ind]this_pos pos[ind]ax.texts.pop 0 if len this_pos 3 ax.text this_pos[0] this_pos[1] this_pos[2] ch_name else ax.text this_pos[0] this_pos[1] ch_name fig.canvas.draw
def test_root_normalized_mean_absolute_error max_rating 5.0min_rating 1.0y_real np.array [0.0 1.0 0.0 2.0 3.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_equals 0.0 normalized_mean_absolute_error y_real y_pred max_rating min_rating y_real np.array [3.0 1.0 2.0 1.0 1.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_almost_equals 0.4 normalized_mean_absolute_error y_real y_pred max_rating min_rating
def sub matlist1 matlist2 K return add matlist1 negate matlist2 K K
def set_log_level_for_all_loggers level logging.DEBUG root_logger logging.getLogger loggers logging.Logger.manager.loggerDict.values loggers + [root_logger]for logger in loggers if not isinstance logger logging.Logger continueset_log_level_for_all_handlers logger logger
@register.filter 'phone2numeric' is_safe True def phone2numeric_filter value return phone2numeric value
def instance_profile_exists name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile try conn.get_instance_profile name return Trueexcept boto.exception.BotoServerError return False
def length_of_national_destination_code numobj if numobj.extension is not None copied_numobj PhoneNumber copied_numobj.merge_from numobj copied_numobj.extension Noneelse copied_numobj numobjnsn format_number copied_numobj PhoneNumberFormat.INTERNATIONAL number_groups re.split NON_DIGITS_PATTERN nsn if len number_groups < 3 return 0if number_type numobj PhoneNumberType.MOBILE mobile_token country_mobile_token numobj.country_code if mobile_token ! U_EMPTY_STRING return len number_groups[2] + len number_groups[3] return len number_groups[2]
def _init_non_posix vars vars['LIBDEST'] get_path 'stdlib' vars['BINLIBDEST'] get_path 'platstdlib' vars['INCLUDEPY'] get_path 'include' vars['SO'] '.pyd'vars['EXE'] '.exe'vars['VERSION'] _PY_VERSION_SHORT_NO_DOTvars['BINDIR'] os.path.dirname _safe_realpath sys.executable
def ode_Liouville eq func order match x func.args[0]f func.funcr matchy r['y'] C1 C2 get_numbered_constants eq num 2 int Integral exp Integral r['g'] y y None f x sol Eq int + C1 * Integral exp - Integral r['h'] x x + C2 0 return sol
@app.route '/put' methods 'PUT' def view_put return jsonify get_dict 'url' 'args' 'form' 'data' 'origin' 'headers' 'files' 'json'
def InsertNodesBefore new_nodes target for node in new_nodes _InsertNodeAt node target after False
def validate_tunnel_config tunnel_types local_ip if not tunnel_types returnvalidate_local_ip local_ip for tun in tunnel_types if tun not in constants.TUNNEL_NETWORK_TYPES LOG.error _LE 'Invalidtunneltypespecified %s' tun raise SystemExit 1
def make_matrix return T.matrix
def dashboard_activity_list user_id limit offset q _dashboard_activity_query user_id limit + offset return _activities_at_offset q limit offset
def require_git_version required_version git_path _DEFAULT_GIT found_version git_version git_path git_path if found_version is None raise SkipTest 'Testrequiresgit> %s butcgitnotfound' % required_version if len required_version > _VERSION_LEN raise ValueError 'Invalidversiontuple%s expected%iparts' % required_version _VERSION_LEN required_version list required_version while len found_version < len required_version required_version.append 0 required_version tuple required_version if found_version < required_version required_version '.'.join map str required_version found_version '.'.join map str found_version raise SkipTest 'Testrequiresgit> %s found%s' % required_version found_version
@then 'itshouldpassbecause"{reason}"' def then_it_should_pass_because context reason pass
def virt_type return __grains__['virtual']
def check_id ID name u'ID' config None pos None if ID is not None and not xml_check.check_id ID warn_or_raise W02 W02 name ID config pos return Falsereturn True
def _iso8601 dt return dt.isoformat
def taggedValue key value f_locals sys._getframe 1 .f_localstagged_values f_locals.setdefault TAGGED_DATA {} tagged_values[key] valuereturn _decorator_non_return
def _addRecentTile layer coord format body age 300 key layer coord format due time + age _recent_tiles['hash'][key] body due _recent_tiles['list'].append key due logging.debug 'TileStache.Core._addRecentTile addedtiletorecenttiles %s' key cutoff 0for i key due_by in enumerate _recent_tiles['list'] if time < due_by cutoff ibreaklogging.debug 'TileStache.Core._addRecentTile removedtilefromrecenttiles %s' key try del _recent_tiles['hash'][key]except KeyError passdel _recent_tiles['list'][ cutoff]
def get_signature signature_data try signature base64.decode_as_bytes signature_data except TypeError binascii.Error raise exception.SignatureVerificationError reason _ 'Thesignaturedatawasnotproperlyencodedusingbase64' return signature
def get_root_dir curdir os.path.dirname os.path.abspath __file__ return os.path.abspath os.path.join curdir '..'
def getGeometryUtilitiesPath subName '' return getJoinedPath getGeometryPath 'geometry_utilities' subName
def skipgrams sequence n k **kwargs if 'pad_left' in kwargs or 'pad_right' in kwargs sequence pad_sequence sequence n **kwargs SENTINEL object for ngram in ngrams sequence n + k pad_right True right_pad_symbol SENTINEL head ngram[ 1]tail ngram[1 ]for skip_tail in combinations tail n - 1 if skip_tail[ -1 ] is SENTINEL continue yield head + skip_tail
def paragraph return ''.join sentence for i in range random.randint 1 4
def check_permission user project permission return has_group_perm user permission project project or check_owner user project permission or user.has_perm permission
def instance_cache func def _wrapper self *args **kwargs key func.__name__ + args for pair in sorted kwargs.items key + pairif key in self._cache return self._cache[key]data func self *args **kwargs self._cache[key] datareturn datareturn _wrapper
def find_common_parent a b a_parents list a.iterancestors b_parents list b.iterancestors a_parents_set set a_parents b_parents_set set b_parents if a b return aif b in a_parents_set return bif a in b_parents_set return aif len a_parents < len b_parents for elem in a_parents if elem b or elem in b_parents_set return elemelse for elem in b_parents if elem a or elem in a_parents_set return elem
def _interpolate a b fraction return a + b - a * fraction
def _consume_topics pubsub_client return list pubsub_client.list_topics
def p_idlist p if len p 2 p[0] [p[1]]else p[0] p[1]p[1].append p[3]
@with_setup prepare_stdout def test_output_snippets_with_normalized_unicode_names runner Runner feature_name 'latin-accents' verbosity 3 no_color True runner.run assert_stdout_lines u'\nFuncionalidade melhorarooutputdesnippetsdolettuce#tests/functional/output_features/latin-accents/latin-accents.feature 2\nComoautordolettuce#tests/functional/output_features/latin-accents/latin-accents.feature 3\nEuqueroterumoutputrefinadodesnippets#tests/functional/output_features/latin-accents/latin-accents.feature 4\nParamelhorar deumaformageral avidadoprogramador#tests/functional/output_features/latin-accents/latin-accents.feature 5\n\nCen\xe1rio normalizarsnippetscomunicode#tests/functional/output_features/latin-accents/latin-accents.feature 7\nDadoqueeutenhopalavr\xf5eseoutrassitua\xe7\xf5es#tests/functional/output_features/latin-accents/latin-accents.feature 8 undefined \nEv\xe1riaspalavrasacentuadass\xe3o\xfateis taiscomo " \xe9 n\xe3o l\xe9o choror\xf3 ch\xe1cara ep\xedgrafo "#tests/functional/output_features/latin-accents/latin-accents.feature 9 undefined \nEnt\xe3oeuficofeliz\xe3o#tests/functional/output_features/latin-accents/latin-accents.feature 10 undefined \n\n1feature 0passed \n1scenario 0passed \n3steps 3undefined 0passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u\'Dadoqueeutenhopalavr\xf5eseoutrassitua\xe7\xf5es\' \ndefdado_que_eu_tenho_palavroes_e_outras_situacoes step \nassertFalse \'Thisstepmustbeimplemented\'\n@step u\'Ev\xe1riaspalavrasacentuadass\xe3o\xfateis taiscomo " [^"]* "\' \ndefe_varias_palavras_acentuadas_sao_uteis_tais_como_group1 step group1 \nassertFalse \'Thisstepmustbeimplemented\'\n@step u\'Ent\xe3oeuficofeliz\xe3o\' \ndefentao_eu_fico_felizao step \nassertFalse \'Thisstepmustbeimplemented\'\n'
def healthz request return HttpResponse 'ok'
def _generateCategory filename 'simple.csv' numSequences 2 elementsPerSeq 1 numRepeats 10 scriptDir os.path.dirname __file__ pathname os.path.join scriptDir 'datasets' filename print 'Creating%s...' % pathname fields [ 'classification' 'string' '' 'field1' 'string' '' ]outFile FileRecordStream pathname write True fields fields sequences []for i in range numSequences seq [x for x in range i * elementsPerSeq i + 1 * elementsPerSeq ]sequences.append seq seqIdxs []for i in range numRepeats seqIdxs + range numSequences random.shuffle seqIdxs for seqIdx in seqIdxs seq sequences[seqIdx]for x in seq outFile.appendRecord [str seqIdx str x ] outFile.close
def raises_StopOnError function def call_and_assert *args **kwargs import ckan.lib.navl.dictization_functions as dfnose.tools.assert_raises df.StopOnError function *args **kwargs return call_and_assert
def n2s data if data is None return ''return data
@nottestdef slow_test f f.slow_test Truereturn f
def unsafeSQLIdentificatorNaming name retVal nameif isinstance name basestring if Backend.getIdentifiedDbms in DBMS.MYSQL DBMS.ACCESS retVal name.replace '`' '' elif Backend.getIdentifiedDbms in DBMS.PGSQL DBMS.DB2 retVal name.replace '"' '' elif Backend.getIdentifiedDbms in DBMS.ORACLE retVal name.replace '"' '' .upper elif Backend.getIdentifiedDbms in DBMS.MSSQL retVal name.replace '[' '' .replace ']' '' if Backend.getIdentifiedDbms in DBMS.MSSQL DBMS.SYBASE prefix '%s.' % DEFAULT_MSSQL_SCHEMA if retVal.startswith prefix retVal retVal[len prefix ]return retVal
def filter_products queryset user if user.is_staff return querysetreturn queryset.filter stockrecords__partner__users__pk user.pk .distinct
@login_required@enforce_shopping_cart_enableddef remove_item request item_id request.GET.get 'id' or request.POST.get 'id' or '-1' items OrderItem.objects.filter id item_id status 'cart' .select_subclasses if not len items log.exception u'CannotremovecartOrderItemid %s.DoesNotExistoritemisalreadypurchased' item_id else item items[0]if item.user request.user Order.remove_cart_item_from_order item request.user item.order.update_order_type return HttpResponse 'OK'
@step 'Isendatestemailwiththefollowingset $' def mail_send_yaml step mail_send yaml.load step.multiline
def layer op def layer_decorated self *args **kwargs name kwargs.setdefault 'name' self.get_unique_name op.__name__ if len self.terminals 0 raise RuntimeError 'Noinputvariablesfoundforlayer%s.' % name elif len self.terminals 1 layer_input self.terminals[0]else layer_input list self.terminals layer_output op self layer_input *args **kwargs self.layers[name] layer_outputself.feed layer_output return selfreturn layer_decorated
def length_conditional_mangler length mangler def mangle key if len key > length return mangler key else return keyreturn mangle
def parse_snmp_return ret is_bulk False err True errIndication errStatus errIdx varBinds retif errIndication data errIndicationelif errStatus if is_bulk varBinds varBinds[ -1 ]data '%sat%s' % errStatus.prettyPrint errIdx and varBinds[ int errIdx - 1 ] or '?' else err Falsedata varBindsreturn err data
def test_structs am eo erfa.apci13 2456165.5 [0.401182685 1] assert am.shape 2 assert am.dtype erfa.dt_eraASTROM assert eo.shape 2 np.testing.assert_allclose am[0]['pmt'] 12.651337940273786 np.testing.assert_allclose am[0]['v'] [4.2896388971570276e-05 8.115034002544664e-05 3.5175551225931444e-05] ri di erfa.atciqd 2.71 0.174 am[0] np.testing.assert_allclose ri 2.709994899247599 np.testing.assert_allclose di 0.17287407209836234
def iface_dtype_name obj dynamic_go_type iface_commontype obj if dynamic_go_type is None returnreturn dynamic_go_type['string'].dereference ['str'].string
def queued_task task @functools.wraps task def wrapped *args **kwargs signature task.si *args **kwargs enqueue_task signature return wrapped
def install_numpy_scipy chdir SRC_DIR apt_command 'build-deppython-numpy' apt_command 'build-deppython-scipy' run_command 'pipinstall-d.numpy' run_command 'tarxvzfnumpy*.tar.gz' run_command "sed-i's/returnNone#/pass#/'numpy*/numpy/core/setup.py" run_command 'cdnumpy*&&pythonsetup.pyinstall' run_command 'pipinstallscipy'
def create_context_manager connection return IMPL.create_context_manager connection connection
def slim_exception_data instance frame_allowance settings.SENTRY_MAX_STACKTRACE_FRAMES frames []for exception in instance.values if not exception.stacktrace continueframes.extend exception.stacktrace.frames slim_frame_data frames frame_allowance
def _extend M sym if not sym return M + 1 True else return M False
def validate_busy func *args **kwargs def inner self *args **kwargs target_id Noneif 'target_id' in kwargs and kwargs['target_id'] ! None target_id kwargs['target_id']else target_id 0if self.target_is_busy target_id raise TargetBusyException return func self *args **kwargs return inner
def bdist py make_env 'wheel' run [py 'setup.py' 'bdist_wheel']
def test_scenario_with_inline_comments scenario Scenario.from_string INLINE_COMMENTS step1 step2 scenario.stepsexpect step1.sentence .to.equal u'GivenIamusingananvil' expect step2.sentence .to.equal u'AndIamusingahammer'
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
def format_timestamp timestamp return u'{0 >010x}'.format int timestamp
def make_logs response None if not response response frappe.local.responseif frappe.error_log response[u'exc'] json.dumps [frappe.utils.cstr d for d in frappe.local.error_log] if frappe.local.message_log response[u'_server_messages'] json.dumps [frappe.utils.cstr d for d in frappe.local.message_log] if frappe.debug_log and frappe.conf.get u'logging' or False response[u'_debug_messages'] json.dumps frappe.local.debug_log
def request_cancellation liveaction requester if liveaction.status action_constants.LIVEACTION_STATUS_CANCELING return liveactionif liveaction.status not in action_constants.LIVEACTION_CANCELABLE_STATES raise Exception 'Unabletocancelexecutionbecauseitisalreadyinacompletedstate.' result {'message' 'Actioncanceledbyuser.' 'user' requester}status action_constants.LIVEACTION_STATUS_CANCELING if liveaction.status action_constants.LIVEACTION_STATUS_RUNNING else action_constants.LIVEACTION_STATUS_CANCELED update_status liveaction status result result execution ActionExecution.get liveaction__id str liveaction.id return liveaction execution
def exceptionFromStanza stanza children []condition text textLang appCondition type code Nonefor element in stanza.elements if element.name 'error' and element.uri stanza.uri code element.getAttribute 'code' type element.getAttribute 'type' error _parseError element NS_XMPP_STANZAS condition error['condition']text error['text']textLang error['textLang']appCondition error['appCondition']if not condition and code condition type CODES_TO_CONDITIONS[code]text unicode stanza.error else children.append element if condition is None return StanzaError None exception StanzaError condition type text textLang appCondition exception.children childrenexception.stanza stanzareturn exception
def run_tests argv None defaultTest None topleveldir None xmloutput None verbosity 1 nomultiproc False if xmloutput is not None import xmlrunnerrunner xmlrunner.XMLTestRunner output xmloutput else runner Noneprog NumbaTestProgram argv argv module None defaultTest defaultTest topleveldir topleveldir testRunner runner exit False verbosity verbosity nomultiproc nomultiproc return prog.result
def rewrite_user user if user is None LOG.warn 'Failedtorewriteuser userisNone.' else augment get_user_augmentation_class user for attr in 'get_groups' 'get_home_directory' 'has_hue_permission' setattr user attr getattr augment attr return user
def group_person s3.prep lambda r r.representation 's3json' and r.method 'options' return s3_rest_controller
def getFileUsed output Configuration._readConfigFile USER_CONFIG if output ! {} return USER_CONFIGreturn DEFAULT_CONFIG
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def restore_nesting d separator ' ' d copy.copy d if any [ separator in k for k in d.keys ] else d for k v in d.copy .items if separator in k top rem k.split separator 1 nest d[top] if isinstance d.get top dict else {} nest[rem] vd[top] restore_nesting nest separator del d[k]return d
def replacement_traverse obj opts replace cloned {}stop_on set [id x for x in opts.get 'stop_on' [] ] def clone elem **kw if id elem in stop_on or 'no_replacement_traverse' in elem._annotations return elemelse newelem replace elem if newelem is not None stop_on.add id newelem return newelemelse if elem not in cloned cloned[elem] newelem elem._clone newelem._copy_internals clone clone **kw return cloned[elem]if obj is not None obj clone obj **opts return obj
def generate_theme_images theme header_hash uuid.uuid4 .hexfooter_hash uuid.uuid4 .hexcreate_theme_images theme 'header' header_hash create_theme_images theme 'footer' footer_hash persona theme.personapersona.header header_hashpersona.footer footer_hashpersona.save save_theme header_hash footer_hash theme
def p_file_input_end p p[0] ast.Stmt p[1]
@auth.s3_requires_membership 1 def tropo_channel tablename 'msg_tropo_channel'table s3db[tablename]table.token_messaging.label T 'TropoMessagingToken' table.token_messaging.comment DIV DIV _class 'stickytip' _title '%s|%s' % T 'TropoMessagingToken' T 'Thetokenassociatedwiththisapplicationon' + "<ahref 'https //www.tropo.com/docs/scripting/troposessionapi.htm'target _blank>Tropo.com</a>" s3.crud_strings[tablename] Storage label_create T 'CreateTropoChannel' title_display T 'TropoChannelDetails' title_list T 'TropoChannels' title_update T 'EditTropoChannel' label_list_button T 'ListTropoChannels' label_delete_button T 'DeleteTropoChannel' msg_record_created T 'TropoChanneladded' msg_record_modified T 'TropoChannelupdated' msg_record_deleted T 'TropoChanneldeleted' msg_list_empty T 'NoTropoChannelscurrentlyregistered' return s3_rest_controller
def dist_location dist egg_link egg_link_path dist if egg_link return egg_linkreturn dist.location
def copy_struct dst src repl {} repl repl.copy for k in src._datamodel._fields v repl.pop k getattr src k setattr dst k v for k v in repl.items setattr dst k v return dst
def evalXKCD individual target_price price 0.0times list for item number in individual.items price + ITEMS[item][0] * number times.append ITEMS[item][1] return abs price - target_price max times
def ReadInput data_filepattern shuffle params image_size params['image_size']filenames tf.gfile.Glob data_filepattern filename_queue tf.train.string_input_producer filenames shuffle shuffle reader tf.TFRecordReader _ example reader.read filename_queue feature_sepc {'moving_objs' tf.FixedLenSequenceFeature shape [ image_size * image_size * 3 ] dtype tf.float32 } _ features tf.parse_single_sequence_example example sequence_features feature_sepc moving_objs tf.reshape features['moving_objs'] [params['seq_len'] image_size image_size 3] if shuffle examples tf.train.shuffle_batch [moving_objs] batch_size params['batch_size'] num_threads 64 capacity params['batch_size'] * 100 min_after_dequeue params['batch_size'] * 4 else examples tf.train.batch [moving_objs] batch_size params['batch_size'] num_threads 16 capacity params['batch_size'] examples / params['norm_scale']return examples
def retrieveReject a TpPd pd 3 b MessageType mesType 30 c Cause packet a / b / c return packet
def parse_iso8601 datestring m ISO8601_REGEX.match datestring if not m raise ValueError u'unabletoparsedatestring%r' % datestring groups m.groupdict tz groups[u'timezone']if tz u'Z' tz FixedOffset 0 elif tz m TIMEZONE_REGEX.match tz prefix hours minutes m.groups hours minutes int hours int minutes if prefix u'-' hours - hours minutes - minutes tz FixedOffset minutes + hours * 60 return datetime int groups[u'year'] int groups[u'month'] int groups[u'day'] int groups[u'hour'] or 0 int groups[u'minute'] or 0 int groups[u'second'] or 0 int groups[u'fraction'] or 0 tz
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def autocreate_username candidate tries 1 max_tries settings.MAX_GEN_USERNAME_TRIESfrom olympia.amo.utils import slugify SLUG_OKmake_u partial slugify ok SLUG_OK lower True spaces False delimiter '-' adjusted_u make_u candidate if tries > 1 adjusted_u '%s%s' % adjusted_u tries if DeniedName.blocked adjusted_u or adjusted_u '' or tries > max_tries or len adjusted_u > 255 log.info 'usernameblocked empty maxtriesreached ortoolong;username %s;max %s' % adjusted_u max_tries return autocreate_username uuid.uuid4 .hex[0 15] if UserProfile.objects.filter username adjusted_u .count return autocreate_username candidate tries tries + 1 return adjusted_u
def regions language x a language.lower [] for tag language region iso639 iso3166 in LANGUAGE_REGION.items if iso639 x a.append iso3166 return sorted a key lambda tag tag.lower ! x and tag or ''
def squeeze_axes shape axes skip 'XY' if len shape ! len axes raise ValueError 'dimensionsofaxesandshapedonotmatch' shape axes zip * i for i in zip shape axes if i[0] > 1 or i[1] in skip return tuple shape ''.join axes
def removeUnreferencedElements doc global numElemsRemovednum 0removeTags ['linearGradient' 'radialGradient' 'pattern']identifiedElements findElementsWithId doc.documentElement referencedIDs findReferencedElements doc.documentElement for id in identifiedElements if not id in referencedIDs goner identifiedElements[id]if goner ! None and goner.parentNode ! None and goner.nodeName in removeTags goner.parentNode.removeChild goner num + 1numElemsRemoved + 1defs doc.documentElement.getElementsByTagName 'defs' for aDef in defs elemsToRemove removeUnusedDefs doc aDef for elem in elemsToRemove elem.parentNode.removeChild elem numElemsRemoved + 1num + 1return num
def linear_kernel X Y None X Y check_pairwise_arrays X Y return safe_sparse_dot X Y.T dense_output True
def ServiceManager run utils.run service_manager _service_managers[get_name_of_init run ]global _service_managertry return _service_managerexcept NameError _service_manager service_manager _get_service_command_generator run _get_service_result_parser run return _service_manager
def compute_kkt_optimality g on_bound g_kkt g * on_bound free_set on_bound 0 g_kkt[free_set] np.abs g[free_set] return np.max g_kkt
def predict_true args return True
def interface_get_options port cmd 'ovs-vsctlgetinterface{0}options'.format port result __salt__['cmd.run_all'] cmd retcode result['retcode']stdout result['stdout']return _stdout_list_split retcode stdout
def _bem_inf_pots mri_rr bem_rr mri_Q None diff bem_rr.T[np.newaxis ] - mri_rr[ np.newaxis] diff_norm np.sum diff * diff axis 1 diff_norm * np.sqrt diff_norm diff_norm[ diff_norm 0 ] 1if mri_Q is None return diff / diff_norm[ np.newaxis ] else return np.einsum 'ijk mj->imk' diff mri_Q / diff_norm[ np.newaxis ]
def rayleigh2waist z_r wavelen z_r wavelen map sympify z_r wavelen return sqrt z_r / pi * wavelen
def convert_markdown markdown_source extensions None extension_configs None md markdown.Markdown extensions extensions or [] extension_configs extension_configs or {} html_content md.convert markdown_source meta getattr md u'Meta' {} toc_html getattr md u'toc' u'' table_of_contents toc.TableOfContents toc_html return html_content table_of_contents meta
def _init_nt g {}g['LIBDEST'] get_python_lib plat_specific 0 standard_lib 1 g['BINLIBDEST'] get_python_lib plat_specific 1 standard_lib 1 g['INCLUDEPY'] get_python_inc plat_specific 0 g['SO'] '.pyd'g['EXE'] '.exe'g['VERSION'] get_python_version .replace '.' '' g['BINDIR'] os.path.dirname os.path.abspath sys.executable global _config_vars_config_vars g
def semaphorereset semaphore originalstate for i in range originalstate semaphore.acquire for i in range originalstate semaphore.release
def get_chr_template stream chrs num_chrs reduce lambda x y x + y[0] chrs 0 stream.write '//Numberofindependent unlinked chromosomes and"chromosomestructure"flag 0foridenticalstructureacrosschromosomes and1fordifferentstructuresondifferentchromosomes.\n' if len chrs > 1 or num_chrs 1 stream.write str num_chrs + '1\n' else stream.write str num_chrs + '0\n' for chr in chrs repeats chr[0]loci chr[1]if len chrs 1 _gen_loci stream loci else for i in range repeats _gen_loci stream loci
def test_against_jpl_horizons obstime Time u'1998-07-2803 00' location EarthLocation lon Angle u'248.405300d' lat Angle u'31.9585d' height 2.06 * u.km altaz_frame AltAz obstime obstime location location altaz SkyCoord u'143.2970d2.6223d' frame altaz_frame radec_actual altaz.transform_to u'icrs' radec_expected SkyCoord u'19h24m55.01s-40d56m28.9s' frame u'icrs' distance radec_actual.separation radec_expected .to u'arcsec' assert distance < 1 * u.arcsec
def demean x axis 0 return detrend_mean x axis axis
def s_word value endian '<' format 'binary' signed False full_range False fuzzable True name None word primitives.word value endian format signed full_range fuzzable name blocks.CURRENT.push word
def test_mult_div dt_small 6 * dt_tiny dt_big TimeDelta 20000.0 format 'jd' dt_big_small_by_6 dt_big + dt_small / 6.0 dt_frac dt_big_small_by_6 - TimeDelta 3333.0 format 'jd' assert allclose_jd2 dt_frac.jd2 0.33333333333333354
def _get_default_column_value column_type type_schema {'datetime' None 'big_integer' 0 'integer' 0 'string' ''}if isinstance column_type sa_sql.type_api.Variant return _get_default_column_value column_type.impl return type_schema[column_type.__visit_name__]
def getTransformedFillOutline elementNode loop yAxisPointingUpward fillOutlineLoops Noneif getStyleValue 'none' elementNode 'fill' .lower 'none' fillOutlineLoops intercircle.getAroundsFromLoop loop getStrokeRadius elementNode else fillOutlineLoops [loop]return getChainMatrixSVGIfNecessary elementNode yAxisPointingUpward .getTransformedPaths fillOutlineLoops
def __flatten_into root prefix target for name value in root.items key prefix + name if isinstance value dict __flatten_into value key + '.' target else target[key] value
def add_time_interval base_time interval textparser parsedatetime.Calendar if interval.strip .isdigit interval + 'days'tzinfo base_time.tzinfo or pytz.UTC return textparser.parseDT interval base_time tzinfo tzinfo [0]
def RetrieveCachedStats return memcache.get KINDS_AND_SIZES_VAR namespace MEMCACHE_NAMESPACE
def user_to_uid user if user is None user salt.utils.get_user try if isinstance user int return userreturn pwd.getpwnam user .pw_uidexcept KeyError return ''
def snapshot_create request conf request.bodyif isinstance conf basestring config json.loads conf snapshot MapSnapshot.objects.create config clean_config conf map Map.objects.get id config['id'] return HttpResponse num_encode snapshot.id content_type 'text/plain' else return HttpResponse 'InvalidJSON' content_type 'text/plain' status 500
def xkcd_info xkcd_id url False request requests.get 'http //www.xkcd.com/' + xkcd_id + '/info.0.json' data request.json date '{}{}{}'.format data['day'] months[int data['month'] ] data['year'] if url url '|http //xkcd.com/' + xkcd_id.replace '/' '' return 'xkcd \x02{}\x02 {} {}'.format data['title'] date url if url else ''
def optimal_data_chunks data minimum 4 data to_bytestring data re_repeat six.b '{' + six.text_type minimum .encode 'ascii' + six.b ' }' num_pattern re.compile six.b '\\d' + re_repeat num_bits _optimal_split data num_pattern alpha_pattern re.compile six.b '[' + re.escape ALPHA_NUM + six.b ']' + re_repeat for is_num chunk in num_bits if is_num yield QRData chunk mode MODE_NUMBER check_data False else for is_alpha sub_chunk in _optimal_split chunk alpha_pattern if is_alpha mode MODE_ALPHA_NUMelse mode MODE_8BIT_BYTE yield QRData sub_chunk mode mode check_data False
def guess method if hasattr method '_api' return method args vname kwname defaults getargspec method names tuple args + None * 4 if names[0] 'self' if names[1] in 'cr' 'cursor' if names[2] in 'uid' 'user' if names[3] 'ids' if 'context' in names or kwname return cr_uid_ids_context method else return cr_uid_ids method elif names[3] 'id' or names[3] 'res_id' if 'context' in names or kwname return cr_uid_id_context method else return cr_uid_id method elif 'context' in names or kwname return cr_uid_context method else return cr_uid method elif 'context' in names return cr_context method else return cr method return noguess method
def restore_required_config_elements config renewalparams required_items itertools.chain six.moves.zip BOOL_CONFIG_ITEMS itertools.repeat _restore_bool six.moves.zip INT_CONFIG_ITEMS itertools.repeat _restore_int six.moves.zip STR_CONFIG_ITEMS itertools.repeat _restore_str for item_name restore_func in required_items if item_name in renewalparams and not cli.set_by_cli item_name value restore_func item_name renewalparams[item_name] setattr config.namespace item_name value
def _parse_course_id_from_string input_str m_obj re.match '^/courses/{}'.format settings.COURSE_ID_PATTERN input_str if m_obj return CourseKey.from_string m_obj.group 'course_id' return None
def run_script_usage_tests test_data_dir scripts_dir working_dir verbose False tests None force_overwrite False timeout 60 working_dir join working_dir 'script_usage_tests' logger Noneif verbose logger sys.stdoutscript_tester ScriptTester logger logger script_tester scripts_dir test_data_dir working_dir scripts tests timeout timeout force_overwrite force_overwrite result_summary script_tester.result_summary has_failures_or_errors script_tester.has_failures_or_errors if exists working_dir rmtree working_dir return result_summary has_failures_or_errors
def _code_to_file co return BytesIO imp.get_magic + '\x00\x00\x00\x00' + marshal.dumps co
def get_partitions diskpath dev parted.getDevice diskpath disk parted.newDisk dev partitions []for part in disk.partitions _ _ pname part.path.rsplit '/' partitions.append {'name' pname 'size' part.getLength * dev.sectorSize } return partitions
def fixSizePolicy size hint policy width height hint.width hint.height expanding policy.expandingDirections hpolicy vpolicy policy.horizontalPolicy policy.verticalPolicy if expanding & Qt.Horizontal width max width size.width if hpolicy QSizePolicy.Maximum width min width size.width if expanding & Qt.Vertical height max height size.height if vpolicy QSizePolicy.Maximum height min height hint.height return QSize width height .boundedTo size
def BgzfBlocks handle data_start 0while True start_offset handle.tell block_length data _load_bgzf_block handle data_len len data yield start_offset block_length data_start data_len data_start + data_len
def _convert_nn_fr val if val < 20 return to_19_fr[val]for dcap dval in k 20 + 10 * v for v k in enumerate tens_fr if dval + 10 > val if val % 10 return dcap + '-' + to_19_fr[ val % 10 ] return dcap
def get_mod_name path base rel_path os.path.relpath path base rel_path ign os.path.splitext rel_path file_module '' h t os.path.split rel_path while h or t if t file_module t + '.' + file_module h t os.path.split h return file_module[ -1 ]
def CreateExtensionSetting client feed_items campaign_feed feed_item_ids platform_restrictions None campaign_extension_setting_service client.GetService 'CampaignExtensionSettingService' 'v201609' extension_feed_items [{CreateSitelinkFeedItem feed_items feed_item_id } for feed_item_id in feed_item_ids]extension_setting {'extensions' extension_feed_items}if platform_restrictions extension_setting['platformRestrictions'] platform_restrictionscampaign_extension_setting {'campaignId' campaign_feed['campaignId'] 'extensionType' 'SITELINK' 'extensionSetting' extension_setting}operation {'operand' campaign_extension_setting 'operator' 'ADD'}campaign_extension_setting_service.mutate [operation]
def tprob t df tails 'high' if tails 'two-sided' if t > 0 return 2 * 1.0 - tdist.cdf t df else return 2 * tdist.cdf t df elif tails 'high' return 1 - tdist.cdf t df elif tails 'low' return tdist.cdf t df else raise ValueError 'Unknowndirection.'
def serverdir path join ROOT_DIR 'server' path normpath path if sys.platform 'cygwin' path realpath path return path
def bidirectional_shortest_path G source target if source not in G or target not in G msg 'Eithersource{}ortarget{}isnotinG'raise nx.NodeNotFound msg.format source target results _bidirectional_pred_succ G source target pred succ w resultspath []while w is not None path.append w w pred[w]path.reverse w succ[path[ -1 ]]while w is not None path.append w w succ[w]return path
def restart_local drain False if _TRAFFICCTL cmd _traffic_ctl 'server' 'restart' '--manager' else cmd _traffic_line '-L' if drain cmd '{0}{1}'.format cmd '--drain' log.debug 'Running %s' cmd return _subprocess cmd
def multiblock_lbp int_image r c width height int_image np.ascontiguousarray int_image dtype np.float32 lbp_code _multiblock_lbp int_image r c width height return lbp_code
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def _include_file context uri calling_uri **kwargs template _lookup_template context uri calling_uri callable_ ctx _populate_self_namespace context._clean_inheritance_tokens template callable_ ctx **_kwargs_for_include callable_ context._data **kwargs
def test_is_repo_url_for_local_urls local_repo_url assert is_repo_url local_repo_url is False
def _get_arg_tokens cli arg cli.input_processor.argreturn [ Token.Prompt.Arg u' arg ' Token.Prompt.Arg.Text str arg Token.Prompt.Arg u' ' ]
def tokenwrap tokens separator '' width 70 return '\n'.join textwrap.wrap separator.join tokens width width
def trimLens lens minLen index 0for i in range len lens if lens[i] < minLen index + 1else breakreturn lens[index len lens ]
def generate_accepted_kwargs function *named_arguments if hasattr function '__code__' and takes_kwargs function function_takes_kwargs Truefunction_takes_arguments []else function_takes_kwargs Falsefunction_takes_arguments takes_arguments function *named_arguments def accepted_kwargs kwargs if function_takes_kwargs return kwargselif function_takes_arguments return {key value for key value in kwargs.items if key in function_takes_arguments }else return {}return accepted_kwargs
def add_atomic_group name max_number_of_machines None description None return models.AtomicGroup.add_object name name max_number_of_machines max_number_of_machines description description .id
def claModelControlEnableTPLearningCb claModel assert isinstance claModel CLAModel claModel._getTPRegion .setParameter 'learningMode' True return
def _determinism_check objects u'mhi' format u'pdf' usetex False plots []for i in range 3 result check_output [sys.executable u'-R' u'-c' u'importmatplotlib;matplotlib._called_from_pytest True;matplotlib.use %r ;frommatplotlib.testing.determinismimport_determinism_save;_determinism_save %r %r %r ' % format objects format usetex ] plots.append result for p in plots[1 ] if usetex if p ! plots[0] pytest.skip u'failed maybeduetoghostscripttimestamps' else assert p plots[0]
@with_setup step_runner_environ def test_scenarios_inherit_feature_tags feature Feature.from_string FEATURE10 scenarios_ran []@after.each_scenariodef just_register scenario scenarios_ran.append scenario.name result feature.run tags ['tag'] assert result.scenario_resultsassert_equals scenarios_ran ['1stone' '2ndone']
def top_down_once rule fns basic_fns return do_one rule lambda expr sall top_down rule fns fns expr
def communicate command None if command is not None logger.info 'DEBUG sendingcommand%s' % command pipe_in.write command result []while True data pipe_out.read if data is None breakresult.append data logger.info 'DEBUG result%s' % repr result return ''.join result
def _connect_socket host port start time.time while True try return _try_connect host port except sc_exceptions.SocketConnectionRefused if time.time - start > constants.SOCKET_CONNECT_TIMEOUT raise sc_exceptions.ConnectionTimeoutException host host port port
def power_state vm state force power_status vm.get_status check_status ''.join state.split '_' .upper if not force and power_status in ['SUSPENDED' 'POWERINGON' 'RESETTING' 'BLOCKEDONMSG'] return 'VMisin%spowerstate.Forceisrequired!' % power_status if power_status check_status return Falseelse try if state 'powered_off' vm.power_off sync_run True elif state 'powered_on' vm.power_on sync_run True elif state 'restarted' if power_status in 'POWEREDON' 'POWERINGON' 'RESETTING' vm.reset sync_run False else return 'CannotrestartVMinthecurrentstate%s' % power_status return Trueexcept Exception return get_exception return False
def add_or_update_given_trace_context trace_context action_executions None rules None trigger_instances None trace_db get_trace trace_context trace_context ignore_trace_tag True if not trace_db trace_context _get_valid_trace_context trace_context trace_db TraceDB trace_tag trace_context.trace_tag return add_or_update_given_trace_db trace_db trace_db action_executions action_executions rules rules trigger_instances trigger_instances
def _get_comment_callback comment_data thread_id parent_id def callback request _uri headers '\nSimulatethecommentcreationorupdateendpointasdescribedabove.\n'response_data make_minimal_cs_comment comment_data response_data['thread_id'] thread_idresponse_data['parent_id'] parent_idfor key val_list in request.parsed_body.items val val_list[0]if key in ['anonymous' 'anonymous_to_peers' 'endorsed'] response_data[key] val 'True' else response_data[key] valreturn 200 headers json.dumps response_data return callback
def webpack_asset path asset_paths asset_paths debug settings.DEBUG_MODE if not asset_paths logger.warn 'webpack-assets.jsonhasnotyetbeengenerated.Fallingbacktonon-cache-bustedassets' return pathif not debug key path.replace base_static_path '' .replace '.js' '' hash_path asset_paths[key]return os.path.join base_static_path hash_path else return path
def discard p global freelistx referents[p]referents[p] freelistfreelist preturn x
def create_work_name name strip_ext ['.nzb' '.par' '.par2']name name.strip if name.find ' //' < 0 name_base ext os.path.splitext name while ext.lower in strip_ext name name_base name_base ext os.path.splitext name return name.strip else return name.strip
def get_print_format_doc print_format_name meta if not print_format_name print_format_name frappe.form_dict.format or meta.default_print_format or u'Standard' if print_format_name u'Standard' return Noneelse try return frappe.get_doc u'PrintFormat' print_format_name except frappe.DoesNotExistError return None
def os_release_info return _distro.os_release_info
def verify_webhook signature body public_key __utils__['http.query'] 'https //api.travis-ci.org/config' ['config']['notifications']['webhook']['public_key']pkey_public_key OpenSSL.crypto.load_publickey OpenSSL.crypto.FILETYPE_PEM public_key certificate OpenSSL.crypto.X509 certificate.set_pubkey pkey_public_key signature base64.b64decode signature payload json.loads parse_qs body ['payload'][0] try OpenSSL.crypto.verify certificate signature payload str 'sha1' except OpenSSL.crypto.Error return Falsereturn True
def interactive_open targets command assert commandtry args shlex_split command except ValueError args [command]args.insert 0 args[0] args + targetsreturn os.execlp *args
def str2regexp string if string.startswith '/' string string.split '/' 2 [1 ]if len string 1 string.append '' string re.compile string[0] sum getattr re f.upper for f in string[1] return string
def get_current_connection return _connection_stack.top
def _makeHeaderUnix sig V2_SIGNATURE verCom '!' famProto '1' addrLength '\x00\xd8' addrs '/home/tests/mysockets/sock' + '\x00' * 82 * 2 return sig + verCom + famProto + addrLength + addrs
def out_format data out opts None **kwargs return try_printout data out opts **kwargs
def split_first s delims min_idx Nonemin_delim Nonefor d in delims idx s.find d if idx < 0 continueif min_idx is None or idx < min_idx min_idx idxmin_delim dif min_idx is None or min_idx < 0 return s '' None return s[ min_idx] s[ min_idx + 1 ] min_delim
def translate_urls json_home new_prefix for dummy_rel resource in json_home['resources'].items if 'href' in resource resource['href'] new_prefix + resource['href'] elif 'href-template' in resource resource['href-template'] new_prefix + resource['href-template']
def WMA ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.WMA timeperiod
def handle_add_var request basket product_id quantity 1 **kwargs vars dict int k.split u'_' [ -1 ] int v for k v in six.iteritems kwargs if k.startswith u'var_' var_product ProductVariationResult.resolve product_id combination vars if not var_product raise ValidationError _ u'Thisvariationisnotavailable.' code u'invalid_variation_combination' return handle_add request request basket basket product_id var_product.pk quantity quantity
def raise_cmdexc_if_invalid url if not url.isValid raise cmdexc.CommandError get_errstring url
def prepare_commentdoc s result []lines [line.strip for line in s.expandtabs .splitlines ]for line in lines if line.startswith '# ' line line[2 ]if line and line[0] '' line line[1 ]result.append line if result and result[ -1 ] result.append '' return result
def _unicode_to_mbcs instr if isinstance instr six.text_type return instr.encode u'mbcs' else return instr
def radius G e None if e is None e eccentricity G return min e.values
def _capabilities conn __get_conn caps conn.getCapabilities caps minidom.parseString caps return caps
def get_thread_cpu thread cmd 'ps-ocpuid lwp-eL|grep-w%s$' % thread cpu_thread system_output cmd if not cpu_thread return []return list set [_.strip .split [0] for _ in cpu_thread.splitlines ]
def classProvides *interfaces frame sys._getframe 1 locals frame.f_localsif locals is frame.f_globals or '__module__' not in locals raise TypeError 'classProvidescanbeusedonlyfromaclassdefinition.' if '__provides__' in locals raise TypeError 'classProvidescanonlybeusedonceinaclassdefinition.' locals['__provides__'] _normalizeargs interfaces addClassAdvisor _classProvides_advice depth 2
def _get_bbox_regression_labels bbox_target_data num_classes clss bbox_target_data[ 0]bbox_targets np.zeros clss.size 4 * num_classes dtype np.float32 bbox_loss_weights np.zeros bbox_targets.shape dtype np.float32 inds np.where clss > 0 [0]for ind in inds cls clss[ind]start 4 * cls end start + 4 bbox_targets[ind start end] bbox_target_data[ind 1 ]bbox_loss_weights[ind start end] [1.0 1.0 1.0 1.0]return bbox_targets bbox_loss_weights
def atanh x np import_module 'numpy' if isinstance x int float if abs x > 1 return interval - np.inf np.inf is_valid False else return interval np.arctanh x elif isinstance x interval if x.is_valid is False or x.start > 1 or x.end < -1 return interval - np.inf np.inf is_valid False elif x.start < -1 or x.end > 1 return interval - np.inf np.inf is_valid None else start np.arctanh x.start end np.arctanh x.end return interval start end is_valid x.is_valid else return NotImplementedError
def p_selection_statement_3 t pass
def port_add br port may_exist False param_may_exist _param_may_exist may_exist cmd 'ovs-vsctl{2}add-port{0}{1}'.format br port param_may_exist result __salt__['cmd.run_all'] cmd retcode result['retcode']return _retcode_to_bool retcode
def set_language_data_from_request request if 'default_language' not in request.session request.session['default_language'] select_best_available_language getattr request.session.get 'facility_user' 'default_language' None or get_default_language cur_lang request.GET.get 'lang' or request.session.get 'default_language' set_request_language request lang_code cur_lang
def _generate_meas_id id_ dict id_['version'] FIFF.FIFFC_VERSIONid_['machid'] get_machid id_['secs'] id_['usecs'] _date_now return id_
def remove_chars string repl if type string str return string.translate maketrans '' '' repl elif type string unicode return string.translate dict [ ord s None for s in repl]
def singleitem attr None doc '' def getter self if len self._items > 1 raise ValueError 'MorethanoneHSPFragmentobjectsfoundinHSP' if attr is None return self._items[0]return getattr self._items[0] attr return property fget getter doc doc
def _get_cleaned_headers headers cleaned_headers []for header in headers sanitized sub '^\\d+' '' sub '[\\W_]' '' header.lower if len sanitized > 0 cleaned_headers.append sanitized else raise GoogleSpreadsheetError "Encounteredaheader'%s'thatwaseitherblankorconsistedonlyofspecialcharacters.CouldnotmaptheheadertotheinternalrepresentationusedbytheGoogleSpreadsheet.Pleasechangetheheadertoconsistofatleastonealphanumericcharacter." % header header_count defaultdict int results []for header cleaned_header in zip headers cleaned_headers new_header cleaned_headerif header_count[cleaned_header] > 0 new_header '%s_%d' % cleaned_header header_count[cleaned_header] + 1 header_count[cleaned_header] + 1results.append new_header return results
def validate_file_path path _validate_path path if not _CS_FULLPATH_REGEX.match path raise ValueError 'Pathshouldhaveformat/bucket/filenamebutgot%s' % path
def empty_queues global __INITIALIZED__return not __INITIALIZED__ or PostProcessor.do.empty and NzbQueue.do.is_empty
def _parse_progress_from_job_tracker html_bytes start html_bytes.rfind 'RunningJobs' if start -1 return None None end html_bytes.find 'Jobs' start + len 'RunningJobs' if end -1 end Nonehtml_bytes html_bytes[start end]matches _JOB_TRACKER_HTML_RE.findall html_bytes if len matches > 2 return float matches[0] float matches[1] else return None None
def p_declaration_specifiers_2 t pass
def close_serial_port *args DEVICE.zb.serial.close
def _buildLikelihoodTrainingSet numOnes 5 relativeFrequencies None numPatterns 7p _getSimplePatterns numOnes numPatterns s1 [p[0] p[1] p[2] p[3] p[4]]s2 [p[0] p[1] p[2] p[3] p[5]]s3 [p[0] p[1] p[2] p[3] p[6]]trainingSequences [s1 s2 s3]allPatterns preturn trainingSequences relativeFrequencies allPatterns
def _decode_utf8 s return unicode s 'utf-8'
def block_device_mapping_get_all_by_instance_uuids context instance_uuids return IMPL.block_device_mapping_get_all_by_instance_uuids context instance_uuids
def create_mig gce params changed Falsereturn_data []actions_filter ['CREATING']mig gce.ex_create_instancegroupmanager name params['name'] size params['size'] template params['template'] zone params['zone'] if mig changed Truereturn_data _get_instance_list mig filter_list actions_filter return changed return_data
def datetimeformat dt fmt None relative False fmt fmt or '%b%d %Y%I %M%p' if relative time_difference _relative_timestamp dt if time_difference return '{}ago'.format time_difference return dt.strftime fmt
def sigterm_handler signum frame logger.info u'GotSIGTERMsignal.Exiting...' exit_process
def InterruptibleSleep sleep_time slept 0.0epsilon 0.0001thread threading.currentThread while slept < sleep_time - epsilon remaining sleep_time - slept this_sleep_time min remaining 0.25 time.sleep this_sleep_time slept + this_sleep_timeif thread.exit_flag return
def reload_ name cmd ['service' name 'reload']return not __salt__['cmd.retcode'] cmd python_shell False
def has_module module modnames {'numpy' numpy 'Cython' Cython 'f2py' f2py}if modnames[module] if module 'f2py' and not f2pyworks skip "Couldn'trunf2py." return Trueskip "Couldn'timport%s." % module
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def cholesky_solve matlist variable constant K new_matlist copy.deepcopy matlist nrow len new_matlist L Lstar cholesky new_matlist K y [[i] for i in symbols 'y %i' % nrow ]forward_substitution L y constant K backward_substitution Lstar variable y K return variable
def _set_random_states estimator random_state None random_state check_random_state random_state to_set {}for key in sorted estimator.get_params deep True if key 'random_state' or key.endswith '__random_state' to_set[key] random_state.randint MAX_RAND_SEED if to_set estimator.set_params **to_set
def make_decorator func def decorate newfunc if hasattr func 'compat_func_name' name func.compat_func_nameelse name func.__name__newfunc.__dict__ func.__dict__newfunc.__doc__ func.__doc__newfunc.__module__ func.__module__if not hasattr newfunc 'compat_co_firstlineno' newfunc.compat_co_firstlineno func.func_code.co_firstlinenotry newfunc.__name__ nameexcept TypeError newfunc.compat_func_name namereturn newfuncreturn decorate
def _fread3 fobj b1 b2 b3 np.fromfile fobj '>u1' 3 return b1 << 16 + b2 << 8 + b3
def remove_blanks elem out list for child in elem remove_blanks child if child.text or len child > 0 out.append child elem[ ] out
def tops opts if 'master_tops' not in opts return {}whitelist list opts['master_tops'].keys ret LazyLoader _module_dirs opts 'tops' 'top' opts tag 'top' whitelist whitelist return FilterDictWrapper ret '.top'
def render s context None if context is None context {}t get_env .from_string s return t.render context
def check_write repo try repo_testfile '.repo_test_file'repo_run_command repo 'touch%s' % repo_testfile .stdout.strip repo_run_command repo 'rm' + repo_testfile except error.CmdError raise error.RepoWriteError 'Unabletowriteto' + repo
def p_tokenid p p[0] p[1]
def posterize image bits lut []mask ~ 2 ** 8 - bits - 1 for i in range 256 lut.append i & mask return _lut image lut
def with_addon allow_missing False def wrapper fn @functools.wraps fn def inner view request **kwargs guid kwargs.get 'guid' None try if guid is None raise Addon.DoesNotExist 'NoGUID' addon Addon.unfiltered.get guid guid except Addon.DoesNotExist if allow_missing addon Noneelse return Response {'error' _ 'Couldnotfindadd-onwithid"{}".' .format guid } status status.HTTP_404_NOT_FOUND has_perm addon is None or addon.has_author request.user or request.method 'GET' and acl.action_allowed_user request.user 'Addons' 'Edit' if has_perm return fn view request addon addon **kwargs else return Response {'error' _ 'Youdonotownthisaddon.' } status status.HTTP_403_FORBIDDEN return innerreturn wrapper
def run_after_loading view func def run if view.is_loading sublime.set_timeout run 10 else sublime.set_timeout func 10 run
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@magic_arguments @kwds argument_default argparse.SUPPRESS @argument '-f' '--foo' help 'anargument' def magic_foo4 self args return parse_argstring magic_foo4 args
def sphinx_extension app exception if not app.builder.name in 'html' 'dirhtml' returnif not app.config.sphinx_to_github if app.config.sphinx_to_github_verbose stdout 'Sphinx-to-github Disabled doingnothing.' returnif exception if app.config.sphinx_to_github_verbose stdout 'Sphinx-to-github Exceptionraisedinmainbuild doingnothing.' returndir_helper DirHelper os.path.isdir os.listdir os.walk shutil.rmtree file_helper FileSystemHelper lambda f mode codecs.open f mode app.config.sphinx_to_github_encoding os.path.join shutil.move os.path.exists operations_factory OperationsFactory handler_factory HandlerFactory layout_factory LayoutFactory operations_factory handler_factory file_helper dir_helper app.config.sphinx_to_github_verbose sys.stdout force True layout layout_factory.create_layout app.outdir layout.process
def get_power_types power_types []power_template re.compile 'fence_ .* ' fence_files glob.glob '/usr/sbin/fence_*' + glob.glob '/sbin/fence_*' for x in fence_files templated_x power_template.search x .group 1 if templated_x not in power_types power_types.append templated_x power_types.sort return power_types
def _sympy_to_scalar e if isinstance e Expr if e.is_Integer return int e elif e.is_Float return float e elif e.is_Rational return float e elif e.is_Number or e.is_NumberSymbol or e I return complex e raise TypeError 'Expectednumber got %r' % e
def npm_check npm_missing "\nnpmpackagesdonotappeartobeinstalled.\nPleasenavigatetothebokehjsdirectoryandtype'npminstall'\n\n"if not path.exists '../bokehjs/node_modules' print red npm_missing
def test_mne_analyze_colormap assert_raises ValueError mne_analyze_colormap [0] assert_raises ValueError mne_analyze_colormap [ -1 1 2] assert_raises ValueError mne_analyze_colormap [0 2 1]
def GetEnabledInterfaces interfaces []show_args ['/c' 'netsh' 'show' 'interface']res client_utils_common.Execute 'cmd' show_args time_limit -1 bypass_whitelist True pattern re.compile '\\s*' for line in res[0].split '\r\n' interface_info pattern.split line if 'Enabled' in interface_info interfaces.extend interface_info[ -1 ] return interfaces
def jsonrpc_client_call url method *args **kwargs _urllib kwargs.pop '_urllib' urllib if args and kwargs raise ValueError 'Pass*argsor**kwargsbutnotbothtojsonrpc_client_call' req {'jsonrpc' '2.0' 'method' method 'params' args or kwargs 'id' 1}res json.loads _urllib.urlopen url json.dumps req .read if 'result' in res return res['result']elif 'error' in res er res['error']raise JsonRpcError er['code'] er['message'] er['data'] else msg "JSON-RPCresponsemustcontain'result'or'error' %s" % res raise ValueError msg
@newrelic.agent.function_trace def make_course_settings course user obj {'is_cohorted' is_course_cohorted course.id 'allow_anonymous' course.allow_anonymous 'allow_anonymous_to_peers' course.allow_anonymous_to_peers 'cohorts' [{'id' str g.id 'name' g.name} for g in get_course_cohorts course ] 'category_map' utils.get_discussion_category_map course user }return obj
def calendar_hierarchy_units hierarchy units []for level in hierarchy.levels role level.role or level.name if role in _CALENDAR_UNITS units.append role else raise ArgumentError "Unknowntimerole'%s'forlevel'%s'" % role str level return units
def n_colors lowcolor highcolor n_colors diff_0 float highcolor[0] - lowcolor[0] incr_0 diff_0 / n_colors - 1 diff_1 float highcolor[1] - lowcolor[1] incr_1 diff_1 / n_colors - 1 diff_2 float highcolor[2] - lowcolor[2] incr_2 diff_2 / n_colors - 1 color_tuples []for index in range n_colors new_tuple lowcolor[0] + index * incr_0 lowcolor[1] + index * incr_1 lowcolor[2] + index * incr_2 color_tuples.append new_tuple return color_tuples
def is_same_transform matrix0 matrix1 matrix0 numpy.array matrix0 dtype numpy.float64 copy True matrix0 / matrix0[ 3 3 ]matrix1 numpy.array matrix1 dtype numpy.float64 copy True matrix1 / matrix1[ 3 3 ]return numpy.allclose matrix0 matrix1
def connect_route53domains aws_access_key_id None aws_secret_access_key None **kwargs from boto.route53.domains.layer1 import Route53DomainsConnectionreturn Route53DomainsConnection aws_access_key_id aws_access_key_id aws_secret_access_key aws_secret_access_key **kwargs
def dot_shape_from_shape x y if isinstance x LinearTransform if type y ! tuple raise TypeError 'yshouldbetuple' y return x.col_shape + x.split_right_shape y False [1] elif isinstance y LinearTransform if type x ! tuple raise TypeError 'xshouldbetuple' x return y.split_left_shape x False [0] + y.row_shape else raise TypeError 'OneofxoryshouldbeaLinearTransform'
@endpoint u'/ajax/library-info' postprocess json def library_info ctx rd library_map default_library ctx.library_info rd return {u'library_map' library_map u'default_library' default_library}
def download_setuptools version DEFAULT_VERSION download_base DEFAULT_URL to_dir os.curdir delay 15 downloader_factory get_best_downloader to_dir os.path.abspath to_dir tgz_name 'setuptools-%s.tar.gz' % version url download_base + tgz_name saveto os.path.join to_dir tgz_name if not os.path.exists saveto log.warn 'Downloading%s' url downloader downloader_factory downloader url saveto return os.path.realpath saveto
def split_by_position linked_promotions context for linked_promotion in linked_promotions promotion linked_promotion.content_objectif not promotion continuekey 'promotions_%s' % linked_promotion.position.lower if key not in context context[key] []context[key].append promotion
def no_log_warn logical_line if logical_line.startswith 'LOG.warn ' yield 0 'Heat301UseLOG.warning ratherthanLOG.warn '
def gen_test func None timeout None if timeout is None timeout get_async_test_timeout def wrap f f gen.coroutine f @functools.wraps f def wrapper self return self.io_loop.run_sync functools.partial f self timeout timeout return wrapperif func is not None return wrap func else return wrap
def absolute self return Absolute self
def _parse url defaultPort None url url.strip parsed http.urlparse url scheme parsed[0]path urlunparse '' '' + parsed[2 ] if defaultPort is None if scheme 'https' defaultPort 443else defaultPort 80 host port parsed[1] defaultPort if ' ' in host host port host.split ' ' try port int port except ValueError port defaultPortif path '' path '/'return scheme host port path
def _microseconds_from_datetime value if not value.tzinfo value value.replace tzinfo UTC value value.astimezone UTC return int calendar.timegm value.timetuple * 1000000.0 + value.microsecond
def matroska_date_to_datetime date format re.split u' [- .] ' u'%Y-%m-%d%H %M %S.%f' while format try return datetime.strptime date u''.join format except ValueError format format[ -2 ]return date
def _is_package path return os.path.isdir path and os.path.exists os.path.join path '__init__.py'
def test_doc_api_merge_children en_tokenizer text u'WKROplayedsongsbythebeachboysallnight'doc en_tokenizer text assert len doc 9 doc.merge doc[4].idx doc[6].idx + len doc[6] u'NAMED' u'LEMMA' u'TYPE' for word in doc if word.i < word.head.i assert word in list word.head.lefts elif word.i > word.head.i assert word in list word.head.rights
def clear_search_index search_services.clear_index SEARCH_INDEX_EXPLORATIONS
def _get_request_value request value_name default '' if request is not None and hasattr request 'GET' and value_name in request.GET return request.GET[value_name]elif request is not None and hasattr request 'POST' and value_name in request.POST return request.POST[value_name]else return default
def ref_sort_key ref return len ref ref
def ones shape dtype None if not isinstance shape list tuple TensorVariable shape [shape]if dtype is None dtype config.floatXreturn alloc numpy.array 1 dtype dtype *shape
def GetPreviousNonBlankLine clean_lines linenum prevlinenum linenum - 1 while prevlinenum > 0 prevline clean_lines.elided[prevlinenum]if not IsBlankLine prevline return prevline prevlinenum prevlinenum - 1return '' -1
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u''.join choice chars for x in range length
def _set_attributes_clean test data test_type {'client' 1 'server' 2}test_time {'short' 1 'medium' 2 'long' 3}test.test_type test_type[data.test_type.lower ]test.test_time test_time[data.time.lower ]string_attributes 'name' 'author' 'test_class' 'test_category' 'test_category' 'sync_count' for attribute in string_attributes setattr test attribute getattr data attribute test.description data.doctest.dependencies ' '.join data.dependencies int_attributes 'experimental' 'run_verify' for attribute in int_attributes setattr test attribute int getattr data attribute
def _retry_instance_update exception_checker lambda exc isinstance exc exception.UnknownInstanceUpdateConflict return oslo_db_api.wrap_db_retry max_retries 5 retry_on_deadlock True exception_checker exception_checker
def _ico_downsample surf dest_grade n_tri surf['ntri']found -1 bad_msg 'Asurfacewith%dtrianglescannotbeisomorphicwithasubdividedicosahedron.' % surf['ntri'] if n_tri % 20 ! 0 raise RuntimeError bad_msg n_tri n_tri // 20 found int round np.log n_tri / np.log 4 if n_tri ! 4 ** found raise RuntimeError bad_msg del n_triif dest_grade > found raise RuntimeError 'Forthissurface decimationgradeshouldbe%dorless not%s.' % found dest_grade source _get_ico_surface found dest _get_ico_surface dest_grade patch_stats True del dest['tri_cent']del dest['tri_nn']del dest['neighbor_tri']del dest['tri_area']if not np.array_equal source['tris'] surf['tris'] raise RuntimeError 'Thesourcesurfacehasamatchingnumberoftrianglesbutorderingiswrong' logger.info 'Goingfrom%dthto%dthsubdivisionofanicosahedron n_tri %d->%d ' % found dest_grade surf['ntri'] dest['ntri'] dest['rr'] surf['rr'][_get_ico_map source dest ]return dest
def test_elemwise_collapse shape 4 5 60 a cuda_ndarray.CudaNdarray theano._asarray numpy.random.rand *shape dtype 'float32' a theano._asarray numpy.random.rand *shape dtype 'float32' a2 tcn.shared_constructor a 'a' a3 a2.dimshuffle 0 'x' 1 2 b tcn.CudaNdarrayType False True False False c a3 + b f pfunc [b] [c] mode mode_with_gpu v theano._asarray numpy.random.rand shape[0] 1 *shape[1 ] dtype 'float32' v cuda_ndarray.CudaNdarray v out f v [0]assert numpy.allclose out a.reshape shape[0] 1 *shape[1 ] + v
def is_collection obj if isinstance obj basestring return Falsereturn hasattr obj '__getitem__'
def setup_gpmdp hass config code add_devices name config.get CONF_NAME host config.get CONF_HOST port config.get CONF_PORT url 'ws //{} {}'.format host port if not code request_configuration hass config url add_devices returnif 'gpmdp' in _CONFIGURING configurator get_component 'configurator' configurator.request_done _CONFIGURING.pop 'gpmdp' add_devices [GPMDP name url code ]
def contract nonce gasprice startgas endowment code v 0 r 0 s 0 tx Transaction nonce gasprice startgas '' endowment code v r s return tx
def move source destination use_sudo False func use_sudo and run_as_root or run func '/bin/mv{0}{1}'.format quote source quote destination
def get_documented filenames documented {}for filename in filenames f open filename u'r' lines f.read .splitlines documented.update get_documented_in_lines lines filename filename f.close return documented
def equalize_epoch_counts epochs_list method 'mintime' if not all isinstance e BaseEpochs for e in epochs_list raise ValueError 'AllinputsmustbeEpochsinstances' for e in epochs_list if not e._bad_dropped e.drop_bad event_times [e.events[ 0] for e in epochs_list]indices _get_drop_indices event_times method for e inds in zip epochs_list indices e.drop inds reason 'EQUALIZED_COUNT'
def attribute_path_to_object_names attribute_container_path object_names ['figure']if 'layout' in attribute_container_path for path_part in attribute_container_path if path_part in OBJECTS object_names.append path_part if path_part in ARRAYS object_names.append path_part object_names.append path_part[ -1 ] elif 'layoutAttributes' in attribute_container_path object_names.append 'layout' start_index attribute_container_path.index 'layoutAttributes' for path_part in attribute_container_path[start_index ] if path_part in OBJECTS object_names.append path_part if path_part in ARRAYS object_names.append path_part object_names.append path_part[ -1 ] else object_names.append 'data' for path_part in attribute_container_path if path_part in OBJECTS object_names.append path_part if path_part in ARRAYS object_names.append path_part object_names.append path_part[ -1 ] return tuple object_names
def get_absolute_path_to_file_in_repository repo_files_dir file_name stripped_file_name basic_util.strip_path file_name file_path Nonefor root dirs files in os.walk repo_files_dir if root.find '.hg' < 0 for name in files if name stripped_file_name return os.path.abspath os.path.join root name return file_path
@unbox types.Array def unbox_array typ obj c nativearycls c.context.make_array typ nativeary nativearycls c.context c.builder aryptr nativeary._getpointer ptr c.builder.bitcast aryptr c.pyapi.voidptr if c.context.enable_nrt errcode c.pyapi.nrt_adapt_ndarray_from_python obj ptr else errcode c.pyapi.numba_array_adaptor obj ptr failed cgutils.is_not_null c.builder errcode return NativeValue c.builder.load aryptr is_error failed
def _turn_off_csrf request csrf_token csrf._get_new_token request.headers.cookie['csrf_token'] csrf_tokenrequest.headers['X-CSRF-TOKEN'] csrf_token
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def _intersect_items baselist comparelist return list set baselist & set comparelist
def validate_course_mode course_id mode is_active None include_expired False if not include_expired include_expired not is_active if is_active is not None else False course_enrollment_info _data_api .get_course_enrollment_info course_id include_expired include_expired course_modes course_enrollment_info['course_modes']available_modes [m['slug'] for m in course_modes]if mode not in available_modes msg u"Specifiedcoursemode'{mode}'unavailableforcourse{course_id}.Availablemodeswere {available}".format mode mode course_id course_id available ' '.join available_modes log.warn msg raise errors.CourseModeNotFoundError msg course_enrollment_info
def n_files_str count return '{}file{}'.format count 's' if count ! 1 else ''
def if_safe_multiprocessing_with_blas func @wraps func def run_test *args **kwargs if sys.platform 'darwin' raise SkipTest 'Possiblemulti-processbugwithsomeBLAS' return func *args **kwargs return run_test
def writeWithAttributeEscaping write def _write data write escapeForContent data .replace '"' '&quot;' return _write
@register.inclusion_tag u'modeladmin/includes/result_list.html' takes_context True def result_list context view context[u'view']object_list context[u'object_list']headers list result_headers view num_sorted_fields 0for h in headers if h[u'sortable'] and h[u'sorted'] num_sorted_fields + 1context.update {u'result_headers' headers u'num_sorted_fields' num_sorted_fields u'results' list results view object_list } return context
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def int_or_true_div x_discrete y_discrete if x_discrete and y_discrete if config.int_division 'raise' raise IntegerDivisionError "With`config.int_division`setto'raise' dividingtwointegertypeswith'/'isforbiddentoavoidconfusionbetweenintegerandfloatingpointdivisions.Pleaseuse//forintegerdivision orifyouwantafloatresulteithercastoneoftheargumentstoafloatordirectlycall`x.__truediv__ y `." elif config.int_division 'int' warnings.warn 'Divisionoftwointegertypeswithx/yisdeprecated pleaseusex//yforanintegerdivision.' DeprecationWarning stacklevel 4 return int_divelif config.int_division 'floatX' return true_divelse raise NotImplementedError config.int_division else return true_div
def odd_ext x n axis -1 if n < 1 return xif n > x.shape[axis] - 1 raise ValueError 'Theextensionlengthn %d istoobig.' + 'Itmustnotexceedx.shape[axis]-1 whichis%d.' % n x.shape[axis] - 1 left_end axis_slice x start 0 stop 1 axis axis left_ext axis_slice x start n stop 0 step -1 axis axis right_end axis_slice x start -1 axis axis right_ext axis_slice x start -2 stop - n + 2 step -1 axis axis ext np.concatenate 2 * left_end - left_ext x 2 * right_end - right_ext axis axis return ext
def set_base_image_properties properties None if isinstance properties dict and len properties 0 properties['disk_format'] 'qcow2'properties['container_format'] 'bare'
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def UnregisterServer clsid progID None verProgID None customKeys None for args in GetUnregisterServerKeys clsid progID verProgID customKeys recurse_delete_key *args
def set_evacuate_or_drain_option facts if facts['common']['version_gte_3_5_or_1_5'] facts['common']['evacuate_or_drain'] '--drain'else facts['common']['evacuate_or_drain'] '--evacuate'return facts
def invalidate_module_pricing_cache driver_type driver_name if driver_name in PRICING_DATA[driver_type] del PRICING_DATA[driver_type][driver_name]
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
def transferClosestPath oldOrderedLocation remainingPaths skein closestDistance 1e+18closestPath NoneoldOrderedLocationComplex oldOrderedLocation.dropAxis 2 for remainingPath in remainingPaths distance min abs oldOrderedLocationComplex - remainingPath[0] abs oldOrderedLocationComplex - remainingPath[ -1 ] if distance < closestDistance closestDistance distanceclosestPath remainingPathremainingPaths.remove closestPath skein.addGcodeFromThreadZ closestPath oldOrderedLocation.z oldOrderedLocation.x closestPath[ -1 ].realoldOrderedLocation.y closestPath[ -1 ].imag
def _extract_issues logs issues ISSUE_REGEX.findall ''.join [log.message for log in logs] links { ISSUE_URL_FORMAT_STRING % issue for issue in issues}return links
def export_states_to_yaml exploration_id version None width 80 exploration get_exploration_by_id exploration_id version version exploration_dict {}for state in exploration.states exploration_dict[state] utils.yaml_from_dict exploration.states[state].to_dict width width return exploration_dict
def FakeOpen filename flags mode 511 raise OSError errno.EPERM 'Operationnotpermitted' filename
def execusercustomize try import usercustomizeexcept ImportError passexcept Exception if sys.flags.verbose sys.excepthook *sys.exc_info else print >>sys.stderr "'importusercustomize'failed;use-vfortraceback"
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
def emptyLine pass
def evaluate op op_str a b raise_on_error False use_numexpr True **eval_kwargs use_numexpr use_numexpr and _bool_arith_check op_str a b if use_numexpr return _evaluate op op_str a b raise_on_error raise_on_error **eval_kwargs return _evaluate_standard op op_str a b raise_on_error raise_on_error
def sets G c color G X set n for n in c if c[n] Y set n for n in c if not c[n] return X Y
def Tspec txt if txt 'None' return T 'None' elif txt in 'Default' '*' return T 'Default' else return txt
def profile func stream None def wrapper *args **kwargs prof LineProfiler val prof func *args **kwargs show_results prof stream stream return valreturn wrapper
def get_osf_statistics time None time get_previous_midnight time latest Noneif OSFWebsiteStatistics.objects.count ! 0 latest OSFWebsiteStatistics.objects.latest 'date' if latest.date.date time.date returndates get_list_of_dates latest.date time else dates [time]for date in dates get_days_statistics date latest latest OSFWebsiteStatistics.objects.latest 'date'
def diff_dicts d expected prefix None prefix prefix or [] diffs {}for k in set d.keys + expected.keys current_prefix prefix + [k] want d.get k got expected.get k if isinstance want dict and isinstance got dict diffs.update diff_dicts got want prefix current_prefix elif got ! want key '.'.join current_prefix diffs[key] got want return diffs
def test_enn_sample_wrong_X enn EditedNearestNeighbours random_state RND_SEED enn.fit X Y assert_raises RuntimeError enn.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def is_func_decorator node parent node.parentwhile parent is not None if isinstance parent astroid.Decorators return Trueif parent.is_statement or isinstance parent astroid.Lambda or isinstance parent scoped_nodes.ComprehensionScope scoped_nodes.ListComp breakparent parent.parentreturn False
def bucket_download_fileobj self Key Fileobj ExtraArgs None Callback None Config None return self.meta.client.download_fileobj Bucket self.name Key Key Fileobj Fileobj ExtraArgs ExtraArgs Callback Callback Config Config
def sanitize_filename filename if isinstance filename str unicode filename re.sub u'[\\\\/\\*]' u'-' filename filename re.sub u'[ "<>|?]' u'' filename filename re.sub u'\u2122' u'' filename filename filename.strip u'.' return filenamereturn u''
def parsedate_tz data res _parsedate_tz data if not res returnif res[9] is None res[9] 0return tuple res
def total_seconds delta if sys.version_info[ 2] ! 2 6 return delta.total_seconds day_in_seconds delta.days * 24 * 3600.0 micro_in_seconds delta.microseconds / 10.0 ** 6 return day_in_seconds + delta.seconds + micro_in_seconds
def epath path expr None func None args None kwargs None _epath EPath path if expr is None return _epathif func is None return _epath.select expr else return _epath.apply expr func args kwargs
def upcast_float16_ufunc fn def ret *args **kwargs out_dtype numpy.find_common_type [a.dtype for a in args] [numpy.float16] if out_dtype 'float16' sig 'f' * fn.nin + '->' + 'f' * fn.nout kwargs.update sig sig return fn *args **kwargs return ret
def pkgdb opts return LazyLoader _module_dirs opts 'pkgdb' base_path os.path.join SALT_BASE_PATH 'spm' opts tag 'pkgdb'
def transplant_func func module from nose.tools import make_decoratorif isgenerator func def newfunc *arg **kw for v in func *arg **kw yield v else def newfunc *arg **kw return func *arg **kw newfunc make_decorator func newfunc newfunc.__module__ modulereturn newfunc
def removeslash method @functools.wraps method def wrapper self *args **kwargs if self.request.path.endswith '/' if self.request.method in 'GET' 'HEAD' uri self.request.path.rstrip '/' if uri if self.request.query uri + '?' + self.request.query self.redirect uri permanent True returnelse raise HTTPError 404 return method self *args **kwargs return wrapper
def image_volume_cache_delete context volume_id return IMPL.image_volume_cache_delete context volume_id
def tic return __timer__.tic
def _construct_yaml_str self node return self.construct_scalar node
def erfinv x a 0.147 lnx log 1 - x * x part1 2 / a * pi + lnx / 2 part2 lnx / a sgn 1 if x > 0 else -1 return sgn * sqrt sqrt part1 * part1 - part2 - part1
def ipv6_to_str ip if isinstance ip numbers.Integral return addrconv.ipv6.bin_to_text type_desc.Int16.from_user ip else return addrconv.ipv6.bin_to_text ip
def check_config_permission permission key permission.replace 'ckan.auth.' '' if key not in CONFIG_PERMISSIONS_DEFAULTS return Falsedefault_value CONFIG_PERMISSIONS_DEFAULTS.get key config_key 'ckan.auth.' + key value config.get config_key default_value if key 'roles_that_cascade_to_sub_groups' value value.split if value else [] else value asbool value return value
def getAdditionalLength path point pointIndex if pointIndex 0 return abs point - path[0] if pointIndex len path return abs point - path[ -1 ] return abs point - path[ pointIndex - 1 ] + abs point - path[pointIndex] - abs path[pointIndex] - path[ pointIndex - 1 ]
def loadarff f if hasattr f 'read' ofile felse ofile open f 'rt' try return _loadarff ofile finally if ofile is not f ofile.close
def _read_cfg_production input return _read_production input standard_nonterm_parser
def _pivot_row T pivcol phase tol 1e-12 if phase 1 k 2else k 1ma np.ma.masked_where T[ - k pivcol] < tol T[ - k pivcol] copy False if ma.count 0 return False np.nan mb np.ma.masked_where T[ - k pivcol] < tol T[ - k -1 ] copy False q mb / ma return True np.ma.where q q.min [0][0]
def normalize_scene text return re.sub u'[^a-zA-Z0-9\\-._ ]' u'' normalize u'NFKD' text .encode u'ASCII' u'ignore' .decode
def _ask_user a formatted try rv _vim.eval 'inputlist %s ' % _vim.escape formatted if rv is None or rv '0' return Nonerv int rv if rv > len a rv len a return a[ rv - 1 ]except _vim.error return Noneexcept KeyboardInterrupt return None
def gen_pubpriv_keys nbits p q e d gen_keys nbits return {'e' e 'n' p * q } {'d' d 'p' p 'q' q}
def get_current_worker_task for task in reversed _task_stack.stack if not task.request.called_directly return task
def educateDashesOldSchool text text re.sub '---' smartchars.emdash text text re.sub '--' smartchars.endash text return text
@app.route '/stream-bytes/<int n>' def stream_random_bytes n n min n 100 * 1024 params CaseInsensitiveDict request.args.items if 'seed' in params random.seed int params['seed'] if 'chunk_size' in params chunk_size max 1 int params['chunk_size'] else chunk_size 10 * 1024 def generate_bytes chunks bytearray for i in xrange n chunks.append random.randint 0 255 if len chunks chunk_size yield bytes chunks chunks bytearray if chunks yield bytes chunks headers {'Content-Type' 'application/octet-stream'}return Response generate_bytes headers headers
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def is_choice action return action.choices
def _count_clades trees bitstrs {}tree_count 0for tree in trees tree_count + 1clade_bitstrs _tree_to_bitstrs tree for clade in tree.find_clades terminal False bitstr clade_bitstrs[clade]if bitstr in bitstrs count sum_bl bitstrs[bitstr]count + 1sum_bl + clade.branch_length or 0 bitstrs[bitstr] count sum_bl else bitstrs[bitstr] 1 clade.branch_length or 0 return bitstrs tree_count
def NXM_IS_NX_REG o return o.is_reg
def test_invalid_usage_exception exception_app request response sanic_endpoint_test exception_app uri '/invalid' assert response.status 400
def index_template_delete name hosts None profile None es _get_instance hosts profile try result es.indices.delete_template name name if result.get 'acknowledged' False return Trueexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def _determine_levels index if isinstance index tuple list and len index > 1 return list range len index else return 0
def use_coupon_code coupons user cart Order.get_cart_for_user user cart_items cart.orderitem_set.all .select_subclasses is_redemption_applied Falsefor coupon in coupons try if CouponRedemption.add_coupon_redemption coupon cart cart_items is_redemption_applied Trueexcept MultipleCouponsNotAllowedException return HttpResponseBadRequest _ 'Onlyonecouponredemptionisallowedagainstanorder' if not is_redemption_applied log.warning u"Discountdoesnotexistagainstcode'%s'." coupons[0].code return HttpResponseNotFound _ "Discountdoesnotexistagainstcode'{code}'." .format code coupons[0].code return HttpResponse json.dumps {'response' 'success' 'coupon_code_applied' True} content_type 'application/json'
def strip_stopwords sentence words sentence.split sentence []for word in words if word.lower not in stopwords sentence.append word return ''.join sentence
def is_dirty return dirty.get thread.get_ident False
def get_image_members_table meta get_image_members_table from_migration_import '008_add_image_members_table' ['get_image_members_table'] images get_image_members_table meta return images
def get_person_contact user if not user or user.is_anonymous return AnonymousContact defaults {u'is_active' user.is_active u'first_name' getattr user u'first_name' u'' u'last_name' getattr user u'last_name' u'' u'email' getattr user u'email' u'' }return PersonContact.objects.get_or_create user user defaults defaults [0]
def format_lea_seq_log input_seqs_count barcode_errors_exceed_max_count barcode_not_in_map_count primer_mismatch_count seq_too_short_count total_seqs_kept log_out 'Qualityfilterresults\nTotalnumberofinputsequences {}\nBarcodenotinmappingfile {}\nSequenceshorterthanthreshold {}\nBarcodeerrorsexceedslimit {}\nPrimermismatchcount {}\n\nTotalnumberseqswritten {}'.format input_seqs_count barcode_not_in_map_count seq_too_short_count barcode_errors_exceed_max_count primer_mismatch_count total_seqs_kept return log_out
def tiles ihtORsize numtilings floats ints [] readonly False qfloats [floor f * numtilings for f in floats]Tiles []for tiling in range numtilings tilingX2 tiling * 2 coords [tiling]b tilingfor q in qfloats coords.append q + b // numtilings b + tilingX2coords.extend ints Tiles.append hashcoords coords ihtORsize readonly return Tiles
def get_cluster_for_job_submission yarn get_next_ha_yarncluster if yarn return yarnmr get_next_ha_mrcluster if mr is not None return mrreturn None
def _cql_from_cass_type cass_type if issubclass cass_type types.ReversedType return cass_type.subtypes[0].cql_parameterized_type else return cass_type.cql_parameterized_type
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def getNewRepository return FillRepository
def reset_model model_elements for model_element in model_elements model_element.reset
def help_output_test subcommand '' cmd get_ipython_cmd + [subcommand '-h'] out err rc get_output_error_code cmd nt.assert_equal rc 0 err nt.assert_not_in 'Traceback' err nt.assert_in 'Options' out nt.assert_in '--help-all' out return out err
def _validate_requirements requirements invalid_requirements []for requirement in requirements invalid_params []if not requirement.get 'namespace' invalid_params.append 'namespace' if not requirement.get 'name' invalid_params.append 'name' if not requirement.get 'display_name' invalid_params.append 'display_name' if 'criteria' not in requirement invalid_params.append 'criteria' if invalid_params invalid_requirements.append u'{requirement}hasmissing/invalidparameters {params}'.format requirement requirement params invalid_params return invalid_requirements
def defer_succeed result d defer.Deferred reactor.callLater 0.1 d.callback result return d
def md5_for_file filename try md5 hashlib.md5 for byte in readFileBuffered filename md5.update byte return md5.hexdigest except Exception return None
def sum x axis None return Sum axis x
def movetotrash path fss Carbon.File.FSSpec path trashfolder Carbon.Folder.FSFindFolder fss.as_tuple [0] 'trsh' 0 move path trashfolder
def movefile source dest if os.path.exists dest try os.unlink dest except OSError passos.rename source dest
def rst_fmt text fmt return fmt % text
def get_fans obj obj_type apps.get_model 'contenttypes' 'ContentType' .objects.get_for_model obj return get_user_model .objects.filter likes__content_type obj_type likes__object_id obj.id
def qsturng p r v if all map _isfloat [p r v] return _qsturng p r v return _vqsturng p r v
def raw_tool_xml_tree path tree _parse_xml path return tree
def file_param registry xml_parent data base_param registry xml_parent data False 'hudson.model.FileParameterDefinition'
def PrintExtremes live hist thinkstats2.Hist live.prglngth thinkplot.Hist hist label 'livebirths' thinkplot.Save root 'first_nsfg_hist_live' title 'Histogram' xlabel 'weeks' ylabel 'frequency' print 'Shortestlengths ' for weeks freq in hist.Smallest 10 print weeks freq print 'Longestlengths ' for weeks freq in hist.Largest 10 print weeks freq
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def addtogether *things return reduce operator.add things
def unhexify hexsum if hexsum 'None' return Nonesum ''for i in range 0 len hexsum 2 sum sum + chr string.atoi hexsum[i i + 2 ] 16 return sum
def register_probe probe_class if probe_class not in REGISTERED_PROBES REGISTERED_PROBES.append probe_class
def logger name 'ibpy' level level format format datefmt datefmt logging.basicConfig level level format format datefmt datefmt return logging.getLogger name
def _get_pyqt_objects lines obj depth 0 for kid in obj.findChildren QObject '' Qt.FindDirectChildrenOnly lines.append '' * depth + repr kid _get_pyqt_objects lines kid depth + 1
def _randint seed None if seed is None return random.randintelif isinstance seed int return random.Random seed .randintelif is_sequence seed seed list seed seed.reverse def give a b seq seed a b as_int a as_int b w b - a if w < 0 raise ValueError '_randintgotemptyrange' try x seq.pop except AttributeError raise ValueError '_randintexpectsalist-likesequence' except IndexError raise ValueError '_randintsequencewastooshort' if a < x < b return xelse return give a b seq return giveelse raise ValueError '_randintgotanunexpectedseed'
def check_compatibility version name if not version raise UnsupportedWheel '%sisinanunsupportedorinvalidwheel' % name if version[0] > VERSION_COMPATIBLE[0] raise UnsupportedWheel "%s'sWheel-Version %s isnotcompatiblewiththisversionofpip" % name '.'.join map str version elif version > VERSION_COMPATIBLE logger.warning 'InstallingfromanewerWheel-Version %s ' '.'.join map str version
def get_bound_method_weakref target on_delete if hasattr target '__get__' return BoundMethodWeakref target target on_delete on_delete else return BoundNonDescriptorMethodWeakref target target on_delete on_delete
def total_seconds delta if sys.version_info[ 2] ! 2 6 return delta.total_seconds day_in_seconds delta.days * 24 * 3600.0 micro_in_seconds delta.microseconds / 10.0 ** 6 return day_in_seconds + delta.seconds + micro_in_seconds
def get_vmdk_size_and_properties context image instance LOG.debug _ 'Gettingimagesizefortheimage%s' % image instance instance image_service image_id glance.get_remote_image_service context image meta_data image_service.show context image_id size properties meta_data['size'] meta_data['properties'] LOG.debug _ 'Gotimagesizeof% size sfortheimage% image s' % locals instance instance return size properties
def unsafe_version version return version.replace '_' '.'
def triu m k 0 return m * 1 - tri m.shape[0] m.shape[1] k k - 1 dtype m.dtype
def create_connection conf new connection_pool return ConnectionContext conf connection_pool pooled not new
def scan_archive path if not os.path.exists path raise ValueError 'Pathdoesnotexist' if not path.endswith ARCHIVE_EXTENSIONS raise ValueError '%risnotavalidarchiveextension' % os.path.splitext path [1] dirpath filename os.path.split path logger.info 'Scanningarchive%rin%r' filename dirpath if filename.endswith '.rar' rar RarFile path rar_filenames [f for f in rar.namelist if f.endswith VIDEO_EXTENSIONS ]if not rar_filenames raise ValueError 'Novideoinarchive' if len rar_filenames > 1 raise ValueError 'Morethanonevideoinarchive' rar_filename rar_filenames[0]rar_filepath os.path.join dirpath rar_filename video Video.fromguess rar_filepath guessit rar_filepath video.size rar.getinfo rar_filename .file_sizeelse raise ValueError 'Unsupportedextension%r' % os.path.splitext path [1] return video
def random_insert circuit choices seed None from sympy.utilities.randtest import _randrangeif not choices return circuitif isinstance circuit Mul circuit circuit.argsrandrange _randrange seed loc randrange len circuit + 1 choice choices[randrange len choices ]circuit list circuit circuit[loc loc] choicereturn tuple circuit
def DownloadFile file_obj target_path buffer_size BUFFER_SIZE logging.info u'Downloading %sto %s' file_obj.urn target_path target_file open target_path 'wb' file_obj.Seek 0 count 0data_buffer file_obj.Read buffer_size while data_buffer target_file.write data_buffer data_buffer file_obj.Read buffer_size count + 1if not count % 3 logging.debug u'Downloading %s %sdone' file_obj.urn utils.FormatNumberAsString count * buffer_size target_file.close
def extract_data input_dir output_dir if os.path.isdir output_dir print 'Usingextracteddataat%s.' % output_dir returnfor filename in 'data_object_label_2.zip' 'data_object_image_2.zip' 'devkit_object.zip' filename os.path.join input_dir filename zf zipfile.ZipFile filename 'r' print 'Unzipping%s...' % filename zf.extractall output_dir
def _gerrit_user_to_author props username u'unknown' username props.get 'username' username username props.get 'name' username if 'email' in props username + u'<% email s>' % props return username
def clear_post_mortem if IS_IPYKERNEL from IPython.core.getipython import get_ipythonipython_shell get_ipython if ipython_shell ipython_shell.set_custom_exc None else sys.excepthook sys.__excepthook__
def looks_like_a_tool_cwl path return looks_like_a_cwl_artifact path classes ['CommandLineTool' 'ExpressionTool']
def most_square_shape N for i in xrange int numpy.sqrt N 0 -1 if 0 N % i return i N / i
def list_stacks_by_path path stacks None cache None if stacks is None stacks []MANIFEST_FILE rospkg.MANIFEST_FILEbasename os.path.basenamefor d dirs files in os.walk path topdown True if STACK_FILE in files stack basename d if stack not in stacks stacks.append stack if cache is not None cache[stack] ddel dirs[ ]continueelif MANIFEST_FILE in files del dirs[ ]continueelif 'rospack_nosubdirs' in files del dirs[ ]continue[dirs.remove di for di in dirs if di[0] '.' ]for sub_d in dirs sub_p os.path.join d sub_d if os.path.islink sub_p stacks.extend list_stacks_by_path sub_p cache cache return stacks
def filter_by_version test_class version_dict current_version find_required_version version_dict.getdef dummy_test_method self passfor name in dir test_class expected_version find_required_version name 0 0 0 if expected_version > current_version setattr test_class name dummy_test_method
@timer.timeddef identity *args **kwargs return args kwargs
def with_setup_command root *args **kwds def generator func @wraps func def deco *args2 **kwargs2 tempdir path tempfile.mkdtemp pkgrootdir tempdir / 'root' root.copytree pkgrootdir cwd os.getcwd os.chdir pkgrootdir command [sys.executable 'setup.py' 'build_sphinx']command.extend args try proc subprocess.Popen command stdout subprocess.PIPE stderr subprocess.PIPE func pkgrootdir proc *args **kwds finally tempdir.rmtree os.chdir cwd return decoreturn generator
def serialize_instance instance ret dict [ k v for k v in instance.__dict__.items if not k.startswith '_' ] return json.loads json.dumps ret cls DjangoJSONEncoder
def equateSphericalDotRadius point returnValue originalRadius abs point if originalRadius > 0.0 point * returnValue / originalRadius
def _parse_profile profile if isinstance profile string_types _profile __salt__['config.option'] profile if not _profile msg 'Pillarkeyforprofile{0}notfound.'.format profile raise SaltInvocationError msg else _profile profilehosts _profile.get 'hosts' index _profile.get 'index' return hosts index
def crc32 data return _crc32 data & 4294967295
def lenSig obj return obj.size / 8
def median v n len v sorted_v sorted v midpoint n // 2 if n % 2 1 return sorted_v[midpoint]else lo midpoint - 1 hi midpointreturn sorted_v[lo] + sorted_v[hi] / 2
def _api_resume name output kwargs scheduler.plan_resume 0 sabnzbd.unpause_all return report output
def geodjango_suite apps True import sysfrom django.db.models import get_appsuite unittest.TestSuite from django.contrib.gis.geos import tests as geos_testssuite.addTest geos_tests.suite from django.contrib.gis.gdal import HAS_GDALif HAS_GDAL from django.contrib.gis.gdal import tests as gdal_testssuite.addTest gdal_tests.suite else sys.stderr.write 'GDALnotavailable-notestsrequiringGDALwillberun.\n' from django.contrib.gis.geoip import HAS_GEOIPif HAS_GEOIP and hasattr settings 'GEOIP_PATH' from django.contrib.gis.geoip import tests as geoip_testssuite.addTest geoip_tests.suite if apps for app_name in geo_apps namespace False suite.addTest build_suite get_app app_name return suite
def from_text_list name ttl rdclass rdtype text_rdatas if isinstance name str unicode name dns.name.from_text name None if isinstance rdclass str unicode rdclass dns.rdataclass.from_text rdclass if isinstance rdtype str unicode rdtype dns.rdatatype.from_text rdtype r RRset name rdclass rdtype r.update_ttl ttl for t in text_rdatas rd dns.rdata.from_text r.rdclass r.rdtype t r.add rd return r
def _traverse metric stats ts tags if isinstance stats dict if 'timestamp' in stats ts stats['timestamp'] / 1000 for key in stats.keys if key ! 'timestamp' _traverse metric + '.' + key stats[key] ts tags if isinstance stats list set tuple count 0for value in stats _traverse metric + '.' + str count value ts tags count + 1if utils.is_numeric stats and not isinstance stats bool if isinstance stats int stats int stats printmetric metric ts stats tags return
@not_implemented_for 'directed' def average_clustering G trials 1000 n len G triangles 0nodes list G for i in [int random.random * n for i in range trials ] nbrs list G[nodes[i]] if len nbrs < 2 continue u v random.sample nbrs 2 if u in G[v] triangles + 1return triangles / float trials
def interpose el seq combined zip itertools.repeat el seq return drop 1 concat combined
def fixed_ip_disassociate_all_by_timeout context host time return IMPL.fixed_ip_disassociate_all_by_timeout context host time
def test_RedshiftScaleFactor m models.RedshiftScaleFactor 0.4 assert m 0 0 assert_array_equal m [1 2] [1.4 2.8] assert_allclose m.inverse m [1 2] [1 2] m models.RedshiftScaleFactor [ -0.5 0 0.5] n_models 3 assert_array_equal m 0 0 assert_array_equal m [1 2] model_set_axis False [[0.5 1] [1 2] [1.5 3]] assert_allclose m.inverse m [1 2] model_set_axis False [[1 2] [1 2] [1 2]]
def convert_DateTimeProperty model prop kwargs if prop.auto_now or prop.auto_now_add return Nonereturn f.DateTimeField format '%Y-%m-%d%H %M %S' **kwargs
def sanitize_path path replacements None replacements replacements or CHAR_REPLACE comps components path if not comps return ''for i comp in enumerate comps for regex repl in replacements comp regex.sub repl comp comps[i] compreturn os.path.join *comps
def p_program p if len p 2 and p[1] p[0] {} line stat p[1]p[0][line] statelif len p 3 p[0] p[1]if not p[0] p[0] {}if p[2] line stat p[2]p[0][line] stat
def _generate_cache_header_key key_prefix request path hashlib.md5 force_bytes iri_to_uri request.get_full_path cache_key u'views.decorators.cache.cache_header.%s.%s' % key_prefix path.hexdigest return _i18n_cache_key_suffix request cache_key
def sdm_to_vector f gens K n None dic sdm_to_dict f dics {}for k v in dic.items dics.setdefault k[0] [] .append k[1 ] v n n or len dics res []for k in range n if k in dics res.append Poly dict dics[k] gens gens domain K .as_expr else res.append S.Zero return res
def decrease_stream_retention_period stream_name retention_hours region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r _execute_with_retries conn 'decrease_stream_retention_period' StreamName stream_name RetentionPeriodHours retention_hours if 'error' not in r r['result'] Truereturn r
def split_huge_add_or_mul node if node.op.scalar_op in scal.add scal.mul max_nb_inputs max_inputs_to_GpuElemwise node if max_nb_inputs < 1 and len node.inputs > 1 return Falsewhile len node.inputs > max_nb_inputs inner_op []for i in xrange 0 len node.inputs max_nb_inputs inner_op.append node.op *node.inputs[i i + max_nb_inputs ] node node.op *inner_op .ownerreturn node
def _ParseFullAppId app_id partition ''psep app_id.find _PARTITION_SEPARATOR if psep > 0 partition app_id[ psep]app_id app_id[ psep + 1 ]domain_name ''dsep app_id.find _DOMAIN_SEPARATOR if dsep > 0 domain_name app_id[ dsep]app_id app_id[ dsep + 1 ]return partition domain_name app_id
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def test_load_train_file environ {'PYLEARN2_DATA_PATH' '/just/a/test/path/'}load_train_file yaml_path + 'test_model.yaml' load_train_file yaml_path + 'test_model.yaml' environ environ
def filter_otus_from_otu_map input_otu_map_fp output_otu_map_fp min_count min_sample_count 1 results set output_otu_map_f open output_otu_map_fp 'w' for line in open input_otu_map_fp 'U' fields line.strip .split ' DCTB ' sample_ids set [e.split '_' [0] for e in fields[1 ]] if len fields > min_count and len sample_ids > min_sample_count output_otu_map_f.write line results.add fields[0].split ' DCTB ' [0] output_otu_map_f.close return results
def dumps obj key None salt u'django.core.signing' serializer JSONSerializer compress False data serializer .dumps obj is_compressed Falseif compress compressed zlib.compress data if len compressed < len data - 1 data compressedis_compressed Truebase64d b64_encode data if is_compressed base64d '.' + base64d return TimestampSigner key salt salt .sign base64d
def filter sum_dict align_dict filter_attribute low_bound high_bound new_sum_dict FSSP.FSSPSumDict new_align_dict copy.deepcopy align_dict for prot_num in sum_dict attr_value getattr sum_dict[prot_num] filter_attribute if attr_value > low_bound and attr_value < high_bound new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict.abs_res_dict new_align_dict.abs pos_num .pos_align_dict {}for prot_num in prot_numbers new_align_dict.abs pos_num .pos_align_dict[prot_num] align_dict.abs pos_num .pos_align_dict[prot_num]return new_sum_dict new_align_dict
def infer_dict node context None has_keywords lambda args all isinstance arg nodes.Keyword for arg in args if not node.args and not node.kwargs return nodes.Dict elif has_keywords node.args and node.args items [ nodes.Const arg.arg arg.value for arg in node.args]elif len node.args > 2 and has_keywords node.args[1 ] elts _get_elts node.args[0] context keys [ nodes.Const arg.arg arg.value for arg in node.args[1 ]]items elts + keys elif len node.args 1 items _get_elts node.args[0] context else raise UseInferenceDefault empty nodes.Dict empty.items itemsreturn empty
def get_deps_dir frame inspect.stack [1]module inspect.getmodule frame[0] p os.path.dirname module.__file__ nesting_limit 10index 0while 'deps' not in os.listdir p if '.git' in os.listdir p raise MissingDepsDirError 'Couldnotfindadepsdirforgitrepo%s' % p if index > nesting_limit raise MissingDepsDirError 'Couldnotfindadepsdirafterlooking%sparentdirectories' % nesting_limit p os.path.dirname p index + 1return os.path.join p 'deps'
def _invert_monoms p1 terms list p1.items terms.sort deg p1.degree R p1.ringp R.zerocv p1.listcoeffs mv p1.listmonoms for i in range len mv p[ deg - mv[i][0] ] cv[i]return p
def values store load return store.values
def execute_request service property_uri request return service.searchanalytics .query siteUrl property_uri body request .execute
def test_get_by_name assert Operator.get_by_name 'SelectKBest' .__class__ TPOTSelectKBest
def readQueue thread_id None return _readQueue thread_id
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def get_issues_url page after template '{base_url}/{owner}/{repo}/issues?state closed&per_page 100&page {page}&since {after}'return template.format page page after after.isoformat **API_PARAMS
def recursive_repr fillvalue u'...' def decorating_function user_function repr_running set def wrapper self key id self get_ident if key in repr_running return fillvaluerepr_running.add key try result user_function self finally repr_running.discard key return resultwrapper.__module__ getattr user_function u'__module__' wrapper.__doc__ getattr user_function u'__doc__' wrapper.__name__ getattr user_function u'__name__' wrapper.__annotations__ getattr user_function u'__annotations__' {} return wrapperreturn decorating_function
def get_next_prior_import_or_install_required_dict_entry prior_required_dict processed_tsr_ids for key value in prior_required_dict.items if key in processed_tsr_ids continueif not value return keyfor key value in prior_required_dict.items if key in processed_tsr_ids continueall_contained Truefor required_repository_id in value if required_repository_id not in processed_tsr_ids all_contained Falsebreakif all_contained return keyfor key value in prior_required_dict.items if key in processed_tsr_ids continuereturn key
@status 'configureregenerated' modal True info str def regenerated_configure file_paths if 'configure.ac' in file_paths return 'yes' if 'configure' in file_paths else 'no' else return 'notneeded'
def _remove_repeated inds sum_index {}for i in inds if i in sum_index sum_index[i] + 1else sum_index[i] 0inds [x for x in inds if not sum_index[x] ]return set inds tuple [i for i in sum_index if sum_index[i]]
def channel return s3_rest_controller
def dump_config profile 'default' cmd {'cmd' 'dump' 'mime' 'prop'}return _do_http cmd profile
def getprime nbits poolsize pipe_recv pipe_send mp.Pipe duplex False procs [mp.Process target _find_prime args nbits pipe_send for _ in range poolsize ][p.start for p in procs]result pipe_recv.recv [p.terminate for p in procs]return result
def write_stream stream outfile flush try buf outfile.bufferexcept AttributeError buf outfilefor chunk in stream buf.write chunk if flush outfile.flush
def test_oss_fit_single_class oss OneSidedSelection random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning oss.fit X y_single_class
def csrf_exempt view_func def wrapped_view *args **kwargs return view_func *args **kwargs wrapped_view.csrf_exempt Truereturn wraps view_func wrapped_view
def method2png output mx raw False buff rawif raw False buff method2dot mx method2format output 'png' mx buff
def add_flex_arithmetic_methods cls flex_arith_method flex_comp_method None flex_bool_method None use_numexpr True force False select None exclude None new_methods _create_methods flex_arith_method flex_comp_method flex_bool_method use_numexpr default_axis 'columns' special False new_methods.update dict multiply new_methods['mul'] subtract new_methods['sub'] divide new_methods['div'] for k in 'ror_' 'rxor' 'rand_' if k in new_methods new_methods.pop k add_methods cls new_methods new_methods force force select select exclude exclude
def _orange_to_numpy x if isinstance x data.Table return x.Xelif isinstance x data.Instance return np.atleast_2d x.x elif isinstance x np.ndarray return np.atleast_2d x else return x
def uppercase_range code1 code2 code3 max code1 ord 'a' code4 min code2 ord 'z' + 1 if code3 < code4 d ord 'A' - ord 'a' return code3 + d code4 + d else return None
def sysv_hash symbol h 0g 0for c in symbol h h << 4 + ord c g h & 4026531840 h ^ g >> 24 h & ~ g return h & 4294967295
def test_cmp a frozenset [1 2] b set [1 2] abig frozenset [1 2 3] bbig set [1 2 3] AreEqual cmp a b 0 AreEqual cmp a bbig -1 AreEqual cmp abig b 1 class sset set passclass fset frozenset passa fset [1 2] b sset [1 2] abig fset [1 2 3] bbig sset [1 2 3] AreEqual cmp a b 0 AreEqual cmp a bbig -1 AreEqual cmp abig b 1
def _long_to_bin x hex_format_string return binascii.unhexlify hex_format_string % x
def send_daily now frappe.utils.now_datetime for report in frappe.get_all u'AutoEmailReport' {u'enabled' 1 u'frequency' u'in' u'Daily' u'Weekly' } auto_email_report frappe.get_doc u'AutoEmailReport' report.name if auto_email_report.frequency u'Weekly' if now.weekday ! {u'Monday' 0 u'Tuesday' 1 u'Wednesday' 2 u'Thursday' 3 u'Friday' 4 u'Saturday' 5 u'Sunday' 6}[auto_email_report.day_of_week] continueauto_email_report.send
def make_main argv sys.argv from sphinx import make_modereturn make_mode.run_make_mode argv[2 ]
def test_token_auth precomptoken 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjoibXkgZGF0YSIsInVzZXIiOiJUaW1vdGh5In0.8QqdQMJUTq0Dq7vHlnDjdoCKFPDAlvxGCpc_8XF41nI'@hug.authentication.tokendef token_authentication token if token precomptoken return 'Timothy'@hug.get requires token_authentication def hello_world return 'HelloWorld!'assert hug.test.get api 'hello_world' headers {'Authorization' precomptoken} .data 'HelloWorld!' assert '401' in hug.test.get api 'hello_world' .status assert '401' in hug.test.get api 'hello_world' headers {'Authorization' 'eyJhbGci'} .status
def sanitize_host host return ''.join [c for c in host[0 255] if c in ascii_letters + digits + '.-' ]
def create_volumes w3af_home os.path.expanduser '~/.w3af' w3af_shared os.path.expanduser '~/w3af-shared' if not os.path.exists w3af_home os.mkdir w3af_home if not os.path.exists w3af_shared os.mkdir w3af_shared
def _serialize_allocations_for_resource_provider allocations resource_provider return _allocations_dict allocations lambda x x.consumer_id resource_provider resource_provider
def _apply_exif_orientation image try exif_tags image._getexif or {} except AttributeError return imageORIENTATION_TAG_ID 274orientation exif_tags.get ORIENTATION_TAG_ID if orientation 1 passelif orientation 2 image image.transpose Image.FLIP_LEFT_RIGHT elif orientation 3 image image.transpose Image.ROTATE_180 elif orientation 4 image image.transpose Image.FLIP_TOP_BOTTOM elif orientation 5 image image.transpose Image.FLIP_LEFT_RIGHT image image.transpose Image.ROTATE_90 elif orientation 6 image image.transpose Image.ROTATE_270 elif orientation 7 image image.transpose Image.FLIP_LEFT_RIGHT image image.transpose Image.ROTATE_270 elif orientation 8 image image.transpose Image.ROTATE_90 return image
def _handle_objects_related_type_conversions values for key in 'access_ip_v4' 'access_ip_v6' if key in values and values[key] is not None values[key] str values[key] datetime_keys 'created_at' 'deleted_at' 'updated_at' 'launched_at' 'terminated_at' convert_objects_related_datetimes values *datetime_keys
def point_is_valid generator x y n generator.order curve generator.curve if x < 0 or n < x or y < 0 or n < y return Falseif not curve.contains_point x y return Falseif not n * ellipticcurve.Point curve x y ellipticcurve.INFINITY return Falsereturn True
def _neighbor_test nr_points dim bucket_size radius kdt _CKDTree.KDTree dim bucket_size coords random.random nr_points dim kdt.set_data coords neighbors kdt.neighbor_search radius r [neighbor.radius for neighbor in neighbors]if r is None l1 0else l1 len r neighbors kdt.neighbor_simple_search radius r [neighbor.radius for neighbor in neighbors]if r is None l2 0else l2 len r if l1 l2 return Trueelse print 'Notpassed %i! %i.' % l1 l2 return False
def lengths *args results []for arg in args try arglen len arg except TypeError arglen Noneresults.append arglen arg return results
def download_command url to STDOUT_INDICATOR quote_url False if quote_url url "'%s'" % url if to ! STDOUT_INDICATOR to "'%s'" % to if which 'wget' download_cmd ['wget' '-q']if to STDOUT_INDICATOR download_cmd + ['-O' STDOUT_INDICATOR url]else download_cmd + ['--recursive' '-O' to url]else download_cmd ['curl' '-L' url]if to ! STDOUT_INDICATOR download_cmd + ['-o' to]return download_cmd
def lookupWellKnownServices name timeout None return getResolver .lookupWellKnownServices name timeout
def requeue queue index -1 x queue.pop index queue.insert 0 x return x
def remove_nanrows y x mask ~ np.isnan y mask * ~ np.isnan x .any -1 y y[mask]x x[mask]return y x
def config_file kind 'local' if kind 'local' return 'setup.cfg'if kind 'global' return os.path.join os.path.dirname distutils.__file__ 'distutils.cfg' if kind 'user' dot os.name 'posix' and '.' or '' return os.path.expanduser convert_path '~/%spydistutils.cfg' % dot raise ValueError "config_file typemustbe'local' 'global' or'user'" kind
def shortcut_launch argv [u'cola' u'--prompt']git_path find_git if git_path prepend_path git_path return main argv
def fake_cluster_orm **updates db_cluster fake_db_cluster **updates del db_cluster['services']cluster models.Cluster **db_cluster return cluster
def collect_merged_boolean_field block_structure transformer xblock_field_name merged_field_name for block_key in block_structure.topological_traversal parents block_structure.get_parents block_key all_parents_merged_value all block_structure.get_transformer_block_field parent_key transformer merged_field_name False for parent_key in parents if parents else False block_structure.set_transformer_block_field block_key transformer merged_field_name all_parents_merged_value or get_field_on_block block_structure.get_xblock block_key xblock_field_name False
def test_nonexistent_extra_warns_user_with_wheel script data result script.pip 'install' '--no-index' '--find-links ' + data.find_links 'simplewheel[nonexistent]' expect_stderr True assert "simplewheel2.0doesnotprovidetheextra'nonexistent'" in result.stderr
def resource_link path request.path.strip '/' if '|item' in request.endpoint path path[ path.rfind '/' ]def strip_prefix hit return path[len hit ] if path.startswith hit else path if config.URL_PREFIX path strip_prefix config.URL_PREFIX + '/' if config.API_VERSION path strip_prefix config.API_VERSION + '/' return path
def get_user_model_safe user_app user_model settings.AUTH_USER_MODEL.split '.' try return apps.get_model user_app user_model except AppRegistryNotReady if apps.apps_ready and not apps.models_ready app_config apps.get_app_config user_app import_module '%s.%s' % app_config.name MODELS_MODULE_NAME return apps.get_registered_model user_app user_model else raise
def build_api_server_args facts cloud_cfg_path os.path.join facts['common']['config_base'] 'cloudprovider' if 'master' in facts api_server_args {}if 'cloudprovider' in facts if 'kind' in facts['cloudprovider'] if facts['cloudprovider']['kind'] 'aws' api_server_args['cloud-provider'] ['aws']api_server_args['cloud-config'] [ cloud_cfg_path + '/aws.conf' ]if facts['cloudprovider']['kind'] 'openstack' api_server_args['cloud-provider'] ['openstack']api_server_args['cloud-config'] [ cloud_cfg_path + '/openstack.conf' ]if facts['cloudprovider']['kind'] 'gce' api_server_args['cloud-provider'] ['gce']api_server_args['cloud-config'] [ cloud_cfg_path + '/gce.conf' ]if api_server_args ! {} facts merge_facts {'master' {'api_server_args' api_server_args}} facts [] [] return facts
def cxTwoPoint ind1 ind2 size min len ind1 len ind2 cxpoint1 random.randint 1 size cxpoint2 random.randint 1 size - 1 if cxpoint2 > cxpoint1 cxpoint2 + 1else cxpoint1 cxpoint2 cxpoint2 cxpoint1 ind1[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] ind1[cxpoint1 cxpoint2] return ind1 ind2
@receiver UNENROLL_DONE def handle_unenroll_done sender course_enrollment None skip_refund False **kwargs if not is_commerce_service_configured or skip_refund returnif course_enrollment and course_enrollment.refundable try request_user get_request_user or course_enrollment.user if isinstance request_user AnonymousUser returnrefund_seat course_enrollment request_user except log.exception u'Unexpectedexceptionwhileattemptingtoinitiaterefundforuser[%s] course[%s]' course_enrollment.user.id course_enrollment.course_id
def isenumattribute x if enum is None return Falsereturn isinstance x enum.Enum
def init_all_applications from django.db.models import get_apps get_modelsfor app in get_apps try get_models app except Exception continue
def dup_ff_div f g K df dup_degree f dg dup_degree g q r dr [] f df if not g raise ZeroDivisionError 'polynomialdivision' elif df < dg return q r lc_g dup_LC g K while True lc_r dup_LC r K c K.exquo lc_r lc_g j dr - dg q dup_add_term q c j K h dup_mul_term g c j K r dup_sub r h K _dr dr dr dup_degree r if dr < dg breakelif not dr < _dr raise PolynomialDivisionFailed f g K return q r
@not_implemented_for 'directed' def is_edge_cover G cover return set G < set chain.from_iterable cover
def add_plugin_translations plugin translation plugin_folder os.path.join current_app.config['PLUGINS_FOLDER'] plugin translations_folder os.path.join plugin_folder 'translations' source_file os.path.join translations_folder 'messages.pot' subprocess.call ['pybabel' 'extract' '-F' 'babel.cfg' '-k' 'lazy_gettext' '-o' source_file plugin_folder] subprocess.call ['pybabel' 'init' '-i' source_file '-d' translations_folder '-l' translation]
def check_cs_ptr result func cargs if not result raise GEOSException 'ErrorencounteredcheckingCoordinateSequencereturnedfromGEOSCfunction"%s".' % func.__name__ return result
@jit nopython True def searchsorted a v lo -1 hi len a while lo < hi - 1 m lo + hi // 2 if v < a[m] hi melse lo mreturn hi
def _is_reference arg return isinstance arg dict and len arg 1 and isinstance next six.itervalues arg six.string_types
def get url conn urlopen url resp conn.read conn.close return resp
def make_color_dict start_name start_hsv end_name end_hsv n colors linear_gradient start_hsv end_hsv n names [ '%sto%s%s_%s' % start_name end_name n i for i in range n ]return dict zip names colors
def show_commit repo commit decode outstream sys.stdout print_commit commit decode decode outstream outstream parent_commit repo[commit.parents[0]]write_tree_diff outstream repo.object_store parent_commit.tree commit.tree
def get_cli_body_ssh_vrf_interface command response module if '^' in response[0] body []elif 'showrun' in command body responseelse body [json.loads response[0] ]return body
def is_installed return get_binstar is not None
def tokenize_wrapper input skip set token.NEWLINE token.INDENT token.DEDENT tokens tokenize.generate_tokens io.StringIO input .readline for quintuple in tokens type value start end line_text quintupleif type not in skip yield quintuple
def _call_brew cmd failhard True user __salt__['file.get_user'] _homebrew_bin runas user if user ! __opts__['user'] else None result __salt__['cmd.run_all'] cmd runas runas output_loglevel 'trace' python_shell False if failhard and result['retcode'] ! 0 raise CommandExecutionError 'Brewcommandfailed' info {'result' result} return result
def remove_license key result {'result' False 'retcode' -1 'output' ''}if not has_powerpath result['output'] 'PowerPathisnotinstalled'return resultcmd '/sbin/emcpreg-remove{0}'.format key ret __salt__['cmd.run_all'] cmd python_shell True result['retcode'] ret['retcode']if ret['retcode'] ! 0 result['output'] ret['stderr']else result['output'] ret['stdout']result['result'] Truereturn result
def gosper_sum f k indefinite Falseif is_sequence k k a b kelse indefinite Trueg gosper_term f k if g is None return Noneif indefinite result f * g else result f * g + 1 .subs k b - f * g .subs k a if result is S.NaN try result f * g + 1 .limit k b - f * g .limit k a except NotImplementedError result Nonereturn factor result
def dup_exquo f g K q r dup_div f g K if not r return qelse raise ExactQuotientFailed f g
def clean_path_execbit path current pathwhile True try mode os.stat current .st_modeif mode & stat.S_IXOTH 0 raise forms.ValidationError _ "Thepath'%s'requiresexecutepermissionbit" % current except OSError breakcurrent os.path.realpath os.path.join current os.path.pardir if current '/' break
def __DocTestFinder_from_module self module object import inspectif module is None return Trueelif inspect.isfunction object or inspect.isclass object return module.__name__ object.__module__ elif inspect.getmodule object is not None return module is inspect.getmodule object elif hasattr object '__module__' return module.__name__ object.__module__ elif isinstance object property return Trueelse raise ValueError 'objectmustbeaclassorfunction'
def make_cidx_file fp if which 'cdbfasta' args ['cdbfasta' fp] stdout stderr Popen args stderr PIPE stdout PIPE .communicate else raise ApplicationNotFoundError
def sample_with_replacement population k return [random.choice population for i in range k ]
def _create_test_message sqs SQSConnection sqs_q sqs.get_queue g.sitemap_sqs_queue assert sqs_q 'failedtoconnecttoqueue'message sqs_q.new_message body json.dumps {'job_name' 'daily-sr-sitemap-reporting' 'location' 's3 //reddit-data-analysis/big-data/r2/prod/' + 'daily_sr_sitemap_reporting/dt 2016-06-14' 'timestamp' _current_timestamp } sqs_q.write message
def _get_changes rsync_out copied list deleted list for line in rsync_out.split '\n\n' [0].split '\n' [1 ] if line.startswith 'deleting' deleted.append line.split '' 1 [ -1 ] else copied.append line return {'copied' os.linesep.join sorted copied or 'N/A' 'deleted' os.linesep.join sorted deleted or 'N/A' }
def msec_time return int time.time * 1000.0
def help_problems command_name help_text problems []expected_start u'Usage {command}'.format command command_name .encode 'utf8' if not help_text.startswith expected_start problems.append 'Doesnotbeginwith{expected}.Found{actual}instead'.format expected repr expected_start actual repr help_text[ len expected_start ] return problems
def _mobius_to_interval M field a b c d M s t field a c field b d if s < t return s t else return t s
def coverage_with_hotshot fn fp HotShotFuncCoverage fn def new_fn *args **kw return fp *args **kw new_fn.__doc__ fn.__doc__new_fn.__name__ fn.__name__new_fn.__dict__ fn.__dict__new_fn.__module__ fn.__module__return new_fn
def ensure_fromlist mod fromlist buf recursive if not hasattr mod '__path__' returnfor item in fromlist if not hasattr item 'rindex' raise TypeError "Itemin``fromlist''notastring" if item '*' if recursive continuetry all mod.__all__except AttributeError passelse ret ensure_fromlist mod all buf 1 if not ret return 0elif not hasattr mod item import_submodule mod item buf + '.' + item
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def setActivePrivacyList disp listname None typ 'active' if listname attrs {'name' listname}else attrs {}resp disp.SendAndWaitForResponse Iq 'set' NS_PRIVACY payload [Node typ attrs ] if isResultNode resp return 1
def _theano_hamiltonian model_vars shared logpt potential dlogp gradient logpt model_vars logp dlogp q join_nonshared_inputs [logpt dlogp] model_vars shared logp CallableTensor logp dlogp CallableTensor dlogp return Hamiltonian logp dlogp potential q
def getrss tag '' popular 0 url '' user '' return dlcs_rss_request tag tag popular popular user user url url
def set_subtensor x y inplace False tolerate_inplace_aliasing False return inc_subtensor x y inplace set_instead_of_inc True tolerate_inplace_aliasing tolerate_inplace_aliasing
def pow_mid p max_denom 1024 assert 0 < p < 1 p Fraction p .limit_denominator max_denom return p p 1 - p
def grade_histogram module_id from django.db import connectioncursor connection.cursor query 'SELECTcourseware_studentmodule.grade \nCOUNT courseware_studentmodule.student_id \nFROMcourseware_studentmodule\nWHEREcourseware_studentmodule.module_id %s\nGROUPBYcourseware_studentmodule.grade'cursor.execute query [module_id.to_deprecated_string ] grades list cursor.fetchall grades.sort key lambda x x[0] if len grades > 1 and grades[0][0] is None return []return grades
def rwxtype mode if stat.S_ISLNK mode return 'l'elif stat.S_ISDIR mode return 'd'elif stat.S_ISREG mode return '-'else return '?'
def list_active_vms conn __get_conn vms []for id_ in conn.listDomainsID vms.append conn.lookupByID id_ .name return vms
def _get_root_versions_dir config root_dir _get_package_root_dir config script_location config.get_main_option 'script_location' part1 part2 script_location.split ' ' parts part1.split '.' + part2.split '.' + ['versions'] return os.path.join root_dir *parts
def timedelta_range start None end None periods None freq 'D' name None closed None return TimedeltaIndex start start end end periods periods freq freq name name closed closed
def solveBilinearTransform points1 points2 import numpy.linalgA np.array [[ points1[i].x * points1[i].y points1[i].x points1[i].y 1] for i in range 4 ] B np.array [[points2[i].x points2[i].y ] for i in range 4 ] matrix np.zeros 2 4 for i in range 2 matrix[i] numpy.linalg.solve A B[ i] return matrix
def fuzzy_not_equal a_str b_str threshold 0.6 return not relative_distance_boolean a_str b_str threshold
def _create_diff_action diff diff_key key value if diff_key not in diff.keys diff[diff_key] {}diff[diff_key][key] value
def _replXMLRef match ref match.group 1 value entcharrefsget ref if value is None if ref[0] '#' ref_code ref[1 ]if ref_code in '34' '38' '60' '62' '39' return match.group 0 elif ref_code[0].lower 'x' return unichr int ref[2 ] 16 else return unichr int ref[1 ] else return refreturn value
def _get_proc_username proc try return proc.username if PSUTIL2 else proc.username except psutil.NoSuchProcess psutil.AccessDenied KeyError return None
def _apply_forwards fstruct forward fs_class visited while id fstruct in forward fstruct forward[id fstruct ]if id fstruct in visited returnvisited.add id fstruct if _is_mapping fstruct items fstruct.items elif _is_sequence fstruct items enumerate fstruct else raise ValueError u'Expectedmappingorsequence' for fname fval in items if isinstance fval fs_class while id fval in forward fval forward[id fval ]fstruct[fname] fval_apply_forwards fval forward fs_class visited return fstruct
def _required_jdk_arch system_arch get_arch if system_arch 'x86_64' return 'x64'elif re.match 'i[0-9]86' system_arch return 'i586'else raise Exception "Unsupportedsystemarchitecture'%s'forOracleJDK" % system_arch
def has_super_powers return os.geteuid 0
def setup_worker fp server_addr port counter 0 verbose False error_profile None if fp is None raise ValueError 'setup_workerneedsfilepathforworker' log_fh Noneif verbose dir dirname fp + '.log' if not exists dir makedirs dir log_fh open fp + '.log' 'a' 0 new_fp fpif exists '/tmp' new_fp '/tmp/' + split fp [1] worker DenoiseWorker new_fp server_addr port counter counter log_fh log_fh error_profile error_profile loop
def read_uic3tag fh byteorder dtype plane_count assert dtype '2I' and byteorder '<' values fh.read_array '<u4' 2 * plane_count .reshape plane_count 2 return {'wavelengths' values[ 0] / values[ 1] }
def getIdentityTetragrid tetragrid None if tetragrid None return [[1.0 0.0 0.0 0.0] [0.0 1.0 0.0 0.0] [0.0 0.0 1.0 0.0] [0.0 0.0 0.0 1.0]]return tetragrid
def RedisSession redis_conn session_expiry False with_lock False db None locker.acquire try instance_name 'redis_instance_' + current.request.application if not hasattr RedisSession instance_name setattr RedisSession instance_name RedisClient redis_conn session_expiry session_expiry with_lock with_lock return getattr RedisSession instance_name finally locker.release
def test_flat b Bundle 's1' 'a2' output 'foo' jl bundle_to_joblist b assert len jl 1 assert jl.keys [0] 'foo' assert len jl['foo'] 1 assert len jl['foo'][0][1] 2
def async_raise tid exctype if not isinstance exctype six.class_types type raise TypeError 'Onlytypescanberaised notinstances ' if not isinstance tid int raise TypeError 'tidmustbeaninteger' res ctypes.pythonapi.PyThreadState_SetAsyncExc ctypes.c_long tid ctypes.py_object exctype if res 0 raise ValueError 'invalidthreadid' elif res ! 1 ctypes.pythonapi.PyThreadState_SetAsyncExc ctypes.c_long tid 0 raise SystemError 'PyThreadState_SetAsyncExcfailed'
def _main test_main test_proxy test_destop test_es2 test_pyopengl
def _GenClientLibCallback args client_func GenClientLib discovery_path language output_path args.discovery_doc[0] args.language args.output client_path client_func discovery_path language output_path print 'APIclientlibrarywrittento%s' % client_path
def equateRectangular point returnValue point.setToVector3 evaluate.getVector3ByDictionaryListValue returnValue point
def cr_uid_records method method._api 'cr_uid_records'return method
def version_windows versions major 1 minor 1 point 1 version_identifiers []for version_string in versions try version_identifiers.append Version version_string except InvalidVersion UnicodeEncodeError passmajor_version_window majorminor_version_window minorpoint_version_window pointmanager VersionManager for v in version_identifiers manager.add v manager.prune_major major_version_window manager.prune_minor minor_version_window manager.prune_point point_version_window return manager.get_version_list
def pwEncode pw pop u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789. ; -_!$?*+#'rpw u''.join random.sample pop 32 + pw + u''.join random.sample pop 32 return EncodeMarker + base64.b64encode rpw.encode u'utf-8' .decode u'ascii'
def get_ext filename try return os.path.splitext filename [1].lower except return ''
def test_sharedlibs mappath os.path.join test_location '../test_data/test_gdb_plugin/info_sharedlibs' p angr.Project binpath load_options {'gdb_map' mappath 'gdb_fix' True} check_addrs p
def testnewdocument document docbody relationships simpledoc coreprops coreproperties 'Pythondocxtestnewdocument' 'AshortexampleofmakingdocxfromPython' 'AlanBrooks' ['python' 'OfficeOpenXML' 'Word'] savedocx document coreprops appproperties contenttypes websettings wordrelationships relationships TEST_FILE
def Get keys **kwargs return GetAsync keys **kwargs .get_result
def get_revision vcs revision tag None None None hgdir os.path.join basedir '..' '.hg' gitdir os.path.join basedir '..' '.git' if os.path.isdir gitdir vcs 'git'vcs_info vcs revision tag return revision vcs_info
def introspector field arg_defs kwarg_defs matching_details field args []kwargs {}for defn in arg_defs try args.append get_value field defn except IsDefault passfor kwd defn in kwarg_defs.items try kwargs[kwd] get_value field defn except IsDefault passreturn args kwargs
def create_cloud oname words maxsize 120 fontname 'Lobster' try from pytagcloud import create_tag_image make_tagsexcept ImportError if not warned_of_error print 'Couldnotimportpytagcloud.Skippingcloudgeneration' returnwords [ w int v * 10000 for v w in words]tags make_tags words maxsize maxsize create_tag_image tags oname size 1800 1200 fontname fontname
def short2rgb short return SHORT2RGB_DICT[short]
def getWarningMethod return warn
def _api_change_cat name output kwargs value kwargs.get 'value' value2 kwargs.get 'value2' if value and value2 nzo_id valuecat value2if cat 'None' cat Noneresult NzbQueue.do.change_cat nzo_id cat return report output keyword 'status' data bool result > 0 else return report output _MSG_NO_VALUE
def register_access_role cls try role_name cls.ROLEREGISTERED_ACCESS_ROLES[role_name] clsexcept AttributeError log.exception u"UnabletoregisterAccessRolewithattribute'ROLE'." return cls
@_FFI.callback u'Value ExternContext* Key* ' def extern_val_for context_handle key c _FFI.from_handle context_handle return c.key_to_value key
def b36 number if not number or number < 0 return B36_ALPHABET[0]base36 []while number number i divmod number 36 base36.append B36_ALPHABET[i] return ''.join reversed base36
def RebuildProxy func token serializer kwds server getattr process.current_process '_manager_server' None if server and server.address token.address util.debug 'Rebuildaproxyownedbymanager token %r' token kwds['manager_owned'] Trueif token.id not in server.id_to_local_proxy_obj server.id_to_local_proxy_obj[token.id] server.id_to_obj[token.id]incref kwds.pop 'incref' True and not getattr process.current_process '_inheriting' False return func token serializer incref incref **kwds
def read_names names_path names_data pd.read_csv names_path names_data.Name names_data.Name.str.lower name_data names_data.groupby by ['Name'] ['Count'].sum name_counts np.array name_data.tolist names_deduped np.array name_data.index.tolist Dataset collections.namedtuple 'Dataset' ['Name' 'Count'] return Dataset names_deduped name_counts
def pick_installer config default plugins question 'Howwouldyouliketoinstallcertificates?' return pick_plugin config default plugins question interfaces.IInstaller
def _from_dict entry name entry.get 'name' code entry.get 'code' message entry.get 'message' return name ErrorCode code message
def test_read_types t1 ascii.read 'abc\n123\n456' format 'fast_basic' guess False t2 ascii.read StringIO 'abc\n123\n456' format 'fast_basic' guess False t3 ascii.read ['abc' '123' '456'] format 'fast_basic' guess False assert_table_equal t1 t2 assert_table_equal t2 t3
def get_locale name locale_cls _locales.get name.lower if locale_cls is None raise ValueError u"Unsupportedlocale'{0}'".format name return locale_cls
def _dt_to_float_ordinal dt if isinstance dt np.ndarray Index Series and is_datetime64_ns_dtype dt base dates.epoch2num dt.asi8 / 1000000000.0 else base dates.date2num dt return base
def config_megam bin None global _megam_bin_megam_bin find_binary 'megam' bin env_vars ['MEGAM'] binary_names ['megam.opt' 'megam' 'megam_686' 'megam_i686.opt'] url 'http //www.umiacs.umd.edu/~hal/megam/index.html'
def _do_download version download_base to_dir download_delay egg os.path.join to_dir 'setuptools-%s-py%d.%d.egg' % version sys.version_info[0] sys.version_info[1] if not os.path.exists egg archive download_setuptools version download_base to_dir download_delay _build_egg egg archive to_dir sys.path.insert 0 egg if 'pkg_resources' in sys.modules _unload_pkg_resources import setuptoolssetuptools.bootstrap_install_from egg
def floating_ip_get_all_by_project context project_id return IMPL.floating_ip_get_all_by_project context project_id
def arg_lookup fun aspec None ret {'kwargs' {}}if aspec is None aspec salt.utils.args.get_function_argspec fun if aspec.defaults ret['kwargs'] dict zip aspec.args[ -1 ] aspec.defaults[ -1 ] ret['args'] [arg for arg in aspec.args if arg not in ret['kwargs'] ]return ret
def test_notation_regexp pattern re.compile SCIENTIFIC_NOTATION_REGEXP matches ['1e3' '1.E4' '-1e-3' '2.3e+4' '.2e4']fails ['string' '4' '2.1' '1.2e3.2' '.e4' 'a3e4']for match in matches assert pattern.match match for fail in fails assert not pattern.match fail
def serialize_dt value return value.isoformat if hasattr value 'isoformat' else value
def limit_validation_results validation messages validation['messages']lim settings.VALIDATOR_MESSAGE_LIMITif lim and len messages > lim TYPES {'error' 0 'warning' 2 'notice' 3}def message_key message if message.get 'signing_severity' return 1else return TYPES.get message.get 'type' messages.sort key message_key leftover_count len messages - lim del messages[lim ]if validation['errors'] msg_type 'error'elif validation['warnings'] msg_type 'warning'else msg_type 'notice'compat_type msg_type if any msg.get 'compatibility_type' for msg in messages else None messages.insert 0 {'tier' 1 'type' msg_type 'id' ['validation' 'messages' 'truncated'] 'message' _ "Validationgeneratedtoomanyerrors/warningsso%smessagesweretruncated.Afteraddressingthevisiblemessages you'llbeabletoseetheothers." % leftover_count 'description' [] 'compatibility_type' compat_type}
def ParseTraceDump msg return re.split kTraceCodeLine msg
def list_add t owner slug get_slug user_name raw_input light_magenta 'Givemenameofthenewbie ' rl True if user_name.startswith '@' user_name user_name[1 ]try t.lists.members.create slug slug owner_screen_name owner screen_name user_name printNicely green 'Added.' except debug_option printNicely light_magenta "I'msorrywecannotaddhim/her."
def ndependents dependencies dependents result dict num_needed dict k len v for k v in dependents.items current set k for k v in num_needed.items if v 0 while current key current.pop result[key] 1 + sum result[parent] for parent in dependents[key] for child in dependencies[key] num_needed[child] - 1if num_needed[child] 0 current.add child return result
def filelines source_file source_file.seek 0 2 while True line source_file.readline if not line sleep 0.1 continue yield line
def poly_collection_2d_to_3d col zs 0 zdir u'z' segments_3d codes paths_to_3d_segments_with_codes col.get_paths zs zdir col.__class__ Poly3DCollectioncol.set_verts_and_codes segments_3d codes col.set_3d_properties
def add_class classname cls if classname in cls._decl_class_registry existing cls._decl_class_registry[classname]if not isinstance existing _MultipleClassMarker existing cls._decl_class_registry[classname] _MultipleClassMarker [cls existing] else cls._decl_class_registry[classname] clstry root_module cls._decl_class_registry['_sa_module_registry']except KeyError cls._decl_class_registry['_sa_module_registry'] root_module _ModuleMarker '_sa_module_registry' None tokens cls.__module__.split '.' while tokens token tokens.pop 0 module root_module.get_module token for token in tokens module module.get_module token module.add_class classname cls
def _flatten_units_collection items if not isinstance items list items [items]result set for item in items if isinstance item UnitBase result.add item else if isinstance item dict units item.values elif inspect.ismodule item units vars item .values elif isiterable item units itemelse continuefor unit in units if isinstance unit UnitBase result.add unit return result
def _plot_raw_onscroll event params len_channels None if 'fig_selection' in params _change_channel_group event.step params returnif len_channels is None len_channels len params['inds'] orig_start params['ch_start']if event.step < 0 params['ch_start'] min params['ch_start'] + params['n_channels'] len_channels - params['n_channels'] else params['ch_start'] max params['ch_start'] - params['n_channels'] 0 if orig_start ! params['ch_start'] _channels_changed params len_channels
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def sendmail smtphost from_addr to_addrs msg senderDomainName None port 25 if not hasattr msg 'read' msg StringIO str msg d defer.Deferred factory SMTPSenderFactory from_addr to_addrs msg d if senderDomainName is not None factory.domain senderDomainNamereactor.connectTCP smtphost port factory return d
def _zstat_generic2 value std_diff alternative zstat value / std_diff if alternative in ['two-sided' '2-sided' '2s'] pvalue stats.norm.sf np.abs zstat * 2 elif alternative in ['larger' 'l'] pvalue stats.norm.sf zstat elif alternative in ['smaller' 's'] pvalue stats.norm.cdf zstat else raise ValueError 'invalidalternative' return zstat pvalue
def roles_required *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perms [Permission RoleNeed role for role in roles]for perm in perms if not perm.can if _security._unauthorized_callback return _security._unauthorized_callback else return _get_unauthorized_view return fn *args **kwargs return decorated_viewreturn wrapper
def _positive_int integer_string strict False cutoff None ret int integer_string if ret < 0 or ret 0 and strict raise ValueError if cutoff ret min ret cutoff return ret
@_ConfigurableFilter executable 'HTML_TIDY_EXECUTABLE' def html_tidy_nowrap infile executable 'tidy5' return _html_tidy_runner infile '-quiet--show-infono--show-warningsno-utf8-indent--indent-attributesno--sort-attributesalpha--wrap0--wrap-sectionsno--drop-empty-elementsno--tidy-markno-modify%1' executable executable
def descendants pid this_pid pidallpids all_pids ppids {}def _parent pid if pid not in ppids ppids[pid] parent pid return ppids[pid]def _children ppid return [pid for pid in allpids if _parent pid ppid ]def _loop ppid return {pid _loop pid for pid in _children ppid }return _loop pid
def print_rows results print 'Rows ' if results.get 'rows' [] for row in results.get 'rows' print ' DCTB '.join row else print 'NoRowsFound'
def jsonrpc_error id code message data None return {'jsonrpc' '2.0' 'error' {'code' code 'message' message 'data' data} 'id' id}
def create_service credentials GoogleCredentials.get_application_default return discovery.build 'storage' 'v1' credentials credentials
def _hash_data data if isinstance data function.Function data copy.deepcopy data if not isinstance data six.string_types if isinstance data collections.Sequence return hash tuple _hash_data d for d in data if isinstance data collections.Mapping item_hashes hash k ^ _hash_data v for k v in data.items return six.moves.reduce operator.xor item_hashes 0 return hash data
@then u'itshouldfailwith' def step_it_should_fail_with context assert context.text is not None 'ENSURE multilinetextisprovided.'step_command_output_should_contain context assert_that context.command_result.returncode is_not equal_to 0
def schema_remove dbname name user None db_user None db_password None db_host None db_port None if not schema_exists dbname name db_user db_user db_password db_password db_host db_host db_port db_port log.info "Schema'{0}'doesnotexistin'{1}'".format name dbname return Falsesub_cmd 'DROPSCHEMA"{0}"'.format name _psql_prepare_and_run ['-c' sub_cmd] runas user maintenance_db dbname host db_host user db_user port db_port password db_password if not schema_exists dbname name db_user db_user db_password db_password db_host db_host db_port db_port return Trueelse log.info "Failedtodeleteschema'{0}'.".format name return False
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def scan_postfix_smtpd_line date log collector m re.match 'NOQUEUE reject RCPTfrom.*? .*? ;from < .*? >to < .*? >' log if m message sender recipient m.groups if recipient in collector['real_mail_addresses'] if 'Recipientaddressrejected Greylisted' in message returnm re.search 'Clienthost\\[ .*? \\]blockedusingzen.spamhaus.org; .* ' message if m message 'ipblocked ' + m.group 2 m re.search 'Senderaddress\\[.*@ .* \\]blockedusingdbl.spamhaus.org; .* ' message if m message 'domainblocked ' + m.group 2 collector['rejected-mail'].setdefault recipient [] .append date sender message
def create_route_table vpc_id None vpc_name None route_table_name None tags None region None key None keyid None profile None vpc_id check_vpc vpc_id vpc_name region key keyid profile if not vpc_id return {'created' False 'error' {'message' 'VPC{0}doesnotexist.'.format vpc_name or vpc_id }}return _create_resource 'route_table' route_table_name tags tags vpc_id vpc_id region region key key keyid keyid profile profile
def get_eol_chars text for eol_chars _os_name in EOL_CHARS if text.find eol_chars > -1 return eol_chars
def get_fixers_from_package pkg_name return [ pkg_name + '.' + fix_name for fix_name in get_all_fix_names pkg_name False ]
def _check_valid key val valid if val not in valid raise ValueError '%smustbeoneof%s not"%s"' % key valid val
def asint value if value is None return valuereturn int value
@constructordef argmin x axis None keepdims False x as_tensor_variable x str_x_type str x.dtype if str_x_type.startswith 'float' or str_x_type in int_dtypes return argmax - x axis axis keepdims keepdims else raise NotImplementedError
def _parse_datetime_string val dt Nonelenval len val fmt {19 '%Y-%m-%d%H %M %S' 10 '%Y-%m-%d'}.get lenval if fmt is None raise exc.InvalidDateTimeString "Thesuppliedvalue'%s'doesnotmatcheitheroftheformats'YYYY-MM-DDHH MM SS'or'YYYY-MM-DD'." % val return datetime.datetime.strptime val fmt
def ntohl integer if sys.byteorder 'big' return integerif not isinstance integer int long raise TypeError 'expectedint/long %sfound' % _TypeName integer if integer < 0 raise OverflowError "can'tconvertnegativenumbertounsignedlong" if integer > 1 << 32 raise OverflowError 'longintlargerthan32bits' return int integer & 4278190080 >> 24 | integer & 16711680 >> 8 | integer & 65280 << 8 | integer & 255 << 24
def hasHandlers logger rv Falsewhile logger if logger.handlers rv Truebreakelif not logger.propagate breakelse logger logger.parentreturn rv
def _AddEqualsMethod message_descriptor cls def __eq__ self other if not isinstance other message_mod.Message or other.DESCRIPTOR ! self.DESCRIPTOR return Falseif self is other return Trueif not self.ListFields other.ListFields return Falseunknown_fields list self._unknown_fields unknown_fields.sort other_unknown_fields list other._unknown_fields other_unknown_fields.sort return unknown_fields other_unknown_fields cls.__eq__ __eq__
def _bootstrap_arch name **kwargs if not salt.utils.which 'pacstrap' raise CommandExecutionError 'pacstrapnotfound isthearch-install-scriptspackageinstalled?' dst _make_container_root name cmd 'pacstrap-c-d{0}base'.format dst ret __salt__['cmd.run_all'] cmd python_shell False if ret['retcode'] ! 0 _build_failed dst name return ret
@app.route '/hello' def hello response make_response json.dumps {'hello' current_app.config['HELLO']} response.headers['Content-Type'] 'application/json'return response
@permission_required 'wiki.delete_document' def delete_document request document try DocumentDeletionLog.objects.create locale document.locale slug document.slug user request.user reason 'Spam' document.delete except Exception return Falsereturn True
def get_controller_args_for_types func arg_types args kwargs result_args []result_kwargs {}argspec inspect.getargspec func names argspec.args[1 ]for index name in enumerate names if name in kwargs try value kwargs[name]value_type arg_types[index]value cast_argument_value value_type value_type value value result_kwargs[name] valueexcept IndexError LOG.warning "Typedefinitionfor'%s'argumentof'%s'ismissing." name func.__name__ continuetry value args.pop 0 value_type arg_types[index]value cast_argument_value value_type value_type value value result_args.append value except IndexError LOG.warning "Typedefinitionfor'%s'argumentof'%s'ismissing." name func.__name__ return result_args result_kwargs
def get_sql_indexes app from django.db import modelsoutput []for model in models.get_models app output.extend get_sql_indexes_for_model model return output
def _epochs_navigation_onclick event params import matplotlib.pyplot as pltp paramshere Noneif event.inaxes p['back'].ax here 1elif event.inaxes p['next'].ax here -1 elif event.inaxes p['reject-quit'].ax if p['reject_idx'] p['epochs'].drop p['reject_idx'] plt.close p['fig'] plt.close event.inaxes.get_figure if here is not None p['idx_handler'].rotate here p['axes_handler'].rotate here this_idx p['idx_handler'][0]_draw_epochs_axes this_idx p['good_ch_idx'] p['bad_ch_idx'] p['data'][this_idx] p['times'] p['axes'] p['title_str'] p['axes_handler'] p['axes'][0].get_figure .canvas.draw
def removeTrueListFromDictionary dictionary keys for key in keys removeTrueFromDictionary dictionary key
def commented_out_code_lines source line_numbers []try for t in generate_tokens source token_type t[0]token_string t[1]start_row t[2][0]line t[4]if not line.lstrip .startswith u'#' continueif token_type tokenize.COMMENT stripped_line token_string.lstrip u'#' .strip if u'' in stripped_line and u'#' not in stripped_line and check_syntax stripped_line line_numbers.append start_row except SyntaxError tokenize.TokenError passreturn line_numbers
def GetIndentLevel line indent Match '^ * \\S' line if indent return len indent.group 1 else return 0
def degrees_to_dms degrees deg int degrees min int degrees - deg * 60 sec degrees - deg - min / 60.0 * 60 * 60 return u'%d\xb0%02u\'%05.2f"' % deg abs min abs sec
def water_source return s3_rest_controller
def _get_json_data eid None fpath None assert eid is not None or fpath is not None if fpath is not None return gzip.open fpath .read fpath _jsonf % eid if os.access fpath os.R_OK return gzip.open fpath .read try return urllib2.urlopen _json_base_url % eid eid timeout 5 .read except urllib2.HTTPError passexcept socket.timeout passreturn None
def alexnet_spec batch_size 500 return DataSpec batch_size batch_size scale_size 256 crop_size 227 isotropic False
def is_builtin name if name in builtins return Trueif name in SPECIAL_BUILTINS return Truereturn False
@require_role 'admin' def asset_del request asset_id request.GET.get 'id' '' if asset_id Asset.objects.filter id asset_id .delete if request.method 'POST' asset_batch request.GET.get 'arg' '' asset_id_all str request.POST.get 'asset_id_all' '' if asset_batch for asset_id in asset_id_all.split ' ' asset get_object Asset id asset_id asset.delete return HttpResponse u'\u5220\u9664\u6210\u529f'
def print_groups_per_container inventory containers get_all_groups inventory required_list ['container_name' 'groups']table prettytable.PrettyTable required_list for container_name groups in containers.iteritems row [container_name ' '.join sorted groups ]table.add_row row for tbl in table.align.keys table.align[tbl] 'l'return table
def getEndIndexConvertEquationValue bracketEndIndex evaluatorIndex evaluators evaluator evaluators[evaluatorIndex]if evaluator.__class__ ! EvaluatorValue return bracketEndIndexif not evaluator.word.startswith 'equation.' return bracketEndIndexif evaluators[ evaluatorIndex + 1 ].word ! ' ' return bracketEndIndexvalueBeginIndex evaluatorIndex + 2 equationValueString ''for valueEvaluatorIndex in xrange valueBeginIndex len evaluators valueEvaluator evaluators[valueEvaluatorIndex]if valueEvaluator.word ' ' or valueEvaluator.word '}' if equationValueString '' return bracketEndIndexelse evaluators[valueBeginIndex] EvaluatorValue equationValueString valueDeleteIndex valueBeginIndex + 1 del evaluators[valueDeleteIndex valueEvaluatorIndex]return bracketEndIndex - valueEvaluatorIndex + valueDeleteIndex equationValueString + valueEvaluator.wordreturn bracketEndIndex
def normalize_line_endings lines newline return [ line.rstrip u'\n\r' + newline for line in lines]
def AddRequestS Handle pIOType Channel Value x1 UserData if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' v ctypes.c_double Value ud ctypes.c_double UserData ec staticLib.AddRequestS Handle pIOType Channel v x1 ud if ec ! 0 raise LabJackException ec else raise LabJackException 0 'FunctiononlysupportedforWindows'
def find_missing_children filters None dryrun False errors []fixed []query Q 'nodes.0' 'exists' True if filters query query & filters with_children models.Node.find query for parent in with_children for child in parent.nodes if not child.node__parent msg u'Inconsistency Child{} {} doesnotpointtoparent{} {} .Attemptingtofix.\n'.format child.title child._primary_key parent.title parent._primary_key logger.info msg errors.append child if dryrun is False child.node__parent.append parent child.save msg u'Fixedinconsistency Child{} {} doesnotpointtoparent{} {} .\n'.format child.title child._primary_key parent.title parent._primary_key logger.info msg fixed.append child return errors fixed
def make_encoding_map decoding_map m {}for k v in decoding_map.items if not v in m m[v] kelse m[v] Nonereturn m
def blend_palette colors n_colors 6 as_cmap False input 'rgb' colors [_color_to_rgb color input for color in colors]name 'blend'pal mpl.colors.LinearSegmentedColormap.from_list name colors if not as_cmap pal _ColorPalette pal np.linspace 0 1 n_colors return pal
def merge_dicts d1 d2 result copy.deepcopy d1 for key value in six.iteritems d2 if isinstance value dict result[key] merge_dicts result[key] value elif key not in result or value is not None result[key] valuereturn result
def get_stdlib_modules modules list sys.builtin_module_names for path in sys.path[1 ] if 'site-packages' not in path modules + module_list path modules set modules if '__init__' in modules modules.remove '__init__' modules list modules return modules
def ts_dlldy y df return - df + 1 / df / 1 + y ** 2 / df * y
def get_exercise_prereqs exercises if exercises exercises get_content_items ids exercises prereqs []for exercise in exercises prereqs + exercise.get 'prerequisites' [] return list set prereqs
def copy_annotations src dest assert len src len dest for src_tok dest_tok in zip src dest dest_tok.annotation src_tok.annotation
def _crop_image_to_square image width height image.sizeif width ! height side width if width < height else height left width - side // 2 top height - side // 2 right width + side // 2 bottom height + side // 2 image image.crop left top right bottom return image
def update_timeline_doc_for timeline_doctype update_for_linked_docs timeline_doctype update_for_dynamically_linked_docs timeline_doctype
def get_exploration_ids_subscribed_to user_id subscriptions_model user_models.UserSubscriptionsModel.get user_id strict False return subscriptions_model.activity_ids if subscriptions_model else []
def find_system_plugins eps []for ep in iter_entry_points group SYSTEM_PLUGINS_ENTRY_POINT_GROUP ep.load eps.append ep.name return eps
def treat_file filename outfp try fp open filename 'r' except OSError sys.stderr.write 'Cannotopen%s\n' % filename returncharno 0lineno 0tags []size 0while 1 line fp.readline if not line breaklineno lineno + 1 m matcher.search line if m tag m.group 0 + '\x7f%d %d\n' % lineno charno tags.append tag size size + len tag charno charno + len line outfp.write '\x0c\n%s %d\n' % filename size for tag in tags outfp.write tag
def find_DN eq var coeff diop_type classify_diop eq _dict False if diop_type 'binary_quadratic' return _find_DN var coeff
def create_finder project name pyname only_calls False imports True unsure None docs False instance None in_hierarchy False keywords True pynames_ set [pyname] filters []if only_calls filters.append CallsFilter if not imports filters.append NoImportsFilter if not keywords filters.append NoKeywordsFilter if isinstance instance pynames.ParameterName for pyobject in instance.get_objects try pynames_.add pyobject[name] except exceptions.AttributeNotFoundError passfor pyname in pynames_ filters.append PyNameFilter pyname if in_hierarchy filters.append InHierarchyFilter pyname if unsure filters.append UnsureFilter unsure return Finder project name filters filters docs docs
def multivariate_t_rvs m S df np.inf n 1 m np.asarray m d len m if df np.inf x 1.0else x np.random.chisquare df n / df z np.random.multivariate_normal np.zeros d S n return m + z / np.sqrt x [ None]
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def quota_usage_get context project_id resource return IMPL.quota_usage_get context project_id resource
def make_request token headers {'Authorization' 'Bearer{}'.format token }conn httplib.HTTPSConnection HOST conn.request 'GET' '/auth/info/googleidtoken' None headers res conn.getresponse conn.close return res.read
def _mkfs root fs_format fs_opts None if fs_opts is None fs_opts {}if fs_format in 'ext2' 'ext3' 'ext4' __salt__['extfs.mkfs'] root fs_format **fs_opts elif fs_format in 'btrfs' __salt__['btrfs.mkfs'] root **fs_opts elif fs_format in 'xfs' __salt__['xfs.mkfs'] root **fs_opts
def get_port_mapper proto 'TCP' import nattraverso.pynupnpreturn nattraverso.pynupnp.get_port_mapper
def walk top topdown True followlinks False names os.listdir top dirs nondirs [] [] for name in names if path.isdir path.join top name dirs.append name else nondirs.append name if topdown yield top dirs nondirs for name in dirs fullpath path.join top name if followlinks or not path.islink fullpath for x in walk fullpath topdown followlinks yield x if not topdown yield top dirs nondirs
def task_package_install package_name distribution package_source PackageSource base_url installer _get_base_url_and_installer_for_distro distribution package_source.build_server package_source.branch return installer package_name distribution package_source base_url
def polynomial_reduce_mod poly polymod p assert polymod[ -1 ] 1 assert len polymod > 1 while len poly > len polymod if poly[ -1 ] ! 0 for i in range 2 len polymod + 1 poly[ - i ] poly[ - i ] - poly[ -1 ] * polymod[ - i ] % p poly poly[0 -1 ]return poly
def truncatechars value arg try length int arg except ValueError return valueif len value > length return value[ length - 3 ] + '...' return value
def factorial n if n < 1 return 1return n * factorial n - 1
@uses_mandrilldef clear_followup_emails_queue email mail_client None if not mail_client items ScheduledJob.objects.filter type ScheduledJob.EMAIL filter_string__iexact email items.delete returnfor email_message in mail_client.messages.list_scheduled to email result mail_client.messages.cancel_scheduled id email_message['_id'] if result.get 'status' 'error' print result.get 'name' result.get 'error' return
def remove_jacket container name find_existing_jacket container if name is not None remove_jacket_images container name container.remove_item name return Truereturn False
def is_html ct_headers url allow_xhtml False if not ct_headers ext os.path.splitext _rfc3986.urlsplit url [2] [1]html_exts ['.htm' '.html']if allow_xhtml html_exts + ['.xhtml']return ext in html_exts ct split_header_words ct_headers [0][0][0]html_types ['text/html']if allow_xhtml html_types + ['text/xhtml' 'text/xml' 'application/xml' 'application/xhtml+xml']return ct in html_types
def list_private_repos profile 'github' repos []for repo in _get_repos profile if repo.private is True repos.append repo.name return repos
def is_masquerading_as_specific_student user course_key course_masquerade get_course_masquerade user course_key return bool course_masquerade and course_masquerade.user_name
def _make_http_response code 200 response requests.Response response.status_code codereturn response
def _check_copy_from_header req return _check_path_header req 'X-Copy-From' 2 'X-Copy-Fromheadermustbeoftheform<containername>/<objectname>'
def rate_limited min_interval def decorate func last_time_called [0.0]def rate_limited_function *args **kargs elapsed time.time - last_time_called[0] log.debug 'Elapsed%fsincelastcall' % elapsed left_to_wait min_interval - elapsed if left_to_wait > 0 log.debug 'Wait%fduetoratelimiting...' % left_to_wait time.sleep left_to_wait ret func *args **kargs last_time_called[0] time.time return retreturn rate_limited_functionreturn decorate
def container_to_string cont if hasattr cont u'__iter__' and not isinstance cont str cont u''.join cont return str cont
def quat2angle_axis quat identity_thresh None w x y z quatvec np.asarray [x y z] if identity_thresh is None try identity_thresh np.finfo vec.dtype .eps * 3 except ValueError identity_thresh FLOAT_EPS * 3 n math.sqrt x * x + y * y + z * z if n < identity_thresh return 0.0 np.array [1.0 0 0] return 2 * math.acos w vec / n
def parse_addon pkg addon None return WebAppParser .parse pkg
def get_exception_for_uncaught_api_error func exc if isinstance exc mongoengine.ValidationError result webob_exc.HTTPBadRequest detail exc.message return resultelif isinstance exc jsonschema.ValidationError result webob_exc.HTTPBadRequest detail exc.message return resultreturn exc
def getCraftedText fileName text '' liftRepository None return getCraftedTextFromText archive.getTextIfEmpty fileName text liftRepository
def everything_but k d assert k in d return concat itervalues keyfilter ne k d
def build_page rex kwargs target_node kwargs.get 'node' or kwargs.get 'project' target_id target_node._iddata {'target_id' target_id}data.update kwargs data.update request.args.to_dict try return rex.format **data except KeyError return None
def solo name **kwargs return _run name 'chef.solo' kwargs
def add_nova for name function in globals .items if not inspect.isfunction function continueargs inspect.getargspec function [0]if args and name.startswith 'nova' exec 'pep8.%s %s' % name name
def thin_sum cachedir form 'sha1' thintar gen_thin cachedir return salt.utils.get_hash thintar form
def install_blas_lapack chdir SRC_DIR apt_install 'libopenblas-dev'
def force_job command name '' frequency 'YEARLY' stop False **kwargs jobs Job.objects.filter command command if jobs.count > 0 job jobs[0]else job Job command command job.frequency frequencyjob.name job.name or name or command job.save if stop job.is_running Falseelse job.next_run datetime.now job.args ''.join [ '%s %s' % k v for k v in kwargs.iteritems ] job.save launch_job not stop and not job.is_running if launch_job if Job.objects.filter disabled False is_running False next_run__lte datetime.now .count > 0 call_command_async 'cron'
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
def is_fp_closed obj try return obj.isclosed except AttributeError passtry return obj.closedexcept AttributeError passtry return obj.fp is None except AttributeError passraise ValueError 'Unabletodeterminewhetherfpisclosed.'
def parseExpected expected_text expected []if expected_text for chunk in expected_text.split ' ' chunk chunk.strip mtype qstuff chunk.split ';' mtype mtype.strip assert '/' in mtype qstuff qstuff.strip q qstr qstuff.split ' ' assert q 'q' qval float qstr expected.append mtype qval return expected
def GetRunlevelsLSB states if not states return set valid set ['0' '1' '2' '3' '4' '5' '6'] _LogInvalidRunLevels states valid return valid.intersection set states.split
def _detach_db_obj func @functools.wraps func def decorator self *args **kwargs synthetic_changed bool self._get_changed_synthetic_fields res func self *args **kwargs if synthetic_changed self.obj_context.session.refresh self.db_obj self.obj_context.session.expunge self.db_obj return resreturn decorator
def get_current_locale return getattr _thread_locals 'locale' None
def printf_format_for_type t types description type_description t types if 'struct' in description specifer printf_format_for_struct t types else specifer description['printf_specifier']return specifer.replace '"' '\\"'
def test_summary np.random.seed 4323 n 100exog np.random.normal size n 2 exog[ 0] 1endog np.random.normal size n for method in 'irls' 'cg' fa sm.families.Gaussian model sm.GLM endog exog family fa rslt model.fit method method s rslt.summary
def apphook_post_title_checker instance **kwargs if instance.publisher_is_draft returnold_title getattr instance '_old_data' None if not old_title if instance.page.application_urls request_finished.connect trigger_restart dispatch_uid DISPATCH_UID else old_values old_title.published old_title.page.application_urls old_title.page.application_namespace old_title.path old_title.slug new_values instance.published instance.page.application_urls instance.page.application_namespace instance.path instance.slug if old_values ! new_values and old_values[2] or new_values[2] request_finished.connect trigger_restart dispatch_uid DISPATCH_UID
def rename_abe_sequences_key store try data store.selectall '\nSELECTDISTINCTkey nextid\nFROMabe_sequences' except Exception store.rollback returnstore.log.info 'copyingsequencepositions %s' data store.ddl 'DROPTABLEabe_sequences' store.ddl 'CREATETABLEabe_sequences \nsequence_keyVARCHAR 100 PRIMARYKEY \nnextidNUMERIC 30 \n ' for row in data store.sql 'INSERTINTOabe_sequences sequence_key nextid VALUES ? ? ' row
def _is_query_precomputed query rules list query._rules while rules rule rules.pop if isinstance rule BooleanOp rules.extend rule.ops continueif rule.lval.name '_date' return Truereturn False
def showinfo title None message None **options return _show title message INFO OK **options
def _OutputFormat return _cpplint_state.output_format
def pkginfo name version arch repoid pkginfo_tuple collections.namedtuple 'PkgInfo' 'name' 'version' 'arch' 'repoid' return pkginfo_tuple name version arch repoid
def quopri_encode input errors 'strict' assert errors 'strict' f StringIO str input g StringIO quopri.encode f g quotetabs True output g.getvalue return output len input
def _parse_search_term s s s.strip split s.split maxsplit 1 if len split 2 engine split[0]try config.get 'searchengines' engine except configexc.NoOptionError engine Noneterm selse term split[1]elif not split raise ValueError 'Emptysearchterm!' else engine Noneterm slog.url.debug 'engine{} term{!r}'.format engine term return engine term
def get_current_target module module_parameter None action_parameter None result exec_action module 'show' module_parameter module_parameter action_parameter action_parameter [0]if not result return Noneif result ' unset ' return Nonereturn result
def ForgetAboutTypelibInterface typelib_ob tla typelib_ob.GetLibAttr guid tla[0]lcid tla[1]major tla[3]minor tla[4]info str guid lcid major minor try del demandGeneratedTypeLibraries[info]except KeyError print 'ForgetAboutTypelibInterface Warning-typelibrarywithinfo%sisnotbeingremembered!' % info for key val in list versionRedirectMap.items if val info del versionRedirectMap[key]
def move_items lib dest query copy album items albums _do_query lib query album False objs albums if album else items action 'Copying' if copy else 'Moving' entity 'album' if album else 'item' log.info u'{0}{1}{2}s.'.format action len objs entity for obj in objs log.debug u'moving {0}'.format util.displayable_path obj.path obj.move copy basedir dest obj.store
def assets_depreciate assets Asset.objects.all for asset in assets if not asset.trash asset.set_current_value
def get_exe_version exe args [u'--version'] version_re u'version\\s+ [0-9._-a-zA-Z]+ ' unrecognized u'present' try out err subprocess.Popen [exe] + args stdout subprocess.PIPE stderr subprocess.STDOUT .communicate except OSError return Falsefirstline out.partition '\n' [0].decode u'ascii' u'ignore' m re.search version_re firstline if m return m.group 1 else return unrecognized
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def intersection_all graphs graphs iter graphs R next graphs for H in graphs R nx.intersection R H return R
def is_resource_modified environ etag None data None last_modified None if etag is None and data is not None etag generate_etag data elif data is not None raise TypeError 'bothdataandetaggiven' if environ['REQUEST_METHOD'] not in 'GET' 'HEAD' return Falseunmodified Falseif isinstance last_modified basestring last_modified parse_date last_modified if last_modified is not None last_modified last_modified.replace microsecond 0 modified_since parse_date environ.get 'HTTP_IF_MODIFIED_SINCE' if modified_since and last_modified and last_modified < modified_since unmodified Trueif etag if_none_match parse_etags environ.get 'HTTP_IF_NONE_MATCH' if if_none_match unmodified if_none_match.contains_raw etag return not unmodified
def testing_off name reload False ret {'name' 'testingmode' 'changes' {} 'result' True 'comment' 'TestingmodealreadyOFF.'}result {}testing __salt__['csf.get_testing_status'] if int testing 0 return retdisable __salt__['csf.disable_testing_mode'] if disable comment 'Csftestingmodedisabled'if reload if __salt__['csf.reload'] comment + 'andcsfreloaded.'ret['changes']['TestingMode'] 'off'ret['comment'] commentreturn ret
def sdb_get uri opts if not isinstance uri string_types return uriif not uri.startswith 'sdb //' return urisdlen len 'sdb //' indx uri.find '/' sdlen if indx -1 or len uri[ indx + 1 ] 0 return uriprofile opts.get uri[sdlen indx] {} if not profile profile opts.get 'pillar' {} .get uri[sdlen indx] {} if 'driver' not in profile return urifun '{0}.get'.format profile['driver'] query uri[ indx + 1 ]loaded_db salt.loader.sdb opts fun return loaded_db[fun] query profile profile
def parse_nms_url url pr urlparse.urlparse url scheme pr.schemeauto scheme 'auto' if auto scheme 'http'user 'admin'password 'nexenta'if '@' not in pr.netloc host_and_port pr.netlocelse user_and_password host_and_port pr.netloc.split '@' 1 if ' ' in user_and_password user password user_and_password.split ' ' else user user_and_passwordif ' ' in host_and_port host port host_and_port.split ' ' 1 else host port host_and_port '2000' return auto scheme user password host port '/rest/nms/'
@decoratordef rollback_open_connections fn *args **kw try fn *args **kw finally testing_reaper.rollback_all
def mv_file_s3 s3_connection src_path dst_path src_bucket_name src_key_name _from_path src_path dst_bucket_name dst_key_name _from_path dst_path src_bucket s3_connection.get_bucket src_bucket_name k boto.s3.Key src_bucket k.key src_key_namek.copy dst_bucket_name dst_key_name k.delete
def make_raw query exclude None rows []for instance in query data model_to_dict instance exclude exclude '\nInDjango1.10 model_to_dictresolvesManyToManyFieldasaQuerySet.\nPreviously weusedtogetprimarykeys.Followingcodeconvertsthe\nQuerySetintoprimarykeys.\nForreference https //www.mail-archive.com/django-updates@googlegroups.com/msg163020.html\n'for field in instance._meta.many_to_many value data[field.name]if isinstance value QuerySet data[field.name] [row.pk for row in value]rows.append data return rows
def _HCCM1 results scale if scale.ndim 1 H np.dot results.model.pinv_wexog scale[ None] * results.model.pinv_wexog.T else H np.dot results.model.pinv_wexog np.dot scale results.model.pinv_wexog.T return H
def find_bricks top_bricks predicate found []visited set to_visit deque top_bricks while len to_visit > 0 current to_visit.popleft if current not in visited visited.add current if predicate current found.append current to_visit.extend current.children return found
def generate_password length 12 chars string.letters + string.digits choice random.SystemRandom .choicereturn ''.join [choice chars for _i in range length ]
def _task_update context task_ref values session None if 'deleted' not in values values['deleted'] Falsetask_ref.update values task_ref.save session session return task_ref
def PackUser name value pbvalue pbvalue.mutable_uservalue .set_email value.email .encode 'utf-8' pbvalue.mutable_uservalue .set_auth_domain value.auth_domain .encode 'utf-8' pbvalue.mutable_uservalue .set_gaiaid 0 if value.user_id is not None pbvalue.mutable_uservalue .set_obfuscated_gaiaid value.user_id .encode 'utf-8' if value.federated_identity is not None pbvalue.mutable_uservalue .set_federated_identity value.federated_identity .encode 'utf-8' if value.federated_provider is not None pbvalue.mutable_uservalue .set_federated_provider value.federated_provider .encode 'utf-8'
def call_service sample operation Nonewhile operation not in ['c' 'C' 'g' 'G' 'u' 'U' 'd' 'D' 'q' 'Q'] operation raw_input 'Do[c create|g get|u update|d delete|q quit] ' operation operation.lower if operation 'q' return 'n'resource_properties get_input operation if operation 'c' sample.create resource_properties elif operation 'g' sample.get resource_properties['resource_id'] elif operation 'u' sample.update resource_properties elif operation 'd' sample.delete resource_properties['resource_id'] do_continue Nonewhile do_continue not in ['' 'y' 'Y' 'n' 'N'] do_continue raw_input 'Wanttocontinue Y/n ' if do_continue '' do_continue 'y'return do_continue.lower
def is_pid_running pid if os.name 'nt' return _is_pid_running_on_windows pid else return _is_pid_running_on_unix pid
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def pairwise_distances_argmin X Y axis 1 metric 'euclidean' batch_size 500 metric_kwargs None if metric_kwargs is None metric_kwargs {}return pairwise_distances_argmin_min X Y axis metric batch_size metric_kwargs [0]
@receiver pre_save sender User def disable_anon_user_password_save sender **kwargs instance kwargs['instance']if instance.username ANONYMOUS_USER_NAME and instance.has_usable_password raise ValueError 'Anonymoususercannothaveusablepassword!'
def regexp_to_list pattern @none_if_emptydef regexp_to_list_lambda value result re.findall pattern value if result [] return Nonereturn resultreturn regexp_to_list_lambda
@real_memoizedef is_netbsd return sys.platform.startswith 'netbsd'
def combine_paths *paths return expand_path combine_values *paths
def get_policy_index req_headers res_headers header 'X-Backend-Storage-Policy-Index'policy_index res_headers.get header req_headers.get header return str policy_index if policy_index is not None else None
def get_element_by_id id html return get_element_by_attribute u'id' id html
def get_tool_path_by_shed_tool_conf_filename app shed_tool_conf for shed_tool_conf_dict in app.toolbox.dynamic_confs include_migrated_tool_conf True config_filename shed_tool_conf_dict['config_filename']if config_filename shed_tool_conf return shed_tool_conf_dict['tool_path']else file_name basic_util.strip_path config_filename if file_name shed_tool_conf return shed_tool_conf_dict['tool_path']return None
def test_settext_empty mocker qtbot label TextBase qtbot.add_widget label mocker.patch 'qutebrowser.mainwindow.statusbar.textbase.TextBase.repaint' autospec True label.setText '' label.repaint.assert_called_with
def read_metric *args ret {}if _TRAFFICCTL cmd _traffic_ctl 'metric' 'get' else cmd _traffic_line '-r' try for arg in args log.debug 'Querying %s' arg ret[arg] _subprocess '{0}{1}'.format cmd arg except KeyError passreturn ret
def format_html_join sep format_string args_generator return mark_safe conditional_escape sep .join format_html format_string *tuple args for args in args_generator
@must_have_permission ADMIN @must_be_valid_projectdef get_draft_registrations auth node *args **kwargs count request.args.get 'count' 100 drafts itertools.islice node.draft_registrations_active 0 count serialized_drafts [serialize_draft_registration d auth for d in drafts]sorted_serialized_drafts sorted serialized_drafts key itemgetter 'updated' reverse True return {'drafts' sorted_serialized_drafts} http.OK
def task_has_custom task attr return mro_lookup task.__class__ attr stop {BaseTask object} monkey_patched [u'celery.app.task']
def initLogger obj if inspect.isclass obj myClass objelse myClass obj.__class__logger logging.getLogger '.'.join ['com.numenta' myClass.__module__ myClass.__name__] return logger
def iscsi_get_sessions cmd 'iscsiadm--modesession'output utils.system_output cmd ignore_status True sessions []if 'Noactivesessions' not in output for session in output.splitlines ip_addr session.split [2].split ' ' [0]target session.split [3]sessions.append ip_addr target return sessions
@gof.local_optimizer [T.mul] def local_mul_zero node if node.op T.mul otype node.outputs[0].typefor i in node.inputs try value get_scalar_constant_value i except NotScalarConstantError continueif value 0 return _fill_chain theano._asarray 0 dtype otype.dtype node.inputs
@register.filter name 'angular_escapes' def angular_escapes value return value.replace '\\' '\\\\' .replace '"' '\\"' .replace "'" "\\'" .replace '\n' '\\n' .replace '\r' '\\r'
def estimate_optimal_with_K_and_f num_kmers des_fp_rate n_tables math.log des_fp_rate 0.5 int_n_tables int n_tables if int_n_tables 0 int_n_tables 1ht_size int - num_kmers / math.log 1 - des_fp_rate ** 1 / float int_n_tables mem_cap ht_size * int_n_tables fp_rate 1 - math.exp - num_kmers / float ht_size ** int_n_tables res namedtuple u'result' [u'num_htables' u'htable_size' u'mem_use' u'fp_rate'] return res int_n_tables ht_size mem_cap fp_rate
def close_issue issue github_auth closed_issue issue.copy closed_issue['state'] 'closed'r requests.post 'https //api.github.com/repos/Khan/khan-exercises/issues/%s' % issue['number'] data json.dumps closed_issue auth github_auth try r.raise_for_status time.sleep 1 return Trueexcept requests.HTTPError return False
def ungroup expr return TokenConverter expr .setParseAction lambda t t[0]
def restrict_dict d keys return {k v for k v in six.iteritems d if k in keys }
def manage_mode mode return salt.utils.normalize_mode mode
def _grains host protocol None port None username password find_credentials DETAILS['host'] ret __salt__['vsphere.system_info'] host host username username password password protocol protocol port port GRAINS_CACHE.update ret return GRAINS_CACHE
def _formatActualSchema schema title schema_store yield '..hidden-code-block json' yield ' label ' + title yield ' starthidden True' yield '' schema resolveSchema schema schema_store lines json.dumps schema indent 4 separators ' ' ' ' sort_keys True .splitlines for line in lines yield '' + line yield ''
def ppcc_plot x a b dist 'tukeylambda' plot None N 80 if b < a raise ValueError '`b`hastobelargerthan`a`.' svals np.linspace a b num N ppcc np.empty_like svals for k sval in enumerate svals _ r2 probplot x sval dist dist fit True ppcc[k] r2[ -1 ]if plot is not None plot.plot svals ppcc 'x' _add_axis_labels_title plot xlabel 'ShapeValues' ylabel 'ProbPlotCorr.Coef.' title ' %s PPCCPlot' % dist return svals ppcc
def get_add_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'add_page' check_global check_global use_cache use_cache return page_ids
def menu_style type default 'dropdown' '' d dict lightdrop 'dropdown' 'lightdrop' tabdrop 'dropdown' 'tabdrop' srdrop 'dropdown' 'srdrop' flatlist 'flatlist' 'flat-list' tabmenu 'tabmenu' '' formtab 'tabmenu' 'formtab' flat_vert 'flatlist' 'flat-vert' return d.get type default
def test_multiple_samples_allowed encoding_model MLP layers [Linear layer_name 'h' dim 10 irange 0.01 ] decoding_model MLP layers [Linear layer_name 'h' dim 10 irange 0.01 ] prior DiagonalGaussianPrior conditional BernoulliVector mlp decoding_model name 'conditional' posterior DiagonalGaussian mlp encoding_model name 'posterior' vae VAE nvis 10 prior prior conditional conditional posterior posterior nhid 5 X T.matrix 'X' lower_bound vae.log_likelihood_lower_bound X num_samples 10 f theano.function inputs [X] outputs lower_bound rng make_np_rng default_seed 11223 f as_floatX rng.uniform size 10 10
def sparse_categorical_crossentropy y_true y_pred y_true tf.cast y_true tf.int64 y_pred logit tf.cast y_pred tf.float32 return tf.reduce_mean tf.nn.sparse_softmax_cross_entropy_with_logits y_pred y_true
def __import__ name globals None locals None fromlist None try return sys.modules[name]except KeyError passmodule_name name.split '.' [ -1 ]module_path os.path.join EXAMPLE_DIR *name.split '.' [ -1 ] fp pathname description imp.find_module module_name [module_path] try return imp.load_module module_name fp pathname description finally if fp fp.close
def build_template_error_formatters formatters []def mako_html_data exc_value if isinstance exc_value mako.exceptions.CompileException mako.exceptions.SyntaxException return mako.exceptions.html_error_template .render full False css False if isinstance exc_value AttributeError and exc_value.args[0].startswith "'Undefined'objecthasnoattribute" return mako.exceptions.html_error_template .render full False css False formatters.append mako_html_data return formatters
def copy_int_little src dest word src.read 4 dest.write word val unpack '<I' word return val
def simplefilter f return type f.__name__ FunctionFilter {'function' f '__module__' getattr f '__module__' '__doc__' f.__doc__}
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def _inherit_docstrings cls for name method in cls.__dict__.items if name.startswith '_' or not callable method continueupstream_method getattr Authenticator name None if not method.__doc__ method.__doc__ upstream_method.__doc__return cls
def _get_object objname objtype ret Noneif objname is None return retif isinstance objname string_types if objname in __opts__ ret __opts__[objname]master_opts __pillar__.get 'master' {} if objname in master_opts ret master_opts[objname]if objname in __pillar__ ret __pillar__[objname]elif isinstance objname objtype ret objnameif not isinstance ret objtype ret Nonereturn ret
def formatters *chained_formatters def formatters_chain input_string for chained_formatter in chained_formatters input_string chained_formatter input_string return input_stringreturn formatters_chain
def _task_format task_ref task_info_ref None task_dict {'id' task_ref['id'] 'type' task_ref['type'] 'status' task_ref['status'] 'owner' task_ref['owner'] 'expires_at' task_ref['expires_at'] 'created_at' task_ref['created_at'] 'updated_at' task_ref['updated_at'] 'deleted_at' task_ref['deleted_at'] 'deleted' task_ref['deleted']}if task_info_ref task_info_dict {'input' task_info_ref['input'] 'result' task_info_ref['result'] 'message' task_info_ref['message']}task_dict.update task_info_dict return task_dict
@register u'unix-line-discard' def unix_line_discard event buff event.current_bufferif buff.document.cursor_position_col 0 and buff.document.cursor_position > 0 buff.delete_before_cursor count 1 else deleted buff.delete_before_cursor count - buff.document.get_start_of_line_position event.cli.clipboard.set_text deleted
def serializers opts return LazyLoader _module_dirs opts 'serializers' opts tag 'serializers'
def limitedMemory limit func *args **kw clearCaches max_rss getMemorySize if max_rss is not None old_limit getMemoryLimit limit max_rss + limit limited setMemoryLimit limit else limited Falsetry return func *args **kw finally if limited setMemoryLimit old_limit clearCaches
@_FFI.callback u'ValueBuffer ExternContext* Value* Field* ' def extern_project_multi context_handle val field c _FFI.from_handle context_handle obj c.from_value val field_name c.from_key field projected tuple c.to_value p for p in getattr obj field_name return c.vals_buf projected len projected
def nfs_shares attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'nfs_shares' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
@bdd.then bdd.parsers.parse 'thepageshouldcontaintheplaintext"{text}"' def check_contents_plain quteproc text content quteproc.get_content .strip assert text in content
def seek_end_of_string module_data start_line start_col next_node_line next_node_col raise NotImplementedError 'Findingendofstringnotyetimplemented'
def preprocess_for_train image output_height output_width padding _PADDING tf.image_summary 'image' tf.expand_dims image 0 image tf.to_float image if padding > 0 image tf.pad image [[padding padding] [padding padding] [0 0]] distorted_image tf.random_crop image [output_height output_width 3] distorted_image tf.image.random_flip_left_right distorted_image tf.image_summary 'distorted_image' tf.expand_dims distorted_image 0 distorted_image tf.image.random_brightness distorted_image max_delta 63 distorted_image tf.image.random_contrast distorted_image lower 0.2 upper 1.8 return tf.image.per_image_whitening distorted_image
def html_publisher registry xml_parent data reporter XML.SubElement xml_parent 'htmlpublisher.HtmlPublisher' targets XML.SubElement reporter 'reportTargets' ptarget XML.SubElement targets 'htmlpublisher.HtmlPublisherTarget' mapping [ 'name' 'reportName' None 'dir' 'reportDir' None 'files' 'reportFiles' None 'link-to-last-build' 'alwaysLinkToLastBuild' False 'keep-all' 'keepAll' False 'allow-missing' 'allowMissing' False ]helpers.convert_mapping_to_xml ptarget data mapping fail_required True XML.SubElement ptarget 'wrapperName' .text 'htmlpublisher-wrapper.html'
def getPathOutput creationFirst derivation translation vector3GearProfileFirst vector3GearPaths xmlElement vector3GearProfileFirst lineation.getPackedGeometryOutputByLoop lineation.SideLoop vector3GearProfileFirst xmlElement if creationFirst 'f' return vector3GearProfileFirstpackedGearGeometry []for vector3GearPath in vector3GearPaths packedGearGeometry + lineation.getPackedGeometryOutputByLoop lineation.SideLoop vector3GearPath xmlElement if creationFirst 's' return packedGearGeometryeuclidean.translateVector3Paths packedGearGeometry translation return vector3GearProfileFirst + packedGearGeometry
@Profiler.profiledef test_orm_query_cols_only n session Session bind engine for id_ in random.sample ids n session.query Customer.id Customer.name Customer.description .filter Customer.id id_ .one
def compute_full_text get_deps_dict buff StringIO sep ' ' * 80 + '\n' buff.write get_deps_dict['spec'].text buff.write '\n' for d in get_deps_dict['uniquedeps'] buff.write sep buff.write 'MSG %s\n' % d buff.write roslib.msgs.get_registered d .text buff.write '\n' return buff.getvalue [ -1 ]
def _clear_weights Distance.__dict__['_weights'].computed False
def truncate content length 100 suffix '...' if len content < length return contentelse return content[ length].rsplit '' 1 [0] + suffix
def add_or_update priority name code None load_order existing_code _existing_info name True if load_order is not None if not code code _default_loader name if load_order priority and code.strip existing_code.strip returnremove name swap_event.wait add priority name code
def trasnlate js HEADER DEFAULT_HEADER return translate_js js HEADER
def test_get_syslog_facility_notempty monkeypatch monkeypatch.setenv 'WALE_SYSLOG_FACILITY' 'local0' out valid_facility log_help.get_syslog_facility assert valid_facility is True assert out handlers.SysLogHandler.LOG_LOCAL0 monkeypatch.setenv 'WALE_SYSLOG_FACILITY' 'user' out valid_facility log_help.get_syslog_facility assert valid_facility is True assert out handlers.SysLogHandler.LOG_USER
def wr_long f x f.write chr x & 255 f.write chr x >> 8 & 255 f.write chr x >> 16 & 255 f.write chr x >> 24 & 255
@commands u'ety' @example u'.etyword' def f_etymology bot trigger word trigger.group 2 try result etymology word except IOError msg u"Can'tconnecttoetymonline.com %s " % etyuri % word bot.msg trigger.sender msg return NOLIMITexcept AttributeError TypeError result Noneif result is not None bot.msg trigger.sender result else uri etysearch % word msg u'Can\'tfindtheetymologyfor"%s".Try%s' % word uri bot.msg trigger.sender msg return NOLIMIT
def detect stream try json.loads stream return Trueexcept ValueError return False
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def getLoopsIntersectionByPair importRadius loopsFirst loopsLast radiusSide 0.01 * importRadius corners getLoopsListsIntersections [loopsFirst loopsLast] corners + getInsetPointsByInsetLoops loopsFirst True loopsLast radiusSide corners + getInsetPointsByInsetLoops loopsLast True loopsFirst radiusSide allPoints corners[ ]allPoints + getInsetPointsByInsetLoops getInBetweenLoopsFromLoops importRadius loopsFirst True loopsLast radiusSide allPoints + getInsetPointsByInsetLoops getInBetweenLoopsFromLoops importRadius loopsLast True loopsFirst radiusSide return trianglemesh.getDescendingAreaLoops allPoints corners importRadius
def test_mixed_inheritance class foo passclass bar object passclass baz1 foo bar passclass baz2 bar foo passAreEqual baz1.__bases__ foo bar AreEqual baz2.__bases__ bar foo class foo abc 3class bar object def get_abc return 42def set_abc passabc property fget get_abc fset set_abc class baz foo bar passAreEqual baz .abc 3
def reorient_bvecs in_dwi old_dwi in_bvec import osimport numpy as npimport nibabel as nb name fext os.path.splitext os.path.basename in_bvec if fext u'.gz' name _ os.path.splitext name out_file os.path.abspath u'%s_reorient.bvec' % name bvecs np.loadtxt in_bvec .Tnew_bvecs []N nb.load in_dwi .affineO nb.load old_dwi .affineRS N.dot np.linalg.inv O [ 3 3]sc_idx np.where np.abs RS ! 1 & RS ! 0 S np.ones_like RS S[sc_idx] RS[sc_idx]R RS / S new_bvecs [R.dot b for b in bvecs]np.savetxt out_file np.array new_bvecs .T fmt '%0.15f' return out_file
def bulk_update_public context data_dict _check_access 'bulk_update_public' context data_dict _bulk_update_dataset context data_dict {'private' False}
def check_run_quick command echo True result run_quick command echo if result.returncode error 'FAILEDwithexitcode{code}\n\nCommandwas{command}\n\nErrorwas{stdout}'.format code result.returncode command command stdout result.stdout raise RuntimeError error return result
def is_nnf expr simplified True expr sympify expr if is_literal expr return Truestack [expr]while stack expr stack.pop if expr.func in And Or if simplified args expr.argsfor arg in args if Not arg in args return Falsestack.extend expr.args elif not is_literal expr return Falsereturn True
def _CreateConfigParserFromConfigString config_string if config_string[0] ! '{' or config_string[ -1 ] ! '}' raise StyleConfigError "Invalidstyledictsyntax '{}'.".format config_string config py3compat.ConfigParser config.add_section 'style' for key value in re.findall ' [a-zA-Z0-9_]+ \\s*[ ]\\s* [a-zA-Z0-9_]+ ' config_string config.set 'style' key value return config
def delPrivacyList disp listname resp disp.SendAndWaitForResponse Iq 'set' NS_PRIVACY payload [Node 'list' {'name' listname} ] if isResultNode resp return 1
def rtb_changed route_tables None vpc_conn None module None vpc None igw None rtb_len len route_tables + 1 remote_rtb_len len vpc_conn.get_all_route_tables filters {'vpc_id' vpc.id} if remote_rtb_len ! rtb_len return Truefor rt in route_tables rt_id Nonefor sn in rt['subnets'] rsn vpc_conn.get_all_subnets filters {'cidr' sn 'vpc_id' vpc.id} if len rsn ! 1 module.fail_json msg 'Thesubnet{0}toassociatewithroute_table{1}doesnotexist aborting'.format sn rt nrt vpc_conn.get_all_route_tables filters {'vpc_id' vpc.id 'association.subnet-id' rsn[0].id} if not nrt return Trueelse nrt nrt[0]if not rt_id rt_id nrt.idif not routes_match rt['routes'] nrt igw return Truecontinueelif rt_id nrt.id continueelse return Truereturn Truereturn False
def guard_invalid_slice context builder typ slicestruct if typ.has_step cgutils.guard_null context builder slicestruct.step ValueError 'slicestepcannotbezero'
def _tag_from_clark name match CLARK_TAG_REGEX.match name if match and match.group 'namespace' in NAMESPACES_REV args {'ns' NAMESPACES_REV[match.group 'namespace' ] 'tag' match.group 'tag' }return '% ns s % tag s' % args return name
def group_followee_list context data_dict _check_access 'group_followee_list' context data_dict return _group_or_org_followee_list context data_dict is_org False
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def get_path_to_toplevel_modules filename curr_dir os.path.dirname os.path.abspath filename pattern '__init__.py'try for i in range 10 files set os.listdir curr_dir if pattern in files curr_dir os.path.dirname curr_dir else return curr_direxcept IOError passreturn None
def cert_is_san cert if len cert_get_domains cert > 1 return True
def _get_course_creator_status user if user.is_staff course_creator_status 'granted'elif settings.FEATURES.get 'DISABLE_COURSE_CREATION' False course_creator_status 'disallowed_for_this_site'elif settings.FEATURES.get 'ENABLE_CREATOR_GROUP' False course_creator_status get_course_creator_status user if course_creator_status is None add_user_with_status_unrequested user course_creator_status get_course_creator_status user else course_creator_status 'granted'return course_creator_status
def parse_tags text if not text return []return Parser variant 'tags' .parse_tags text
def test_SAMPHubError SAMPHubError 'test'
def list_active_vms conn __get_conn vms []for id_ in conn.listDomainsID vms.append conn.lookupByID id_ .name return vms
def batches2string batches s [''] * batches[0].shape[0] for b in batches s [''.join x for x in zip s characters b ]return s
def PBKDF1 password salt dkLen count 1000 hashAlgo None if not hashAlgo hashAlgo SHA1password tobytes password pHash hashAlgo.new password + salt digest pHash.digest_sizeif dkLen > digest raise TypeError 'Selectedhashalgorithmhasatooshortdigest %dbytes .' % digest if len salt ! 8 raise ValueError 'Saltisnot8byteslong.' for i in xrange count - 1 pHash pHash.new pHash.digest return pHash.digest [ dkLen]
def Not query return ' NOT%s ' % query
def clean_hosts hosts default_port None cleaned_hosts []for cur_host in [host.strip for host in hosts.split ' ' if host.strip ] cleaned_host clean_host cur_host default_port if cleaned_host cleaned_hosts.append cleaned_host cleaned_hosts ' '.join cleaned_hosts if cleaned_hosts else '' return cleaned_hosts
def get_meta doctype cached True import frappe.model.metareturn frappe.model.meta.get_meta doctype cached cached
def libvlc_audio_get_delay p_mi f _Cfunctions.get 'libvlc_audio_get_delay' None or _Cfunction 'libvlc_audio_get_delay' 1 None ctypes.c_int64 MediaPlayer return f p_mi
def get_num_args f if inspect.ismethod f return f.__func__.__code__.co_argcount - 1 elif inspect.isfunction f return f.__code__.co_argcountelse raise TypeError u'fshouldbeafunctionoramethod'
def qnwtrap n a b return _make_multidim_func _qnwtrap1 n a b
def frames_iter socket while True n next_frame_size socket if n 0 breakwhile n > 0 result read socket n n - len result yield result
def img_as_uint image force_copy False return convert image np.uint16 force_copy
def get_edxnotes_id_token user try client Client.objects.get name CLIENT_NAME except Client.DoesNotExist raise ImproperlyConfigured 'OAuth2Clientwithname[{}]doesnotexist.'.format CLIENT_NAME scopes ['email' 'profile']expires_in settings.OAUTH_ID_TOKEN_EXPIRATIONjwt JwtBuilder user secret client.client_secret .build_token scopes expires_in aud client.client_id return jwt
def test_lex_integers objs tokenize '42' assert objs [HyInteger 42 ]
def test_validate_coord result conesearch._validate_coord ICRS 6.02233 * u.degree -72.08144 * u.degree np.testing.assert_allclose result [6.022330000000011 -72.08144 ] result conesearch._validate_coord SkyCoord 6.02233 * u.degree -72.08144 * u.degree frame u'icrs' np.testing.assert_allclose result [6.022330000000011 -72.08144 ] result conesearch._validate_coord 0 0 np.testing.assert_allclose result [0 0] result conesearch._validate_coord -1 -1 np.testing.assert_allclose result [359 -1 ]
def dt_to_http dt return dt.strftime '%a %d%b%Y%H %M %SGMT'
def open_file filename mode 'r' encoding None errors 'strict' lazy False atomic False if lazy return LazyFile filename mode encoding errors atomic atomic f should_close open_stream filename mode encoding errors atomic atomic if not should_close f KeepOpenFile f return f
def make_canvas parent width 0 height 0 hbar 1 vbar 1 fill BOTH expand 1 pack 1 class_ None name None takefocus None hbar vbar frame make_scrollbars parent hbar vbar pack class_ class_ name name takefocus takefocus widget Canvas frame scrollregion 0 0 width height name 'canvas' if width widget.config width width if height widget.config height height widget.pack expand expand fill fill side LEFT set_scroll_commands widget hbar vbar return widget frame
def mro_lookup cls attr stop set monkey_patched [] for node in cls.mro if node in stop try value node.__dict__[attr]module_origin value.__module__except AttributeError KeyError passelse if module_origin not in monkey_patched return nodereturnif attr in node.__dict__ return node
def normal_approximation_to_binomial n p mu p * n sigma math.sqrt p * 1 - p * n return mu sigma
def complete_hybi00 headers challenge key1 headers['Sec-WebSocket-Key1']key2 headers['Sec-WebSocket-Key2']first int ''.join i for i in key1 if i in digits // key1.count '' second int ''.join i for i in key2 if i in digits // key2.count '' nonce pack '>II8s' first second challenge return md5 nonce .digest
def processors return Rebulk .rules EnlargeGroupMatches EquivalentHoles RemoveAmbiguous SeasonYear Processors
def set_ key value profile None conn salt.utils.memcached.get_conn profile time profile.get 'expire' DEFAULT_EXPIRATION return salt.utils.memcached.set_ conn key value time time
@task queue 'web' time_limit EMAIL_TIME_LIMIT def send_email_task recipient subject template template_html context None msg EmailMultiAlternatives subject get_template template .render context settings.DEFAULT_FROM_EMAIL [recipient] try msg.attach_alternative get_template template_html .render context 'text/html' except TemplateDoesNotExist passmsg.send log.info 'Sentemailtorecipient %s' recipient
def _checkPrefix ip prefixlen version bits _ipVersionToLen version if prefixlen < 0 or prefixlen > bits return Noneif ip 0 zbits bits + 1 else zbits _count0Bits ip if zbits < bits - prefixlen return 0else return 1
def LineEnding lines endings {CRLF 0 CR 0 LF 0}for line in lines if line.endswith CRLF endings[CRLF] + 1elif line.endswith CR endings[CR] + 1elif line.endswith LF endings[LF] + 1return sorted endings key endings.get reverse True or [LF] [0]
@oncedef install_logging_hook _patch_logger
def _CheckPrefix prefix return _ValidateString prefix 'prefix' MAXIMUM_FIELD_PREFIX_LENGTH empty_ok True
@_docstring 'urls' browse True def browse_urls resource None includes [] limit None offset None valid_includes VALID_BROWSE_INCLUDES['urls']params {'resource' resource}return _browse_impl 'url' includes valid_includes limit offset params
@should_dump_tracemallocdef stop_tracemalloc_dump cancel_thread SAVE_TRACEMALLOC_PTR dump_tracemalloc
def _expand_config config defaults defaults.update config return defaults
def _is_ascii_encoding encoding if encoding is None return Falsetry return codecs.lookup encoding .name 'ascii' except LookupError return False
def write_Fasta_from_name_seq_pairs name_seqs fh if fh is None raise ValueError 'Needopenfilehandletowriteto.' for name seq in name_seqs fh.write '%s\n' % BiologicalSequence seq id name .to_fasta
def double_urlencode t return urllib.quote urllib.quote t
def _get_timestamp data position dummy0 dummy1 dummy2 end position + 8 inc timestamp _UNPACK_TIMESTAMP data[position end] return Timestamp timestamp inc end
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def ckan_before_request app_globals.app_globals._check_uptodate identify_user
def ulp_abs_check expected got ulp_tol abs_tol ulp_error abs to_ulps expected - to_ulps got abs_error abs expected - got if abs_error < abs_tol or ulp_error < ulp_tol return Noneelse fmt 'error { .3g} { d}ulps ;permittederror { .3g}or{ d}ulps'return fmt.format abs_error ulp_error abs_tol ulp_tol
def get_project_groups_roles request project groups_roles collections.defaultdict list project_role_assignments role_assignments_list request project project for role_assignment in project_role_assignments if not hasattr role_assignment 'group' continuegroup_id role_assignment.group['id']role_id role_assignment.role['id']if 'project' in role_assignment.scope and role_assignment.scope['project']['id'] project groups_roles[group_id].append role_id return groups_roles
def detrend x order 1 axis -1 from scipy.signal import detrendif axis > len x.shape raise ValueError 'xdoesnothave%daxes' % axis if order 0 fit 'constant'elif order 1 fit 'linear'else raise ValueError 'ordermustbe0or1' y detrend x axis axis type fit return y
def process_image source processor_options processors None global _default_processorsif processors is None if _default_processors is None _default_processors [import_string name for name in VERSION_PROCESSORS]processors _default_processorsimage sourcefor processor in processors image processor image **processor_options return image
@app.template_filter 'external_url' def external_url url url_pattern '^ https? //.*$'scheme re.match url_pattern url if not scheme url_root request.url_root.rstrip '/' return '{}{}'.format url_root url else return url
def _GetRemoteAppId url throttle email passin raw_input_fn raw_input password_input_fn getpass.getpass throttle_class None scheme host_port url_path _ _ urlparse.urlsplit url secure scheme 'https' throttled_rpc_server_factory remote_api_throttle.ThrottledHttpRpcServerFactory throttle throttle_class throttle_class def AuthFunction return _AuthFunction host_port email passin raw_input_fn password_input_fn app_id server remote_api_stub.GetRemoteAppId host_port url_path AuthFunction rpc_server_factory throttled_rpc_server_factory secure secure return app_id server
def lookup_command command_name BASE_COMMANDS {'help' print_help}REPLICATION_COMMANDS {'compare' replication_compare 'dump' replication_dump 'livecopy' replication_livecopy 'load' replication_load 'size' replication_size}commands {}for command_set in BASE_COMMANDS REPLICATION_COMMANDS commands.update command_set try command commands[command_name]except KeyError if command_name sys.exit _ 'Unknowncommand %s' % command_name else command commands['help']return command
def make_absolute request view_name kwargs None return request.build_absolute_uri urlresolvers.reverse view_name kwargs kwargs
def publish_pages include_unpublished False language None site None qs Page.objects.drafts if not include_unpublished qs qs.filter title_set__published True .distinct if site qs qs.filter site site output_language Nonefor i page in enumerate qs add Truetitles page.title_setif not include_unpublished titles titles.filter published True for lang in titles.values_list 'language' flat True if language is None or lang language if not output_language output_language langif not page.publish lang add Falseactivate output_language yield page add
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def do_with_ruby ruby cmdline runas None if not cmdline raise SaltInvocationError 'Commandmustbespecified' try cmdline salt.utils.shlex_split cmdline except AttributeError cmdline salt.utils.shlex_split str cmdline env {}if ruby env['RBENV_VERSION'] rubycmd cmdlineelse cmd cmdlinereturn do cmd runas runas env env
def _get_or_define_module full_name modules module modules.get full_name if not module module new.module full_name modules[full_name] modulesplit_name full_name.rsplit '.' 1 if len split_name > 1 parent_module_name sub_module_name split_nameparent_module _get_or_define_module parent_module_name modules setattr parent_module sub_module_name module return module
def get_roles_with_permission permission roles []for role in ROLE_PERMISSIONS permissions ROLE_PERMISSIONS[role]if permission in permissions or 'admin' in permissions roles.append role return roles
def get_releases episode downloaded None start None stop None count False descending False sort_by None session None releases session.query Release .filter Release.episode_id episode.id if downloaded is not None releases releases.filter Release.downloaded downloaded if count return releases.count releases releases.slice start stop .from_self if descending releases releases.order_by getattr Release sort_by .desc else releases releases.order_by getattr Release sort_by return releases.all
def test_summary_without_shipping_method request_cart_with_item client monkeypatch monkeypatch.setattr 'saleor.checkout.core.Checkout.email' True response client.get reverse 'checkout summary' assert response.status_code 302 assert get_redirect_location response reverse 'checkout shipping-method'
def find_boundaries label_img connectivity 1 mode 'thick' background 0 if label_img.dtype 'bool' label_img label_img.astype np.uint8 ndim label_img.ndimselem ndi.generate_binary_structure ndim connectivity if mode ! 'subpixel' boundaries dilation label_img selem ! erosion label_img selem if mode 'inner' foreground_image label_img ! background boundaries & foreground_imageelif mode 'outer' max_label np.iinfo label_img.dtype .maxbackground_image label_img background selem ndi.generate_binary_structure ndim ndim inverted_background np.array label_img copy True inverted_background[background_image] max_labeladjacent_objects dilation label_img selem ! erosion inverted_background selem & ~ background_image boundaries & background_image | adjacent_objects return boundarieselse boundaries _find_boundaries_subpixel label_img return boundaries
def mmNull a TpPd pd 5 b MessageType mesType 48 packet a / b return packet
def make_fastq_multi in_fasta quals out_fp label_transform split_lib_transform mkdir out_fp seen_libs defaultdict list for rec label in iter_fastq in_fasta quals label_transform lib_id seq_id label.rsplit '_' 1 seen_libs[lib_id].append rec for lib recs in seen_libs.items if lib is None continueoutfile open out_fp + '/' + lib + '.fastq' 'w' outfile.write '\n'.join recs outfile.close
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
@shared_task def update_email_in_basket old_email new_email if not BASKET_ENABLED or not waffle.switch_is_active 'BASKET_SWITCH_ENABLED' returnchain lookup_user_task.subtask old_email | group subscribe_user_task.subtask new_email unsubscribe_user_task.subtask .delay
def normalizeXRI xri if xri.startswith 'xri //' xri xri[6 ]return xri
def check_dyad w w_dyad if not is_weight w and is_dyad_weight w_dyad return Falseif w w_dyad return Trueif len w_dyad len w + 1 return w tuple Fraction v 1 - w_dyad[ -1 ] for v in w_dyad[ -1 ] else return False
def notify_list_member_added e target e['target']if target['screen_name'] ! c['original_name'] returnsource e['source']target_object [e['target_object']]created_at e['created_at']source_user cycle_color source['name'] + color_func c['NOTIFICATION']['source_nick'] '@' + source['screen_name'] notify color_func c['NOTIFICATION']['notify'] 'addedyoutoalist' date parser.parse created_at clock fallback_humanize date clock color_func c['NOTIFICATION']['clock'] clock meta c['NOTIFY_FORMAT']meta source_user.join meta.split '#source_user' meta notify.join meta.split '#notify' meta clock.join meta.split '#clock' meta emojize meta printNicely '' printNicely meta print_list target_object noti True
def select_option_by_value browser_query value select Select browser_query.first.results[0] select.select_by_value value def options_selected '\nReturnsTrueifalloptionsinselectelementwherevalueattribute\nmatches`value`.ifanyoptionisnotselectedthenreturnsFalse\nandselectit.ifvalueisnotanoptionchoicethenitreturnsFalse.\n'all_options_selected Truehas_option Falsefor opt in select.options if opt.get_attribute 'value' value has_option Trueif not opt.is_selected all_options_selected Falseopt.click if all_options_selected and not has_option all_options_selected Falsereturn all_options_selectedEmptyPromise options_selected 'Optionisselected' .fulfill
def _log_ch start info ch if ch is not None extra just ch 'storedonchannel ' 50 info['ch_names'][ch] else extra just ch 'notstored' 0 '' logger.info start + extra .ljust just + ch
def get_minions log.debug 'sqlite3returner<get_minions>called' conn _get_conn ret None cur conn.cursor sql 'SELECTDISTINCTidFROMsalt_returns'cur.execute sql data cur.fetchall ret []for minion in data ret.append minion[0] _close_conn conn return ret
def _get_options raw_options apply_config if not raw_options return parse_args [u''] apply_config apply_config if isinstance raw_options dict options parse_args [u''] apply_config apply_config for name value in raw_options.items if not hasattr options name raise ValueError u"Nosuchoption'{}'".format name expected_type type getattr options name if not isinstance expected_type str unicode if isinstance value str unicode raise ValueError u"Option'{}'shouldnotbeastring".format name setattr options name value else options raw_optionsreturn options
def set_cached_content content CONTENT_CACHE.set unicode content.location .encode 'utf-8' content version STATIC_CONTENT_VERSION
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def openshift_build_verify registry xml_parent data osb XML.SubElement xml_parent 'com.openshift.jenkins.plugins.pipeline.OpenShiftBuildVerifier' mapping [ 'api-url' 'apiURL' 'https //openshift.default.svc.cluster.local' 'bld-cfg' 'bldCfg' 'frontend' 'namespace' 'namespace' 'test' 'auth-token' 'authToken' '' 'verbose' 'verbose' False ]convert_mapping_to_xml osb data mapping fail_required True
def correl_ts frame1 frame2 results {}for col series in compat.iteritems frame1 if col in frame2 other frame2[col]idx1 series.valid .indexidx2 other.valid .indexcommon_index idx1.intersection idx2 seriesStand zscore series.reindex common_index otherStand zscore other.reindex common_index results[col] seriesStand * otherStand .mean return Series results
def rm_job user cmd minute None hour None daymonth None month None dayweek None identifier None lst list_tab user ret 'absent'rm_ Nonefor ind in range len lst['crons'] if rm_ is not None breakif _cron_matched lst['crons'][ind] cmd identifier identifier if not any [ x is not None for x in minute hour daymonth month dayweek ] rm_ indelif _date_time_match lst['crons'][ind] minute minute hour hour daymonth daymonth month month dayweek dayweek rm_ indif rm_ is not None lst['crons'].pop rm_ ret 'removed'comdat _write_cron_lines user _render_tab lst if comdat['retcode'] return comdat['stderr']return ret
def get_exploration_rights exploration_id strict True model exp_models.ExplorationRightsModel.get exploration_id strict strict if model is None return Nonereturn _get_activity_rights_from_model model feconf.ACTIVITY_TYPE_EXPLORATION
def __cacheit_debug maxsize def func_wrapper func from .decorators import wrapscfunc __cacheit maxsize func @wraps func def wrapper *args **kw_args r1 func *args **kw_args r2 cfunc *args **kw_args hash r1 hash r2 if r1 ! r2 raise RuntimeError 'Returnedvaluesarenotthesame' return r1return wrapperreturn func_wrapper
def test_cache_deactivated_insert_data config_stub tmpdir url 'http //qutebrowser.org'disk_cache QNetworkDiskCache disk_cache.setCacheDirectory str tmpdir metadata QNetworkCacheMetaData metadata.setUrl QUrl url device disk_cache.prepare metadata assert device is not None config_stub.data {'storage' {'cache-size' 1024} 'general' {'private-browsing' True}}deactivated_cache cache.DiskCache str tmpdir assert deactivated_cache.insert device is None
def first_hour_average timeseries last_hour_threshold time - FULL_DURATION - 3600 series pandas.Series [x[1] for x in timeseries if x[0] < last_hour_threshold ] mean series.mean stdDev series.std t tail_avg timeseries return abs t - mean > 3 * stdDev
def read_unsigned_var_int file_obj result 0shift 0while True byte struct.unpack '<B' file_obj.read 1 [0]result | byte & 127 << shift if byte & 128 0 breakshift + 7return result
def create_new_paste contents import reif sys.version_info < 3 0 from urllib import urlopen urlencodeelse from urllib.request import urlopenfrom urllib.parse import urlencodeparams {'code' contents 'lexer' 'python3' if sys.version_info[0] 3 else 'python' 'expiry' '1week'}url 'https //bpaste.net'response urlopen url data urlencode params .encode 'ascii' .read m re.search 'href "/raw/ \\w+ "' response.decode 'utf-8' if m return '%s/show/%s' % url m.group 1 else return 'badresponse ' + response
def frame_msg_ipc body header None raw_body False framed_msg {}if header is None header {}framed_msg['head'] headerframed_msg['body'] bodyif six.PY2 return msgpack.dumps framed_msg else return msgpack.dumps framed_msg use_bin_type True
def add_handlers handler_list subparsers command_handlers [ListArtifactsHandler 'screenboard' None 'list_datadog_screenboards' 'GetthelistofScreenboardsfromDatadog.' ListArtifactsHandler 'timeboard' None 'list_datadog_timeboards' 'GetthelistofTimeboardsfromDatadog.' GetArtifactHandler 'screenboard' None 'get_datadog_screenboard' 'GettheaDatadogScreenboard.' GetArtifactHandler 'timeboard' None 'get_datadog_timeboard' 'GettheaDatadogTimeboard.' ]for handler in command_handlers handler.add_argparser subparsers handler_list.append handler
def abandon_execution_if_incomplete liveaction_id publish True liveaction_db action_utils.get_liveaction_by_id liveaction_id if liveaction_db.status in action_constants.LIVEACTION_COMPLETED_STATES raise ValueError 'LiveAction%salreadyinacompletedstate%s.' % liveaction_id liveaction_db.status liveaction_db action_utils.update_liveaction_status status action_constants.LIVEACTION_STATUS_ABANDONED liveaction_db liveaction_db result {} execution_db update_execution liveaction_db publish publish LOG.info 'Markedexecution%sas%s.' execution_db.id action_constants.LIVEACTION_STATUS_ABANDONED return execution_db
def is_masquerading_as_student user course_key return get_masquerade_role user course_key 'student'
def error_from_response message http_response error_class response_body None if response_body is None body http_response.read else body response_bodyerror error_class '%s %i %s' % message http_response.status body error.status http_response.statuserror.reason http_response.reasonerror.body bodyerror.headers atom.http_core.get_headers http_response return error
@login_required@check_local_site_accessdef new_review_request request local_site None template_name u'reviews/new_review_request.html' valid_repos []repos Repository.objects.accessible request.user local_site local_site if local_site local_site_name local_site.nameelse local_site_name u''for repo in repos.order_by u'name' try scmtool repo.get_scmtool valid_repos.append {u'id' repo.id u'name' repo.name u'scmtool_name' scmtool.name u'supports_post_commit' repo.supports_post_commit u'local_site_name' local_site_name u'files_only' False u'requires_change_number' scmtool.supports_pending_changesets u'requires_basedir' not scmtool.diffs_use_absolute_paths } except Exception logging.exception u'ErrorloadingSCMToolforrepository"%s" ID%d ' repo.name repo.id valid_repos.insert 0 {u'id' u'' u'name' _ u' None-Fileattachmentsonly ' u'scmtool_name' u'' u'supports_post_commit' False u'files_only' True u'local_site_name' local_site_name} return render_to_response template_name RequestContext request {u'repos' valid_repos}
def do_cloudpipe_list cs _args cloudpipes cs.cloudpipe.list columns ['ProjectId' 'PublicIP' 'PublicPort' 'InternalIP']utils.print_list cloudpipes columns
@require_chanmsg@require_privilege OP u'Youarenotachanneloperator.' @commands u'tmask' def set_mask bot trigger bot.db.set_channel_value trigger.sender u'topic_mask' trigger.group 2 bot.say u'Gotcha ' + trigger.nick
def check_coverage images used_images uncovered set images - set [x[0] for x in used_images] if uncovered LOGGER.error 'ThefollowingDockerfilesarenotdescribedintheparsefiles_config.ymlfile {}.PleaseseethefollowingdocumentationonhowtoaddDockerfilerankstotheconfigurationfile {}'.format uncovered 'https //github.com/edx/configuration/blob/master/util/README.md' sys.exit 1
def libvlc_media_tracks_release p_tracks i_count f _Cfunctions.get 'libvlc_media_tracks_release' None or _Cfunction 'libvlc_media_tracks_release' 1 1 None None ctypes.POINTER MediaTrack ctypes.c_uint return f p_tracks i_count
def test_help_command_should_exit_status_error_when_cmd_does_not_exist script result script.pip 'help' 'mycommand' expect_error True assert result.returncode ERROR
def make_image location size fmt if not os.path.isabs location return ''if not os.path.isdir os.path.dirname location return ''if not __salt__['cmd.retcode'] 'qemu-imgcreate-f{0}{1}{2}M'.format fmt location size python_shell False return locationreturn ''
@then u'weseetabledropped' def step_see_table_dropped context _expect_exact context u'DROPTABLE' timeout 2
def render_from_lms template_name dictionary context None namespace 'main' return render_to_string template_name dictionary context namespace 'lms.' + namespace
def restart_service service_name minimum_running_time None if minimum_running_time ret_code Falseservices __salt__['cmd.run'] ['/usr/bin/openstack-service' 'list' service_name] .split '\n' for service in services service_info __salt__['service.show'] service boot_time float salt.utils.fopen '/proc/uptime' .read .split '' [0] expr_time int service_info.get 'ExecMainStartTimestampMonotonic' 0 / 1000000 < boot_time - minimum_running_time expr_active service_info.get 'ActiveState' 'active' if expr_time or not expr_active ret __salt__['service.restart'] service if ret ret_code Truereturn ret_codeelse os_cmd ['/usr/bin/openstack-service' 'restart' service_name]return __salt__['cmd.retcode'] os_cmd 0
def try_dbfield fn field_class for cls in field_class.mro if cls is models.Field continuedata fn cls if data return data
@csrf_exempt@require_POSTdef password_reset request limiter BadRequestRateLimiter if limiter.is_rate_limit_exceeded request AUDIT_LOG.warning 'Ratelimitexceededinpassword_reset' return HttpResponseForbidden form PasswordResetFormNoActive request.POST if form.is_valid form.save use_https request.is_secure from_email configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL request request domain_override request.get_host tracker.emit SETTING_CHANGE_INITIATED {'setting' 'password' 'old' None 'new' None 'user_id' request.user.id} destroy_oauth_tokens request.user else AUDIT_LOG.info 'Badpassword_resetuserpassedin.' limiter.tick_bad_request_counter request return JsonResponse {'success' True 'value' render_to_string 'registration/password_reset_done.html' {} }
def _old_process_multipart entity process_multipart entity params entity.paramsfor part in entity.parts if part.name is None key ntou 'parts' else key part.nameif part.filename is None value part.fullvalue else value partif key in params if not isinstance params[key] list params[key] [params[key]]params[key].append value else params[key] value
def addCageGroove derivation negatives positives addCage derivation derivation.demiheight negatives positives addGroove derivation negatives
def enable_tab_completion unused_command libedit 'libedit' in readline.__doc__ command 'bind^Irl_complete' if libedit else 'tab complete' readline.parse_and_bind command
def rename_in_module occurrences_finder new_name resource None pymodule None replace_primary False region None reads True writes True if resource is not None source_code resource.read else source_code pymodule.source_codechange_collector codeanalyze.ChangeCollector source_code for occurrence in occurrences_finder.find_occurrences resource pymodule if replace_primary and occurrence.is_a_fixed_primary continueif replace_primary start end occurrence.get_primary_range else start end occurrence.get_word_range if not reads and not occurrence.is_written or not writes and occurrence.is_written continueif region is None or region[0] < start < region[1] change_collector.add_change start end new_name return change_collector.get_changed
def extract_cluster_size line cluster_size line.split ' ' [ -1 ]try cluster_size int cluster_size except ValueError return 0return cluster_size
@ignore_warnings category DeprecationWarning def check_estimators_fit_returns_self name Estimator X y make_blobs random_state 0 n_samples 9 n_features 4 y multioutput_estimator_convert_y_2d name y X - X.min estimator Estimator set_testing_parameters estimator set_random_state estimator assert_true estimator.fit X y is estimator
def logspace start stop num 50 endpoint True base 10.0 dtype None y linspace start stop num num endpoint endpoint if dtype is None return core.power base y return core.power base y .astype dtype
def safecharencode value retVal valueif isinstance value basestring if any _ not in SAFE_CHARS for _ in value retVal retVal.replace '\\' SLASH_MARKER for char in SAFE_ENCODE_SLASH_REPLACEMENTS retVal retVal.replace char repr char .strip "'" retVal reduce lambda x y x + y if y in string.printable or isinstance value unicode and ord y > 160 else '\\x%02x' % ord y retVal unicode if isinstance value unicode else str retVal retVal.replace SLASH_MARKER '\\\\' elif isinstance value list for i in xrange len value retVal[i] safecharencode value[i] return retVal
def p_base_type p if p[1] 'bool' p[0] TType.BOOLif p[1] 'byte' p[0] TType.BYTEif p[1] 'i16' p[0] TType.I16if p[1] 'i32' p[0] TType.I32if p[1] 'i64' p[0] TType.I64if p[1] 'double' p[0] TType.DOUBLEif p[1] 'string' p[0] TType.STRINGif p[1] 'binary' p[0] TType.BINARY
def get_pdherr code code & 2 ** 32 - 1 return _pdh_errcodes.get code code
def group_member_role return s3_rest_controller
def update_model model item_id data event_id None if event_id is not None item get_object_in_event model item_id event_id else item get_object_or_404 model item_id if len data 0 return itemdb.session.query model .filter_by id item_id .update dict data save_to_db item '%supdated' % model.__name__ return item
def gzip_decode data if not gzip raise NotImplementedErrorf StringIO.StringIO data gzf gzip.GzipFile mode 'rb' fileobj f try decoded gzf.read except IOError raise ValueError 'invaliddata' f.close gzf.close return decoded
def dataset_purge context data_dict from sqlalchemy import or_model context['model']id _get_or_bust data_dict 'id' pkg model.Package.get id context['package'] pkgif pkg is None raise NotFound 'Datasetwasnotfound' _check_access 'dataset_purge' context data_dict members model.Session.query model.Member .filter model.Member.table_id pkg.id .filter model.Member.table_name 'package' if members.count > 0 for m in members.all m.purge for r in model.Session.query model.PackageRelationship .filter or_ model.PackageRelationship.subject_package_id pkg.id model.PackageRelationship.object_package_id pkg.id .all r.purge pkg model.Package.get id pkg.purge model.repo.commit_and_remove
def extract_code_from_function function if not function.__name__.startswith u'fix_' return Nonecode re.sub u'^fix_' u'' function.__name__ if not code return Nonetry int code[1 ] except ValueError return Nonereturn code
def check_password password encoded setter None preferred u'default' if not password or not is_password_usable encoded return Falsepreferred get_hasher preferred hasher identify_hasher encoded must_update hasher.algorithm ! preferred.algorithm is_correct hasher.verify password encoded if setter and is_correct and must_update setter password return is_correct
def option_was_set option value return set_by_cli option or not has_default_value option value
def _publish_file token room filepath message '' api_url None if not os.path.isfile filepath raise ValueError "File'{0}'doesnotexist".format filepath if len message > 1000 raise ValueError 'Messagetoolong' url '{0}/v2/room/{1}/share/file'.format api_url room headers {'Content-type' 'multipart/related;boundary boundary123456'}headers['Authorization'] 'Bearer' + token msg json.dumps {'message' message} payload '--boundary123456\nContent-Type application/json;charset UTF-8\nContent-Disposition attachment;name "metadata"\n\n{0}\n\n--boundary123456\nContent-Disposition attachment;name "file";filename "{1}"\n\n{2}\n\n--boundary123456--'.format msg os.path.basename filepath open filepath 'rb' .read salt.utils.http.query url method 'POST' header_dict headers data payload
def format_live_refs ignore NoneType s 'LiveReferences\n\n'now time for cls wdict in sorted six.iteritems live_refs key lambda x x[0].__name__ if not wdict continueif issubclass cls ignore continueoldest min six.itervalues wdict s + '%-30s%6doldest %dsago\n' % cls.__name__ len wdict now - oldest return s
def salt_auth_tool if 'token' not in cherrypy.session raise cherrypy.HTTPError 401 cherrypy.response.headers['Cache-Control'] 'private'
def glob pathname return list iglob pathname
def test_denoise_tv_chambolle_4d im 255 * np.random.rand 8 8 8 8 res restoration.denoise_tv_chambolle im.astype np.uint8 weight 0.1 assert_ res.dtype np.float assert_ res.std * 255 < im.std
def decargs arglist return [s.decode _encoding for s in arglist]
def _future_repr_info future info [future._state.lower ]if future._state _FINISHED if future._exception is not None info.append 'exception {!r}'.format future._exception else result reprlib.repr future._result info.append 'result {}'.format result if future._callbacks info.append _format_callbacks future._callbacks if future._source_traceback frame future._source_traceback[ -1 ]info.append 'createdat%s %s' % frame[0] frame[1] return info
def guess_kern_maxfiles return 65536
def activity_hours mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepreturn s3_rest_controller
def get_impl_ver impl_ver get_config_var 'py_version_nodot' if not impl_ver or get_abbr_impl 'pp' impl_ver ''.join map str get_impl_version_info return impl_ver
def get_saved_rules conf_file None family 'ipv4' return _parse_conf conf_file conf_file family family
def _make_error index code errmsg operation return {_UINDEX index _UCODE code _UERRMSG errmsg _UOP operation}
def make_opt_parser command_descriptions []for name in sorted commands.iterkeys command commands[name]params ''.join [ '<%s>' % param for param in command.required] + [ '[<%s>]' % param for param in command.optional] command_descriptions.append '%%prog[options]%s%s' % name params command_usage 'usage %s\n' % '\n'.join command_descriptions parser optparse.OptionParser usage command_usage parser.add_option '-d' '--dest_dir' dest 'dest_dir' default os.getcwd help 'WritegeneratedfilestoDIR' metavar 'DIR' parser.add_option '-f' '--force' action 'store_true' dest 'force' default False help 'Forceoverwriteofexistingfiles' return parser
def generate_ims variation 1.0 fonts font_char_ims load_fonts FONT_DIR num_bg_images len os.listdir 'bgs' while True yield generate_im font_char_ims[random.choice fonts ] num_bg_images
def cache_with_field field_name def decorator fn @wraps fn assigned available_attrs fn def wrapper self *args **kwargs force_fresh kwargs.pop 'force_fresh' False field_val getattr self field_name if field_val is not None and not force_fresh return field_valfield_val fn self force_fresh force_fresh setattr self field_name field_val return field_valreturn wrapperreturn decorator
def _index_document index_list if isinstance index_list collections.Mapping raise TypeError 'passingadicttosort/create_index/hintisnotallowed-usealistoftuplesinstead.didyoumean%r?' % list iteritems index_list elif not isinstance index_list list tuple raise TypeError 'mustusealistof key direction pairs not ' + repr index_list if not len index_list raise ValueError 'key_or_listmustnotbetheemptylist' index SON for key value in index_list if not isinstance key string_type raise TypeError 'firstitemineachkeypairmustbeastring' if not isinstance value string_type int collections.Mapping raise TypeError "seconditemineachkeypairmustbe1 -1 '2d' 'geoHaystack' oranothervalidMongoDBindexspecifier." index[key] valuereturn index
def relative_luminance color rgb mpl.colors.colorConverter.to_rgba_array color [ 3]rgb np.where rgb < 0.03928 rgb / 12.92 rgb + 0.055 / 1.055 ** 2.4 lum rgb.dot [0.2126 0.7152 0.0722] try return lum.item except ValueError return lum
def find_join_source clauses join_to selectables list _from_objects join_to for i f in enumerate clauses for s in selectables if f.is_derived_from s return i f else return None None
def WmiTimeToEpoch cimdatetime_str re_match TIME_WMI_RE.match cimdatetime_str try t_dict re_match.groupdict flt_time time.strptime t_dict['date'] '%Y%m%d%H%M%S' epoch_time int calendar.timegm flt_time * 1000000 epoch_time + int t_dict['subsecond'] return epoch_timeexcept KeyError AttributeError return 0
def p_statement_blank p p[0] 0 'BLANK' int p[1]
def Int2AP num val ''AP 'ABCDEFGHIJKLMNOP'num int abs num while num num mod divmod num 16 val AP[mod] + val return val
def _to_bool string_value string_value_low string_value.lower if string_value_low not in 'false' 'true' raise ValueError 'invalidliteralforboolean %s mustbe"true"or"false" ' % string_value return string_value_low 'true'
def api_v2_url path_str params None base_route website_settings.API_DOMAIN base_prefix api_settings.API_BASE **kwargs params params or {} base_url furl.furl base_route + base_prefix base_url.path.add [x for x in path_str.split '/' if x] + [''] base_url.args.update params base_url.args.update kwargs return str base_url
def AddBatchJob client batch_job_service client.GetService 'BatchJobService' version 'v201605' batch_job_operations [{'operand' {} 'operator' 'ADD'}]return batch_job_service.mutate batch_job_operations ['value'][0]
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def emit_setting_changed_event user db_table setting_name old_value new_value truncated_fields truncate_fields old_value new_value truncated_fields['setting'] setting_nametruncated_fields['user_id'] user.idtruncated_fields['table'] db_tabletracker.emit USER_SETTINGS_CHANGED_EVENT_NAME truncated_fields USER_FIELD_CHANGED.send sender None user user table db_table setting setting_name old_value old_value new_value new_value
def s3_required_label field_label return TAG[''] '%s ' % field_label SPAN '*' _class 'req'
def make_minimal_cs_comment overrides None ret {'type' 'comment' 'id' 'dummy' 'commentable_id' 'dummy' 'thread_id' 'dummy' 'parent_id' None 'user_id' '0' 'username' 'dummy' 'anonymous' False 'anonymous_to_peers' False 'created_at' '1970-01-01T00 00 00Z' 'updated_at' '1970-01-01T00 00 00Z' 'body' 'dummy' 'abuse_flaggers' [] 'votes' {'up_count' 0} 'endorsed' False 'child_count' 0 'children' []}ret.update overrides or {} return ret
def simple_entry_analyze fig data n data2 dataentry_nbar_best data2['entry_nbar_best']entry_nbar_worst data2['entry_nbar_worst']return plot_simple_entry fig entry_nbar_best entry_nbar_worst n
def _copy master_fd master_read _read stdin_read _read fds [master_fd STDIN_FILENO]while True rfds wfds xfds select fds [] [] if master_fd in rfds data master_read master_fd if not data fds.remove master_fd else os.write STDOUT_FILENO data if STDIN_FILENO in rfds data stdin_read STDIN_FILENO if not data fds.remove STDIN_FILENO else _writen master_fd data
def mulrowscaler row scaler K return [ scaler * element for element in row]
def pbucket tail return 's3 //' + bucket tail
def summer rc 'image' cmap 'summer' im gci if im is not None im.set_cmap cm.summer draw_if_interactive
def pad_method_dict method_dict for key in AUTH_BACKEND_NAME_MAP if key not in method_dict method_dict[key] Falsereturn method_dict
@get '/scan/<taskid>/log/<start>/<end>' def scan_log_limited taskid start end json_log_messages list if taskid not in DataStore.tasks logger.warning '[%s]InvalidtaskIDprovidedtoscan_log_limited ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} if not start.isdigit or not end.isdigit or end < start logger.warning '[%s]Invalidstartorendvalueprovidedtoscan_log_limited ' % taskid return jsonize {'success' False 'message' 'Invalidstartorendvalue mustbedigits'} start max 1 int start end max 1 int end for time_ level message in DataStore.current_db.execute 'SELECTtime level messageFROMlogsWHEREtaskid ?ANDid> ?ANDid< ?ORDERBYidASC' taskid start end json_log_messages.append {'time' time_ 'level' level 'message' message} logger.debug '[%s]Retrievedscanlogmessagessubset' % taskid return jsonize {'success' True 'log' json_log_messages}
def _splitall path allparts []while True parts os.path.split path if parts[0] path allparts.insert 0 parts[0] breakelif parts[1] path allparts.insert 0 parts[1] breakelse path parts[0]allparts.insert 0 parts[1] return allparts
def _calc_padding_for_alignment align base rmdr int base % align if rmdr 0 return 0else return align - rmdr
def guess_field_type field if isinstance field TranslatedFieldsField return 'object'elif isinstance field EnumField types Counter [type x for x in field.choices] most_common types.most_common 1 [0][0]if most_common in six.string_types or most_common six.text_type return 'string'elif most_common in six.integer_types return 'number'elif most_common bool return 'boolean'return types_lookup[field]
def hamming M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym w _cos_win M [0.54 0.46] return _truncate w needs_trunc
def PresentDialog message choices default_choice_index 0 to_eval u"confirm '{0}' '{1}' {2} ".format EscapeForVim ToUnicode message EscapeForVim ToUnicode u'\n'.join choices default_choice_index + 1 try return GetIntValue to_eval - 1 except KeyboardInterrupt return -1
def _crop image offset_height offset_width crop_height crop_width original_shape tf.shape image rank_assertion tf.Assert tf.equal tf.rank image 3 ['Rankofimagemustbeequalto3.'] cropped_shape control_flow_ops.with_dependencies [rank_assertion] tf.pack [crop_height crop_width original_shape[2]] size_assertion tf.Assert tf.logical_and tf.greater_equal original_shape[0] crop_height tf.greater_equal original_shape[1] crop_width ['Cropsizegreaterthantheimagesize.'] offsets tf.to_int32 tf.pack [offset_height offset_width 0] image control_flow_ops.with_dependencies [size_assertion] tf.slice image offsets cropped_shape return tf.reshape image cropped_shape
def claModelControlDisableSPLearningCb claModel assert isinstance claModel CLAModel claModel._getSPRegion .setParameter 'learningMode' False return
def _prepare_trans_tar name mods None saltenv 'base' pillar None chunks _compile_state mods saltenv refs salt.client.ssh.state.lowstate_file_refs chunks _mk_fileclient trans_tar salt.client.ssh.state.prep_trans_tar __opts__ __context__['cp.fileclient'] chunks refs pillar name return trans_tar
@declareddef set_value obj_ref output None perfdata None return_code None obj get_object obj_ref if not obj returnoutput output or obj.output perfdata perfdata or obj.perf_data if return_code is None return_code obj.state_idlogger.debug '[trigger]Setting%s%s%sforobject%s' output perfdata return_code obj.get_full_name if perfdata output output + '|' + perfdata now time.time cls obj.__class__i obj.launch_check now force True for chk in obj.checks_in_progress if chk.id i logger.debug '[trigger]IfoundthecheckIwanttochange' c chkc.exit_status return_codec.get_outputs output obj.max_plugins_output_length c.status 'waitconsume'c.check_time nowc.from_trigger True
def get_all_specs context filters None marker None limit None offset None sort_keys None sort_dirs None return objects.QualityOfServiceSpecsList.get_all context filters filters marker marker limit limit offset offset sort_keys sort_keys sort_dirs sort_dirs
@mine.command 'remove' @click.argument 'x' type float @click.argument 'y' type float def mine_remove x y click.echo 'Removedmineat%s %s' % x y
def factor_sum self limits None radical False clear False fraction False sign True from sympy.core.exprtools import factor_termsfrom sympy.concrete.summations import Sumresult self.function if limits is None else self limits self.limits if limits is None else limits if result 0 return S.Zerosum_vars set [limit.args[0] for limit in limits] retv factor_terms result radical radical clear clear fraction fraction sign sign if not result.is_commutative return Sum result *limits i d retv.as_independent *sum_vars if isinstance retv Add return i * Sum 1 *limits + Sum d *limits else return i * Sum d *limits
def expanded_data_double_fc n 100 expanded_training_data _ _ network3.load_data_shared '../data/mnist_expanded.pkl.gz' for j in range 3 print 'Trainingwithexpandeddata %sneuronsintwoFClayers runnum%s' % n j net Network [ConvPoolLayer image_shape mini_batch_size 1 28 28 filter_shape 20 1 5 5 poolsize 2 2 activation_fn ReLU ConvPoolLayer image_shape mini_batch_size 20 12 12 filter_shape 40 20 5 5 poolsize 2 2 activation_fn ReLU FullyConnectedLayer n_in 40 * 4 * 4 n_out n activation_fn ReLU FullyConnectedLayer n_in n n_out n activation_fn ReLU SoftmaxLayer n_in n n_out 10 ] mini_batch_size net.SGD expanded_training_data 60 mini_batch_size 0.03 validation_data test_data lmbda 0.1
def unarmor pem_bytes multiple False generator _unarmor pem_bytes if not multiple return next generator return generator
def _split_module_dicts if not isinstance __salt__ dict return __salt__mod_dict dict __salt__ for module_func_name mod_fun in six.iteritems mod_dict.copy mod fun module_func_name.split '.' 1 if mod not in mod_dict mod_dict[mod] lambda None setattr mod_dict[mod] fun mod_fun return mod_dict
def dmp_slice_in f m n j u K if j < 0 or j > u raise IndexError '-%s< j<%sexpected got%s' % u u j if not u return dup_slice f m n K f g dmp_to_dict f u {} for monom coeff in f.items k monom[j]if k < m or k > n monom monom[ j] + 0 + monom[ j + 1 ] if monom in g g[monom] + coeffelse g[monom] coeffreturn dmp_from_dict g u K
def _RetainVerticalSpacingBetweenTokens cur_tok prev_tok if prev_tok is None returnif prev_tok.is_string prev_lineno prev_tok.lineno + prev_tok.value.count u'\n' elif prev_tok.is_pseudo_paren if not prev_tok.previous_token.is_multiline_string prev_lineno prev_tok.previous_token.linenoelse prev_lineno prev_tok.linenoelse prev_lineno prev_tok.linenoif cur_tok.is_comment cur_lineno cur_tok.lineno - cur_tok.value.count u'\n' else cur_lineno cur_tok.linenocur_tok.AdjustNewlinesBefore cur_lineno - prev_lineno
def coreTest vm prompt Prompt log '*Makingsurecgroupsaremounted' vm.sendline 'sudo-nservicecgroup-literestart' vm.expect prompt vm.sendline 'sudo-ncgroups-mount' vm.expect prompt log '*Runningmaketest' vm.sendline 'cd~/mininet;sudomaketest' for test in range 0 2 if vm.expect ['OK.*\r\n' 'FAILED.*\r\n' pexpect.TIMEOUT] timeout 180 0 log '*Test' test 'OK' else log '*Test' test 'FAILED' log '*Test' test 'output ' log vm.before
def label_rgb colors return 'rgb %s %s %s ' % colors[0] colors[1] colors[2]
def split_string_separator txt size if len txt > size txt ''.join [re.sub u'\\. ?P<ends>[^.]* $' '.\n\n\\g<ends>' txt[i i + size ] 1 for i in xrange 0 len txt size ] return txt
def run_banner_output cmd banner_output '%s\n%%s\n\n' % cmd.center 60 '-' command_output ''try cmd_out utils.run cmd ignore_status True timeout 30 command_output cmd_out.stdout + cmd_out.stderr except error.CmdError command_output 'Timedout'return banner_output % command_output
def merge_setting request_setting session_setting dict_class OrderedDict if session_setting is None return request_settingif request_setting is None return session_settingif not isinstance session_setting Mapping and isinstance request_setting Mapping return request_settingmerged_setting dict_class to_key_val_list session_setting merged_setting.update to_key_val_list request_setting none_keys [k for k v in merged_setting.items if v is None ]for key in none_keys del merged_setting[key]return merged_setting
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def communicability_exp G import scipy.linalgnodelist list G A nx.to_numpy_matrix G nodelist A[ A ! 0.0 ] 1expA scipy.linalg.expm A.A mapping dict zip nodelist range len nodelist c {}for u in G c[u] {}for v in G c[u][v] float expA[ mapping[u] mapping[v] ] return c
def defaultFactoryMethod rowClass data kw newObject rowClass newObject.__dict__.update kw return newObject
def test_parse_no_timezone d iso8601.parse_date '2007-01-01T08 00 00' assert d.year 2007 assert d.month 1 assert d.day 1 assert d.hour 8 assert d.minute 0 assert d.second 0 assert d.microsecond 0 assert d.tzinfo iso8601.UTC
def _active_games inactive_interval games _games_in_week _cur_year _cur_week _cur_season_phase active []for info in games if not _game_is_active info inactive_interval continueactive.append info return active
def get_rtd_version version None version_str get_docs_version version version positions 3 return 'latest' if version_str 'dev' else 'stable-%s' % version_str
def _leftmost_descendants node try treepos node.treepositions except AttributeError return []return [node[x] for x in treepos[1 ] if all y 0 for y in x ]
def import_curve p a b g r name 'dummyName' oid 1 3 132 0 255 if isinstance p str p pkcs_os2ip p if isinstance a str a pkcs_os2ip a if isinstance b str b pkcs_os2ip b if isinstance r str r pkcs_os2ip r curve CurveFp p a b x y extract_coordinates g curve generator Point curve x y r return Curve name curve generator oid
def _validate_sos sos sos np.atleast_2d sos if sos.ndim ! 2 raise ValueError 'sosarraymustbe2D' n_sections m sos.shapeif m ! 6 raise ValueError 'sosarraymustbeshape n_sections 6 ' if not sos[ 3] 1 .all raise ValueError 'sos[ 3]shouldbeallones' return sos n_sections
def read_from_numa_maps pid key numa_maps open '/proc/%s/numa_maps' % pid numa_map_info numa_maps.read numa_maps.close numa_maps_dict {}numa_pattern ' ^[\\dabcdfe]+ \\s+.*%s[ ] \\d+ ' % key for address number in re.findall numa_pattern numa_map_info re.M numa_maps_dict[address] numberreturn numa_maps_dict
def test_option_exclude_module pyi_builder pyi_builder.test_source "\ntry \nimportxml.sax\n#Option--exclude-module xml.saxdidnotworkandthemodule\n#wassuccessfullyimported.\nraiseSystemExit 'Modulexml.saxwasexcludedbutitis'\n'bundledwiththeexecutable.' \nexceptImportError \n#TheImporterrorisexpectedsincePyInstallershould\n#notbundle'xml.sax'module.\npass\n" pyi_args ['--exclude-module' 'xml.sax']
def get_city_data data pd.read_csv pm.get_data_file 'pymc3.examples' 'data/srrs2.dat' cty_data pd.read_csv pm.get_data_file 'pymc3.examples' 'data/cty.dat' data data[ data.state 'MN' ]data['fips'] data.stfips * 1000 + data.cntyfips cty_data['fips'] cty_data.stfips * 1000 + cty_data.ctfips data['lradon'] np.log np.where data.activity 0 0.1 data.activity data data.merge cty_data 'inner' on 'fips' unique data[['fips']].drop_duplicates unique['group'] np.arange len unique unique.set_index 'fips' return data.merge unique 'inner' on 'fips'
def obl_cv_seq m n c if not isscalar m and isscalar n and isscalar c raise ValueError 'Argumentsmustbescalars.' if n ! floor n or m ! floor m raise ValueError 'Modesmustbeintegers.' if n - m > 199 raise ValueError 'Differencebetweennandmistoolarge.' maxL n - m + 1 return specfun.segv m n c -1 [1][ maxL]
def run_discovery entry_points_iter cached False reg_cache {}if cached reg_cache cache.registry_cache discovery QtWidgetDiscovery cached_descriptions reg_cache registry QtWidgetRegistry discovery.found_category.connect registry.register_category discovery.found_widget.connect registry.register_widget discovery.run if cached cache.save_registry_cache reg_cache return registry
def jenkins_result_from_api result if result is None return JenkinsResults.RUNNINGelif result in ['FAILURE' 'ABORTED'] return JenkinsResults.FAILEDelif result 'SUCCESS' return JenkinsResults.PASSEDelse raise AssertionError "Don'tknowhowtohandleJenkinsresult{}".format result
def _effective_debug_level ctx bundle extra_filters None default None if default is None default ctx.environment.debugif bundle.config.get 'debug' is not None level bundle.config.debugelse filters merge_filters bundle.filters extra_filters level 'merge' if select_filters filters True else None if level is not None if cmp_debug_levels default level > 0 return levelreturn default
def find_the_diff s t t_dict {}s_dict {}for i in s s_dict[i] s_dict.get i 0 + 1 for i in t t_dict[i] t_dict.get i 0 + 1 for i in t_dict.keys if t_dict[i] > s_dict.get i 0 return i
def GDataEntryFromString xml_string return atom.CreateClassFromXMLString GDataEntry xml_string
def strips a b return rstrips lstrips a b b
def map_tag source target source_tag if target u'universal' if source u'wsj' source u'en-ptb'if source u'brown' source u'en-brown'return tagset_mapping source target [source_tag]
def cubic_spline x absx np.abs x absx2 absx ** 2 absx3 absx ** 3 kernel_weight 1.5 * absx3 - 2.5 * absx2 + 1 * absx < 1 + -0.5 * absx3 + 2.5 * absx2 - 4 * absx + 2 * 1 < absx & absx < 2 return kernel_weight
def get_physical_type unit r unit._get_physical_type_id return _physical_unit_mapping.get r u'unknown'
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
def binhex inp out finfo getfileinfo inp ofp BinHex finfo out ifp io.open inp 'rb' while True d ifp.read 128000 if not d breakofp.write d ofp.close_data ifp.close ifp openrsrc inp 'rb' while True d ifp.read 128000 if not d breakofp.write_rsrc d ofp.close ifp.close
def format_national_number_with_preferred_carrier_code numobj fallback_carrier_code if numobj.preferred_domestic_carrier_code is not None carrier_code numobj.preferred_domestic_carrier_codeelse carrier_code fallback_carrier_codereturn format_national_number_with_carrier_code numobj carrier_code
def init_addons settings routes True from website.addons.base import init_addonsettings.ADDONS_AVAILABLE getattr settings 'ADDONS_AVAILABLE' [] settings.ADDONS_AVAILABLE_DICT getattr settings 'ADDONS_AVAILABLE_DICT' OrderedDict for addon_name in settings.ADDONS_REQUESTED if settings.USE_POSTGRES try addon apps.get_app_config 'addons_{}'.format addon_name except LookupError addon Noneelse addon init_addon app addon_name routes routes if addon if addon not in settings.ADDONS_AVAILABLE settings.ADDONS_AVAILABLE.append addon settings.ADDONS_AVAILABLE_DICT[addon.short_name] addonsettings.ADDON_CAPABILITIES render_addon_capabilities settings.ADDONS_AVAILABLE
def GetAllHeaders message name for header_line in message.getallmatchingheaders name yield header_line.split ' ' 1 [1].strip
def validate_thrift_transport confvar transport confvar.get error_res [ confvar 'Thrifttransport%snotsupported.Pleasechooseasupportedtransport %s' % transport ' '.join SUPPORTED_THRIFT_TRANSPORTS ]if transport not in SUPPORTED_THRIFT_TRANSPORTS return error_resreturn []
def init mpstate return CmdlongModule mpstate
def KeyStr key assert isinstance key datastore.Key path key.to_path out_path []for part in path if isinstance part int long part '%020d' % part else part ' %s' % part out_path.append zero_matcher.sub u'\x00\x01' part out_str u'\x00\x00'.join out_path return out_str
def chemical_equations_equal eq1 eq2 exact False left1 arrow1 right1 split_on_arrow eq1 left2 arrow2 right2 split_on_arrow eq2 if arrow1 '' or arrow2 '' return Falseif arrow1 ! arrow2 return Falsetry factor_left divide_chemical_expression left1 left2 if not factor_left return Falsefactor_right divide_chemical_expression right1 right2 if not factor_right return Falseif factor_left ! factor_right return Falseif exact and factor_left ! 1 return Falsereturn Trueexcept ParseException return False
def test_starts_with_empty_strings assert strings.strings {}
def safe_repr fmt *args **kwargs if not is_py3 fmt fmt.decode 'utf-8' out fmt.format *args **kwargs return out.encode 'utf-8' else return fmt.format *args **kwargs
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
def connection_from_url url **kw scheme host port get_host url if scheme 'https' return HTTPSConnectionPool host port port **kw else return HTTPConnectionPool host port port **kw
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
def _aggr_weighted_mean inList params assert len inList len params weightsSum sum params if weightsSum 0 return NoneweightedMean 0for i elem in enumerate inList weightedMean + elem * params[i] return weightedMean / weightsSum
def port container private_port status base_status.copy client _get_client try port_info client.port _get_container_infos container ['Id'] private_port _valid status id_ container out port_info except Exception _invalid status id_ container out traceback.format_exc return status
def amin a axis None out None keepdims False dtype None return a.min axis axis dtype dtype out out keepdims keepdims
def p_struct_declarator_list_1 t pass
def colorStr c return '%02x' * 4 % colorTuple c
def flip_tree node if hasattr node 'root' node node.get_root if node.left flip_tree node.left if node.right flip_tree node.right node.left node.right node.right node.left
def mean_absolute_error y_true y_pred return tf.reduce_mean tf.abs y_pred - y_true
@FileSystem.in_directory current_directory 'django' 'alfaces' def test_django_background_server_running_in_background_with_custom_port import tornado.ioloopimport tornado.webclass MainHandler tornado.web.RequestHandler def get self self.write 'Hello world' raise SystemExit def runserver application tornado.web.Application [ '/' MainHandler ] application.listen 9889 tornado.ioloop.IOLoop.instance .start server multiprocessing.Process target runserver server.start time.sleep 1 e 'LettucecouldnotrunthebuiltinDjangoserverat0.0.0.0 9889"\nmaybeyouforgota"runserver"instancerunning?\n\nwellifyoureallydonotwantlettucetoruntheserverforyou thenjustrun \n\npythonmanage.py--no-server'try status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 3--no-color--port 9889' assert_equals out e assert_not_equals status 0 finally os.kill server.pid 9
def _error_to_jsondict mod type_ code t_name c_name _get_error_names mod type_ code return {'type' '%s %d ' % t_name type_ 'code' '%s %d ' % c_name code }
def combine_map_label_cols combinecolorby mapping combinedmapdata array [''] * len mapping dtype 'a100' title []match Falsefor p in range len combinecolorby for i in range len mapping[0] if str combinecolorby[p] str mapping[0][i] match Truefor q in range len mapping combinedmapdata[q] combinedmapdata[q] + mapping[q][i] breakelse match Falseif not match raise ValueError 'Oneofthecolumnsyoutriedtocombinedoesnotexist!' title.append combinecolorby[p] combinedmapdata[0] '&&'.join title for i in range len combinedmapdata mapping[i].append combinedmapdata[i] return mapping
def _superlative interface comparison_result class ComparisonProxy proxyForInterface interface '_original' def __cmp__ self other return comparison_resultreturn ComparisonProxy
def corename filename f1 Nonef2 os.path.basename filename while f1 ! f2 f1 f2 f2 ext os.path.splitext f1 return f2
def get_networks context filters None fields None session context.sessiontry nets session.query BrocadeNetwork .all return netsexcept sa.exc.SQLAlchemyError return None
def FindNextMatchingAngleBracket clean_lines linenum init_suffix line init_suffixnesting_stack ['<']while True match Search '^[^<> ;\\[\\]]* [<> ;\\[\\]] .* $' line if match operator match.group 1 line match.group 2 if nesting_stack[ -1 ] '<' if operator in '<' ' ' '[' nesting_stack.append operator elif operator '>' nesting_stack.pop if not nesting_stack return Trueelif operator ' ' return Trueelse return Falseelif operator in '<' ' ' '[' nesting_stack.append operator elif operator in ' ' ']' nesting_stack.pop else linenum + 1if linenum > len clean_lines.elided breakline clean_lines.elided[linenum]return True
@django_jinja.library.global_function@jinja2.contextfunctiondef show_prices context options PriceDisplayOptions.from_context context return options.show_prices
def _allow_new_attributes f def decorated self *args **kw 'Thedecoratedfunctionthatreplaces__init__ or__setstate__ \n\n'if not hasattr self '_canAddAttributes' self.__dict__['_canAddAttributes'] 1else self._canAddAttributes + 1assert self._canAddAttributes > 1 count self._canAddAttributesf self *args **kw if hasattr self '_canAddAttributes' self._canAddAttributes - 1else self._canAddAttributes count - 1 assert self._canAddAttributes > 0 if self._canAddAttributes 0 del self._canAddAttributesdecorated.__doc__ f.__doc__decorated.__name__ f.__name__return decorated
def test_get_set_sensor_positions raw1 read_raw_fif raw_fname picks pick_types raw1.info meg False eeg True pos np.array [ch['loc'][ 3] for ch in raw1.info['chs']] [picks]raw_pos raw1._get_channel_positions picks picks assert_array_equal raw_pos pos ch_name raw1.info['ch_names'][13]assert_raises ValueError raw1._set_channel_positions [1 2] ['name'] raw2 read_raw_fif raw_fname raw2.info['chs'][13]['loc'][ 3] np.array [1 2 3] raw1._set_channel_positions [[1 2 3]] [ch_name] assert_array_equal raw1.info['chs'][13]['loc'] raw2.info['chs'][13]['loc']
def check_win_pos pos if not pos.strip return dict valid True message 'Windowpositionnotset default ' pos pos.lower reg ' TOP|BOTTOM .? LEFT|RIGHT 'if not re.match reg pos re.I msg 'Trysomethingliketop-leftorbottom-right ordefault 'return dict valid False message msg else p re.match reg pos re.I .groups p '%s-%s' % p msg 'Windowpositionsetto%s' % p return dict valid True message msg value p
def parameterize ref params ref.copy for key in ref if key[ -3 ] '_id' params.setdefault key[ -3 ] params.pop key return params
def find_induced_nodes G s t treewidth_bound sys.maxsize if not is_chordal G raise nx.NetworkXError 'Inputgraphisnotchordal.' H nx.Graph G H.add_edge s t I set triplet _find_chordality_breaker H s treewidth_bound while triplet u v w tripletI.update triplet for n in triplet if n ! s H.add_edge s n triplet _find_chordality_breaker H s treewidth_bound if I I.add t for u in G[s] if len I & set G[u] 2 I.add u breakreturn I
def GenBankCdsFeatureIterator handle alphabet Alphabet.generic_protein return GenBankScanner debug 0 .parse_cds_features handle alphabet
def parse_host_connect_string hcs if '@' in hcs p re.compile ' ?P<username>[^@ ]* ? ?P<password>.* ?!\\\\ @ ?P<hostname>[^ ]* ? ?P<port>[0-9]* ' else p re.compile ' ?P<username> ?P<password> ?P<hostname>[^ ]* ? ?P<port>[0-9]* ' m p.search hcs d m.groupdict d['password'] d['password'].replace '\\@' '@' return d
def format_file_subscription user node_id path provider AbstractNode apps.get_model 'osf.AbstractNode' node AbstractNode.load node_id wb_path path.lstrip '/' for subscription in get_all_node_subscriptions user node if wb_path in getattr subscription 'event_name' return serialize_event user subscription node return serialize_event user node node event_description 'file_updated'
def restore fid url build_url RESOURCE id fid route 'restore' return request 'post' url
def test_install_pardir script data run_from data.packages.join 'FSPkg' 'fspkg' result script.pip 'install' pardir cwd run_from expect_error False fspkg_folder script.site_packages / 'fspkg' egg_info_folder script.site_packages / 'FSPkg-0.1.dev0-py%s.egg-info' % pyversion assert fspkg_folder in result.files_created str result.stdout assert egg_info_folder in result.files_created str result
def html_diff old new diff SequenceMatcher None old new result []for tag oldpos1 oldpos2 newpos1 newpos2 in diff.get_opcodes if tag 'replace' result.append '<del>%s</del><ins>%s</ins>' % old[oldpos1 oldpos2] new[newpos1 newpos2] elif tag 'delete' result.append '<del>%s</del>' % old[oldpos1 oldpos2] elif tag 'insert' result.append '<ins>%s</ins>' % new[newpos1 newpos2] elif tag 'equal' result.append new[newpos1 newpos2] return ''.join result
def list_running ret []for line in _machinectl 'list' ['stdout'].splitlines try ret.append line.split [0] except IndexError passreturn sorted ret
def create_dark_lang_config apps schema_editor DarkLangConfig apps.get_model u'dark_lang' u'DarkLangConfig' objects DarkLangConfig.objectsif not objects.exists objects.create enabled True
def public func func.publicly_accessible True@functools.wraps func def wrapped *a **kw return func *a **kw return wrapped
def get_lineno node lineno Nonewhile lineno is None and node node node.parentlineno node.linereturn lineno
def dist_string dist out '%.1f%%' % 1 - dist * 100 if dist < config['match']['strong_rec_thresh'].as_number out ui.colorize 'green' out elif dist < config['match']['medium_rec_thresh'].as_number out ui.colorize 'yellow' out else out ui.colorize 'red' out return out
def get_ids lines field bad_ids None debug False result defaultdict list for line in lines if line.startswith '>' fields map strip line[1 ].split label fields[0]if not '_' in label continue lib id_ label.rsplit '_' 1 if bad_ids and label in bad_ids if debug print 'Excludedbadid %s' % label else result[lib].append fields[field] return result
def find_in_path fname path None if path is None path os.environ.get 'PATH' '' for dir in path.split os.pathsep fpath os.path.join dir fname if os.path.isfile fpath return fpathelse return None
def data_upload_progress req if 'id' in req.GET upload_id str req.GET['id'] if upload_id in req.session upload_obj get_object_or_404 Upload import_id upload_id user req.user upload_session upload_obj.get_session else upload_session req.session[upload_id]import_session upload_session.import_sessionprogress import_session.tasks[0].get_progress return json_response progress else return json_response {'state' 'NONE'}
@click.command 'remote-set-url' @click.argument 'git-url' def remote_set_url git_url set_git_remote_url git_url
def s3_redirect_default location '' how 303 client_side False headers None response current.responsesession current.sessionsession.error response.errorsession.warning response.warningsession.confirmation response.confirmationsession.flash response.flashredirect location how how client_side client_side headers headers
def xprotect_entries attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'xprotect_entries' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def sample_final_epsilon final_epsilons np.array [0.1 0.01 0.5] probabilities np.array [0.4 0.3 0.3] return np.random.choice final_epsilons 1 p list probabilities [0]
def v4_key_to_string v4_key path_element_strings []for path_element in v4_key.path_element_list if path_element.has_id id_or_name str path_element.id elif path_element.has_name id_or_name path_element.name else id_or_name ''path_element_strings.append '%s %s' % path_element.kind id_or_name return '[%s]' % ' '.join path_element_strings
def gf_cofactors f g p K if not f and not g return [] [] [] h gf_gcd f g p K return h gf_quo f h p K gf_quo g h p K
@require_chanmsg@require_privilege OP u'Youarenotachanneloperator.' @commands u'topic' def topic bot trigger if bot.privileges[trigger.sender][bot.nick] < HALFOP return bot.reply u"I'mnotachanneloperator!" if not trigger.group 2 returnchannel trigger.sender.lower narg 1mask Nonemask bot.db.get_channel_value channel u'topic_mask' mask mask or default_mask trigger mask mask.replace u'%s' u'{}' narg len re.findall u'{}' mask top trigger.group 2 args []if top args top.split u'~' narg if len args ! narg message u'Notenougharguments.Yougave{} itrequires{}.'.format len args narg return bot.say message topic mask.format *args bot.write u'TOPIC' channel + u' ' + topic
def get_conf if _HIVE_SITE_DICT is None _parse_hive_site return _HIVE_SITE_DICT
def api_doc section uses_site False **kwargs def add_metadata api_function doc api_function._api_doc getattr api_function '_api_doc' {} if 'extends' in kwargs kwargs['extends'] kwargs['extends']._api_docdoc.update kwargs doc['uses_site'] uses_sitedoc['section'] sectiondoc['lineno'] api_function.func_code.co_firstlinenofile_path abspath api_function.func_code.co_filename root_dir g.paths['root']if file_path.startswith root_dir doc['relfilepath'] relpath file_path root_dir doc['source_root_url'] 'https //github.com/reddit/reddit/blob/master/r2/r2/'else for plugin in g.plugins plugin_root plugin.pathif plugin.source_root_url and file_path.startswith plugin_root doc['relfilepath'] relpath file_path plugin_root doc['source_root_url'] plugin.source_root_urlreturn api_functionreturn add_metadata
def get_paths_extents paths transforms [] from .transforms import Bbox Affine2Dif len paths 0 raise ValueError u'Nopathsprovided' return Bbox.from_extents *_path.get_path_collection_extents Affine2D paths transforms [] Affine2D
def _unquote_json quoted_json_document json_document unquote quoted_json_document return json.loads json_document
def shrink_tensor x w raise NotImplementedError 'TODO implementthisfunction.'
def cart_counter request cart get_cart_from_request request return {u'cart_counter' cart.quantity}
def check_normal_basic shape_as_symbolic dim_as_symbolic False rng CURAND_RandomStreams 234 if shape_as_symbolic shape constant 10 10 elif dim_as_symbolic shape 10 constant 10 else shape 10 10 u0 rng.normal shape u1 rng.normal shape f0 theano.function [] u0 mode mode_with_gpu f1 theano.function [] u1 mode mode_with_gpu v0list [f0 for i in range 3 ]v1list [f1 for i in range 3 ]assert numpy.all v0list[0] ! v0list[1] assert numpy.all v1list[0] ! v1list[1] assert numpy.all v0list[0] ! v1list[0] for v in v0list assert v.shape 10 10 assert v.min < v.max assert -0.5 < v.mean < 0.5
def _make_chunk_iter stream limit buffer_size if isinstance stream bytes bytearray text_type raise TypeError 'Passedastringorbyteobjectinsteadoftrueiteratororstream.' if not hasattr stream 'read' for item in stream if item yield item returnif not isinstance stream LimitedStream and limit is not None stream LimitedStream stream limit _read stream.readwhile 1 item _read buffer_size if not item break yield item
def test_cnn_fit_sample_with_wrong_object knn 'rnd'cnn CondensedNearestNeighbour random_state RND_SEED n_neighbors knn assert_raises ValueError cnn.fit_sample X Y
def test_incorrect_case_file_index data req InstallRequirement.from_line 'dinner' None finder PackageFinder [] [data.find_links3] session PipSession link finder.find_requirement req False assert link.url.endswith 'Dinner-2.0.tar.gz'
def GetAdWordsClient **kwargs client_customer_id kwargs.get 'ccid' 'clientcustomerid' dev_token kwargs.get 'dev_token' 'dev_token' user_agent kwargs.get 'user_agent' 'user_agent' validate_only kwargs.get 'validate_only' False partial_failure kwargs.get 'partial_failure' False report_downloader_headers kwargs.get 'report_downloader_headers' {} if 'oauth2_client' in kwargs oauth2_client kwargs['oauth2_client']else oauth_header {'Authorization' 'header'}oauth2_client mock.Mock oauth2_client.CreateHttpHeader.return_value dict oauth_header client googleads.adwords.AdWordsClient dev_token oauth2_client user_agent client_customer_id client_customer_id cache kwargs.get 'cache' proxy_config kwargs.get 'proxy_config' validate_only validate_only partial_failure partial_failure report_downloader_headers report_downloader_headers return client
def freeze G G.add_node frozenG.add_nodes_from frozenG.remove_node frozenG.remove_nodes_from frozenG.add_edge frozenG.add_edges_from frozenG.remove_edge frozenG.remove_edges_from frozenG.clear frozenG.frozen Truereturn G
def get_top_rated_exploration_summary_dicts language_codes limit filtered_exp_summaries [exp_summary for exp_summary in exp_services.get_top_rated_exploration_summaries limit .values if exp_summary.language_code in language_codes and sum exp_summary.ratings.values > 0 ]sorted_exp_summaries sorted filtered_exp_summaries key lambda exp_summary exp_summary.scaled_average_rating reverse True return get_displayable_exp_summary_dicts sorted_exp_summaries
def test_radian_base assert 1 * u.degree .si.unit u.rad
def educate_single_backticks s return s.replace '`' '&#8216;' .replace "'" '&#8217;'
def libvlc_media_set_meta p_md e_meta psz_value f _Cfunctions.get 'libvlc_media_set_meta' None or _Cfunction 'libvlc_media_set_meta' 1 1 1 None None Media Meta ctypes.c_char_p return f p_md e_meta psz_value
def global_contrast_normalize X scale 1.0 subtract_mean True use_std False sqrt_bias 0.0 min_divisor 1e-08 assert X.ndim 2 'X.ndimmustbe2'scale float scale assert scale > min_divisor mean X.mean axis 1 if subtract_mean X X - mean[ numpy.newaxis] else X X.copy if use_std ddof 1if X.shape[1] 1 ddof 0normalizers numpy.sqrt sqrt_bias + X.var axis 1 ddof ddof / scale else normalizers numpy.sqrt sqrt_bias + X ** 2 .sum axis 1 / scale normalizers[ normalizers < min_divisor ] 1.0X / normalizers[ numpy.newaxis]return X
def restore_file_ownership path os.path.join os.path.expanduser '~/' '.w3af' if not os.path.exists path return Falsetry uid int os.getenv 'SUDO_UID' gid int os.getenv 'SUDO_GID' except ValueError return Falsetry _chown path uid gid except return Falsereturn True
def loadMimeTypes mimetype_locations None init mimetypes.init init mimetype_locations mimetypes.types_map.update {'.conf' 'text/plain' '.diff' 'text/plain' '.flac' 'audio/x-flac' '.java' 'text/plain' '.oz' 'text/x-oz' '.swf' 'application/x-shockwave-flash' '.wml' 'text/vnd.wap.wml' '.xul' 'application/vnd.mozilla.xul+xml' '.patch' 'text/plain'} return mimetypes.types_map
def hsetnx key field value host None port None db None password None server _connect host port db password return server.hsetnx key field value
def get_attributes_dicts object_name parent_object_names object_dict OBJECTS[object_name]additional_attributes object_dict['additional_attributes']attribute_paths list object_dict['attribute_paths'] if FRAME_NAME in parent_object_names len_parent_object_names len parent_object_names index parent_object_names.index FRAME_NAME if len_parent_object_names index + 1 if object_name in 'data' 'layout' parent_object_names ['figure' object_name]elif len_parent_object_names > index + 1 if parent_object_names[ index + 1 ] in 'data' 'layout' parent_object_names ['figure'] + list parent_object_names [ index + 1 ] for parent_object_name in reversed parent_object_names if parent_object_name in ARRAYS continueparent_object_dict OBJECTS[parent_object_name]parent_attribute_paths parent_object_dict['attribute_paths']for path in list attribute_paths if not _is_valid_sub_path path parent_attribute_paths attribute_paths.remove path attributes_dicts {path utils.get_by_path GRAPH_REFERENCE path for path in attribute_paths}attributes_dicts['additional_attributes'] additional_attributesreturn attributes_dicts
def parse_call_named_group source info pos group parse_name source source.expect ' ' return CallGroup info group pos
def test_compilation cfile compiler None **compiler_attrs cc get_compiler compiler **compiler_attrs efile ext os.path.splitext cfile cpreargs lpreargs Noneif sys.platform 'darwin' if platform.architecture [0] '32bit' if platform.processor 'powerpc' cpu 'ppc'else cpu 'i386'cpreargs ['-arch' cpu]lpreargs ['-arch' cpu '-undefined' 'dynamic_lookup']else lpreargs ['-undefined' 'dynamic_lookup']if sys.platform 'sunos5' if platform.architecture [0] '32bit' lpreargs ['-m32']else lpreargs ['-m64']extra compiler_attrs.get 'extra_compile_args' None objs cc.compile [cfile] extra_preargs cpreargs extra_postargs extra cc.link_executable objs efile extra_preargs lpreargs return efile
def _get_random_string length 44 allowed_chars 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' secret_key settings.secret_key_bytes secret_key _ensure_bytes secret_key _reseed_if_needed using_sysrandom secret_key return ''.join random.choice allowed_chars for i in range length
def escape_invalid_characters name invalid_char_list replace_with '_' for char in invalid_char_list if char in name name name.replace char replace_with return name
def auth_complete request backend user *args **kwargs if request.session.get PIPELINE_KEY data request.session.pop PIPELINE_KEY kwargs kwargs.copy if user kwargs['user'] user idx xargs xkwargs backend.from_session_dict data request request *args **kwargs if 'backend' in xkwargs and xkwargs['backend'].name backend.AUTH_BACKEND.name return backend.continue_pipeline pipeline_index idx *xargs **xkwargs return backend.auth_complete user user request request *args **kwargs
def image_whitening data assert len np.shape data 4 nb_pixels np.shape data [1] * np.shape data [2] * np.shape data [3] mean np.mean data axis 1 2 3 ones np.ones np.shape data [1 4] dtype np.float32 for i in xrange len data data[i ] - mean[i] * ones adj_std_var np.maximum np.ones len data dtype np.float32 / math.sqrt nb_pixels np.std data axis 1 2 3 for i in xrange len data data[i ] data[i ] / adj_std_var[i] print np.shape data return data
def handle_500 _ response exception logging.exception exception response.set_status 500 response.write jinja_environment.get_template '500.html' .render
def organization_create context data_dict data_dict.setdefault 'type' 'organization' _check_access 'organization_create' context data_dict return _group_or_org_create context data_dict is_org True
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
def undefine vm_ dom _get_domain vm_ return dom.undefine 0
def connectServerAndClient test clientFactory serverFactory addr '127.0.0.1' clientBroker clientFactory.buildProtocol addr serverBroker serverFactory.buildProtocol addr clientTransport StringIO serverTransport StringIO clientBroker.makeConnection protocol.FileWrapper clientTransport serverBroker.makeConnection protocol.FileWrapper serverTransport pump IOPump clientBroker serverBroker clientTransport serverTransport def maybeDisconnect broker if not broker.disconnected broker.connectionLost failure.Failure main.CONNECTION_DONE def disconnectClientFactory clientFactory.clientConnectionLost connector None reason failure.Failure main.CONNECTION_DONE test.addCleanup maybeDisconnect clientBroker test.addCleanup maybeDisconnect serverBroker test.addCleanup disconnectClientFactory pump.pump return clientBroker serverBroker pump
def split_datastore_path datastore_path spl datastore_path.split '[' 1 [1].split ']' 1 path ''if len spl 1 datastore_url spl[0]else datastore_url path splreturn datastore_url path.strip
def _api_rss_now name output kwargs scheduler.force_rss return report output
def rindex s *args return s.rindex *args
def submit_row context opts context['opts']change context['change']is_popup context['is_popup']save_as context['save_as']return {'onclick_attrib' opts.get_ordered_objects and change and 'onclick "submitOrderForm ;"' or '' 'show_delete_link' not is_popup and context['has_delete_permission'] and change or context['show_delete'] 'show_save_as_new' not is_popup and change and save_as 'show_save_and_add_another' context['has_add_permission'] and not is_popup and not save_as or context['add'] 'show_save_and_continue' not is_popup and context['has_change_permission'] 'is_popup' is_popup 'show_save' True}
def globalsfilter input_dict check_all False filters None exclude_private None exclude_capitalized None exclude_uppercase None exclude_unsupported None excluded_names None output_dict {}for key value in list input_dict.items excluded exclude_private and key.startswith '_' or exclude_capitalized and key[0].isupper or exclude_uppercase and key.isupper and len key > 1 and not key[1 ].isdigit or key in excluded_names or exclude_unsupported and not is_supported value check_all check_all filters filters if not excluded output_dict[key] valuereturn output_dict
def absolute_reverse view_name query_kwargs None args None kwargs None relative_url reverse view_name kwargs kwargs url website_util.api_v2_url relative_url params query_kwargs base_prefix '' return url
def _specify_repositories base disablerepo enablerepo base.read_all_repos repos base.reposfor repo_pattern in disablerepo for repo in repos.get_matching repo_pattern repo.disable for repo_pattern in enablerepo for repo in repos.get_matching repo_pattern repo.enable
def login_redirect request ignorable_nexts u'' if u'mezzanine.accounts' in settings.INSTALLED_APPS from mezzanine.accounts import urlsignorable_nexts + urls.SIGNUP_URL urls.LOGIN_URL urls.LOGOUT_URL next next_url request or u'' if next in ignorable_nexts next settings.LOGIN_REDIRECT_URLif next u'/accounts/profile/' next get_script_prefix else try next reverse next except NoReverseMatch passreturn redirect next
def Pdf pdf **options low high options.pop 'low' None options.pop 'high' None n options.pop 'n' 101 xs ps pdf.Render low low high high n n options _Underride options label pdf.label Plot xs ps **options
def cov_nw_groupsum results nlags time weights_func weights_bartlett use_correction 0 xu hessian_inv _get_sandwich_arrays results S_hac S_hac_groupsum xu time nlags nlags weights_func weights_func cov_hac _HCCM2 hessian_inv S_hac if use_correction nobs k_params xu.shapeif use_correction 'hac' cov_hac * nobs / float nobs - k_params elif use_correction in ['c' 'cluster'] n_groups len np.unique time cov_hac * n_groups / n_groups - 1.0 cov_hac * nobs - 1.0 / float nobs - k_params return cov_hac
def __options2hash list retval {}counter 0while counter < len list retval[list[counter]] list[ counter + 1 ]counter + 2__debug '__options2hashreturning ' retval return retval
def register linter linter.register_checker ExceptionsChecker linter
@mock_streams 'stdout' def test_puts_with_unicode_output s u'string!'output.user Trueputs s show_prefix False eq_ sys.stdout.getvalue s + '\n'
def transform_command src show_diff True i 0limit sys.getrecursionlimit lst ''raw srcwhile src ! lst lst srcsrcs events.on_transform_command.fire src for s in srcs if s ! lst src sbreaki + 1if i limit print_exception 'Modifcationstosourceinputtookmorethantherecursionlimitnumberofinterationstoconverge.' debug_level builtins.__xonsh_env__.get 'XONSH_DEBUG' if show_diff and debug_level > 1 and src ! raw sys.stderr.writelines difflib.unified_diff raw.splitlines keepends True src.splitlines keepends True fromfile 'beforeprecommandevent' tofile 'afterprecommandevent' return src
def load_pandas data _get_data return du.process_recarray_pandas data endog_idx 0 dtype float
def tokenize readline from itertools import chain repeat encoding consumed detect_encoding readline rl_gen iter readline '' empty repeat '' return _tokenize chain consumed rl_gen empty .__next__ encoding
def get_registered_from registration if registration.registered_from return registration.registered_from_idelse log registration.logs[0]return log.params.get 'node' or log.params.get 'project'
def do_one *brules def do_one_brl expr yielded Falsefor brl in brules for nexpr in brl expr yielded True yield nexpr if yielded returnreturn do_one_brl
def FilterFnTable fn_table symbol new_table list for entry in fn_table if entry[0] ! symbol new_table.append entry return new_table
def ztost x1 low upp x2 None usevar 'pooled' ddof 1.0 tt1 ztest x1 x2 alternative 'larger' usevar usevar value low ddof ddof tt2 ztest x1 x2 alternative 'smaller' usevar usevar value upp ddof ddof return np.maximum tt1[1] tt2[1] tt1 tt2
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def _generate_tar_package target sources sources_dir suffix mode _get_tar_mode_from_suffix suffix tar tarfile.open target mode manifest _archive_package_sources tar.add sources sources_dir manifest_path '%s.MANIFEST' % target m open manifest_path 'w' print >>m '\n'.join manifest + '\n' m.close tar.add manifest_path _PACKAGE_MANIFEST tar.close return None
def disable_site site_name if is_site_enabled site_name run_as_root 'a2dissite%s' % _site_config_filename site_name
def getPerimeterWidth elementNode if elementNode None return 0.72preferences skeinforge_craft.getCraftPreferences 'carve' layerThickness skeinforge_craft.getCraftValue 'LayerThickness' preferences layerThickness getCascadeFloatWithoutSelf layerThickness elementNode 'layerThickness' perimeterWidthOverThickness skeinforge_craft.getCraftValue 'PerimeterWidthoverThickness' preferences perimeterWidthOverThickness getCascadeFloatWithoutSelf perimeterWidthOverThickness elementNode 'perimeterWidthOverThickness' return getCascadeFloatWithoutSelf perimeterWidthOverThickness * layerThickness elementNode 'perimeterWidth'
def s3_get_foreign_key field m2m True ftype str field.type multiple Falseif ftype[ 9] 'reference' key ftype[10 ]elif m2m and ftype[ 14] 'list reference' key ftype[15 ]multiple Trueelse key current.s3db.virtual_reference field if not key return None None None if '.' in key rtablename key key.split '.' else rtablename keyrtable current.s3db.table rtablename if rtable key rtable._id.nameelse key Nonereturn rtablename key multiple
def fixRelativeLinks document linkrel for attr in 'src' 'href' for node in domhelpers.findElementsWithAttribute document attr href node.getAttribute attr if not href.startswith 'http' and not href.startswith '/' node.setAttribute attr linkrel + node.getAttribute attr
def unpack_zipfile filename extract_dir progress_filter default_filter if not zipfile.is_zipfile filename raise UnrecognizedFormat '%sisnotazipfile' % filename z zipfile.ZipFile filename try for info in z.infolist name info.filenameif name.startswith '/' or '..' in name.split '/' continuetarget os.path.join extract_dir *name.split '/' target progress_filter name target if not target continueif name.endswith '/' ensure_directory target else ensure_directory target data z.read info.filename f open target 'wb' try f.write data finally f.close del dataunix_attributes info.external_attr >> 16 if unix_attributes os.chmod target unix_attributes finally z.close
def GetGlobalVSMacroEnv vs_version env {}if vs_version.Path env['$ VSInstallDir '] vs_version.Path env['$ VCInstallDir '] os.path.join vs_version.Path 'VC' + '\\' dxsdk_dir _FindDirectXInstallation env['$ DXSDK_DIR '] dxsdk_dir if dxsdk_dir else '' env['$ WDK_DIR '] os.environ.get 'WDK_DIR' '' return env
def test_type for c in Script 'importos;os.path.' .completions assert c.type
def submit_step outer_step def decorator f @functools.wraps f def wrapper request *args **kw from mkt.submit.views import _resumefrom mkt.submit.models import AppSubmissionChecklistaddon kw.get 'addon' False if addon try step addon.appsubmissionchecklist.get_next except AppSubmissionChecklist.DoesNotExist step Noneif step and step ! outer_step return _resume addon step return f request *args **kw wrapper.submitting Truereturn wrapperreturn decorator
def create_bookmark_action parent url title icon None shortcut None @Slot def open_url return programs.start_file url return create_action parent title shortcut shortcut icon icon triggered open_url
def prepare_fsdev job global FSDEV_JOBglobal FSDEV_DISKLISTglobal FSDEV_PREP_CNTif not FSDEV_FS_DESC return None None FSDEV_PREP_CNT + 1if FSDEV_PREP_CNT > 1 return FSDEV_DISKLIST[0]['mountpt'] FSDEV_DISKLIST FSDEV_JOB job path toss disks prepare_disks job fs_desc FSDEV_FS_DESC disk1_only FSDEV_DISK1_ONLY disk_list None FSDEV_DISKLIST disksreturn path disks
def demo_serialize_tagger postag serialize_output 'tagger.pcl'
def has_gravatar email if frappe.flags.in_import or frappe.flags.in_install or frappe.flags.in_test return u''hexdigest md5.md5 frappe.as_unicode email .encode u'utf-8' .hexdigest gravatar_url u'https //secure.gravatar.com/avatar/{hash}?d 404&s 200'.format hash hexdigest try res requests.get gravatar_url if res.status_code 200 return gravatar_urlelse return u''except requests.exceptions.ConnectionError return u''
def askyesno title None message None **options s _show title message QUESTION YESNO **options return s YES
def _ll_nb2 y X beta alph ll _ll_nbp y X beta alph Q 0 return ll
def execute_rule rule matches context if rule.enabled context log rule.log_level 'Checkingrulecondition %s' rule when_response rule.when matches context if when_response log rule.log_level 'Rulewastriggered %s' when_response log rule.log_level 'Runningruleconsequence %s%s' rule when_response rule.then matches when_response context return when_responseelse log rule.log_level 'Ruleisdisabled %s' rule
def verify_running_as_root if os.getuid ! 0 raise error.TestNAError 'Thistestrequiresrootprivileges currentlyrunningwithuser%s ' % getpass.getuser
def test_setting_the_same_value_marks_field_as_dirty class FieldTester XBlock 'Testblockforset-gettest.'non_mutable String scope Scope.settings list_field List scope Scope.settings dict_field Dict scope Scope.settings runtime TestRuntime services {'field-data' DictFieldData {} } field_tester FieldTester runtime scope_ids Mock spec ScopeIds assert_equals len field_tester._dirty_fields 0 assert_false field_tester.fields['list_field'].is_set_on field_tester assert_false field_tester.fields['dict_field'].is_set_on field_tester assert_false field_tester.fields['non_mutable'].is_set_on field_tester field_tester.non_mutable field_tester.non_mutablefield_tester.list_field field_tester.list_fieldfield_tester.dict_field field_tester.dict_fieldassert_not_in field_tester.fields['non_mutable'] field_tester._dirty_fields assert_in field_tester.fields['list_field'] field_tester._dirty_fields assert_in field_tester.fields['dict_field'] field_tester._dirty_fields assert_false field_tester.fields['non_mutable'].is_set_on field_tester assert_false field_tester.fields['list_field'].is_set_on field_tester assert_false field_tester.fields['dict_field'].is_set_on field_tester
def template pattern flags 0 return _compile pattern flags | TEMPLATE
def _get_kernel value if value is None or value.lower u'builtin' return Noneif value.lower u'jpl' value DEFAULT_JPL_EPHEMERISif value.lower in u'de430' u'de432s' value u'http //naif.jpl.nasa.gov/pub/naif/generic_kernels/spk/planets/{ s}.bsp'.format value.lower else try six.moves.urllib.parse.urlparse value except Exception raise ValueError u'{}wasnotoneofthestandardstringsandcouldnotbeparsedasaURL'.format value try from jplephem.spk import SPKexcept ImportError raise ImportError u'SolarsystemJPLephemeriscalculationsrequirethejplephempackage https //pypi.python.org/pypi/jplephem ' return SPK.open download_file value cache True
def is_logged_in_cookie_set request return settings.EDXMKTG_LOGGED_IN_COOKIE_NAME in request.COOKIES and settings.EDXMKTG_USER_INFO_COOKIE_NAME in request.COOKIES
def get_family families if not isinstance families list families [families]for family in families if font_is_installed family return familyelse print 'Warning Noneofthefollowingfontsisinstalled %r' % families return QFont .family
def callIntoPAM service user conv pam PAM.pam pam.start service pam.set_item PAM.PAM_USER user pam.set_item PAM.PAM_CONV conv gid os.getegid uid os.geteuid os.setegid 0 os.seteuid 0 try pam.authenticate pam.acct_mgmt return 1finally os.setegid gid os.seteuid uid
def mpd distmat return distmat.sum / distmat.size - distmat.shape[0]
@frappe.whitelist def update_column_order board_name order board frappe.get_doc u'KanbanBoard' board_name order json.loads order old_columns board.columnsnew_columns []for col in order for column in old_columns if col column.column_name new_columns.append column old_columns.remove column new_columns.extend old_columns board.columns []for col in new_columns board.append u'columns' dict column_name col.column_name status col.status order col.order indicator col.indicator board.save return board
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
def test_tb_syntaxerror ip get_ipython ip.run_cell 'for' save_stdout sys.stdouttry sys.stdout StringIO ip.run_cell '%tb' out sys.stdout.getvalue finally sys.stdout save_stdoutlast_line out.rstrip .splitlines [ -1 ].strip nt.assert_equal last_line 'SyntaxError invalidsyntax'
def pool_list **kwargs return ceph_cfg.pool_list **kwargs
def p_exclusive_or_expression_1 t pass
def inference_tip infer_function def transform node infer_function infer_function node._explicit_inference infer_functionreturn nodereturn transform
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def test_renn_sample_wrong_X renn RepeatedEditedNearestNeighbours random_state RND_SEED renn.fit X Y assert_raises RuntimeError renn.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def candlestick_ochl ax quotes width 0.2 colorup u'k' colordown u'r' alpha 1.0 return _candlestick ax quotes width width colorup colorup colordown colordown alpha alpha ochl True
def dup_from_sympy f K return dup_strip [K.from_sympy c for c in f]
def fullsplit path result None if result is None result [] head tail os.path.split path if head '' return [tail] + result if head path return resultreturn fullsplit head [tail] + result
def _check_group_branches config physical_skel logging.debug 'Checkinggroupbranchesmatchexpectations' for group relations in physical_skel.items if 'belongs_to' not in relations continueparents relations['belongs_to']for parent in parents if parent in config.keys message 'Group{parent}hasachildgroup{child} butalsohashostentriesinuserconfiguration.Hostscannotbesiblingwithgroups.'.format parent parent child group raise GroupConflict message logging.debug 'Groupbranchesok.' return True
def user_must_complete_entrance_exam request user course if user_can_skip_entrance_exam user course return Falseif user_has_passed_entrance_exam request course return Falsereturn True
def validate_timeout_or_none option value if value is None return valuereturn validate_positive_float option value / 1000.0
def _MakeXMLSafe s s cgi.escape s s re.sub '[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]' '' s s s.encode 'ascii' 'xmlcharrefreplace' return s
def get_cache_key request key_prefix None method 'GET' cache None if key_prefix is None key_prefix settings.CACHE_MIDDLEWARE_KEY_PREFIXcache_key _generate_cache_header_key key_prefix request if cache is None cache caches[settings.CACHE_MIDDLEWARE_ALIAS]headerlist cache.get cache_key if headerlist is not None return _generate_cache_key request method headerlist key_prefix else return None
def _fix_shape x n axis s list x.shape if s[axis] > n index [slice None ] * len s index[axis] slice 0 n x x[index]return x False else index [slice None ] * len s index[axis] slice 0 s[axis] s[axis] nz zeros s x.dtype.char z[index] xreturn z True
def _reorient_starts starts blksizes seqlen strand assert len starts len blksizes 'Unequalstartcoordinatesandblocksizeslist %rvs%r ' % len starts len blksizes if strand > 0 return startselse return [ seqlen - start - blksize for start blksize in zip starts blksizes ]
def all_valid formsets valid Truefor formset in formsets if not formset.is_valid valid Falsereturn valid
@with_setup prepare_stdout registry.clear def test_xunit_output_with_one_error called []def assert_correct_xml filename content called.append True assert_xsd_valid filename content root etree.fromstring content assert_equals root.get 'tests' '2' assert_equals root.get 'failures' '1' assert_equals len root.getchildren 2 passed failed root.findall 'testcase' assert_equals passed.get 'name' 'Givenmystepthatpasses' assert_true float passed.get 'time' > 0 assert_equals failed.get 'name' 'Givenmystepthatblowsaexception' assert_true float failed.get 'time' > 0 assert_true failed.find 'failure' is not None old xunit_output.wrt_outputxunit_output.wrt_output assert_correct_xmlrunner Runner feature_name 'error_traceback' enable_xunit True runner.run assert_equals 1 len called 'Functionnotcalled' xunit_output.wrt_output old
def test_hosts_decorator_overrides_env_hosts @hosts 'bar' def command passeq_hosts command ['bar'] env {'hosts' ['foo']}
@deprecated u'2.1' def allequal seq if len seq < 2 return Trueval seq[0]for i in xrange 1 len seq thisval seq[i]if thisval ! val return Falsereturn True
def ode_1st_homogeneous_coeff_best eq func order match sol1 ode_1st_homogeneous_coeff_subs_indep_div_dep eq func order match sol2 ode_1st_homogeneous_coeff_subs_dep_div_indep eq func order match simplify match.get 'simplify' True if simplify constants sol1.free_symbols.difference eq.free_symbols sol1 odesimp sol1 func order constants '1st_homogeneous_coeff_subs_indep_div_dep' constants sol2.free_symbols.difference eq.free_symbols sol2 odesimp sol2 func order constants '1st_homogeneous_coeff_subs_dep_div_indep' return min [sol1 sol2] key lambda x ode_sol_simplicity x func trysolving not simplify
def get_vlan vlanid module command 'showvlanid' + vlanid body execute_show_command command module try vlan_table body[0]['TABLE_vlanbriefid']['ROW_vlanbriefid']except TypeError IndexError return {}key_map {'vlanshowbr-vlanid-utf' 'vlan_id' 'vlanshowbr-vlanname' 'name' 'vlanshowbr-vlanstate' 'vlan_state' 'vlanshowbr-shutstate' 'admin_state'}vlan apply_key_map key_map vlan_table value_map {'admin_state' {'shutdown' 'down' 'noshutdown' 'up'}}vlan apply_value_map value_map vlan vlan['mapped_vni'] get_vni vlanid module return vlan
def get_text_tag tag name default if tag is None return defaultt tag.find name if t is not None and t.text is not None return t.textelse return default
def test_dataset_validation_shuffle_split skip_if_no_sklearn mapping {'dataset_iterator' 'DatasetValidationShuffleSplit'}test_yaml test_yaml_dataset_iterator % mapping trainer yaml_parse.load test_yaml trainer.main_loop
def read_crop fname lims 0 None return read_raw_fif fname allow_maxshield 'yes' .crop *lims
@image_comparison baseline_images [u'tight_layout4'] freetype_version u'2.4.5' u'2.4.9' def test_tight_layout4 fig plt.figure ax1 plt.subplot2grid 3 3 0 0 ax2 plt.subplot2grid 3 3 0 1 colspan 2 ax3 plt.subplot2grid 3 3 1 0 colspan 2 rowspan 2 ax4 plt.subplot2grid 3 3 1 2 rowspan 2 example_plot ax1 example_plot ax2 example_plot ax3 example_plot ax4 plt.tight_layout
def get_ninja_plugin_file path extension '.plugin'return get_ninja_file path extension only_first True
def _correct_auto_elements surf mat pi2 2.0 * np.pi tris_flat surf['tris'].ravel misses pi2 - mat.sum axis 1 for j miss in enumerate misses n_memb len surf['neighbor_tri'][j] mat[ j j ] miss / 2.0 miss / 4.0 * n_memb members np.where j tris_flat [0]mods members % 3 offsets np.array [[1 2] [ -1 1] [ -1 -2 ]] tri_1 members + offsets[ mods 0 ] tri_2 members + offsets[ mods 1 ] for t1 t2 in zip tri_1 tri_2 mat[ j tris_flat[t1] ] + missmat[ j tris_flat[t2] ] + missreturn
def read_url url logging.debug 'reading{url}...'.format url url r urlopen url .read return json.loads r.decode 'UTF-8'
def valid_jsonp_callback_value value for identifier in value.split u'.' while '[' in identifier if not has_valid_array_index identifier return Falseidentifier replace_array_index u'' identifier if not valid_javascript_identifier identifier return Falsereturn True
def p_function_definition_4 t pass
def test_signature_is_definition s 'classSpam pass\nSpam'signature Script s + ' ' .call_signatures [0]definition Script s + ' ' column 0 .goto_definitions [0] signature.line 1 signature.column 6 for attr_name in dir definition dont_scan ['defined_names' 'line_nr' 'start_pos' 'documentation' 'doc' 'parent' 'goto_assignments']if attr_name.startswith '_' or attr_name in dont_scan continueattribute getattr definition attr_name signature_attribute getattr signature attr_name if inspect.ismethod attribute assert attribute signature_attribute else assert attribute signature_attribute
def _validate_time req values for time_field in ['created_at' 'updated_at' 'deleted_at'] if time_field in values and values[time_field] try time timeutils.parse_isotime values[time_field] if time.year < 1900 raise ValueErrorvalues[time_field] time.strftime timeutils.PERFECT_TIME_FORMAT except ValueError msg _ 'Invalidtimeformatfor%s.' % time_field raise HTTPBadRequest explanation msg request req
def gen_cosine_amp amp 100 period 1000 x0 0 xn 50000 step 1 k 0.0001 cos np.zeros xn - x0 * step 1 1 for i in range len cos idx x0 + i * step cos[ i 0 0 ] amp * np.cos 2 * np.pi * idx / period cos[ i 0 0 ] cos[ i 0 0 ] * np.exp - k * idx return cos
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def from_tuple tup if len tup not in 2 3 raise ValueError 'tuplemustcontain2or3elements not %d %r' % len tup tup return range *tup
def _cursor return connections[router.db_for_read Document ].cursor
def test_elemwise_collapse7 atol 1e-06 shape 5 4 1 a cuda_ndarray.CudaNdarray theano._asarray numpy.random.rand *shape dtype 'float32' a theano._asarray numpy.random.rand *shape dtype 'float32' a2 tcn.shared_constructor a.copy 'a' a3 a2.dimshuffle 0 'x' 1 2 f pfunc [] [ a3 + 2 ] mode mode_with_gpu out f [0]ans a + 2 .reshape shape[0] 1 shape[1] shape[2] assert numpy.allclose out ans atol atol
def get_featured_activity_references featured_model_instance activity_models.ActivityReferencesModel.get_or_create activity_models.ACTIVITY_REFERENCE_LIST_FEATURED return [activity_domain.ActivityReference reference['type'] reference['id'] for reference in featured_model_instance.activity_references]
def stub_and_esp32_function_only func return check_supported_function func lambda o o.IS_STUB or o.CHIP_NAME 'ESP32'
def test_read_unbounded_right_column_header table '\n#comment withblanklineabove \n \nCol1Col2Col3Long\n \n1.22Hello\n2.44Worlds\n \n'reader ascii.get_reader Reader ascii.RST dat reader.read table assert_equal dat.colnames[ -1 ] 'Col3Long'
def get_nic module cli vrouter_name module.params['pn_vrouter_name']interface_ip module.params['pn_interface_ip']global VRRP_EXISTSshow cli + 'vrouter-interface-showvrouter-name%s' % vrouter_name show + 'ip%sformatip nicno-show-headers' % interface_ip show shlex.split show out module.run_command show [1]out out.split if len out > 3 VRRP_EXISTS Truereturn Noneelse nic out[2]VRRP_EXISTS Falsereturn nic
def find_newline source assert not isinstance source unicode counter collections.defaultdict int for line in source if line.endswith CRLF counter[CRLF] + 1elif line.endswith CR counter[CR] + 1elif line.endswith LF counter[LF] + 1return sorted counter key counter.get reverse True or [LF] [0]
def _convert_date_time_string dt_string dt_string dt_string.split '.' [0]dt_obj datetime.strptime dt_string '%Y%m%d%H%M%S' return dt_obj.strftime '%Y-%m-%d%H %M %S'
def featurewise_norm x mean None std None epsilon 1e-07 if mean x x - mean if std x x / std + epsilon return x
def atlas6 Atlas graph_atlas_g [0 208]U nx.Graph for G in Atlas zerodegree [n for n in G if G.degree n 0 ]for n in zerodegree G.remove_node n U nx.disjoint_union U G C nx.connected_component_subgraphs U UU nx.Graph nlist []for G in C if not iso G nlist nlist.append G UU nx.disjoint_union UU G return UU
def cert_generation_enabled course_key return CertificateGenerationConfiguration.current .enabled and CertificateGenerationCourseSetting.is_enabled_for_course course_key
def mul_expr lh_op rh_op size return lo.LinOp lo.MUL size [rh_op] lh_op
def log_query func def wrapper obj query_string *args **kwargs start time try return func obj query_string *args **kwargs finally stop time if settings.DEBUG from haystack import connectionsconnections[obj.connection_alias].queries.append {u'query_string' query_string u'additional_args' args u'additional_kwargs' kwargs u'time' u'%.3f' % stop - start u'start' start u'stop' stop} return wrapper
def compute_readout params epi_factor 1.0acc_factor 1.0try if params[u'epi_factor'] > 1 epi_factor float params[u'epi_factor'] - 1 except passtry if params[u'acc_factor'] > 1 acc_factor 1.0 / params[u'acc_factor'] except passreturn acc_factor * epi_factor * params[u'echospacing']
def _get_finder import_path Finder import_by_path import_path if not issubclass Finder BaseFinder raise ImproperlyConfigured 'Finder"%s"isnotasubclassof"%s"' % Finder BaseFinder return Finder
def delete_users users test False commit True return __salt__['net.load_template'] 'delete_users' users users test test commit commit
@builtin u'Capitalizetext ignoretags ' capitalize apply_func_to_html_text def replace_capitalize_ignore_tags match number file_name metadata dictionaries data functions *args **kwargs return apply_func_to_html_text match capitalize
def _GenericRetrieve root default path if not root return defaultif not path return rootreturn _GenericRetrieve root.get path[0] default path[1 ]
def __GetServiceVersionDescription protocol server port path sslContext tree __GetElementTree protocol server port path + '/vimServiceVersions.xml' sslContext if tree is not None return treetree __GetElementTree protocol server port path + '/vimService.wsdl' sslContext return tree
def _store_option config option default type_ None allowed None section 'server' if config.has_option section option if type_ 'bool' value config.getboolean section option elif type_ 'int' value config.getint section option else value config.get section option else value defaultif allowed and value not in allowed raise ConfigurationError "Invaluedvalue'%s'foroption'%s'" % value option setattr current_app.slicer option value
@decorators.which 'blkid' def blkid device None args ''if device args '' + device ret {}blkid_result __salt__['cmd.run_all'] 'blkid' + args python_shell False if blkid_result['retcode'] > 0 return retfor line in blkid_result['stdout'].splitlines if not line continuecomps line.split device comps[0][ -1 ]info {}device_attributes re.split '"*"' line.partition '' [2] for key value in zip * [iter device_attributes ] * 2 key key.strip ' ' .strip '' info[key] value.strip '"' ret[device] inforeturn ret
def verify_signed_by_app data signature public_certificates app_identity.get_public_certificates for cert in public_certificates if verify_signature data signature cert.x509_certificate_pem return Truereturn False
def tokenize_by_number s r find_number s if r is None return [s]else tokens []if r[0] > 0 tokens.append s[0 r[0]] tokens.append float s[r[0] r[1]] if r[1] < len s tokens.extend tokenize_by_number s[r[1] ] return tokensassert False
def _find_start_entry line n infield 0if n 1 return 0c 1leng len line if line[0] '' infield 0field 0else infield 1field 1while c < leng and field < n if infield if line[c] '' and not line[ c - 1 ] '' infield 0elif not line[c] '' infield 1field field + 1 c c + 1 return c - 1
def setOffsetByMultiplier begin end multiplier offset segment end - begin delta segment * multiplier - segment offset.setToVector3 offset + delta
def rgba_to_hex rgba_string return '#' + ''.join [hex int each .replace '0x' '' .upper for each in rgba_string.replace 'rgba ' '' .replace ' ' '' .split ' ' [ -1 ]]
def modulePath try _ sys.executable if weAreFrozen else __file__ except NameError _ inspect.getsourcefile modulePath return getUnicode os.path.dirname os.path.realpath _ encoding sys.getfilesystemencoding or UNICODE_ENCODING
def getFilesWithFileTypesWithoutWords fileTypes words [] fileInDirectory '' filesWithFileTypes []for filePath in getFilePaths fileInDirectory for fileType in fileTypes if isFileWithFileTypeWithoutWords fileType filePath words filesWithFileTypes.append filePath filesWithFileTypes.sort return filesWithFileTypes
def test_with_refcounts runner verbosity testcase import gcimport ctypesptc ctypes._pointer_type_cache.copy cfc ctypes._c_functype_cache.copy wfc ctypes._win_functype_cache.copy def cleanup ctypes._pointer_type_cache ptc.copy ctypes._c_functype_cache cfc.copy ctypes._win_functype_cache wfc.copy gc.collect test unittest.makeSuite testcase for i in range 5 rc sys.gettotalrefcount runner.run test cleanup COUNT 5refcounts [None] * COUNT for i in range COUNT rc sys.gettotalrefcount runner.run test cleanup refcounts[i] sys.gettotalrefcount - rc if filter None refcounts print '%sleaks \n DCTB ' % testcase refcountselif verbosity print '%s ok.' % testcase
def multithread_request urls config None config config or Configuration num_threads config.number_threadstimeout config.thread_timeout_secondspool ThreadPool num_threads timeout m_requests []for url in urls m_requests.append MRequest url config for req in m_requests pool.add_task req.send pool.wait_completion return m_requests
def _getUserNameUID user os.environ.get 'USER' None or os.environ.get 'USERNAME' None if not user return 'undefined' '-1' if sys.platform not in ['win32'] uid shellCall 'id-u' else uid '1000'if haveCtypes and ctypes.windll.shell32.IsUserAnAdmin uid '0'return str user int uid
def additions_removed name force False ret {'name' name 'changes' {} 'result' False 'comment' ''}current_state __salt__['vbox_guest.additions_version'] if not current_state ret['result'] Trueret['comment'] 'Systemalreadyinthecorrectstate'return retif __opts__['test'] ret['comment'] 'ThestateofVirtualBoxGuestAdditionswillbechanged.'ret['changes'] {'old' current_state 'new' True}ret['result'] Nonereturn retnew_state __salt__['vbox_guest.additions_remove'] force force ret['comment'] 'ThestateofVirtualBoxGuestAdditionswaschanged!'ret['changes'] {'old' current_state 'new' new_state}ret['result'] bool new_state return ret
def _policyFileReplaceOrAppendList string_list policy_data if not policy_data policy_data ''specialValueRegex ' \\*\\*Del\\.|\\*\\*DelVals\\. {0 1}'for this_string in string_list list_item_key this_string.split '{0};'.format chr 0 [0].lstrip '[' list_item_value_name re.sub specialValueRegex '' this_string.split '{0};'.format chr 0 [1] flags re.IGNORECASE log.debug 'itemvaluenameis{0}'.format list_item_value_name data_to_replace _regexSearchKeyValueCombo policy_data list_item_key list_item_value_name if data_to_replace log.debug 'replacing{0}with{1}'.format [data_to_replace] [this_string] policy_data policy_data.replace data_to_replace this_string else log.debug 'appending{0}'.format [this_string] policy_data ''.join [policy_data this_string] return policy_data
def list_length queue items _list_items queue return len items
def config_get pattern '*' host None port None db None password None server _connect host port db password return server.config_get pattern
def get_next_double context builder state_ptr a builder.lshr get_next_int32 context builder state_ptr const_int 5 b builder.lshr get_next_int32 context builder state_ptr const_int 6 a builder.uitofp a double b builder.uitofp b double return builder.fdiv builder.fadd b builder.fmul a ir.Constant double 67108864.0 ir.Constant double 9007199254740992.0
def _dlog10 c e p p + 2l len str c f e + l - e + l > 1 if p > 0 M 10 ** p k e + p - f if k > 0 c * 10 ** k else c _div_nearest c 10 ** - k log_d _ilog c M log_10 _log10_digits p log_d _div_nearest log_d * M log_10 log_tenpower f * M else log_d 0log_tenpower _div_nearest f 10 ** - p return _div_nearest log_tenpower + log_d 100
def get_system_managers only_name False import email.utilsfrom frappe.core.doctype.user.user import STANDARD_USERSsystem_managers frappe.db.sql u'selectdistinctname \n DCTB DCTB concat_ws "" if first_name "" null first_name if last_name "" null last_name \n DCTB DCTB asfullnamefromtabUserp\n DCTB DCTB wheredocstatus<2andenabled 1\n DCTB DCTB andnamenotin {} \n DCTB DCTB andexists select*fromtabUserRoleur\n DCTB DCTB DCTB whereur.parent p.nameandur.role "SystemManager" \n DCTB DCTB orderbycreationdesc'.format u' '.join [u'%s'] * len STANDARD_USERS STANDARD_USERS as_dict True if only_name return [p.name for p in system_managers]else return [email.utils.formataddr p.fullname p.name for p in system_managers]
def libvlc_media_player_set_title p_mi i_title f _Cfunctions.get 'libvlc_media_player_set_title' None or _Cfunction 'libvlc_media_player_set_title' 1 1 None None MediaPlayer ctypes.c_int return f p_mi i_title
def array_to_img x dim_ordering 0 1 2 scale True from PIL import Imagex x.transpose dim_ordering if scale x + max - np.min x 0 x_max np.max x if x_max ! 0 x x / x_max x * 255if x.shape[2] 3 return Image.fromarray x.astype 'uint8' 'RGB' elif x.shape[2] 1 return Image.fromarray x[ 0].astype 'uint8' 'L' else raise Exception 'Unsupportedchannelnumber ' x.shape[2]
def get_kvm_arch flags {'kvm_amd' 'svm' 'kvm_intel' 'vmx'}vendor_name utils.get_cpu_vendor_name if not vendor_name raise error.TestError 'CPUMustbeAMD IntelorPower7' arch_type 'kvm_%s' % vendor_name cpu_flag flags.get arch_type None if cpu_flag is None and vendor_name in 'power7' return arch_typeif not utils.cpu_has_flags cpu_flag raise error.TestError '%sCPUarchitecturemusthave%sflagactiveandmustbeKVMready' % arch_type cpu_flag return arch_type
def get_family families if not isinstance families list families [families]for family in families if font_is_installed family return familyelse print 'Warning Noneofthefollowingfontsisinstalled %r' % families return QFont .family
def get_collection_links request items links []try limit int request.params.get 'limit' or 0 except ValueError limit 0if limit > 0 and limit len items last_item items[ -1 ]last_item_id last_item['id']links.append {'rel' 'next' 'href' _get_next_link request last_item_id } return links
def setup app app.add_role 'rfc' rfclink return
def token_from_http_body http_body for response_line in http_body.splitlines if response_line.startswith 'Token ' return response_line[6 ]return None
def bfs_edges G source reverse False if reverse and G.is_directed successors G.predecessorselse successors G.neighborsfor e in generic_bfs_edges G source successors yield e
def getattribute value arg if hasattr value str arg return getattr value arg elif hasattr value 'has_key' and value.has_key arg return value[arg]else return settings.TEMPLATE_STRING_IF_INVALID
def token_bytes nbytes None if nbytes is None nbytes DEFAULT_ENTROPYreturn os.urandom nbytes
def read_features_from_file filename f loadtxt filename return f[ 4] f[ 4 ]
def popall seq for i in xrange len seq seq.pop
def fancify_summary expr seen_names.clear name_dict.clear exprs pipe expr.values map Expr._traverse concat filter lambda x isinstance x Reduction set one summary **dict _name expr expr for expr in exprs two dict _name expr symbol _name expr datashape.var * expr.dshape for expr in exprs d dict expr two[_name expr ] for expr in exprs three dict name value._subs d for name value in zip expr.names expr.values return one two three
def ptp a axis None a as_tensor_variable a out max a axis - min a axis return out
def validipport port try assert 0 < int port < 65535 except AssertionError ValueError return Falsereturn True
def guess_scheme environ if environ.get 'HTTPS' in 'yes' 'on' '1' return 'https'else return 'http'
def _functionOnlyImplementer *interfaces def check obj '\nIfthedecoratedobjectisnotafunction raiseanexception.\n'if not isinstance obj FunctionType raise TypeError "Can'tuseimplementerwithclasses.Useoneoftheclass-declarationfunctionsinstead." return check
def entropy image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._entropy image selem out out mask mask shift_x shift_x shift_y shift_y out_dtype np.double
def get_preferred_input_encoding if hasattr locale u'LC_MESSAGES' return locale.getlocale locale.LC_MESSAGES [1] or locale.getdefaultlocale [1] or u'latin1' return locale.getdefaultlocale [1] or u'latin1'
def standard_deviation input labels None index None return numpy.sqrt variance input labels index
@must_be_contributor_or_public@must_have_addon 'github' 'node' def github_root_folder *args **kwargs node_settings kwargs['node_addon']auth kwargs['auth']data request.args.to_dict return github_hgrid_data node_settings auth auth **data
def marquee txt '' width 78 mark '*' if not txt return mark * width [ width]nmark width - len txt - 2 // len mark // 2 if nmark < 0 nmark 0marks mark * nmark return '%s%s%s' % marks txt marks
def _zpklp2lp z p k wo 1.0 z atleast_1d z p atleast_1d p wo float wo degree _relative_degree z p z_lp wo * z p_lp wo * p k_lp k * wo ** degree return z_lp p_lp k_lp
def kendall_tau worder normalize True worder_len len worder increasing_sequences find_increasing_sequences worder num_increasing_pairs sum choose len seq 2 for seq in increasing_sequences num_possible_pairs choose worder_len 2 tau 2 * num_increasing_pairs / num_possible_pairs - 1 if normalize return tau + 1 / 2 else return tau
def sudo_network_interacting_from_args *a **kw return retry_effect_with_timeout sudo_from_args *a **kw timeout _TIMEOUT.total_seconds
def get_package_paths package file_attr get_module_file_attribute package pkg_dir os.path.dirname file_attr pkg_base remove_suffix pkg_dir package.replace '.' os.sep return pkg_base pkg_dir
def get_placementgroup vm_ return config.get_cloud_config_value 'placementgroup' vm_ __opts__ search_global False
def mod10r number codec [0 9 4 6 8 2 7 1 3 5]report 0result ''for digit in number result + digitif digit.isdigit report codec[ int digit + report % 10 ]return result + str 10 - report % 10
def catch_request request try uh urlopen request return uh False except HTTP_ERRORS e get_exception return None e
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
@login_required@app_view@use_master@json_viewdef pay_status request addon contrib_uuid qs Contribution.objects.filter uuid contrib_uuid addon__addonpurchase__user request.user type mkt.CONTRIB_PURCHASE return {'status' 'complete' if qs.exists else 'incomplete' }
def call_unrar params custom_path None global rar_executable_cachedif rar_executable_cached is None for command in custom_path 'unrar' 'rar' osx_unrar if not command continuetry subprocess.Popen [command] stdout subprocess.PIPE rar_executable_cached commandbreakexcept OSError passif rar_executable_cached is None raise UnpackerNotInstalled 'NosuitableRARunpackerinstalled' assert type params list 'paramsmustbelist'args [rar_executable_cached] + params try gc.disable return subprocess.Popen args stdout subprocess.PIPE stderr subprocess.PIPE finally gc.enable
def test_triadic_census G nx.DiGraph G.add_edges_from ['01' '02' '03' '04' '05' '12' '16' '51' '56' '65'] expected {'030T' 2 '120C' 1 '210' 0 '120U' 0 '012' 9 '102' 3 '021U' 0 '111U' 0 '003' 8 '030C' 0 '021D' 9 '201' 0 '111D' 1 '300' 0 '120D' 0 '021C' 2}actual nx.triadic_census G assert_equal expected actual
def _fs_to_tree_path fs_path fs_encoding None if fs_encoding is None fs_encoding sys.getfilesystemencoding if not isinstance fs_path bytes fs_path_bytes fs_path.encode fs_encoding else fs_path_bytes fs_pathif os_sep_bytes ! '/' tree_path fs_path_bytes.replace os_sep_bytes '/' else tree_path fs_path_bytesreturn tree_path
def gf_to_dict f p symmetric True n result gf_degree f {} for k in range 0 n + 1 if symmetric a gf_int f[ n - k ] p else a f[ n - k ]if a result[k] areturn result
def _fast_traverse self cls result []if isinstance self cls result.append self for child in self.children result.extend child._fast_traverse cls return result
def show_version_queue a_device output_q output_dict {}creds a_device.credentialsremote_conn ConnectHandler device_type a_device.device_type ip a_device.ip_address username creds.username password creds.password port a_device.port secret '' verbose False output '#' * 80 + '\n' output + remote_conn.send_command_expect 'showversion' + '\n' output + '#' * 80 + '\n' output_dict[a_device.device_name] outputoutput_q.put output_dict
def never_cache view_func def _wrapped_view_func request *args **kwargs response view_func request *args **kwargs add_never_cache_headers response return responsereturn _wrapped_view_func
def derive_by_array expr dx from sympy.matrices import MatrixBasearray_types collections.Iterable MatrixBase NDimArray if isinstance dx array_types dx ImmutableDenseNDimArray dx for i in dx if not i._diff_wrt raise ValueError 'cannotderivebythisarray' if isinstance expr array_types expr ImmutableDenseNDimArray expr if isinstance dx array_types new_array [[y.diff x for y in expr] for x in dx]return type expr new_array dx.shape + expr.shape else return expr.diff dx elif isinstance dx array_types return ImmutableDenseNDimArray [expr.diff i for i in dx] dx.shape else return diff expr dx
def autoload Model extract_key inject_key func @functools.wraps func def wrapper *args **kwargs primary_key kwargs.get extract_key instance get_or_http_error Model primary_key kwargs[inject_key] instancereturn func *args **kwargs return wrapper
def ListHuntApprovals context None items context.SendIteratorRequest 'ListHuntApprovals' api_pb2.ApiListHuntApprovalsArgs def MapHuntApproval data return HuntApproval data data username context.username context context return utils.MapItemsIterator MapHuntApproval items
def gammamomentcond2 distfn params mom2 quantile None alpha scale paramsmom2s distfn.stats alpha 0.0 scale return np.array mom2 - mom2s
def ifacestartswith cidr net_list interfaces intfnames []pattern str cidr size len pattern for ifname ifval in six.iteritems net_list if 'inet' in ifval for inet in ifval['inet'] if inet['address'][0 size] pattern if 'label' in inet intfnames.append inet['label'] else intfnames.append ifname return intfnames
def fuzzy_equal a_str b_str threshold 0.6 return relative_distance_boolean a_str b_str threshold
def getMaximumByVector3Path path maximum Vector3 -9.876543219876543e+17 -9.876543219876543e+17 -9.876543219876543e+17 for point in path maximum.maximize point return maximum
def get_server_status server_status {}concerns Falsedisk_treshold int settings.get_value 'SERVER' 'logs_disk_usage_treshold' default '80' used_space_logs _get_logs_used_space if used_space_logs > disk_treshold concerns Trueserver_status['used_space_logs'] used_space_logsscheduler_running _process_running 'autotest-scheduler' if not scheduler_running concerns Trueserver_status['scheduler_running'] scheduler_runningwatcher_running _process_running 'autotest-scheduler-watcher' if not watcher_running concerns Trueserver_status['scheduler_watcher_running'] watcher_runningif settings.get_value 'INSTALL_SERVER' 'xmlrpc_url' default '' install_server_running get_install_server_profiles is not None if not install_server_running concerns Trueelse install_server_running Falseserver_status['install_server_running'] install_server_runningserver_status['concerns'] concernsreturn server_status
def expand_mul expr deep True return sympify expr .expand deep deep mul True power_exp False power_base False basic False multinomial False log False
def recreq table s3db.dvi_recreqtable.person_id.default s3_logged_in_person def prep r if r.interactive and not r.record table.status.readable Falsetable.status.writable Falsetable.bodies_recovered.readable Falsetable.bodies_recovered.writable Falsereturn Trues3.prep prepoutput s3_rest_controller return output
def _MakeWelcomeProperties web_xml static_files static_welcome_files []for welcome_file in web_xml.welcome_files if any f.endswith '/' + welcome_file for f in static_files static_welcome_files.append welcome_file welcome_value tuple static_welcome_files or None return {'welcome' welcome_value}
def ask_for_credentials api Mobileclient logged_in Falseattempts 0while not logged_in and attempts < 3 email input u'Email ' password getpass logged_in api.login email password Mobileclient.FROM_MAC_ADDRESS attempts + 1return api
@mark.skipif not hasattr zmq '_libzmq' reason 'bundledlibzmq' def test_has_curve assert zmq.has 'curve'
@webapp_file_view_tokendef serve request viewer key files viewer.get_files obj files.get key if not obj log.error u"Couldn'tfind%sin%s %dentries forfile%s" % key files.keys [ 10] len files.keys viewer.file.id raise http.Http404 return get_file_response request obj['full'] content_type obj['mimetype']
@login_required@post_required@json_viewdef watch request username slug collection get_collection request username slug d dict user request.user collection collection qs CollectionWatcher.objects.no_cache .using 'default' .filter **d watching not qs if qs qs.delete else CollectionWatcher.objects.create **d if request.is_ajax return {'watching' watching}else return http.HttpResponseRedirect collection.get_url_path
@require_GETdef contributors_detail request readout_slug product _get_product request return _kb_detail request readout_slug CONTRIBUTOR_READOUTS 'dashboards.contributors' _ 'KnowledgeBaseDashboard' locale settings.WIKI_DEFAULT_LANGUAGE product product
def add_func_stats target source cc nc tt ct callers source t_cc t_nc t_tt t_ct t_callers targetreturn cc + t_cc nc + t_nc tt + t_tt ct + t_ct add_callers t_callers callers
def get_utc_now iso False now datetime.utcnow .replace tzinfo iso8601.iso8601.UTC if iso return datetime_tuple_to_iso now else return now
def _ensure_running name no_start False path None _ensure_exists name path path pre state name path path if pre 'running' return start name path path elif pre 'stopped' if no_start raise CommandExecutionError "Container'{0}'isnotrunning".format name return start name path path elif pre 'frozen' if no_start raise CommandExecutionError "Container'{0}'isnotrunning".format name return unfreeze name path path
def inplace_relu_derivative Z delta delta[ Z 0 ] 0
@memoizeddef getColor value default None if isinstance value Color return valuevalue str value .strip .lower if value 'transparent' or value 'none' return defaultif value in COLOR_BY_NAME return COLOR_BY_NAME[value]if value.startswith '#' and len value 4 value '#' + value[1] + value[1] + value[2] + value[2] + value[3] + value[3] elif rgb_re.search value r g b [int x for x in rgb_re.search value .groups ]value '#%02x%02x%02x' % r g b else passreturn toColor value default
def teardown_container container_dir container_root_device None try img _DiskImage image None mount_dir container_dir img.teardown if container_root_device if 'loop' in container_root_device LOG.debug 'Releaseloopdevice%s' container_root_device utils.execute 'losetup' '--detach' container_root_device run_as_root True attempts 3 elif 'nbd' in container_root_device LOG.debug 'Releasenbddevice%s' container_root_device utils.execute 'qemu-nbd' '-d' container_root_device run_as_root True else LOG.debug 'Noreleasenecessaryforblockdevice%s' container_root_device except Exception LOG.exception _LE 'Failedtoteardowncontainerfilesystem'
def safe_scan path python myself os.path.join os.path.dirname os.path.abspath __file__ 'pybinary.py' proc TimedPopen cmd '%s%s%s' % python myself path env dict PYTHONPATH os.pathsep.join sys.path out err proc.communicate if err raise BinaryScanError err return out
def _check_meg_type meg allow_auto False if isinstance meg string_types allowed_types ['grad' 'mag' 'planar1' 'planar2']allowed_types + ['auto'] if allow_auto else [] if meg not in allowed_types raise ValueError 'megvaluemustbeoneof%sorbool not%s' % allowed_types meg
def getifaddrs libc ctypes.CDLL ctypes.util.find_library 'c' getifaddrs libc.getifaddrsgetifaddrs.restype ctypes.c_intgetifaddrs.argtpes [ctypes.POINTER ctypes.POINTER struct_ifaddrs ]freeifaddrs libc.freeifaddrsfreeifaddrs.restype Nonefreeifaddrs.argtypes [ctypes.POINTER struct_ifaddrs ]ifaptr ctypes.POINTER struct_ifaddrs result getifaddrs ctypes.pointer ifaptr if result -1 raise OSError ctypes.get_errno del resulttry ifas []while ifaptr ifac ifaptr.contentsifa {'name' ifac.ifa_name 'flags' ifac.ifa_flags}if ifac.ifa_addr ifa['family'] ifa['addr'] sockaddr_fixup ifac.ifa_addr else ifa['family'] ifa['addr'] None None if ifac.ifa_netmask _ ifa['netmask'] sockaddr_fixup ifac.ifa_netmask else ifa['network'] Noneifas.append ifa ifaptr ifac.ifa_nextreturn ifasfinally freeifaddrs ifaptr
def uninstall_flocker nodes return _run_on_all_nodes nodes task lambda node task_uninstall_flocker node.distribution
def get_exploration_by_id exploration_id strict True version None exploration_memcache_key _get_exploration_memcache_key exploration_id version version memcached_exploration memcache_services.get_multi [exploration_memcache_key] .get exploration_memcache_key if memcached_exploration is not None return memcached_explorationelse exploration_model exp_models.ExplorationModel.get exploration_id strict strict version version if exploration_model exploration get_exploration_from_model exploration_model memcache_services.set_multi {exploration_memcache_key exploration} return explorationelse return None
def write_sff_header header fh num None lines ['CommonHeader ']if num is not None header['#ofFlows'] numlines.extend [ '%s DCTB %s' % param header[param] for param in header] fh.write '\n'.join lines + '\n\n'
def versiontuple v return tuple int x for x in v.split '.'
def _setRequestFromFile if not conf.requestFile returnaddedTargetUrls set conf.requestFile safeExpandUser conf.requestFile infoMsg "parsingHTTPrequestfrom'%s'" % conf.requestFile logger.info infoMsg if not os.path.isfile conf.requestFile errMsg 'thespecifiedHTTPrequestfile'errMsg + 'doesnotexist'raise SqlmapFilePathException errMsg _feedTargetsDict conf.requestFile addedTargetUrls
def __last_error namespace args cmd SON [ 'getlasterror' 1 ] cmd.update args splitns namespace.split '.' 1 return query 0 splitns[0] + '.$cmd' 0 -1 cmd None DEFAULT_CODEC_OPTIONS
def dump_privatekey type pkey cipher None passphrase None bio _new_mem_buf if cipher is not None if passphrase is None raise TypeError 'ifavalueisgivenforcipheronemustalsobegivenforpassphrase' cipher_obj _lib.EVP_get_cipherbyname _byte_string cipher if cipher_obj _ffi.NULL raise ValueError 'Invalidciphername' else cipher_obj _ffi.NULLhelper _PassphraseHelper type passphrase if type FILETYPE_PEM result_code _lib.PEM_write_bio_PrivateKey bio pkey._pkey cipher_obj _ffi.NULL 0 helper.callback helper.callback_args helper.raise_if_problem elif type FILETYPE_ASN1 result_code _lib.i2d_PrivateKey_bio bio pkey._pkey elif type FILETYPE_TEXT rsa _ffi.gc _lib.EVP_PKEY_get1_RSA pkey._pkey _lib.RSA_free result_code _lib.RSA_print bio rsa 0 else raise ValueError 'typeargumentmustbeFILETYPE_PEM FILETYPE_ASN1 orFILETYPE_TEXT' _openssl_assert result_code ! 0 return _bio_to_string bio
def decipher_rsa i key n d keyreturn pow i d n
def test_hash_evoked ave read_evokeds fname 0 ave_2 read_evokeds fname 0 assert_equal hash ave hash ave_2 assert_true pickle.dumps ave pickle.dumps ave_2 ave_2.data[ 0 0 ] - 1assert_not_equal hash ave hash ave_2
def parse_tmp_to_final_filepath_map_file lines infiles_lists []out_filepaths []for line in lines fields line.split infiles_lists.append fields[ -1 ] out_filepaths.append fields[ -1 ] return infiles_lists out_filepaths
def delete_mount_target mounttargetid keyid None key None profile None region None **kwargs client _get_conn key key keyid keyid profile profile region region client.delete_mount_target MountTargetId mounttargetid
def _check_all_conf_groups_present config environment excludes 'global_overrides' 'cidr_networks' 'used_ips' config_groups [k for k in config.keys if k not in excludes ]env_groups environment['physical_skel'].keys retval Truefor group in config_groups if group not in env_groups msg 'Group{}wasfoundinconfigurationbutnottheenvironment.'.format group warnings.warn msg retval Falsereturn retval
def parse_addon pkg addon None return WebAppParser .parse pkg
def symlink_list saltenv 'base' backend None fileserver salt.fileserver.Fileserver __opts__ load {'saltenv' saltenv 'fsbackend' backend}return fileserver.symlink_list load load
def s3_url_represent url if not url return ''return A url _href url _target '_blank'
def texture im im im.astype np.uint8 return mh.features.haralick im .ravel
def get_calltip project source_code offset resource None maxfixes 1 ignore_unknown False remove_self False fixer fixsyntax.FixSyntax project source_code resource maxfixes pyname fixer.pyname_at offset if pyname is None return Nonepyobject pyname.get_object return PyDocExtractor .get_calltip pyobject ignore_unknown remove_self
def _merge_results x y return dict s dict x.get s {} .items + y.get s {} .items for s in set x.keys + y.keys
def set_mysql_collation_for_column apps cursor model column collation schema if not hasattr cursor.db 'mysql_version' returndb_name cursor.db.get_connection_params ['db']table_name apps.get_model model ._meta.db_tablecursor.execute "SELECTCOLLATION_NAMEFROM`information_schema`.`columns`WHERETABLE_SCHEMA '%s'ANDTABLE_NAME '%s'ANDCOLUMN_NAME '%s';" % db_name table_name column current_collation cursor.fetchone [0]if current_collation ! collation cursor.execute 'ALTERTABLE`%s`.`%s`MODIFY`%s`%sCHARACTERSETutf8COLLATE%sNOTNULL;' % db_name table_name column schema collation
def addPositivePeg derivation positives x y positivePegRadius derivation.pegRadiusArealized - derivation.halfPegClearance radiusArealized complex positivePegRadius positivePegRadius copyShallow derivation.elementNode.getCopyShallow start Vector3 x y derivation.demiheight endZ derivation.heightpeg.addPegOutput derivation.pegBevel endZ positives radiusArealized derivation.sides start derivation.topOverBottom
def element_has_text page css_selector text text_present Falsetext_list page.q css css_selector .textif len text_list > 0 and text in text_list text_present Truereturn text_present
def build_ssl_validation_error hostname port paths exc None msg ['FailedtovalidatetheSSLcertificatefor%s %s.MakesureyourmanagedsystemshaveavalidCAcertificateinstalled.']if not HAS_SSLCONTEXT msg.append 'IfthewebsiteservingtheurlusesSNIyouneedpython> 2.7.9onyourmanagedmachine' if not HAS_URLLIB3_SNI_SUPPORT msg.append 'oryoucaninstallthe`urllib3` `pyopenssl` `ndg-httpsclient` and`pyasn1`pythonmodules' msg.append 'toperformSNIverificationinpython> 2.6.' msg.append 'Youcanusevalidate_certs Falseifyoudonotneedtoconfirmtheserversidentitybutthisisunsafeandnotrecommended.Pathscheckedforthisplatform %s.' if exc msg.append 'Theexceptionmsgwas %s.' % to_native exc raise SSLValidationError ''.join msg % hostname port ' '.join paths
def check_policy_enforce logical_line filename msg 'N351 nova.policy._ENFORCER.enforce shouldnotbeused.Usetheauthorize methodinstead.'if policy_enforce_re.match logical_line yield 0 msg
def configured backend_configured cfg.CONF.coordination.url is not None mock_backend backend_configured and cfg.CONF.coordination.url.startswith 'zake' or cfg.CONF.coordination.url.startswith 'file' return backend_configured and not mock_backend
def _solve_compute_return b bcpy raise NotImplementedError
def hexWithoutQuotes l return str [hex i for i in l] .replace "'" ''
def count_lines filename non_empty False try if non_empty out subprocess.Popen ['grep' '-cve' '^\\s*$' filename] stdout subprocess.PIPE else out subprocess.Popen ['wc' '-l' filename] stdout subprocess.PIPE return int out.communicate [0].split [0] except passreturn 0
def post_container url token container headers http_conn None response_dict None service_token None if http_conn parsed conn http_connelse parsed conn http_connection url path '%s/%s' % parsed.path quote container method 'POST'headers['X-Auth-Token'] tokenif service_token headers['X-Service-Token'] service_tokenif 'content-length' not in k.lower for k in headers headers['Content-Length'] '0'conn.request method path '' headers resp conn.getresponse body resp.read http_log '%s%s' % url.replace parsed.path '' path method {'headers' headers} resp body store_response resp response_dict if resp.status < 200 or resp.status > 300 raise ClientException.from_response resp 'ContainerPOSTfailed' body
def report_error error exc_info request None extra_data None level None if HAS_ROLLBAR and hasattr settings u'ROLLBAR' rollbar.report_exc_info exc_info request extra_data extra_data level level LOGGER.error u'Handledexception%s %s' error.__class__.__name__ force_text error .encode u'utf-8' if sys.argv[1 2] [u'test'] traceback.print_exc
def decode_rfc2231 s parts s.split TICK 2 if len parts < 2 return None None s return parts
def map_project_slug view_func @wraps view_func def inner_view request project None project_slug None *args **kwargs if project is None if not project_slug project_slug request.slugtry project Project.objects.get slug project_slug except Project.DoesNotExist raise Http404 'Projectdoesnotexist.' return view_func request project project *args **kwargs return inner_view
def _has_fulfilled_prerequisites user course_id return MilestoneError if get_pre_requisite_courses_not_completed user course_id else ACCESS_GRANTED
def has_access_api f if hasattr f '_permission_name' permission_str f._permission_nameelse permission_str f.__name__def wraps self *args **kwargs permission_str PERMISSION_PREFIX + f._permission_name if self.appbuilder.sm.has_access permission_str self.__class__.__name__ return f self *args **kwargs else log.warning LOGMSG_ERR_SEC_ACCESS_DENIED.format permission_str self.__class__.__name__ response make_response jsonify {'message' str FLAMSG_ERR_SEC_ACCESS_DENIED 'severity' 'danger'} 401 response.headers['Content-Type'] 'application/json'return responsereturn redirect url_for self.appbuilder.sm.auth_view.__class__.__name__ + '.login' f._permission_name permission_strreturn functools.update_wrapper wraps f
def show_tenant status result _query action 'tenants' command 'current' return result
def _add_batch_axis var new_var new_var tensor.shape_padleft var new_var.name 'shape_padleft {} '.format var.name return new_var
def test_cnn_sample_wrong_X cnn CondensedNearestNeighbour random_state RND_SEED cnn.fit X Y assert_raises RuntimeError cnn.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def read_preprocessed_data out_fp '/tmp/' seqs dict [ a.split ' ' [0] b for a b in parse_fasta open out_fp + '/prefix_dereplicated.fasta' ] mapping read_denoiser_mapping open out_fp + '/prefix_mapping.txt' return out_fp + '/prefix_dereplicated.sff.txt' len mapping mapping seqs
def is_response_to_head response method response._methodif isinstance method int return method 3 return method.upper 'HEAD'
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def decode_entities html def decode m html m.group 0 if html[ 2] u'&#' try if html[ 3] u'&#x' return chr int html[3 -1 ] 16 else return chr int html[2 -1 ] except ValueError passelse try html chr name2codepoint[html[1 -1 ]] except KeyError passreturn htmlreturn re.sub u'&#?\\w+;' decode html.replace u'&amp;' u'&'
def _assert_reorder cov_new cov_orig order inv_order np.argsort order assert_array_equal [cov_new['names'][ii] for ii in inv_order] cov_orig['names'] assert_allclose cov_new['data'][inv_order][ inv_order] cov_orig['data'] atol 1e-20
def ResolveNamespace namespace if namespace is None namespace namespace_manager.get_namespace else namespace_manager.validate_namespace namespace datastore_errors.BadArgumentError return namespace
def extract request response None ids []cookie_name settings.OSCAR_RECENTLY_VIEWED_COOKIE_NAMEif cookie_name in request.COOKIES try ids json.loads request.COOKIES[cookie_name] except ValueError if response response.delete_cookie cookie_name else if not isinstance ids list ids []return ids
def test_multicolumn_write col1 [1 2 3]col2 [ 1.0 1.0 2.0 2.0 3.0 3.0 ]col3 [ 'a' 'a' 'a' 'b' 'b' 'b' 'c' 'c' 'c' ]table Table [col1 col2 col3] names 'C1' 'C2' 'C3' expected '<html>\n<head>\n<metacharset "utf-8"/>\n<metacontent "text/html;charset UTF-8"http-equiv "Content-type"/>\n</head>\n<body>\n<table>\n<thead>\n<tr>\n<th>C1</th>\n<thcolspan "2">C2</th>\n<thcolspan "3">C3</th>\n</tr>\n</thead>\n<tr>\n<td>1</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>b</td>\n<td>b</td>\n<td>b</td>\n</tr>\n<tr>\n<td>3</td>\n<td>3.0</td>\n<td>3.0</td>\n<td>c</td>\n<td>c</td>\n<td>c</td>\n</tr>\n</table>\n</body>\n</html>\n'out html.HTML .write table [0].strip assert out expected.strip
def test_not_equal_x_labels line Line line.add 'test1' range 100 line.truncate_label -1 line.x_labels map str range 11 q line.render_pyquery assert len q '.dots' 100 assert len q '.axis.x' 1 assert q '.axis.xtext' .map texts ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10']
def _set_result_unless_cancelled fut result if fut.cancelled returnfut.set_result result
def _explode_shorthand_ip_string ip_str if not _is_shorthand_ip ip_str return ip_strnew_ip []hextet ip_str.split ' ' if '.' in ip_str.split ' ' [ -1 ] fill_to 7else fill_to 8if len hextet > 1 sep len hextet[0].split ' ' + len hextet[1].split ' ' new_ip hextet[0].split ' ' for __ in range fill_to - sep new_ip.append '0000' new_ip + hextet[1].split ' ' else new_ip ip_str.split ' ' ret_ip []for hextet in new_ip ret_ip.append '0' * 4 - len hextet + hextet .lower return ' '.join ret_ip
def get_account_by_name account_name account Account.query.filter Account.name account_name .first manager_class account_registry.get account.account_type.name account manager_class ._load account db.session.expunge account return account
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
@_FFI.callback u'UTF8Buffer ExternContext* Value* ' def extern_val_to_str context_handle val c _FFI.from_handle context_handle return c.utf8_buf str c.from_value val
def host_format s host None name None **extra host host or gethostname hname _ domain host.partition u'.' name name or hname keys dict {u'h' host u'n' name u'd' domain u'i' _fmt_process_index u'I' _fmt_process_index_with_prefix} **extra return simple_format s keys
def test_rfc822_format stub_message_from_raw api_client mime_message full_path '/messages/{}'.format stub_message_from_raw.public_id resp api_client.get_raw full_path headers {'Accept' 'message/rfc822'} assert resp.data get_from_blockstore stub_message_from_raw.data_sha256
def default_feedback_url return 'http //groups.google.com/a/cloudera.org/group/hue-user'
def add_pseudo_pupy_module if not 'pupy' in sys.modules mod imp.new_module 'pupy' mod.__name__ 'pupy'mod.__file__ '<memimport>\\\\pupy'mod.__package__ 'pupy'sys.modules['pupy'] modmod.pseudo True
@testing.requires_testing_data@requires_nibabel def test_add_htmls_to_section report Report info_fname raw_fname subject 'sample' subjects_dir subjects_dir html '<b>MNE-PythonisAWESOME</b>' caption section 'html' 'html_section' report.add_htmls_to_section html caption section idx report._sectionlabels.index 'report_' + section html_compare report.html[idx]assert_true html in html_compare assert_true repr report
def decrypt_stream mode in_stream out_stream block_size BLOCK_SIZE padding PADDING_DEFAULT decrypter Decrypter mode padding padding _feed_stream decrypter in_stream out_stream block_size
def brain_to_mpl brain tmp_path op.abspath op.join op.curdir 'my_tmp' brain.save_imageset tmp_path views ['ven'] im imread tmp_path + '_ven.png' os.remove tmp_path + '_ven.png' return im
def get_repository_and_repository_dependencies_from_repo_info_dict app repo_info_dict repository_name list repo_info_dict.keys [0]repo_info_tuple repo_info_dict[repository_name] description repository_clone_url changeset_revision ctx_rev repository_owner repository_dependencies tool_dependencies get_repo_info_tuple_contents repo_info_tuple if hasattr app 'install_model' tool_shed get_tool_shed_from_clone_url repository_clone_url repository get_repository_for_dependency_relationship app tool_shed repository_name repository_owner changeset_revision else repository get_repository_by_name_and_owner app repository_name repository_owner return repository repository_dependencies
def sge_debug_print message logger.debug DEBUGGING_PREFIX + u'' + u' !' * 3 + u'' + message
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def local_plugins if not os.path.isfile resources.PLUGINS_DESCRIPTOR return []plugins json_manager.read_json resources.PLUGINS_DESCRIPTOR return plugins
def extend image size virt_size get_disk_size image if virt_size > size returnutils.execute 'qemu-img' 'resize' image size resize2fs image
def _nvp_dump data def escape k v return '%s %s' % k urlquote v out []for k v in sorted data.items if isinstance v list tuple out.extend [escape '%s %s ' % k x v_ for x v_ in enumerate v ] else out.append escape k v return '&'.join out
def numpy_cupy_array_equal err_msg '' verbose True name 'xp' type_check True accept_error False def check_func x y array.assert_array_equal x y err_msg verbose return _make_decorator check_func name type_check accept_error
def get_client_options session *args **kwargs client_options session get True
def messages_path module_path os.path.abspath __file__ return os.path.join os.path.dirname module_path 'messages'
def next_run return default_scheduler.next_run
def no_os_popen logical_line if 'os.popen ' in logical_line yield 0 'N348Deprecatedlibraryfunctionos.popen .Replaceitusingsubprocessmodule.'
def _safe_reshape arr new_shape if isinstance arr ABCSeries arr arr._valuesif not isinstance arr Categorical arr arr.reshape new_shape return arr
def slugify_iarc_name obj return obj.iarc_name.lower .replace '' '-'
def _simpleprint_styles _styles return u'[{}]'.format u'|'.join map u"'{}'".format sorted _styles
def retry jenkins_session url params print 'Retrying{}'.format url if params jenkins_session.post url + '/buildWithParameters' data params else jenkins_session.post url + '/build'
@with_devicedef which name which_cmd '\nIFS \nBINARY %s\nP $PATH \nforpathin"${P[@]}";doif[-e"$path/$BINARY"];thenecho"$path/$BINARY";\nbreak\nfi\ndone\n' % name which_cmd which_cmd.strip return process ['sh' '-c' which_cmd] .recvall .strip
def choice_in choices ignore_case False if ignore_case choice_set frozenset e.upper if isinstance e basestring else e for e in choices else choice_set frozenset choices def validator value if not isinstance value collections.Hashable raise ValidationError 'Mustspecifyasinglechoice;valuecannotbeacollection' if ignore_case and isinstance value basestring value value.upper if value in choice_set return Trueelse raise ValidationValueError 'Valuemustbeoneoftheseoptions {}'.format choices return validator
def getInt value return int value
def network_size value options None version None ipaddr_filter_out _filter_ipaddr value options options version version if not ipaddr_filter_out returnif not isinstance value list tuple types.GeneratorType return _network_size ipaddr_filter_out[0] return [_network_size ip_a for ip_a in ipaddr_filter_out]
def _get_format_datetime64_from_values values date_format is_dates_only _is_dates_only values if is_dates_only return date_format or '%Y-%m-%d' return date_format
def get_feedback_form_context request context {}context['subject'] request.POST['subject']context['details'] request.POST['details']context['tags'] dict [ tag request.POST[tag] for tag in ['issue_type' 'course_id'] if request.POST.get tag ] context['additional_info'] {}if request.user.is_authenticated context['realname'] request.user.profile.namecontext['email'] request.user.emailcontext['additional_info']['username'] request.user.usernameelse context['realname'] request.POST['name']context['email'] request.POST['email']for header pretty in [ 'HTTP_REFERER' 'Page' 'HTTP_USER_AGENT' 'Browser' 'REMOTE_ADDR' 'ClientIP' 'SERVER_NAME' 'Host' ] context['additional_info'][pretty] request.META.get header context['support_email'] configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL return context
def safe_truncate value length b_value encodeutils.safe_encode value [ length]decode_ok Falsewhile not decode_ok try u_value encodeutils.safe_decode b_value decode_ok Trueexcept UnicodeDecodeError b_value b_value[ -1 ]return u_value
def stats_quantile data q sx sorted data def get_quantile q1 pos len sx - 1 * q1 if abs pos - int pos - 0.5 < 0.1 return sx[int pos ] + sx[ int pos + 1 ] * 0.5 else return sx[int pos + 0.5 ]if hasattr q '__iter__' return tuple [get_quantile qi for qi in q] else return get_quantile q
def _find_identity_pool_ids name pool_id conn ids []if pool_id is None for pools in salt.utils.boto3.paged_call conn.list_identity_pools marker_flag 'NextToken' marker_arg 'NextToken' MaxResults 25 for pool in pools['IdentityPools'] if pool['IdentityPoolName'] name ids.append pool['IdentityPoolId'] else ids.append pool_id return ids
def rounded num precision 0 precision cint precision multiplier 10 ** precision num round num * multiplier if precision else num 8 floor math.floor num decimal_part num - floor if not precision and decimal_part 0.5 num floor if floor % 2 0 else floor + 1 else num round num return num / multiplier if precision else num
def jwt_response_payload_handler token user None request None return {'user' get_username user 'token' token}
def image_comparison_expect_rms im1 im2 tol expect_rms im1 os.path.join baseline_dir im1 im2_src os.path.join baseline_dir im2 im2 os.path.join result_dir im2 shutil.copyfile im2_src im2 results compare_images im1 im2 tol tol in_decorator True if expect_rms is None assert_equal None results else assert results is not None assert_almost_equal expect_rms results[u'rms'] decimal 4
def _get_flavor_image_meta key flavor image_meta flavor_key ' '.join ['hw' key] image_key '_'.join ['hw' key] flavor_policy flavor.get 'extra_specs' {} .get flavor_key image_policy image_meta.properties.get image_key return flavor_policy image_policy
def FindNextMultiLineCommentEnd lines lineix while lineix < len lines if lines[lineix].strip .endswith '*/' return lineixlineix + 1return len lines
def remove_vdir name site app '/' ret {'name' name 'changes' {} 'comment' str 'result' None}current_vdirs __salt__['win_iis.list_vdirs'] site app if name not in current_vdirs ret['comment'] 'Virtualdirectoryhasalreadybeenremoved {0}'.format name ret['result'] Trueelif __opts__['test'] ret['comment'] 'Virtualdirectorywillberemoved {0}'.format name ret['changes'] {'old' name 'new' None}else ret['comment'] 'Removedvirtualdirectory {0}'.format name ret['changes'] {'old' name 'new' None}ret['result'] __salt__['win_iis.remove_vdir'] name site app return ret
def _get_run_by_other_worker worker task_sets _get_external_workers worker .values return functools.reduce lambda a b a | b task_sets set
def make_pdf_to_png_converter tools_available []try check_output [str u'pdftocairo' u'-v'] stderr subprocess.STDOUT tools_available.append u'pdftocairo' except pass gs ver mpl.checkdep_ghostscript if gs tools_available.append u'gs' if u'pdftocairo' in tools_available def cairo_convert pdffile pngfile dpi cmd [str u'pdftocairo' u'-singlefile' u'-png' u'-r%d' % dpi pdffile os.path.splitext pngfile [0]]check_output cmd shell True stderr subprocess.STDOUT return cairo_convertelif u'gs' in tools_available def gs_convert pdffile pngfile dpi cmd [str gs u'-dQUIET' u'-dSAFER' u'-dBATCH' u'-dNOPAUSE' u'-dNOPROMPT' u'-sDEVICE png16m' u'-dUseCIEColor' u'-dTextAlphaBits 4' u'-dGraphicsAlphaBits 4' u'-dDOINTERPOLATE' u'-sOutputFile %s' % pngfile u'-r%d' % dpi pdffile]check_output cmd stderr subprocess.STDOUT return gs_convertelse raise RuntimeError u'Nosuitablepdftopngrendererfound.'
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def do_mark_safe value return Markup value
def _merge_element_contents el parent el.getparent text el.text or '' if el.tail if not len el text + el.tailelif el[ -1 ].tail el[ -1 ].tail + el.tailelse el[ -1 ].tail el.tailindex parent.index el if text if index 0 previous Noneelse previous parent[ index - 1 ]if previous is None if parent.text parent.text + textelse parent.text textelif previous.tail previous.tail + textelse previous.tail textparent[index index + 1 ] el.getchildren
def doFile filename linkrel ext url templ options {} outfileGenerator getOutputFileName doc parseFileAndReport filename clonedNode templ.cloneNode 1 munge doc clonedNode linkrel os.path.dirname filename filename ext url options outfileGenerator newFilename outfileGenerator filename ext _writeDocument newFilename clonedNode
def getCubicPoint along begin controlPoints end segmentBegin getQuadraticPoint along begin controlPoints[0] controlPoints[1] segmentEnd getQuadraticPoint along controlPoints[0] controlPoints[1] end return 1.0 - along * segmentBegin + along * segmentEnd
def makeBuilder options if options.namespaces return ExpatBuilderNS options else return ExpatBuilder options
def _unique_list seq seen set return [x for x in seq if x not in seen and not seen.add x ]
def get_size start_path total_size 0for dirpath __ filenames in os.walk start_path for f in filenames fp os.path.join dirpath f total_size + os.path.getsize fp return total_size
def cpu_seconds_to_megacycles cpu_secs return int cpu_secs * MCYCLES_PER_SECOND
def _build_cmdtuple path cmdtuples for f in os.listdir path real_f os.path.join path f if os.path.isdir real_f and not os.path.islink real_f _build_cmdtuple real_f cmdtuples else cmdtuples.append os.remove real_f cmdtuples.append os.rmdir path
def sitemonitor registry xml_parent data mon XML.SubElement xml_parent 'hudson.plugins.sitemonitor.SiteMonitorRecorder' if data.get 'sites' sites XML.SubElement mon 'mSites' for siteurl in data.get 'sites' site XML.SubElement sites 'hudson.plugins.sitemonitor.model.Site' XML.SubElement site 'mUrl' .text siteurl['url']
def release_data key state delete True if key in state['waiting_data'] assert not state['waiting_data'][key] del state['waiting_data'][key]state['released'].add key if delete del state['cache'][key]
def querydict_to_multidict query_dict wrap None wrap wrap or lambda val val return MultiDict chain.from_iterable izip repeat key wrap v for v in vals for key vals in query_dict.iterlists
def supply_item_rheader r if r.representation 'html' item r.recordif item T current.Ttabs [ T 'EditDetails' None T 'Packs' 'item_pack' T 'AlternativeItems' 'item_alt' T 'InInventories' 'inv_item' T 'Requested' 'req_item' T 'InCatalogs' 'catalog_item' ]if item.kit True tabs.append T 'KitItems' 'kit_item' rheader_tabs s3_rheader_tabs r tabs table r.tablerheader DIV TABLE TR TH '%s ' % table.name.label item.name TR TH '%s ' % table.brand_id.label table.brand_id.represent item.brand_id TR TH '%s ' % table.model.label item.model or current.messages['NONE'] rheader_tabs return rheaderreturn None
def connect_to_cloud_databases region None return _create_client ep_name 'database' region region
def login_wrapper request template_name 'registration/login.html' redirect_field_name REDIRECT_FIELD_NAME authentication_form ExtendedAuthForm current_app None extra_context None view appPool.hook_app_index 'account_login' request view filter None view if view return view[0]if extra_context is None extra_context {}extra_context.update {'sw_login_version' get_sw_login_version 'sw_name' get_sw_name } if not models.bsdUsers.has_root_password authentication_form forms.NewPasswordFormextra_context.update {'reset_password' True} response login request template_name 'registration/login.html' redirect_field_name redirect_field_name authentication_form authentication_form current_app current_app extra_context extra_context if response.status_code in 301 302 and response._headers.get 'location' '' '' [1] in reverse 'system_reboot' reverse 'system_shutdown' reverse 'account_logout' response._headers['location'] 'Location' '/' elif request.user.is_authenticated return HttpResponseRedirect '/' return response
def netParse ipstr prefixLen 0if '/' in ipstr ip pf ipstr.split '/' prefixLen int pf else ip ipstrprefixLen 24return ipParse ip prefixLen
def solo name **kwargs return _run name 'chef.solo' kwargs
def HexBin xs ys **options options _Underride options cmap matplotlib.cm.Blues pyplot.hexbin xs ys **options
def test_gmail_missing_sent constants monkeypatch folder_base [ '\\HasNoChildren' '/' u'INBOX' '\\Noselect' '\\HasChildren' '/' u'[Gmail]' '\\HasNoChildren' '\\All' '/' u'[Gmail]/AllMail' '\\HasNoChildren' '\\Drafts' '/' u'[Gmail]/Drafts' '\\HasNoChildren' '\\Important' '/' u'[Gmail]/Important' '\\HasNoChildren' '\\Junk' '/' u'[Gmail]/Spam' '\\Flagged' '\\HasNoChildren' '/' u'[Gmail]/Starred' '\\HasNoChildren' '\\Trash' '/' u'[Gmail]/Trash' '\\HasNoChildren' '/' u'reference' ]check_missing_generic 'sent' folder_base localized_folder_names['sent'] 'gmail' constants monkeypatch
def lcm2 a b return a * b // gcd a b
def get_vswitch_for_vlan_interface session vlan_interface cluster None host_mor vm_util.get_host_ref session cluster vswitches_ret session._call_method vim_util 'get_dynamic_property' host_mor 'HostSystem' 'config.network.vswitch' if not vswitches_ret returnvswitches vswitches_ret.HostVirtualSwitchfor elem in vswitches try for nic_elem in elem.pnic if str nic_elem .split '-' [ -1 ].find vlan_interface ! -1 return elem.nameexcept AttributeError pass
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
@not_implemented_for 'undirected' @not_implemented_for 'multigraph' def tournament_matrix G A nx.adjacency_matrix G return A - A.T
def download_data filename merge java_application oldrecords []oldfile Noneif merge try oldfile open filename 'rb' except IOError logging.info 'Nofiletomerge.Creatingnewfile%s' filename if oldfile logging.info 'Mergingwithexistingfile%s' filename oldrecords loader.UnpickleFromFile oldfile oldfile.close if oldrecords last_timestamp oldrecords[0].start_timestamp_milliseconds records loader.FromMemcache filter_timestamp last_timestamp java_application java_application else records loader.FromMemcache java_application java_application merged_records records + oldrecords try outfile open filename 'wb' except IOError logging.error 'Cannotopen%s' filename returnloader.PickleToFile merged_records outfile outfile.close
def censor_non_alphanum s def censor ch if ch > 'A' and ch < 'z' or ch > '0' and ch < '9' return chreturn '*'return ''.join censor ch for ch in s
def person_tag_descriptions_for_tag_text person tag_text return person.get_tag_descriptions_for_keyword tag_text
def scp_to_remote host port username password local_path remote_path limit '' log_filename None timeout 600 interface None if limit limit '-l%s' % limit if host and host.lower .startswith 'fe80' if not interface raise SCPError 'Whenusingipv6linklocaladdressmustassign' 'theinterfacetheneighbourattache' host '%s%%%s' % host interface command 'scp-v-oUserKnownHostsFile /dev/null-oPreferredAuthentications password-r%s-P%s%s%s@\\[%s\\] %s' % limit port local_path username host remote_path password_list []password_list.append password return remote_scp command password_list log_filename timeout
def _json_game_player_stats game data players OrderedDict for team in 'home' 'away' for category in nflgame.statmap.categories if category not in data[team]['stats'] continuefor pid raw in data[team]['stats'][category].iteritems stats {}for k v in raw.iteritems if k 'name' continuestats[ '%s_%s' % category k ] vif pid not in players home team 'home' if home team_name game.homeelse team_name game.awayplayers[pid] nflgame.player.GamePlayerStats pid raw['name'] home team_name players[pid]._add_stats stats return players
def pi_hex_digits n prec 14 n prec as_int n as_int prec if n < 0 raise ValueError 'ncannotbenegative' if prec 0 return ''n - 1a [4 2 1 1]j [1 4 5 6]D _dn n prec x + a[0] * _series j[0] n prec - a[1] * _series j[1] n prec - a[2] * _series j[2] n prec - a[3] * _series j[3] n prec & 16 ** D - 1 s '%0' + '%ix' % prec % x // 16 ** D - prec return s
def semiflatten multi if multi result multi.to_dict flat False for k v in result.items if len v 1 result[k] v[0]return resultelse return multi
def desargues_graph create_using None G LCF_graph 20 [5 -5 9 -9 ] 5 create_using G.name 'DesarguesGraph'return G
def libvlc_audio_output_device_list_get p_instance aout f _Cfunctions.get 'libvlc_audio_output_device_list_get' None or _Cfunction 'libvlc_audio_output_device_list_get' 1 1 None ctypes.POINTER AudioOutputDevice Instance ctypes.c_char_p return f p_instance aout
def longest_ones x return longest_contiguous_ones x
def max_abs_diff a1 a2 return np.max np.abs a1 - a2
def get_search_rank_from_exp_summary exp_summary rating_weightings {'1' -5 '2' -2 '3' 2 '4' 5 '5' 10}rank _DEFAULT_RANK + _STATUS_PUBLICIZED_BONUS if exp_summary.status rights_manager.ACTIVITY_STATUS_PUBLICIZED else 0 if exp_summary.ratings for rating_value in exp_summary.ratings rank + exp_summary.ratings[rating_value] * rating_weightings[rating_value] return max rank 0
def extract_capabilities text if not '\x00' in text return text [] text capabilities text.rstrip .split '\x00' return text capabilities.strip .split ''
def get_prior_import_or_install_required_dict app tsr_ids repo_info_dicts prior_import_or_install_required_dict {}for tsr_id in tsr_ids prior_import_or_install_required_dict[tsr_id] []for repo_info_dict in repo_info_dicts repository repository_dependencies get_repository_and_repository_dependencies_from_repo_info_dict app repo_info_dict if repository encoded_repository_id app.security.encode_id repository.id if encoded_repository_id in tsr_ids prior_import_or_install_ids get_repository_ids_requiring_prior_import_or_install app tsr_ids repository_dependencies prior_import_or_install_required_dict[encoded_repository_id] prior_import_or_install_idsreturn prior_import_or_install_required_dict
def p_start t pass
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def choose_best_location locations **kwargs locations get_ordered_locations locations **kwargs if locations return locations[0]else return None
def _add_epytext_field obj field message indent ''if obj.__doc__ obj.__doc__ obj.__doc__.rstrip + '\n\n' indents re.findall ' ?< \\n []+ ?!\\s ' obj.__doc__.expandtabs if indents indent min indents else obj.__doc__ ''obj.__doc__ + textwrap.fill '@%s %s' % field message initial_indent indent subsequent_indent indent + ''
def build_volume_from volume_from_spec if isinstance volume_from_spec.source Service containers volume_from_spec.source.containers stopped True if not containers return u'{} {}'.format volume_from_spec.source.create_container .id volume_from_spec.mode container containers[0]return u'{} {}'.format container.id volume_from_spec.mode elif isinstance volume_from_spec.source Container return u'{} {}'.format volume_from_spec.source.id volume_from_spec.mode
def GroupBy items key key_map {}try item_iter iter items except TypeError item_iter [items]for item in item_iter key_id key item key_map.setdefault key_id [] .append item return key_map
def _ensure_encodeable value try json.dumps value except ValueError TypeError return repr value return value
def complete_rmdir prefix line start end ctx if start ! 0 and line.split '' [0] 'rmdir' opts {i for i in complete_from_man '-' 'rmdir-' 6 7 ctx if i.startswith prefix } comps lp complete_dir prefix line start end ctx True return comps | opts lp return set
def _escape_argspec obj iterable for key value in iterable if hasattr value '__html__' or isinstance value basestring obj[key] escape value return obj
def _setWarningRegistryToNone modules for v in list modules.values if v is not None try v.__warningregistry__ Noneexcept pass
def get_user_count db db entry_points ENTRY_POINTS count_list []percent_list []tags entry_points.values tags.append 'osf' total db.user.find {} .count for entry_point in entry_points.keys count db.user.find {'system_tags' entry_point} .count percent round float count / float total 2 count_list.append count percent_list.append percent osf_count total - sum count_list osf_percent 1 - sum percent_list count_list.append osf_count percent_list.append osf_percent sorted_index get_sorted_index count_list count_list [count_list[i] for i in sorted_index]percent_list [percent_list[i] for i in sorted_index]tags [tags[i] for i in sorted_index]return {'tags' tags 'count' count_list 'percent' percent_list 'total' total}
@image_comparison baseline_images [u'EventCollection_plot__set_linestyle'] def test__EventCollection__set_linestyle splt coll _ generate_EventCollection_plot new_linestyle u'dashed'coll.set_linestyle new_linestyle assert_equal coll.get_linestyle [ 0 6.0 6.0 ] splt.set_title u'EventCollection set_linestyle'
def test_print_monitor_cv skip_if_no_sklearn handle filename tempfile.mkstemp trainer yaml_parse.load test_print_monitor_cv_yaml % {'filename' filename} trainer.main_loop print_monitor_cv.main filename print_monitor_cv.main filename all True os.remove filename
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def input_string_or_dict options allow_multiples True if options '<<inherit>>' options {}if options is None or options 'delete' return True {} elif isinstance options list raise CX _ 'Noideawhattodowithlist %s' % options elif isinstance options basestring new_dict {}tokens shlex.split options for t in tokens tokens2 t.split ' ' 1 if len tokens2 1 key tokens2[0]value Noneelse key tokens2[0]value tokens2[1]if key in new_dict.keys and allow_multiples if isinstance new_dict[key] list new_dict[key].append value else new_dict[key] [new_dict[key] value]else new_dict[key] valuenew_dict.pop '' None return True new_dict elif isinstance options dict options.pop '' None return True options else raise CX _ 'invalidinputtype'
def get_load jid cb_ _get_connection try jid_doc cb_.get str jid except couchbase.exceptions.NotFoundError return {}ret jid_doc.value['load']if 'minions' in jid_doc.value ret['Minions'] jid_doc.value['minions']return ret
def GetActiveEditorDocument view GetActiveView if view is None or isinstance view TreeView return None None doc view.GetDocument if hasattr doc 'MarkerAdd' return doc view return None None
def _expm_multiply_simple_core A B t mu m_star s tol None balance False if balance raise NotImplementedErrorif tol is None u_d 2 ** -53 tol u_dF Beta np.exp t * mu / float s for i in range s c1 _exact_inf_norm B for j in range m_star coeff t / float s * j + 1 B coeff * A.dot B c2 _exact_inf_norm B F F + B if c1 + c2 < tol * _exact_inf_norm F breakc1 c2F eta * F B Freturn F
def yesno value arg None if arg is None arg gettext 'yes no maybe' bits arg.split ' ' if len bits < 2 return valuetry yes no maybe bitsexcept ValueError yes no maybe bits[0] bits[1] bits[1] if value is None return maybeif value return yesreturn no
@task.task ignore_result True def store_likes user likes converter_class get_class_for 'user_conversion' logger.info 'celeryisstoring%slikes' % len likes converter_class._store_likes user likes return likes
def create_banner message if message is None versions get_versions return 'Python%s%dbits[%s]' % versions['python'] versions['bitness'] versions['system'] else return message
def cy_kim_smoother regime_transition predicted_joint_probabilities filtered_joint_probabilities k_regimes filtered_joint_probabilities.shape[0]nobs filtered_joint_probabilities.shape[ -1 ]order filtered_joint_probabilities.ndim - 2 dtype filtered_joint_probabilities.dtypesmoothed_joint_probabilities np.zeros k_regimes * order + 1 + nobs dtype dtype if regime_transition.shape[ -1 ] nobs + order regime_transition regime_transition[... order ] prefix dtype _ find_best_blas_type regime_transition predicted_joint_probabilities filtered_joint_probabilities func prefix_kim_smoother_map[prefix]func nobs k_regimes order regime_transition predicted_joint_probabilities.reshape k_regimes ** order + 1 nobs filtered_joint_probabilities.reshape k_regimes ** order + 1 nobs smoothed_joint_probabilities.reshape k_regimes ** order + 1 nobs smoothed_marginal_probabilities smoothed_joint_probabilitiesfor i in range 1 smoothed_marginal_probabilities.ndim - 1 smoothed_marginal_probabilities np.sum smoothed_marginal_probabilities axis -2 return smoothed_joint_probabilities smoothed_marginal_probabilities
def quorum_size n return n + 1 // 2
def _sysv_disable name if not _service_is_chkconfig name and not _chkconfig_add name return Falsecmd '/sbin/chkconfig{0}off'.format name return not __salt__['cmd.retcode'] cmd python_shell False
def get_bookmark user usage_key fields None bookmarks_queryset Bookmark.objectsif len set fields or [] & set OPTIONAL_FIELDS > 0 bookmarks_queryset bookmarks_queryset.select_related 'user' 'xblock_cache' else bookmarks_queryset bookmarks_queryset.select_related 'user' bookmark bookmarks_queryset.get user user usage_key usage_key return BookmarkSerializer bookmark context {'fields' fields} .data
def getFabmetheusToolsPath subName '' return getJoinedPath getFabmetheusUtilitiesPath 'fabmetheus_tools' subName
def register_exporter exporter EXPORTERS[exporter.name] exporterreturn exporter
def safe_to_snap client repository None retry_interval 120 retry_count 3 if not repository raise MissingArgument 'Novaluefor"repository"provided' for count in range 1 retry_count + 1 in_progress snapshot_in_progress client repository repository if in_progress logger.info 'Snapshotalreadyinprogress {0}'.format in_progress logger.info 'Pausing{0}secondsbeforeretrying...'.format retry_interval time.sleep retry_interval logger.info 'Retry{0}of{1}'.format count retry_count else return Truereturn False
def with_metaclass meta *bases class metaclass meta __call__ type.__call____init__ type.__init__def __new__ cls name this_bases d if this_bases is None return type.__new__ cls name d return meta name bases d return metaclass 'DummyMetaClass' None {}
@decoratordef assert_signal_called signal **expected handler Mock def on_call **kwargs return handler **kwargs signal.connect on_call try yield handler finally signal.disconnect on_call handler.assert_called_with signal signal **expected
def in_special_context node global p0 p1 p2 pats_builtif not pats_built p0 patcomp.compile_pattern p0 p1 patcomp.compile_pattern p1 p2 patcomp.compile_pattern p2 pats_built Truepatterns [p0 p1 p2]for pattern parent in zip patterns attr_chain node 'parent' results {}if pattern.match parent results and results['node'] is node return Truereturn False
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def make_colorscale colors scale None colorscale []if len colors < 2 raise exceptions.PlotlyError 'Youmustinputalistofcolorsthathasatleasttwocolors.' if scale is None scale_incr 1.0 / len colors - 1 return [[ i * scale_incr color] for i color in enumerate colors ]else if len colors ! len scale raise exceptions.PlotlyError 'Thelengthofcolorsandscalemustbethesame.' validate_scale_values scale colorscale [list tup for tup in zip scale colors ]return colorscale
def getRadiusArealizedMultiplier sides return math.sqrt globalTau / sides / math.sin globalTau / sides
def _should_update_date verified_mode return not verified_mode is None or verified_mode.expiration_datetime_is_explicit
def nickname_commands *command_list def add_attribute function if not hasattr function u'rule' function.rule []rule u'\n^\n$nickname[ ]?#Nickname.\n\\s+ {command} #Commandasgroup1.\n ? \\s+#Whitespacetoendcommand.\n #Restofthelineasgroup2.\n ? \\S+ ?#Parameters1-4asgroups3-6.\n ? \\s+ \\S+ ?\n ? \\s+ \\S+ ?\n ? \\s+ \\S+ ?\n.*#Acceptanythingaftertheparameters.Leaveitupto\n#themoduletoparsetheline.\n ?#Group1mustbeNone iftherearenoparameters.\n$#EoL sotherearenopartialmatches.\n'.format command u'|'.join command_list function.rule.append rule return functionreturn add_attribute
def _to_ansi obj if hasattr obj '__iter__' return [_to_ansi o for o in obj]else return ANSIString to_unicode obj
def json_response body None errors None redirect_to None exception None content_type None status None if content_type is None content_type 'application/json'if errors if isinstance errors basestring errors [errors]body {'success' False 'errors' errors}elif redirect_to body {'success' True 'redirect_to' redirect_to}elif exception if body is None body 'Unexpectedexception%s' % exception else body body % exception body {'success' False 'errors' [body]}elif body passelse raise Exception 'mustcallwithbody errorsorredirect_to' if status is None status 200if not isinstance body basestring body json.dumps body return HttpResponse body content_type content_type status status
@pytest.mark.parametrize 'key modifiers text filtered' [ Qt.Key_A Qt.NoModifier 'a' True Qt.Key_Up Qt.NoModifier '' False Qt.Key_A Qt.ShiftModifier 'A' True Qt.Key_A Qt.ShiftModifier | Qt.ControlModifier 'x' False ] def test_non_alphanumeric key modifiers text filtered fake_keyevent_factory modeman evt fake_keyevent_factory key key modifiers modifiers text text assert modeman.eventFilter evt filtered
def get_region_code request if 'X-AppEngine-City' in request.headers return request.headers['X-AppEngine-Region']return None
def vocabulary_delete context data_dict model context['model']vocab_id data_dict.get 'id' if not vocab_id raise ValidationError {'id' _ 'idnotindata' } vocab_obj model.vocabulary.Vocabulary.get vocab_id if vocab_obj is None raise NotFound _ 'Couldnotfindvocabulary"%s"' % vocab_id _check_access 'vocabulary_delete' context data_dict vocab_obj.delete model.repo.commit
def get_active_conferences user conferences get_memcached get_key 'conferences' list_conferences []for key in conferences.keys if user in conferences[key]['users'].keys list_conferences.append dict id key title conferences[key]['info']['title'] creator conferences[key]['info']['creator'] creation_date str conferences[key]['info']['creation_date'] users [dict username username profile get_user_profile username for username in conferences[key]['users'].keys if not username user ] return list_conferences
def get_manager_class_from_engine django_engine rdbms_type engine_to_rdbms_type django_engine return get_manager_class rdbms_type
def parse_firewall rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--enable' '--enabled' dest 'enable' action 'store_true' parser.add_argument '--disable' '--disabled' dest 'disable' action 'store_true' parser.add_argument '--port' dest 'port' action 'store' parser.add_argument '--service' dest 'service' action 'store' parser.add_argument '--ssh' dest 'ssh' action 'store_true' parser.add_argument '--smtp' dest 'smtp' action 'store_true' parser.add_argument '--http' dest 'http' action 'store_true' parser.add_argument '--ftp' dest 'ftp' action 'store_true' args clean_args vars parser.parse_args rules parser Nonereturn args
def toGraphicsObjectIfPossible item if item is None return Noneobj item.toGraphicsObject return item if obj is None else obj
def offset_line y yerr if cbook.is_numlike yerr or cbook.iterable yerr and len yerr len y ymin y - yerr ymax y + yerr elif len yerr 2 ymin ymax y - yerr[0] y + yerr[1] else raise ValueError u'yerrmustbescalar 1xNor2xN' return ymin ymax
def rename_register llvmir def repl mat return '%_dot_.{0}'.format mat.group 1 return re_regname.sub repl llvmir
def modpythonHandler request from mod_python import apacheconfig_path request.get_options .get 'config' 'tilestache.cfg' config_path realpath pathjoin dirname request.filename config_path path_info request.path_infoquery_string request.args mimetype content requestHandler config_path path_info query_string request.status apache.HTTP_OKrequest.content_type mimetyperequest.set_content_length len content request.send_http_header request.write content return apache.OK
def fetch_gravatar email gravatar_url get_gravatar_url email try result urlfetch.fetch gravatar_url headers {'Content-Type' 'image/png'} follow_redirects False except urlfetch.InvalidURLError urlfetch.DownloadError logging.error 'FailedtofetchGravatarfrom%s' % gravatar_url else if result.status_code 200 if imghdr.what None result.content 'png' return utils.convert_png_binary_to_data_url result.content else logging.error '[Status%s]FailedtofetchGravatarfrom%s' % result.status_code gravatar_url return DEFAULT_IDENTICON_DATA_URL
def _revoke_challenge global challengechallenge None
def get_net_size mask binary_str ''for octet in mask.split '.' binary_str + bin int octet [2 ].zfill 8 return len binary_str.rstrip '0'
def videos_index_html course return render_to_response 'videos_index.html' {'context_course' course 'video_handler_url' reverse_course_url 'videos_handler' unicode course.id 'encodings_download_url' reverse_course_url 'video_encodings_download' unicode course.id 'previous_uploads' _get_index_videos course 'concurrent_upload_limit' settings.VIDEO_UPLOAD_PIPELINE.get 'CONCURRENT_UPLOAD_LIMIT' 0 'video_supported_file_formats' VIDEO_SUPPORTED_FILE_FORMATS.keys 'video_upload_max_file_size' VIDEO_UPLOAD_MAX_FILE_SIZE_GB}
@np.deprecate new_name 'expm' def expm2 A A _asarray_square A t A.dtype.charif t not in ['f' 'F' 'd' 'D'] A A.astype 'd' t 'd' s vr eig A vri inv vr r dot dot vr diag exp s vri if t in ['f' 'd'] return r.real.astype t else return r.astype t
def fake_team db teamowner teamname None isapproved [True False]productorservice ['Product' 'Service']if teamname is None teamname faker.first_name + fake_text_id 3 ctime teamowner.ctime + datetime.timedelta days 7 try teamslug slugize teamname homepage 'http //www.example.org/' + fake_text_id 3 insert_fake_data db 'teams' slug teamslug slug_lower teamslug.lower name teamname homepage homepage ctime ctime product_or_service random.sample productorservice 1 [0] onboarding_url homepage + '/contributing' owner teamowner.username is_approved random.sample isapproved 1 [0] receiving 0.1 nreceiving_from 3 except IntegrityError InvalidTeamName return fake_team db teamowner return Team.from_slug teamslug
def class_is_abstract node for method in node.methods if method.parent.frame is node if method.is_abstract pass_is_abstract False return Truereturn False
def normalize_and_reduce_paths paths reduced_paths []for p in paths np os.path.normpath p if np not in reduced_paths reduced_paths.append np return reduced_paths
def auth_sub_string_from_url url scopes_param_prefix 'auth_sub_scopes' if isinstance url str unicode url atom.http_core.Uri.parse_uri url if 'token' not in url.query return None None token url.query['token']scopes Noneif scopes_param_prefix in url.query scopes tuple url.query[scopes_param_prefix].split '' return token scopes
@jit nopython True cache True def lex_min_ratio_test tableau pivot slack_start argmins nrows tableau.shape[0]num_candidates nrowsfor i in range nrows argmins[i] inum_argmins min_ratio_test_no_tie_breaking tableau pivot -1 argmins num_candidates if num_argmins 1 return argmins[0]for j in range slack_start slack_start + nrows if j pivot continuenum_argmins min_ratio_test_no_tie_breaking tableau pivot j argmins num_argmins if num_argmins 1 breakreturn argmins[0]
def initExperimentPrng seed 42random.seed seed numpy.random.seed seed
def transformation_to_normal eq var coeff diop_type classify_diop eq _dict False if diop_type in 'homogeneous_ternary_quadratic' 'homogeneous_ternary_quadratic_normal' return _transformation_to_normal var coeff
def SplitByKind freqdict kinds {}for kind_fullname freq in freqdict.items kind fullname kind_fullname.split ' ' if not kind in kinds kinds[kind] []kinds[kind].append fullname freq['read'] freq['write'] freq['miss'] for kind in kinds kinds[kind].sort key lambda ent ent[1] + ent[2] reverse True kinds_bycount sorted kinds.iteritems key lambda pair len pair[1] reverse True maxcount 0for kind in kinds maxcount max maxcount kinds[kind][0][1] + kinds[kind][0][2] return kinds_bycount maxcount
def best_match supported header parsed_header [parse_media_range r for r in header.split ' ' ]weighted_matches [ quality_parsed mime_type parsed_header mime_type for mime_type in supported]weighted_matches.sort return weighted_matches[ -1 ][0] and weighted_matches[ -1 ][1] or ''
def get_connection_ip_list as_wmi_format False server _DEFAULT_SERVER ret dict setting 'IPGrant'reg_separator ' \\s*'if as_wmi_format ret list addresses _get_wmi_setting 'IIsIPSecuritySetting' setting server for unnormalized_address in addresses ip_address subnet re.split reg_separator unnormalized_address if as_wmi_format ret.append '{0} {1}'.format ip_address subnet else ret[ip_address] subnetif not ret _LOG.debug '%sisempty.' setting return ret
def get_random_text_and_whitespace length 10 return ''.join random.sample BLOG_CHARACTERS length .strip
def arrangeByType service_list preferred_types def enumerate elts 'Returnaniterablethatpairstheindexofanelementwith\nthatelement.\n\nForPython2.2compatibility'return zip range len elts elts def bestMatchingService service 'Returntheindexofthefirstmatchingtype orsomething\nhigherifnotypematches.\n\nThisprovidesanorderinginwhichserviceelementsthat\ncontainatypethatcomesearlierinthepreferredtypeslist\ncomebeforeserviceelementsthatcomelater.Ifaservice\nelementhasmorethanonetype themostpreferredonewins.\n'for i t in enumerate preferred_types if preferred_types[i] in service.type_uris return ireturn len preferred_types prio_services [ bestMatchingService s orig_index s for orig_index s in enumerate service_list ]prio_services.sort for i in range len prio_services prio_services[i] prio_services[i][2]return prio_services
def getCircleNodesFromPoints points radius circleNodes []oneOverRadius 1.0 / radius points euclidean.getAwayPoints points 0.001 * radius for point in points circleNodes.append CircleNode point * oneOverRadius len circleNodes return circleNodes
def _quoteAndEscape string assert type string in types.StringTypes return pprint.pformat string
def assert_request_user_has_rule_trigger_and_action_permission request rule_api if not cfg.CONF.rbac.enable return Truetrigger rule_api.triggeraction rule_api.actiontrigger_type trigger['type']action_ref action['ref']user_db get_user_db_from_request request request has_trigger_permission request_user_has_rule_trigger_permission request request trigger trigger if not has_trigger_permission msg 'User"%s"doesn\'thaverequiredpermission %s tousetrigger%s' % user_db.name PermissionType.WEBHOOK_CREATE trigger_type raise AccessDeniedError message msg user_db user_db has_action_permission request_user_has_rule_action_permission request request action_ref action_ref if not has_action_permission msg 'User"%s"doesn\'thaverequired %s permissiontouseaction%s' % user_db.name PermissionType.ACTION_EXECUTE action_ref raise AccessDeniedError message msg user_db user_db return True
def fallocate fd size global _sys_fallocateif _sys_fallocate is None _sys_fallocate FallocateWrapper if size < 0 size 0ret _sys_fallocate fd 1 0 ctypes.c_uint64 size err ctypes.get_errno if ret and err not in 0 errno.ENOSYS errno.EOPNOTSUPP errno.EINVAL raise OSError err 'Unabletofallocate %s ' % size
def properties_to_params props candidates filter lambda x 'parameterDefinitions' in x props if candidates def transform x return {x['name'] x['defaultParameterValue']['value']}return {k v for d in map transform candidates[0]['parameterDefinitions'] for k v in d.items }return None
@handle_response_format@treeio_login_required@module_admin_required def index_pages request response_format 'html' pages Page.objects.all .order_by 'name' folders PageFolder.objects.all .order_by 'name' return render_to_response 'core/administration/index_pages' {'pages' pages 'folders' folders} context_instance RequestContext request response_format response_format
def write_external_book_rel book root Element 'Relationships' xmlns PKG_REL_NS rel Relationship '' target book.Target targetMode book.TargetMode id 'rId1' rel.type book.Typeroot.append rel.to_tree return root
@_docstring 'label' def get_label_by_id id includes [] release_status [] release_type [] params _check_filter_and_make_params 'label' includes release_status release_type return _do_mb_query 'label' id includes params
@register.filter name 'role_contain_which_sudos' def role_contain_which_sudos role sudo_names [sudo.name for sudo in role.sudo.all ]return ' '.join sudo_names
@disable_for_loaddatadef ping_directories_handler sender **kwargs entry kwargs['instance']if entry.is_visible and settings.SAVE_PING_DIRECTORIES for directory in settings.PING_DIRECTORIES DirectoryPinger directory [entry]
def get_sharejs_uuid node wname wiki_key to_mongo_key wname private_uuid node.wiki_private_uuids.get wiki_key return str uuid.uuid5 uuid.UUID private_uuid str node._id if private_uuid else None
def _create_post_request rf directory user url '/' data None if data is None data {}request rf.post url data data request.user userrequest.permissions get_matching_permissions request.user directory return request
def target_outdated target deps try target_time os.path.getmtime target except os.error return 1for dep in deps dep_time os.path.getmtime dep if dep_time > target_time return 1return 0
def tidy_stacktrace stack trace []for frame path line_no func_name text in f[ 5] for f in stack if omit_path os.path.realpath path continuetext u''.join force_text t for t in text .strip if text else u'' trace.append path line_no func_name text return trace
def hosts hostnames zone 'net' addresses [gethostbyname name for name in hostnames]return '%s %s' % zone ' '.join addresses
def virtual_interface_get_by_instance_and_network context instance_id network_id return IMPL.virtual_interface_get_by_instance_and_network context instance_id network_id
def get_page_class page_id warn u'get_page_classisdeprecatedinReviewBoard3.0andwillberemoved;useAccountPage.registry.getinstead.' DeprecationWarning return AccountPage.registry.get u'page_id' page_id
def can_resize_image image size LOG.debug 'Checkingifwecanresizeimage% image s.size % size s' {'image' image 'size' size} virt_size get_disk_size image if virt_size > size LOG.debug 'Cannotresizeimage%stoasmallersize.' image return Falsereturn True
def UpdateManifestResourcesFromXML dstpath xmlstr names None languages None logger.info 'Updatingmanifestin%s' dstpath if dstpath.lower .endswith '.exe' name 1else name 2winresource.UpdateResources dstpath xmlstr RT_MANIFEST names or [name] languages or [0 '*']
def new_figure_manager num *args **kwargs FigureClass kwargs.pop 'FigureClass' Figure thisFig FigureClass *args **kwargs canvas FigureCanvasTemplate thisFig manager FigureManagerTemplate canvas num return manager
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def check_config changed Falsedata get_all_config for key in c if key in data if data[key] ! c[key] changed Trueif changed reload_config
def configure_proxy proxyname start True changes_new []changes_old []status_file Truetest __opts__['test']proxyfile '/etc/salt/proxy' status_file msg_new msg_old _proxy_conf_file proxyfile test changes_new.extend msg_new changes_old.extend msg_old status_proc Falseif start status_proc msg_new msg_old _proxy_process proxyname test changes_old.extend msg_old changes_new.extend msg_new else changes_old.append 'StartisFalse notstartingsalt-proxyprocess' log.debug 'Processnotstarted' return {'result' status_file and status_proc 'changes' {'old' '\n'.join changes_old 'new' '\n'.join changes_new }}
def euler n if not isscalar n or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' n int n if n < 2 n1 2else n1 nreturn specfun.eulerb n1 [ n + 1 ]
def to_unit value unit return value / 1024 ** BYTE_SIZES.index unit
def _unpack_matrix fid rows cols dtype out_dtype dtype np.dtype dtype string fid.read int dtype.itemsize * rows * cols out np.fromstring string dtype dtype .reshape rows cols .astype out_dtype return out
def pixmap_to_data pixmap format 'JPEG' quality 90 ba QByteArray buf QBuffer ba buf.open QBuffer.WriteOnly pixmap.save buf format quality quality return bytes ba.data
def bzr_wc_sudo_user test 'bzr_wc_sudo_user'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric.api import cd sudofrom fabtools.files import group is_dir ownerfrom fabtools import requirerequire.user 'bzruser' group 'bzrgroup' assert not is_dir wt require.bazaar.working_copy REMOTE_URL wt use_sudo True user 'bzruser' assert_wc_exists wt assert owner wt 'bzruser' assert group wt 'bzrgroup'
def append_token url token if token url + '?' + urlencode {'X-Plex-Token' token} return url
@require_POST@login_requireddef watch_locale request product None kwargs {'locale' request.LANGUAGE_CODE}if product is not None kwargs['product'] productReviewableRevisionInLocaleEvent.notify request.user **kwargs statsd.incr 'wiki.watches.locale' return HttpResponse
def dict_to_string _dict buffer ''if not isinstance _dict dict return _dictfor key in _dict value _dict[key]if not value buffer + str key + '' elif isinstance value list for item in value buffer + str key + ' ' + str item + '' else buffer + str key + ' ' + str value + '' return buffer
def get_column_name column try inspected_column inspect column except NoInspectionAvailable return columnelse return inspected_column.key
def to_bytes text default 0 mult_key_org text.lstrip '-1234567890' mult_key mult_key_org.lower mult_key_len len mult_key if mult_key.endswith 'b' mult_key mult_key[0 -1 ]try multiplier BYTE_MULTIPLIERS[mult_key]if mult_key_len text text[0 - mult_key_len ]return int text * multiplier except KeyError msg _ 'Unknownbytemultiplier %s' % mult_key_org raise TypeError msg except ValueError return default
@register.simple_tag takes_context True def translate_url context language try request context[u'request']except KeyError return u''view resolve request.path current_language translation.get_language translation.activate language try url reverse view.func args view.args kwargs view.kwargs except NoReverseMatch try url_name view.url_name if not view.namespace else u'%s %s' % view.namespace view.url_name url reverse url_name args view.args kwargs view.kwargs except NoReverseMatch url_name u'admin ' + view.url_name url reverse url_name args view.args kwargs view.kwargs translation.activate current_language if context[u'request'].META[u'QUERY_STRING'] url + u'?' + context[u'request'].META[u'QUERY_STRING'] return url
def delete_blob call None kwargs None global storconnif not storconn storconn get_conn StorageManagementClient if kwargs is None kwargs {}if 'container' not in kwargs raise SaltCloudSystemExit 'Acontainermustbespecified' if 'blob' not in kwargs raise SaltCloudSystemExit 'Ablobmustbespecified' storageaccount azure.storage.CloudStorageAccount config.get_cloud_config_value 'storage_account' get_configured_provider __opts__ search_global False config.get_cloud_config_value 'storage_key' get_configured_provider __opts__ search_global False storageservice storageaccount.create_block_blob_service storageservice.delete_blob kwargs['container'] kwargs['blob'] return True
def create_configuration username password management_url san_iscsi_ip poolname thin_provision True configuration mock.Mock configuration.san_login usernameconfiguration.san_password passwordconfiguration.qnap_management_url management_urlconfiguration.san_thin_provision thin_provisionconfiguration.san_iscsi_ip san_iscsi_ipconfiguration.qnap_poolname poolnameconfiguration.safe_get.return_value 'QNAP'configuration.iscsi_ip_address '1.2.3.4'configuration.qnap_storage_protocol 'iscsi'configuration.reserved_percentage 0return configuration
def show_instance name call None if call ! 'action' raise SaltCloudException 'Theshow_instanceactionmustbecalledwith-aor--action.' node_id get_linode_id_from_name name node_data get_linode kwargs {'linode_id' node_id} ips get_ips node_id state int node_data['STATUS'] ret {'id' node_data['LINODEID'] 'image' node_data['DISTRIBUTIONVENDOR'] 'name' node_data['LABEL'] 'size' node_data['TOTALRAM'] 'state' _get_status_descr_by_id state 'private_ips' ips['private_ips'] 'public_ips' ips['public_ips']}return ret
def dist_matrix_clustering matrix linkage AVERAGE Z dist_matrix_linkage matrix linkage linkage return tree_from_linkage Z
def _my_trans data data_t fft data data_t np.concatenate [data_t[ None] data_t[ None]] axis 2 return data_t None
def class_from_name module_name class_name m importlib.import_module module_name c getattr m class_name return c
def solution return s3_rest_controller
def login_user user remember False force False fresh True if not force and not user.is_active return Falseuser_id getattr user current_app.login_manager.id_attribute session['user_id'] user_idsession['_fresh'] freshsession['_id'] _create_identifier if remember session['remember'] 'set'_request_ctx_stack.top.user useruser_logged_in.send current_app._get_current_object user _get_user return True
def get_rate name [curr_metrics last_metrics] get_metrics name name[len NAME_PREFIX ]try rate float curr_metrics['data'][name] - last_metrics['data'][name] / float curr_metrics['time'] - last_metrics['time'] if rate < 0 rate float 0 except StandardError rate float 0 return rate
def broadcast_change _ res SendMessageTimeout HWND_BROADCAST WM_SETTINGCHANGE 0 0 SMTO_ABORTIFHUNG 5000 return not bool res
def latex expr **settings return LatexPrinter settings .doprint expr
def edge_boundary G nbunch1 nbunch2 None data False keys False default None nset1 {v for v in G if v in nbunch1 }if G.is_multigraph edges G.edges nset1 data data keys keys default default else edges G.edges nset1 data data default default if nbunch2 is None return e for e in edges if e[1] not in nset1 nset2 set nbunch2 return e for e in edges if e[1] in nset2
def is_sabnzbd_running url try url '%s&mode version' % url prev sabnzbd.set_https_verification False ver sabnzbd.newsunpack.get_from_url url sabnzbd.set_https_verification prev return ver and re.search '\\d+\\.\\d+\\.' ver or ver.strip sabnzbd.__version__ except return False
def fixed_ip_get_by_address context address columns_to_join None return IMPL.fixed_ip_get_by_address context address columns_to_join columns_to_join
def test_qiime_config_variable variable qiime_config test access_var R_OK fail_on_missing False fp qiime_config[variable]if not fp if fail_on_missing test.fail '%snotset.' % variable else returntest.assertTrue exists fp '%ssettoaninvalidfilepath %s' % variable fp modes {R_OK 'readable' W_OK 'writable' X_OK 'executable'}test.assertTrue access fp access_var '%sisnot%s %s' % variable modes[access_var] fp
@pytest.mark.parametrize 'encoding' [None 'UTF-8' 'unicode_escape'] def test_issue encoding context Nonetext2 ''expected_text u'\u043f\u043e\u0440\u0443\u0441\u0441\u043a\u0438'try problematic_step_impl context except Exception text2 traceback.format_exc text3 text text2 encoding print u'EXCEPTION-TEXT %s' % text3 assert_that text3 contains_string u'raiseException u"\u043f\u043e\u0440\u0443\u0441\u0441\u043a\u0438"' assert_that text3 contains_string u'Exception \u043f\u043e\u0440\u0443\u0441\u0441\u043a\u0438'
def _check_worktree_support failhard True git_version version versioninfo False if _LooseVersion git_version < _LooseVersion '2.5.0' if failhard raise CommandExecutionError 'Worktreesareonlysupportedingit2.5.0andnewer detectedgitversion ' + git_version + ' ' return Falsereturn True
def fetch_public_key repo keyurl 'https //api.travis-ci.org/repos/{0}/key'.format repo data json.loads urlopen keyurl .read .decode if 'key' not in data errmsg 'Couldnotfindpublickeyforrepo {}.\n'.format repo errmsg + 'HaveyoualreadyaddedyourGitHubrepotoTravis?'raise ValueError errmsg return data['key']
def getInsidesAddToOutsides loops outsides insides []for loopIndex in xrange len loops loop loops[loopIndex]if isInsideOtherLoops loopIndex loops insides.append loop else outsides.append loop return insides
@collect_authdef auth_login auth campaign request.args.get 'campaign' next_url request.args.get 'next' data login_and_register_handler auth login True campaign campaign next_url next_url if data['status_code'] http.FOUND return redirect data['next_url']
def _is_metaclass klass seen None if klass.name 'type' return Trueif seen is None seen set for base in klass.bases try for baseobj in base.infer if baseobj in seen continueelse seen.add baseobj if isinstance baseobj Instance return Falseif baseobj is YES continueif baseobj is klass continueif not isinstance baseobj Class continueif baseobj._type 'metaclass' return Trueif _is_metaclass baseobj seen return Trueexcept InferenceError continuereturn False
def l2_norm tensors squared False summed [tensor.sqr tensor.as_tensor_variable t .sum for t in tensors]joined tensor.stack summed axis 0 return joined.sum if squared else tensor.sqrt joined.sum
def i1 x return tt.switch tt.lt x 5 x / 2 + x ** 3 / 16 + x ** 5 / 384 + x ** 7 / 18432 + x ** 9 / 1474560 + x ** 11 / 176947200 + x ** 13 / 29727129600 np.e ** x / 2 * np.pi * x ** 0.5 * 1 - 3 / 8 * x + 15 / 128 * x ** 2 + 315 / 3072 * x ** 3 + 14175 / 98304 * x ** 4
def _escape_backslashes data jinja_env if '\\' in data and '{{' in data new_data []d2 jinja_env.preprocess data in_var Falsefor token in jinja_env.lex d2 if token[1] 'variable_begin' in_var Truenew_data.append token[2] elif token[1] 'variable_end' in_var Falsenew_data.append token[2] elif in_var and token[1] 'string' new_data.append token[2].replace '\\' '\\\\' else new_data.append token[2] data ''.join new_data return data
def dijkstra_shortest_paths graph id heuristic None directed False W adjacency graph directed directed heuristic heuristic Q []D {}P {}P[id] [id]seen {id 0}heappush Q 0 id while Q dist v heappop Q if v in D continueD[v] distfor w in W[v].keys vw_dist D[v] + W[v][w] if w not in D and w not in seen or vw_dist < seen[w] seen[w] vw_distheappush Q vw_dist w P[w] P[v] + [w] for n in graph if n not in P P[n] Nonereturn P
def edges G nbunch None return G.edges nbunch
def create_tarball fileobj path callback None tar_cmd 'tar-zc--directory % path s.' % locals tar_proc make_subprocess tar_cmd stdout True stderr True while True chunk tar_proc.stdout.read CHUNK_SIZE if chunk '' breakif callback callback chunk if fileobj fileobj.write chunk finish_subprocess tar_proc tar_cmd
def state_schema module '' specs state_argspec module schemas []for state_mod state_spec in specs.items schemas.append _argspec_to_schema state_mod state_spec return schemas
def devices out __salt__['cmd.run_all'] 'blkid-oexport' salt.utils.fsutils._verify_run out return salt.utils.fsutils._blkid_output out['stdout'] fs_type 'btrfs'
def ADX barDs count timeperiod - 2 ** 31 return call_talib_with_hlc barDs count talib.ADX timeperiod
def _FindNodeWithStandaloneLineParent node if pytree_utils.NodeName node.parent in _STANDALONE_LINE_NODES return nodeelse return _FindNodeWithStandaloneLineParent node.parent
def GetImageNames test_name _SUMMARY[test_name]['images'] []current_path os.path.join _RESULTS_PATH 'current' test_path os.path.join current_path options.conf if test_name files os.listdir '%s/%s/%s' % test_path test_name 'Run1/' files.sortfor tmpfile in files if tmpfile.endswith 'png' _SUMMARY[test_name]['images'].append tmpfile return _SUMMARY[test_name]['images']
def get_metadata_from_object instance metadata {'display_name' instance.name 'name' getattr instance 'OS-EXT-SRV-ATTR instance_name' u'' 'instance_type' instance.flavor['id'] if instance.flavor else None 'host' instance.hostId 'image_ref' instance.image['id'] if instance.image else None }if instance.image and instance.image.get 'links' metadata['image_ref_url'] instance.image['links'][0]['href']else metadata['image_ref_url'] Nonefor name in INSTANCE_PROPERTIES metadata[name] getattr instance name u'' return metadata
def regions language x a language.lower [] for tag language region iso639 iso3166 in LANGUAGE_REGION.items if iso639 x a.append iso3166 return sorted a key lambda tag tag.lower ! x and tag or ''
def update_email_preferences user_id can_receive_email_updates can_receive_editor_role_email can_receive_feedback_email can_receive_subscription_email email_preferences_model user_models.UserEmailPreferencesModel.get user_id strict False if email_preferences_model is None email_preferences_model user_models.UserEmailPreferencesModel id user_id email_preferences_model.site_updates can_receive_email_updatesemail_preferences_model.editor_role_notifications can_receive_editor_role_emailemail_preferences_model.feedback_message_notifications can_receive_feedback_emailemail_preferences_model.subscription_notifications can_receive_subscription_emailemail_preferences_model.put
def _split_input_list str_list new_list re.split '[\\n\\r\\s ]' str_list new_list [s.strip for s in new_list]new_list [s for s in new_list if s ! '' ]return new_list
def get_runner_constructor suite_tag module_name 'api_tests.' + suite_tag.lower module importlib.import_module module_name suite_runner_function getattr module 'Test' + suite_tag return suite_runner_function
def shape x return tf.shape x
def identical_signature_wrapper original_function wrapped_function context {'__wrapped__' wrapped_function}function_def compile 'def{0} {1} \nreturn__wrapped__ {2} '.format original_function.__name__ inspect.formatargspec *salt.utils.args.get_function_argspec original_function [1 -1 ] inspect.formatargspec formatvalue lambda val '' *salt.utils.args.get_function_argspec original_function [1 -1 ] '<string>' 'exec' six.exec_ function_def context return wraps original_function context[original_function.__name__]
def walktree classes children parent results []classes.sort key attrgetter '__module__' '__name__' for c in classes results.append c c.__bases__ if c in children results.append walktree children[c] children c return results
def del_lease mac ip_address api network_rpcapi.NetworkAPI api.release_fixed_ip context.get_admin_context ip_address CONF.host mac
def getFileTextGivenDirectoryFileName directory fileName absoluteFilePath os.path.join directory fileName return archive.getFileText absoluteFilePath
def where_art_thy_filehandles os.system 'ls-l/proc/%d/fd>>/dev/tty' % os.getpid
def user_delete user_id None name None profile None **connection_args kstone auth profile **connection_args if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}kstone.users.delete user_id ret 'UserID{0}deleted'.format user_id if name ret + ' {0} '.format name return ret
def ip_to_uuid ip return UUID bytes md5 ip.encode 'utf-8' .digest
def get_authorities return dict DIRECTORY_AUTHORITIES
def hard_linking_possible scratch_directory FilePath tempfile.mkdtemp test_file scratch_directory.child 'src' test_file.touch try os.link test_file.path scratch_directory.child 'dst' .path return Trueexcept return Falsefinally scratch_directory.remove
@csrf_protectdef render_flatpage request f if f.registration_required and not request.user.is_authenticated from django.contrib.auth.views import redirect_to_loginreturn redirect_to_login request.path if f.template_name t loader.select_template f.template_name DEFAULT_TEMPLATE else t loader.get_template DEFAULT_TEMPLATE f.title mark_safe f.title f.content mark_safe f.content c RequestContext request {'flatpage' f} response HttpResponse t.render c populate_xheaders request response FlatPage f.id return response
def _secureEnoughString path secureishString armor sha1 randomBytes 64 .digest [ 16]return _coerceToFilesystemEncoding path secureishString
def _pretty_size size units ['G' 'M' 'K' 'B']while len units and size > 1000 size size / 1024.0 units.pop return '{0}{1}'.format round size 1 units[ -1 ]
def _generate_doc ret retc ret.copy retc['_id'] ret['jid']retc['timestamp'] time.time return retc
def _skew a try res stats.skew a except ValueError res np.nanreturn res
def diag_mat operator size operator.size[0] 1 return lo.LinOp lo.DIAG_MAT size [operator] None
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def process_or_children_is_defunct ppid defunct Falsetry pids get_children_pids ppid except error.CmdError return Truefor pid in pids cmd 'ps--no-headers-ocmd%d' % int pid proc_name system_output cmd ignore_status True if '<defunct>' in proc_name defunct Truebreakreturn defunct
def srange s try return ''.join [_expanded part for part in _reBracketExpr.parseString s .body] except return ''
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
def gzip_compress data s BytesIO g gzip.GzipFile fileobj s mode 'wb' g.write data g.close return s.getvalue
def fg2 x return np.sin 2 * x + 2 * np.exp -16 * x ** 2
def queue_models models context MAX_CYCLES 5model_queue []number_remaining_models len models allowed_cycles MAX_CYCLESwhile number_remaining_models > 0 previous_number_remaining_models number_remaining_modelsmodel models.pop 0 if check_dependencies model model_queue model_class ModelCode model model context context model_queue.append model_class else models.append model number_remaining_models len models if number_remaining_models previous_number_remaining_models allowed_cycles - 1if allowed_cycles < 0 missing_models [ModelCode model m context context for m in models]model_queue + missing_modelsmodels[ ] missing_modelsbreakelse allowed_cycles MAX_CYCLESreturn model_queue
def create_retention_policy database name duration replication default False **client_args client _client **client_args client.create_retention_policy name duration replication database default return True
def get_python_lib plat_specific 0 standard_lib 0 prefix None if prefix is None if standard_lib prefix plat_specific and BASE_EXEC_PREFIX or BASE_PREFIX else prefix plat_specific and EXEC_PREFIX or PREFIX if os.name 'posix' libpython os.path.join prefix 'lib' 'python' + get_python_version if standard_lib return libpythonelse return os.path.join libpython 'site-packages' elif os.name 'nt' if standard_lib return os.path.join prefix 'Lib' else return os.path.join prefix 'Lib' 'site-packages' else raise DistutilsPlatformError "Idon'tknowwherePythoninstallsitslibraryonplatform'%s'" % os.name
def convert_from_latlon_to_utm points None latitudes None longitudes None false_easting None false_northing None old_geo Geo_reference utm_points []if points None assert len latitudes len longitudes points map None latitudes longitudes for point in points zone easting northing redfearn float point[0] float point[1] false_easting false_easting false_northing false_northing new_geo Geo_reference zone old_geo.reconcile_zones new_geo utm_points.append [easting northing] return utm_points old_geo.get_zone
def check_whitelist request_host whitelist if ' ' not in request_host request_host request_host + ' 80' if request_host in whitelist return Truereturn any match_host request_host host for host in whitelist
@commands u'info' @example u'.infoallboardmemberspresent' def meetinginfo bot trigger if not ismeetingrunning trigger.sender bot.say u"Can'tdothat startmeetingfirst" returnif not trigger.group 2 bot.say u'try.infosomeinformativething' returnif not ischair trigger.nick trigger.sender bot.say u'Onlymeetingheadorchairscandothat' returnlogplain u'INFO ' + trigger.group 2 trigger.sender logHTML_listitem trigger.group 2 trigger.sender bot.say u'\x02INFO\x0f ' + trigger.group 2
def render_template_file template context None assert isinstance context Mapping template get_template template return template.render context
def last_arg_byref args return args[ -1 ]._obj.value
def test_rl_end_of_line lineedit bridge lineedit.set_aug_text 'f<oo>bar' bridge.rl_end_of_line assert lineedit.aug_text 'foobar|'
def close_tunnel _data global KNXTUNNELKNXTUNNEL.disconnect KNXTUNNEL None
def attach_epic_custom_attributes queryset as_field 'epic_custom_attributes_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json custom_attributes_epiccustomattribute \nORDERBYcustom_attributes_epiccustomattribute.order\n \nFROMcustom_attributes_epiccustomattribute\nWHEREcustom_attributes_epiccustomattribute.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def _contextual_locale context request context.get 'request' locale request.LANGUAGE_CODEif not localedata.exists locale locale settings.LANGUAGE_CODEreturn locale
def writePlistToString rootObject f StringIO writePlist rootObject f return f.getvalue
def libvlc_media_player_get_time p_mi f _Cfunctions.get 'libvlc_media_player_get_time' None or _Cfunction 'libvlc_media_player_get_time' 1 None ctypes.c_longlong MediaPlayer return f p_mi
def frt2 a if a.ndim ! 2 or a.shape[0] ! a.shape[1] raise ValueError 'Inputmustbeasquare 2-Darray' ai a.copy n ai.shape[0]f np.empty n + 1 n np.uint32 f[0] ai.sum axis 0 for m in range 1 n for row in range 1 n ai[row] roll ai[row] - row f[m] ai.sum axis 0 f[n] ai.sum axis 1 return f
def forwards apps schema_editor config {u'default' {u'accomplishment_class_append' u'accomplishment-certificate' u'platform_name' u'YourPlatformNameHere' u'company_about_url' u'http //www.example.com/about-us' u'company_privacy_url' u'http //www.example.com/privacy-policy' u'company_tos_url' u'http //www.example.com/terms-service' u'company_verified_certificate_url' u'http //www.example.com/verified-certificate' u'logo_src' u'/static/certificates/images/logo.png' u'logo_url' u'http //www.example.com'} u'honor' {u'certificate_type' u'HonorCode' u'certificate_title' u'CertificateofAchievement'} u'verified' {u'certificate_type' u'Verified' u'certificate_title' u'VerifiedCertificateofAchievement'}}certificate_html_view_configuration_model apps.get_model u'certificates' u'CertificateHtmlViewConfiguration' objects certificate_html_view_configuration_model.objectsif not objects.exists objects.create configuration json.dumps config enabled False
def check_for_date filename matcher x 0if matcher for expression in matcher regex re.compile expression match1 regex.search filename x + 1if match1 return match1 x return None 0
def diff before after assert after.eid before.eid plays []after_plays list after.drives.plays before_plays list before.drives.plays for play in after_plays if play not in before_plays plays.append play _players OrderedDict after_players list after.max_player_stats before_players list before.max_player_stats for aplayer in after_players has_before Falsefor bplayer in before_players if aplayer.playerid bplayer.playerid has_before Truepdiff aplayer - bplayer if pdiff is not None _players[aplayer.playerid] pdiffif not has_before _players[aplayer.playerid] aplayerplayers nflgame.seq.GenPlayerStats _players return GameDiff before before after after plays plays players players
def attach_issue_statuses queryset as_field 'issue_statuses_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json projects_issuestatus \nORDERBYprojects_issuestatus.order\n \nFROMprojects_issuestatus\nWHEREprojects_issuestatus.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def dylib_info filename is_dylib DYLIB_RE.match filename if not is_dylib return Nonereturn is_dylib.groupdict
def generate_sentence start_with_lorem False return _GENERATOR.generate_sentence start_with_lorem
def _AddByteSizeMethod message_descriptor cls def ByteSize self if not self._cached_byte_size_dirty return self._cached_byte_sizesize 0for field_descriptor field_value in self.ListFields size + field_descriptor._sizer field_value for tag_bytes value_bytes in self._unknown_fields size + len tag_bytes + len value_bytes self._cached_byte_size sizeself._cached_byte_size_dirty Falseself._listener_for_children.dirty Falsereturn sizecls.ByteSize ByteSize
def widget_move request profile Profile.objects.get_or_create user request.user [0]profile_data profile.extra_datawidget_type request.POST.get u'type' if widget_type u'primary' positions_key u'primary_widget_positions'widgets primary_widgetselse positions_key u'secondary_widget_positions'widgets secondary_widgetspositions profile_data.setdefault positions_key {} for widget in widgets widget_position request.POST.get widget.widget_id if widget_position is not None positions[widget.widget_id] widget_positionelse positions[widget.widget_id] str len widgets profile.save return HttpResponse
def scale s dtype None assert len s 3 return np.array np.diag np.concatenate [s 1.0 ] dtype
def p_const_ref p child thrift_stack[ -1 ]for name in p[1].split '.' father childchild getattr child name None if child is None raise ThriftParserError "Cann'tfindname%ratline%d" % p[1] p.lineno 1 if _get_ttype child is None or _get_ttype father TType.I32 p[0] childelse raise ThriftParserError 'Noenumvalueorconstantfoundnamed%r' % p[1]
def safe_rmtree directory if os.path.islink directory safe_delete directory else shutil.rmtree directory ignore_errors True
def safe_brands brands if isinstance brands str brands set [brands] if isinstance brands list brands set brands return brands
def _serialize_inventory inventory generation None data {field getattr inventory field for field in OUTPUT_INVENTORY_FIELDS}if generation data['resource_provider_generation'] generationreturn data
def getCraftedText fileName text '' liftRepository None return getCraftedTextFromText archive.getTextIfEmpty fileName text liftRepository
def ec2_credentials_delete user_id None name None access_key None profile None **connection_args kstone auth profile **connection_args if name user_id user_get name name profile None **connection_args [name]['id']if not user_id return {'Error' 'CouldnotresolveUserID'}kstone.ec2.delete user_id access_key return 'ec2key"{0}"deletedunderuserid"{1}"'.format access_key user_id
def triplet_to_rrggbb rgbtuple global _tripdicthexname _tripdict.get rgbtuple if hexname is None hexname '#%02x%02x%02x' % rgbtuple _tripdict[rgbtuple] hexnamereturn hexname
def kill_job jid return signal_job jid salt_SIGKILL
def getIsLayerStart firstWord skein splitLine if skein.isThereALayerStartWord return firstWord ' <layer>' if firstWord ! 'G1' and firstWord ! 'G2' and firstWord ! 'G3' return Falselocation gcodec.getLocationFromSplitLine skein.oldLocation splitLine if location.z - skein.oldZ > 0.1 skein.oldZ location.zreturn Truereturn False
def _encode_dbref name value check_keys opts buf bytearray '\x03' + name + '\x00\x00\x00\x00' begin len buf - 4 buf + _name_value_to_bson '$ref\x00' value.collection check_keys opts buf + _name_value_to_bson '$id\x00' value.id check_keys opts if value.database is not None buf + _name_value_to_bson '$db\x00' value.database check_keys opts for key val in iteritems value._DBRef__kwargs buf + _element_to_bson key val check_keys opts buf + '\x00'buf[begin begin + 4 ] _PACK_INT len buf - begin return bytes buf
def pid sig cmd __grains__['ps']output __salt__['cmd.run_stdout'] cmd pids ''for line in output.splitlines if 'status.pid' in line continueif re.search sig line if pids pids + '\n'pids + line.split [1]return pids
def validate_email_address emailaddress emailaddress '%s' % emailaddress domains 'aero' 'asia' 'biz' 'cat' 'com' 'coop' 'edu' 'gov' 'info' 'int' 'jobs' 'mil' 'mobi' 'museum' 'name' 'net' 'org' 'pro' 'tel' 'travel' if len emailaddress < 7 return Falsetry localpart domainname emailaddress.rsplit '@' 1 host toplevel domainname.rsplit '.' 1 except ValueError return Falseif len toplevel ! 2 and toplevel not in domains return Falsefor i in '-_.%+.' localpart localpart.replace i '' for i in '-_.' host host.replace i '' if localpart.isalnum and host.isalnum return Trueelse return False
def configtest ret {}cmd '{0}-t'.format __detect_os out __salt__['cmd.run_all'] cmd if out['retcode'] ! 0 ret['comment'] 'SyntaxError'ret['stderr'] out['stderr']ret['result'] Falsereturn retret['comment'] 'SyntaxOK'ret['stdout'] out['stderr']ret['result'] Truereturn ret
def repr_strength strength return {REQUIRED u'Required' STRONG u'Strong' MEDIUM u'Medium' WEAK u'Weak'}[strength]
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def get_sleep return {'Computer' get_computer_sleep 'Display' get_display_sleep 'HardDisk' get_harddisk_sleep }
def getrsq fitresult if hasattr fitresult 'resid' and hasattr fitresult 'model' resid fitresult.residendog fitresult.model.endognobs fitresult.nobselse resid fitresult[0]endog fitresult[1]nobs resid.shape[0]rss np.dot resid resid tss np.var endog * nobs return 1 - rss / tss rss tss tss - rss
def pause_execution message 'Testexecutionpaused.PressOKtocontinue.' MessageDialog message .show
def norm_l21 A n_orient copy True if A.size 0 return 0.0if copy A A.copy return np.sum np.sqrt groups_norm2 A n_orient
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def _setAuthCred if kb.passwordMgr and all _ is not None for _ in conf.scheme conf.hostname conf.port conf.authUsername conf.authPassword kb.passwordMgr.add_password None '%s //%s %d' % conf.scheme conf.hostname conf.port conf.authUsername conf.authPassword
def bitarray_to_bool data length results []for byte in data if six.PY2 byte ord byte for bit_no in range 7 -1 -1 bit byte & 1 << bit_no bit bit ! 0 results.append bit if len results length breakif len results length breakreturn np.array results dtype u'b1'
def _bootstrap_ubuntu name **kwargs version kwargs.get 'version' False if not version if __grains__['os'].lower 'ubuntu' version __grains__['oscodename']else version 'xenial'dst _make_container_root name cmd 'debootstrap--arch amd64{0}{1}'.format version dst ret __salt__['cmd.run_all'] cmd python_shell False if ret['retcode'] ! 0 _build_failed dst name return ret
def SigTermHandler signum frame raise KeyboardInterrupt
def memory since 0.0 ans get_memory ans / float 1024 ** 2 return ans - since
def _fixencoding input encoding final False prefix u'@charset"'if len input > len prefix if input.startswith prefix pos input.find u'"' len prefix if pos > 0 if encoding.replace '_' '-' .lower 'utf-8-sig' encoding u'utf-8'return prefix + encoding + input[pos ] else return inputelif not prefix.startswith input or final return inputif final return inputreturn None
def security_group_update context security_group_id values columns_to_join None return IMPL.security_group_update context security_group_id values columns_to_join columns_to_join
def mount module args mount_bin module.get_bin_path 'mount' required True name args['name']cmd [mount_bin]if ismount name return remount module mount_bin args if get_platform .lower 'openbsd' if module.params['fstab'] is not None module.fail_json msg 'OpenBSDdoesnotsupportalternatefstabfiles.DonotspecifythefstabparameterforOpenBSDhosts' else cmd + _set_fstab_args args['fstab'] cmd + [name] rc out err module.run_command cmd if rc 0 return 0 '' else return rc out + err
def test_cc_sk_estimator check_estimator ClusterCentroids
def _get_thumbnail_path image_path width height if image_path is None return None _ ext os.path.splitext image_path if ext in ['.png' '.jpg' '.jpeg' '.gif'] thumbnail_path image_pathelse fingerprint cache.hash_digest '{width}x{height}\n{image_path}'.format **locals thumbnail_path os.path.join temp_path fingerprint + _IMAGE_EXTENSION _validate_thumbnail_currentness image_path thumbnail_path return thumbnail_path
def _get_regexp_ops connection regexp_op_map {'postgresql' '~' 'mysql' 'REGEXP' 'sqlite' 'REGEXP'}regex_safe_filters {'mysql' _safe_regex_mysql}db_type _db_connection_type connection return regex_safe_filters.get db_type lambda x x regexp_op_map.get db_type 'LIKE'
def b2a_hex s return binascii.b2a_hex s
def lexicographic alphabet for n in count for e in product alphabet repeat n yield e
@not_implemented_for 'directed' def min_weighted_dominating_set G weight None if len G 0 return set dom_set set def _cost node_and_neighborhood 'Returnsthecost-effectivenessofgreedilychoosingthegiven\nnode.\n\n`node_and_neighborhood`isatwo-tuplecomprisinganodeandits\nclosedneighborhood.\n\n' v neighborhood node_and_neighborhoodreturn G.node[v].get weight 1 / len neighborhood - dom_set vertices set G neighborhoods {v {v} | set G[v] for v in G}while vertices dom_node min_set min neighborhoods.items key _cost dom_set.add dom_node del neighborhoods[dom_node]vertices - min_setreturn dom_set
def dumps obj key None salt u'django.core.signing' serializer JSONSerializer compress False data serializer .dumps obj is_compressed Falseif compress compressed zlib.compress data if len compressed < len data - 1 data compressedis_compressed Truebase64d b64_encode data if is_compressed base64d '.' + base64d return TimestampSigner key salt salt .sign base64d
def get_release_group_image_front releasegroupid size None return get_image releasegroupid 'front' size size entitytype 'release-group'
def slide_in clip duration side w h clip.sizepos_dict {'left' lambda t min 0 w * t / duration - 1 'center' 'right' lambda t max 0 w * 1 - t / duration 'center' 'top' lambda t 'center' min 0 h * t / duration - 1 'bottom' lambda t 'center' max 0 h * 1 - t / duration }return clip.set_pos pos_dict[side]
def am_following_dataset context data_dict return _am_following context data_dict ckan.logic.schema.default_follow_dataset_schema context['model'].UserFollowingDataset
def SocketConnection host port DEFAULT_PORT return Connection Channel SocketStream.from_new_socket host port
@click.group def tsdb pass
def get_repository_dependencies app metadata_id sa_session app.model.context.currentreturn sa_session.query app.model.RepositoryDependency .filter app.model.RepositoryDependency.table.c.parent_metadata_id metadata_id .all
def test_bayesian_info_criterion_lsq n_samples 25n_params 1 2 1 ssr 48959 32512 37980 answer 192.706 185.706 186.36 assert_allclose answer[0] bayesian_info_criterion_lsq ssr[0] n_params[0] n_samples atol 0.01 assert_allclose answer[1] bayesian_info_criterion_lsq ssr[1] n_params[1] n_samples atol 0.01 assert_allclose answer[2] bayesian_info_criterion_lsq ssr[2] n_params[2] n_samples atol 0.01
def str_startswith arr pat na np.nan f lambda x x.startswith pat return _na_map f arr na dtype bool
def test_lex_symbols objs tokenize 'foo' assert objs [HySymbol 'foo' ]
def generate_kindofgarch nobs ar ma mu 1.0 from statsmodels.tsa.arima_process import arma_generate_sampleh arma_generate_sample ar ma nobs 0.1 h mu + h ** 2 h np.exp h err np.sqrt h * np.random.randn nobs return err h
def _clean_names names remove_whitespace False before_dash True cleaned []for name in names if '' in name and remove_whitespace name name.replace '' '' if '-' in name and before_dash name name.split '-' [0]if name.endswith '_virtual' name name[ -8 ]cleaned.append name return cleaned
def enroll_email course_id student_email auto_enroll False email_students False email_params None language None previous_state EmailEnrollmentState course_id student_email enrollment_obj Noneif previous_state.user if CourseMode.is_white_label course_id course_mode CourseMode.DEFAULT_SHOPPINGCART_MODE_SLUGelse course_mode Noneif previous_state.enrollment course_mode previous_state.modeenrollment_obj CourseEnrollment.enroll_by_email student_email course_id course_mode if email_students email_params['message'] 'enrolled_enroll'email_params['email_address'] student_emailemail_params['full_name'] previous_state.full_namesend_mail_to_student student_email email_params language language else cea _ CourseEnrollmentAllowed.objects.get_or_create course_id course_id email student_email cea.auto_enroll auto_enrollcea.save if email_students email_params['message'] 'allowed_enroll'email_params['email_address'] student_emailsend_mail_to_student student_email email_params language language after_state EmailEnrollmentState course_id student_email return previous_state after_state enrollment_obj
def forums request qs Forum.objects.filter is_listed True qs qs.select_related 'last_post' 'last_post__author' qs qs.extra select {'thread_count' 'SELECTCOUNT * FROMforums_threadWHEREforums_thread.forum_id forums_forum.id'} forums_ [f for f in qs if f.allows_viewing_by request.user ]return render request 'forums/forums.html' {'forums' paginate request forums_ }
def longest_increasing_subseq seq if not seq return []head [0]predecessor [ -1 ]for i in range 1 len seq j bisect_left [seq[head[idx]] for idx in range len head ] seq[i] if j len head head.append i if seq[i] < seq[head[j]] head[j] ipredecessor.append head[ j - 1 ] if j > 0 else -1 result []trace_idx head[ -1 ]while trace_idx > 0 result.append seq[trace_idx] trace_idx predecessor[trace_idx]return result[ -1 ]
def update_comments_in_parent_after_request if hasattr frappe.local u'_comments' for reference_doctype reference_name _comments in frappe.local._comments add_column reference_doctype u'_comments' u'Text' update_comments_in_parent reference_doctype reference_name _comments frappe.db.commit
def mem_rss p ps if p is not None return humanbytes _process_memory_info p .rss
def conda prefix '~/miniconda' use_sudo False if not is_conda_installed install_miniconda prefix prefix use_sudo use_sudo
def fake_set_locale category value None original_setlocale locale.setlocale if value not in None '' 'C' 'POSIX' raise locale.Error 'localeemulationonlysupports"C"locale' return original_setlocale category 'C'
def register_admin_extension url_prefix extension_data ADMIN_EXTENSIONS[url_prefix] extension_data
def qqplot data dist stats.norm distargs a 0 loc 0 scale 1 fit False line None ax None probplot ProbPlot data dist dist distargs distargs fit fit a a loc loc scale scale fig probplot.qqplot ax ax line line return fig
def yellow text attrib None return colorize text 'yellow' attrib
def FilesBelongToSameModule filename_cc filename_h if not filename_cc.endswith '.cc' return False '' filename_cc filename_cc[ - len '.cc' ]if filename_cc.endswith '_unittest' filename_cc filename_cc[ - len '_unittest' ]elif filename_cc.endswith '_test' filename_cc filename_cc[ - len '_test' ]filename_cc filename_cc.replace '/public/' '/' filename_cc filename_cc.replace '/internal/' '/' if not filename_h.endswith '.h' return False '' filename_h filename_h[ - len '.h' ]if filename_h.endswith '-inl' filename_h filename_h[ - len '-inl' ]filename_h filename_h.replace '/public/' '/' filename_h filename_h.replace '/internal/' '/' files_belong_to_same_module filename_cc.endswith filename_h common_path ''if files_belong_to_same_module common_path filename_cc[ - len filename_h ]return files_belong_to_same_module common_path
def isIPAddress addr dottedParts addr.split '.' if len dottedParts 4 for octet in dottedParts try value int octet except ValueError return Falseelse if value < 0 or value > 255 return Falsereturn Truereturn False
def character_count html count 0strip_space re.compile u'\\s+' for match in re.finditer u'>[^<]+<' html count + len strip_space.sub u'' match.group - 2 return count
def reinstall_ruby ruby runas None return _rvm ['reinstall' ruby] runas runas
def validate_reading data return data ! 'Disabled'
def set_test_mode v True global _TEST_MODE _TEST_RESULT_TEST_MODE v_TEST_RESULT []
@register_hookdef bitbucket_hook_helper data if 'push' in data return bitbucket_webhook_helper data owner data['repository']['owner']slug data['repository']['slug']if data['commits'] branch data['commits'][ -1 ]['branch']else branch Noneparams {'owner' owner 'slug' slug}if data['repository']['scm'] 'git' repos [ repo % params for repo in BITBUCKET_GIT_REPOS]elif data['repository']['scm'] 'hg' repos [ repo % params for repo in BITBUCKET_HG_REPOS]else LOGGER.error 'unsupportedrepository %s' repr data['repository'] raise ValueError 'unsupportedrepository' return {'service_long_name' 'Bitbucket' 'repo_url' ''.join [data['canon_url'] data['repository']['absolute_url']] 'repos' repos 'branch' branch}
def film rebulk Rebulk .regex_defaults flags re.IGNORECASE rebulk.regex 'f \\d{1 2} ' name 'film' private_parent True children True formatter int rebulk.rules FilmTitleRule return rebulk
def _get_sqs_conn profile region None key None keyid None if profile if isinstance profile string_types _profile __opts__[profile]elif isinstance profile dict _profile profilekey _profile.get 'key' None keyid _profile.get 'keyid' None region _profile.get 'region' None if not region region __opts__.get 'sqs.region' 'us-east-1' if not key key __opts__.get 'sqs.key' None if not keyid keyid __opts__.get 'sqs.keyid' None try conn boto.sqs.connect_to_region region aws_access_key_id keyid aws_secret_access_key key except boto.exception.NoAuthHandlerFound log.error 'Noauthenticationcredentialsfoundwhenattemptingtomakesqs_eventengineconnectiontoAWS.' return Nonereturn conn
def whois t Twitter auth authen try screen_name g['stuff'].split [0]except printNicely red "SorryIcan'tunderstand." returnif screen_name.startswith '@' try user t.users.show screen_name screen_name[1 ] include_entities False show_profile user except debug_option printNicely red 'Nouser.' else printNicely red "Anameshouldbeginwitha'@'"
def qubit_to_matrix qubit format 'sympy' return represent qubit format format
def regexp_bool regexp flags 0 def transform_function value return bool re.match regexp value flags return transform_function
def delete_thread request thread_id cc_thread context _get_thread_and_context request thread_id if can_delete cc_thread context cc_thread.delete thread_deleted.send sender None user request.user post cc_thread else raise PermissionDenied
def savehist readline.write_history_file HISTFILE
def template_macro_params root param_dict {}macro_dict _macros_of_type root 'template' lambda el el.text for key value in macro_dict.items param_dict[key] valuereturn param_dict
def dry registry xml_parent data xml_element XML.SubElement xml_parent 'hudson.plugins.dry.DryPublisher' helpers.build_trends_publisher '[DRY]' xml_element data settings [ 'high-threshold' 'highThreshold' 50 'normal-threshold' 'normalThreshold' 25 ]helpers.convert_mapping_to_xml xml_element data settings fail_required True
def bulk_build jail pkg_file keep False if not os.path.isfile pkg_file return 'Couldnotfindfile{0}onfilesystem'.format pkg_file if not is_jail jail return 'Couldnotfindjail{0}'.format jail if keep cmd 'poudrierebulk-k-f{0}-j{1}'.format pkg_file jail else cmd 'poudrierebulk-f{0}-j{1}'.format pkg_file jail res __salt__['cmd.run'] cmd lines res.splitlines for line in lines if 'packagesbuilt' in line return linereturn 'Theremayhavebeenanissuebuildingpackagesdumpingoutput {0}'.format res
def get_score submissions_scores csm_scores persisted_block block weight _get_weight_from_block persisted_block block raw_earned raw_possible weighted_earned weighted_possible attempted _get_score_from_submissions submissions_scores block or _get_score_from_csm csm_scores block weight or _get_score_from_persisted_or_latest_block persisted_block block weight if weighted_possible is None or weighted_earned is None return Noneelse has_valid_denominator weighted_possible > 0.0 graded _get_graded_from_block persisted_block block if has_valid_denominator else False return ProblemScore raw_earned raw_possible weighted_earned weighted_possible weight graded attempted attempted
def safe_name name return re.sub '[^A-Za-z0-9.]+' '-' name
def _tuplify obj if np.iterable obj and not isinstance obj string_types res tuple str o for o in obj else res str obj return res
@blueprint.route '/sources/<source>/meters' def list_meters_by_source source rq flask.requestmeters rq.storage_conn.get_meters source source project acl.get_limited_to_project rq.headers metaquery _get_metaquery rq.args return flask.jsonify meters [m.as_dict for m in meters]
def get_query_words query word_finder re.compile u'" [^"]+ "| \\S+ ' .findallnormalize_spaces re.compile u'\\s{2 }' .subwords []for word in word_finder query found_word word[0] or word[1] words.append normalize_spaces u'' found_word.strip return words
def askdirectory **options return apply DirectoryBrowser options .show
def valid_anytype val for validator in VALIDATOR.values if validator valid_anytype continuetry if validator val return Trueexcept NotValid passif isinstance val type return Trueraise NotValid 'AnyType'
def _api_test_growl name output kwargs logging.info 'SendingGrowlnotification' res sabnzbd.notifier.send_growl 'SABnzbd' T 'TestNotification' 'other' test kwargs return report output error res
def reportDeprecatedWorkerNameUsage message stacklevel None filename None lineno None if filename is None if stacklevel is None stacklevel 3else stacklevel + 2warnings.warn DeprecatedWorkerNameWarning message None stacklevel else assert stacklevel is None if lineno is None lineno 0warnings.warn_explicit DeprecatedWorkerNameWarning message DeprecatedWorkerNameWarning filename lineno
def classname object modname name object.__name__if object.__module__ ! modname name object.__module__ + '.' + name return name
def instance_group_get_all_by_project_id context project_id return IMPL.instance_group_get_all_by_project_id context project_id
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def maybe_add_auth url auth force False if not auth return urlurl_parts urlparse url ._asdict if url_parts[u'auth'] and not force return urlurl_parts[u'auth'] authreturn Url **url_parts .url
def capfirst value return value and value[0].upper + value[1 ]
def linear_transform_weights input_dim output_dim param_list None name '' weight_inialization uniform numpy.sqrt 2.0 / input_dim input_dim output_dim W theano.shared weight_inialization name name assert param_list is not None param_list.append W return W
def _tgrep_nltk_tree_pos_action _s _l tokens node_tree_position tuple int x for x in tokens if x.isdigit return lambda i lambda n m None l None hasattr n u'treeposition' and n.treeposition i node_tree_position
def get_ordered_categories database_cats get_categories categories []for cat in database_cats.keys if cat ! '*' categories.append database_cats[cat].get_dict categories.sort key lambda cat cat['order'] categories.insert 0 database_cats['*'].get_dict return categories
@with_open_mode 'r' @with_sizes 'medium' def seek_forward_blockwise f f.seek 0 2 size f.tell f.seek 0 0 for i in xrange 0 size - 1 1000 f.seek i 0
def string_escape text replacements '\\' '\\\\' "'" "\\'" '"' '\\"' '\n' '\\n' '\r' '\\r' '\x00' '\\x00' '\\ufeff' '\\ufeff' '\\u2028' '\\u2028' '\\u2029' '\\u2029' for orig repl in replacements text text.replace orig repl return text
def cos mat target None if not target target materr_code _cudamat.apply_cos mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def returner ret conn mdb _get_conn ret if isinstance ret['return'] dict back _remove_dots ret['return'] else back ret['return']if isinstance ret dict full_ret _remove_dots ret else full_ret retlog.debug back sdata {'minion' ret['id'] 'jid' ret['jid'] 'return' back 'fun' ret['fun'] 'full_ret' full_ret}if 'out' in ret sdata['out'] ret['out']if float version > 2.3 mdb.saltReturns.insert_one sdata.copy else mdb.saltReturns.insert sdata.copy
def organization_purge context data_dict return _group_or_org_purge context data_dict is_org True
def separate_users node user_ids OSFUser apps.get_model 'osf.OSFUser' removed []subbed []for user_id in user_ids try user OSFUser.load user_id except TypeError user user_idif node.has_permission user 'read' subbed.append user_id else removed.append user_id return subbed removed
def test_record_good output StringIO recorder Record file_object output replay False num_lines 10for i in xrange num_lines recorder.handle_line str i + '\n' output_value output.getvalue assert output_value ''.join str i + '\n' for i in xrange num_lines output StringIO output_value playback_checker Record file_object output replay True for i in xrange num_lines playback_checker.handle_line str i + '\n'
def check_virtualserver lb name if __opts__['load_balancers'].get lb None username password list __opts__['load_balancers'][lb].values else raise Exception 'Unabletofind`{0}`loadbalancer'.format lb F5 F5Mgmt lb username password return F5.check_virtualserver name
def to_marshallable_type obj if obj is None return Noneif hasattr obj '__marshallable__' return obj.__marshallable__ if hasattr obj '__getitem__' return objreturn dict obj.__dict__
def build_repository_type_select_field trans repository None name 'repository_type' if repository selected_type str repository.type else selected_type Nonerepository_type_select_field SelectField name name for type_label type_class in trans.app.repository_types_registry.repository_types_by_label.items option_label str type_class.label option_value str type_class.type if selected_type and selected_type option_value selected Trueelse selected Falseif repository if repository.type option_value repository_type_select_field.add_option option_label option_value selected selected elif type_class.is_valid_for_type trans.app repository repository_type_select_field.add_option option_label option_value selected selected else repository_type_select_field.add_option option_label option_value selected selected return repository_type_select_field
def polygamma n x n x asarray n asarray x fac2 -1.0 ** n + 1 * gamma n + 1.0 * zeta n + 1 x return where n 0 psi x fac2
def all_pairs_shortest_path G cutoff None return {n single_source_shortest_path G n cutoff cutoff for n in G}
def parse_field_path field_path model_path field_name field_path.rsplit u'.' 1 app_name model_name model_path.split u'.models.' _ app_label app_name.rsplit u'.' 1 return app_label model_name.lower field_name
def stub_set_host_enabled context host_name enabled results {True 'enabled' False 'disabled'}if host_name 'notimplemented' raise NotImplementedError elif host_name 'dummydest' raise exception.ComputeHostNotFound host host_name elif host_name 'service_not_available' raise exception.ComputeServiceUnavailable host host_name elif host_name 'host_c2' return results[ not enabled ]else return results[enabled]
def secgroup_create name description profile None conn _auth profile return conn.secgroup_create name description
def unsafe_eval_enabled response non_report_only_policies retrieve_csp_policies response report_only_policies retrieve_csp_policies response True policies_all merge_policies_dict non_report_only_policies report_only_policies if len policies_all > 0 for directive_name in policies_all if directive_name.lower ! CSP_DIRECTIVE_SCRIPT continuefor directive_value in policies_all[directive_name] if directive_value.strip .lower CSP_DIRECTIVE_VALUE_UNSAFE_EVAL return Truereturn False
def _to_micropennies_per_op pennies per return pennies * 1000000 / per
def fuse_getitem dsk func place return fuse_selections dsk getitem func lambda a b tuple b[ place] + a[2] + tuple b[ place + 1 ]
def p_expression_uminus t t[0] - t[2]
def istraceback object return isinstance object types.TracebackType
def cmServiceRequest PriorityLevel_presence 0 a TpPd pd 5 b MessageType mesType 36 c CmServiceTypeAndCiphKeySeqNr e MobileStationClassmark2 f MobileId packet a / b / c / e / f if PriorityLevel_presence is 1 g PriorityLevelHdr ieiPL 8 eightBitPL 0 packet packet / g return packet
def shape x return tf.shape x
def page_not_found request template_name '404.html' t loader.get_template template_name return http.HttpResponseNotFound t.render RequestContext request {'request_path' request.path}
def cmd_map args from mavflightview import mavflightview_mav mavflightview_optionsoptions mavflightview_options options.condition mestate.settings.conditionoptions._flightmodes mestate.mlog._flightmodesoptions.show_flightmode_legend mestate.settings.show_flightmodeif len args > 0 options.types ' '.join args [path wp fen used_flightmodes] mavflightview_mav mestate.mlog options mestate.flightmode_selections child multiprocessing.Process target map_process args [path wp fen used_flightmodes options] child.start mestate.mlog.rewind
def do_cli manager options if options.list_action u'all' entry_list_lists options returnif options.list_action u'list' entry_list_list options returnif options.list_action u'show' entry_list_show options returnif options.list_action u'add' entry_list_add options returnif options.list_action u'del' entry_list_del options returnif options.list_action u'purge' entry_list_purge options return
def size string return Utf8 string .__size__
def format_html html return html.replace u'\n' u'' .replace u'' u''
def get_deleted_objects objs opts user admin_site using collector NestedObjects using using collector.collect objs perms_needed set def format_callback obj has_admin obj.__class__ in admin_site._registry opts obj._metaif has_admin admin_url reverse u'%s %s_%s_change' % admin_site.name opts.app_label opts.object_name.lower None quote obj._get_pk_val p u'%s.%s' % opts.app_label opts.get_delete_permission if not user.has_perm p perms_needed.add opts.verbose_name return format_html u'{0} <ahref "{1}">{2}</a>' capfirst opts.verbose_name admin_url obj else return u'%s %s' % capfirst opts.verbose_name force_text obj to_delete collector.nested format_callback protected [format_callback obj for obj in collector.protected]return to_delete perms_needed protected
def find_vpc module vpc_conn vpc_id None cidr None if vpc_id None and cidr None module.fail_json msg 'Youmustspecifyeitheravpc_idoracidrblock+listofuniquetags aborting' found_vpcs []resource_tags module.params.get 'resource_tags' if vpc_id is not None found_vpcs vpc_conn.get_all_vpcs None {'vpc-id' vpc_id 'state' 'available'} else previous_vpcs vpc_conn.get_all_vpcs None {'cidr' cidr 'state' 'available'} for vpc in previous_vpcs vpc_tags dict t.name t.value for t in vpc_conn.get_all_tags filters {'resource-id' vpc.id} if resource_tags and set resource_tags.items .issubset set vpc_tags.items found_vpcs.append vpc found_vpc Noneif len found_vpcs 1 found_vpc found_vpcs[0]if len found_vpcs > 1 module.fail_json msg 'Foundmorethanonevpcbasedonthesuppliedcriteria aborting' return found_vpc
def extract_javascript_msgids source extracted extract_javascript fileobj StringIO source keywords {'_' None 'P_' 1 2 'N_' None 'NP_' 1 2 } comment_tags {} options {} return [msg_id for line func msg_id comments in extracted]
def _handle_zeros_in_scale scale copy True if np.isscalar scale if scale 0.0 scale 1.0return scaleelif isinstance scale np.ndarray if copy scale scale.copy scale[ scale 0.0 ] 1.0return scale
def create_figure fig Figure a fig.add_subplot 111 t np.arange 0.0 3.0 0.01 s np.sin 2 * np.pi * t a.plot t s return fig
def getOnePayload results ans auth add resultsreturn ans[0].payload
def get_browse_partitioned_table_limit return BROWSE_PARTITIONED_TABLE_LIMIT.get
def same_file a b a os.path.normpath os.path.abspath a b os.path.normpath os.path.abspath b if sabnzbd.WIN32 or sabnzbd.DARWIN a a.lower b b.lower if b.startswith a return 2if 'samefile' in os.path.__dict__ try return int os.path.samefile a b except return 0else return int a b
def no_such_executable_logged case logger assertHasMessage case logger ZFS_ERROR {'status' 1 'zfs_command' 'nonsensegarbagemadeupnosuchcommand' 'output' '[Errno2]Nosuchfileordirectory'} case.assertEqual len LoggedMessage.ofType logger.messages ZFS_ERROR 1
def createModel modelParams model ModelFactory.create modelParams model.enableInference {'predictedField' 'kw_energy_consumption'} return model
def test_dont_break_imports_without_namespaces src u 'from__future__importabsolute_import\nimportxyzzy' parser ParserWithRecovery load_grammar src 'test.py' assert parser.module.has_explicit_absolute_import
@register.simple_tag takes_context True def locale_js_include context request context['request']try lang_code request.LANGUAGE_CODEexcept AttributeError return ''if lang_code 'en' or lang_code not in settings.SUPPORTED_LANGUAGES return ''href get_asset_url 'sentry' 'dist/locale/' + lang_code + '.js' return '<scriptsrc "{0}"{1}></script>'.format href crossorigin
def test_randomize_corrmat_dist a rs.randn 3 20 for n_i in [5 10] p_mat dist algo.randomize_corrmat a n_iter n_i return_dist True assert_equal n_i dist.shape[ -1 ] p_mat dist algo.randomize_corrmat a n_iter 10000 return_dist True diag_mean dist[ 0 0 ].mean assert_equal diag_mean 1 off_diag_mean dist[ 0 1 ].mean nose.tools.assert_greater 0.05 off_diag_mean
def getGaleraFile return '/usr/lib/libgalera_smm.so'
@evalcontextfilterdef do_urlize eval_ctx value trim_url_limit None nofollow False target None rel None policies eval_ctx.environment.policiesrel set rel or '' .split or [] if nofollow rel.add 'nofollow' rel.update policies['urlize.rel'] or '' .split if target is None target policies['urlize.target']rel ''.join sorted rel or None rv urlize value trim_url_limit rel rel target target if eval_ctx.autoescape rv Markup rv return rv
@check_is_trading@export_as_api@ExecutionContext.enforce_phase EXECUTION_PHASE.HANDLE_BAR EXECUTION_PHASE.SCHEDULED def order_lots id_or_ins amount style None order_book_id assure_order_book_id id_or_ins round_lot int get_data_proxy .instrument order_book_id .round_lot return order_shares order_book_id amount * round_lot style
def setup app app.add_role 'rfc' rfclink return
def abstract func def wrapper *__args **__kw raise NotImplementedError 'Missingrequired%s method' % func.__name__ wrapper.__name__ func.__name__wrapper.__dict__ func.__dict__wrapper.__doc__ func.__doc__return wrapper
def wait_for_volume_status client volume_id status body client.show_volume volume_id ['volume']volume_status body['status']start int time.time while volume_status ! status time.sleep client.build_interval body client.show_volume volume_id ['volume']volume_status body['status']if volume_status 'error' and status ! 'error' raise exceptions.VolumeBuildErrorException volume_id volume_id if volume_status 'error_restoring' raise exceptions.VolumeRestoreErrorException volume_id volume_id if int time.time - start > client.build_timeout message 'Volume%sfailedtoreach%sstatus current%s withintherequiredtime %ss .' % volume_id status volume_status client.build_timeout raise lib_exc.TimeoutException message
def _abstractPath case return md5 case.mktemp .hexdigest
def get_pull_request project num github_api 3 if github_api 2 url 'http //github.com/api/v2/json/pulls/{project}/{num}'.format project project num num elif github_api 3 url 'https //api.github.com/repos/{project}/pulls/{num}'.format project project num num response requests.get url response.raise_for_status if github_api 2 return json.loads response.text ['pull']return json.loads response.text
def _format_content password salt encrypt True if not encrypt and not salt return passwordassert salt '_format_contentwascalledwithencryptionrequestedbutnosaltvalue'return u'%ssalt %s' % password salt
def handle_extensions extensions 'html' ignored 'py' ext_list []for ext in extensions ext_list.extend ext.replace '' '' .split ' ' for i ext in enumerate ext_list if not ext.startswith '.' ext_list[i] '.%s' % ext_list[i] return set [x for x in ext_list if x.strip '.' not in ignored ]
def get_output_volume cmd 'osascript-e"getoutputvolumeof getvolumesettings "'call __salt__['cmd.run_all'] cmd output_loglevel 'debug' python_shell False _check_cmd call return call.get 'stdout'
def _trace_D gj p_i Dxtrav for h in Dxtrav if h[gj] p_i return hreturn None
def compile_file filepath libraries None combined 'bin abi' optimize True extra_args None workdir filename os.path.split filepath args solc_arguments libraries libraries combined combined optimize optimize extra_args extra_args args.insert 0 get_compiler_path args.append filename output subprocess.check_output args cwd workdir return solc_parse_output output
def send_notif_for_after_purchase user invoice_id order_url send_notification user user action NOTIF_TICKET_PURCHASED title NOTIFS[NOTIF_TICKET_PURCHASED]['title'].format invoice_id invoice_id message NOTIFS[NOTIF_TICKET_PURCHASED]['message'].format order_url order_url
def ustr what if isinstance what unicode return whattry r what.__str__ except AttributeError r str what if not isinstance r unicode return unicode r ENCODING return r
def _tgrep_rel_disjunction_action _s _l tokens tokens [x for x in tokens if x ! u'|' ]if len tokens 1 return tokens[0]elif len tokens 2 return lambda a b lambda n m None l None a n m l or b n m l tokens[0] tokens[1]
def _invalidWin32App pywinerr return pywinerr.args[0] 193
def assert_array_list_equal xlist ylist err_msg '' verbose True if len xlist ! len ylist raise AssertionError 'Listsizeisdifferent' for x y in zip xlist ylist numpy.testing.assert_array_equal cupy.asnumpy x cupy.asnumpy y err_msg err_msg verbose verbose
def _get_output_filename dataset_dir split_name return '%s/mnist_%s.tfrecord' % dataset_dir split_name
@auth.route '/reset-password' methods ['GET' 'POST'] def forgot_password if not current_user.is_anonymous return redirect url_for 'forum.index' form ForgotPasswordForm if form.validate_on_submit user User.query.filter_by email form.email.data .first if user send_reset_token.delay user flash _ 'Emailsent!Pleasecheckyourinbox.' 'info' return redirect url_for 'auth.forgot_password' else flash _ 'Youhaveenteredanusernameoremailaddressthatisnotlinkedwithyouraccount.' 'danger' return render_template 'auth/forgot_password.html' form form
def lambdify leaves expr s scope funcstr leaves expr return eval s scope
def ContactVCard parent synopsis [ t and t.replace 'vcard' 'contact' or t for t in parent.SYNOPSIS]synopsis[2] synopsis[1]class ContactVCardCommand parent SYNOPSIS tuple synopsis KIND 'individual'ORDER 'Tagging' 3 VCARD 'contact'return ContactVCardCommand
def get_flow **kwargs task_id kwargs.get 'task_id' task_type kwargs.get 'task_type' image_repo kwargs.get 'image_repo' LOG.debug 'Flow % task_type swithID% id son% repo s' {'task_type' task_type 'id' task_id 'repo' image_repo} return lf.Flow task_type .add _Introspect task_id task_type image_repo
def RekallEProcessRenderer x return '%s %s ' % x['Cybox']['Name'] x['Cybox']['PID']
def test_get_editor_filter assert get_editor_filter state 'untranslated' '#filter untranslated' assert get_editor_filter state 'untranslated' sort 'newest' '#filter untranslated&sort newest' assert get_editor_filter sort 'newest' '#sort newest' assert get_editor_filter state 'all' search 'Foo' sfields 'locations' '#filter all' assert get_editor_filter search 'Foo' sfields 'locations' '#search Foo&sfields locations' assert get_editor_filter search 'Foo' sfields ['locations' 'notes'] '#search Foo&sfields locations notes' assert get_editor_filter search 'Foo bar.po\nID 1' sfields 'locations' '#search Foo%3A+bar.po%0AID%3A+1&sfields locations'
def get_default_gcs_bucket_name deadline None rpc create_rpc deadline make_get_default_gcs_bucket_name_call rpc rpc.wait return rpc.get_result
def _aggr_mean inList aggrSum 0nonNone 0for elem in inList if elem ! SENTINEL_VALUE_FOR_MISSING_DATA aggrSum + elemnonNone + 1if nonNone ! 0 return aggrSum / nonNone else return None
def test_zeros AreEqual binascii.b2a_hex '\x00\x00\x10\x00' '00001000'
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
def mask_secret_parameters parameters secret_parameters result copy.deepcopy parameters for parameter in secret_parameters if parameter in result result[parameter] MASKED_ATTRIBUTE_VALUEreturn result
def iriToURI iri return _escapeme_re.sub _percentEscapeUnicode iri
def schema_create dbname name owner None user None db_user None db_password None db_host None db_port None if schema_exists dbname name db_user db_user db_password db_password db_host db_host db_port db_port log.info "'{0}'alreadyexistsin'{1}'".format name dbname return Falsesub_cmd 'CREATESCHEMA"{0}"'.format name if owner is not None sub_cmd '{0}AUTHORIZATION"{1}"'.format sub_cmd owner ret _psql_prepare_and_run ['-c' sub_cmd] user db_user password db_password port db_port host db_host maintenance_db dbname runas user return ret['retcode'] 0
def make_cgi_application global_conf script path None include_os_environ None query_string None if path is None path global_conf.get 'path' or global_conf.get 'PATH' include_os_environ converters.asbool include_os_environ return CGIApplication None script path path include_os_environ include_os_environ query_string query_string
def connected return {'out' __proxy__['napalm.ping'] }
@frappe.whitelist def set_value doctype name fieldname value None if fieldname ! u'idx' and fieldname in frappe.model.default_fields frappe.throw _ u'Cannoteditstandardfields' if not value values fieldnameif isinstance fieldname basestring try values json.loads fieldname except ValueError values {fieldname u''}else values {fieldname value}doc frappe.db.get_value doctype name [u'parenttype' u'parent'] as_dict True if doc and doc.parent and doc.parenttype doc frappe.get_doc doc.parenttype doc.parent child doc.getone {u'doctype' doctype u'name' name} child.update values else doc frappe.get_doc doctype name doc.update values doc.save return doc.as_dict
def get_image_label name default 'not_found.png' label QLabel label.setPixmap QPixmap get_image_path name default return label
@command 'rmp\\s* \\d+|%s ' % WORD def playlist_remove name if name.isdigit or g.userpl.get name if name.isdigit name int name - 1 name sorted g.userpl [name]del g.userpl[name]g.message 'Deletedplaylist%s%s%s' % c.y name c.w g.content content.playlists_display playlists.save else g.message util.F 'plnotfoundadvisels' % name g.content content.playlists_display
def listify_value arg split None out []if not isinstance arg list tuple arg [arg]for val in arg if val is None continueif isinstance val list tuple out.extend listify_value val split split continueout.extend s.strip for s in text_type val .split split assert all isinstance val string_types for val in out return out
def base64_decode s if not isinstance s bytes s s.encode 'ascii' 'replace' decoded decodebytes s return decoded
def auto_fields resource resource_def config.DOMAIN[resource]fields [resource_def['id_field'] config.LAST_UPDATED config.DATE_CREATED config.ETAG]fields + [config.ISSUES config.STATUS config.LINKS]if resource_def['versioning'] is True fields.append config.VERSION fields.append config.LATEST_VERSION fields.append resource_def['id_field'] + config.VERSION_ID_SUFFIX if resource_def['soft_delete'] is True fields.append config.DELETED return fields
def document_batch_action section resource_name event_emitter batch_action_model service_model collection_model include_signature True operation_model service_model.operation_model batch_action_model.request.operation ignore_params get_resource_ignore_params batch_action_model.request.params example_return_value 'response'if batch_action_model.resource example_return_value xform_name batch_action_model.resource.type example_resource_name xform_name resource_name if service_model.service_name resource_name example_resource_name resource_nameexample_prefix '%s %s.%s.%s' % example_return_value example_resource_name collection_model.name batch_action_model.name document_model_driven_resource_method section section method_name batch_action_model.name operation_model operation_model event_emitter event_emitter method_description operation_model.documentation example_prefix example_prefix exclude_input ignore_params resource_action_model batch_action_model include_signature include_signature
def diff_jid jid config 'root' pre_snapshot post_snapshot _get_jid_snapshots jid config config return diff config num_pre pre_snapshot num_post post_snapshot
def _split_symbol_mappings df mappings df[list mapping_columns ]ambigious {}for symbol in mappings.symbol.unique persymbol mappings[ mappings.symbol symbol ]intersections list intersecting_ranges map from_tuple zip persymbol.start_date persymbol.end_date if intersections ambigious[symbol] intersections persymbol[['start_date' 'end_date']].astype 'datetime64[ns]' if ambigious raise ValueError 'Ambiguousownershipfor%dsymbol%s multipleassetsheldthefollowingsymbols \n%s' % len ambigious '' if len ambigious 1 else 's' '\n'.join '%s \nintersections %s\n%s' % symbol tuple map _format_range intersections '\n'.join str df .splitlines for symbol intersections df in sorted ambigious.items key first return df.groupby level 0 .apply _check_asset_group df[list mapping_columns ]
def test_ros_fit_sample ros RandomOverSampler random_state RND_SEED X_resampled y_resampled ros.fit_sample X Y X_gt np.array [[0.04352327 -0.20515826 ] [0.20792588 1.49407907] [0.22950086 0.33367433] [0.15490546 0.3130677] [0.09125309 -0.85409574 ] [0.12372842 0.6536186] [0.094035 -2.55298982 ] [0.92923648 0.76103773] [0.47104475 0.44386323] [0.13347175 0.12167502] [0.92923648 0.76103773] [0.47104475 0.44386323] [0.92923648 0.76103773] [0.47104475 0.44386323]] y_gt np.array [1 1 1 1 1 1 1 0 0 0 0 0 0 0] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def fullmatch pattern string flags 0 grouped_pattern re.compile '^ ? %s $' % pattern.pattern pattern.flags m grouped_pattern.match string if m and m.end < len string m Nonereturn m
def lookupNamingAuthorityPointer name timeout None return getResolver .lookupNamingAuthorityPointer name timeout
def build_auxiliary_edge_connectivity G if G.is_directed H nx.DiGraph H.add_nodes_from G.nodes H.add_edges_from G.edges capacity 1 return Helse H nx.DiGraph H.add_nodes_from G.nodes for source target in G.edges H.add_edges_from [ source target target source ] capacity 1 return H
def test_factory support_as_data True if support_as_data return DataModelTester_SupportAsDataMixinelse return DataModelTester_NotSupportAsDataMixin
def internalerror context.status '500InternalServerError'context.headers [ 'Content-Type' 'text/html' ]context.output 'internalservererror'
def GetFlavor params flavors {'cygwin' 'win' 'win32' 'win' 'darwin' 'mac'}if 'flavor' in params return params['flavor']if sys.platform in flavors return flavors[sys.platform]if sys.platform.startswith 'sunos' return 'solaris'if sys.platform.startswith 'freebsd' return 'freebsd'if sys.platform.startswith 'openbsd' return 'openbsd'if sys.platform.startswith 'netbsd' return 'netbsd'if sys.platform.startswith 'aix' return 'aix'return 'linux'
def looks_like_a_tool path invalid_names [] enable_beta_formats False looks Falseif os.path.basename path in invalid_names return Falseif looks_like_a_tool_xml path looks Trueif not looks and enable_beta_formats for tool_checker in BETA_TOOL_CHECKERS.values if tool_checker path looks Truebreakreturn looks
def _find_vpcs vpc_id None vpc_name None cidr None tags None region None key None keyid None profile None if all vpc_id vpc_name raise SaltInvocationError 'Onlyoneofvpc_nameorvpc_idmaybeprovided.' if not any vpc_id vpc_name tags cidr raise SaltInvocationError 'Atleastoneofthefollowingmustbeprovided vpc_id vpc_name cidrortags.' conn _get_conn region region key key keyid keyid profile profile filter_parameters {'filters' {}}if vpc_id filter_parameters['vpc_ids'] [vpc_id]if cidr filter_parameters['filters']['cidr'] cidrif vpc_name filter_parameters['filters']['tag Name'] vpc_nameif tags for tag_name tag_value in six.iteritems tags filter_parameters['filters']['tag {0}'.format tag_name ] tag_valuevpcs conn.get_all_vpcs **filter_parameters log.debug 'Thefilterscriteria{0}matchedthefollowingVPCs {1}'.format filter_parameters vpcs if vpcs return [vpc.id for vpc in vpcs]else return []
def load_config filename None text None test False commit True debug False replace False fun 'load_merge_candidate'if replace fun 'load_replace_candidate'_loaded __proxy__['napalm.call'] fun **{'filename' filename 'config' text} loaded_config Noneif debug if filename loaded_config open filename .read else loaded_config textreturn _config_logic _loaded test test commit_config commit loaded_config loaded_config
def frame_msg body header None raw_body False framed_msg {}if header is None header {}framed_msg['head'] headerframed_msg['body'] bodyreturn msgpack.dumps framed_msg
def footnotes document footnotes domhelpers.findElementsWithAttribute document 'class' 'footnote' if not footnotes returnfootnoteElement dom.Element 'ol' id 1for footnote in footnotes href dom.parseString '<ahref "#footnote-% id d"><super>% id d</super></a>' % vars .documentElementtext ''.join domhelpers.getNodeText footnote .split href.setAttribute 'title' text target dom.Element 'a' target.setAttribute 'name' 'footnote-%d' % id target.childNodes [footnote]footnoteContent dom.Element 'li' footnoteContent.childNodes [target]footnoteElement.childNodes.append footnoteContent footnote.parentNode.replaceChild href footnote id + 1body domhelpers.findNodesNamed document 'body' [0]header dom.parseString '<h2>Footnotes</h2>' .documentElementbody.childNodes.append header body.childNodes.append footnoteElement
def _upgrade_from_setuptools python_cmd use_sudo _easy_install ['-U' 'setuptools'] python_cmd use_sudo
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _get_address_binary address if is_valid_ipv4_address address return ''.join [_get_binary int octet 8 for octet in address.split '.' ] elif is_valid_ipv6_address address address expand_ipv6_address address return ''.join [_get_binary int grouping 16 16 for grouping in address.split ' ' ] else raise ValueError "'%s'isneitheranIPv4orIPv6address" % address
def _check_cron user path mask cmd arg_mask mask.split ' ' arg_mask.sort lst __salt__['incron.list_tab'] user for cron in lst['crons'] if path cron['path'] and cron['cmd'] cmd cron_mask cron['mask'].split ' ' cron_mask.sort if cron_mask arg_mask return 'present'if any [ x in cron_mask for x in arg_mask] return 'update'return 'absent'
def api_get_manageable_volumes *args **kwargs vols [{'reference' {'source-name' 'volume-%s' % fake.VOLUME_ID } 'size' 4 'extra_info' 'qos_setting high' 'safe_to_manage' False 'cinder_id' fake.VOLUME_ID 'reason_not_safe' 'volumeinuse'} {'reference' {'source-name' 'myvol'} 'size' 5 'extra_info' 'qos_setting low' 'safe_to_manage' True 'cinder_id' None 'reason_not_safe' None}]return vols
def custom_verify_access_cookie zmirror_verify_cookie flask_request return verify_ip_hash_cookie zmirror_verify_cookie
def printExc msg '' indent 4 prefix '|' exc getExc indent prefix + '' skip 2 print '[%s]%s\n' % time.strftime '%H %M %S' msg print '' * indent + prefix + ' ' * 30 + '>>' print exc print '' * indent + prefix + ' ' * 30 + '<<'
@utils.arg 'monitor_id' metavar '<monitor-id>' help 'IDofthemonitortosnapshot' @utils.arg '--force' metavar '<True|False>' help "Optionalflagtoindicatewhethertosnapshotamonitorevenifit'sattachedtoaninstance. Default False " default False @utils.arg '--display-name' metavar '<display-name>' default None help 'Optionalsnapshotname. Default None ' @utils.arg '--display_name' help argparse.SUPPRESS @utils.arg '--display-description' metavar '<display-description>' default None help 'Optionalsnapshotdescription. Default None ' @utils.arg '--display_description' help argparse.SUPPRESS @utils.service_type 'monitor' def do_snapshot_create cs args snapshot cs.monitor_snapshots.create args.monitor_id args.force args.display_name args.display_description _print_monitor_snapshot snapshot
def get_field java_object field_name command proto.FIELD_COMMAND_NAME + proto.FIELD_GET_SUBCOMMAND_NAME + java_object._target_id + u'\n' + field_name + u'\n' + proto.END_COMMAND_PART answer java_object._gateway_client.send_command command if answer proto.NO_MEMBER_COMMAND or is_error answer [0] raise Py4JError u'nofield{0}inobject{1}'.format field_name java_object._target_id else return get_return_value answer java_object._gateway_client java_object._target_id field_name
def validate_color s if s.lower 'none' return 'None'if is_color_like s return sstmp '#' + s if is_color_like stmp return stmpcolorarg smsg ''if s.find ' ' > 0 stmp ''.join [c for c in s if c.isdigit or c '.' or c ' ' ] vals stmp.split ' ' if len vals ! 3 msg '\nColortuplesmustbelength3'else try colorarg [float val for val in vals]except ValueError msg '\nCouldnotconvertallentriestofloats'if not msg and is_color_like colorarg return colorargraise ValueError '%sdoesnotlooklikeacolorarg%s' % s msg
def dict_error_formatting errors index None formatted_error_list []top_level_error_keys ['links' 'status' 'code' 'detail' 'source' 'meta']resource_object_identifiers ['type' 'id']if index is None index ''else index str index + '/' for error_key error_description in errors.iteritems if isinstance error_description basestring error_description [error_description]if error_key in top_level_error_keys formatted_error_list.extend {error_key description} for description in error_description elif error_key in resource_object_identifiers formatted_error_list.extend [{'source' {'pointer' '/data/{}'.format index + error_key } 'detail' reason} for reason in error_description] elif error_key 'non_field_errors' formatted_error_list.extend [{'detail' description for description in error_description}] else formatted_error_list.extend [{'source' {'pointer' '/data/{}attributes/'.format index + error_key } 'detail' reason} for reason in error_description] return formatted_error_list
def resnet_v2_101 inputs num_classes None is_training True global_pool True output_stride None reuse None scope 'resnet_v2_101' blocks [resnet_utils.Block 'block1' bottleneck [ 256 64 1 ] * 2 + [ 256 64 2 ] resnet_utils.Block 'block2' bottleneck [ 512 128 1 ] * 3 + [ 512 128 2 ] resnet_utils.Block 'block3' bottleneck [ 1024 256 1 ] * 22 + [ 1024 256 2 ] resnet_utils.Block 'block4' bottleneck [ 2048 512 1 ] * 3 ]return resnet_v2 inputs blocks num_classes is_training is_training global_pool global_pool output_stride output_stride include_root_block True reuse reuse scope scope
def deploy_application war_file webapp_path None if not webapp_path webapp_path os.path.join DEFAULT_INSTALLATION_PATH 'webapps' put local_path war_file remote_path os.path.join webapp_path war_file use_sudo True
def patch_vary_headers response newheaders if response.has_header 'Vary' vary_headers cc_delim_re.split response['Vary'] else vary_headers []existing_headers set [header.lower for header in vary_headers] additional_headers [newheader for newheader in newheaders if newheader.lower not in existing_headers ]response['Vary'] ' '.join vary_headers + additional_headers
def get_vsphere_location context image_id if image_id metadata IMAGE_API.get context image_id include_locations True locations metadata.get 'locations' if locations for loc in locations loc_url loc.get 'url' if loc_url and loc_url.startswith 'vsphere //' return loc_urlreturn None
def test_close_connections print 'Runningtest_close_connections' s3 boto.connect_s3 for b in s3.get_all_buckets if b.name.startswith 'test-' for key in b.get_all_keys key.delete b.delete bucket s3.create_bucket 'test-%d' % int time.time names [str uuid.uuid4 for _ in range 30 ]threads [spawn put_object bucket name for name in names]for t in threads t.join threads [spawn get_object bucket name for name in names]for t in threads t.join
def list_env saltenv 'base' ret {}if saltenv not in __opts__['file_roots'] return retfor f_root in __opts__['file_roots'][saltenv] ret[f_root] {}for root dirs files in os.walk f_root sub ret[f_root]if root ! f_root sroot rootabove []while not os.path.samefile sroot f_root base os.path.basename sroot if base above.insert 0 base sroot os.path.dirname sroot for aroot in above sub sub[aroot]for dir_ in dirs sub[dir_] {}for fn_ in files sub[fn_] 'f'return ret
def read_reflog f for l in f yield parse_reflog_line l
def same_origin url1 url2 p1 p2 urlparse url1 urlparse url2 try return p1.scheme p1.hostname p1.port p2.scheme p2.hostname p2.port except ValueError return False
def b64d s return base64.b64decode s
def file_upload_filename_case_view request file request.FILES[u'file_field']obj FileModel obj.testfile.save file.name file return HttpResponse u'%d' % obj.pk
def compile_function name code globs co compile code.rstrip '<string>' 'single' ns {}eval co globs ns return ns[name]
def line2d_seg_dist p1 p2 p0 x21 p2[0] - p1[0] y21 p2[1] - p1[1] x01 np.asarray p0[0] - p1[0] y01 np.asarray p0[1] - p1[1] u x01 * x21 + y01 * y21 / float abs x21 ** 2 + y21 ** 2 u np.clip u 0 1 d np.sqrt x01 - u * x21 ** 2 + y01 - u * y21 ** 2 return d
@_noconds_ True def _fourier_transform f x k a b name simplify True from sympy import exp IF integrate a * f * exp b * I * x * k x - oo oo if not F.has Integral return _simplify F simplify True if not F.is_Piecewise raise IntegralTransformError name f 'couldnotcomputeintegral' F cond F.args[0]if F.has Integral raise IntegralTransformError name f 'integralinunexpectedform' return _simplify F simplify cond
def convert_to_bcd decimal place bcd 0 0 while decimal > 0 nibble decimal % 10 bcd + nibble << place decimal / 10place + 4return bcd
def from_any size fraction_ref None if cbook.is_numlike size return Fixed size elif cbook.is_string_like size if size[ -1 ] u'%' return Fraction float size[ -1 ] / 100.0 fraction_ref raise ValueError u'Unknownformat'
def attribute_assortativity_coefficient G attribute nodes None M attribute_mixing_matrix G attribute nodes return attribute_ac M
def unparse_multistring values if not isinstance values multistring or isinstance values list return valuestry values_list list values.strings has_plural_placeholder getattr values 'plural' False except AttributeError values_list valueshas_plural_placeholder Falseif list_empty values_list return ''if len values_list 1 and has_plural_placeholder values_list.append PLURAL_PLACEHOLDER return SEPARATOR.join values_list
def query_yes_no question default 'yes' valid {'yes' True 'y' True 'ye' True 'no' False 'n' False}if default is None prompt '[y/n]'elif default 'yes' prompt '[Y/n]'elif default 'no' prompt '[y/N]'else raise ValueError "invaliddefaultanswer '%s'" % default while True sys.stdout.write question + prompt choice raw_input .lower if default is not None and choice '' return valid[default]elif choice in valid return valid[choice]else sys.stdout.write "Pleaserespondwith'yes'or'no' or'y'or'n' .\n"
def kernel d1 d2 r None weights None diff d1 - d2 if weights is None or r[0] 0 return np.all r * diff 0 else return weights[diff] * np.all r[1 ] * diff[1 ] 0
def expected_text *args text '<table>'for group in args text + "<tr><td>{}</td><tdstyle 'color {}'>{}</td><tdstyle 'padding-left 2ex'>{}</td></tr>".format *group return text + '</table>'
def _get_bus_number_for_scsi_controller devices taken [dev.busNumber for dev in devices if _is_scsi_controller dev ]for i in range constants.SCSI_MAX_CONTROLLER_NUMBER if i not in taken return imsg _ 'Only%dSCSIcontrollersareallowedtobecreatedonthisinstance.' % constants.SCSI_MAX_CONTROLLER_NUMBER raise vexc.VMwareDriverException msg
def minkowski u v p u _validate_vector u v _validate_vector v if p < 1 raise ValueError 'pmustbeatleast1' dist norm u - v ord p return dist
def _git_diff_name_status left right diff_filter '' git_cmd ['git' 'diff' '--name-status']if diff_filter git_cmd.append '--diff-filter {}'.format diff_filter git_cmd.extend [left right] out err _start_subprocess_for_result git_cmd if not err file_list []for line in out.splitlines file_list.append FileDiff line[0] line[ line.rfind ' DCTB ' + 1 ] return file_listelse raise ValueError err
@docfillerdef mat_reader_factory file_name appendmat True **kwargs byte_stream _open_file file_name appendmat mjv mnv get_matfile_version byte_stream if mjv 0 return MatFile4Reader byte_stream **kwargs elif mjv 1 return MatFile5Reader byte_stream **kwargs elif mjv 2 raise NotImplementedError 'PleaseuseHDFreaderformatlabv7.3files' else raise TypeError 'Didnotrecognizeversion%s' % mjv
def unique_everseen iterable key None seen set seen_add seen.addif key is None for element in ifilterfalse seen.__contains__ iterable seen_add element yield element else for element in iterable k key element if k not in seen seen_add k yield element
def samples_from_file file_in start 0 stop -1 if not os.path.isfile file_in raise IOError 'nosuchfile`{0}`'.format file_in rate table table_from_file file_in start start stop stop return rate np.array table.getTable
def contrast_all_one nm contr np.column_stack np.ones nm - 1 - np.eye nm - 1 return contr
def get_horizontal_shift_value label return _check_range_and_return 'horizontalshift' label -5 5
def grey_closing input size None footprint None structure None output None mode 'reflect' cval 0.0 origin 0 tmp grey_dilation input size footprint structure None mode cval origin return grey_erosion tmp size footprint structure output mode cval origin
@staff_member_requireddef cache_stats request template_name u'admin/cache_stats.html' cache_stats get_cache_stats cache_info settings.CACHES[DEFAULT_FORWARD_CACHE_ALIAS]return render_to_response template_name RequestContext request {u'cache_hosts' cache_stats u'cache_backend' cache_info[u'BACKEND'] u'title' _ u'ServerCache' u'root_path' settings.SITE_ROOT + u'admin/db/' }
def _rfc3339_to_datetime dt_str return datetime.datetime.strptime dt_str _RFC3339_MICROS .replace tzinfo UTC
def unquote_to_bytes string if not string string.splitreturn ''if isinstance string str string string.encode 'utf-8' bits string.split '%' if len bits 1 return stringres [bits[0]]append res.appendglobal _hextobyteif _hextobyte is None _hextobyte { a + b .encode bytes [int a + b 16 ] for a in _hexdig for b in _hexdig}for item in bits[1 ] try append _hextobyte[item[ 2]] append item[2 ] except KeyError append '%' append item return ''.join res
def validate_title value if value is None or not value.strip raise ValidationValueError 'Titlecannotbeblank.' value sanitize.strip_html value if value is None or not value.strip raise ValidationValueError 'Invalidtitle.' if len value > 200 raise ValidationValueError 'Titlecannotexceed200characters.' return True
def search_explorations query limit sort None cursor None return search_services.search query SEARCH_INDEX_EXPLORATIONS cursor limit sort ids_only True
def register_mimetype_handler handler if not issubclass handler MimetypeHandler raise TypeError u'OnlyMimetypeHandlersubclassescanberegistered' _registered_mimetype_handlers.append handler
def getstatementrange_old lineno source assertion False from codeop import compile_commandfor start in range lineno -1 -1 if assertion line source.lines[start]if 'super' in line and 'self' in line and '__init__' in line raise IndexError 'likelyasubclass' if 'assert' not in line and 'raise' not in line continuetrylines source.lines[start lineno + 1 ]trylines.insert 0 'defxxx ' trysource '\n'.join trylines try compile_command trysource except SyntaxError OverflowError ValueError continuefor end in range lineno + 1 len source + 1 trysource source[start end]if trysource.isparseable return start end raise SyntaxError 'novalidsourcerangearoundline%d' % lineno
@context.quietfunc@with_devicedef logcat stream False if stream return process ['logcat'] else return process ['logcat' '-d'] .recvall
def sql_demo print print u"UsingSQLtoextractrowsfrom'city.db'RDB." for row in sql_query u'corpora/city_database/city.db' u'SELECT*FROMcity_table' print row
def get_unmounted_partition_list root_part job None min_blocks 0 filter_func None exclude_swap True open_func open partitions get_partition_list job job min_blocks min_blocks filter_func filter_func exclude_swap exclude_swap open_func open_func unmounted []for part in partitions if part.device ! partname_to_device root_part and not part.get_mountpoint open_func open_func unmounted.append part return unmounted
def get_slug list_name raw_input light_magenta 'Givemethelist\'sname "@owner/list_name" ' rl True try owner slug list_name.split '/' if slug.startswith '@' slug slug[1 ]return owner slug except printNicely light_magenta 'Listnameshouldfollow"@owner/list_name"format.' raise Exception 'Wronglistname'
@transaction.non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def calculate_grades_csv request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id try lms.djangoapps.instructor_task.api.submit_calculate_grades_csv request course_key success_status _ 'Thegradereportisbeingcreated.Toviewthestatusofthereport seePendingTasksbelow.' return JsonResponse {'status' success_status} except AlreadyRunningError already_running_status _ 'Thegradereportiscurrentlybeingcreated.Toviewthestatusofthereport seePendingTasksbelow.Youwillbeabletodownloadthereportwhenitiscomplete.' return JsonResponse {'status' already_running_status}
def cleanRequestURL url url.transport Noneurl.maddr Noneurl.ttl Noneurl.headers {}
def test_cc_fit_single_class ratio 'auto'cc ClusterCentroids ratio ratio random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning cc.fit X y_single_class
def _make_compatible_taxa_summaries ts1 ts2 sample_id_map None if sample_id_map for samp_id in ts1[0] + ts2[0] if samp_id not in sample_id_map raise ValueError "TheoriginalsampleID'%s'doesnothaveamappinginthesampleIDmap.AllsampleIDsmusthaveamapping." % samp_id new_samp_ids1 new_samp_ids2 new_data1 new_data2 [] [] [] [] for samp_idx samp_id in enumerate ts1[0] matching_samp_id Noneif sample_id_map new_samp_id sample_id_map[samp_id]for orig_samp_id in sample_id_map if orig_samp_id ! samp_id and sample_id_map[orig_samp_id] new_samp_id matching_samp_id orig_samp_idelif samp_id in ts2[0] matching_samp_id samp_idif matching_samp_id new_samp_ids1.append samp_id new_samp_ids2.append matching_samp_id new_data1.append ts1[2].T[samp_idx] new_data2.append ts2[2].T[ts2[0].index matching_samp_id ] if len new_samp_ids1 0 raise ValueError 'NosampleIDsmatchedbetweenthetaxasummaries.Thetaxasummariesareincompatible.' return new_samp_ids1 ts1[1] array new_data1 .T new_samp_ids2 ts2[1] array new_data2 .T
def setSliceElementZ decimalPlacesCarried sliceElement sliceElementIndex z roundedZ euclidean.getRoundedToPlacesString decimalPlacesCarried z idValue 'z %s' % roundedZ sliceElement.attributeDictionary['id'] idValuetextElement sliceElement.getFirstChildWithClassName 'text' textElement.text 'Layer%s %s' % sliceElementIndex idValue
def _set_contour_locator vmin vmax contours locator Noneif isinstance contours int from matplotlib import tickerlocator ticker.MaxNLocator nbins contours + 1 contours locator.tick_values vmin vmax return locator contours
def get_instance_type_access_by_flavor_id flavorid ctxt None if ctxt is None ctxt context.get_admin_context return db.instance_type_access_get_by_flavor_id ctxt flavorid
def getcfs key filename filter None try t stat filename .st_mtimeexcept OSError return filter if callable filter else '' cfs_lock.acquire item cfs.get key None cfs_lock.release if item and item[0] t return item[1]if not callable filter data read_file filename else data filter cfs_lock.acquire cfs[key] t data cfs_lock.release return data
def search_by_name service name **kwargs if 'search' in inspect.getargspec service.list [0] res service.list search 'name {name}'.format name name else res [e for e in service.list if e.name name ]if kwargs res [e for e in service.list if len [k for k v in kwargs.items if getattr e k None v ] len kwargs ]res res or [None] return res[0]
def blank_lines logical_line blank_lines indent_level line_number previous_logical previous_indent_level if line_number < 3 and not previous_logical returnif previous_logical.startswith '@' if blank_lines yield 0 'E304blanklinesfoundafterfunctiondecorator' elif blank_lines > 2 or indent_level and blank_lines 2 yield 0 'E303toomanyblanklines %d ' % blank_lines elif logical_line.startswith 'def' 'class' '@' if indent_level if not blank_lines or previous_indent_level < indent_level or DOCSTRING_REGEX.match previous_logical yield 0 'E301expected1blankline found0' elif blank_lines ! 2 yield 0 'E302expected2blanklines found%d' % blank_lines
def _deferGenerator g deferred result Nonewaiting [True None]while 1 try result g.next except StopIteration deferred.callback result return deferredexcept deferred.errback return deferredif isinstance result Deferred return fail TypeError 'YieldwaitForDeferred d notd!' if isinstance result waitForDeferred def gotResult r result result result.result rif waiting[0] waiting[0] Falsewaiting[1] relse _deferGenerator g deferred result.d.addBoth gotResult if waiting[0] waiting[0] Falsereturn deferredwaiting[0] Truewaiting[1] Noneresult None
def failure_code sub return '{\n% failure_var s % id s;\nif !PyErr_Occurred {\nPyErr_SetString PyExc_RuntimeError \n"UnexpectederrorinanOp\'sCcode."\n"NoPythonexceptionwasset." ;\n}\ngoto__label_% id i;}' % sub
def create_private_key path None text False bits 2048 passphrase None cipher 'aes_128_cbc' verbose True if not path and not text raise salt.exceptions.SaltInvocationError 'Eitherpathortextmustbespecified.' if path and text raise salt.exceptions.SaltInvocationError 'Eitherpathortextmustbespecified notboth.' if verbose _callback_func M2Crypto.RSA.keygen_callbackelse _callback_func _keygen_callbackrsa M2Crypto.RSA.gen_key bits M2Crypto.m2.RSA_F4 _callback_func bio M2Crypto.BIO.MemoryBuffer if passphrase is None cipher Nonersa.save_key_bio bio cipher cipher callback _passphrase_callback passphrase if path return write_pem text bio.read_all path path pem_type 'RSAPRIVATEKEY' else return bio.read_all
def compute_node_get context compute_id return IMPL.compute_node_get context compute_id
def test_seed_diff skip_if_no_scipy rng np.random.RandomState [1 2 3] seed rng.randint 2147462579 - 1 dim 3mu rng.randn dim rank dimX rng.randn rank dim cov np.dot X.T X mnd1 MND sigma cov mu mu seed seed num_samples 5rd1 mnd1.random_design_matrix num_samples rd1 function [] rd1 mnd2 MND sigma cov mu mu seed seed + 1 rd2 mnd2.random_design_matrix num_samples rd2 function [] rd2 assert np.any rd1 ! rd2
def getTempMarkdownPreviewPath view settings sublime.load_settings 'MarkdownPreview.sublime-settings' tmp_filename '%s.html' % view.id tmp_dir tempfile.gettempdir if settings.get 'path_tempfile' if os.path.isabs settings.get 'path_tempfile' tmp_dir settings.get 'path_tempfile' else tmp_dir os.path.join os.path.dirname view.file_name settings.get 'path_tempfile' if not os.path.isdir tmp_dir os.makedirs tmp_dir tmp_fullpath os.path.join tmp_dir tmp_filename return tmp_fullpath
def timestampUUID60 value if not isinstance value float int long raise TypeError 'anintegerorfloatisrequired' if value < 0 raise ValueError 'valuehavetobeapositiveornulinteger' try return UUID60_TIMESTAMP_T0 + timedelta microseconds value / 10 except OverflowError raise ValueError _ 'timestampUUID60 overflow value %s ' % value
def patch_vary_headers response newheaders if response.has_header 'Vary' vary_headers cc_delim_re.split response['Vary'] else vary_headers []existing_headers set [header.lower for header in vary_headers] additional_headers [newheader for newheader in newheaders if newheader.lower not in existing_headers ]response['Vary'] ' '.join vary_headers + additional_headers
def groupby key seq if not callable key key getter key d collections.defaultdict lambda [].append for item in seq d[key item ] item rv {}for k v in iteritems d rv[k] v.__self__return rv
def random_game nums_actions random_state None N len nums_actions if N 0 raise ValueError 'nums_actionsmustbenon-empty' random_state check_random_state random_state players [Player random_state.random_sample nums_actions[i ] + nums_actions[ i] for i in range N ]g NormalFormGame players return g
def vlan_in_use segmentation_id namespace None ip_wrapper IPWrapper namespace namespace interfaces ip_wrapper.netns.execute ['ip' '-d' 'link' 'list'] check_exit_code True return '802.1Qid%s' % segmentation_id in interfaces
def is_namespace_property_mutable context namespace_property if context.is_admin return Trueif context.owner is None return Falsereturn namespace_property.namespace.owner context.owner
def get_global_options return _global_options
def check_installed name path try return _read_link name path except OSError return False
def _mbcs_to_unicode instr if instr is None or isinstance instr six.text_type return instrelse return six.text_type instr u'mbcs'
def _control_segment_path name server_dir os.path.dirname os.path.abspath __file__ return os.path.join server_dir 'control_segments' name
def _operation_complete result return result
def freeze G G.add_node frozenG.add_nodes_from frozenG.remove_node frozenG.remove_nodes_from frozenG.add_edge frozenG.add_edges_from frozenG.remove_edge frozenG.remove_edges_from frozenG.clear frozenG.frozen Truereturn G
def setLoggerClass loggingClass assert issubclass loggingClass ILogger 'loggingClassmustsubclassILogger'global _LoggerClass_LoggerClass loggingClass
def _get_task_statuses task_ids response client.describe_tasks tasks task_ids if response['failures'] ! [] raise Exception 'Thereweresomefailures \n{0}'.format response['failures'] status_code response['ResponseMetadata']['HTTPStatusCode']if status_code ! 200 msg 'Taskstatusrequestreceivedstatuscode{0} \n{1}'raise Exception msg.format status_code response return [t['lastStatus'] for t in response['tasks']]
def fnpickle object fileorname usecPickle True protocol None append False if usecPickle and six.PY2 import cPickle as pickleelse import pickleif protocol is None protocol pickle.HIGHEST_PROTOCOLif isinstance fileorname six.string_types f open fileorname u'ab' if append else u'wb' close Trueelse f fileornameclose Falsetry pickle.dump object f protocol protocol finally if close f.close
def _parse_check rule if rule '!' return FalseCheck elif rule '@' return TrueCheck try kind match rule.split ' ' 1 except Exception LOG.exception _ 'Failedtounderstandrule%s' % rule return FalseCheck if kind in _checks return _checks[kind] kind match elif None in _checks return _checks[None] kind match else LOG.error _ 'Nohandlerformatchesofkind%s' % kind return FalseCheck
def iplayer_from_raw raw linktype 1 if linktype 1 try pkt dpkt.ethernet.Ethernet raw return pkt.dataexcept dpkt.NeedData passelif linktype 101 return dpkt.ip.IP raw else raise CuckooProcessingError 'unknownPCAPlinktype'
@core_helper@maintain.deprecated 'h.subnav_named_routeisdeprecatedpleaseuseh.nav_link\nNOTE youwillneedtopasstheroute_nameasanamedparameter' def subnav_named_route text named_route **kwargs return nav_link text named_route named_route **kwargs
@require_role 'admin' def asset_update request asset_id request.GET.get 'id' '' asset get_object Asset id asset_id name request.user.usernameif not asset return HttpResponseRedirect reverse 'asset_detail' + '?id %s' % asset_id else asset_ansible_update [asset] name return HttpResponseRedirect reverse 'asset_detail' + '?id %s' % asset_id
def ode_1st_homogeneous_coeff_subs_dep_div_indep eq func order match x func.args[0]f func.funcu Dummy 'u' u1 Dummy 'u1' r matchC1 get_numbered_constants eq num 1 xarg match.get 'xarg' 0 yarg match.get 'yarg' 0 int Integral - r[r['e']] / r[r['d']] + u1 * r[r['e']] .subs {x 1 r['y'] u1} u1 None f x / x sol logcombine Eq log x int + log C1 force True sol sol.subs f x u .subs u u - yarg x x - xarg u f x return sol
def setup_livestreamer global livestreamerlivestreamer Livestreamer
def skip_unless_lms func return skipUnless settings.ROOT_URLCONF 'lms.urls' 'TestonlyvalidinLMS' func
def server_handled_successfully status_int return is_success status_int or is_redirection status_int or status_int HTTP_NOT_FOUND or status_int HTTP_PRECONDITION_FAILED or status_int HTTP_REQUESTED_RANGE_NOT_SATISFIABLE
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
def grain_funcs opts proxy None return LazyLoader _module_dirs opts 'grains' 'grain' ext_type_dirs 'grains_dirs' opts tag 'grains'
def _diff_cache_subnet_group current desired modifiable {'CacheSubnetGroupDescription' 'CacheSubnetGroupDescription' 'SubnetIds' 'SubnetIds'}need_update {}for m o in modifiable.items if m in desired if not o need_update[m] desired[m]elif m in current if current[m] ! desired[m] need_update[m] desired[m]return need_update
def CDLADVANCEBLOCK barDs count return call_talib_with_ohlc barDs count talib.CDLADVANCEBLOCK
def usages_add_import_modules evaluator definitions new set for d in definitions imp_or_stmt d.get_definition if isinstance imp_or_stmt tree.Import s imports.ImportWrapper evaluator d new | set s.follow is_goto True return set definitions | new
def GetLabel plist try return plist['Label']except KeyError return 'False'
def _get_borrowing_getitem context seqty retty seqty.dtypegetitem_impl context.get_function 'getitem' signature retty seqty types.intp def wrap builder args ret getitem_impl builder args if context.enable_nrt context.nrt.decref builder retty ret return retreturn wrap
def sign_string_v2 string_to_sign signature base64.encodestring hmac.new Config.Config .secret_key deunicodise string_to_sign sha1 .digest .strip return signature
def upload_dev_pdf user 'pandas' if os.system 'cdbuild/latex;scppandas.pdf{0}@pandas.pydata.org /usr/share/nginx/pandas/pandas-docs/dev/'.format user raise SystemExit 'PDFuploadtoPydataDevfailed'
def get_group_type_by_name context name if name is None msg _ 'namecannotbeNone' raise exception.InvalidGroupType reason msg return db.group_type_get_by_name context name
def load_item_types item_types {}for meta_source in META_SOURCES.values item_types.update meta_source.item_types return item_types
def group_membership s3db.hrm_configure_pr_group_membership table db.pr_group_membershipgtable db.pr_grouphtable s3db.hrm_human_resources3.filter gtable.system False & gtable.group_type 3 & htable.type 1 & htable.person_id table.person_id def prep r if r.method in 'create' 'create.popup' 'update' 'update.popup' person_id get_vars.get '~.person_id' None if person_id field table.person_idfield.default person_idfield.readable field.writable Falsereturn Trues3.prep prepoutput s3_rest_controller 'pr' 'group_membership' csv_stylesheet 'hrm' 'group_membership.xsl' csv_template 'group_membership' return output
def test_hermite_cardinal Chart datas chart Chart interpolate 'hermite' interpolation_parameters {'type' 'cardinal' 'c' 0.75} chart make_data chart datas assert chart.render
def invoke_cmd stdout stderr environ prefix cmd cmd_args error_msg error_status func_name prefix + cmd if func_name in globals return globals [func_name] stdout stderr environ *cmd_args else stderr.write error_msg return -1
def _rec_list_terms g v monom d terms dmp_degree g v [] if not v for i c in enumerate g if not c continueterms.append monom + d - i c else w v - 1 for i c in enumerate g terms.extend _rec_list_terms c w monom + d - i return terms
def update_quota tenant_id subnet None router None network None floatingip None port None security_group None security_group_rule None profile None conn _auth profile return conn.update_quota tenant_id subnet router network floatingip port security_group security_group_rule
def _get_profile_image_filename name size file_extension PROFILE_IMAGE_FILE_EXTENSION return '{name}_{size}.{file_extension}'.format name name size size file_extension file_extension
def viewdefaults wrapped def wrapper self *arg **kw defaults {}if arg view arg[0]else view kw.get 'view' view self.maybe_dotted view if inspect.isclass view defaults getattr view '__view_defaults__' {} .copy if '_backframes' not in kw kw['_backframes'] 1defaults.update kw return wrapped self *arg **defaults return functools.wraps wrapped wrapper
def is_py2exe_or_cx_Freeze return osp.isfile osp.join get_module_path 'spyder' osp.pardir
def eglQueryString display name out _lib.eglQueryString display name if not out raise RuntimeError 'Couldnotquery%s' % name return out
def getPage url contextFactory None *args **kwargs def _clientfactory *args **kwargs timeout kwargs.pop 'timeout' 0 f client.ScrapyHTTPClientFactory Request *args **kwargs timeout timeout f.deferred.addCallback lambda r r.body return ffrom twisted.web.client import _makeGetterFactoryreturn _makeGetterFactory url _clientfactory contextFactory contextFactory *args **kwargs .deferred
def set_var_value hass entity_id value data {ATTR_ENTITY_ID entity_id ATTR_VALUE value}hass.services.call DOMAIN SERVICE_SET_VAR_VALUE data
def ValidateStringLength name value max_len if len value > max_len raise datastore_errors.BadValueError 'Property%sis%dbyteslong;itmustbe%dorless.ConsiderTextinstead whichcanstorestringsofanylength.' % name len value max_len
def no_import_translation_in_tests logical_line filename if 'nova/tests/' in filename res import_translation_for_log_or_exception.match logical_line if res yield 0 "N337Don'timporttranslationintests"
def _gs_decorrelation w W j t np.zeros_like w for u in range j t t + np.dot w W[u] * W[u] w - treturn w
def getMinimumByPathsComplex paths minimum complex 999999999.0 999999999.0 for path in paths minimum getMinimum minimum getMinimumByPathComplex path return minimum
def expect_warnings *messages **kw return _expect_warnings sa_exc.SAWarning messages **kw
def export_to_files record_list None record_module None verbose 0 create_init None if frappe.flags.in_import returnif record_list for record in record_list write_document_file frappe.get_doc record[0] record[1] record_module create_init create_init
def service_get_all_by_host context host return IMPL.service_get_all_by_host context host
def computeComprRate meta compr_size if not meta.has 'width' or not meta.has 'height' or not meta.has 'bits_per_pixel' returnif not compr_size returnorig_size meta.get 'width' * meta.get 'height' * meta.get 'bits_per_pixel' meta.compr_rate float orig_size / compr_size
def sp_sum x axis None sparse_grad False return SpSum axis sparse_grad x
@register.simple_tag takes_context True def admin_widget context widget request context.get u'request' siteconfig SiteConfiguration.objects.get site Site.objects.get_current widget_states siteconfig.get u'widget_settings' if widget_states widget.collapsed widget_states.get widget.name u'0' ! u'0' else widget.collapsed Falsereturn widget.render request
def test_unicode_labels_python3 Chart if sys.version_info[0] 2 returnchart Chart chart.add u 'S\xc3\xa9rie1' [{'value' 1 'xlink' 'http //1/' 'label' eval "'{\\}\xc3\x82\xc2\xb0\xc4\xb3\xc3\xa6\xc3\xb0\xc2\xa9&\xc3\x97&<\xe2\x80\x94\xc3\x97\xe2\x82\xac\xc2\xbf_\xe2\x80\xa6\\{_\xe2\x80\xa6'" } {'value' 2 'xlink' {'href' 'http //6.example.com/'} 'label' eval "'\xc3\xa6\xc3\x82\xc2\xb0\xe2\x82\xac\xe2\x89\xa0|\xe2\x82\xac\xc3\xa6\xc3\x82\xc2\xb0\xe2\x82\xac\xc9\x99\xc3\xa6'" } {'value' 3 'label' eval "b'unicode<3'" }] if not chart._dual chart.x_labels eval "['&\xc5\x93' '\xc2\xbf?' '\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0\xe2\x80\xa0' 'unicode<3']" chart.render_pyquery
def stringformat value arg try return '%' + str arg % value except ValueError TypeError return ''
def list_quota_volume name cmd 'volumequota{0}'.format name cmd + 'list'root _gluster_xml cmd if not _gluster_ok root return Noneret {}for limit in _iter root 'limit' path limit.find 'path' .textret[path] _etree_to_dict limit return ret
def DESL K D d1 des expandDesKey K[0 7] d2 des expandDesKey K[7 14] d3 des expandDesKey K[14 16] + '\x00' * 5 return d1.encrypt D + d2.encrypt D + d3.encrypt D
def checkGoogle words factory GoogleCheckerFactory words reactor.connectTCP 'www.google.com' 80 factory return factory.deferred
def pretty_try_use_unicode try symbols []symbols.extend greek_unicode.values symbols + atoms_table.values for s in symbols if s is None returnencoding getattr sys.stdout 'encoding' None if encoding is None returns.encode encoding except UnicodeEncodeError passelse pretty_use_unicode True
def update_session_plot_options **kwargs for key in kwargs if key not in PLOT_OPTIONS raise exceptions.PlotlyError '{}isnotavalidconfigorplotoptionkey'.format key if not isinstance kwargs[key] PLOT_OPTIONS[key] raise exceptions.PlotlyError "{}mustbeoftype'{}'".format key PLOT_OPTIONS[key] if key 'sharing' and not kwargs[key] in SHARING_OPTIONS raise exceptions.PlotlyError "'{0}'mustbeofeither'{1}' '{2}'or'{3}'".format key *SHARING_OPTIONS _session['plot_options'].update kwargs
def layers n m def bump a x 1 / 0.1 + np.random.random y 2 * np.random.random - 0.5 z 10 / 0.1 + np.random.random for i in range m w i / float m - y * z a[i] + x * np.exp - w * w a np.zeros m n for i in range n for j in range 5 bump a[ i] return a
def _partial_regression endog exog_i exog_others res1a OLS endog exog_others .fit res1b OLS exog_i exog_others .fit res1c OLS res1a.resid res1b.resid .fit return res1c res1a res1b
def update_nested_dict main_dict new_dict for name rc_dict in six.iteritems new_dict if name in main_dict main_dict[name].update rc_dict else main_dict[name] rc_dictreturn main_dict
def get_course_cohorts course assignment_type None migrate_cohort_settings course query_set CourseUserGroup.objects.filter course_id course.location.course_key group_type CourseUserGroup.COHORT query_set query_set.filter cohort__assignment_type assignment_type if assignment_type else query_set return list query_set
def _translate_conductor_detail_view context vol image_id None d _translate_conductor_summary_view context vol image_id return d
def get_public_certificates deadline None rpc create_rpc deadline make_get_public_certificates_call rpc rpc.wait return rpc.get_result
def store_media_files document resource original None for field in resource_media_fields document resource if original and field in original if isinstance original[field] list for file_id in original[field] app.media.delete file_id resource else app.media.delete original[field] resource if document[field] if isinstance document[field] list id_lst []for stor_obj in document[field] id_lst.append app.media.put stor_obj filename stor_obj.filename content_type stor_obj.mimetype resource resource document[field] id_lstelse document[field] app.media.put document[field] filename document[field].filename content_type document[field].mimetype resource resource
def _morph_sparse stc subject_from subject_to subjects_dir None maps read_morph_map subject_to subject_from subjects_dir stc_morph stc.copy stc_morph.subject subject_tocnt 0for k hemi in enumerate ['lh' 'rh'] if stc.vertices[k].size > 0 map_hemi maps[k]vertno_k _sparse_argmax_nnz_row map_hemi[stc.vertices[k]] order np.argsort vertno_k n_active_hemi len vertno_k data_hemi stc_morph._data[cnt cnt + n_active_hemi ]stc_morph._data[cnt cnt + n_active_hemi ] data_hemi[order]stc_morph.vertices[k] vertno_k[order]cnt + n_active_hemielse stc_morph.vertices[k] np.array [] int return stc_morph
def test_install_from_local_directory_with_no_setup_py script data result script.pip 'install' data.root expect_error True assert not result.files_created assert "isnotinstallable.File'setup.py'notfound." in result.stderr
def runLengthEncode stream encodedStream ''return -1 'RunLengthEncodenotsupportedyet'
def split_keyword keyword split set re.findall '\\w+' keyword return split
def resolve_possible_pending_xrefs app fromdocname maybe_xrefs result []for node in maybe_xrefs if isinstance node addnodes.pending_xref result.extend resolve_pending_xref app fromdocname node.deepcopy else result.append node return result
def root_create request root get_or_create_root return redirect 'wiki get' path root.path
def libvlc_vlm_get_media_instance_title p_instance psz_name i_instance f _Cfunctions.get 'libvlc_vlm_get_media_instance_title' None or _Cfunction 'libvlc_vlm_get_media_instance_title' 1 1 1 None ctypes.c_int Instance ctypes.c_char_p ctypes.c_int return f p_instance psz_name i_instance
def _merge_entries path tree1 tree2 entries1 _tree_entries path tree1 entries2 _tree_entries path tree2 i1 i2 0len1 len entries1 len2 len entries2 result []while i1 < len1 and i2 < len2 entry1 entries1[i1]entry2 entries2[i2]if entry1.path < entry2.path result.append entry1 _NULL_ENTRY i1 + 1elif entry1.path > entry2.path result.append _NULL_ENTRY entry2 i2 + 1else result.append entry1 entry2 i1 + 1i2 + 1for i in range i1 len1 result.append entries1[i] _NULL_ENTRY for i in range i2 len2 result.append _NULL_ENTRY entries2[i] return result
def unique_file_name base_name extension '' idcount 0if extension and not extension.startswith '.' extension '.%s' % extension fname base_name + extension while os.path.exists fname fname '%s-%d%s' % base_name idcount extension idcount + 1return fname
def UniqueIterator iterator key lambda x x so_far set def no_dups x k key x if k in so_far return Falseelse so_far.add k return Truereturn IteratorFilter iterator no_dups
def _get_frame_class frame import inspectif isinstance frame six.string_types frame_names frame_transform_graph.get_names if frame not in frame_names raise ValueError u'Coordinateframe{0}notinallowedvalues{1}'.format frame sorted frame_names frame_cls frame_transform_graph.lookup_name frame elif inspect.isclass frame and issubclass frame BaseCoordinateFrame frame_cls frameelse raise ValueError u'Coordinateframemustbeaframenameorframeclass' return frame_cls
def _warn_iers ierserr msg u'{0}AssumingUT1-UTC 0forcoordinatetransformations.'warnings.warn msg.format ierserr.args[0] AstropyWarning
def get_details_for_etag options tags noserver read_etag_file options if noserver and not options.noserver options.noserver noserverm re.match ' ? W/ ?"? .* "?$' options.etag if m options.etag m.group 1 etag options.etagif etag in tags print 'Foundetag[%s]forversion%s' % etag tags[etag][0]['version'] return tags[etag]short etag[etag.index '-' ]for t in tags if t.find short ! -1 print 'PartialETagmatch [%s] [%s]forversion%s' % etag t tags[t][0]['version'] return tags[t]return None
def parse_options parser cli_args if not cli_args cli_args.append '-h' options args parser.parse_args cli_args options.__parser parserif not args parser.print_usage sys.exit 0 command_name args.pop 0 command lookup_command parser command_name return options command args
def get_profiler_log_path autodir return os.path.join autodir 'results' 'default' 'debug' 'client.DEBUG'
def dup_transform f p q K if not f return []n len f - 1 h Q [f[0]] [[K.one]] for i in range 0 n Q.append dup_mul Q[ -1 ] q K for c q in zip f[1 ] Q[1 ] h dup_mul h p K q dup_mul_ground q c K h dup_add h q K return h
def create_instance context user_id 'fake' project_id 'fake' params None flavor flavors.get_flavor_by_name 'm1.tiny' net_info model.NetworkInfo [] info_cache objects.InstanceInfoCache network_info net_info inst objects.Instance context context image_ref uuids.fake_image_ref reservation_id 'r-fakeres' user_id user_id project_id project_id instance_type_id flavor.id flavor flavor old_flavor None new_flavor None system_metadata {} ami_launch_index 0 root_gb 0 ephemeral_gb 0 info_cache info_cache if params inst.update params inst.create return inst
def current_route_url request *elements **kw return request.current_route_url *elements **kw
def synopsis filename cache {} mtime os.stat filename .st_mtime lastupdate result cache.get filename None None if lastupdate is None or lastupdate < mtime info inspect.getmoduleinfo filename try file open filename except IOError return Noneif info and 'b' in info[2] try module imp.load_module '__temp__' file filename info[1 ] except return Noneresult module.__doc__.splitlines [0] if module.__doc__ else None del sys.modules['__temp__']else result source_synopsis file file.close cache[filename] mtime result return result
def get_default_ddir user_home os.path.expanduser '~' join exists os.path.join os.path.exists if mswin return join user_home 'Downloads' 'mps' USER_DIRS join user_home '.config' 'user-dirs.dirs' DOWNLOAD_HOME join user_home 'Downloads' if 'XDG_DOWNLOAD_DIR' in os.environ ddir os.environ['XDG_DOWNLOAD_DIR']elif exists USER_DIRS lines open USER_DIRS .readlines defn [x for x in lines if x.startswith 'XDG_DOWNLOAD_DIR' ]if len defn 1 ddir defn[0].split ' ' [1].replace '"' '' ddir ddir.replace '$HOME' user_home .strip else ddir DOWNLOAD_HOME if exists DOWNLOAD_HOME else user_home else ddir DOWNLOAD_HOME if exists DOWNLOAD_HOME else user_home ddir ddirreturn os.path.join ddir 'mps'
def floating_ip_pool_list call None if call ! 'function' raise SaltCloudSystemExit 'Thefloating_ip_pool_listactionmustbecalledwith-for--function' conn get_conn return conn.floating_ip_pool_list
def data_path path return path if isabs path else join project_data_dir path
def add_interface zone interface permanent True if interface in get_interfaces zone permanent log.info 'Interfaceisalreadyboundtozone.' cmd '--zone {0}--add-interface {1}'.format zone interface if permanent cmd + '--permanent'return __firewall_cmd cmd
def confirm title text informative_text ok_text icon None default True cancel_text None cancel_icon None msgbox QtWidgets.QMessageBox active_window msgbox.setWindowModality Qt.WindowModal msgbox.setWindowTitle title msgbox.setText text msgbox.setInformativeText informative_text icon icons.mkicon icon icons.ok ok msgbox.addButton ok_text QtWidgets.QMessageBox.ActionRole ok.setIcon icon cancel msgbox.addButton QtWidgets.QMessageBox.Cancel cancel_icon icons.mkicon cancel_icon icons.close cancel.setIcon cancel_icon if cancel_text cancel.setText cancel_text if default msgbox.setDefaultButton ok else msgbox.setDefaultButton cancel msgbox.exec_ return msgbox.clickedButton ok
def lstrips text remove return _strips 'l' text remove
def move source destination use_sudo False func use_sudo and run_as_root or run func '/bin/mv{0}{1}'.format quote source quote destination
def float_sum iterable return float sum iterable
def json2csv_entities tweets_file outfile main_fields entity_type entity_fields encoding 'utf8' errors 'replace' gzip_compress False writer outf outf_writer_compat outfile encoding errors gzip_compress header get_header_field_list main_fields entity_type entity_fields writer.writerow header for line in tweets_file tweet json.loads line if _is_composed_key entity_type key value _get_key_value_composed entity_type object_json _get_entity_recursive tweet key if not object_json continueobject_fields extract_fields object_json main_fields items _get_entity_recursive object_json value _write_to_file object_fields items entity_fields writer else tweet_fields extract_fields tweet main_fields items _get_entity_recursive tweet entity_type _write_to_file tweet_fields items entity_fields writer outf.close
def quota_allocated_update context project_id resource allocated return IMPL.quota_allocated_update context project_id resource allocated
def AllocateIdsAsync model_key size None **kwargs max kwargs.pop 'max' None config _GetConfigFromKwargs kwargs if getattr config 'read_policy' None EVENTUAL_CONSISTENCY raise datastore_errors.BadRequestError 'read_policyisonlysupportedonreadoperations.' keys _ NormalizeAndTypeCheckKeys model_key if len keys > 1 raise datastore_errors.BadArgumentError 'CannotallocateIDsformorethanonemodelkeyatatime' rpc _GetConnection .async_allocate_ids config keys[0] size max return rpc
def write_checkpoint current_key ctr cluster_mapping ids bestscores order out_fp checkpoint_dir out_fp + '/checkpoints/' if not exists checkpoint_dir create_dir checkpoint_dir out_fp checkpoint_dir + '/checkpoint%d.pickle' % ctr out_fh open out_fp 'w' pickle.dump current_key ctr cluster_mapping ids bestscores order out_fh return out_fp
def ChiNoncentral name k l return rv name ChiNoncentralDistribution k l
def zip_timeseries *series **kwargs next_slice max if kwargs.get 'order' 'descending' 'descending' else min iterators [PeekableIterator s for s in series]widths []for w in iterators r w.peek if r date values rwidths.append len values else widths.append 0 while True items [it.peek for it in iterators]if not any items returncurrent_slice next_slice item[0] for item in items if item data []for i item in enumerate items if item and item[0] current_slice data.extend item[1] iterators[i].next else data.extend [0] * widths[i] yield current_slice tuple data
def wlPen wl l1 400l2 700hue np.clip l2 - l1 - wl - l1 * 0.8 / l2 - l1 0 0.8 val 1.0if wl > 700 val 1.0 * 700 - wl / 700.0 + 1 elif wl < 400 val wl * 1.0 / 400.0 color pg.hsvColor hue 1.0 val pen pg.mkPen color return pen
def test_lda_empty_docs Z np.zeros 5 4 for X in [Z csr_matrix Z ] lda LatentDirichletAllocation max_iter 750 .fit X assert_almost_equal lda.components_.sum axis 0 np.ones lda.components_.shape[1]
def op_abs_tmul lin_op value if lin_op.type is lo.NEG result valueelif lin_op.type is lo.MUL coeff mul lin_op.data {} True if np.isscalar coeff result coeff * value else result coeff.T * value elif lin_op.type is lo.DIV divisor mul lin_op.data {} True result value / divisor elif lin_op.type is lo.CONV result conv_mul lin_op value True True else result op_tmul lin_op value return result
def get_resources_dests resources_root rules def get_rel_path base path base base.replace os.path.sep '/' path path.replace os.path.sep '/' assert path.startswith base return path[len base ].lstrip '/' destinations {}for base suffix dest in rules prefix os.path.join resources_root base for abs_base in iglob prefix abs_glob os.path.join abs_base suffix for abs_path in iglob abs_glob resource_file get_rel_path resources_root abs_path if dest is None destinations.pop resource_file None else rel_path get_rel_path abs_base abs_path rel_dest dest.replace os.path.sep '/' .rstrip '/' destinations[resource_file] rel_dest + '/' + rel_path return destinations
def local_extra_dirs func def wraps self *args **kwargs if kwargs.get 'base_dir' None is None return func self *args **kwargs else for c in self.__class__.__mro__ if c.__name__ 'DiskObjectStore' return getattr c func.__name__ self *args **kwargs raise Exception "CouldnotcallDiskObjectStore's%smethod doesyourObjectStoreplugininheritfromDiskObjectStore?" % func.__name__ return wraps
def _labels_inertia_precompute_dense X x_squared_norms centers distances n_samples X.shape[0] labels mindist pairwise_distances_argmin_min X X Y centers metric 'euclidean' metric_kwargs {'squared' True} labels labels.astype np.int32 if n_samples distances.shape[0] distances[ ] mindistinertia mindist.sum return labels inertia
def _validate_dict_keys dict_to_check required_keys optional_keys assert set required_keys < set dict_to_check.keys 'Missingkeys %s' % dict_to_check assert set dict_to_check.keys < set required_keys + optional_keys 'Extrakeys %s' % dict_to_check
def image_volume_cache_create context host cluster_name image_id image_updated_at volume_id size return IMPL.image_volume_cache_create context host cluster_name image_id image_updated_at volume_id size
def copy_constr constr func expr func constr.expr return type constr expr constr.constr_id constr.size
def _write_3 fid val f_bytes np.zeros 3 dtype np.uint8 f_bytes[0] val >> 16 & 255 f_bytes[1] val >> 8 & 255 f_bytes[2] val & 255 fid.write f_bytes.tostring
def cluster_remove version name 'main' stop False cmd [salt.utils.which 'pg_dropcluster' ]if stop cmd + ['--stop']cmd + [version name]cmdstr ''.join [pipes.quote c for c in cmd] ret __salt__['cmd.run_all'] cmdstr python_shell False if ret.get 'retcode' 0 ! 0 log.error 'ErrorremovingaPostgresqlcluster{0}/{1}'.format version name else ret['changes'] 'Successfullyremovedcluster{0}/{1}'.format version name return ret
def getLocalAndroidPath client args localPath os.path.join args.localOutputFolder '{0}-{1}'.format client.conn.modules['pupydroid.utils'].getAndroidID client.desc['user'] if not os.path.exists localPath logging.info 'Creating{0}folderlocally'.format localPath os.makedirs localPath return localPath
def mult a b try return a * b except TypeError return to_decimal a * to_decimal b
def _run_shell_command cmd tmpdir cmdsuf ''if platform.system 'Windows' cmdsuf '.bat'cmd '@echooff\r\n' + cmd handle path tempfile.mkstemp text True dir tmpdir suffix cmdsuf os.write handle cmd.encode 'utf-8' os.close handle os.chmod path stat.S_IRWXU proc Popen path shell True stdout PIPE stderr PIPE proc.wait stdout _ proc.communicate os.unlink path return _chomp as_unicode stdout
def SearchDataAdapter results format collection if results and results['response'] and results['response']['docs'] search_data results['response']['docs']if collection['template']['fieldsSelected'] headers collection['template']['fieldsSelected']else headers [field['name'] for field in collection['fields']]rows []for data in search_data row []for column in headers if column not in data row.append '' elif isinstance data[column] basestring or isinstance data[column] int long float complex row.append data[column] elif isinstance data[column] list row.append [smart_str val errors 'replace' for val in data[column]] else row.append smart_str data[column] rows.append row else rows [[]] yield headers rows
def to_tornado_future asyncio_future tf tornado.concurrent.Future tornado.concurrent.chain_future asyncio_future tf return tf
def import_string dotted_path try module_path class_name dotted_path.rsplit u'.' 1 except ValueError msg u"%sdoesn'tlooklikeamodulepath" % dotted_path six.reraise ImportError ImportError msg sys.exc_info [2] module import_module module_path try return getattr module class_name except AttributeError msg u'Module"%s"doesnotdefinea"%s"attribute/class' % dotted_path class_name six.reraise ImportError ImportError msg sys.exc_info [2]
def english_sort x y _spat re.compile '^the\\s+|^a\\s+|^an\\s+' re.IGNORECASE return cmp _spat.sub '' x _spat.sub '' y
def set_block_scalar_indent TokenClass def callback lexer match context text match.group context.block_scalar_indent Noneif not text returnincrement match.group 1 if increment current_indent max context.indent 0 increment int increment context.block_scalar_indent current_indent + increment if text yield match.start TokenClass text context.pos match.end return callback
def run_discovery entry_points_iter cached False reg_cache {}if cached reg_cache cache.registry_cache discovery QtWidgetDiscovery cached_descriptions reg_cache registry QtWidgetRegistry discovery.found_category.connect registry.register_category discovery.found_widget.connect registry.register_widget discovery.run if cached cache.save_registry_cache reg_cache return registry
def do_lower s return soft_unicode s .lower
def verbose_lookup_expr lookup_expr from .conf import settings as app_settingsVERBOSE_LOOKUPS app_settings.VERBOSE_LOOKUPS or {} lookups [force_text VERBOSE_LOOKUPS.get lookup _ lookup for lookup in lookup_expr.split LOOKUP_SEP ]return ''.join lookups
def instance_add_security_group context instance_id security_group_id return IMPL.instance_add_security_group context instance_id security_group_id
@login_required@expect_jsondef _create_item request parent_locator request.json['parent_locator']usage_key usage_key_with_run parent_locator if not has_studio_write_access request.user usage_key.course_key raise PermissionDenied category request.json['category']if isinstance usage_key LibraryUsageLocator if category not in ['html' 'problem' 'video'] return HttpResponseBadRequest "Category'%s'notsupportedforLibraries" % category content_type 'text/plain' created_block create_xblock parent_locator parent_locator user request.user category category display_name request.json.get 'display_name' boilerplate request.json.get 'boilerplate' return JsonResponse {'locator' unicode created_block.location 'courseKey' unicode created_block.location.course_key }
def simsam_range_to_files table tree simulated_sample_sizes dissimilarities output_dir mapping_f None output_table_basename 'table' output_map_basename 'map' create_dir output_dir for e in simsam_range table tree simulated_sample_sizes dissimilarities mapping_f output_table e[0]output_mapping_lines e[1]simulated_sample_size e[2]dissimilarity e[3]output_table_fp join output_dir '%s_n%d_d%r.biom' % output_table_basename simulated_sample_size dissimilarity write_biom_table output_table output_table_fp if output_mapping_lines is not None output_map_fp join output_dir '%s_n%d_d%r.txt' % output_map_basename simulated_sample_size dissimilarity output_map_f open output_map_fp 'w' output_map_f.write ''.join output_mapping_lines output_map_f.close
def parse_function_plugin logger line state try acc state['test_acc'] + 1 except KeyError acc 1state['test_acc'] accres line.split res[2] accres[3] {'metric_type' 'counter'}return tuple res
def set_subnet_name name cmd 'systemsetup-setlocalsubnetname"{0}"'.format name salt.utils.mac_utils.execute_return_success cmd return salt.utils.mac_utils.confirm_updated name get_subnet_name
@ignore_warningsdef check_estimators_pickle name Estimator check_methods ['predict' 'transform' 'decision_function' 'predict_proba'] X y make_blobs n_samples 30 centers [[0 0 0] [1 1 1]] random_state 0 n_features 2 cluster_std 0.1 X - X.min y multioutput_estimator_convert_y_2d name y estimator Estimator set_random_state estimator set_testing_parameters estimator estimator.fit X y result dict for method in check_methods if hasattr estimator method result[method] getattr estimator method X pickled_estimator pickle.dumps estimator if Estimator.__module__.startswith 'sklearn.' assert_true 'version' in pickled_estimator unpickled_estimator pickle.loads pickled_estimator for method in result unpickled_result getattr unpickled_estimator method X assert_array_almost_equal result[method] unpickled_result
def estimate_beta_ridge x y alpha beta_initial [random.random for x_i in x[0]]return minimize_stochastic partial squared_error_ridge alpha alpha partial squared_error_ridge_gradient alpha alpha x y beta_initial 0.001
def get_common_path pathlist common osp.normpath osp.commonprefix pathlist if len common > 1 if not osp.isdir common return abspardir common else for path in pathlist if not osp.isdir osp.join common path[ len common + 1 ] return abspardir common else return osp.abspath common
def remove_wsgi_intercept host port key host port if _wsgi_intercept.has_key key del _wsgi_intercept[key]
def findImageFile filename isfile os.path.isfileif isfile filename return filenameorig copy.copy filename extensions '.jpg' '.png' '.tif' '.bmp' '.gif' '.jpeg' '.tiff' def logCorrected orig actual logging.warn 'Requestedimage{!r}notfoundbutsimilarfilename{!r}exists.Thiswillbeusedinsteadbutchangingthefilenameisadvised.'.format orig actual if filename.endswith extensions filename os.path.splitext orig [0]if isfile filename logCorrected orig filename return filenamefor ext in extensions if isfile filename + ext filename + extlogCorrected orig filename return filename
def login_required func @wraps func def decorated_view *args **kwargs if not users.get_current_user return redirect users.create_login_url request.url return func *args **kwargs return decorated_view
def _compute_variable_length_solns model t0 k0 g tol results {}for integrator in ['dopri5' 'dop853' 'vode' 'lsoda'] discrete_soln model.solve t0 k0 h 1.0 g g tol tol integrator integrator atol 1e-14 rtol 1e-11 results[integrator] discrete_solnreturn results
def compile_and_install_client project_client extra_args '' install_client True java_args {}java_args['compile_dir'] _TMP_COMPILE_DIRjava_args['app_dir'] _DEFAULT_APP_DIRjava_args['gwt_dir'] find_gwt_dir java_args['extra_args'] extra_argsjava_args['project_client'] project_clientcmd _COMPILE_LINE % java_args logging.info 'Compilingclient%s' project_client try utils.run cmd verbose True if install_client return install_completed_client java_args['compile_dir'] project_client return Trueexcept error.CmdError logging.info 'Errorcompiling%s leavingoldclient' project_client return False
def validate_auth_option option value lower value validate option value if lower not in _AUTH_OPTIONS raise ConfigurationError 'Unknownauthenticationoption %s' % option return lower value
def UINT value if value is None raise ValueError u'Noneisnotavalidinteger' if not value.isdigit raise ValueError u'Onlypositivenumbersareallowed' return int value
def libvlc_video_set_spu p_mi i_spu f _Cfunctions.get 'libvlc_video_set_spu' None or _Cfunction 'libvlc_video_set_spu' 1 1 None ctypes.c_int MediaPlayer ctypes.c_int return f p_mi i_spu
def cache_project cls projects dict resources dict def get_ctx *args **kwargs path env.curbuf.nameif resources.get path return resources.get path project_path env.var 'g pymode_rope_project_root' if not project_path project_path env.curdirenv.debug 'Lookctx' project_path if env.var 'g pymode_rope_lookup_project' True project_path look_ropeproject project_path if not os.path.exists project_path env.error 'Ropeprojectrootnotexist %s' % project_path ctx Noneelse ctx projects.get project_path if not ctx projects[project_path] ctx cls path project_path resources[path] ctxreturn ctxreturn get_ctx
def filename_match filename if not options.filename return Truefor pattern in options.filename if fnmatch filename pattern return True
def connect_configservice aws_access_key_id None aws_secret_access_key None **kwargs from boto.configservice.layer1 import ConfigServiceConnectionreturn ConfigServiceConnection aws_access_key_id aws_access_key_id aws_secret_access_key aws_secret_access_key **kwargs
def _decode_preferred_encoding s enc locale.getpreferredencoding try try return s.decode enc except LookupError enc _DEFAULT_ENCODINGreturn s.decode enc except UnicodeDecodeError return s.decode u'latin-1'
def _onPygletText text emulated False global useTextif not useText returnkeyTime psychopy.core.getTime if emulated keySource 'EmulatedKey'else keySource 'KeyPress'_keyBuffer.append text keyTime logging.data '%s %s' % keySource text
def _sphinx_version major minor micro level serial sys.version_inforelease '%s%s' % major minor if micro release + '%s' % micro if level 'candidate' release + 'rc%s' % serial elif level ! 'final' release + '%s%s' % level[0] serial return release
def Zero dtype None return Constant 0.0 dtype dtype
def wrap_aws_conn raw_conn def retry_if ex 'Retryifwegetaservererrorindicatingthrottling.Also\nhandlespurious505sthatarethoughttobepartofaload\nbalancerissueinsideAWS.'return isinstance ex boto.exception.BotoServerError and 'Throttling' in ex.body or 'RequestExpired' in ex.body or ex.status 505 or isinstance ex socket.error and ex.args in 104 'Connectionresetbypeer' 110 'Connectiontimedout' return RetryWrapper raw_conn retry_if retry_if backoff _EMR_BACKOFF multiplier _EMR_BACKOFF_MULTIPLIER max_tries _EMR_MAX_TRIES
def computeOverlap x y return x & y .sum
def _fulfills_version_spec version version_spec for oper spec in version_spec if oper is None continueif not salt.utils.compare_versions ver1 version oper oper ver2 spec return Falsereturn True
def mkdir dir_path return os.system 'mkdir-p' + dir_path
def option_present name value reload False ret {'name' 'testingmode' 'changes' {} 'result' True 'comment' 'Optionalreadypresent.'}option namecurrent_option __salt__['csf.get_option'] option if current_option l __salt__['csf.split_option'] current_option option_value l[1]if '"{0}"'.format value option_value return retelse result __salt__['csf.set_option'] option value ret['comment'] 'Optionmodified.'ret['changes']['Option'] 'Changed'else result __salt__['file.append'] '/etc/csf/csf.conf' args '{0} "{1}"'.format option value ret['comment'] 'Optionnotpresent.Appendedtocsf.conf'ret['changes']['Option'] 'Changed.'if reload if __salt__['csf.reload'] ret['comment'] + '.Csfreloaded.'else ret['comment'] + '.Csffailedtoreload.'ret['result'] Falsereturn ret
def attach_total_points queryset as_field 'total_points_attr' model queryset.modelsql 'SELECTSUM projects_points.value \nFROMuserstories_rolepoints\nINNERJOINprojects_pointsONuserstories_rolepoints.points_id projects_points.id\nWHEREuserstories_rolepoints.user_story_id {tbl}.id'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def test_hsl_to_rgb_part_4 assert hsl_to_rgb 0 100 50 255 0 0 assert hsl_to_rgb 12 100 50 255 51 0 assert hsl_to_rgb 24 100 50 255 102 0 assert hsl_to_rgb 36 100 50 255 153 0 assert hsl_to_rgb 48 100 50 255 204 0 assert hsl_to_rgb 60 100 50 255 255 0 assert hsl_to_rgb 72 100 50 204 255 0 assert hsl_to_rgb 84 100 50 153 255 0 assert hsl_to_rgb 96 100 50 102 255 0 assert hsl_to_rgb 108 100 50 51 255 0 assert hsl_to_rgb 120 100 50 0 255 0
def initiate_deletion req location_data id store_utils.delete_image_location_from_backend req.context id location_data
def publish_exploration_and_update_user_profiles committer_id exp_id rights_manager.publish_exploration committer_id exp_id contribution_time_msec utils.get_current_time_in_millisecs contributor_ids get_exploration_summary_by_id exp_id .contributor_idsfor contributor in contributor_ids user_services.update_first_contribution_msec_if_not_set contributor contribution_time_msec
def riemann_cyclic t2 if isinstance t2 TensMul Tensor args [t2]else args t2.argsa1 [x.split for x in args]a2 [[riemann_cyclic_replace tx for tx in y] for y in a1]a3 [tensor_mul *v for v in a2]t3 TensAdd *a3 if not t3 return t3else return canon_bp t3
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def kinetic_energy frame *body if not isinstance frame ReferenceFrame raise TypeError 'PleaseenteravalidReferenceFrame' ke_sys S 0 for e in body if isinstance e RigidBody Particle ke_sys + e.kinetic_energy frame else raise TypeError '*bodymusthaveonlyParticleorRigidBody' return ke_sys
def generate_module src if not src return UNKNOWN_MODULE filename ext splitext urlsplit src .path if ext not in '.js' '.jsx' '.coffee' return UNKNOWN_MODULEif filename.endswith '.min' filename filename[ -4 ]tokens filename.split '/' for idx token in enumerate tokens if VERSION_RE.match token return '/'.join tokens[ idx + 1 ] return CLEAN_MODULE_RE.sub '' filename or UNKNOWN_MODULE
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def _get_ssh_interface vm_ return config.get_cloud_config_value 'ssh_interface' vm_ __opts__ default 'public_ips' search_global False
@decorators.api_view ['GET'] @decorators.permission_classes permissions.AllowAny @decorators.renderer_classes JSONRenderer def section_search request query request.GET.get 'q' None if not query return Response {'error' 'Searchtermrequired.Usethe"q"GETargtosearch.'} status status.HTTP_400_BAD_REQUEST project_slug request.GET.get 'project' None version_slug request.GET.get 'version' LATEST path request.GET.get 'path' None log.debug ' APISectionSearch [%s %s]%s' project_slug version_slug query results search_section request request query query project_slug project_slug version_slug version_slug path path return Response {'results' results}
def is_filelike obj return hasattr obj 'read'
@csrf_exempt@gzip_page@require_sync_session@api_handle_error_with_jsondef device_download data session zone session.client_device.get_zone devicezones list DeviceZone.all_objects.filter zone zone device__in data['devices'] devices [devicezone.device for devicezone in devicezones]session.models_downloaded + len devices + len devicezones return JsonResponse {'devices' serialize devices + devicezones dest_version session.client_version ensure_ascii False }
def load_auth_tokens user None if user is None user users.get_current_user if user is None return {}pickled_tokens memcache.get 'gdata_pickled_tokens %s' % user if pickled_tokens return pickle.loads pickled_tokens user_tokens TokenCollection.all .filter 'user ' user .get if user_tokens memcache.set 'gdata_pickled_tokens %s' % user user_tokens.pickled_tokens return pickle.loads user_tokens.pickled_tokens return {}
@sopel.module.commands u'reload' @sopel.module.priority u'low' @sopel.module.thread False def pm_f_reload bot trigger if trigger.is_privmsg f_reload bot trigger
def get_default_access_key_id access_key_id_script AWS_ACCOUNTS['default'].ACCESS_KEY_ID_SCRIPT.get return access_key_id_script or get_s3a_access_key
def _not_a_knot x k x np.asarray x if k % 2 ! 1 raise ValueError 'Odddegreefornowonly.Got%s.' % k m k - 1 // 2 t x[ m + 1 - m - 1 ]t np.r_[ x[0] * k + 1 t x[ -1 ] * k + 1 ]return t
def reinitialize_command self command reinit_subcommands cmd_obj _DISTUTILS_REINIT self command reinit_subcommands options self.command_options.get command if options self._set_command_options cmd_obj options return cmd_obj
def _allow_CTRL_C_posix signal.signal signal.SIGINT signal.default_int_handler
def backup_dir dir ext '.bak' n 1extension extwhile os.path.exists dir + extension n + 1extension ext + str n return dir + extension
def init_native init_subsystem Native.Factory return Native.Factory.global_instance .create
def timeout reactor deferred timeout_sec reason None def _timeout deferred.cancel delayed_timeout reactor.callLater timeout_sec _timeout if reason is not None def maybe_replace_reason passthrough if delayed_timeout.active return passthroughreturn Failure reason deferred.addErrback maybe_replace_reason def abort_timeout passthrough if delayed_timeout.active delayed_timeout.cancel return passthroughdeferred.addBoth abort_timeout return deferred
def _row_from_json row schema row_data []for field cell in zip schema row['f'] converter _CELLDATA_FROM_JSON[field.field_type]if field.mode 'REPEATED' row_data.append [converter item['v'] field for item in cell['v']] else row_data.append converter cell['v'] field return tuple row_data
def createMemoryWorker def perform if not worker._pending return Falseif worker._pending[0] is NoMoreWork return Falseworker._pending.pop 0 return Trueworker MemoryWorker return worker perform
def do_baremetal_node_list cs _args _emit_deprecation_warning 'baremetal-node-list' nodes cs.baremetal.list _print_baremetal_nodes_list nodes
def primary_key_value instance as_string False result getattr instance primary_key_for instance if not as_string return resulttry return str result except UnicodeEncodeError return url_quote_plus result.encode 'utf-8'
def setup app app.add_role 'rfc' rfclink return
def ci a which 95 axis None p 50 - which / 2 50 + which / 2 return percentiles a p axis
@CELERY_APP.taskdef send_ccx_course_published course_key course_key CourseLocator.from_string course_key for ccx in CustomCourseForEdX.objects.filter course_id course_key try ccx_key CCXLocator.from_course_locator course_key unicode ccx.id except InvalidKeyError log.info 'Attempttopublishcoursewithdeprecatedid.Course %s.CCX %s' course_key ccx.id continueresponses SignalHandler.course_published.send sender ccx course_key ccx_key for rec response in responses log.info 'Signalfiredwhencourseispublished.Receiver %s.Response %s' rec response
def inverse_hankel_transform F k r nu **hints return InverseHankelTransform F k r nu .doit **hints
def set_main_css css_file assert css_file.endswith '.css' new_css css_fileapp_globals.main_css str new_css
def brightness_temperature beam_area disp beam beam_area.to si.sr .valuenu disp.to si.GHz spectral def convert_Jy_to_K x_jybm factor 2 * _si.k_B * si.K * nu ** 2 / _si.c ** 2 .to astrophys.Jy .valuereturn x_jybm / beam / factor def convert_K_to_Jy x_K factor astrophys.Jy / 2 * _si.k_B * nu ** 2 / _si.c ** 2 .to si.K .valuereturn x_K * beam / factor return [ astrophys.Jy si.K convert_Jy_to_K convert_K_to_Jy ]
def color text color_code readline False if sys.platform 'win32' and os.getenv 'TERM' ! 'xterm' return str text if readline return '\x01\x1b[%dm\x02%s\x01\x1b[0m\x02' % color_code text return '\x1b[%dm%s\x1b[0m' % color_code text
def CreateGRRTempFileVFS directory None filename None lifetime 0 mode 'w+b' suffix '' fd CreateGRRTempFile directory directory filename filename lifetime lifetime mode mode suffix suffix pathspec rdf_paths.PathSpec path fd.name pathtype rdf_paths.PathSpec.PathType.TMPFILE return fd pathspec
def p_postfix_expression_2 t pass
def can_introspect field if hasattr field '_south_introspects' and field._south_introspects return Truefull_name '%s.%s' % field.__class__.__module__ field.__class__.__name__ for regex in allowed_fields if re.match regex full_name return Truereturn False
def etc_hosts attrs None where None return _osquery_cmd table 'etc_hosts' attrs attrs where where
def available_modules extra_service_versions set [] _tempest_modules set tempest_modules plugin_services ClientsRegistry .get_service_clients for plugin_name in plugin_services plug_service_versions set [x['service_version'] for x in plugin_services[plugin_name]] if plug_service_versions if not plug_service_versions.isdisjoint extra_service_versions detailed_error 'Plugin%sistryingtoregisteraservice%salreadyclaimedbyanotherone' % plugin_name extra_service_versions & plug_service_versions raise exceptions.PluginRegistrationException name plugin_name detailed_error detailed_error if not plug_service_versions.isdisjoint _tempest_internal_modules detailed_error 'Plugin%sistryingtoregisteraservice%salreadyclaimedbyaTempestone' % plugin_name _tempest_internal_modules & plug_service_versions raise exceptions.PluginRegistrationException name plugin_name detailed_error detailed_error extra_service_versions | plug_service_versionsreturn _tempest_modules | extra_service_versions
def _get_mask X value_to_mask if value_to_mask 'NaN' or np.isnan value_to_mask return np.isnan X else return X value_to_mask
def colname colx alphabet 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'if colx < 25 return alphabet[colx]else xdiv26 xmod26 divmod colx 26 return alphabet[ xdiv26 - 1 ] + alphabet[xmod26]
def seek_wrapped_response response if not hasattr response 'seek' wrapper_class get_seek_wrapper_class response response wrapper_class response assert hasattr response 'get_data' return response
def _buildFakeFKTable cls fakeTableName countCols 0attrs {}for col in cls._imdbpySchema.cols countCols + 1if col.name 'id' continueif not col.foreignKey attrs[col.name] MAP_COLS[col.kind] **col.params continuethisColName col.nameif thisColName.endswith 'ID' thisColName thisColName[ -2 ]fks col.foreignKey.split '.' 1 foreignTableName fks[0]if len fks 2 foreignColName fks[1]else foreignColName 'id'fk ForeignKey foreignTableName name thisColName default None attrs[thisColName] fknewcls type fakeTableName SQLObject attrs return newcls
def edns_from_text text return _from_text text _edns_by_text
def addYGroove derivation negatives x if derivation.topBevel < 0.0 returnbottom derivation.height - derivation.topBevel top derivation.heightgroove [complex x bottom complex x - derivation.topBevel top complex x + derivation.topBevel top ]triangle_mesh.addSymmetricYPath negatives groove 1.0001 * derivation.topRight.imag
def is_valid_number_for_region numobj region_code country_code numobj.country_codeif region_code is None return Falsemetadata PhoneMetadata.metadata_for_region_or_calling_code country_code region_code.upper if metadata is None or region_code ! REGION_CODE_FOR_NON_GEO_ENTITY and country_code ! country_code_for_valid_region region_code return Falsensn national_significant_number numobj return _number_type_helper nsn metadata ! PhoneNumberType.UNKNOWN
def NeedsMacOSXProxyFakes return sys.platform 'darwin' and 2 6 0 < sys.version_info < 2 6 4
def event name ret {'name' name 'changes' {} 'comment' '' 'result' False}for event in __events__ if salt.utils.expr_match event['tag'] name ret['result'] Truereturn ret
def prepare_wmt_data data_dir en_vocabulary_size fr_vocabulary_size tokenizer None train_path get_wmt_enfr_train_set data_dir dev_path get_wmt_enfr_dev_set data_dir from_train_path train_path + '.en' to_train_path train_path + '.fr' from_dev_path dev_path + '.en' to_dev_path dev_path + '.fr' return prepare_data data_dir from_train_path to_train_path from_dev_path to_dev_path en_vocabulary_size fr_vocabulary_size tokenizer
def setraw fd when TCSAFLUSH mode tcgetattr fd mode[IFLAG] mode[IFLAG] & ~ BRKINT | ICRNL | INPCK | ISTRIP | IXON mode[OFLAG] mode[OFLAG] & ~ OPOST mode[CFLAG] mode[CFLAG] & ~ CSIZE | PARENB mode[CFLAG] mode[CFLAG] | CS8 mode[LFLAG] mode[LFLAG] & ~ ECHO | ICANON | IEXTEN | ISIG mode[CC][VMIN] 1mode[CC][VTIME] 0tcsetattr fd when mode
@jinja2.contextfunction@library.global_functiondef number context n if n is None return ''return format_decimal n locale _babel_locale _contextual_locale context
def split_qexpr_parts e expr_part []qexpr_part []for arg in e.args if not isinstance arg QExpr expr_part.append arg else qexpr_part.append arg return expr_part qexpr_part
def pmap_field key_type value_type optional False invariant _valid initial _UNDEFINED factory None input_factory factoryclass TheMap CheckedPMap __key_type__ key_type__value_type__ value_typeTheMap.__name__ key_type.__name__.capitalize + value_type.__name__.capitalize + 'PMap' if optional def mapping_factory argument if argument is None return Noneelse return TheMap argument else mapping_factory TheMapif input_factory factory lambda x mapping_factory input_factory x else factory mapping_factoryif initial is _UNDEFINED initial TheMap else initial factory initial return field mandatory True initial initial type optional_type TheMap if optional else TheMap factory factory invariant invariant
def curve4_bezier p1 p2 p3 p4 x1 y1 p1 x2 y2 p2 x3 y3 p3 x4 y4 p4points []_curve4_recursive_bezier points x1 y1 x2 y2 x3 y3 x4 y4 dx dy points[0][0] - x1 points[0][1] - y1 if dx * dx + dy * dy > 1e-10 points.insert 0 x1 y1 dx dy points[ -1 ][0] - x4 points[ -1 ][1] - y4 if dx * dx + dy * dy > 1e-10 points.append x4 y4 return np.array points .reshape len points 2
def cram text maxlen if len text > maxlen pre max 0 maxlen - 3 // 2 post max 0 maxlen - 3 - pre return text[ pre] + '...' + text[ len text - post ] return text
def build_provider_location system lun_type lun_id version location_dict {'system' system 'type' lun_type 'id' six.text_type lun_id 'version' version}return dump_provider_location location_dict
def p_unary_expression_4 t pass
def get_hqe_percentage_complete **filter_data query models.HostQueueEntry.query_objects filter_data complete_count query.filter complete True .count total_count query.count if total_count 0 return 1return float complete_count / total_count
def build_query_rep query divider u'-' return divider.join [el[0] for el in query]
def set_range_metadata builder load lower_bound upper_bound range_operands [Constant.int load.type lower_bound Constant.int load.type upper_bound ]md builder.module.add_metadata range_operands load.set_metadata 'range' md
def hadoop_fs_ls stdout stderr environ *args if mock_hadoop_uses_yarn environ and args and args[0] '-R' path_args args[1 ]recursive Trueelse path_args argsrecursive Falsereturn _hadoop_fs_ls 'ls' stdout stderr environ path_args path_args recursive recursive
def runCalibration eyegaze_control import subprocess timeresult pEyeGaze.EgExit byref eyegaze_control eyegaze_control Nonep subprocess.Popen 'calibrate.exe' '' while p.poll is None time.sleep 0.05 return initEyeGaze
def __validate__ config if not isinstance config dict return False 'Configurationforbonjour_announcementbeaconmustbeadictionary' elif not all x in list config.keys for x in 'servicetype' 'port' 'txt' return False 'Configurationforbonjour_announcebeaconmustcontainservicetype portandtxtitems' return True 'Validbeaconconfiguration'
def heatmap data vmin None vmax None cmap None center None robust False annot None fmt '.2g' annot_kws None linewidths 0 linecolor 'white' cbar True cbar_kws None cbar_ax None square False ax None xticklabels True yticklabels True mask None **kwargs plotter _HeatMapper data vmin vmax cmap center robust annot fmt annot_kws cbar cbar_kws xticklabels yticklabels mask kwargs['linewidths'] linewidthskwargs['edgecolor'] linecolorif ax is None ax plt.gca if square ax.set_aspect 'equal' plotter.plot ax cbar_ax kwargs return ax
def getLevel level return _levelNames.get level 'Level%s' % level
def _delete_rpm_probes probes return __salt__['probes.delete_probes'] _ordered_dict_to_dict probes commit False
def _get_encryption_headers key source False if key is None return {}key _to_bytes key key_hash hashlib.sha256 key .digest key_hash base64.b64encode key_hash .rstrip key base64.b64encode key .rstrip if source prefix 'X-Goog-Copy-Source-Encryption-'else prefix 'X-Goog-Encryption-'return { prefix + 'Algorithm' 'AES256' prefix + 'Key' _bytes_to_unicode key prefix + 'Key-Sha256' _bytes_to_unicode key_hash }
def test_get_debug_values_no_debugger prev_value config.compute_test_valuetry config.compute_test_value 'off'x T.vector for x_val in op.get_debug_values x assert Falsefinally config.compute_test_value prev_value
def berp_zeros nt if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'ntmustbepositiveintegerscalar.' return specfun.klvnzo nt 5
def generate_random_alphanumeric length return ''.join random.choice string.ascii_uppercase + string.digits for _x in range length
def assert_raises_regex exception_class expected_regexp callable_obj None *args **kwargs __tracebackhide__ Truenose import_nose if sys.version_info.major > 3 funcname nose.tools.assert_raises_regexelse funcname nose.tools.assert_raises_regexpreturn funcname exception_class expected_regexp callable_obj *args **kwargs
def find_tests testdir prefixes DEFAULT_PREFIXES suffix '.py' excludes remove_suffix True tests []for name in os.listdir testdir if not suffix or name.endswith suffix for prefix in prefixes if name.startswith prefix if remove_suffix and name.endswith suffix name name[ - len suffix ]if name not in excludes tests.append name tests.sort return tests
def load_class dotted_path dotted_path_split dotted_path.split '.' if len dotted_path_split > 1 klass_name dotted_path_split[ -1 ]module_name '.'.join dotted_path_split[ -1 ] module load_module module_name if has_attribute module klass_name klass getattr module klass_name return klasselse raise AttributeError 'Module%sdoesnothaveclassattribute%s' % module_name klass_name else raise ValueError 'Dottedmodulepath%smustcontainamodulenameandaclassname' % dotted_path
def deconv X w subsample 1 1 border_mode 0 0 conv_mode 'conv' img gpu_contiguous X kerns gpu_contiguous w desc GpuDnnConvDesc border_mode border_mode subsample subsample conv_mode conv_mode gpu_alloc_empty img.shape[0] kerns.shape[1] img.shape[2] * subsample[0] img.shape[3] * subsample[1] .shape kerns.shape out gpu_alloc_empty img.shape[0] kerns.shape[1] img.shape[2] * subsample[0] img.shape[3] * subsample[1] d_img GpuDnnConvGradI kerns img out desc return d_img
def volumedriver cls _volume_register.append cls return cls
def _matchingString constantString inputString if isinstance constantString bytes otherType constantString.decode 'ascii' else otherType constantString.encode 'ascii' if type constantString type inputString return constantStringelse return otherType
def node_degree_xy G x 'out' y 'in' weight None nodes None if nodes is None nodes set G else nodes set nodes xdeg G.degreeydeg G.degreeif G.is_directed direction {'out' G.out_degree 'in' G.in_degree}xdeg direction[x]ydeg direction[y]for u degu in xdeg nodes weight weight neighbors nbr for _ nbr in G.edges u if nbr in nodes for v degv in ydeg neighbors weight weight yield degu degv
def load_meta prefix dist return linked_data prefix .get dist
def validate **vkargs depr 'Useroutewildcardfiltersinstead.' def decorator func @functools.wraps func def wrapper *args **kargs for key value in vkargs.iteritems if key not in kargs abort 403 'Missingparameter %s' % key try kargs[key] value kargs[key] except ValueError abort 403 'Wrongparameterformatfor %s' % key return func *args **kargs return wrapperreturn decorator
def tetrahedral_graph create_using None G complete_graph 4 create_using G.name 'PlatonicTetrahedralgraph'return G
def get_data_path file_name None if file_name is None file_name ''return os.path.join DATA_DIR file_name
def python_version return _sys_version [1]
def liveobj_changed obj other return obj ! other or type obj ! type other
def _d n j prec sq23pi sqrt8 j from_int j pi mpf_pi prec a mpf_div sq23pi j prec b mpf_sub from_int n from_rational 1 24 prec prec c mpf_sqrt b prec ch sh mpf_cosh_sinh mpf_mul a c prec D mpf_div mpf_sqrt j prec mpf_mul mpf_mul sqrt8 b pi prec E mpf_sub mpf_mul a ch mpf_div sh c prec prec return mpf_mul D E
def mkdir_p dir if not dir returnif dir.endswith '/' or dir.endswith '\\' mkdir_p dir[ -1 ] returnif os.path.isdir dir returnmkdir_p os.path.dirname dir try os.mkdir dir except Exception pass
def _can_do_sum_of_squares n k if k < 1 return Falseif n < 0 return Falseif n 0 return Trueif k 1 return is_square n if k 2 if n in 1 2 return Trueif isprime n if n % 4 1 return 1return Falseelse f factorint n for p m in f.items if p % 4 3 and m % 2 return Falsereturn Trueif k 3 if n // 4 ** multiplicity 4 n % 8 7 return Falsereturn True
def dynamize_value val dynamodb_type get_dynamodb_type val if dynamodb_type 'N' val {dynamodb_type serialize_num val }elif dynamodb_type 'S' val {dynamodb_type val}elif dynamodb_type 'NS' val {dynamodb_type list map serialize_num val }elif dynamodb_type 'SS' val {dynamodb_type [n for n in val]}elif dynamodb_type 'B' if isinstance val bytes val Binary val val {dynamodb_type val.encode }elif dynamodb_type 'BS' val {dynamodb_type [n.encode for n in val]}return val
def split_title title width title_fs titles []if not title return titlessize reverse_text_len width title_fs * 1.1 title_lines title.split '\n' for title_line in title_lines while len title_line > size title_part title_line[ size]i title_part.rfind '' if i -1 i len title_part titles.append title_part[ i] title_line title_line[i ].strip titles.append title_line return titles
def to_nnf expr simplify True if is_nnf expr simplify return exprreturn expr.to_nnf simplify
def create_and_check_dir path if not os.path.exists path os.makedirs path elif not os.access path os.W_OK raise OSError 'DATA_DIR{0}isnotwritable!'.format path
def get_datasources orgname None profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.get '{0}/api/datasources'.format profile['grafana_url'] auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def terminal_action parent fn action cmd_action parent cmds.LaunchTerminal lambda utils.select_directory fn hotkeys.TERMINAL return action
def get_all_collections bus service_obj bus_get_object bus SS_PATH service_props_iface dbus.Interface service_obj dbus.PROPERTIES_IFACE for collection_path in service_props_iface.Get SERVICE_IFACE 'Collections' signature 'ss' yield Collection bus collection_path
def is_valid_csv parser file_name row_limit row_count 0for row in csv.reader open file_name row_count + 1if row_limit > row_count parser.error "The'row_count'of'{}'is>thenumberofrowsin'{}'!".format row_limit file_name sys.exit 1
def _extract_id_token id_token if type id_token bytes segments id_token.split '.' else segments id_token.split u'.' if len segments ! 3 raise VerifyJwtTokenError 'Wrongnumberofsegmentsintoken {0}'.format id_token return json.loads _helpers._from_bytes _helpers._urlsafe_b64decode segments[1]
def unwatch_log log_root logging.getLogger None .loggerto_replace [h for h in log_root.handlers if isinstance h handlers.WatchedFileHandler ]for handler in to_replace new_handler std_logging.FileHandler handler.baseFilename mode handler.mode encoding handler.encoding log_root.removeHandler handler log_root.addHandler new_handler
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def convert_tree beautiful_soup_tree makeelement None if makeelement is None makeelement html.html_parser.makeelementroot _convert_tree beautiful_soup_tree makeelement children root.getchildren for child in children root.remove child return children
def _validate_list key value for ind element in enumerate value if not isinstance element basestring or isinstance element datetime.date or isinstance element datetime.datetime or isinstance element numbers.Number raise ValueError 'Allvaluesofamulti-valuedfieldmustbenumbers strings dateordatetimeinstances The%dthvalueforfield%shastype%s.' % ind key type element
def ntohl integer if sys.byteorder 'big' return integerif not isinstance integer int long raise TypeError 'expectedint/long %sfound' % _TypeName integer if integer < 0 raise OverflowError "can'tconvertnegativenumbertounsignedlong" if integer > 1 << 32 raise OverflowError 'longintlargerthan32bits' return int integer & 4278190080 >> 24 | integer & 16711680 >> 8 | integer & 65280 << 8 | integer & 255 << 24
def load_stored_item cache path item return cache.load_parser path item.change_time - 1
def has_flag conf atom flag if flag in get_flags_from_package_conf conf atom return Truereturn False
def obtain_lock_id_to_hog for id in board_ids if _obtain_lock id return idreturn -1
def get_latest_flexget_version_number try page requests.get u'http //download.flexget.com/latestversion' except requests.RequestException returnver page.text.strip return ver
def isproxy obj return orig_isinstance obj NetProxy
def _to_app_identity_error error error_map {app_identity_service_pb.AppIdentityServiceError.NOT_A_VALID_APP InternalError app_identity_service_pb.AppIdentityServiceError.DEADLINE_EXCEEDED BackendDeadlineExceeded app_identity_service_pb.AppIdentityServiceError.BLOB_TOO_LARGE BlobSizeTooLarge app_identity_service_pb.AppIdentityServiceError.UNKNOWN_ERROR InternalError app_identity_service_pb.AppIdentityServiceError.UNKNOWN_SCOPE InvalidScope app_identity_service_pb.AppIdentityServiceError.NOT_ALLOWED NotAllowed app_identity_service_pb.AppIdentityServiceError.NOT_IMPLEMENTED OperationNotImplemented}if error.application_error in error_map return error_map[error.application_error] error.error_detail else return InternalError '%s %s' % error.application_error error.error_detail
def _putResultInDeferred reactor deferred f args kwargs try result f *args **kwargs except Exception f failure.Failure reactor.callFromThread deferred.errback f else reactor.callFromThread deferred.callback result
def export_stats request project subproject subprj get_subproject request project subproject data [trans.get_stats for trans in subprj.translation_set.all ]return export_response request 'stats-%s-%s.csv' % subprj.project.slug subprj.slug 'name' 'code' 'total' 'translated' 'translated_percent' 'total_words' 'translated_words' 'failing' 'failing_percent' 'fuzzy' 'fuzzy_percent' 'url_translate' 'url' 'last_change' 'last_author' data
def convert_opt key val if key 'env' val env_to_str val elif val is None val ''else val str val return val
def disinherit name objectType copy_inherited_acl True ret {'name' name 'result' True 'changes' {} 'comment' ''}tRet __salt__['win_dacl.check_inheritance'] name objectType if tRet['result'] if tRet['Inheritance'] if __opts__['test'] ret['result'] Noneret['changes']['Inheritance'] 'Disabled'ret['comment'] 'Inheritanceissettobedisabled.'ret['changes']['InheritedACLs'] 'Aresettobekept' if copy_inherited_acl else 'Aresettoberemoved' return reteRet __salt__['win_dacl.disable_inheritance'] name objectType copy_inherited_acl ret['result'] eRet['result']if eRet['result'] ret['changes'] dict ret['changes'] **eRet['changes'] else ret['comment'] ''.join [ret['comment'] eRet['comment']] elif __opts__['test'] ret['result'] Noneret['comment'] 'Inheritanceisdisabled.'else ret['result'] Falseret['comment'] tRet['comment']return ret
def colnum2name n assert n > 0 s ''while n n m divmod n - 1 26 s chr m + ord 'A' + s return s
def task_reserved request add_request requests.__setitem__ add_reserved_request reserved_requests.add add_request request.id request add_reserved_request request
@csrf_exempt@require_POSTdef password_reset request limiter BadRequestRateLimiter if limiter.is_rate_limit_exceeded request AUDIT_LOG.warning 'Ratelimitexceededinpassword_reset' return HttpResponseForbidden form PasswordResetFormNoActive request.POST if form.is_valid form.save use_https request.is_secure from_email configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL request request domain_override request.get_host tracker.emit SETTING_CHANGE_INITIATED {'setting' 'password' 'old' None 'new' None 'user_id' request.user.id} destroy_oauth_tokens request.user else AUDIT_LOG.info 'Badpassword_resetuserpassedin.' limiter.tick_bad_request_counter request return JsonResponse {'success' True 'value' render_to_string 'registration/password_reset_done.html' {} }
def worker_e_step input_queue result_queue logger.debug 'workerprocessenteringE-steploop' while True logger.debug 'gettinganewjob' chunk_no chunk worker_lda input_queue.get logger.debug 'processingchunk#%iof%idocuments' chunk_no len chunk worker_lda.state.reset worker_lda.do_estep chunk del chunklogger.debug 'processedchunk queuingtheresult' result_queue.put worker_lda.state del worker_ldalogger.debug 'resultput'
def _relpath path start '.' if not path raise ValueError 'nopathspecified' startList os.path.abspath start .split os.path.sep pathList os.path.abspath path .split os.path.sep i len os.path.commonprefix [startList pathList] relList ['..'] * len startList - i + pathList[i ] if not relList return pathreturn os.path.join *relList
def construct_mirror_name volume return 'mirror_' + six.text_type volume.id
def assert_array_max_ulp a b maxulp 1 dtype None numpy.testing.assert_array_max_ulp cupy.asnumpy a cupy.asnumpy b maxulp maxulp dtype dtype
def _map_to_list game_map list_map game_map.split '\n' return [ character.decode 'UTF-8' if isinstance character basestring else character for character in list_map]
def serviceCommand methodName cmdClass ServiceWrapperCommand def wrapper obj journal *args **kwargs return journal.executeCommand cmdClass methodName args kwargs return wrapper
def _build_offset offset kwargs default if offset is None if not kwargs return defaultelse return _td_check datetime.timedelta **kwargs elif kwargs raise ValueError 'Cannotpasskwargsandanoffset' elif isinstance offset datetime.timedelta return _td_check offset else raise TypeError "Mustpass'hours'and/or'minutes'askeywords"
def has_required_keys xblock for key in 'discussion_id' 'discussion_category' 'discussion_target' if getattr xblock key None is None log.debug "Requiredkey'%s'notindiscussion%s leavingoutofcategorymap" key xblock.location return Falsereturn True
@add_to_dict _after_create_functions def after_VBD_create vbd_ref vbd_rec vbd_rec['currently_attached'] Falsevbd_rec['device'] ''vbd_rec.setdefault 'other_config' {} vm_ref vbd_rec['VM']vm_rec _db_content['VM'][vm_ref]vm_rec['VBDs'].append vbd_ref vm_name_label _db_content['VM'][vm_ref]['name_label']vbd_rec['vm_name_label'] vm_name_labelvdi_ref vbd_rec['VDI']if vdi_ref and vdi_ref ! 'OpaqueRef NULL' vdi_rec _db_content['VDI'][vdi_ref]vdi_rec['VBDs'].append vbd_ref
def identify_format origin data_class_required path fileobj args kwargs valid_formats []for data_format data_class in _identifiers if _is_best_match data_class_required data_class _identifiers if _identifiers[ data_format data_class ] origin path fileobj *args **kwargs valid_formats.append data_format return valid_formats
def get_messages_from_page name return _get_messages_from_page_or_report u'Page' name
def extra_padding_y_keep_ratio original_size padding return _resize original_size 1 padding padding keep_aspect_ratio True
def get_all_vlanids LOG.debug _ 'get_all_vlanids called' session db.get_session try vlanids session.query network_models_v2.VlanID .all return vlanidsexcept exc.NoResultFound return []
def countNonPrintableChars string counter 0for i in range len string if ord string[i] < 31 or ord string[i] > 127 counter + 1return counter
def kill_pid pid signal 15 try psutil.Process pid .send_signal signal return Trueexcept psutil.NoSuchProcess return False
def for_all_dtypes name 'dtype' no_float16 False no_bool False return for_dtypes _make_all_dtypes no_float16 no_bool name name
def mapping_file_to_dict mapping_data header map_dict {}for i in range len mapping_data sam mapping_data[i]map_dict[sam[0]] {}for j in range len header if j 0 continuemap_dict[sam[0]][header[j]] sam[j]return map_dict
def is_jid jid if not isinstance jid six.string_types return Falseif len jid ! 20 return Falsetry int jid return Trueexcept ValueError return False
def _patched_list_steps emr_conn *args **kwargs try boto.emr.emrobject.ClusterTimeline _PatchedClusterTimelinereturn emr_conn.list_steps *args **kwargs finally boto.emr.emrobject.ClusterTimeline ClusterTimeline
def is_list_of_ints intlist if not isinstance intlist list return Falsefor i in intlist if not isinstance i int return Falsereturn True
def in6_isaddr6to4 x x inet_pton socket.AF_INET6 x return x[ 2] '\x02'
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def new_figure_manager_given_figure num figure canvas FigureCanvasMac figure manager FigureManagerMac canvas num return manager
def generate_presigned_url self ClientMethod Params None ExpiresIn 3600 HttpMethod None client_method ClientMethodparams Paramsexpires_in ExpiresInhttp_method HttpMethodrequest_signer self._request_signerserializer self._serializertry operation_name self._PY_TO_OP_NAME[client_method]except KeyError raise UnknownClientMethodError method_name client_method operation_model self.meta.service_model.operation_model operation_name request_dict serializer.serialize_to_request params operation_model if http_method is not None request_dict['method'] http_methodprepare_request_dict request_dict endpoint_url self.meta.endpoint_url return request_signer.generate_presigned_url request_dict request_dict expires_in expires_in operation_name operation_name
def oo_random_word length source 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' return ''.join random.choice source for i in range length
def _get_info_slice obj indexer if not hasattr obj '_info_axis_number' raise TypeError 'objectoftype%rhasnoinfoaxis' % type obj .__name__ slices [slice None ] * obj.ndim slices[obj._info_axis_number] indexerreturn tuple slices
def add_key_to_url url scheme key query request.args.to_dict query['view_only'] keyreplacements {'query' urllib.urlencode query }if scheme replacements['scheme'] schemeparsed_url urlparse.urlparse url if parsed_url.fragment replacements['path'] '{}%23{}'.format parsed_url.path parsed_url.fragment replacements['fragment'] ''parsed_redirect_url parsed_url._replace **replacements return urlparse.urlunparse parsed_redirect_url
def batch_indices batch_nb data_length batch_size start int batch_nb * batch_size end int batch_nb + 1 * batch_size if end > data_length shift end - data_length start - shiftend - shiftreturn start end
def recreate_tags_from_list list_of_tags tags list i 0list_of_tags list_of_tagsfor i in range len list_of_tags key_name list_of_tags[i][0]key_val list_of_tags[i][1]tags.append {'Key' key_name 'Value' key_val} return tags
def get_base_domain url domain get_domain url tld '.'.join domain.split '.' [ -2 ] if tld in ['co.uk' 'com.au' 'au.com'] end_chunks domain.split '.' [ -3 ]else end_chunks domain.split '.' [ -2 ]base_domain '.'.join end_chunks return base_domain
def relativize_classpath classpath root_dir followlinks True def relativize_url url root_dir url os.path.realpath url if followlinks else url root_dir os.path.realpath root_dir if followlinks else root_dir url_in_bundle os.path.relpath url root_dir if os.path.isdir url url_in_bundle + u'/'return url_in_bundlereturn [relativize_url url root_dir for url in classpath]
