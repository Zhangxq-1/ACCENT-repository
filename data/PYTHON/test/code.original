def resource_patch context data_dict _check_access 'resource_patch' context data_dict show_context {'model' context['model'] 'session' context['session'] 'user' context['user'] 'auth_user_obj' context['auth_user_obj']}resource_dict _get_action 'resource_show' show_context {'id' _get_or_bust data_dict 'id' } patched dict resource_dict patched.update data_dict return _update.resource_update context patched
def pyramid_laplacian image max_layer -1 downscale 2 sigma None order 1 mode 'reflect' cval 0 _check_factor downscale image img_as_float image if sigma is None sigma 2 * downscale / 6.0 layer 0rows image.shape[0]cols image.shape[1]smoothed_image _smooth image sigma mode cval yield image - smoothed_image while layer ! max_layer layer + 1out_rows math.ceil rows / float downscale out_cols math.ceil cols / float downscale resized_image resize smoothed_image out_rows out_cols order order mode mode cval cval smoothed_image _smooth resized_image sigma mode cval prev_rows rowsprev_cols colsrows resized_image.shape[0]cols resized_image.shape[1]if prev_rows rows and prev_cols cols break yield resized_image - smoothed_image
def get_svc_avail_path return AVAIL_SVR_DIRS
def unhex s bits 0for c in s c bytes c if '0' < c < '9' i ord '0' elif 'a' < c < 'f' i ord 'a' - 10 elif 'A' < c < 'F' i ord 'A' - 10 else assert False 'non-hexdigit' + repr c bits bits * 16 + ord c - i return bits
def walk top topdown True followlinks False names os.listdir top dirs nondirs [] [] for name in names if path.isdir path.join top name dirs.append name else nondirs.append name if topdown yield top dirs nondirs for name in dirs fullpath path.join top name if followlinks or not path.islink fullpath for x in walk fullpath topdown followlinks yield x if not topdown yield top dirs nondirs
def url_filename url match upload_title_re.match url if match return match.group 'filename' else return url
def get_preamble latex_preamble rcParams.get u'pgf.preamble' u'' if type latex_preamble list latex_preamble u'\n'.join latex_preamble return latex_preamble
def sdm_spoly f g O K phantom None if not f or not g return sdm_zero LM1 sdm_LM f LM2 sdm_LM g if LM1[0] ! LM2[0] return sdm_zero LM1 LM1[1 ]LM2 LM2[1 ]lcm monomial_lcm LM1 LM2 m1 monomial_div lcm LM1 m2 monomial_div lcm LM2 c K.quo - sdm_LC f K sdm_LC g K r1 sdm_add sdm_mul_term f m1 K.one O K sdm_mul_term g m2 c O K O K if phantom is None return r1r2 sdm_add sdm_mul_term phantom[0] m1 K.one O K sdm_mul_term phantom[1] m2 c O K O K return r1 r2
def analyze_modules project task_handle taskhandle.NullTaskHandle resources project.get_python_files job_set task_handle.create_jobset 'AnalyzingModules' len resources for resource in resources job_set.started_job resource.path analyze_module project resource job_set.finished_job
def get_sw_login_version return '-'.join get_sw_version strip_build_num True .split '-' [1 -2 ]
def SetHelpMenuOtherHelp mainMenu global helpIDMapif helpIDMap is None helpIDMap {}cmdID win32ui.ID_HELP_OTHERexcludeList ['MainPythonDocumentation' 'PythonwinReference']firstList ListAllHelpFiles excludeFnames []for desc fname in firstList if desc in excludeList excludeFnames.append fname helpDescs []for desc fname in firstList if fname not in excludeFnames helpIDMap[cmdID] desc fname win32ui.GetMainFrame .HookCommand HandleHelpOtherCommand cmdID cmdID cmdID + 1 helpMenu mainMenu.GetSubMenu mainMenu.GetMenuItemCount - 1 otherHelpMenuPos 2otherMenu helpMenu.GetSubMenu otherHelpMenuPos while otherMenu.GetMenuItemCount otherMenu.DeleteMenu 0 win32con.MF_BYPOSITION if helpIDMap for id desc fname in helpIDMap.iteritems otherMenu.AppendMenu win32con.MF_ENABLED | win32con.MF_STRING id desc else helpMenu.EnableMenuItem otherHelpMenuPos win32con.MF_BYPOSITION | win32con.MF_GRAYED
def to location code falcon.HTTP_302 raise falcon.http_status.HTTPStatus code {'location' location}
def select_command corrected_commands try selector CommandSelector corrected_commands except NoRuleMatched logs.failed 'Nofucksgiven' returnif not settings.require_confirmation logs.show_corrected_command selector.value return selector.valuelogs.confirm_text selector.value for action in read_actions if action const.ACTION_SELECT sys.stderr.write '\n' return selector.valueelif action const.ACTION_ABORT logs.failed '\nAborted' returnelif action const.ACTION_PREVIOUS selector.previous logs.confirm_text selector.value elif action const.ACTION_NEXT selector.next logs.confirm_text selector.value
def partial_project endog exog x1 x2 endog exog params np.linalg.pinv x2 .dot x1 predicted x2.dot params residual x1 - predicted res Bunch params params fittedvalues predicted resid residual return res
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def testOnSequenceData module dataset target dataset.getField 'target' output ModuleValidator.calculateModuleOutput module dataset ends SequenceHelper.getSequenceEnds dataset summed_output zeros dataset.outdim class_output []class_target []for j in range len output summed_output + output[j]if j in ends class_output.append argmax summed_output class_target.append argmax target[j] summed_output zeros dataset.outdim class_output array class_output class_target array class_target return Validator.classificationPerformance class_output class_target
def getPath edges pathIndexes loop z path []for pathIndexIndex in xrange len pathIndexes pathIndex pathIndexes[pathIndexIndex]edge edges[pathIndex]carveIntersection getCarveIntersectionFromEdge edge loop z path.append carveIntersection return path
def _has_required_botocore if not HAS_BOTO return Falseelif LooseVersion botocore.__version__ < LooseVersion required_botocore_version return Falseelse return True
def config_option_show context data_dict return {'success' False}
@preserve_value sys 'dont_write_bytecode' def _load_module_no_bytecode filename module_file module_file_path py_source_description sys.dont_write_bytecode 1new_module imp.load_module os.path.splitext filename [0].replace '-' '_' module_file module_file_path py_source_description return new_module
def populate_tables db prefix tmp_prefix bounds bbox 'ST_SetSRID ST_MakeBox2D ST_MakePoint %.6f %.6f ST_MakePoint %.6f %.6f 900913 ' % bounds db.execute 'BEGIN' for table in 'point' 'line' 'roads' 'polygon' db.execute 'DELETEFROM% prefix s_% table sWHEREST_Intersects way % bbox s ' % locals db.execute 'INSERTINTO% prefix s_% table s\nSELECT*FROM% tmp_prefix s_% table s\nWHEREST_Intersects way % bbox s ' % locals db.execute 'COMMIT'
def is_1pexp t only_process_constants True if t.owner and t.owner.op tensor.add scalars scalar_inputs nonconsts opt.scalarconsts_rest t.owner.inputs only_process_constants only_process_constants if len nonconsts 1 maybe_exp nonconsts[0]if maybe_exp.owner and maybe_exp.owner.op tensor.exp if scalars scal_sum scalars[0]for s in scalars[1 ] scal_sum scal_sum + s if numpy.allclose scal_sum 1 return False maybe_exp.owner.inputs[0] if config.warn.identify_1pexp_bug warnings.warn "Althoughyourcurrentcodeisfine pleasenotethatTheanoversionspriorto0.5 morespecifically priortocommit7987b51on2011-12-18 mayhaveyieldedanincorrectresult.Toremovethiswarning eithersetthe`warn.identify_1pexp_bug`configoptiontoFalse or`warn.ignore_bug_before`toatleast'0.4.1'." return None
def round_if_near_integer a epsilon 0.0001 if abs a - round a < epsilon return round a else return a
def make_msgid idstring None timeval time.time utcdate time.strftime '%Y%m%d%H%M%S' time.gmtime timeval pid os.getpid randint random.randrange 100000 if idstring is None idstring ''else idstring '.' + idstring idhost socket.getfqdn msgid '<%s.%s.%s%s@%s>' % utcdate pid randint idstring idhost return msgid
def get_linode_id_from_name name nodes _query 'linode' 'list' ['DATA']linode_id ''for node in nodes if name node['LABEL'] linode_id node['LINODEID']return linode_idif not linode_id raise SaltCloudNotFound 'Thespecifiedname {0} couldnotbefound.'.format name
def did_you_mean_units s all_units deprecated_units format_decomposed def fix_deprecated x if x in deprecated_units results [ x + u' deprecated ' ]decomposed _try_decomposed all_units[x] format_decomposed if decomposed is not None results.append decomposed return resultsreturn x return did_you_mean s all_units fix fix_deprecated
def is_classifier estimator return getattr estimator '_estimator_type' None 'classifier'
def _get_objects obj_type lst_objs FakeRetrieveResult for key in _db_content[obj_type] lst_objs.add_object _db_content[obj_type][key] return lst_objs
def expandvars path global _varprogif '$' not in path return pathif not _varprog import re_varprog re.compile '\\$ \\w+|\\{[^}]*\\} ' i 0while True m _varprog.search path i if not m break i j m.span 0 name m.group 1 if name.startswith '{' and name.endswith '}' name name[1 -1 ]if name in os.environ tail path[j ]path path[ i] + os.environ[name] i len path path + tailelse i jreturn path
def getNewRepository return FillRepository
def ValidateActionsInTarget target target_dict build_file target_name target_dict.get 'target_name' actions target_dict.get 'actions' [] for action in actions action_name action.get 'action_name' if not action_name raise GypError "Anonymousactionintarget%s.Anactionmusthavean'action_name'field." % target_name inputs action.get 'inputs' None if inputs is None raise GypError 'Actionintarget%shasnoinputs.' % target_name action_command action.get 'action' if action_command and not action_command[0] raise GypError 'Emptyactionascommandintarget%s.' % target_name
def match_hostname cert hostname if not cert raise ValueError u'emptyornocertificate' dnsnames []san cert.get u'subjectAltName' for key value in san if key u'DNS' if _dnsname_match value hostname returndnsnames.append value if not dnsnames for sub in cert.get u'subject' for key value in sub if key u'commonName' if _dnsname_match value hostname returndnsnames.append value if len dnsnames > 1 raise CertificateError u"hostname%rdoesn'tmatcheitherof%s" % hostname u' '.join map repr dnsnames elif len dnsnames 1 if sys.version_info[ 3] < 2 7 3 and dnsnames[0] u'calibre-ebook.com' returnraise CertificateError u"hostname%rdoesn'tmatch%r" % hostname dnsnames[0] else raise CertificateError u'noappropriatecommonNameorsubjectAltNamefieldswerefound'
def gf_quo_ground f a p K return gf_mul_ground f K.invert a p p K
def _do_search conf connargs {}for name in ['server' 'port' 'tls' 'binddn' 'bindpw' 'anonymous'] connargs[name] _config name conf if connargs['binddn'] and connargs['bindpw'] connargs['anonymous'] Falsetry _filter conf['filter']except KeyError raise SaltInvocationError 'missingfilter' _dn _config 'dn' conf scope _config 'scope' conf _lists _config 'lists' conf or [] _attrs _config 'attrs' conf or [] attrs _lists + _attrs if not attrs attrs Nonetry result __salt__['ldap.search'] _filter _dn scope attrs **connargs ['results']except IndexError log.debug 'LDAPsearchreturnednoresultsforfilter{0}'.format _filter result {}except Exception log.critical 'FailedtoretrievepillardatafromLDAP \n' exc_info True return {}return result
def test_rus_fit rus RandomUnderSampler random_state RND_SEED rus.fit X Y assert_equal rus.min_c_ 0 assert_equal rus.maj_c_ 1 assert_equal rus.stats_c_[0] 3 assert_equal rus.stats_c_[1] 7
def MissingMetricsCriteria return [] []
def FlagOverrider **flag_kwargs def Decorator f 'Allowafunctiontosafelychangeflags restoringthemonreturn.'def Decorated *args **kwargs global FLAGSold_flags copy.copy FLAGS for k v in flag_kwargs.items setattr FLAGS k v try return f *args **kwargs finally FLAGS old_flagsreturn Decoratedreturn Decorator
def follow_link connection link if link return connection.follow_link link else return None
def add_arg f *args **kwargs if not hasattr f 'arguments' f.arguments []if args kwargs not in f.arguments f.arguments.insert 0 args kwargs
def singleton cls instances {}def getinstance if cls not in instances instances[cls] cls return instances[cls]return getinstance
def _get_pseudo_pgp_block remaining_contents if not remaining_contents return Noneblock_match PGP_BLOCK_START.match remaining_contents[0] if block_match block_type block_match.groups [0]block_lines []end_line PGP_BLOCK_END % block_type while True if not remaining_contents raise ValueError "Unterminatedpgpstyleblock lookingfor'%s' \n%s" % end_line '\n'.join block_lines line remaining_contents.pop 0 block_lines.append line if line end_line return block_type '\n'.join block_lines else return None
def plugin_cache_dir return os.path.join tempfile.gettempdir 'UltiSnips_test_vim_plugins'
def after_script destroy_cmd ['terraform' 'destroy' '-force']logging.info 'Destroyingcloudproviderresources' sys.exit run_cmd destroy_cmd
def standard_b64encode s return b64encode s
def import_buffer_to_ast buf module_name return hy_compile import_buffer_to_hst buf module_name
def merge_with func *dicts **kwargs if len dicts 1 and not isinstance dicts[0] dict dicts dicts[0]factory _get_factory merge_with kwargs result factory for d in dicts for k v in iteritems d if k not in result result[k] [v]else result[k].append v return valmap func result factory
def textListToColorsSimple names uNames list set names uNames.sort textToColor [uNames.index n for n in names]textToColor np.array textToColor textToColor 255 * textToColor - textToColor.min / textToColor.max - textToColor.min textmaps generateColorMap colors [textmaps[int c ] for c in textToColor]return colors
def multidict_to_dict multidict if config.AUTO_COLLAPSE_MULTI_KEYS d dict multidict.lists for key value in d.items if len value 1 d[key] value[0]return delse return multidict.to_dict
def get_can_enable_ldap if has_module u'ldap' return True None else return False _ u'LDAPauthenticationrequiresthepython-ldaplibrary whichisnotinstalled.'
def get_ident return -1
def agent_leave consul_url None node None ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not node raise SaltInvocationError 'Requiredargument"node"ismissing.' function 'agent/force-leave/{0}'.format node res _query consul_url consul_url function function method 'GET' query_params query_params if res['res'] ret['res'] Trueret['message'] 'Node{0}putinleavestate.'.format node else ret['res'] Falseret['message'] 'Unabletochangestatefor{0}.'.format node return ret
def task_cli_pip_prereqs package_manager if package_manager in 'dnf' 'yum' return yum_install PIP_CLI_PREREQ_YUM package_manager package_manager sudo True elif package_manager 'apt' return sequence [apt_get_update sudo True apt_get_install PIP_CLI_PREREQ_APT sudo True ] else raise UnsupportedDistribution
def count_values expr sort True result by expr count expr.count if sort result result.sort 'count' ascending False return result
def pairwise_most_common sets from sympy.utilities.iterables import subsetsfrom collections import defaultdictmost -1 for i j in subsets list range len sets 2 com sets[i] & sets[j] if com and len com > most best defaultdict list best_keys []most len com if len com most if com not in best_keys best_keys.append com best[best_keys.index com ].append i j if most -1 return []for k in range len best best_keys[k] best_keys[k] best[k] best_keys.sort key lambda x len x[1] return best_keys
def skip reason def decorator test_item if isinstance test_item type and issubclass test_item TestCase test_item.__unittest_skip__ Truetest_item.__unittest_skip_why__ reasonreturn test_item@functools_copy.wraps test_item def skip_wrapper *args **kwargs raise SkipTest reason return skip_wrapperreturn decorator
def jet rc 'image' cmap 'jet' im gci if im is not None im.set_cmap cm.jet draw_if_interactive
def pperm accessing_obj accessed_obj *args **kwargs return perm _to_player accessing_obj accessed_obj *args **kwargs
def reconn_notice guide light_magenta 'Youcanuse' + light_green 'switch' + light_magenta 'commandtoreturntoyourstream.\n' guide + light_magenta 'Type' + light_green 'hstream' + light_magenta 'formoredetails.' printNicely guide sys.stdout.write g['decorated_name'] g['PREFIX'] sys.stdout.flush
def runproc cmd proc Popen [cmd] shell True stdin PIPE stdout PIPE stderr PIPE close_fds True stdoutdata stderrdata proc.communicate return stdoutdata stderrdata
def convert_unreachable_exception e error_format u'Facebookisunreachable%s' exception_class map_unreachable_exception e error_message error_format % str e exception exception_class error_message return exception
def init_pool_worker signal.signal signal.SIGINT signal.SIG_IGN
def count_ngrams text max_ngram_size stop_words if not isinstance stop_words set stop_words set stop_words words [word.lower for word in WORD_RE.findall text if word.lower not in stop_words ]ngram_counts defaultdict int for i in range len words for n in range 1 max_ngram_size + 1 if i + n < len words ngram ''.join words[i i + n ] ngram_counts[ n ngram ] + 1for n in range 1 max_ngram_size + 1 ngram_counts[ n None ] len words - n + 1 return ngram_counts
def FormatCode unformatted_source filename '<unknown>' style_config None lines None print_diff False verify False _CheckPythonVersion style.SetGlobalStyle style.CreateStyleFromConfig style_config if not unformatted_source.endswith '\n' unformatted_source + '\n'tree pytree_utils.ParseCodeToTree unformatted_source comment_splicer.SpliceComments tree continuation_splicer.SpliceContinuations tree subtype_assigner.AssignSubtypes tree split_penalty.ComputeSplitPenalties tree blank_line_calculator.CalculateBlankLines tree uwlines pytree_unwrapper.UnwrapPyTree tree for uwl in uwlines uwl.CalculateFormattingInformation _MarkLinesToFormat uwlines lines reformatted_source reformatter.Reformat uwlines verify if unformatted_source reformatted_source return '' if print_diff else reformatted_source False code_diff _GetUnifiedDiff unformatted_source reformatted_source filename filename if print_diff return code_diff code_diff ! '' return reformatted_source True
@step 'Iwillconfirmallalerts' def i_confirm_all_alerts step world.browser.execute_script 'window.confirm function {returntrue;};window.alert function {return;}'
def test_ranking_ignores_identifier_quotes completer text u'user'collection [u'user_action' u'"user"']matches completer.find_matches text collection assert len matches 2
def token_urlsafe nbytes None tok token_bytes nbytes return base64.urlsafe_b64encode tok .rstrip ' ' .decode 'ascii'
def saturated color factor 150 h color.hsvHueF s color.hsvSaturationF v color.valueF a color.alphaF s factor * s / 100.0 s max min 1.0 s 0.0 return QColor.fromHsvF h s v a .convertTo color.spec
def _absolute_path path relative_to None if path and os.path.isabs path return pathif path and relative_to is not None _abspath os.path.join relative_to path if os.path.isfile _abspath log.debug "Relativepath'{0}'convertedtoexistingabsolutepath'{1}'".format path _abspath return _abspathreturn path
def lonlat2grid lon lat return '%d%s' % lon2zone lon lat2zone lat
def create_continuous_query database name query **client_args client _client **client_args full_query 'CREATECONTINUOUSQUERY{0}ON{1}BEGIN{2}END'query full_query.format name database query client.query query return True
def iso_now now datetime.datetime.now return '%s.%06d' % now.strftime '%Y%m%d.%H%M%S' now.microsecond
@flaskbb.group def plugins pass
def idz_frmi m return _id.idz_frmi m
def run_gdb *args **env_vars if env_vars env os.environ.copy env.update env_vars else env Nonebase_cmd 'gdb' '--batch' if gdb_major_version gdb_minor_version > 7 4 base_cmd + '-iex' 'add-auto-load-safe-path' + checkout_hook_path out err subprocess.Popen base_cmd + args stdout subprocess.PIPE stderr subprocess.PIPE env env .communicate return out err
def get_fasta_labels input_fasta_fp fasta_labels []fasta_f open input_fasta_fp 'U' for label seq in parse_fasta fasta_f fasta_labels.append label.split [0] return fasta_labels
def n_to_one arr return where arr 1 [0][0]
def _AuthFunction host email passin raw_input_fn password_input_fn if not email print 'Pleaseenterlogincredentialsfor%s' % host email raw_input_fn 'Email ' if email password_prompt 'Passwordfor%s ' % email if passin password raw_input_fn password_prompt else password password_input_fn password_prompt else password Nonereturn email password
def _openbsd_remotes_on port which_end remotes set try data subprocess.check_output ['netstat' '-nf' 'inet'] except subprocess.CalledProcessError log.error 'Failednetstat' raiselines data.split '\n' for line in lines if 'ESTABLISHED' not in line continuechunks line.split local_host local_port chunks[3].rsplit '.' 1 remote_host remote_port chunks[4].rsplit '.' 1 if which_end 'remote_port' and int remote_port ! port continueif which_end 'local_port' and int local_port ! port continueremotes.add remote_host return remotes
def lpmerge L R setitem L.__setitem__[setitem k v for k v in items R if v is not None ]return L
def cleanup_version sender instance **kw if kw.get 'raw' returnfor file_ in instance.files.all cleanup_file file_.__class__ file_
def flatten_list list_of_list [[] []] return sum list_of_list []
def _tosequence X if isinstance X Mapping return [X]else return tosequence X
def check_path_traversal path user 'root' skip_perm_errors False for tpath in list_path_traversal path if not os.access tpath os.R_OK msg 'Couldnotaccess{0}.'.format tpath if not os.path.exists tpath msg + 'Pathdoesnotexist.'else current_user salt.utils.get_user if user ! current_user msg + 'Tryrunningasuser{0}.'.format user else msg + 'Pleasegive{0}readpermissions.'.format user if skip_perm_errors returnraise SaltClientError msg
def htmlsafe_json_dumps obj dumper None **kwargs if dumper is None dumper json.dumpsrv dumper obj **kwargs .replace u'<' u'\\u003c' .replace u'>' u'\\u003e' .replace u'&' u'\\u0026' .replace u"'" u'\\u0027' return rv
def _resp_status_property def getter self return '%s%s' % self.status_int self.title def setter self value if isinstance value int long self.status_int valueself.explanation self.title RESPONSE_REASONS[value][0]else if isinstance value unicode value value.encode 'utf-8' self.status_int int value.split '' 1 [0] self.explanation self.title value.split '' 1 [1]return property getter setter doc "RetrieveandsettheResponsestatus e.g.'200OK'"
def _absolute_flat_glob pattern dirname basename os.path.split pattern if basename if os.path.exists pattern yield pattern elif os.path.isdir dirname yield pattern return
def camel_to_underscore name import stringfor c in string.ascii_uppercase name name.replace c '_%c' % c return name.strip '_' .lower
def filter_sff_reads sff_data ids_to_keep None ids_to_remove None header reads sff_dataif ids_to_keep is not None reads [r for r in reads if r['Name'] in ids_to_keep ]if ids_to_remove is not None reads [r for r in reads if r['Name'] not in ids_to_remove ]header['number_of_reads'] len reads return header reads
def binary_search_std_lib sorted_collection item index bisect.bisect_left sorted_collection item if index ! len sorted_collection and sorted_collection[index] item return indexreturn None
def test_rechunk_1d a np.random.uniform 0 1 300 x da.from_array a chunks 100 * 3 new 50 * 6 x2 rechunk x chunks new assert x2.chunks new assert np.all x2.compute a
def memoized_method func None key_factory per_instance **kwargs return memoized func func key_factory key_factory **kwargs
def rekey db packer n 0while 1 m _rekey_one_batch db packer if m 0 breakn + mreturn n
def _Filters return _cpplint_state.filters
def placeholder *args **kwargs warnings.simplefilter 'default' DeprecationWarning warnings.warn 'ed.placeholder isdeprecated;usetf.placeholder instead.' DeprecationWarning x tf.placeholder *args **kwargs tf.add_to_collection 'PLACEHOLDERS' x return x
def libvlc_media_get_duration p_md f _Cfunctions.get 'libvlc_media_get_duration' None or _Cfunction 'libvlc_media_get_duration' 1 None ctypes.c_longlong Media return f p_md
def initializeZoneIntervalTable shape vertexes shape.zoneInterval shape.layerThickness / math.sqrt len vertexes / 1000.0 shape.zZoneTable {}for point in vertexes addToZoneTable point shape
def invitation_detail request token invitation Invitation.objects.get_invitation token if not invitation return invitation_error request 'Thisinvitationisnolongervalid.' backend getattr settings 'REGISTRATION_BACKEND' 'registration.backends.default.DefaultBackend' return register request backend
def pipeline_code_wrapper pipeline_code return '\nexported_pipeline {}\n\nexported_pipeline.fit training_features training_classes \nresults exported_pipeline.predict testing_features \n'.format pipeline_code
def expand_to_match items cfg2newlines {}for configuration lines in items cfg2newlines[configuration] []maxguard 2 ** 30 while True minimalsourceline maxguardfor configuration lines in items if lines minimalsourceline min minimalsourceline lines[0].sourceline if minimalsourceline maxguard breakfor configuration lines in items if lines and lines[0].sourceline < minimalsourceline cfg2newlines[configuration].append lines[0] del lines[0]number_of_lines max len x for x in cfg2newlines.values for newlines in cfg2newlines.values add number_of_lines - len newlines newlines.extend ['\n'] * add return cfg2newlines
def is_suppressed_warning type subtype suppress_warnings if type is None return Falsefor warning_type in suppress_warnings if '.' in warning_type target subtarget warning_type.split '.' 1 else target subtarget warning_type None if target type if subtype is None or subtarget is None or subtarget subtype or subtarget '*' return Truereturn False
def first_nibble_hex_encoding t parts []for c in t x y _get_nibbles c parts.append '%%%X%s' % ord x y return '%' + '%'.join parts
def test_should_report_both_errors_and_warnings_negative expected [ 'cannotassigntoNone' 'None' -1 Error 'Variableaassignedbeforeglobaldeclaration' 'globala' -1 Warning ]code 'None 2\ndeffoo \na 2\nglobala'AssertError AssertionError AreEqual expected compile_file code
def p_constant_expression_opt_2 t pass
def get_best_match target_name names exact []wildcard_start []wildcard_end []regex []for name in names if _exact_match target_name name exact.append name elif _wildcard_match target_name name True wildcard_start.append name elif _wildcard_match target_name name False wildcard_end.append name elif _regex_match target_name name regex.append name if len exact > 0 match min exact key len return 'exact' match if len wildcard_start > 0 match max wildcard_start key len return 'wildcard_start' match if len wildcard_end > 0 match max wildcard_end key len return 'wildcard_end' match if len regex > 0 match regex[0]return 'regex' match return None None
def parse_test_files_option opt opt str opt if ' ' in opt f_name rest opt.split ' ' 1 return f_name list map int rest.split ' ' else return opt []
@get '/admin/<taskid>/flush' def task_flush taskid if is_admin taskid DataStore.tasks dict else for key in list DataStore.tasks if DataStore.tasks[key].remote_addr request.remote_addr del DataStore.tasks[key]logger.debug '[%s]Flushedtaskpool %s ' % taskid 'admin' if is_admin taskid else request.remote_addr return jsonize {'success' True}
def test_comparision_with_c raw events _get_data [ 2]c_evoked read_evokeds evoked_nf_name condition 0 epochs Epochs raw events event_id tmin tmax baseline None preload True proj False evoked epochs.set_eeg_reference .apply_proj .average sel pick_channels c_evoked.ch_names evoked.ch_names evoked_data evoked.datac_evoked_data c_evoked.data[sel]assert_true evoked.nave c_evoked.nave assert_array_almost_equal evoked_data c_evoked_data 10 assert_array_almost_equal evoked.times c_evoked.times 12
def mw_boot x y num_reps 999 tol MACHEP * 100 observed_stat obs_p mw_t x y u_stats_as_or_more_extreme 0for sampled_x sampled_y in _get_bootstrap_sample x y num_reps try sample_stat sample_p mw_t sampled_x sampled_y if sample_stat < observed_stat - tol u_stats_as_or_more_extreme + 1except ValueError passreturn observed_stat u_stats_as_or_more_extreme + 1 / num_reps + 1
def _get_target_ch container target picks pick_channels container.ch_names include [target] ref_picks pick_types container.info meg False eeg False ref_meg True if len ref_picks > 0 picks list set picks - set ref_picks if len picks 0 raise ValueError '%snotinchannellist %s ' % target container.ch_names return picks
def graph_atlas_g return list _generate_graphs
def num_cpus try return psutil.cpu_count except AttributeError return psutil.NUM_CPUS
def which program def is_exe fpath return os.path.isfile fpath and os.access fpath os.X_OK fpath fname os.path.split program if fpath if is_exe program return programelse for path in os.environ['PATH'].split os.pathsep exe_file os.path.join path program if is_exe exe_file return exe_file
def ParseAndUnwrap code dumptree False tree pytree_utils.ParseCodeToTree code comment_splicer.SpliceComments tree continuation_splicer.SpliceContinuations tree subtype_assigner.AssignSubtypes tree split_penalty.ComputeSplitPenalties tree blank_line_calculator.CalculateBlankLines tree if dumptree pytree_visitor.DumpPyTree tree target_stream sys.stderr uwlines pytree_unwrapper.UnwrapPyTree tree for uwl in uwlines uwl.CalculateFormattingInformation return uwlines
def iri_to_uri iri if iri is None return irireturn quote force_bytes iri safe "/#%[] ;$& + !?*@'~"
def string_from_module module variable None default None val variable_from_module module variable variable default default if val if variable return valelse result [v for v in make_iter val if isinstance v basestring ]return result if result else default return default
def _upload param_dict timeout data param_dict['format'] 'json'param_dict['wait'] 'true'param_dict['bucket'] 'audio_summary'result util.callm 'track/upload' param_dict POST True socket_timeout 300 data data return _track_from_response result timeout
def TestData parent None source None include_suites None warn_on_skipped False extensions None if os.path.isdir source return TestDataDirectory parent source .populate include_suites warn_on_skipped extensions return TestCaseFile parent source .populate
def _check_reg_match sss_py sss_mf comp_tol info_py sss_py.info['proc_history'][0]['max_info']['sss_info']assert_true info_py is not None assert_true len info_py > 0 info_mf sss_mf.info['proc_history'][0]['max_info']['sss_info']n_in Nonefor inf in info_py info_mf if n_in is None n_in _get_n_moments inf['in_order'] else assert_equal n_in _get_n_moments inf['in_order'] assert_equal inf['components'][ n_in].sum inf['nfree'] assert_allclose info_py['nfree'] info_mf['nfree'] atol comp_tol err_msg sss_py._filenames[0]
def safe_int val allow_zero True try ret int val except ValueError print "Sorry '%s'isnotavalidinteger." % val return Falseif not allow_zero and ret 0 print 'Pleaseenteranon-zerointeger.' return Falsereturn ret
def pearsonr x y x np.asarray x y np.asarray y n len x mx x.mean my y.mean xm ym x - mx y - my r_num np.add.reduce xm * ym r_den np.sqrt _sum_of_squares xm * _sum_of_squares ym r r_num / r_den r max min r 1.0 -1.0 df n - 2 if abs r 1.0 prob 0.0else t_squared r ** 2 * df / 1.0 - r * 1.0 + r prob _betai 0.5 * df 0.5 df / df + t_squared return r prob
def group_detail request slug template_name 'groups/group_detail.html' group get_object_or_404 Group slug slug is_active True if group.invite_only and not GroupMember.objects.is_member group request.user return redirect request reverse 'groups join' kwargs {'slug' group.slug} return render request template_name {'group' group 'topic_list' group.topics.all }
def has_access f if hasattr f '_permission_name' permission_str f._permission_nameelse permission_str f.__name__def wraps self *args **kwargs permission_str PERMISSION_PREFIX + f._permission_name if self.appbuilder.sm.has_access permission_str self.__class__.__name__ return f self *args **kwargs else log.warning LOGMSG_ERR_SEC_ACCESS_DENIED.format permission_str self.__class__.__name__ flash as_unicode FLAMSG_ERR_SEC_ACCESS_DENIED 'danger' return redirect url_for self.appbuilder.sm.auth_view.__class__.__name__ + '.login' f._permission_name permission_strreturn functools.update_wrapper wraps f
def shift_multi x wrg 0.1 hrg 0.1 is_random False row_index 0 col_index 1 channel_index 2 fill_mode 'nearest' cval 0.0 h w x[0].shape[row_index] x[0].shape[col_index] if is_random tx np.random.uniform - hrg hrg * h ty np.random.uniform - wrg wrg * w else tx ty hrg * h wrg * w translation_matrix np.array [[1 0 tx] [0 1 ty] [0 0 1]] transform_matrix translation_matrixresults []for data in x results.append apply_transform data transform_matrix channel_index fill_mode cval return np.asarray results
def _standardize structure def mutating_helper structure if isinstance structure list structure.sort key _id_or_key for each in structure mutating_helper each elif isinstance structure dict structure dict structure for k v in six.iteritems structure mutating_helper k mutating_helper v new_structure copy.deepcopy structure mutating_helper new_structure return new_structure
def slug_validator s ok SLUG_OK lower True spaces False delimiter '-' message validate_slug.message code validate_slug.code if not s and slugify s ok lower spaces delimiter s raise ValidationError message code code
def csrf request def _get_val token get_token request if token is None return 'NOTPROVIDED'else return force_text token return {'csrf_token' SimpleLazyObject _get_val }
def make_table_file lines labels dir_path filename lines.sort lines.insert 0 ' DCTB '.join labels output open os.path.join dir_path filename 'w' output.write '\n'.join lines output.close
def _htmldecode text if isinstance text str uchr chrelse def uchr value value > 127 and chr value or chr value def entitydecode match uchr uchr entity match.group 1 if entity.startswith u'#x' return uchr int entity[2 ] 16 elif entity.startswith u'#' return uchr int entity[1 ] elif entity in name2codepoint return uchr name2codepoint[entity] else return match.group 0 return charrefpat.sub entitydecode text
def mounts cmd 'mount'ret {}out __salt__['cmd.run_all'] cmd output out['stdout'].splitlines for line in output if not line continueif 'fuse.mfs' in line comps line.split '' info1 comps[0].split ' ' info2 info1[1].split '/' ret[comps[2]] {'remote' {'master' info1[0] 'port' info2[0] 'subfolder' '/' + info2[1] } 'local' comps[2] 'options' comps[5].replace ' ' '' .replace ' ' '' .split ' ' }return ret
def aware_utcnow return datetime.utcnow .replace tzinfo utc
@register u'menu-complete-backward' def menu_complete_backward event event.current_buffer.complete_previous
def _getFullPolicyName policy_item policy_name return_full_policy_names adml_data if policy_name in adm_policy_name_map[return_full_policy_names] return adm_policy_name_map[return_full_policy_names][policy_name]if return_full_policy_names and 'displayName' in policy_item.attrib fullPolicyName _getAdmlDisplayName adml_data policy_item.attrib['displayName'] if fullPolicyName adm_policy_name_map[return_full_policy_names][policy_name] fullPolicyNamepolicy_name fullPolicyNameelif return_full_policy_names and 'id' in policy_item.attrib fullPolicyName _getAdmlPresentationRefId adml_data policy_item.attrib['id'] if fullPolicyName adm_policy_name_map[return_full_policy_names][policy_name] fullPolicyNamepolicy_name fullPolicyNamepolicy_name policy_name.rstrip ' ' .rstrip return policy_name
def get_default_collection bus session None try return Collection bus except ItemNotFoundException return create_collection bus 'Default' 'default' session
def DEFINE_multichoice name default choices help CONFIG.AddOption type_info.MultiChoice name name default default choices choices description help
def _file_lines fname try outfile open fname except IOError return []else out outfile.readlines outfile.close return out
def get_git_revision repopath try git programs.find_program 'git' assert git is not None and osp.isdir osp.join repopath '.git' commit programs.run_program git ['rev-parse' '--short' 'HEAD'] cwd repopath .communicate commit commit[0].strip if PY3 commit commit.decode sys.getdefaultencoding branches programs.run_program git ['branch'] cwd repopath .communicate branches branches[0]if PY3 branches branches.decode sys.getdefaultencoding branches branches.split '\n' active_branch [b for b in branches if b.startswith '*' ]if len active_branch ! 1 branch Noneelse branch active_branch[0].split None 1 [1]return commit branch except subprocess.CalledProcessError AssertionError AttributeError return None None
def patch_vary_headers response newheaders if response.has_header 'Vary' vary_headers cc_delim_re.split response['Vary'] else vary_headers []existing_headers set [header.lower for header in vary_headers] additional_headers [newheader for newheader in newheaders if newheader.lower not in existing_headers ]response['Vary'] ' '.join vary_headers + additional_headers
def term_div a b domain a_lm a_lc a b_lm b_lc bmonom monomial_div a_lm b_lm if domain.has_Field if monom is not None return monom domain.quo a_lc b_lc else return Noneelif not monom is None or a_lc % b_lc return monom domain.quo a_lc b_lc else return None
def getdirs dirs [i for i in os.listdir dname ]dirs filter lambda x not os.path.isfile os.path.join dname x dirs return dirs
def posixGetLinkLocalIPv6Addresses retList []for interface family address in _interfaces interface nativeString interface address nativeString address if family socket.AF_INET6 and address.startswith 'fe80 ' retList.append '%s%%%s' % address interface return retList
def _get_exploration_memcache_key exploration_id version None if version return 'exploration-version %s %s' % exploration_id version else return 'exploration %s' % exploration_id
def has_freesurfer return 'FREESURFER_HOME' in os.environ
def get_session_user_dept request return request.user None
def tarball local 'makestatic' local 'pythonsetup.pysdist--formats gztar' capture False
def GetManifestResources filename names None languages None return winresource.GetResources filename [RT_MANIFEST] names languages
def location object pos None object Carbon.File.FSRef object object_alias object.FSNewAliasMinimal if not pos return _getlocation object_alias return _setlocation object_alias pos
def _get_xmodule_instance_args request task_id request_info {'username' request.user.username 'user_id' request.user.id 'ip' request.META['REMOTE_ADDR'] 'agent' request.META.get 'HTTP_USER_AGENT' '' .decode 'latin1' 'host' request.META['SERVER_NAME']}xmodule_instance_args {'xqueue_callback_url_prefix' get_xqueue_callback_url_prefix request 'request_info' request_info 'task_id' task_id}return xmodule_instance_args
def _build_synset_lookup imagenet_metadata_file lines tf.gfile.FastGFile imagenet_metadata_file 'r' .readlines synset_to_human {}for l in lines if l parts l.strip .split ' DCTB ' assert len parts 2 synset parts[0]human parts[1]synset_to_human[synset] humanreturn synset_to_human
def floor_to_utc_day value return value.astimezone pytz.utc .replace hour 0 minute 0 second 0 microsecond 0
def get_layer_bytes layer arr []layer layer.encode 'hex' for f s in zip layer[0 2] layer[1 2] arr.append f + s return arr
def RConn *args **vars locker.acquire try instance_name 'redis_conn_' + current.request.application if not hasattr RConn instance_name setattr RConn instance_name redis.StrictRedis *args **vars return getattr RConn instance_name finally locker.release
def list_query_history request DEFAULT_PAGE_SIZE 100prefix 'q-'share_queries request.user.is_superuserquerydict_query request.GET.copy if not share_queries querydict_query[ prefix + 'user' ] request.user.usernameapp_name get_app_name request querydict_query[ prefix + 'type' ] app_name page filter_params _list_query_history request.user querydict_query DEFAULT_PAGE_SIZE prefix filter request.GET.get prefix + 'search' and request.GET.get prefix + 'search' or '' if request.GET.get 'format' 'json' resp {'queries' [massage_query_history_for_json app_name query_history for query_history in page.object_list]}return JsonResponse resp return render 'list_history.mako' request {'request' request 'page' page 'filter_params' filter_params 'share_queries' share_queries 'prefix' prefix 'filter' filter}
def list_windows profile None api_key None return salt.utils.pagerduty.list_items 'maintenance_windows' 'id' __salt__['config.option'] profile api_key opts __opts__
def run_stddev_tests if settings.DATABASES[DEFAULT_DB_ALIAS]['ENGINE'] 'django.db.backends.sqlite3' return Falseclass StdDevPop object sql_function 'STDDEV_POP'try connection.ops.check_aggregate_support StdDevPop except return Falsereturn True
def api_model_exists restApiId modelName region None key None keyid None profile None r describe_api_model restApiId modelName region region key key keyid keyid profile profile return {'exists' bool r.get 'model' }
@receiver ENROLL_STATUS_CHANGE def award_badge_on_enrollment sender event None user None **kwargs if badges_enabled and event EnrollStatusChange.enroll award_enrollment_badge user
def vgremove vgname cmd ['vgremove' '-f' vgname]out __salt__['cmd.run'] cmd python_shell False return out.strip
def validate_title value if value is None or not value.strip raise ValidationValueError 'Titlecannotbeblank.' value sanitize.strip_html value if value is None or not value.strip raise ValidationValueError 'Invalidtitle.' if len value > 200 raise ValidationValueError 'Titlecannotexceed200characters.' return True
def QualifyDependencies targets all_dependency_sections [ dep + op for dep in dependency_sections for op in '' '!' '/' ]for target target_dict in targets.iteritems target_build_file gyp.common.BuildFile target toolset target_dict['toolset']for dependency_key in all_dependency_sections dependencies target_dict.get dependency_key [] for index in xrange 0 len dependencies dep_file dep_target dep_toolset gyp.common.ResolveTarget target_build_file dependencies[index] toolset if not multiple_toolsets dep_toolset toolsetdependency gyp.common.QualifiedTarget dep_file dep_target dep_toolset dependencies[index] dependencyif dependency_key ! 'dependencies' and dependency not in target_dict['dependencies'] raise GypError 'Found' + dependency + 'in' + dependency_key + 'of' + target + ' butnotindependencies'
def chrome_extensions attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'chrome_extensions' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def get_dvr_allowed_address_pair_device_owners return [n_const.DEVICE_OWNER_LOADBALANCER n_const.DEVICE_OWNER_LOADBALANCERV2]
def _read_tag_header fid s fid.read 4 * 4 if len s 0 return Nonereturn Tag *struct.unpack '>iIii' s
def find_space addr_space procs mod_base if addr_space.is_valid_address mod_base return addr_spacefor proc in procs ps_ad proc.get_process_address_space if ps_ad ! None if ps_ad.is_valid_address mod_base return ps_adreturn None
def setSerializer serializer global serser serializer
def _queue_exists queue return queue in list_queues
def job_delete_by_tag tag Job.objects.get tag tag .delete return job_get_by_tag tag is None
def _make_image_square source_image side settings.THUMBNAIL_SIZE square_image Image.new 'RGBA' side side 255 255 255 0 width side - source_image.size[0] / 2 height side - source_image.size[1] / 2 square_image.paste source_image width height return square_image
def addInfillBoundary infillBoundary nestedRings infillPoint infillBoundary[0]for nestedRing in nestedRings if euclidean.isPointInsideLoop nestedRing.boundary infillPoint nestedRing.infillBoundaries.append infillBoundary return
@genericdef inspect_object obj raise TryNext
def set_device request device u'' response redirect add_cache_bypass next_url request or u'/' set_cookie response u'mezzanine-device' device 60 * 60 * 24 * 365 return response
def StructureAttribute struct_info cls_dict dict _Structure.__dict__ cls type struct_info.name _Structure.__bases__ cls_dict cls.__module__ struct_info.namespacecls.__gtype__ PGType struct_info.g_type cls._size struct_info.sizecls._is_gtype_struct struct_info.is_gtype_structfor method_info in struct_info.get_methods add_method method_info cls for field_info in struct_info.get_fields field_name escape_identifier field_info.name attr FieldAttribute field_name field_info setattr cls field_name attr return cls
def peer name if suc.check_name name 'a-zA-Z0-9._-' raise SaltInvocationError 'Invalidcharactersinpeername"{0}"'.format name cmd 'peerprobe{0}'.format name return _gluster cmd
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def term_to_integer term return int ''.join list map str list term 2
def _get_codon_list codonseq full_rf_table codonseq.get_full_rf_table codon_lst []for i k in enumerate full_rf_table if isinstance k int start ktry end int full_rf_table[ i + 1 ] except IndexError end start + 3 this_codon str codonseq[start end] if len this_codon 3 codon_lst.append this_codon else codon_lst.append str this_codon.ungap elif str codonseq[int k int k + 3 ] '---' codon_lst.append '---' else codon_lst.append codonseq[int k int k + 3 ] return codon_lst
def libvlc_vlm_seek_media p_instance psz_name f_percentage f _Cfunctions.get 'libvlc_vlm_seek_media' None or _Cfunction 'libvlc_vlm_seek_media' 1 1 1 None ctypes.c_int Instance ctypes.c_char_p ctypes.c_float return f p_instance psz_name f_percentage
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def which_package path path abspath path prefix which_prefix path if prefix is None raise RuntimeError u'couldnotdeterminecondaprefixfrom %s' % path for dist in linked prefix meta is_linked prefix dist if any abspath join prefix f path for f in meta[u'files'] yield dist
def check_predictions clf X y n_samples len y classes np.unique y n_classes classes.shape[0]predicted clf.fit X y .predict X assert_array_equal clf.classes_ classes assert_equal predicted.shape n_samples assert_array_equal predicted y probabilities clf.predict_proba X assert_equal probabilities.shape n_samples n_classes assert_array_almost_equal probabilities.sum axis 1 np.ones n_samples assert_array_equal probabilities.argmax axis 1 y
def is_ip_addr_list value min None max None return [is_ip_addr mem for mem in is_list value min max ]
def _report_failed_challs failed_achalls problems dict for achall in failed_achalls if achall.error problems.setdefault achall.error.typ [] .append achall reporter zope.component.getUtility interfaces.IReporter for achalls in six.itervalues problems reporter.add_message _generate_failed_chall_msg achalls reporter.MEDIUM_PRIORITY
def enforce_port_deletion_rules resource event trigger **kwargs context kwargs['context']port_id kwargs['port_id']subport_obj trunk_objects.SubPort.get_object context port_id port_id if subport_obj raise trunk_exc.PortInUseAsSubPort port_id port_id trunk_id subport_obj.trunk_id trunk_obj trunk_objects.Trunk.get_object context port_id port_id if trunk_obj raise trunk_exc.PortInUseAsTrunkParent port_id port_id trunk_id trunk_obj.id
def perceptron_output weights bias x return step_function dot weights x + bias
def users_to_remove source_event source_node new_node NotificationSubscription apps.get_model 'osf.NotificationSubscription' removed_users {key [] for key in constants.NOTIFICATION_TYPES}if source_node new_node return removed_usersold_sub NotificationSubscription.load to_subscription_key source_node._id source_event old_node_sub NotificationSubscription.load to_subscription_key source_node._id '_'.join source_event.split '_' [ -2 ] if not old_sub and not old_node_sub return removed_usersfor notification_type in constants.NOTIFICATION_TYPES users list getattr old_sub notification_type .values_list 'guids___id' flat True + list getattr old_node_sub notification_type .values_list 'guids___id' flat True subbed removed_users[notification_type] separate_users new_node users return removed_users
def scheme_svg_thumbnail scheme_file from .. import schemefrom ..canvas import scenefrom ..registry import global_registryscheme scheme.Scheme errors []scheme_load scheme scheme_file error_handler errors.append tmp_scene scene.CanvasScene tmp_scene.set_channel_names_visible False tmp_scene.set_registry global_registry tmp_scene.set_scheme scheme tmp_scene.anchor_layout .activate svg scene.grab_svg tmp_scene tmp_scene.clear tmp_scene.deleteLater return svg
def _to_epoch_time date if hasattr date 'timestamp' return int date.timestamp else epoch datetime.fromtimestamp 0 delta date - epoch return int delta.total_seconds
def move source destination use_sudo False func use_sudo and run_as_root or run func '/bin/mv{0}{1}'.format quote source quote destination
def _RegistryQueryBase sysdir key value if sys.platform not in 'win32' 'cygwin' return Nonecmd [os.path.join os.environ.get 'WINDIR' '' sysdir 'reg.exe' 'query' key]if value cmd.extend ['/v' value] p subprocess.Popen cmd stdout subprocess.PIPE stderr subprocess.PIPE text p.communicate [0]if p.returncode return Nonereturn text
def create_rule_dict_from_obj rule return dict id rule.id name rule.name description rule.description protocol rule.protocol source_port_range rule.source_port_range destination_port_range rule.destination_port_range source_address_prefix rule.source_address_prefix destination_address_prefix rule.destination_address_prefix access rule.access priority rule.priority direction rule.direction provisioning_state rule.provisioning_state etag rule.etag
def p4_has_move_command if not p4_has_command 'move' return Falsecmd p4_build_cmd ['move' '-k' '@from' '@to'] p subprocess.Popen cmd stdout subprocess.PIPE stderr subprocess.PIPE out err p.communicate if err.find 'Invalidoption' > 0 return Falseif err.find 'disabled' > 0 return Falsereturn True
def autolog message func inspect.currentframe .f_back.f_codelogging.debug '%s %s in%s %i' % message func.co_name func.co_filename func.co_firstlineno
def make_decreasing_candle open high low close dates **kwargs decrease_x decrease_y _Candlestick open high low close dates **kwargs .get_candle_decrease if 'line' in kwargs kwargs.setdefault 'fillcolor' kwargs['line']['color'] else kwargs.setdefault 'fillcolor' _DEFAULT_DECREASING_COLOR kwargs.setdefault 'showlegend' False kwargs.setdefault 'line' dict color _DEFAULT_DECREASING_COLOR kwargs.setdefault 'name' 'Decreasing' candle_decr_data dict type 'box' x decrease_x y decrease_y whiskerwidth 0 boxpoints False **kwargs return [candle_decr_data]
def reverse x axes if isinstance axes int axes [axes]slices [ slice None None -1 if i in axes else slice None None None for i in range x.ndim ]return x[slices]
def hex_to_filename path hex if getattr path 'encode' None is not None hex hex.decode 'ascii' dir hex[ 2]file hex[2 ]return os.path.join path dir file
def _mean_image_subtraction image means if image.get_shape .ndims ! 3 raise ValueError 'Inputmustbeofsize[height width C>0]' num_channels image.get_shape .as_list [ -1 ]if len means ! num_channels raise ValueError 'len means mustmatchthenumberofchannels' channels tf.split 2 num_channels image for i in range num_channels channels[i] - means[i]return tf.concat 2 channels
def webapi_token_saved_cb instance created **kwargs if created op u'created'else op u'updated'mail_webapi_token instance op
def interval *args def add_attribute function if not hasattr function u'interval' function.interval []for arg in args function.interval.append arg return functionreturn add_attribute
def create_zone_manager config configuration.Configuration manager.volume_manager_opts LOG.debug 'Zoningmode %s.' config.safe_get 'zoning_mode' if config.safe_get 'zoning_mode' 'fabric' LOG.debug 'FCZoneManagerenabled.' zm fc_zone_manager.ZoneManager if zm.initialized LOG.info _LI 'UsingFCZoneManager% zm_version s Driver% drv_name s% drv_version s.' {'zm_version' zm.get_version 'drv_name' zm.driver.__class__.__name__ 'drv_version' zm.driver.get_version } return zmelse LOG.debug 'FCZoneManager% zm_version sdisabled' {'zm_version' zm.get_version } return Noneelse LOG.debug 'FCZoneManagernotenabledincinder.conf.' return None
def AutoLegend chart chart._show_legend Falselabels []for series in chart.data if series.label is None labels.append '' else labels.append series.label chart._show_legend Trueif chart._show_legend chart._legend_labels labels
def openshift_img_tagger registry xml_parent data osb XML.SubElement xml_parent 'com.openshift.jenkins.plugins.pipeline.OpenShiftImageTagger' mapping [ 'api-url' 'apiURL' 'https //openshift.default.svc.cluster.local' 'test-tag' 'testTag' 'origin-nodejs-sample latest' 'prod-tag' 'prodTag' 'origin-nodejs-sample prod' 'namespace' 'namespace' 'test' 'auth-token' 'authToken' '' 'verbose' 'verbose' False ]convert_mapping_to_xml osb data mapping fail_required True
def authority_matrix G nodelist None M nx.to_numpy_matrix G nodelist nodelist return M.T * M
def make_XAxis xaxis_title xaxis_range xaxis graph_objs.XAxis title xaxis_title range xaxis_range showgrid False zeroline False showline False mirror False ticks '' showticklabels False return xaxis
def instrument_declarative cls registry metadata if '_decl_class_registry' in cls.__dict__ raise exc.InvalidRequestError 'Class%ralreadyhasbeeninstrumenteddeclaratively' % cls cls._decl_class_registry registrycls.metadata metadata_as_declarative cls cls.__name__ cls.__dict__
def foldr fn elems initializer None name None return tf.foldr fn elems initializer initializer name name
def _print_baremetal_resource resource info resource._info.copy utils.print_dict info
def validate_annotated_heatmap z x y annotation_text if annotation_text is not None and isinstance annotation_text list utils.validate_equal_length z annotation_text for lst in range len z if len z[lst] ! len annotation_text[lst] raise exceptions.PlotlyError 'zandtextshouldhavethesamedimensions' if x if len x ! len z[0] raise exceptions.PlotlyError 'oops thexlistthatyouprovideddoesnotmatchthewidthofyourzmatrix' if y if len y ! len z raise exceptions.PlotlyError 'oops theylistthatyouprovideddoesnotmatchthelengthofyourzmatrix'
def df2idf docfreq totaldocs log_base 2.0 add 0.0 return add + math.log 1.0 * totaldocs / docfreq log_base
def mapping_get index doc_type hosts None profile None es _get_instance hosts profile try ret es.indices.get_mapping index index doc_type doc_type return retexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def is_ava_value_equal attribute_type val1 val2 return prep_case_insensitive val1 prep_case_insensitive val2
def applyFilter normalized_uri xrd_data flt None flt mkFilter flt et parseXRDS xrd_data endpoints []for service_element in iterServices et endpoints.extend flt.getServiceEndpoints normalized_uri service_element return endpoints
def getAbsoluteFrozenFolderPath filePath folderName '' if hasattr sys 'frozen' if '.py' in filePath filePath ''.join filePath.rpartition '\\' [ 2] filePath os.path.join filePath 'skeinforge_application' return getAbsoluteFolderPath filePath folderName
def edxnotes cls if 'edxnotes' in sys.modules from edxnotes.decorators import edxnotes as notesreturn notes cls else return cls
def create_lrouter cluster tenant_id display_name nexthop tags [{'tag' tenant_id 'scope' 'os_tid'}]display_name _check_and_truncate_name display_name lrouter_obj {'display_name' display_name 'tags' tags 'routing_config' {'default_route_next_hop' {'gateway_ip_address' nexthop 'type' 'RouterNextHop'} 'type' 'SingleDefaultRouteImplicitRoutingConfig'} 'type' 'LogicalRouterConfig'}try return json.loads do_single_request HTTP_POST _build_uri_path LROUTER_RESOURCE json.dumps lrouter_obj cluster cluster except NvpApiClient.NvpApiException LOG.exception _ 'AnexceptionoccuredwhilecommunicatingwiththeNVPcontrollerforcluster %s' cluster.name raise
def writestatus text mute False if not mute and config.SHOW_STATUS.get _writeline text
def get_format fmt None if not fmt fmt config['convert']['format'].as_str .lower fmt ALIASES.get fmt fmt try format_info config['convert']['formats'][fmt].get dict command format_info['command']extension format_info.get 'extension' fmt except KeyError raise ui.UserError u'convert format{0}needsthe"command"field'.format fmt except ConfigTypeError command config['convert']['formats'][fmt].get str extension fmtkeys config['convert'].keys if 'command' in keys command config['convert']['command'].as_str elif 'opts' in keys command u'ffmpeg-i$source-y{0}$dest'.format config['convert']['opts'].as_str if 'extension' in keys extension config['convert']['extension'].as_str return command.encode 'utf-8' extension.encode 'utf-8'
def PrintUsageExit code render_dict DEFAULT_ARGS.copy render_dict['script'] os.path.basename sys.argv[0] print sys.modules['__main__'].__doc__ % render_dict sys.stdout.flush sys.exit code
def s3_store_last_record_id tablename record_id session current.sessiontry record_id long record_id except ValueError return Falseif RCVARS not in session session[RCVARS] Storage {tablename record_id} else session[RCVARS][tablename] record_idreturn True
def _hash_file path if not os.path.isfile path return Falsereturn hashlib.sha1 open path 'rb' .read .hexdigest
def apply_adjustments rgba adjustments if not adjustments return rgbafor adjustment in adjustments name args adjustment[0] adjustment[1 ] if name 'threshold' rgba apply_threshold_adjustment rgba *args elif name 'curves' rgba apply_curves_adjustment rgba *args elif name 'curves2' rgba apply_curves2_adjustment rgba *args else raise KnownUnknown 'Unrecognizedcompositeadjustment "%s"withargs%s' % name repr args return rgba
def _plot_window value params max_times len params['times'] - params['duration'] if value > max_times value len params['times'] - params['duration'] if value < 0 value 0if params['t_start'] ! value params['t_start'] valueparams['hsel_patch'].set_x value params['plot_update_proj_callback'] params
def tutte_graph create_using None description ['adjacencylist' "Tutte'sGraph" 46 [[2 3 4] [5 27] [11 12] [19 20] [6 34] [7 30] [8 28] [9 15] [10 39] [11 38] [40] [13 40] [14 36] [15 16] [35] [17 23] [18 45] [19 44] [46] [21 46] [22 42] [23 24] [41] [25 28] [26 33] [27 32] [34] [29] [30 33] [31] [32 34] [33] [] [] [36 39] [37] [38 40] [39] [] [] [42 45] [43] [44 46] [45] [] []]]G make_small_undirected_graph description create_using return G
def _build_image data cmap 'gray' import matplotlib.pyplot as pltfrom matplotlib.figure import Figurefrom matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvasfigsize data.shape[ -1 ]if figsize[0] 1 figsize tuple figsize[1 ] data data[ 0]fig Figure figsize figsize dpi 1.0 frameon False FigureCanvas fig cmap getattr plt.cm cmap plt.cm.gray fig.figimage data cmap cmap output BytesIO fig.savefig output dpi 1.0 format 'png' return base64.b64encode output.getvalue .decode 'ascii'
def run_on_executor fn @functools.wraps fn def wrapper self *args **kwargs callback kwargs.pop 'callback' None future self.executor.submit fn self *args **kwargs if callback self.io_loop.add_future future lambda future callback future.result return futurereturn wrapper
def expanded_data n 100 expanded_training_data _ _ network3.load_data_shared '../data/mnist_expanded.pkl.gz' for j in range 3 print 'Trainingwithexpandeddata %sneuronsintheFClayer runnum%s' % n j net Network [ConvPoolLayer image_shape mini_batch_size 1 28 28 filter_shape 20 1 5 5 poolsize 2 2 activation_fn ReLU ConvPoolLayer image_shape mini_batch_size 20 12 12 filter_shape 40 20 5 5 poolsize 2 2 activation_fn ReLU FullyConnectedLayer n_in 40 * 4 * 4 n_out n activation_fn ReLU SoftmaxLayer n_in n n_out 10 ] mini_batch_size net.SGD expanded_training_data 60 mini_batch_size 0.03 validation_data test_data lmbda 0.1 return net
def find_subdirectories package try subdirectories next os.walk package_to_path package [1]except StopIteration subdirectories []return subdirectories
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def _make_tag_list n 26 lc string.lowercaselc_len len lc return [{'name' lc[ i % lc_len ] * int math.ceil i / lc_len + 2 } for i in range 0 n ]
def get_free_range parent_range excluded_ranges size PRIMARY_VIP_RANGE_SIZE free_cidrs netaddr.IPSet [parent_range] - netaddr.IPSet excluded_ranges for cidr in free_cidrs.iter_cidrs if cidr.prefixlen < size return '%s/%s' % cidr.network size raise ValueError _ 'Networkofsize% size s fromIPrange% parent_range sexcludingIPranges% excluded_ranges swasnotfound.' % {'size' size 'parent_range' parent_range 'excluded_ranges' excluded_ranges}
def _authenticate_cram_md5 credentials sock_info source credentials.sourceusername credentials.usernamepassword credentials.passwordpasswd _password_digest username password cmd SON [ 'saslStart' 1 'mechanism' 'CRAM-MD5' 'payload' Binary '' 'autoAuthorize' 1 ] response sock_info.command source cmd mac hmac.HMAC key passwd.encode 'utf-8' digestmod md5 mac.update response['payload'] challenge username.encode 'utf-8' + '' + b mac.hexdigest cmd SON [ 'saslContinue' 1 'conversationId' response['conversationId'] 'payload' Binary challenge ] sock_info.command source cmd
def test_make_imbalance_2 X_ y_ make_imbalance X Y ratio 0.25 min_c_ 1 counter Counter y_ assert_equal counter[0] 500 assert_equal counter[1] 125 assert_true np.all [ X_i in X for X_i in X_]
def _element_in_child_binder root e return any x.typeid.startswith 'bind ' for x in root.path_to e
def flavor_delete flavor_id profile None conn _auth profile return conn.flavor_delete flavor_id
def user_roles_exists name roles database user None password None host None port None authdb None try roles _to_dict roles except Exception return 'Rolesprovidedinwrongformat'users user_list user password host port database authdb if isinstance users string_types return 'Failedtoconnecttomongodatabase'for user in users if name dict user .get 'user' for role in roles if not isinstance role dict role {'role' role 'db' database}if role not in dict user .get 'roles' [] return Falsereturn Truereturn False
def merge_insert ins_chunks doc unbalanced_start balanced unbalanced_end split_unbalanced ins_chunks doc.extend unbalanced_start if doc and not doc[ -1 ].endswith '' doc[ -1 ] + ''doc.append '<ins>' if balanced and balanced[ -1 ].endswith '' balanced[ -1 ] balanced[ -1 ][ -1 ]doc.extend balanced doc.append '</ins>' doc.extend unbalanced_end
def extract_task_features task features ['task_type' 'task_input' 'task_id' 'requester' 'task_state']task_feature_dict {feature str getattr task feature for feature in features}task_feature_dict['created'] task.created.isoformat duration_sec 'unknown'if hasattr task 'task_output' and task.task_output is not None try task_output json.loads task.task_output except ValueError log.error 'Couldnotparsetaskoutputasvalidjson;taskoutput %s' task.task_output else if 'duration_ms' in task_output duration_sec int task_output['duration_ms'] / 1000.0 task_feature_dict['duration_sec'] duration_sec success task_message get_task_completion_info task status _ 'Complete' if success else _ 'Incomplete' task_feature_dict['status'] statustask_feature_dict['task_message'] task_messagereturn task_feature_dict
def get_section_display_name course_id course modulestore .get_course course_id depth 4 section_display_name [''] * len course.get_children i 0for section in course.get_children section_display_name[i] own_metadata section .get 'display_name' '' i + 1return section_display_name
def displayable_path path separator u';' if isinstance path list tuple return separator.join displayable_path p for p in path elif isinstance path unicode return pathelif not isinstance path str return unicode path try return path.decode _fsencoding 'ignore' except UnicodeError LookupError return path.decode 'utf8' 'ignore'
def history_not_changed proc TIMEOUT proc.send '\x1b[A' assert proc.expect [TIMEOUT u'fuck']
def fig_to_vega fig notebook False renderer VegaRenderer Exporter renderer .run fig vega_html VegaHTML renderer if notebook return vega_htmlelse return vega_html.html
def ss_to_index ss if ss 'H' return 0if ss 'E' return 1if ss 'C' return 2assert 0
def basics_match original_result modified_result return all getattr original_result member getattr modified_result member for member in ['origin' 'message' 'severity' 'debug_msg']
@register.inclusion_tag 'admin/prepopulated_fields_js.html' takes_context True def prepopulated_fields_js context prepopulated_fields []if 'adminform' in context prepopulated_fields.extend context['adminform'].prepopulated_fields if 'inline_admin_formsets' in context for inline_admin_formset in context['inline_admin_formsets'] for inline_admin_form in inline_admin_formset if inline_admin_form.original is None prepopulated_fields.extend inline_admin_form.prepopulated_fields prepopulated_fields_json []for field in prepopulated_fields prepopulated_fields_json.append {'id' '#%s' % field['field'].auto_id 'name' field['field'].name 'dependency_ids' [ '#%s' % dependency.auto_id for dependency in field['dependencies']] 'dependency_list' [dependency.name for dependency in field['dependencies']] 'maxLength' field['field'].field.max_length or 50 'allowUnicode' getattr field['field'].field 'allow_unicode' False } context.update {'prepopulated_fields' prepopulated_fields 'prepopulated_fields_json' json.dumps prepopulated_fields_json } return context
def get_notifications user notifications []try user.idexcept return []try if not getattr settings 'HARDTREE_ALLOW_GRITTER_NOTIFICATIONS' False return notificationsrequest HttpRequest request.user userstorage default_storage request for msg in storage._get [0] notifications.append {'message' msg.message 'tags' msg._get_tags } storage._store None except passreturn notifications
def chopstring message key n funcref msglen len message mbits msglen * 8 nbits int math.floor math.log n 2 nbytes nbits / 8 blocks msglen / nbytes if msglen % nbytes > 0 blocks + 1cypher []for bindex in range blocks offset bindex * nbytes block message[offset offset + nbytes ]value bytes2int block cypher.append funcref value key n return picklechops cypher
def validate_user_data user_data try user_data base64.b64decode user_data except TypeError return Falsereturn True
def test_debug_stdout_logging caplog debug_logger debug_messages [stream_handler] debug_logger.handlersassert isinstance stream_handler logging.StreamHandler assert stream_handler.level logging.DEBUG create_log_records stream_messages [stream_handler.format r for r in caplog.records if r.levelno > stream_handler.level ]assert stream_messages debug_messages
def fnmatch name pat import osname os.path.normcase name pat os.path.normcase pat return fnmatchcase name pat
def logout request user getattr request 'user' None if hasattr user 'is_authenticated' and not user.is_authenticated user Noneuser_logged_out.send sender user.__class__ request request user user language request.session.get 'django_language' request.session.flush if language is not None request.session['django_language'] languageif hasattr request 'user' from django.contrib.auth.models import AnonymousUserrequest.user AnonymousUser
def transform_bilogistic t beta delta def _check_args beta delta cond1 beta > 0 and beta < 1 and delta > 0 and delta < 1 cond2 beta < 0 and delta < 0 return cond1 | cond2 if not np.all _check_args beta delta raise ValueError 'invalidargs' def _integrant w term1 1 - beta * np.power w - beta * 1 - t term2 1 - delta * np.power 1 - w - delta * t np.maximum term1 term2 from scipy.integrate import quadtransf quad _integrant 0 1 return transf
def poly_TC f K if not f return K.zeroelse return f[ -1 ]
def uses_shib course return course.enrollment_domain and course.enrollment_domain.startswith settings.SHIBBOLETH_DOMAIN_PREFIX
def getenv key default None return environ.get key default
def _mt_spectra x dpss sfreq n_fft None if n_fft is None n_fft x.shape[1]x x - np.mean x axis -1 [ np.newaxis] freqs fftpack.fftfreq n_fft 1.0 / sfreq freq_mask freqs > 0 freqs freqs[freq_mask]n_tapers dpss.shape[0] if dpss.ndim > 1 else 1 x_mt np.zeros len x n_tapers freq_mask.sum dtype np.complex128 for idx sig in enumerate x x_mt[idx] fftpack.fft sig[np.newaxis ] * dpss n n_fft [ freq_mask]return x_mt freqs
def getLockedHandle runtimeElement expression fullExpression '__import__ "nupic.bindings.research" fromlist ["lockHandle"] .lockHandle ' + expression + ' ' return runtimeElement.interpret fullExpression
def get_qiime_temp_dir return load_qiime_config ['temp_dir']
def _graded_scorable_blocks_to_header course_key scorable_blocks_map OrderedDict grading_context grading_context_for_course course_key for assignment_type_name subsection_infos in grading_context['all_graded_subsections_by_type'].iteritems for subsection_index subsection_info in enumerate subsection_infos start 1 for scorable_block in subsection_info['scored_descendants'] header_name u'{assignment_type}{subsection_index} {subsection_name}-{scorable_block_name}'.format scorable_block_name scorable_block.display_name assignment_type assignment_type_name subsection_index subsection_index subsection_name subsection_info['subsection_block'].display_name scorable_blocks_map[scorable_block.location] [ header_name + ' Earned ' header_name + ' Possible ' ]return scorable_blocks_map
def get_account_id_from_arn trail_arn return trail_arn.split ' ' [4]
def p_expression_name t try t[0] names[t[1]]except LookupError print u"Undefinedname'%s'" % t[1] t[0] 0
def remove_result_ranges_diffs result_list file_dict result_diff_dict_dict {}for original_result in result_list mod_file_dict copy.deepcopy file_dict source_ranges []previous Nonefor source_range in sorted original_result.affected_code reverse True if previous is not None and source_range.overlaps previous combined_sr SourceRange.join previous source_range previous combined_srelif previous is None previous source_rangeelse source_ranges.append previous previous source_rangeif previous source_ranges.append previous for source_range in source_ranges file_name source_range.filenew_file remove_range mod_file_dict[file_name] source_range mod_file_dict[file_name] new_filediff_dict {}for file_name in file_dict diff_dict[file_name] Diff.from_string_arrays file_dict[file_name] mod_file_dict[file_name] result_diff_dict_dict[original_result] diff_dictreturn result_diff_dict_dict
def get_temp_dir temp get_environ_variable 'TMP' if temp None temp get_environ_variable 'TEMP' if temp None or '' in temp and os.name 'nt' temp 'C \\temp'if temp None or '' in temp and os.name 'posix' temp '/tmp'return temp
def exec_command_all *cmdargs **kwargs proc subprocess.Popen cmdargs bufsize -1 stdout subprocess.PIPE stderr subprocess.PIPE **kwargs out err proc.communicate if is_py3 encoding kwargs.get 'encoding' if encoding out out.decode encoding err err.decode encoding else out os.fsdecode out err os.fsdecode err return proc.returncode out err
def mask_sequence seq maskchar fpos tpos if len maskchar > 1 raise RuntimeError 'Internalerror morethanonecharactergiventomask_sequence' if fpos < 0 fpos 0if tpos > len seq tpos len seq newseq ''.join seq[ fpos] maskchar * tpos - fpos seq[tpos ] return newseq
def do_format value *args **kwargs if args and kwargs raise FilterArgumentError "can'thandlepositionalandkeywordargumentsatthesametime" return soft_unicode value % kwargs or args
def InstallLibrary name version explicit True installed_version explicitly_installed installed.get name [None] * 2 if name in sys.modules if explicit CheckInstalledVersion name version explicit True returnelif installed_version if version installed_version returnif explicit if explicitly_installed raise ValueError '%s%srequested but%salreadyinuse' % name version installed_version RemoveLibrary name else version_ob distutils.version.LooseVersion version installed_ob distutils.version.LooseVersion installed_version if version_ob < installed_ob returnelse RemoveLibrary name AddLibrary name version explicit dep_details PACKAGES[name][1][version]if not dep_details returnfor dep_name dep_version in dep_details InstallLibrary dep_name dep_version explicit False
def getdefaultencoding prefer_stream True enc Noneif prefer_stream enc get_stream_enc sys.stdin if not enc or enc 'ascii' try enc locale.getpreferredencoding except Exception passenc enc or sys.getdefaultencoding if enc 'cp0' warnings.warn 'Invalidcodepagecp0detected-usingcp1252instead.Ifcp1252isincorrectpleaseensureavalidcodepageisdefinedfortheprocess.' RuntimeWarning return 'cp1252'return enc
@coroutinedef async_run_ctl args stdin '' endpoint DEFAULT_ENDPOINT_DEALER queue Queue circusctl_process Process target run_ctl args args queue stdin endpoint circusctl_process.start while queue.empty yield tornado_sleep 0.1 stderr queue.get stdout queue.get raise Return stdout stderr
def _envs branch repo_location gitpil _LegacyGitPillar branch repo_location __opts__ return gitpil.envs
def lookupNameservers name timeout None return getResolver .lookupNameservers name timeout
def emit_via_redis event message room r get_redis_server try r.publish u'events' frappe.as_json {u'event' event u'message' message u'room' room} except redis.exceptions.ConnectionError pass
def mc2mnc mc n len mc mean mc[0]mc [1] + list mc mc[1] 0mnc [1 mean]for nn m in enumerate mc[2 ] n nn + 2 mnc.append 0 for k in range n + 1 mnc[n] + comb n k exact 1 * mc[k] * mean ** n - k return mnc[1 ]
def getKeyM row column prefix '' return '%sm%s%s' % prefix row + 1 column + 1
@csrf_exempt@require_post@has_request_variablesdef api_dev_fetch_api_key request username REQ if not dev_auth_enabled or settings.PRODUCTION return json_error _ 'Devenvironmentnotenabled.' return_data {}user_profile authenticate username username realm_subdomain get_subdomain request return_data return_data if return_data.get 'inactive_realm' return json_error _ 'Yourrealmhasbeendeactivated.' data {'reason' 'realmdeactivated'} status 403 if return_data.get 'inactive_user' return json_error _ 'Youraccounthasbeendisabled.' data {'reason' 'userdisable'} status 403 login request user_profile return json_success {'api_key' user_profile.api_key 'email' user_profile.email}
def test_short_users_list u1 UserProfile username 'oscar' display_name 'OscartheGrouch' pk 1 u2 UserProfile username 'grover' display_name 'Grover' pk 2 u3 UserProfile username 'cookies!' display_name 'CookieMonster' pk 3 shortlist users_list [u1 u2 u3] size 2 assert shortlist ' '.join user_link u1 user_link u2 + ' others'
def assert_all_instances list_ class_ label 'object' for obj in list_ or [] assert_instance obj class_ label 'object'
def process_sms_outbox msg.process_outbox contact_method 'SMS'
def sh_escape command command command.replace '\\' '\\\\' command command.replace '$' '\\$' command command.replace '"' '\\"' command command.replace '`' '\\`' return command
def levenshtein_dist t1_fname t2_fname len_t1_fname len_t2_fname len t1_fname len t2_fname if len_t1_fname > len_t2_fname t1_fname t2_fname t2_fname t1_fname len_t1_fname len_t2_fname len_t2_fname len_t1_fname current range len_t1_fname + 1 for i in xrange 1 len_t2_fname + 1 previous current current [i] + [0] * len_t1_fname for j in xrange 1 len_t1_fname + 1 add delete previous[j] + 1 current[ j - 1 ] + 1 change previous[ j - 1 ]if t1_fname[ j - 1 ] ! t2_fname[ i - 1 ] change + 1current[j] min add delete change return current[len_t1_fname]
def get_user_config config_file None default_config False if default_config return copy.copy DEFAULT_CONFIG if config_file and config_file is not USER_CONFIG_PATH return get_config config_file try env_config_file os.environ[u'COOKIECUTTER_CONFIG']except KeyError if os.path.exists USER_CONFIG_PATH return get_config USER_CONFIG_PATH else return copy.copy DEFAULT_CONFIG else return get_config env_config_file
def get_color value alpha color QColor for typ in COLORS if isinstance value typ color QColor COLORS[typ] color.setAlphaF alpha return color
def _mp_compile self sources output_dir None macros None include_dirs None debug 0 extra_preargs None extra_postargs None depends None macros objects extra_postargs pp_opts build self._setup_compile output_dir macros include_dirs sources depends extra_postargs cc_args self._get_cc_args pp_opts debug extra_preargs pool Pool MAX_PROCS try print 'Buildingusing%dprocesses' % pool._processes except passarr [ self obj build cc_args extra_postargs pp_opts for obj in objects]pool.map_async _mp_compile_one arr pool.close pool.join return objects
def rad_rationalize num den if not den.is_Add return num den g a b split_surds den a a * sqrt g num _mexpand a - b * num den _mexpand a ** 2 - b ** 2 return rad_rationalize num den
def _get_gcd_project return os.getenv GCD_DATASET
def pid_is_alive pid path '/proc/%s/stat' % pid try stat read_one_line path except IOError if not os.path.exists path return Falseraisereturn stat.split [2] ! 'Z'
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _getPropertyValue schema propertyName options if propertyName not in options paramsSchema schema['properties'][propertyName]if 'default' in paramsSchema options[propertyName] paramsSchema['default']else options[propertyName] None
def _reassign check clusters base num check[ check num ] baseclusters[ base - 1 ] np.concatenate clusters[ base - 1 ] clusters[ num - 1 ] clusters[ num - 1 ] np.array [] dtype int
def rec_keep_fields rec names if cbook.is_string_like names names names.split u' ' arrays []for name in names arrays.append rec[name] return np.rec.fromarrays arrays names names
def fixup_paths path try import googlegoogle.__path__.append '{0}/google'.format path except ImportError passsys.path.insert 0 path
def ldap2py val return utf8_decode val
def getWinDrives assert os.name 'nt' drives []bitmask windll.kernel32.GetLogicalDrives for letter in string.uppercase if bitmask & 1 drives.append letter bitmask >> 1return drives
def _chain_stop_result service stop maybeDeferred service.stopService .chainDeferred stop
def is_table doctype def get_tables return db.sql_list u'selectnamefromtabDocTypewhereistable 1' tables cache .get_value u'is_table' get_tables return doctype in tables
def server_list profile None conn _auth profile return conn.server_list
def get_auth_token request current_user users.get_current_user if current_user is None or current_user.user_id is None return False token_string token_scopes gdata.gauth.auth_sub_string_from_url request.url if token_string is None return gdata.gauth.ae_load 'blogger' + current_user.user_id single_use_token gdata.gauth.AuthSubToken token_string token_scopes client gdata.client.GDClient session_token client.upgrade_token single_use_token gdata.gauth.ae_save session_token 'blogger' + current_user.user_id return session_token
def days_at_time days t tz day_offset 0 if len days 0 return daysdays DatetimeIndex days .tz_localize None delta pd.Timedelta days day_offset hours t.hour minutes t.minute seconds t.second return days + delta .tz_localize tz .tz_convert 'UTC'
def assert_request_user_is_system_admin request is_system_admin request_user_is_system_admin request request if not is_system_admin user_db get_user_db_from_request request request raise AccessDeniedError message 'SystemAdministratoraccessrequired' user_db user_db
@api_versions.wraps '2.26' @utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg 'tag' metavar '<tag>' nargs '+' help _ 'Tag s toadd.' def do_server_tag_add cs args server _find_server cs args.server utils.do_action_on_many lambda t server.add_tag t args.tag _ 'Requesttoaddtag%stospecifiedserverhasbeenaccepted.' _ 'Unabletoaddtag%stothespecifiedserver.'
def get_view_builder req base_url req.application_urlreturn ViewBuilder base_url
def _message_pb_to_mapping message_pb return {'messageId' message_pb.message_id 'data' message_pb.data 'attributes' message_pb.attributes 'publishTime' _pb_timestamp_to_rfc3339 message_pb.publish_time }
def gf_add_mul f g h p K return gf_add f gf_mul g h p K p K
def sublist a b c []for item in a if item not in b c.append item return c
def deep_update d u for k v in u.iteritems if isinstance v collections.Mapping r deep_update d.get k {} v d[k] relse d[k] u[k]return d
def symptom_keys_in_credential_fernet_key_repository fernet_utils utils.FernetUtils CONF.credential.key_repository credential_fernet.MAX_ACTIVE_KEYS return 'fernet' in CONF.credential.provider and not fernet_utils.load_keys
def _task_info_update task_id values global DATAtry task_info DATA['task_info'][task_id]except KeyError LOG.debug 'Notaskinfofoundwithtaskid%s' task_id raise exception.TaskNotFound task_id task_id task_info.update values DATA['task_info'][task_id] task_inforeturn task_info
def _p2p xy projection loc projection.projLocation _Point *xy return loc.lon loc.lat
def increment_index builder val one val.type 1 return builder.add val one flags ['nsw']
def module_check module ri raw_input '[-]python-%snotinstalled wouldyouliketoinstallnow? apt-getinstall-ypython-%swillberunifyes [y/n] ' % module module if ri 'y' os.system 'apt-getinstall-ypython-%s' % module else exit '[-]Exitingduetomissingdependency'
def _downscale images K arr np.zeros [K K 3 3] arr[ 0 0] 1.0 / K * K arr[ 1 1] 1.0 / K * K arr[ 2 2] 1.0 / K * K dowscale_weight tf.constant arr dtype tf.float32 downscaled tf.nn.conv2d images dowscale_weight strides [1 K K 1] padding 'SAME' return downscaled
def GetPlatformToken os_module os sys_module sys platform sys.platform if hasattr sys_module 'getwindowsversion' windows_version sys_module.getwindowsversion version_info '.'.join str i for i in windows_version[ 4] return platform + '/' + version_info elif hasattr os_module 'uname' uname os_module.uname return '%s/%s' % uname[0] uname[2] else return 'unknown'
def _set_protobuf_value value_pb val attr val _pb_attr_value val if attr 'key_value' value_pb.key_value.CopyFrom val elif attr 'timestamp_value' value_pb.timestamp_value.CopyFrom val elif attr 'entity_value' entity_pb entity_to_protobuf val value_pb.entity_value.CopyFrom entity_pb elif attr 'array_value' l_pb value_pb.array_value.valuesfor item in val i_pb l_pb.add _set_protobuf_value i_pb item elif attr 'geo_point_value' value_pb.geo_point_value.CopyFrom val else setattr value_pb attr val
def chunkreadable iter chunk_size 65536 return chunkiter iter chunk_size if hasattr iter 'read' else iter
def list_ profile 'splunk' client _get_splunk profile searches [x['name'] for x in client.saved_searches]return searches
def returns_clone func def inner self *args **kwargs clone self.clone func clone *args **kwargs return cloneinner.call_local funcreturn inner
def pr data start 0 end None pprint list islice data start end
def get_layer name fns layers[name]return eval fns[0] eval fns[1]
def this_month_day t None t t or time.localtime t return time.localtime t .tm_mday
def execute_return_success cmd ret _run_all cmd if ret['retcode'] ! 0 or 'notsupported' in ret['stdout'].lower msg 'CommandFailed {0}\n'.format cmd msg + 'ReturnCode {0}\n'.format ret['retcode'] msg + 'Output {0}\n'.format ret['stdout'] msg + 'Error {0}\n'.format ret['stderr'] raise CommandExecutionError msg return True
def create_countgraph args ksize None multiplier 1.0 fp_rate 0.1 args _check_fp_rate args fp_rate if hasattr args u'force' if args.n_tables > 20 if not args.force print_error u'\n**ERROR khmeronlysupportsnumberoftables< 20.\n' sys.exit 1 elif args.n_tables > 20 log_warn u'\n***Warning Maximumrecommendednumberoftablesis20 discardedbyforcenonetheless!\n' if ksize is None ksize args.ksizeif ksize > 32 print_error u'\n**ERROR khmeronlysupportsk-mersizes< 32.\n' sys.exit 1 if args.small_count tablesize calculate_graphsize args u'smallcountgraph' multiplier multiplier return khmer.SmallCountgraph ksize tablesize args.n_tables else tablesize calculate_graphsize args u'countgraph' multiplier multiplier return khmer.Countgraph ksize tablesize args.n_tables
@require_chanmsg@require_privilege OP u'Youarenotachanneloperator.' @commands u'kickban' u'kb' @priority u'high' def kickban bot trigger if bot.privileges[trigger.sender][bot.nick] < HALFOP return bot.reply u"I'mnotachanneloperator!" text trigger.group .split argc len text if argc < 4 returnopt Identifier text[1] nick optmask text[2]channel trigger.senderreasonidx 3if not opt.is_nick if argc < 5 returnchannel optnick text[2]mask text[3]reasonidx 4reason u''.join text[reasonidx ] mask configureHostMask mask if mask u'' returnbot.write [u'MODE' channel u'+b' mask] bot.write [u'KICK' channel nick] reason
def xor aa bb result bytearray for a b in zip bytearray aa bytearray bb result.append a ^ b return result
def _dropout_from_layer rng layer p srng theano.tensor.shared_randomstreams.RandomStreams rng.randint 999999 mask srng.binomial n 1 p 1 - p size layer.shape output layer * T.cast mask theano.config.floatX return output
def decode encoding None default_encoding 'utf-8' body cherrypy.request.bodyif encoding is not None if not isinstance encoding list encoding [encoding]body.attempt_charsets encodingelif default_encoding if not isinstance default_encoding list default_encoding [default_encoding]body.attempt_charsets body.attempt_charsets + default_encoding
def sha512_encode t s hashlib.sha512 t return s.hexdigest
def sina_xml_to_url_list xml_data rawurl []dom parseString xml_data for node in dom.getElementsByTagName 'durl' url node.getElementsByTagName 'url' [0]rawurl.append url.childNodes[0].data return rawurl
def form_for_instance instance form BaseForm formfield_callback lambda f **kwargs f.formfield **kwargs model instance.__class__opts model._metafield_list []for f in opts.fields + opts.many_to_many if not f.editable continuecurrent_value f.value_from_object instance formfield formfield_callback f initial current_value if formfield field_list.append f.name formfield fields SortedDictFromList field_list return type opts.object_name + 'InstanceForm' form {'base_fields' fields '_model' model 'save' make_instance_save instance }
def excInfoOrFailureToExcInfo err if isinstance err Failure err err.type err.value err.getTracebackObject return err
def complete_year_spans spans spans.sort key lambda x x['from'] for x y in pairwise spans if 'to' not in x x['to'] y['from'] - 1 if spans and 'to' not in spans[ -1 ] spans[ -1 ]['to'] datetime.now .year
def stacked_autoencoder_predict theta input_size hidden_size num_classes net_config data softmax_theta theta[0 hidden_size * num_classes ].reshape num_classes hidden_size stack params2stack theta[ hidden_size * num_classes ] net_config m data.shape[1]a [data]z [np.array 0 ]for s in stack z.append s['w'].dot a[ -1 ] + np.tile s['b'] m 1 .transpose a.append sigmoid z[ -1 ] pred softmax.softmax_predict softmax_theta hidden_size num_classes a[ -1 ] return pred
def funcinfo function warnings.warn '[v2.5]Useinspect.getargspecinsteadoftwisted.python.reflect.funcinfo' DeprecationWarning stacklevel 2 code function.func_codename function.func_nameargc code.co_argcountargv code.co_varnames[ argc]defaults function.func_defaultsout []out.append 'Thefunction%saccepts%sarguments' % name argc if defaults required argc - len defaults out.append 'Itrequires%sarguments' % required out.append 'Theargumentsrequiredare %s' % argv[ required] out.append 'additionalargumentsare ' for i in range argc - required j i + required out.append '%swhichhasadefaultof' % argv[j] defaults[i] return out
def _update_coordinate_descent X W Ht l1_reg l2_reg shuffle random_state n_components Ht.shape[1]HHt fast_dot Ht.T Ht XHt safe_sparse_dot X Ht if l2_reg ! 0.0 HHt.flat[ n_components + 1 ] + l2_regif l1_reg ! 0.0 XHt - l1_regif shuffle permutation random_state.permutation n_components else permutation np.arange n_components permutation np.asarray permutation dtype np.intp return _update_cdnmf_fast W HHt XHt permutation
def getPageWordSet page retVal set if isinstance page unicode _ getFilteredPageContent page retVal set re.findall '\\w+' _ return retVal
def getframeinfo frame context 1 if istraceback frame lineno frame.tb_linenoframe frame.tb_frameelse lineno frame.f_linenoif not isframe frame raise TypeError 'argisnotaframeortracebackobject' filename getsourcefile frame or getfile frame if context > 0 start lineno - 1 - context // 2 try lines lnum findsource frame except IOError lines index Noneelse start max start 1 start max 0 min start len lines - context lines lines[start start + context ]index lineno - 1 - start else lines index Nonereturn Traceback filename lineno frame.f_code.co_name lines index
def validate_gantt df if pd and isinstance df pd.core.frame.DataFrame for key in REQUIRED_GANTT_KEYS if key not in df raise exceptions.PlotlyError 'Thecolumnsinyourdataframemustincludethefollowingkeys {0}'.format ' '.join REQUIRED_GANTT_KEYS num_of_rows len df.index chart []for index in range num_of_rows task_dict {}for key in df task_dict[key] df.ix[index][key]chart.append task_dict return chartif not isinstance df list raise exceptions.PlotlyError 'Youmustinputeitheradataframeoralistofdictionaries.' if len df < 0 raise exceptions.PlotlyError 'Yourlistisempty.Itmustcontainatleastonedictionary.' if not isinstance df[0] dict raise exceptions.PlotlyError 'Yourlistmustonlyincludedictionaries.' return df
def _get_sql_for_pending_references model pending_references from django.db import backend get_creation_moduledata_types get_creation_module .DATA_TYPESfinal_output []if backend.supports_constraints opts model._metaif model in pending_references for rel_class f in pending_references[model] rel_opts rel_class._metar_table rel_opts.db_tabler_col f.columntable opts.db_tablecol opts.get_field f.rel.field_name .columnr_name '%s_refs_%s_%x' % r_col col abs hash r_table table final_output.append style.SQL_KEYWORD 'ALTERTABLE' + '%sADDCONSTRAINT%sFOREIGNKEY %s REFERENCES%s %s %s;' % backend.quote_name r_table r_name backend.quote_name r_col backend.quote_name table backend.quote_name col backend.get_deferrable_sql del pending_references[model]return final_output
def list_policies ret {}cmd __execute_kadmin 'list_policies' if cmd['retcode'] ! 0 or cmd['stderr'] ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retret {'policies' []}for i in cmd['stdout'].splitlines [1 ] ret['policies'].append i return ret
def _convert_out_to_series x dates name from statsmodels.compat import StringIOfrom pandas import read_tableout read_table StringIO x skiprows 2 header None return out.set_index dates .rename columns {1 name} [name]
def write_ast patched_ast_node result []for child in patched_ast_node.sorted_children if isinstance child ast.AST result.append write_ast child else result.append child return ''.join result
def list_master saltenv 'base' prefix '' return __context__['fileclient'].file_list saltenv prefix
def test_issue_114 template '"""\n%s\n"""'msp ip.prefilter_manager.multi_line_specialsip.prefilter_manager.multi_line_specials Falsetry for mgk in ip.magics_manager.lsmagic ['line'] raw template % mgk nt.assert_equal ip.prefilter raw raw finally ip.prefilter_manager.multi_line_specials msp
def compatible_platforms provided required if provided is None or required is None or provided required return TruereqMac macosVersionString.match required if reqMac provMac macosVersionString.match provided if not provMac provDarwin darwinVersionString.match provided if provDarwin dversion int provDarwin.group 1 macosversion '%s.%s' % reqMac.group 1 reqMac.group 2 if dversion 7 and macosversion > '10.3' or dversion 8 and macosversion > '10.4' return Truereturn Falseif provMac.group 1 ! reqMac.group 1 or provMac.group 3 ! reqMac.group 3 return Falseif int provMac.group 2 > int reqMac.group 2 return Falsereturn Truereturn False
def parsestream stream encoding None stack engine.FilterStack stack.full_analyze return stack.run stream encoding
def _must_skip spec entry is_type if not isinstance spec type if entry in getattr spec '__dict__' {} return Falsespec spec.__class__for klass in spec.__mro__ result klass.__dict__.get entry DEFAULT if result is DEFAULT continueif isinstance result staticmethod classmethod return Falseelif isinstance getattr result '__get__' None MethodWrapperTypes return is_typeelse return Falsereturn is_type
def parse_interval interval_string regexp u'^\\d+ second|minute|hour|day|week s?$'if not re.match regexp interval_string raise ValueError u"shouldbeinformat'x seconds|minutes|hours|days|weeks '" return parse_timedelta interval_string
def _filter_disabled_blocks all_blocks disabled_block_names [block.name for block in disabled_xblocks ]return [block_name for block_name in all_blocks if block_name not in disabled_block_names ]
def country_name_for_number numobj lang script None region None region_codes region_codes_for_country_code numobj.country_code if len region_codes 1 return _region_display_name region_codes[0] lang script region else region_where_number_is_valid u 'ZZ' for region_code in region_codes if is_valid_number_for_region numobj region_code if region_where_number_is_valid ! u 'ZZ' return U_EMPTY_STRINGregion_where_number_is_valid region_codereturn _region_display_name region_where_number_is_valid lang script region
def setup_server config web_server WebServer bind config[u'bind'] port config[u'port'] ssl_certificate config[u'ssl_certificate'] ssl_private_key config[u'ssl_private_key'] _default_app.secret_key get_secret user get_user if not user or not user.password log.warning u'Nopasswordsetforwebserver createonebyusing`flexgetwebpasswd<password>`' if _app_register web_server.start return web_server
def save_to_well_known_file credentials well_known_file None if well_known_file is None well_known_file _get_well_known_file config_dir os.path.dirname well_known_file if not os.path.isdir config_dir raise OSError 'Configdirectorydoesnotexist {0}'.format config_dir credentials_data credentials.serialization_data_save_private_file well_known_file credentials_data
@py.test.mark.parametrize 'item_name' [item.name for item in six._urllib_request_moved_attributes] def test_move_items_urllib_request item_name if sys.version_info[ 2] > 2 6 assert item_name in dir six.moves.urllib.request getattr six.moves.urllib.request item_name
def create_request_object request_dict r request_dictrequest_object AWSRequest method r['method'] url r['url'] data r['body'] headers r['headers'] request_object.context.update r['context'] return request_object
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def fill_diagonal_offset a val offset return fill_diagonal_offset_ a val offset
@with_setup prepare_stdout def test_output_with_success_colorless runner Runner join_path 'ru' 'success' 'dumb.feature' verbosity 3 no_color True runner.run assert_stdout_lines u'\n\u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b \u0442\u0443\u043f\u0430\u044f\u0444\u0438\u0447\u0430#tests/functional/language_specific_features/ru/success/dumb.feature 3\n\u0427\u0442\u043e\u0431\u044blettuce\u0431\u044b\u043b\u0431\u043e\u043b\u0435\u0435\u043d\u0430\u0434\u0435\u0436\u043d\u044b\u043c#tests/functional/language_specific_features/ru/success/dumb.feature 4\n\u041a\u0430\u043a\u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0441\u0442#tests/functional/language_specific_features/ru/success/dumb.feature 5\n\u042f\u0445\u043e\u0447\u0443\u0447\u0442\u043e\u0431\u044b\u0442\u0435\u0441\u0442\u0431\u044b\u043b\u0437\u0435\u043b\u0435\u043d\u044b\u0439#tests/functional/language_specific_features/ru/success/dumb.feature 6\n\n\u0421\u0446\u0435\u043d\u0430\u0440\u0438\u0439 \u041d\u0438\u0447\u0435\u0433\u043e\u043d\u0435\u0434\u0435\u043b\u0430\u0442\u044c#tests/functional/language_specific_features/ru/success/dumb.feature 8\n\u041f\u0443\u0441\u043a\u0430\u044f\u044f\u043d\u0438\u0447\u0435\u0433\u043e\u043d\u0435\u0434\u0435\u043b\u0430\u044e#tests/functional/language_specific_features/ru/success/dumb_steps.py 6\n\u0422\u043e\u0433\u0434\u0430\u044f\u0432\u0438\u0436\u0443\u0447\u0442\u043e\u0442\u0435\u0441\u0442\u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442\u0441\u044f#tests/functional/language_specific_features/ru/success/dumb_steps.py 10\n\n1feature 1passed \n1scenario 1passed \n2steps 2passed \n'
def config_dict filename f open filename 'r' cfglines f.readlines f.close cfgdict {}for line in cfglines line line.strip if not line or line.startswith '#' continuetry key value line.split ' ' except print 'Badlineinconfig-file%s \n%s' % filename line continuekey key.strip value value.strip if value in ['True' 'False' 'None' "''" '""'] value eval value else try if '.' in value value float value else value int value except passcfgdict[key] valuereturn cfgdict
def delete_recurring_runs **filter_data to_delete models.RecurringRun.query_objects filter_data to_delete.delete
def solve a b try return linalg.solve a b except linalg.LinAlgError return np.dot linalg.pinv a b
def _bgp_dispatcher payload cls conf.raw_layerif payload is None cls _get_cls 'BGPHeader' conf.raw_layer elif len payload > _BGP_HEADER_SIZE and payload[ 16] _BGP_HEADER_MARKER message_type struct.unpack '!B' payload[18] [0]if message_type 4 cls _get_cls 'BGPKeepAlive' else cls _get_cls 'BGPHeader' return cls
def set_node_schedulability facts if 'node' in facts if 'schedulable' not in facts['node'] if 'master' in facts facts['node']['schedulable'] Falseelse facts['node']['schedulable'] Truereturn facts
def datetime_format_to_js_time_format format try format format.split [1]except IndexError passconverted formatreplacements {'%H' 'hh' '%I' 'HH' '%M' 'ii' '%S' 'ss'}for search replace in replacements.items converted converted.replace search replace return converted.strip
def render_constants generate_file 'constant_enums.pxi' cython_enums pjoin root 'zmq' 'backend' 'cython' generate_file 'constants.pxi' constants_pyx pjoin root 'zmq' 'backend' 'cython' generate_file 'zmq_constants.h' ifndefs pjoin root 'zmq' 'utils'
def _defragment_mountpoint mountpoint out __salt__['cmd.run_all'] 'btrfsfilesystemdefragment-f{0}'.format mountpoint return {'mount_point' mountpoint 'passed' not out['stderr'] 'log' out['stderr'] or False 'range' False}
def get_type_from_spec_info spec_info if u'anexistingfilename' in spec_info or u'inputvolumes' in spec_info return u'File'elif u'aninteger' in spec_info or u'afloat' in spec_info return u'Number'elif u'aboolean' in spec_info return u'Boolean'return u'String'
def float_format number return '%.3f' % number .rstrip '0' .rstrip '.'
def file_in_same_dir ref_file desired_file return os.path.join * split_path ref_file [ -1 ] + [desired_file]
def view_roots r owner r.ownerif owner is not None try view_map owner.op.view_mapview_map dict owner.outputs[o] i for o i in iteritems view_map except AttributeError return [r]if r in view_map answer []for i in view_map[r] answer + view_roots owner.inputs[i] return answerelse return [r]else return [r]
def _yield_all_instances emr_conn cluster_id *args **kwargs for resp in _repeat emr_conn.list_instances cluster_id *args **kwargs for instance in getattr resp 'instances' [] yield instance
def _get_rcvar name jail None if not available name jail log.error 'Service{0}notfound'.format name return Falsecmd '{0}{1}rcvar'.format _cmd jail name for line in __salt__['cmd.run_stdout'] cmd python_shell False .splitlines if '_enable "' not in line continue rcvar _ line.split ' ' 1 return rcvarreturn None
def cluster_distance cluster1 cluster2 distance_agg min return distance_agg [distance input1 input2 for input1 in get_values cluster1 for input2 in get_values cluster2 ]
def uses_database name 'sqlite3' try engine settings.DATABASES['default']['ENGINE']except KeyError engine settings.DATABASE_ENGINEreturn engine 'django.db.backends.%s' % name
def code_verifier n_bytes 64 verifier base64.urlsafe_b64encode os.urandom n_bytes .rstrip ' ' if len verifier < 43 raise ValueError 'Verifiertooshort.n_bytesmustbe>30.' elif len verifier > 128 raise ValueError 'Verifiertoolong.n_bytesmustbe<97.' else return verifier
def execute_without_nm *cmd **kwargs funcs {test_data.sensor_status_cmd get_sensor_status_uninit test_data.init_sensor_cmd init_sensor_agent test_data.sdr_dump_cmd sdr_dump}return _execute funcs *cmd **kwargs
def mkpartfs device part_type fs_type start end _validate_device device if part_type not in set ['primary' 'logical' 'extended'] raise CommandExecutionError 'Invalidpart_typepassedtopartition.mkpartfs' if fs_type not in set ['ext2' 'fat32' 'fat16' 'linux-swap' 'reiserfs' 'hfs' 'hfs+' 'hfsx' 'NTFS' 'ufs' 'xfs'] raise CommandExecutionError 'Invalidfs_typepassedtopartition.mkpartfs' _validate_partition_boundary start _validate_partition_boundary end cmd 'parted-m-s--{0}mkpart{1}{2}{3}{4}'.format device part_type fs_type start end out __salt__['cmd.run'] cmd .splitlines return out
def resource_id_from_record_tuple record return record[0]['resource_id']
def ones_and_zeros digits return bin random.getrandbits digits .lstrip '0b' .zfill digits
def constr_mul constraints var_dict vec_size is_abs product np.zeros vec_size offset 0for constr in constraints result mul constr.expr var_dict is_abs rows cols constr.sizefor col in range cols if np.isscalar result product[offset offset + rows ] resultelse product[offset offset + rows ] np.squeeze result[ col] offset + rowsreturn product
def triangle_sequence creation_sequence cs creation_sequenceseq []dr cs.count 'd' dcur dr - 1 * dr - 2 // 2 irun 0drun 0for i sym in enumerate cs if sym 'd' drun + 1tri dcur + dr - 1 * irun else if prevsym 'd' dcur + dr - 1 * irun irun 0dr - drundrun 0irun + 1tri dr * dr - 1 // 2 seq.append tri prevsym symreturn seq
def no_spm if u'NIPYPE_NO_MATLAB' in os.environ or Info.version is None return Trueelse return False
def test_bitwiseshift _test_interop_set clr_integer_types py_integer_types bitwise_test_cases
@image_comparison baseline_images [u'tight_layout8'] def test_tight_layout8 fig plt.figure fig.set_tight_layout {u'pad' 0.1} ax fig.add_subplot 111 example_plot ax fontsize 24
def technical_500_response request exc_type exc_value tb reporter ExceptionReporter request exc_type exc_value tb html reporter.get_traceback_html return HttpResponseServerError html mimetype 'text/html'
def gitCommit name commit check_output ['git' 'show' name] universal_newlines True .split '\n' [0]assert commit[ 7] 'commit' return commit[7 ]
@hug.default_input_format 'application/made-up' def made_up_formatter data return data
def drop_x_cc_block_id store store.sql 'DROPINDEXx_cc_block_id'
def int_conv value try value int value except value 0return value
def read_big fid size None buf_size 16777216if size is None if not isinstance fid gzip.GzipFile size os.fstat fid.fileno .st_size - fid.tell if size is not None segments np.r_[ np.arange 0 size buf_size size ]buf bytearray '' * size for start end in zip segments[ -1 ] segments[1 ] data fid.read int end - start if len data ! end - start raise ValueError 'Readerror' buf[start end] databuf bytes buf else buf ['']new fid.read buf_size while len new > 0 buf.append new new fid.read buf_size buf ''.join buf return buf
def generate_test machines hostname profilers timeout_start timeout_stop timeout_sync 180 control_file []for profiler in profilers control_file.append 'job.profilers.add %s ' % _encode_args *profiler profiler_sync_call _RUNTEST_PATTERN % timeout_sync timeout_start timeout_stop hostname _PROF_MASTER machines control_file.append profiler_sync_call for profiler in reversed profilers control_file.append "job.profilers.delete '%s' " % profiler[0] return '\n'.join control_file
def deduce_alpha_implications implications implications implications + [ Not j Not i for i j in implications] res defaultdict set full_implications transitive_closure implications for a b in full_implications if a b continueres[a].add b for a impl in res.items impl.discard a na Not a if na in impl raise ValueError 'implicationsareinconsistent %s->%s%s' % a na impl return res
def set_vif_host_backend_bridge_config conf brname tapname None conf.net_type 'bridge'conf.source_dev brnameif tapname conf.target_dev tapname
def isFinite value return _exponent value ! 2047
def active_code return get_link_suffix 'viewfinder'
def connect_entry_signals post_save.connect ping_directories_handler sender Entry dispatch_uid ENTRY_PS_PING_DIRECTORIES post_save.connect ping_external_urls_handler sender Entry dispatch_uid ENTRY_PS_PING_EXTERNAL_URLS post_save.connect flush_similar_cache_handler sender Entry dispatch_uid ENTRY_PS_FLUSH_SIMILAR_CACHE post_delete.connect flush_similar_cache_handler sender Entry dispatch_uid ENTRY_PD_FLUSH_SIMILAR_CACHE
def calc_chksums buf unsigned_chksum 256 + sum struct.unpack '148B' buf[ 148] + struct.unpack '356B' buf[156 512] signed_chksum 256 + sum struct.unpack '148b' buf[ 148] + struct.unpack '356b' buf[156 512] return unsigned_chksum signed_chksum
def test_exclude_columns table UnorderedTable [] exclude u'i' assert table.columns.names [u'alpha' u'beta'] class PartialTable UnorderedTable class Meta exclude u'alpha' table PartialTable [] assert table.columns.names [u'i' u'beta'] class AddonTable PartialTable added tables.Column table AddonTable [] assert table.columns.names [u'i' u'beta' u'added'] class ExcludeTable UnorderedTable added tables.Column class Meta exclude u'beta' table ExcludeTable [] assert table.columns.names [u'i' u'alpha' u'added']
def _osx_platform_data cmd 'system_profilerSPHardwareDataType'hardware __salt__['cmd.run'] cmd grains {}for line in hardware.splitlines field_name _ field_val line.partition ' ' if field_name.strip 'ModelName' key 'model_name'grains[key] _clean_value key field_val if field_name.strip 'BootROMVersion' key 'boot_rom_version'grains[key] _clean_value key field_val if field_name.strip 'SMCVersion system ' key 'smc_version'grains[key] _clean_value key field_val if field_name.strip 'SerialNumber system ' key 'system_serialnumber'grains[key] _clean_value key field_val return grains
def UseBasicAuth service username password for_proxy False deprecation 'callingdeprecatedfunctionUseBasicAuth' base_64_string base64.encodestring '%s %s' % username password base_64_string base_64_string.strip if for_proxy header_name 'Proxy-Authorization'else header_name 'Authorization'service.additional_headers[header_name] 'Basic%s' % base_64_string
@frappe.whitelist def get_all_nodes tree_method tree_args parent tree_method frappe.get_attr tree_method if not tree_method in frappe.whitelisted frappe.throw _ u'NotPermitted' frappe.PermissionError frappe.local.form_dict frappe._dict json.loads tree_args frappe.local.form_dict.parent parentdata tree_method out [dict parent parent data data ]to_check [d.value for d in data if d.expandable]while to_check frappe.local.form_dict.parent to_check.pop data tree_method out.append dict parent frappe.local.form_dict.parent data data for d in data if d.expandable to_check.append d.value return out
def test_set_source_model model1 base.BaseCompletionModel model2 base.BaseCompletionModel filter_model sortfilter.CompletionFilterModel model1 filter_model.set_pattern 'foo' assert filter_model.srcmodel is model1 assert filter_model.sourceModel is model1 assert filter_model.pattern 'foo' filter_model.setSourceModel model2 assert filter_model.srcmodel is model2 assert filter_model.sourceModel is model2 assert not filter_model.pattern
def should_recompile source_files 'conv_util.cu' 'conv_util.cuh' 'cudaconv2.cuh' 'filter_acts.cu' 'img_acts.cu' 'nvmatrix.cu' 'nvmatrix.cuh' 'nvmatrix_kernels.cu' 'nvmatrix_kernels.cuh' 'nvmatrix_operators.cuh' 'weight_acts.cu' stat_times [os.stat os.path.join this_dir source_file [stat.ST_MTIME] for source_file in source_files]date max stat_times _logger.debug 'maxdate %f' date if not os.path.exists cuda_convnet_so or date > os.stat cuda_convnet_so [stat.ST_MTIME] return Truereturn False
def getOutputFileName originalFileName outputExtension index None return os.path.splitext originalFileName [0] + outputExtension
@must_be_valid_project@must_have_permission ADMIN def node_identifiers_post auth node **kwargs if not node.is_public or node.is_retracted raise HTTPError http.BAD_REQUEST if node.get_identifier 'doi' or node.get_identifier 'ark' raise HTTPError http.BAD_REQUEST try identifiers _get_or_create_identifiers node except HTTPError raise HTTPError http.BAD_REQUEST for category value in identifiers.iteritems node.set_identifier_value category value node.add_log NodeLog.EXTERNAL_IDS_ADDED params {'parent_node' node.parent_id 'node' node._id 'identifiers' identifiers} auth auth return identifiers http.CREATED
@not_implemented_for 'multigraph' def _triangles_and_degree_iter G nodes None if nodes is None nodes_nbrs G.adj.items else nodes_nbrs n G[n] for n in G.nbunch_iter nodes for v v_nbrs in nodes_nbrs vs set v_nbrs - {v} gen_degree Counter [len vs & set G[w] - {w} for w in vs] ntriangles sum [ k * val for k val in gen_degree.items ] yield v len vs ntriangles gen_degree
def package pkg_name repos None yes None options None if not is_installed pkg_name install pkg_name repos yes options
def _access_rule method ip None port None proto 'tcp' direction 'in' port_origin 'd' ip_origin 'd' comment '' if _status_csf if ip is None return {'error' 'YoumustsupplyanipaddressorCIDR.'}if port is None args _build_args method ip comment return __csf_cmd args else if method not in ['allow' 'deny'] return {'error' 'Onlyallowanddenyrulesareallowedwhenspecifyingaport.'}return _access_rule_with_port method method ip ip port port proto proto direction direction port_origin port_origin ip_origin ip_origin comment comment
def _getfinder global _finder_talkerif not _finder_talker _finder_talker Finder.Finder _finder_talker.send_flags _finder_talker.send_flags | AppleEvents.kAECanInteract | AppleEvents.kAECanSwitchLayer return _finder_talker
def acquire_for pid_dir num_available 1 kill_signal None my_pid my_cmd pid_file get_info pid_dir if not os.path.exists pid_dir os.mkdir pid_dir os.chmod pid_dir 511 pids {pid for pid in _read_pids_file pid_file if getpcmd pid my_cmd }if kill_signal is not None for pid in pids os.kill pid kill_signal print 'SentkillsignaltoPids {}'.format pids num_available + 1if len pids > num_available print 'Pid s {}alreadyrunning'.format pids if kill_signal is not None print 'Note Therehave probably been1other"--take-lock"processwhichcontinuedtorun!Probablynoneedtorunthisoneaswell.' return False_write_pids_file pid_file pids | {my_pid} return True
def test_immunohistochemistry data.immunohistochemistry
def _cleanup_callback option opt_str value parser result []for choice in value.split ' ' if choice in CLEANUP_CHOICES result.append choice else parser.error '%sgot%s whichisnotoneof %s' % opt_str choice ' '.join CLEANUP_CHOICES if 'NONE' in result and len set result > 1 parser.error '%s Cannotcleanupbothnothingandsomething!' % opt_str setattr parser.values option.dest result
def register_sync_strategy session strategy_cls sync_type 'file_at_src_and_dest' strategy strategy_cls sync_type strategy.register_strategy session
def capture_signals return CaptureSignals ALL_SIGNALS
def maximal_independent_set G nodes None if not nodes nodes set [random.choice list G ] else nodes set nodes if not nodes.issubset G raise nx.NetworkXUnfeasible '%sisnotasubsetofthenodesofG' % nodes neighbors set.union *[set G.neighbors v for v in nodes] if set.intersection neighbors nodes raise nx.NetworkXUnfeasible '%sisnotanindependentsetofG' % nodes indep_nodes list nodes available_nodes set G.nodes .difference neighbors.union nodes while available_nodes node random.choice list available_nodes indep_nodes.append node available_nodes.difference_update list G.neighbors node + [node] return indep_nodes
def add_validator segmentation_type validator_function if segmentation_type in _supported msg _ 'Cannotredefineexisting%ssegmentationtype' % segmentation_type raise KeyError msg _supported[segmentation_type] validator_function
def isCarbonTk assert _tk_type is not None return _tk_type 'carbon'
@block_user_agents@require_GET@allow_CORS_GET@process_document_path@prevent_indexingdef as_json request document_slug None document_locale None kwargs {'locale' request.LANGUAGE_CODE 'current_revision__isnull' False}if document_slug is not None kwargs['slug'] document_slugkwargs['locale'] document_localeelif 'title' in request.GET kwargs['title'] request.GET['title']elif 'slug' in request.GET kwargs['slug'] request.GET['slug']else return HttpResponseBadRequest document get_object_or_404 Document **kwargs kuma.wiki.content.parse document.html .injectSectionIDs .serialize stale Trueif request.user.is_authenticated ua_cc request.META.get 'HTTP_CACHE_CONTROL' if ua_cc 'no-cache' stale Falsedata document.get_json_data stale stale return JsonResponse data
def coerce data egdata pdata pack data pegdata pack egdata pdata pdata.AECoerceDesc pegdata.type return unpack pdata
def get_credit_requirements course_key namespace None requirements CreditRequirement.get_course_requirements course_key namespace return [{'namespace' requirement.namespace 'name' requirement.name 'display_name' requirement.display_name 'criteria' requirement.criteria} for requirement in requirements]
def _execute3 *args **kargs cmd args[1 -3 ] if args[0] 'raidcom' else args result EXECUTE_TABLE3.get cmd CMD_SUCCEED if cmd 'pairevtwait' '-d' CONFIG_MAP['serial'] 1 '-nowaits' '-IM%s' % INST_NUMS[1] EXECUTE_TABLE3.update { 'pairevtwait' '-d' CONFIG_MAP['serial'] 1 '-nowaits' '-IM%s' % INST_NUMS[1] vsp_horcm.PSUE STDOUT STDERR } return result
def test_run_link start_link count 1000 if isinstance start_link basestring start_link int start_link 36 links Link._byID range start_link - count start_link data True return_dict False uploader SolrLinkUploader things links return uploader.inject
def test_debug_error_message prev_value config.compute_test_valuefor mode in ['ignore' 'raise'] try config.compute_test_value modetry op.debug_error_message 'msg' raised Falseexcept ValueError raised Trueassert raisedfinally config.compute_test_value prev_value
def get_primary_language current_site None current_site current_site or Site.objects.get_current return get_languages [current_site.id][0]['code']
def compose_all stream Loader Loader loader Loader stream while loader.check_node yield loader.get_node
def textinfo_from_path path encoding None follow_symlinks False quick_determine_lang False return TextInfo.init_from_path path encoding encoding follow_symlinks follow_symlinks quick_determine_lang quick_determine_lang
def CreateExtensionSetting client feed_items campaign_feed feed_item_ids platform_restrictions None campaign_extension_setting_service client.GetService 'CampaignExtensionSettingService' 'v201609' extension_feed_items [{CreateSitelinkFeedItem feed_items feed_item_id } for feed_item_id in feed_item_ids]extension_setting {'extensions' extension_feed_items}if platform_restrictions extension_setting['platformRestrictions'] platform_restrictionscampaign_extension_setting {'campaignId' campaign_feed['campaignId'] 'extensionType' 'SITELINK' 'extensionSetting' extension_setting}operation {'operand' campaign_extension_setting 'operator' 'ADD'}campaign_extension_setting_service.mutate [operation]
@Profiler.profiledef test_orm_query_cols_only n session Session bind engine for id_ in random.sample ids n session.query Customer.id Customer.name Customer.description .filter Customer.id id_ .one
@transaction_taskdef send_first_edit_email revision_pk revision Revision.objects.get pk revision_pk user doc revision.creator revision.document subject u'[MDN][% loc s]% user smadetheirfirstedit to % doc s' % {'loc' doc.locale 'user' user.username 'doc' doc.title} message render_to_string 'wiki/email/edited.ltxt' context_dict revision doc_url absolutify doc.get_absolute_url email EmailMessage subject message settings.DEFAULT_FROM_EMAIL to [config.EMAIL_LIST_SPAM_WATCH] headers {'X-Kuma-Document-Url' doc_url 'X-Kuma-Editor-Username' user.username} email.send
def copy_missing_vector a b missing inplace False prefix None if prefix is None prefix find_best_blas_type a b [0]copy prefix_copy_missing_vector_map[prefix]if not inplace b np.copy b order 'F' try if not a.is_f_contig raise ValueError except a np.asfortranarray a copy a b np.asfortranarray missing return b
def filer_image_from_data request path file_name file_data sha1 None if sha1 is True sha1 hashlib.sha1 file_data .hexdigest upload_data ContentFile file_data file_name return _filer_file_from_upload model Image request request path path upload_data upload_data sha1 sha1
def test_parametrized_collected_from_command_line testdir py_file testdir.makepyfile '\nimportpytest\n@pytest.mark.parametrize "arg" [None 1.3 "2-3"] \ndeftest_func arg \npass\n' file_name os.path.basename py_file.strpath rec testdir.inline_run file_name + ' ' + 'test_func' rec.assertoutcome passed 3
def test_passthrough_context form SampleForm form.helper FormHelper form.helper.template u'custom_form_template_with_context.html'c {u'prefix' u'foo' u'suffix' u'bar'}html render_crispy_form form helper form.helper context c assert u'Gotprefix foo' in html assert u'Gotsuffix bar' in html
def _apply_scaling_cov data picks_list scalings scalings _check_scaling_inputs data picks_list scalings scales Noneif isinstance scalings dict n_channels len data covinds list zip *picks_list [1]assert len data sum len k for k in covinds assert list sorted np.concatenate covinds list range len data scales np.zeros n_channels for ch_t idx in picks_list scales[idx] scalings[ch_t]elif isinstance scalings np.ndarray if len scalings ! len data raise ValueError 'Scalingfactorsanddataareofincompatibleshape' scales scalingselif scalings is None passelse raise RuntimeError 'Arff...' if scales is not None assert np.sum scales 0.0 0 data * scales[None ] * scales[ None]
def to_fahrenheit celsius return celsius * 1.8 + 32
def strip_headers post if '\n\n' in post headers body post.split '\n\n' 1 return body.lower else return post.lower
def can_access_account func @wraps func def wrapper *args **kwargs user getattr g 'user' None user_id kwargs.get 'user_id' get_object_or_404 UserModel user_id if user and user.id user_id or user.is_staff return func *args **kwargs else raise PermissionDeniedError return wrapper
def _IsColor color if not isinstance color basestring return Falsecolor color.strip '#' if len color ! 3 and len color ! 6 return Falsehex_letters '0123456789abcdefABCDEF'for letter in color if letter not in hex_letters return Falsereturn True
def _validate_str_list arg if isinstance arg six.string_types ret [arg]elif isinstance arg Iterable and not isinstance arg Mapping ret []for item in arg if isinstance item six.string_types ret.append item else ret.append str item else ret [str arg ]return ret
def editor_test from spyder.utils.qthelpers import qapplicationapp qapplication dialog CollectionsEditor dialog.setup get_test_data dialog.show app.exec_
def has_method obj name return callable getattr obj name None
def _check_dir_meta name user group mode follow_symlinks False stats __salt__['file.stats'] name None follow_symlinks changes {}if not stats changes['directory'] 'new'return changesif user is not None and user ! stats['user'] and user ! stats.get 'uid' changes['user'] userif group is not None and group ! stats['group'] and group ! stats.get 'gid' changes['group'] groupsmode salt.utils.normalize_mode stats['mode'] mode salt.utils.normalize_mode mode if mode is not None and mode ! smode changes['mode'] modereturn changes
def _many_to_one input_dict return dict key val for keys val in input_dict.items for key in keys
def require_collection_playable handler def test_can_play self collection_id **kwargs 'Checkifthecurrentusercanplaythecollection.'actor rights_manager.Actor self.user_id can_play actor.can_play feconf.ACTIVITY_TYPE_COLLECTION collection_id can_view actor.can_view feconf.ACTIVITY_TYPE_COLLECTION collection_id if can_play and can_view return handler self collection_id **kwargs else raise self.PageNotFoundExceptionreturn test_can_play
def read_plain file_obj type_ count if count 0 return []conv DECODE_PLAIN[type_]return conv file_obj count
def get_entry_point_abs_path pack None entry_point None if not entry_point return Noneif os.path.isabs entry_point pack_base_path get_pack_base_path pack_name pack common_prefix os.path.commonprefix [pack_base_path entry_point] if common_prefix ! pack_base_path raise ValueError 'Entrypointfile"%s"islocatedoutsideofthepackdirectory' % entry_point return entry_pointentry_point_abs_path get_pack_resource_file_abs_path pack_ref pack resource_type 'action' file_path entry_point return entry_point_abs_path
def _make_profile_image_name username hash_input settings.PROFILE_IMAGE_SECRET_KEY + username return hashlib.md5 hash_input.encode 'utf-8' .hexdigest
def local_job cmd pollpath name queue to_submit '%s;echo$?>%s' % cmd pollpath return to_submit
def _Connect region ec2_region Nonefor r in regions if r.name region ec2_region rbreakassert ec2_region is not None '"%s"notinthelistofec2regions %s' % region ' '.join kValidRegions return boto.connect_ec2 region ec2_region
def _allow_join_condition statement if not statement or not statement.tokens return Falselast_tok statement.token_prev len statement.tokens [1]return last_tok.value.lower in 'on' 'and' 'or'
def _create_temporary path return _create_carefully '%s.%s.%s.%s' % path int time.time socket.gethostname os.getpid
def contextfunction f f.contextfunction Truereturn f
def outputter data return data
def edge_load_centrality G cutoff False betweenness {}for u v in G.edges betweenness[ u v ] 0.0betweenness[ v u ] 0.0for source in G ubetween _edge_betweenness G source cutoff cutoff for e ubetweenv in ubetween.items betweenness[e] + ubetweenvreturn betweenness
def _read_images sprites dict files tf.gfile.Glob tf.flags.FLAGS.data_filepattern for f in files image scipy.misc.imread f m re.search 'image_ [0-9]+ _ [0-9]+ _ [0-9]+ .jpg' os.path.basename f if m.group 1 not in sprites sprites[m.group 1 ] dict character sprites[m.group 1 ]if m.group 2 not in character character[m.group 2 ] dict pose character[m.group 2 ]pose[int m.group 3 ] imagereturn sprites
def user_password_not_empty key data errors context if data.get 'password_hash' missing is not missing and authz.is_sysadmin context.get 'user' returnif not 'password1' in data and not 'password2' in data password data.get 'password' None if not password errors[key].append _ 'Missingvalue'
def _netstat_linux ret []cmd 'netstat-tulpnea'out __salt__['cmd.run'] cmd for line in out.splitlines comps line.split if line.startswith 'tcp' ret.append {'proto' comps[0] 'recv-q' comps[1] 'send-q' comps[2] 'local-address' comps[3] 'remote-address' comps[4] 'state' comps[5] 'user' comps[6] 'inode' comps[7] 'program' comps[8]} if line.startswith 'udp' ret.append {'proto' comps[0] 'recv-q' comps[1] 'send-q' comps[2] 'local-address' comps[3] 'remote-address' comps[4] 'user' comps[5] 'inode' comps[6] 'program' comps[7]} return ret
def subscribe document_class query sub_id schema None topic None lease_duration_sec DEFAULT_LEASE_DURATION_SEC assert schema is None topic _get_document_topic document_class topic schema _model_to_entity_schema document_class return prospective_search.subscribe datastore.Entity query sub_id schema schema topic topic lease_duration_sec lease_duration_sec
def pyimplementation if hasattr _platform u'python_implementation' return _platform.python_implementation elif sys.platform.startswith u'java' return u'Jython' + sys.platform elif hasattr sys u'pypy_version_info' v u'.'.join str p for p in sys.pypy_version_info[ 3] if sys.pypy_version_info[3 ] v + u'-' + u''.join str p for p in sys.pypy_version_info[3 ] return u'PyPy' + v else return u'CPython'
def format_for_columns pkgs options running_outdated options.outdatedif running_outdated header ['Package' 'Version' 'Latest' 'Type']else header ['Package' 'Version']data []if any dist_is_editable x for x in pkgs header.append 'Location' for proj in pkgs row [proj.project_name proj.version]if running_outdated row.append proj.latest_version row.append proj.latest_filetype if dist_is_editable proj row.append proj.location data.append row return data header
def trapzWarp pic cx cy ismask False Y X pic.shape[ 2]src np.array [[0 0] [X 0] [X Y] [0 Y]] dst np.array [[ cx * X cy * Y ] [ 1 - cx * X cy * Y ] [X Y] [0 Y]] tform tf.ProjectiveTransform tform.estimate src dst im tf.warp pic tform.inverse output_shape Y X return im if ismask else im * 255 .astype 'uint8'
def _check_is_permutation indices n_samples if len indices ! n_samples return Falsehit np.zeros n_samples dtype bool hit[indices] Trueif not np.all hit return Falsereturn True
def compute_node_delete context compute_id return IMPL.compute_node_delete context compute_id
def _convert_unsigned data fmt num len data return struct.unpack '{0}{0}'.format num fmt.upper .encode u'utf-8' struct.pack '{0}{0}'.format num fmt .encode u'utf-8' *data
def _is_mobile ntype return ntype PhoneNumberType.MOBILE or ntype PhoneNumberType.FIXED_LINE_OR_MOBILE or ntype PhoneNumberType.PAGER
def killall greenlets exception GreenletExit block True timeout None greenlets list greenlets if not greenlets returnloop greenlets[0].loopif block waiter Waiter loop.run_callback _killall3 greenlets exception waiter t Timeout._start_new_or_dummy timeout try alive waiter.get if alive joinall alive raise_error False finally t.cancel else loop.run_callback _killall greenlets exception
def _api_key_patch_remove conn apiKey pvlist response conn.update_api_key apiKey apiKey patchOperations _api_key_patchops 'remove' pvlist return response
def get_saved_rules conf_file None family 'ipv4' return _parse_conf conf_file conf_file family family
@task@needs 'pavelib.prereqs.install_prereqs' @cmdopts [ 'settings ' 's' 'Djangosettings' ] def celery options settings getattr options 'settings' 'dev_with_worker' run_process django_cmd 'lms' settings 'celery' 'worker' '--beat' '--loglevel INFO' '--pythonpath .'
def command_map args if multiprocessing.current_process .name ! 'MainProcess' logger.initMultiprocessing try return command *args except Exception logger.exception 'Encoderraisedanexception.' return False
def set_hidden module_name user None hidden 1 if user icon get_user_copy module_name user if hidden and icon.custom frappe.delete_doc icon.doctype icon.name ignore_permissions True returnicon.db_set u'hidden' hidden else icon frappe.get_doc u'DesktopIcon' {u'standard' 1 u'module_name' module_name} icon.db_set u'blocked' hidden
@_get_clientdef task_delete client task_id session None return client.task_delete task_id task_id session session
def handle_process_exit_code exit_code if os.WIFSIGNALED exit_code exit_code - os.WTERMSIG exit_code elif os.WIFEXITED exit_code exit_code os.WEXITSTATUS exit_code else raise RuntimeError 'Unknownchildexitstatus!' return exit_code
def synchronize reference stream key lambda x x unused None for left right in leftjoin reference stream key unused yield right
def _representing_matrices basis G ring domain ring.domainu ring.ngens - 1 def var i return tuple [0] * i + [1] + [0] * u - i def representing_matrix m M [ [domain.zero] * len basis for _ in range len basis ]for i v in enumerate basis r ring.term_new monomial_mul m v domain.one .rem G for monom coeff in r.terms j basis.index monom M[j][i] coeffreturn Mreturn [representing_matrix var i for i in range u + 1 ]
def filename_to_title filename if utils.is_homepage filename return u'Home'return utils.filename_to_title filename
def _spatial_median X max_iter 300 tol 0.001 if X.shape[1] 1 return 1 np.median X.ravel tol ** 2spatial_median_old np.mean X axis 0 for n_iter in range max_iter spatial_median _modified_weiszfeld_step X spatial_median_old if np.sum spatial_median_old - spatial_median ** 2 < tol breakelse spatial_median_old spatial_medianelse warnings.warn 'Maximumnumberofiterations{max_iter}reachedinspatialmedianforTheilSenregressor.'.format max_iter max_iter ConvergenceWarning return n_iter spatial_median
def _buildAB lap_sparse labels labels labels[ labels > 0 ]indices np.arange labels.size unlabeled_indices indices[ labels 0 ]seeds_indices indices[ labels > 0 ]B lap_sparse[unlabeled_indices][ seeds_indices]lap_sparse lap_sparse[unlabeled_indices][ unlabeled_indices]nlabels labels.max rhs []for lab in range 1 nlabels + 1 mask labels[seeds_indices] lab fs sparse.csr_matrix mask fs fs.transpose rhs.append B * fs return lap_sparse rhs
def delay_denial func func.delay_denial True@functools.wraps func def wrapped *a **kw return func *a **kw return wrapped
def add_new_message id user user_profile text try if not verification_user id user return get_new_message_for_user user if checking_conference id conferences get_memcached get_key 'conferences' for key in conferences[id]['users'].keys conferences[id]['users'][key]['messages'].append dict user user text text time strftime '%H %M %S' date strftime '%Y-%m-%d' profile user_profile set_memcached get_key 'conferences' conferences except data json.dumps {'cmd' 'Error' 'data' {'msg' str sys.exc_info }} return HttpResponse data content_type 'application/json' status 200 return get_new_message_for_user user
def __gen_rtag return os.path.join __opts__['cachedir'] 'pkg_refresh'
def get_recommended_exercises subtopic_id if not subtopic_id return []tree get_recommendation_tree generate_recommendation_data return tree[subtopic_id]
def simulate_options app path **kwargs return simulate_request app 'OPTIONS' path **kwargs
def parse_upgrade rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--root-device' dest 'root-device' action 'store' args clean_args vars parser.parse_args rules parser Noneif args return argsreturn True
def rewind_body body body_pos body_seek getattr body 'seek' None if body_seek is not None and isinstance body_pos integer_types try body_seek body_pos except IOError OSError raise UnrewindableBodyError 'Anerroroccuredwhenrewindingrequestbodyforredirect/retry.' elif body_pos is _FAILEDTELL raise UnrewindableBodyError 'Unabletorecordfilepositionforrewindingrequestbodyduringaredirect/retry.' else raise ValueError 'body_posmustbeoftypeinteger insteaditwas%s.' % type body_pos
def getNewRepository return FillRepository
def setup_multiprocessing_logging queue None from salt.utils import is_windowsglobal __MP_LOGGING_CONFIGUREDglobal __MP_LOGGING_QUEUE_HANDLERif __MP_IN_MAINPROCESS is True and not is_windows returntry logging._acquireLock if __MP_LOGGING_CONFIGURED is True return__MP_LOGGING_CONFIGURED Trueif __MP_LOGGING_QUEUE_HANDLER is not None return__remove_null_logging_handler __remove_queue_logging_handler __MP_LOGGING_QUEUE_HANDLER SaltLogQueueHandler queue or get_multiprocessing_logging_queue logging.root.addHandler __MP_LOGGING_QUEUE_HANDLER logging.root.setLevel logging.GARBAGE logging.getLogger __name__ .debug 'MultiprocessingqueueloggingconfiguredfortheprocessrunningunderPID {0}'.format os.getpid time.sleep 0.0001 finally logging._releaseLock
def test_hsl_to_rgb_part_13 assert hsl_to_rgb 0 100 0 0 0 0 assert hsl_to_rgb 0 100 10 51 0 0 assert hsl_to_rgb 0 100 20 102 0 0 assert hsl_to_rgb 0 100 30 153 0 0 assert hsl_to_rgb 0 100 40 204 0 0 assert hsl_to_rgb 0 100 50 255 0 0 assert hsl_to_rgb 0 100 60 255 51 51 assert hsl_to_rgb 0 100 70 255 102 102 assert hsl_to_rgb 0 100 80 255 153 153 assert hsl_to_rgb 0 100 90 255 204 204 assert hsl_to_rgb 0 100 100 255 255 255
def unverified_raw_input superConsole.SendKeys 'x raw_input{ }"foo "{ }{ENTER}' superConsole.SendKeys '{ENTER}'
def knownPlaintext known_key random_plaintext stallion AES.new known_key encrypted_string EncodeAES stallion random_plaintext return encrypted_string
def add_allow_top_to_srs from r2.models import Subredditfrom r2.lib.db.operators import descfrom r2.lib.utils import fetch_things2q Subreddit._query Subreddit.c._spam True False sort desc '_date' for sr in fetch_things2 q sr.allow_top Truesr._commit
def make_temp string suffix '' decode True delete True ntf NamedTemporaryFile suffix suffix delete delete if decode ntf.write base64.b64decode string else ntf.write string ntf.seek 0 return ntf ntf.name
def extractHeights array w h array.shape[ 2]heightMap zeros w h 'int16' heights argmax array > 0 [... -1 ] 2 heights array.shape[2] - heights heights[ array[... -1 ] 0 & heights array.shape[2] ] 0heightMap[ ] heightsreturn heightMap
def _get_count_effects effects exog count_ind method model params for i in count_ind exog0 exog.copy exog0[ i] - 1effect0 model.predict params exog0 exog0[ i] + 2effect1 model.predict params exog0 if 'ey' in method effect0 np.log effect0 effect1 np.log effect1 effects[ i] effect1 - effect0 / 2 return effects
def teardown_databases old_config verbosity parallel 0 keepdb False for connection old_name destroy in old_config if destroy if parallel > 1 for index in range parallel connection.creation.destroy_test_db number index + 1 verbosity verbosity keepdb keepdb connection.creation.destroy_test_db old_name verbosity keepdb
def validate_enabled enabled if isinstance enabled str if enabled.lower not in ['on' 'off' 'yes' 'no'] msg "\nMacPower InvalidStringValueforEnabled.\nStringvaluesmustbe'on'or'off'/'yes'or'no'.\nPassed {0}".format enabled raise SaltInvocationError msg return 'on' if enabled.lower in ['on' 'yes'] else 'off' return 'on' if bool enabled else 'off'
def oedit obj modal True namespace None from spyder.utils.qthelpers import qapplicationapp qapplication if modal obj_name ''else assert is_text_string obj obj_name objif namespace is None namespace globals keeper.set_namespace namespace obj namespace[obj_name]namespace['__qapp__'] appresult create_dialog obj obj_name if result is None return dialog end_func resultif modal if dialog.exec_ return end_func dialog else keeper.create_dialog dialog obj_name end_func import osif os.name 'nt' app.exec_
def to_edgelist G nodelist None if nodelist is None return G.edges data True else return G.edges nodelist data True
def get_event_transaction_type return get_cache 'event_transaction' .get 'type' None
def maybe_patch_concurrency argv sys.argv short_opts [u'-P'] long_opts [u'--pool'] patches {u'eventlet' _patch_eventlet u'gevent' _patch_gevent} try pool _find_option_with_arg argv short_opts long_opts except KeyError passelse try patcher patches[pool]except KeyError passelse patcher from celery import concurrencyconcurrency.get_implementation pool
def episode_by_id episode_id session None return session.query Episode .filter Episode.id episode_id .one
def validate_password_length value message _ 'InvalidLength {0} ' code 'length'min_length getattr settings 'PASSWORD_MIN_LENGTH' None max_length getattr settings 'PASSWORD_MAX_LENGTH' None if min_length and len value < min_length raise ValidationError message.format _ 'mustbe{0}charactersormore' .format min_length code code elif max_length and len value > max_length raise ValidationError message.format _ 'mustbe{0}charactersorfewer' .format max_length code code
def remove_logical_volumes *paths for path in paths clear_logical_volume path if paths lvremove 'lvremove' '-f' + paths execute attempts 3 run_as_root True *lvremove
def i16le c o 0 return unpack '<H' c[o o + 2 ] [0]
def block_collapse expr hasbm lambda expr isinstance expr MatrixExpr and expr.has BlockMatrix rule exhaust bottom_up exhaust condition hasbm typed {MatAdd do_one bc_matadd bc_block_plus_ident MatMul do_one bc_matmul bc_dist Transpose bc_transpose Inverse bc_inverse BlockMatrix do_one bc_unpack deblock } result rule expr try return result.doit except AttributeError return result
def resource def prep r if r.interactive if r.method in 'create' 'update' table r.tablelocation_id get_vars.get ' location ' None if location_id field table.location_idfield.default location_idfield.readable field.writable Falseorganisation_id get_vars.get ' organisation ' None if organisation_id field table.organisation_idfield.default organisation_idfield.readable field.writable Falsereturn Trues3.prep prepreturn s3_rest_controller
def draw_spectral G **kwargs draw G spectral_layout G **kwargs
@pytest.mark.parametrize 'parallel' [True False] def test_quoted_empty_values parallel read_basic if parallel pytest.xfail 'Multiprocessingcanfailwithquotedfields' text 'abc\n12"\n"'table read_basic text parallel parallel assert table['c'][0] is ma.masked
def raet_minion_run cleanup_protecteds minion daemons.Minion minion.call cleanup_protecteds cleanup_protecteds
def is_jframe_request request return request.META.get 'HTTP_X_HUE_JFRAME' or request.GET.get 'format' 'embed'
def machine_get_idx_by_hostname hostname machine machine_get_by_hostname hostname if machine is None return Nonereturn machine.machine_idx
def get_ignore_scope line keyword toignore line[ line.rfind keyword + len keyword ]if toignore.startswith 'all' return []else return list StringConverter toignore list_delimiters ' '
@receiver SignalHandler.course_published def trigger_update_xblocks_cache_task sender course_key **kwargs tasks import_module 'openedx.core.djangoapps.bookmarks.tasks' tasks.update_xblocks_cache.apply_async [unicode course_key ] countdown 0
@lower_constant types.UniTuple @lower_constant types.NamedUniTuple def unituple_constant context builder ty pyval consts [context.get_constant_generic builder ty.dtype v for v in pyval]return ir.ArrayType consts[0].type len consts consts
@login_notrequireddef show_login_page request login_errors False redirect_to request.REQUEST.get 'next' '/' is_first_login_ever OAuthBackend.is_first_login_ever request.session.set_test_cookie return render 'oauth-login.mako' request {'action' urlresolvers.reverse 'oauth_login' 'next' redirect_to 'first_login_ever' is_first_login_ever 'login_errors' request.method 'POST' or login_errors 'socialGoogle' liboauth.conf.CONSUMER_KEY_GOOGLE.get ! '' and liboauth.conf.CONSUMER_SECRET_GOOGLE.get ! '' 'socialFacebook' liboauth.conf.CONSUMER_KEY_FACEBOOK.get ! '' and liboauth.conf.CONSUMER_SECRET_FACEBOOK.get ! '' 'socialLinkedin' liboauth.conf.CONSUMER_KEY_LINKEDIN.get ! '' and liboauth.conf.CONSUMER_SECRET_LINKEDIN.get ! '' 'socialTwitter' liboauth.conf.CONSUMER_KEY_TWITTER.get ! '' and liboauth.conf.CONSUMER_SECRET_TWITTER.get ! '' }
def _get_token challenge proxy.get_challenge priv_key rsa.PrivateKey.load_pkcs1 open settings.WINDOWS_VM_SECRET .read signature rsa.sign challenge priv_key 'SHA-512' sig_b64 base64.b64encode signature return sig_b64
def int2long val return val + 4294967296 - 4294967296
def ContentGenerator csv_file batch_size create_csv_reader csv.reader create_csv_writer csv.writer try csv.field_size_limit 800000 except AttributeError passreader create_csv_reader csv_file skipinitialspace True exhausted Falsewhile not exhausted rows_written 0content StringIO.StringIO writer create_csv_writer content try for i in xrange batch_size row reader.next writer.writerow row rows_written + 1except StopIteration exhausted Trueif rows_written > 0 yield rows_written content.getvalue
def parse_gid gid try return int gid except ValueError if grp try return grp.getgrnam gid .gr_gidexcept KeyError raise KeyError 'Groupdoesnotexist %r' % gid raise
@receiver project_import def handle_project_import sender **kwargs project senderrequest kwargs.get 'request' attach_webhook project project request request
def preferences attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'preferences' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def getincrementaldecoder encoding decoder lookup encoding .incrementaldecoderif decoder is None raise LookupError encoding return decoder
def getNavigationLine contentsLinkText previousLinkText nextLinkText return '<p>\n%s/%s/%s\n</p>\n' % previousLinkText nextLinkText contentsLinkText
@block_user_agents@require_GET@allow_CORS_GET@process_document_path@prevent_indexingdef as_json request document_slug None document_locale None kwargs {'locale' request.LANGUAGE_CODE 'current_revision__isnull' False}if document_slug is not None kwargs['slug'] document_slugkwargs['locale'] document_localeelif 'title' in request.GET kwargs['title'] request.GET['title']elif 'slug' in request.GET kwargs['slug'] request.GET['slug']else return HttpResponseBadRequest document get_object_or_404 Document **kwargs kuma.wiki.content.parse document.html .injectSectionIDs .serialize stale Trueif request.user.is_authenticated ua_cc request.META.get 'HTTP_CACHE_CONTROL' if ua_cc 'no-cache' stale Falsedata document.get_json_data stale stale return JsonResponse data
def create_relative_media_url nav url parsed urlparse url if parsed.netloc return urlif url.startswith u'/' base u'/'url url[1 ]else base nav.url_context.base_pathrelative_base nav.url_context.make_relative base if relative_base u'.' and url.startswith u'./' relative_url urlelse relative_url u'%s/%s' % relative_base url if nav.file_context.current_file.endswith u'/index.md' is False and nav.url_context.base_path ! u'/' and relative_url.startswith u'./' relative_url u'.%s' % relative_url return relative_url
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def decode_base64 text encoding 'utf-8' text to_bytes text encoding return to_unicode base64.b64decode text encoding
def _tag_added sender question_id tag_name **kwargs if tag_name config.ESCALATE_TAG_NAME escalate_question.delay question_id
def last_modified_date_to_timestamp last_modified_date_str start datetime.datetime.strptime last_modified_date_str '%Y-%m-%dT%H %M %S.%f' delta start - EPOCH return Timestamp delta.total_seconds
def __ip_addr addr address_family socket.AF_INET mask_max '32'if address_family socket.AF_INET6 mask_max '128'try if '/' not in addr addr '{addr}/{mask_max}'.format addr addr mask_max mask_max except TypeError return False ip mask addr.rsplit '/' 1 try socket.inet_pton address_family ip except socket.error return Falsetry mask int mask except ValueError return Falseelse if not 1 < mask < int mask_max return Falsereturn True
def region_invalidate namespace region *args if callable namespace if not region region namespace._arg_regionnamespace namespace._arg_namespaceif not region raise BeakerException 'Regionorcallablefunctionnamespaceisrequired' else region cache_regions[region]cache Cache._get_cache namespace region cache_key ''.join str x for x in args cache.remove_value cache_key
def _get_catalogs service_type catalog_db **kwargs if catalog_db is None catalog_db get_remote_catalog_db service_type **kwargs catalogs catalog_db.get_catalogs elif isinstance catalog_db VOSDatabase catalogs catalog_db.get_catalogs elif isinstance catalog_db VOSCatalog six.string_types catalogs [ None catalog_db ]elif isinstance catalog_db list for x in catalog_db assert isinstance x VOSCatalog six.string_types and not isinstance x VOSDatabase catalogs [ None x for x in catalog_db]else raise VOSError u'catalog_dbmustbeacatalogdatabase alistofcatalogs oracatalog' return catalogs
def user_agent return 'python-social-auth-' + social.__version__
def isTrue val val val.lower return val 'true' or val 't' or val '1' or val 'yes'
def get_api_version version_string version_string str version_string if version_string in DEPRECATED_VERSIONS LOG.warning _LW 'Version% deprecated_version sisdeprecated usingalternativeversion% alternative sinstead.' {'deprecated_version' version_string 'alternative' DEPRECATED_VERSIONS[version_string]} version_string DEPRECATED_VERSIONS[version_string]if strutils.is_int_like version_string version_string '%s.0' % version_string api_version APIVersion version_string check_major_version api_version return api_version
def get_board state planes np.zeros 3 state.size state.size planes[0 ] state.board state.current_player planes[1 ] state.board - state.current_player planes[2 ] state.board go.EMPTY return planes
def _ordereddict2dict input_ordered_dict return json.loads json.dumps input_ordered_dict
@blueprint.route '/<job_id>.json' methods ['GET'] @blueprint.route '/<job_id>' methods ['GET'] def show job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' related_jobs scheduler.get_related_jobs job if request_wants_json return flask.jsonify job.json_dict True elif isinstance job model_images.ImageClassificationModelJob return model_images.classification.views.show job related_jobs related_jobs elif isinstance job model_images.GenericImageModelJob return model_images.generic.views.show job related_jobs related_jobs else raise werkzeug.exceptions.BadRequest 'Invalidjobtype'
def build_ws_upgrade_request web_socket_url extra_headers None web_socket_version DEFAULT_PROTOCOL_VERSION origin None request_headers Headers request_headers['Sec-WebSocket-Key'] gen_ws_sec_key for key value in WEBSOCKET_UPGRADE_HEADERS.items request_headers[key] valueif extra_headers is not None for key value in extra_headers request_headers[key] valuerequest_headers['Sec-WebSocket-Version'] str web_socket_version if origin is not None request_headers['Origin'] originelse scheme 'https //' if 'wss //' in web_socket_url else 'http //' args scheme web_socket_url.get_domain request_headers['Origin'] '%s%s' % args forged_url web_socket_url.url_string.replace 'wss //' 'https //' 1 forged_url forged_url.replace 'ws //' 'http //' 1 forged_url URL forged_url upgrade_request FuzzableRequest forged_url 'GET' headers request_headers return upgrade_request
def bokeh_installer env_name install_string if os.name 'nt' command_string 'activate%s&%s' % env_name install_string else command_string 'sourceactivate%s;%s' % env_name install_string result subprocess.call command_string shell True executable '/bin/bash' return result 0
def _get_plugin_methods plugin_klass methods inspect.getmembers plugin_klass inspect.ismethod method_names []for name method in methods method_properties method.__dict__is_abstract method_properties.get '__isabstractmethod__' False if is_abstract continuemethod_names.append name return method_names
def binop x op y lineno None col None lineno x.lineno if lineno is None else lineno col x.col_offset if col is None else col return ast.BinOp left x op op right y lineno lineno col_offset col
def CombinePlaces places time_resolution sorted_places sorted [{'locality' GetPlace p['placemark'] 'timestamp' p['timestamp'] 'opacity' 1.0 'num_combined' 1 'total_count' p['total_count']} for p in places] key itemgetter 'timestamp' place_list []def _GetAvgTimestamp p return p['timestamp'] / p['num_combined'] def _MaybeCombinePlace p if place_list last_place place_list[ -1 ]if p['locality'] last_place['locality'] and abs p['timestamp'] - _GetAvgTimestamp last_place < time_resolution for attr in ['timestamp' 'total_count' 'num_combined'] last_place[attr] + p[attr]returnplace_list.append p for p in sorted_places _MaybeCombinePlace p for p in place_list p['timestamp'] _GetAvgTimestamp p return place_list
def f5_reduce f B order Polyn f .ring.orderdomain Polyn f .ring.domainif not Polyn f return fwhile True g ffor h in B if Polyn h if monomial_divides Polyn h .LM Polyn f .LM t term_div Polyn f .LT Polyn h .LT domain if sig_cmp sig_mult Sign h t[0] Sign f order < 0 hp lbp_mul_term h t f lbp_sub f hp breakif g f or not Polyn f return f
def check_random_port port socket_type 'all' assert socket_type in 'all' 'tcp' 'udp' 'Invalidsockettype%s' % type socket_type assert isinstance port int 'Invalidporttype%s' % type port assert 0 < port < 65535 'Invalidportvalue%s' % port _family socket.AF_INET_sock_type Noneif socket_type 'udp' _sock_type socket.SOCK_DGRAMelif socket_type 'tcp' _sock_type socket.SOCK_STREAMis_port_working Falseif socket_type 'all' if _test_port _family socket.SOCK_DGRAM port is_port_working _test_port _family socket.SOCK_STREAM port else is_port_working _test_port _family _sock_type port return is_port_working
def _walk_vdi_chain session vdi_uuid scan_default_sr session while True vdi_ref session.call_xenapi 'VDI.get_by_uuid' vdi_uuid vdi_rec session.call_xenapi 'VDI.get_record' vdi_ref yield vdi_rec parent_uuid _get_vhd_parent_uuid session vdi_ref if not parent_uuid breakvdi_uuid parent_uuid
def isnan a return reshape array [_isnan i for i in ravel a ] 'b' shape a
def get_dhcp_leases context network_ref hosts []host Noneif network_ref['multi_host'] host CONF.hostfor data in db.network_get_associated_fixed_ips context network_ref['id'] host host if data['allocated'] and data['leased'] hosts.append _host_lease data return '\n'.join hosts
def address_pairs fields pairs list zip fields[ 2] fields[1 2] if len fields % 2 pairs.append fields[ -1 ] return pairs
def decompose_kernel_2x_once kernel for mapping in get_mappings_2x suffix becomes is_full patch_templates mappingparams {}match re.search '^ .* ' + suffix kernel if not match continueparams['full'] kernelparams['base'] match.group 1 match re.search '^ \\d+\\.\\d+ \\. \\d+ ' kernel if not match raise NameError 'Unabletodeterminemajor/minorversionforkernel%s' % kernel params['minor'] match.group 1 params['major'] match.group 2 params['minor-prev'] match.group 2 + '.%d' % int match.group 3 - 1 new_kernel becomes % params patch_list []for template in patch_templates patch_list.append template % params return is_full new_kernel patch_list return True kernel None
def add_attachments name attachments from frappe.utils.file_manager import save_urlfor a in attachments if isinstance a basestring attach frappe.db.get_value u'File' {u'name' a} [u'file_name' u'file_url' u'is_private'] as_dict 1 save_url attach.file_url attach.file_name u'Communication' name u'Home/Attachments' attach.is_private
def average_pooling_2d x ksize stride None pad 0 use_cudnn True return AveragePooling2D ksize stride pad False use_cudnn x
def set_emulated_double number double np.array [number 0] dtype np.float32 double[1] number - double[0] return double
def fixed_quad func a b args n 5 x w _cached_roots_legendre n x np.real x if np.isinf a or np.isinf b raise ValueError 'Gaussianquadratureisonlyavailableforfinitelimits.' y b - a * x + 1 / 2.0 + a return b - a / 2.0 * np.sum w * func y *args axis -1 None
def activities_from_everything_followed_by_user user_id limit offset q _activities_from_everything_followed_by_user_query user_id limit + offset return _activities_at_offset q limit offset
def save_new_collection committer_id collection commit_message "Newcollectioncreatedwithtitle'%s'." % collection.title _create_collection committer_id collection commit_message [{'cmd' CMD_CREATE_NEW 'title' collection.title 'category' collection.category}]
def _minify source_path target_path cmd 'java-jar%s%s-o%s' % YUICOMPRESSOR_DIR source_path target_path subprocess.check_call cmd shell True
def get_envs yaml_dict env get_yaml_entry yaml_dict 'env' if env is None return ''if isinstance env basestring return env + '\n' if isinstance env list tuple return env[0] + '\n' globals matrix [get_yaml_entry env name for name in 'global' 'matrix' ]if hasattr matrix 'keys' raise TravisError 'Oops envstoocomplicated' lines []if not globals is None if matrix is None raise TravisError 'globalsectionneedsmatrixsection' lines + globalsif not matrix is None lines.append matrix[0] return '\n'.join lines + '\n'
def cgsnapshot_get context cgsnapshot_id return IMPL.cgsnapshot_get context cgsnapshot_id
def process_attribute_value key value if not cfg.CONF.log.mask_secrets return valueif isinstance value SIMPLE_TYPES if key in MASKED_ATTRIBUTES_BLACKLIST value MASKED_ATTRIBUTE_VALUEelif isinstance value dict value copy.deepcopy value for dict_key dict_value in six.iteritems value value[dict_key] process_attribute_value key dict_key value dict_value return value
def test_declarations class GeoAreaTable tables.Table name tables.Column population tables.Column assert len GeoAreaTable.base_columns 2 assert u'name' in GeoAreaTable.base_columns assert not hasattr GeoAreaTable u'name' class CountryTable GeoAreaTable capital tables.Column assert len CountryTable.base_columns 3 assert u'capital' in CountryTable.base_columns class AddedMixin tables.Table added tables.Column class CityTable GeoAreaTable AddedMixin mayor tables.Column assert len CityTable.base_columns 4 assert u'added' in CityTable.base_columns class MayorlessCityTable CityTable mayor Noneassert len MayorlessCityTable.base_columns 3
def userdata_cached userterm userterm ''.join [t.strip .lower for t in userterm.split '' ] return g.username_query_cache.get userterm
def _write_instance_repr out visited name pyop_attrdict address out.write '<' out.write name if isinstance pyop_attrdict PyDictObjectPtr out.write ' ' first Truefor pyop_arg pyop_val in pyop_attrdict.items if not first out.write ' ' first Falseout.write pyop_arg.proxyval visited out.write ' ' pyop_val.write_repr out visited out.write ' ' out.write 'atremote0x%x>' % address
def LJHash hashStr size print 'HashString ' + str hashStr outBuff ctypes.c_char * 16 retBuff ''staticLib ctypes.windll.LoadLibrary 'labjackud' ec staticLib.LJHash ctypes.cast hashStr ctypes.POINTER ctypes.c_char size ctypes.cast outBuff ctypes.POINTER ctypes.c_char 0 if ec ! 0 raise LabJackException ec for i in range 16 retBuff + outBuff[i]return retBuff
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def test_completion_alone script result script.pip 'completion' expect_error True assert 'ERROR Youmustpass--bashor--fishor--zsh' in result.stderr 'completionalonefailed--' + result.stderr
def CalculateDataLength data if isinstance data str return len data elif isinstance data list return Noneelif ElementTree.iselement data return len ElementTree.tostring data elif hasattr data 'read' return Noneelse return len str data
def splprep x w None u None ub None ue None k 3 task 0 s None t None full_output 0 nest None per 0 quiet 1 res _impl.splprep x w u ub ue k task s t full_output nest per quiet return res
def _log_multivariate_normal_density_diag X means covars n_samples n_dim X.shapelpr -0.5 * n_dim * np.log 2 * np.pi + np.sum np.log covars 1 + np.sum means ** 2 / covars 1 - 2 * np.dot X means / covars .T + np.dot X ** 2 1.0 / covars .T return lpr
def FormatResults file_obj results out file_obj.name + ' \n' for result in results out + '' + result['name'] + 'fingerprinttype\n' for key value in sorted result.items if key 'name' continueout + '' + key + ' ' if type value is list for v in value if type v is tuple out + ' rev %d type %d certlen %dbytes ' % v[0] v[1] len v[2] else out + v.encode 'hex' + ' ' else out + value.encode 'hex' out + '\n'return out
def FixArgFileName fileName import os path fname os.path.split fileName if len path 0 path os.curdirpath os.path.abspath path for syspath in sys.path if os.path.abspath syspath path breakelse sys.path.append path return os.path.splitext fname [0]
def empty_str in_str if in_str is not None and not isinstance in_str string_types raise TypeError 'ArgmustbeNoneorastringtype' return in_str is None or len in_str.strip 0
def get_color_names names list _color_dict.keys names.sort return names
def wsgi_to_bytes data if isinstance data bytes return datareturn data.encode 'latin1'
def _isString obj return type obj in types.StringTypes
def api_calls_left user domain 'all' max_window _rules_for_user user [ -1 ][0]max_calls _rules_for_user user [ -1 ][1]return _get_api_calls_left user domain max_window max_calls
def _ToTimeZone t tzinfo if pytz is None return t.replace tzinfo None elif tzinfo if not t.tzinfo t pytz.utc.localize t return tzinfo.normalize t.astimezone tzinfo elif t.tzinfo return pytz.utc.normalize t.astimezone pytz.utc .replace tzinfo None else return t
def ListProjects service projects service.projects .list .execute logging.info json.dumps projects indent 2
def LocateOptionalPath fileName searchPaths try return LocatePath fileName searchPaths except KeyboardInterrupt return None
def cachedmethod f cache {} def _ *args **kwargs try key f tuple args frozenset kwargs.items if key not in cache cache[key] f *args **kwargs except key ''.join str _ for _ in f args kwargs if key not in cache cache[key] f *args **kwargs return cache[key]return _
def tp_write fd buf return get_hub .threadpool.apply_e BaseException _write fd buf
@auth.s3_requires_membership 1 def sms_outbound_gateway s3.crud_strings['msg_sms_outbound_gateway'] Storage label_create T 'CreateSMSOutboundGateway' title_display T 'SMSOutboundGatewayDetails' title_list T 'SMSOutboundGateways' title_update T 'EditSMSOutboundGateway' label_list_button T 'ListSMSOutboundGateways' label_delete_button T 'DeleteSMSOutboundGateway' msg_record_created T 'SMSOutboundGatewayadded' msg_record_modified T 'SMSOutboundGatewayupdated' msg_record_deleted T 'SMSOutboundGatewaydeleted' msg_list_empty T 'NoSMSOutboundGatewayscurrentlyregistered' return s3_rest_controller
def generate_user_certificates student course_key course None insecure False generation_mode 'batch' forced_grade None xqueue XQueueCertInterface if insecure xqueue.use_https Falsegenerate_pdf not has_html_certificates_enabled course_key course cert xqueue.add_cert student course_key course course generate_pdf generate_pdf forced_grade forced_grade if cert is None returnif CertificateStatuses.is_passing_status cert.status emit_certificate_event 'created' student course_key course {'user_id' student.id 'course_id' unicode course_key 'certificate_id' cert.verify_uuid 'enrollment_mode' cert.mode 'generation_mode' generation_mode} return cert.status
def dispersion p q None *gens **args J dispersionset p q *gens **args if not J j S.NegativeInfinityelse j max J return j
def p_labeled_statement_2 t pass
def collect_addon_assets node return {'tree_js' list collect_addon_js node 'tree_css' list collect_addon_css node }
def reload_theme value prev if value ! prev config os.path.dirname __file__ + '/colorset/' + value + '.json' data load_config config if data for d in data c[d] data[d]start_cycle set_config 'THEME' value return valuereturn prev
def validip6addr address try socket.inet_pton socket.AF_INET6 address except socket.error AttributeError return Falsereturn True
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def getRankIndex rulingSeparationWidthMillimeters screenOrdinate return int round screenOrdinate / rulingSeparationWidthMillimeters
def pwDecrypt epw masterPW None if not epw.startswith CryptoMarker return epw False if masterPW is None if MasterPassword is None __getMasterPassword if MasterPassword is None return u'' False masterPW pwDecode MasterPassword from .py3AES import decryptDatafrom .py3PBKDF2 import rehashPassword hashParameters epw epw[3 ].rsplit Delimiter 1 try key rehashPassword masterPW hashParameters [ 32]plaintext decryptData key base64.b64decode epw.encode u'ascii' except ValueError return u'' False return plaintext.decode u'utf-8' True
def get_test_hooks test_files cfg tracer None results []dirs set map os.path.dirname test_files for dir in list dirs if os.path.basename dir 'ftests' dirs.add os.path.join os.path.dirname dir 'tests' dirs list dirs dirs.sort for dir in dirs filename os.path.join dir 'checks.py' if os.path.exists filename module import_module filename cfg tracer tracer if tracer is not None hooks tracer.runfunc module.test_hooks else hooks module.test_hooks results.extend hooks return results
def encode_json data indent None return json.dumps data indent indent cls Encoder
def sanitize_hostname hostname if six.PY3 hostname hostname.encode 'latin-1' 'ignore' hostname hostname.decode 'latin-1' elif isinstance hostname six.text_type hostname hostname.encode 'latin-1' 'ignore' hostname re.sub '[_]' '-' hostname hostname re.sub '[^\\w.-]+' '' hostname hostname hostname.lower hostname hostname.strip '.-' return hostname
def list_locations provider 'all' client _get_client locations client.list_locations provider return locations
@require_http_methods 'DELETE' 'POST' 'PUT' @login_required@ensure_csrf_cookiedef _update_asset request course_key asset_key if request.method 'DELETE' try delete_asset course_key asset_key return JsonResponse except AssetNotFoundException return JsonResponse status 404 elif request.method in 'PUT' 'POST' if 'file' in request.FILES return _upload_asset request course_key else try modified_asset json.loads request.body except ValueError return HttpResponseBadRequest contentstore .set_attr asset_key 'locked' modified_asset['locked'] del_cached_content asset_key return JsonResponse modified_asset status 201
def verify_oauth_request request oauth_request consumer token None from treeio.core.api.auth.store import storeif not store.check_nonce request oauth_request oauth_request['oauth_nonce'] return Falsetry oauth_server oauth.Server oauth_server.add_signature_method oauth.SignatureMethod_HMAC_SHA1 oauth_server.add_signature_method oauth.SignatureMethod_PLAINTEXT consumer oauth.Consumer consumer.key.encode 'ascii' 'ignore' consumer.secret.encode 'ascii' 'ignore' if token is not None token oauth.Token token.key.encode 'ascii' 'ignore' token.secret.encode 'ascii' 'ignore' oauth_server.verify_request oauth_request consumer token except oauth.Error return Falsereturn True
def execute_count expected def innerCounter fn def wrapped_function *args **kwargs count StatementCounter cassandra.cqlengine.connection.execute original_function cassandra.cqlengine.connection.executecassandra.cqlengine.connection.execute count.wrapped_executeto_return fn *args **kwargs count.get_counter cassandra.cqlengine.connection.execute original_functionif len args is 0 test_case unittest.TestCase '__init__' else test_case args[0]test_case.assertEqual count.get_counter expected msg "Expectednumberofcassandra.cqlengine.connection.executecalls {0} doesn'tmatchactualnumberinvoked {1} ".format expected count.get_counter return to_returnwrapped_function.__name__ fn.__name__wrapped_function.__doc__ fn.__doc__if CQL_SKIP_EXECUTE return fnelse return wrapped_functionreturn innerCounter
def is_method_call callfunc_node types methods if not isinstance callfunc_node astroid.CallFunc return Falsefunc utils.safe_infer callfunc_node.func return isinstance func astroid.BoundMethod and isinstance func.bound astroid.Instance and func.bound.name in types if types else True and func.name in methods if methods else True
def is_gzip fp return open fp 'rb' .read 2 '\x1f\x8b'
def get_train_test reviews None random_state None import numpy as npimport randomr random.Random random_state if reviews is None reviews load U M np.where reviews test_idxs np.array r.sample range len U len U // 10 train reviews.copy train[ U[test_idxs] M[test_idxs] ] 0test np.zeros_like reviews test[ U[test_idxs] M[test_idxs] ] reviews[ U[test_idxs] M[test_idxs] ]return train test
def ssh_file opts dest_path contents None kwargs None local_file None if opts.get 'file_transport' 'sftp' 'sftp' return sftp_file dest_path contents kwargs local_file return scp_file dest_path contents kwargs local_file
def streql s1 s2 if len s1 ! len s2 return Falseb Truefor ch1 ch2 in zip s1 s2 if ch1 ! ch2 b Falsereturn b
def write_html_report results_dir report_path None encoding 'utf8' default_report_path os.path.join results_dir 'job_report.html' if report_path is None report_path default_report_pathrelative_links Trueif report_path ! default_report_path relative_links Falserendered_html generate_html_report results_dir relative_links report_dir os.path.dirname report_path if not os.path.isdir report_dir raise InvalidOutputDirError report_dir html_result open report_path 'w' html_result.write rendered_html.encode encoding html_result.close logging.info 'Reportsuccessfullygeneratedat%s' report_path
def onchange *args return attrsetter '_onchange' args
def format_html html return html.replace u'\n' u'' .replace u'' u''
def _pFormatArray array_ fmt '%.2f' return '[' + ''.join fmt % x for x in array_ + ']'
def get_makefile_filename if _PYTHON_BUILD return os.path.join _PROJECT_BASE 'Makefile' return os.path.join get_path 'platstdlib' 'config' 'Makefile'
def get_file_language filename text None ext osp.splitext filename [1]if ext.startswith '.' ext ext[1 ]language extif not ext if text is None text _enc encoding.read filename for line in text.splitlines if not line.strip continueif line.startswith '#!' shebang line[2 ]if 'python' in shebang language 'python'else breakreturn language
def constant x x np.asarray x dtype np.float64 n_eval x.shape[0]f np.ones [n_eval 1] return f
def obtain_device_type model if '881' in model return 'router'else return None
def find_definition project code offset resource None maxfixes 1 fixer fixsyntax.FixSyntax project code resource maxfixes pyname fixer.pyname_at offset if pyname is not None module lineno pyname.get_definition_location name rope.base.worder.Worder code .get_word_at offset if lineno is not None start module.lines.get_line_start lineno def check_offset occurrence if occurrence.offset < start return Falsepyname_filter occurrences.PyNameFilter pyname finder occurrences.Finder project name [check_offset pyname_filter] for occurrence in finder.find_occurrences pymodule module return Location occurrence
def get_size start_path total_size 0for dirpath __ filenames in os.walk start_path for f in filenames fp os.path.join dirpath f total_size + os.path.getsize fp return total_size
def convert_to_utc dt if not dt.tzinfo return add_utc_tz dt dt dt.astimezone dateutil.tz.tzutc return dt
def grains_refresh DETAILS['grains_cache'] Nonereturn grains
@xfail is_win reason 'Issuescipy/scipy#5461.' @xfail is_darwin reason 'Issue#1895.' @importorskip 'scipy' def test_scipy_special pyi_builder pyi_builder.test_source 'importscipy.special'
def _nested_variable init name None trainable False if isinstance init list or isinstance init tuple result [_nested_variable i name trainable for i in init]if isinstance init tuple return tuple result return resultelse return tf.Variable init name name trainable trainable
def t_one_sample a popmean 0 tails 'two-sided' t _ ttest_1samp a popmean if isnan t or isinf t return nan nan p tprob t len a - 1 tails return float t p
def total_physical_memory try return psutil.virtual_memory .totalexcept AttributeError return psutil.TOTAL_PHYMEM
def _assert_no_element_by context by value wait_time MAX_WAIT_FOR_UNEXPECTED_ELEMENT try WebDriverWait context.browser wait_time .until EC.presence_of_element_located by value except TimeoutException return Trueraise KALiteTimeout
def test_xbm h f s '#define'if h[ len s ] s return 'xbm'
def getPlugins interface package None if package is None import twisted.plugins as packageallDropins getCache package for key dropin in iteritems allDropins for plugin in dropin.plugins try adapted interface plugin None except log.err else if adapted is not None yield adapted
def pytest_terminal_summary terminalreporter try get_ipython except NameError returnif not terminalreporter.stats.get u'failed' returnterminalreporter.ensure_newline terminalreporter.write_line u'SometestsareknowntofailwhenrunfromtheIPythonprompt;especially butnotlimitedtotestsinvolvingloggingandwarninghandling.Unlessyouarecertainastothecauseofthefailure pleasecheckthatthefailureoccursoutsideIPythonaswell.Seehttp //docs.astropy.org/en/stable/known_issues.html#failing-logging-tests-when-running-the-tests-in-ipythonformoreinformation.' yellow True bold True
def _embed_bpython_shell namespace {} banner '' import bpython@wraps _embed_bpython_shell def wrapper namespace namespace banner '' bpython.embed locals_ namespace banner banner return wrapper
def show_instance name call None if call ! 'action' raise SaltCloudException 'Theshow_instanceactionmustbecalledwith-aor--action.' node_id get_linode_id_from_name name node_data get_linode kwargs {'linode_id' node_id} ips get_ips node_id state int node_data['STATUS'] ret {'id' node_data['LINODEID'] 'image' node_data['DISTRIBUTIONVENDOR'] 'name' node_data['LABEL'] 'size' node_data['TOTALRAM'] 'state' _get_status_descr_by_id state 'private_ips' ips['private_ips'] 'public_ips' ips['public_ips']}return ret
def select_proxy url proxies proxies proxies or {} urlparts urlparse url proxy proxies.get urlparts.scheme + ' //' + urlparts.hostname if proxy is None proxy proxies.get urlparts.scheme return proxy
def _handle_read_field api_content form_value user cc_content if form_value and not cc_content['read'] user.read cc_content api_content['unread_comment_count'] 0
def merge_branch repo branch try check_call ['git' 'pull' repo branch] stdin io.open os.devnull except CalledProcessError check_call ['git' 'merge' '--abort'] return Falsereturn True
def test_binary_operator_subclass class A object def __add__ self other return 'a' self.__class__.__name__ __radd__ __add__class B A def __add__ self other return 'b' self.__class__.__name__ __radd__ __add__class C A passa A b B c C AreEqual a + b 'b' 'B' AreEqual a + c 'a' 'A'
def agent_join consul_url None address None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not address raise SaltInvocationError 'Requiredargument"address"ismissing.' if 'wan' in kwargs query_params['wan'] kwargs['wan']function 'agent/join/{0}'.format address res _query consul_url consul_url function function method 'GET' query_params query_params if res['res'] ret['res'] Trueret['message'] 'Agentjoinedthecluster'else ret['res'] Falseret['message'] 'Unabletojointhecluster.'return ret
def getModuleWithPath path return getModuleWithDirectoryPath os.path.dirname path os.path.basename path
def __dict_replace s d for key value in d.items s s.replace key value return s
def default_for_missing env for param in SECTIONS if param not in env and param ! PARAMETER_MERGE_STRATEGIES if param in ENCRYPTED_PARAM_NAMES EVENT_SINKS env[param] []else env[param] {}
def source_tokens source use_exact_op_types False source sourcereadline StringIO source .readlinereturn generate_tokens readline use_exact_op_types
def _abi_trim seq_record start Falsesegment 20trim_start 0cutoff 0.05if len seq_record < segment return seq_recordelse score_list [ cutoff - 10 ** qual / -10.0 for qual in seq_record.letter_annotations['phred_quality']]cummul_score [0]for i in range 1 len score_list score cummul_score[ -1 ] + score_list[i] if score < 0 cummul_score.append 0 else cummul_score.append score if not start trim_start istart Truetrim_finish cummul_score.index max cummul_score return seq_record[trim_start trim_finish]
def coroutine_traceback typ value tb all_frames traceback.extract_tb tb useful_frames []for frame in all_frames if frame[0] '<string>' and frame[2] 'raise_exc_info' continueelif frame[0].endswith 'tornado/gen.py' and frame[2] in {'run' 'wrapper'} continueelif frame[0].endswith 'tornado/concurrent.py' and frame[2] 'result' continueuseful_frames.append frame tb_list ['Traceback mostrecentcalllast \n']tb_list.extend traceback.format_list useful_frames tb_list.extend traceback.format_exception_only typ value return tb_list
def reverse_timestamp dt epoch datetime.datetime 1970 1 1 td dt - epoch ts td.microseconds + td.seconds + td.days * 24 * 3600 * 100000 / 100000 return 9223372036854775807 - ts
def generate_etag data return md5 data .hexdigest
def do_dictsort value case_sensitive False by 'key' if by 'key' pos 0elif by 'value' pos 1else raise FilterArgumentError 'Youcanonlysortbyeither"key"or"value"' def sort_func item value item[pos]if isinstance value string_types and not case_sensitive value value.lower return valuereturn sorted value.items key sort_func
def compileToTemp language payloadSource if language 'cs' tempExeName settings.TEMP_DIR + '/temp.exe' tempSourceName settings.TEMP_DIR + '/temp.cs' f open settings.TEMP_DIR + '/temp.cs' 'w' f.write payloadSource f.close os.system 'mcs-platform x86-target winexe' + tempSourceName + '-out ' + tempExeName return tempExeName
def get_request_unique_id http_response prepend None uri_str http_response.get_uri .url_string.encode 'utf-8' body_str http_response.bodyif isinstance body_str unicode body_str body_str.encode 'utf-8' 'replace' _to_hash body_str + uri_str hash_string str hash _to_hash hash_string + str zlib.adler32 _to_hash if prepend hash_string '%s-%s' % prepend hash_string return hash_string
def bytes_ s encoding 'latin-1' errors 'strict' if isinstance s text_type return s.encode encoding errors return s
def get_cosine vec1 vec2 return numpy.dot vec1 vec2 / numpy.linalg.norm vec1 * numpy.linalg.norm vec2
def get_driver drivers provider deprecated_providers None deprecated_constants None deprecated_providers deprecated_providers or {} if provider in deprecated_providers url deprecated_providers[provider]['url']reason deprecated_providers[provider]['reason']msg 'Providernolongersupported %s pleasevisit %s' % url reason raise Exception msg deprecated_constants deprecated_constants or {} if provider in deprecated_constants old_name provider.upper new_name deprecated_constants[provider].upper url 'https //s.apache.org/lc0140un'msg 'Providerconstant"%s"hasbeenremoved.Newconstantisnowcalled"%s".\nFormoreinformationonthischangeandhowtomodifyyourcodetoworkwithit pleasevisit %s' % old_name new_name url raise Exception msg if provider in drivers mod_name driver_name drivers[provider]_mod __import__ mod_name globals locals [driver_name] return getattr _mod driver_name raise AttributeError 'Provider%sdoesnotexist' % provider
def fix_w602 source aggressive True if not aggressive return sourcereturn refactor source [u'raise'] ignore u'with_traceback'
def dominant expr n terms Add.make_args expr.expand func True term0 terms[ -1 ]comp [term0]for t in terms[ -1 ] e term0 / t .combsimp l limit_seq e n if l is S.Zero term0 tcomp [term0]elif l is None return Noneelif l not in [S.Infinity - S.Infinity ] comp.append t if len comp > 1 return Nonereturn term0
@ship.command 'shoot' @click.argument 'ship' @click.argument 'x' type float @click.argument 'y' type float def ship_shoot ship x y click.echo 'Ship%sfiresto%s %s' % ship x y
def _find_set_type set setinfo _find_set_info set if setinfo return setinfo['Type']else return False
def get_warning_for_invalid_pattern pattern if isinstance pattern str hint "Tryremovingthestring'{}'.Thelistofurlpatternsshouldnothaveaprefixstringasthefirstelement.".format pattern elif isinstance pattern tuple hint 'Tryusingurl insteadofatuple.'else hint Nonereturn [Error 'YourURLpattern{!r}isinvalid.Ensurethaturlpatternsisalistofurl instances.'.format pattern hint hint id 'urls.E004' ]
def list_vlans call None if call ! 'function' raise SaltCloudSystemExit 'Thelist_vlansfunctionmustbecalledwith-for--function.' conn get_conn service 'SoftLayer_Account' return conn.getNetworkVlans
def facility_type return s3_rest_controller
def dispose_resources device device._ctx.dispose device
def GetPrintableStrs namespace kinds namespace_str namespace or '' if kinds kind_str 'all%sentities' % ' '.join kinds else kind_str ''return namespace_str kind_str
def _get_name_map saltenv u'base' u_name_map {}name_map get_repo_data saltenv .get u'name_map' {} for k in name_map.keys u_name_map[k.decode u'utf-8' ] name_map[k]return u_name_map
def health_node consul_url None node None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not node raise SaltInvocationError 'Requiredargument"node"ismissing.' if 'dc' in kwargs query_params['dc'] kwargs['dc']function 'health/node/{0}'.format node ret _query consul_url consul_url function function query_params query_params return ret
@check_event_permissionsdef cancel_occurrence request event_id template_name 'schedule/cancel_occurrence.html' *args **kwargs event occurrence get_occurrence event_id *args **kwargs next kwargs.get 'next' None or get_next_url request event.get_absolute_url if request.method ! 'POST' return render_to_response template_name {'occurrence' occurrence 'next' next} context_instance RequestContext request occurrence.cancel return HttpResponseRedirect next
def _handleLegacyResult result if not isinstance result dict warnings.warn 'TheGerritstatuscallbackusestheoldwaytocommunicateresults.Theoutcomemightbenotwhatisexpected.' message verified reviewed resultresult makeReviewResult message GERRIT_LABEL_VERIFIED verified GERRIT_LABEL_REVIEWED reviewed return result
def query_tasks session if session.config['singletons'] for item in session.lib.items session.query task SingletonImportTask None item for task in task.handle_created session yield task else for album in session.lib.albums session.query log.debug u'yieldingalbum{0} {1}-{2}' album.id album.albumartist album.album items list album.items for item in items item.id Noneitem.album_id Nonetask ImportTask None [album.item_dir ] items for task in task.handle_created session yield task
def thumbnail_url link if link.has_thumbnail if hasattr link 'thumbnail_url' return link.thumbnail_urlelse return ''else return ''
def usergroup_exists name None node None nodeids None **connection_args conn_args _login **connection_args zabbix_version apiinfo_version **connection_args try if conn_args if LooseVersion zabbix_version > LooseVersion '2.5' if not name name ''ret usergroup_get name None **connection_args return bool ret else method 'usergroup.exists'params {}if not name and not node and not nodeids return {'result' False 'comment' 'Pleasesubmitname nodeornodeidsparametertocheckifatleastoneusergroupexists.'}if name params['name'] nameif LooseVersion zabbix_version < LooseVersion '2.4' if node params['node'] nodeif nodeids params['nodeids'] nodeidsret _query method params conn_args['url'] conn_args['auth'] return ret['result']else raise KeyErrorexcept KeyError return False
def _mdb_get_database uri **kwargs if not 'tz_aware' in kwargs kwargs['tz_aware'] Trueconnection_factory MongoClient_parsed_uri {}try _parsed_uri pymongo.uri_parser.parse_uri uri except pymongo.errors.InvalidURI db_name uri_conn MongoClient passelse if 'replicaset' in _parsed_uri['options'] connection_factory MongoReplicaSetClientdb_name _parsed_uri.get 'database' 'pysaml2' _conn connection_factory uri **kwargs _db _conn[db_name]if 'username' in _parsed_uri _db.authenticate _parsed_uri.get 'username' None _parsed_uri.get 'password' None return _db
def curve n_turns phi np.linspace 0 2 * np.pi 2000 return [ np.cos phi * 1 + 0.5 * np.cos n_turns * phi np.sin phi * 1 + 0.5 * np.cos n_turns * phi 0.5 * np.sin n_turns * phi ]
def decargs arglist return [s.decode _encoding for s in arglist]
def directory_browser request path '/' directories DojoFileStore path dirsonly True root request.GET.get 'root' '/' .items context directoriescontent json.dumps context return HttpResponse content content_type 'application/json'
def import_demo_csv_part2 job_id request.post_vars.jobif not job_id return "ErrorNoJobID'sprovided"request.controller 'stats'output s3_rest_controller 'stats' 'demographic_data' csv_stylesheet 'demographic_data.xsl' totalRecords output[0]totalErrors output[1]totalIgnored output[2]from gluon.serializers import json as jsonsresponse.headers['Content-Type'] 'application/json'return jsons {'totalRecords' totalRecords 'totalErrors' totalErrors 'totalIgnored' totalIgnored}
@should_dump_thread_stackdef stop_thread_stack_dump cancel_thread SAVE_THREAD_PTR dump_thread_stack
def get_edit_extensions edit_filetypes get_edit_filetypes return _get_extensions edit_filetypes + ['']
def __get_location conn vm_ location config.get_cloud_config_value 'location' vm_ __opts__ return conn.ex_get_zone location
def _assert_n_free raw_sss lower upper None upper lower if upper is None else upper n_free raw_sss.info['proc_history'][0]['max_info']['sss_info']['nfree']assert_true lower < n_free < upper 'nfreefail %s< %s< %s' % lower n_free upper
def _get_dev_port_var backend instance None port_var 'BACKEND_PORT.%s' % str backend .lower if instance is not None port_var '%s.%d' % port_var instance return port_var
def ts_function context return context['execution_date'] + context['dag'].schedule_interval
def _gitInit path runCommand ['git' 'init' path.path] _gitConfig path
def _fastq_generic in_handle out_handle mapping from Bio.SeqIO.QualityIO import FastqGeneralIteratorcount 0null chr 0 for title seq old_qual in FastqGeneralIterator in_handle count + 1qual old_qual.translate mapping if null in qual raise ValueError 'Invalidcharacterinqualitystring' out_handle.write '@%s\n%s\n+\n%s\n' % title seq qual return count
def dmp_neg f u K if not u return dup_neg f K v u - 1 return [dmp_neg cf v K for cf in f]
def markup_join seq buf []iterator imap soft_unicode seq for arg in iterator buf.append arg if hasattr arg '__html__' return Markup u'' .join chain buf iterator return concat buf
def should_be_retracted retraction return timezone.now - retraction.initiation_date > settings.RETRACTION_PENDING_TIME
def safe_str o return _safeFormat str o
def _eat_items value iter_parts part end_char replace_char '' current partchunks [current.replace replace_char '' ]while True try current six.advance_iterator iter_parts except StopIteration raise ValueError value chunks.append current.replace replace_char '' if current.endswith end_char breakreturn ' '.join chunks
def compress_signals signals groups group_by_all reversed signals key lambda sig sig.link sig.id signals []def has_none signals return any sig.value is None for sig in signals for link id signals_grouped in groups if len signals_grouped > 1 and has_none signals_grouped[1 ] signals.append signals_grouped[0] signals.append _Signal link None id else signals.append signals_grouped[0] return list reversed signals
def lz4_encode_old_kafka payload data lz4_encode payload header_size 7if isinstance data[4] int flg data[4]else flg ord data[4] content_size_bit flg >> 3 & 1 if content_size_bit header_size + 8hc xxhash.xxh32 data[0 header_size - 1 ] .digest [ -2 -1 ]return ''.join [data[0 header_size - 1 ] hc data[header_size ]]
def normalize_openstack_facts metadata facts facts['zone'] metadata['availability_zone']local_ipv4 metadata['ec2_compat']['local-ipv4'].split ' ' [0]facts['network']['ip'] local_ipv4facts['network']['public_ip'] metadata['ec2_compat']['public-ipv4']for f_var h_var ip_var in [ 'hostname' 'hostname' 'local-ipv4' 'public_hostname' 'public-hostname' 'public-ipv4' ] try if socket.gethostbyname metadata['ec2_compat'][h_var] metadata['ec2_compat'][ip_var] facts['network'][f_var] metadata['ec2_compat'][h_var]else facts['network'][f_var] metadata['ec2_compat'][ip_var]except socket.gaierror facts['network'][f_var] metadata['ec2_compat'][ip_var]return facts
def import_dashboard_config modules config collections.defaultdict dict for module in modules for key submodule in import_submodules module .items if hasattr submodule 'DASHBOARD' dashboard submodule.DASHBOARDconfig[dashboard].update submodule.__dict__ elif hasattr submodule 'PANEL' or hasattr submodule 'PANEL_GROUP' or hasattr submodule 'FEATURE' config[submodule.__name__] submodule.__dict__else logging.warning "Skipping%sbecauseitdoesn'thaveDASHBOARD PANEL PANEL_GROUP orFEATUREdefined." submodule.__name__ return sorted config.items key lambda c c[1]['__name__'].rsplit '.' 1 [1]
def _get_and_validate_course course_key_string user course_key CourseKey.from_string course_key_string course get_course_and_check_access course_key user if settings.FEATURES['ENABLE_VIDEO_UPLOAD_PIPELINE'] and getattr settings 'VIDEO_UPLOAD_PIPELINE' None and course and course.video_pipeline_configured return courseelse return None
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_shelve cs args _find_server cs args.server .shelve
def getAutoCompleteList command '' locals None includeMagic 1 includeSingle 1 includeDouble 1 attributes []root getRoot command terminator '.' try if locals is not None object eval root locals else object eval root except Exception passelse attributes getAttributeNames object includeMagic includeSingle includeDouble return attributes
def splittag url path delim tag url.rpartition '#' if delim return path tag return url None
def _dec_from_triple sign coefficient exponent special False self object.__new__ Decimal self._sign signself._int coefficientself._exp exponentself._is_special specialreturn self
def mask_or clip other_clip if isinstance other_clip ImageClip other_clip other_clip.imgif isinstance other_clip np.ndarray return clip.fl_image lambda f np.maximum f other_clip else return clip.fl lambda gf t np.maximum gf t other_clip.get_frame t
def make_biplot_scores_output taxa output []ndims len taxa['coord'][1] header '#Taxon DCTB ' + ' DCTB '.join [ 'pc%d' % i for i in xrange ndims ] output.append header for i taxon in enumerate taxa['lineages'] line taxon + ' DCTB ' line + ' DCTB '.join map str taxa['coord'][i] output.append line return output
def get_transactions link campaigns campaigns [c for c in campaigns if c.trans_id ! 0 and c.link_id link._id ]if not campaigns return {}bids Bid.lookup thing_id link._id bid_dict { b.campaign b.transaction b for b in bids}bids_by_campaign {c._id bid_dict[ c._id c.trans_id ] for c in campaigns}return bids_by_campaign
@snippetdef topic_exists client to_delete TOPIC_NAME 'topic_exists-%d' % _millis topic client.topic TOPIC_NAME to_delete.append topic assert not topic.exists topic.create assert topic.exists
def _handle_precomputed_bsgs base strong_gens transversals None basic_orbits None strong_gens_distr None if strong_gens_distr is None strong_gens_distr _distribute_gens_by_base base strong_gens if transversals is None if basic_orbits is None basic_orbits transversals _orbits_transversals_from_bsgs base strong_gens_distr else transversals _orbits_transversals_from_bsgs base strong_gens_distr transversals_only True elif basic_orbits is None base_len len base basic_orbits [None] * base_len for i in range base_len basic_orbits[i] list transversals[i].keys return transversals basic_orbits strong_gens_distr
def matrix_product *matrices return reduce matmul matrices
def get_os_platform ver sys.platform.lower if ver.startswith 'java' import java.langver java.lang.System.getProperty 'os.name' .lower print 'platform %s' % ver return ver
def get_poetry host port timeout d defer.Deferred from twisted.internet import reactorfactory PoetryClientFactory d timeout reactor.connectTCP host port factory return d
def test_discretize_callable_2d def f x y return x ** 2 + y ** 2 actual discretize_model f -5 6 -5 6 y x np.indices 11 11 - 5 desired x ** 2 + y ** 2 assert_allclose actual desired
def whiten_individuals_loop x transform group_iter x_new []for g in group_iter x_g x[g]x_new.append np.dot transform x_g return np.concatenate x_new
def _psd_func epoch noverlap nfft fs freq_mask func return func epoch fs fs nperseg nfft noverlap noverlap nfft nfft window 'hann' [2][... freq_mask ]
def GetJavaSourceDirs target_list target_dicts toplevel_dir for target_name in target_list target target_dicts[target_name]for action in target.get 'actions' [] for input_ in action['inputs'] if os.path.splitext input_ [1] '.java' and not input_.startswith '$' dir_ os.path.dirname os.path.join os.path.dirname target_name input_ parent_search dir_while os.path.basename parent_search not in ['src' 'java'] parent_search _ os.path.split parent_search if not parent_search or parent_search toplevel_dir yield dir_ breakelse yield parent_search
def _test_owner kwargs user None if user return userif 'owner' in kwargs log.warning 'Useofargumentownerfound "owner"isinvalid pleaseuse"user"' return kwargs['owner']return user
def descrFromDoc obj if obj.__doc__ is None or obj.__doc__.isspace return Nonelines [x.strip for x in obj.__doc__.split '\n' if x and not x.isspace ]return ''.join lines
def _get_size fileno import fcntlimport termiosbuf array.array 'h' if six.PY2 else u'h' [0 0 0 0] fcntl.ioctl fileno termios.TIOCGWINSZ buf return buf[0] buf[1]
def dispatch environ start_response mapper result mapper.match environ environ if result is None raise webob.exc.HTTPNotFound json_formatter util.json_error_formatter handler result.pop 'action' environ['wsgiorg.routing_args'] result return handler environ start_response
def cleanup_staging_area staging_path if os.path.exists staging_path shutil.rmtree staging_path
def parse_plain_scalar_indent TokenClass def callback lexer match context text match.group if len text < context.indent context.stack.pop context.stack.pop returnif text yield match.start TokenClass text context.pos match.end return callback
def send_patch self path data u'' content_type u'application/octet-stream' follow False **extra from django.test.client import Clientresponse super Client self .patch path data data content_type content_type **extra if follow response self._handle_redirects response **extra return response
def create_engine *args **kwargs strategy kwargs.pop 'strategy' default_strategy strategy strategies.strategies[strategy]return strategy.create *args **kwargs
def _solve_as_rational f symbol domain f together f deep True g h fraction f if not h.has symbol return _solve_as_poly g symbol domain else valid_solns _solveset g symbol domain invalid_solns _solveset h symbol domain return valid_solns - invalid_solns
def _read_spec_tests path b common.read path u unicode b encoding FILE_ENCODING spec_data parse u tests spec_data['tests']cases []for data in tests case _deserialize_spec_test data path cases.append case return cases
def google channel settings.get_auth_google if not channel redirect URL f 'user' args request.args vars get_vars from s3oauth import GooglePlusAccountauth.settings.login_form GooglePlusAccount channel form auth return {'form' form}
def load_vector *names return pkg_resources.resource_string __name__ os.path.join 'testdata' *names
def get_file filename return os.path.join TEST_DIR filename
def get_limit_choices_to_from_path model path fields get_fields_from_path model path fields remove_trailing_data_field fields limit_choices_to fields and hasattr fields[ -1 ] u'rel' and getattr fields[ -1 ].rel u'limit_choices_to' None if not limit_choices_to return models.Q elif isinstance limit_choices_to models.Q return limit_choices_toelse return models.Q **limit_choices_to
def bad_function_unknown_module self context from lxml import etreex etree.fromstring '<hello/>' x.attrib['foo'] None
def doAuth realm return digestAuth realm + '' + basicAuth realm
def create_grid_mesh xs ys zs shape xs.shapelength shape[0] * shape[1] vertices np.zeros length 3 vertices[ 0] xs.reshape length vertices[ 1] ys.reshape length vertices[ 2] zs.reshape length basic_indices np.array [0 1 1 + shape[1] 0 0 + shape[1] 1 + shape[1] ] dtype np.uint32 inner_grid_length shape[0] - 1 * shape[1] - 1 offsets np.arange inner_grid_length offsets + np.repeat np.arange shape[0] - 1 shape[1] - 1 offsets np.repeat offsets 6 indices np.resize basic_indices len offsets + offsets indices indices.reshape len indices // 3 3 return vertices indices
def resolve_duplicates session task if task.choice_flag in action.ASIS action.APPLY ident task.chosen_ident found_duplicates task.find_duplicates session.lib if ident in session.seen_idents or found_duplicates session.resolve_duplicate task found_duplicates session.log_choice task True session.seen_idents.add ident
@cli_app.command 'create-db' @click.option '--app' default 'app' help 'Yourapplicationinitdirectory package ' @click.option '--appbuilder' default 'appbuilder' help 'yourAppBuilderobject' def create_db app appbuilder from flask_appbuilder.models.sqla import Base_appbuilder import_application app appbuilder engine _appbuilder.get_session.get_bind mapper None clause None Base.metadata.create_all engine click.echo click.style 'DBobjectscreated' fg 'green'
def get_form_params data frappe._dict frappe.local.form_dict del data[u'cmd']if isinstance data.get u'filters' basestring data[u'filters'] json.loads data[u'filters'] if isinstance data.get u'fields' basestring data[u'fields'] json.loads data[u'fields'] if isinstance data.get u'docstatus' basestring data[u'docstatus'] json.loads data[u'docstatus'] if isinstance data.get u'save_list_settings' basestring data[u'save_list_settings'] json.loads data[u'save_list_settings'] else data[u'save_list_settings'] Truedata.query Nonereturn data
@cronjobs.registerdef reindex_users_that_contributed_yesterday if settings.STAGE returntoday datetime.now yesterday today - timedelta days 1 user_ids list Answer.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter reviewed__gte yesterday reviewed__lt today .values_list 'reviewer_id' flat True index_task.delay UserMappingType list set user_ids
def _parse_prefix_as_idd idd_pattern number match idd_pattern.match number if match match_end match.end digit_match _CAPTURING_DIGIT_PATTERN.search number[match_end ] if digit_match normalized_group normalize_digits_only digit_match.group 1 if normalized_group U_ZERO return False number return True number[match_end ] return False number
def str_or_none val return str val if val is not None else None
def filter_section_bears_by_languages bears languages new_bears {}languages set language.lower for language in languages | {'all'} for section in bears.keys new_bears[section] tuple bear for bear in bears[section] if {language.lower for language in bear.LANGUAGES} & languages return new_bears
def try_passwordless_ssh server keyfile paramiko None if paramiko is None paramiko sys.platform 'win32' if not paramiko f _try_passwordless_opensshelse f _try_passwordless_paramikoreturn f server keyfile
def abort global __SCHEDif __SCHED logging.debug 'Terminatingscheduler' __SCHED.running False
def _split p dash _allowMOSFSNames and p[ 1] '-' if dash q string.find p '-' 1 + 1 elif p[ 1] ' ' q 0else q string.find p ' ' + 1 s string.find p '#' if s -1 or s > q s qelse for c in p[dash s] if c not in string.ascii_letters q 0breakr qif p[q q + 1 ] ' ' r string.find p '.' q + 1 + 1 if r 0 r len p return p[ q] p[q r] p[r ]
@check_login_required@check_local_site_accessdef submitter request username grid None template_name u'datagrids/datagrid.html' local_site None if local_site try user local_site.users.get username username except User.DoesNotExist raise Http404else user get_object_or_404 User username username if grid is None or grid u'review-requests' datagrid_cls UserPageReviewRequestDataGridelif grid u'reviews' datagrid_cls UserPageReviewsDataGridelse raise Http404datagrid datagrid_cls request user local_site local_site datagrid.tabs [ UserPageReviewRequestDataGrid.tab_title local_site_reverse u'user' local_site local_site args [username] UserPageReviewsDataGrid.tab_title local_site_reverse u'user-grid' local_site local_site args [username u'reviews'] ]return datagrid.render_to_response template_name
def _match_names pattern names result []for name in names match pattern.match name if match result.append name match.group 'name' return result
def _accessible_courses_list_from_groups request def filter_ccx course_access 'CCXscannotbeeditedinStudioandshouldnotbeshowninthisdashboard'return not isinstance course_access.course_id CCXLocator courses_list {}in_process_course_actions []instructor_courses UserBasedRole request.user CourseInstructorRole.ROLE .courses_with_role staff_courses UserBasedRole request.user CourseStaffRole.ROLE .courses_with_role all_courses filter filter_ccx instructor_courses | staff_courses for course_access in all_courses course_key course_access.course_idif course_key is None raise AccessListFallbackif course_key not in courses_list in_process_course_actions.extend CourseRerunState.objects.find_all exclude_args {'state' CourseRerunUIStateManager.State.SUCCEEDED} should_display True course_key course_key try course modulestore .get_course course_key except ItemNotFoundError passif course is not None and not isinstance course ErrorDescriptor courses_list[course_key] coursereturn courses_list.values in_process_course_actions
def addHeightsByBitmap heights textLines for line in textLines[3 ] for integerWord in line.split heights.append float integerWord
def flavor_get_by_flavor_id context id read_deleted None return IMPL.flavor_get_by_flavor_id context id read_deleted
def flush_time return logs_buffer .flush_time
def digamma x return polygamma 0 x
def get_mode path if not os.path.exists path return ''func_name '{0}.get_mode'.format __virtualname__ if __opts__.get 'fun' '' func_name log.info 'Thefunction{0}shouldnotbeusedonWindowssystems;seefunctiondocsfordetails.ThevaluereturnedisalwaysNone.'.format func_name return None
def tap registry xml_parent data tap XML.SubElement xml_parent 'org.tap4j.plugin.TapPublisher' tap.set 'plugin' 'tap' mappings [ 'results' 'testResults' None 'fail-if-no-results' 'failIfNoResults' False 'failed-tests-mark-build-as-failure' 'failedTestsMarkBuildAsFailure' False 'output-tap-to-console' 'outputTapToConsole' True 'enable-subtests' 'enableSubtests' True 'discard-old-reports' 'discardOldReports' False 'todo-is-failure' 'todoIsFailure' True 'include-comment-diagnostics' 'includeCommentDiagnostics' False 'validate-tests' 'validateNumberOfTests' False 'plan-required' 'planRequired' True 'verbose' 'verbose' True 'show-only-failures' 'showOnlyFailures' False ]helpers.convert_mapping_to_xml tap data mappings fail_required True
def hqic llf nobs df_modelwc return -2.0 * llf + 2 * np.log np.log nobs * df_modelwc
def recently_changed_packages_activity_list_html context data_dict activity_stream recently_changed_packages_activity_list context data_dict offset int data_dict.get 'offset' 0 extra_vars {'controller' 'package' 'action' 'activity' 'offset' offset}return activity_streams.activity_list_to_html context activity_stream extra_vars
def url_concat url args parsed_url urlparse url if isinstance args dict parsed_query parse_qsl parsed_url.query keep_blank_values True parsed_query.extend args.items elif isinstance args list or isinstance args tuple parsed_query parse_qsl parsed_url.query keep_blank_values True parsed_query.extend args else err "'args'parametershouldbedict listortuple.Not{0}".format type args raise TypeError err final_query urlencode parsed_query url urlunparse parsed_url[0] parsed_url[1] parsed_url[2] parsed_url[3] final_query parsed_url[5] return url
def _process_mass_form f def wrap request *args **kwargs 'Wrap'if 'massform' in request.POST for key in request.POST if 'mass-order' in key try order SaleOrder.objects.get pk request.POST[key] form MassActionForm request.user.profile request.POST instance order if form.is_valid and request.user.profile.has_permission order mode 'w' form.save except passreturn f request *args **kwargs wrap.__doc__ f.__doc__wrap.__name__ f.__name__return wrap
def srepr expr **settings return ReprPrinter settings .doprint expr
def dmp_list_terms f u K order None def sort terms O return sorted terms key lambda term O term[0] reverse True terms _rec_list_terms f u if not terms return [ 0 * u + 1 K.zero ]if order is None return termselse return sort terms monomial_key order
def grad_sources_inputs sources inputs if inputs is None inputs theano.gof.graph.inputs [source[0] for source in sources] return dict izip inputs theano.gradient.grad cost None known_grads dict sources wrt inputs consider_constant inputs
def get_page_models return PAGE_MODEL_CLASSES
def assert_not_has_text output text assert output.find text < 0 "Outputfilecontainsunexpectedtext'%s'" % text
def test_dirname return os.path.dirname __file__
def test_table_groups_array_index T1 for masked in False True t1 Table T1 masked masked .group_by 'a' t2 t1.groups[np.array [0 2] ]assert len t2.groups 2 assert t2.groups[0].pformat t1.groups[0].pformat assert t2.groups[1].pformat t1.groups[2].pformat assert np.all t2.groups.keys['a'] np.array [0 2]
@api_versions.wraps '2.26' @utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_server_tag_delete_all cs args server _find_server cs args.server server.delete_all_tags
def admin_media_prefix try from django.conf import settingsexcept ImportError return ''return iri_to_uri settings.ADMIN_MEDIA_PREFIX
def integer_to_term k n_bits None s '{0 0{1}b}'.format abs as_int k as_int abs n_bits or 0 return list map int s
def _process_exists pid try os.kill pid 0 except OSError return Falsereturn True
def get_computer_sleep ret salt.utils.mac_utils.execute_return_result 'systemsetup-getcomputersleep' return salt.utils.mac_utils.parse_return ret
def get_change_advanced_settings_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'change_page_advanced_settings' check_global check_global use_cache use_cache return page_ids
def disconnectNetToMs Facility_presence 0 ProgressIndicator_presence 0 UserUser_presence 0 AllowedActions_presence 0 a TpPd pd 3 b MessageType mesType 37 c Cause packet a / b / c if Facility_presence is 1 d FacilityHdr ieiF 28 eightBitF 0 packet packet / d if ProgressIndicator_presence is 1 e ProgressIndicatorHdr ieiPI 30 eightBitPI 0 packet packet / e if UserUser_presence is 1 f UserUserHdr ieiUU 126 eightBitUU 0 packet packet / f if AllowedActions_presence is 1 g AllowedActionsHdr ieiAA 123 eightBitAA 0 packet packet / g return packet
def header_quopri_len s count 0for c in s if hqre.match c count + 3else count + 1return count
def redirect_back url source_domain parse_data urlparse url domain parse_data.netlocquery parse_data.queryif source_domain in domain or domain in source_domain return urlquery_item parse_qs query if query_item.get 'url' return query_item['url'][0]return url
def _build_status data item stream item['stream']if 'Runningin' in stream data.setdefault 'Intermediate_Containers' [] .append stream.rstrip .split [ -1 ] if 'Successfullybuilt' in stream data['Id'] stream.rstrip .split [ -1 ]
def getnodes tree if isinstance tree tuple name subtree treeab [name]al []if len subtree 1 adeg [name]else adeg []for st in subtree b l d getnodes st ab.extend b al.extend l adeg.extend d return ab al adeg return [] [tree] []
def label_absent name node None apiserver None ret __salt__['k8s.label_absent'] name node apiserver return ret
def wf global _wfif _wf is None _wf workflow.Workflow return _wf
def get_plugin_media_path instance filename return instance.get_media_path filename
def ErrorMsg import tracebacktype value tb limit None type value tb sys.exc_info list traceback.format_tb tb limit + traceback.format_exception_only type value return 'Traceback innermostlast \n' + '%-20s%s' % string.join list[ -1 ] '' list[ -1 ]
def test_cache_config_enable_private_browsing config_stub tmpdir config_stub.data {'storage' {'cache-size' 1024} 'general' {'private-browsing' False}}disk_cache cache.DiskCache str tmpdir assert disk_cache.cacheSize 0 preload_cache disk_cache assert disk_cache.cacheSize > 0 config_stub.set 'general' 'private-browsing' True assert disk_cache.cacheSize 0
def _contains_yieldpoint children if isinstance children dict return any isinstance i YieldPoint for i in children.values if isinstance children list return any isinstance i YieldPoint for i in children return False
def show_model_changes new old None fields None always False old old or new._db._get type new new.id changes []for field in old if field 'mtime' or fields and field not in fields continueline _field_diff field old new if line changes.append u'{0} {1}'.format field line for field in set new - set old if fields and field not in fields continuechanges.append u'{0} {1}'.format field colorize 'text_highlight' new.formatted [field] if changes or always print_ format old if changes print_ u'\n'.join changes return bool changes
def random_mac request virttype 'xenpv' if not test_user_authenticated request return login request expired True random_mac remote.get_random_mac virttype request.session['token'] return HttpResponse random_mac
def test_sobel_v_mask np.random.seed 0 result filters.sobel_v np.random.uniform size 10 10 np.zeros 10 10 bool assert_allclose result 0
def candlestick ax quotes width 0.2 colorup 'k' colordown 'r' alpha 1.0 OFFSET width / 2.0 lines []patches []for q in quotes t open close high low q[ 5]if close > open color coloruplower openheight close - open else color colordownlower closeheight open - close vline Line2D xdata t t ydata low high color 'k' linewidth 0.5 antialiased True rect Rectangle xy t - OFFSET lower width width height height facecolor color edgecolor color rect.set_alpha alpha lines.append vline patches.append rect ax.add_line vline ax.add_patch rect ax.autoscale_view return lines patches
def create_document_editor_user User get_user_model user user_created User.objects.get_or_create username 'conantheeditor' defaults dict email 'user_%s@example.com' is_active True is_staff False is_superuser False if user_created user.set_password 'testpass' user.groups [create_document_editor_group ]user.save return user
def _is_printable char category unicodedata.category char return not category.startswith 'C' and not category.startswith 'Z' or category 'Zs'
def p_specifier_qualifier_list_4 t pass
def supports_librabbitmq if _detect_environment u'default' try import librabbitmqexcept ImportError passelse return True
def success_renewal domains z_util interfaces.IDisplay .notification 'Yourexistingcertificatehasbeensuccessfullyrenewed andthenewcertificatehasbeeninstalled.{1}{1}Thenewcertificatecoversthefollowingdomains {0}{1}{1}Youshouldtestyourconfigurationat {1}{2}'.format _gen_https_names domains os.linesep os.linesep.join _gen_ssl_lab_urls domains pause False
def _get_tag repo name try return [x for x in _all_tags repo if x[0] name ][0]except IndexError return False
def setup_custom_perms parent if not frappe.db.exists u'CustomDocPerm' dict parent parent copy_perms parent return True
def prep_pickle_for_total df agg_name 'median' def prep df agg getattr df agg_name df DataFrame agg 1 cols list df.columns cols[0] 'timing'df.columns colsdf['name'] list df.index return dfreturn prep df
def _inherit_doc cls def func fn fn.__doc__ cls.__dict__[fn.__name__].__doc__return fnreturn func
def p_relational_expression_3 t pass
def _get_subproject_script_location subproject entrypoint _get_installed_entrypoint subproject return ' '.join [entrypoint.module_name entrypoint.attrs[0]]
def parse_date_delta value if not value return Nonetry value int value except ValueError return parse_date value else return _now + timedelta seconds value
def _is_random_access_file_backed fileobj return isfile fileobj or isinstance fileobj gzip.GzipFile
def get_files addon_guids addons Addon.objects.filter guid__in addon_guids status__in amo.VALID_ADDON_STATUSES files []for addon in addons files + addon.find_latest_version amo.RELEASE_CHANNEL_LISTED .unreviewed_filesreturn files
def _get_storage_model storage_model_settings getattr django.conf.settings 'GOOGLE_OAUTH2_STORAGE_MODEL' None if storage_model_settings is not None return storage_model_settings['model'] storage_model_settings['user_property'] storage_model_settings['credentials_property'] else return None None None
def parse_positional_flags source info flags_on flags_off version info.flags & _ALL_VERSIONS or DEFAULT_VERSION if version VERSION0 if flags_off raise error 'badinlineflags cannotturnflagsoff' source.string source.pos new_global_flags flags_on & ~ info.global_flags if new_global_flags info.global_flags | new_global_flagsraise _UnscopedFlagSet info.global_flags else info.flags info.flags | flags_on & ~ flags_off source.ignore_space bool info.flags & VERBOSE
def test_make_function_with_signature_lineno def crashy_function *args **kwargs 1 / 0 wrapped make_function_with_signature crashy_function u'a' u'b' line u"\nwrapped make_function_with_signature crashy_function 'a' 'b' \n".strip try wrapped 1 2 except Exception exc_cls exc tb sys.exc_info assert exc_cls is ZeroDivisionError tb_lines traceback.format_tb tb assert u'1/0' in tb_lines[ -1 ] assert line in tb_lines[ -2 ] and u'line ' not in tb_lines[ -2 ] else pytest.fail u'Thisshouldhavecausedanexception'
def port2string port return struct.pack '>H' port
def match document topic None result_key None result_relative_url '/_ah/prospective_search' result_task_queue 'default' result_batch_size DEFAULT_RESULT_BATCH_SIZE result_return_document True from google.appengine.ext import dbrequest prospective_search_pb.MatchRequest if isinstance document db.Model topic _get_document_topic document topic doc_pb db.model_to_protobuf document if result_return_document request.set_result_python_document_class _doc_class.MODEL elif isinstance document datastore.Entity topic _get_document_topic document topic doc_pb document.ToPb if result_return_document request.set_result_python_document_class _doc_class.ENTITY else raise DocumentTypeError request.set_topic topic request.mutable_document .CopyFrom doc_pb if result_key request.set_result_key result_key request.set_result_relative_url result_relative_url request.set_result_task_queue result_task_queue request.set_result_batch_size result_batch_size response prospective_search_pb.MatchResponse _make_sync_call 'matcher' 'Match' request response
def success request message extra_tags '' fail_silently False add_message request constants.SUCCESS message extra_tags extra_tags fail_silently fail_silently
def split_into n type value parts [x.strip for x in value.split ';' n - 1 ]if sum 1 for part in parts if part < n raise ValueError 'invalid%sindexentry%r' % type value return parts
def parse_cache_control_header value on_update None cls None if cls is None cls RequestCacheControlif not value return cls None on_update return cls parse_dict_header value on_update
def xml_prettify elem text ET.tostring elem 'utf-8' reparsed minidom.parseString text return reparsed.toprettyxml indent ''
def add_member_into_chatroom self chatroomUserName memberList useInvitation False if not useInvitation chatroom self.storageClass.search_chatrooms userName chatroomUserName if not chatroom chatroom self.update_chatroom chatroomUserName if len chatroom['MemberList'] > self.loginInfo['InviteStartCount'] useInvitation Trueif useInvitation fun memberKeyName 'invitemember' 'InviteMemberList' else fun memberKeyName 'addmember' 'AddMemberList' url '%s/webwxupdatechatroom?fun %s&pass_ticket %s' % self.loginInfo['url'] fun self.loginInfo['pass_ticket'] params {'BaseRequest' self.loginInfo['BaseRequest'] 'ChatRoomName' chatroomUserName memberKeyName ' '.join [member['UserName'] for member in memberList] }headers {'content-type' 'application/json;charset UTF-8' 'User-Agent' config.USER_AGENT}r self.s.post url data json.dumps params headers headers return ReturnValue rawResponse r
def roster opts runner whitelist None return LazyLoader _module_dirs opts 'roster' opts tag 'roster' whitelist whitelist pack {'__runner__' runner}
def getOneAddress results return getOnePayload results .dottedQuad
def create_or_update_tool_dependency app tool_shed_repository name version type status set_status True context app.install_model.contextif version tool_dependency get_tool_dependency_by_name_version_type_repository app tool_shed_repository name version type else tool_dependency get_tool_dependency_by_name_type_repository app tool_shed_repository name type if tool_dependency if set_status set_tool_dependency_attributes app tool_dependency tool_dependency status status else debug_msg 'Creatinganewrecordforversion%softooldependency%sforrevision%sofrepository%s.' % str version str name str tool_shed_repository.changeset_revision str tool_shed_repository.name debug_msg + 'Thestatusisbeingsetto%s.' % str status log.debug debug_msg tool_dependency app.install_model.ToolDependency tool_shed_repository.id name version type status context.add tool_dependency context.flush return tool_dependency
def _get_version_from_git_tag path m GIT_DESCRIBE_REGEX.match _git_describe_tags path or '' if m is None return None version post_commit hash m.groups return version if post_commit '0' else '{0}.post{1}+{2}'.format version post_commit hash
def set_pricing driver_type driver_name pricing PRICING_DATA[driver_type][driver_name] pricing
def DEFINE_boolean name default help CONFIG.AddOption type_info.Bool name name default default description help
def date_to_key date return int date.strftime '%Y%m%d'
@check_is_trading@export_as_api@ExecutionContext.enforce_phase EXECUTION_PHASE.HANDLE_BAR EXECUTION_PHASE.SCHEDULED def order_target_percent id_or_ins percent style None order_book_id assure_order_book_id id_or_ins bar_dict ExecutionContext.get_current_bar_dict price bar_dict[order_book_id].closeposition get_simu_exchange .account.portfolio.positions[order_book_id]current_value position.quantity * price portfolio_value get_simu_exchange .account.portfolio.portfolio_valuereturn order_value order_book_id portfolio_value * percent - current_value style
def _log file_list list_name in_path file_names '\n'.join file_list LOG.debug '\nDiscovered{0}{1}file s in{2} \n{3}\n'.format len file_list list_name in_path file_names
def gf_crt U M K None p prod M start K.one v K.zerofor u m in zip U M e p // m s _ _ K.gcdex e m v + e * u * s % m return v % p
def save_child_position seq_module child_name for position child in enumerate seq_module.get_display_items start 1 if child.location.name child_name if position ! seq_module.position seq_module.position positionseq_module.save
def read_packet data local_sock remote_addr opcode unpack '!H' data[0 2] if opcode < 1 or opcode > 6 logging.warn 'Unknownrequestid%dfrom%s' % opcode remote_addr local_sock.sendto ERRORPacket 0 'Unknownrequest' .marshall remote_addr return Noneif REQUESTS[opcode][REQ_CLASS] is None if opcode ! TFTP_OPCODE_ERROR logging.warn 'Unsupportedrequest%d %s from%s' % opcode REQUESTS[opcode][REQ_NAME] remote_addr local_sock.sendto ERRORPacket 2 'Unsupportedrequest' .marshall remote_addr return Nonetry return REQUESTS[opcode][REQ_CLASS] data local_sock remote_addr except return None
def virtual_interface_list provider names **kwargs client _get_client return client.extra_action provider provider names names action 'virtual_interface_list' **kwargs
def fmt docstr docstr docstr.replace '\n' '' docstr docstr.strip return docstr
def find_media_source url while url[0] '/' url url[1 ]d os.path.dirnamen os.path.normpathj os.path.joinf os.path.isfileskins n j d d __file__ 'skins' try media os.path.join skins settings.OSQA_DEFAULT_SKIN url assert f media use_skin settings.OSQA_DEFAULT_SKINexcept try media j skins 'default' url assert f media use_skin 'default'except media j skins 'common' url try assert f media use_skin 'common'except logging.error 'couldnotfindmediafor%s' % url use_skin ''return Nonereturn use_skin + '/' + url
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def send_moderator_action_email sender_id recipient_id intent exploration_title email_body require_moderator_email_prereqs_are_satisfied email_config feconf.VALID_MODERATOR_ACTIONS[intent]recipient_user_settings user_services.get_user_settings recipient_id sender_user_settings user_services.get_user_settings sender_id email_subject feconf.VALID_MODERATOR_ACTIONS[intent]['email_subject_fn'] exploration_title email_salutation_html email_config['email_salutation_html_fn'] recipient_user_settings.username email_signoff_html email_config['email_signoff_html_fn'] sender_user_settings.username full_email_content '%s<br><br>%s<br><br>%s<br><br>%s' % email_salutation_html email_body email_signoff_html EMAIL_FOOTER.value _send_email recipient_id sender_id intent email_subject full_email_content feconf.SYSTEM_EMAIL_ADDRESS bcc_admin True
def is_valid_ipv6_address address allow_brackets False if allow_brackets if address.startswith '[' and address.endswith ']' address address[1 -1 ]colon_count address.count ' ' if colon_count > 7 return Falseelif colon_count ! 7 and ' ' not in address return Falseelif address.count ' ' > 1 or ' ' in address return Falsefor entry in address.split ' ' if not re.match '^[0-9a-fA-f]{0 4}$' entry return Falsereturn True
def add_entrance_exam_milestone course entrance_exam namespace_choices get_namespace_choices milestone_relationship_types get_milestone_relationship_types milestone_namespace generate_milestone_namespace namespace_choices.get 'ENTRANCE_EXAM' course.id milestone add_milestone {'name' 'TestMilestone' 'namespace' milestone_namespace 'description' 'TestingCoursewareEntranceExamChapter'} add_course_milestone unicode course.id milestone_relationship_types['REQUIRES'] milestone add_course_content_milestone unicode course.id unicode entrance_exam.location milestone_relationship_types['FULFILLS'] milestone
def iso_to_javascript_timestamp iso secs iso_to_unix_time iso return secs * 1000
def _intToBin val if val < 0 raise ValueError 'OnlypositiveValuesallowed' s hex val .lower ret ''if s[ -1 ] 'l' s s[ -1 ]for x in s[2 ] if __debug__ if x not in _BitTable raise AssertionError 'hex returnedstrangeresult' ret + _BitTable[x]while ret[0] '0' and len ret > 1 ret ret[1 ]return ret
def isqref object return isinstance object tuple and len object 2 and isinstance object[0] basestring and isinstance object[1] basestring
def is_solution_quad var coeff u v reps dict zip var u v eq Add *[ j * i.xreplace reps for i j in coeff.items ] return _mexpand eq 0
def moments image order 3 return _moments_cy.moments_central image 0 0 order
@frappe.whitelist def get_opening_accounts company accounts frappe.db.sql_list u"select\n DCTB DCTB DCTB namefromtabAccount\n DCTB DCTB where\n DCTB DCTB DCTB is_group 0and\n DCTB DCTB DCTB report_type 'BalanceSheet'and\n DCTB DCTB DCTB ifnull warehouse '' ''and\n DCTB DCTB DCTB company %s\n DCTB DCTB orderbynameasc" company return [{u'account' a u'balance' get_balance_on a } for a in accounts]
def supports_firefox file_obj apps file_obj.version.apps.all if not file_obj.binary_components and not file_obj.strict_compatibility return apps.filter max__application__in SIGN_FOR_APPS max__version_int__gte version_int settings.MIN_D2C_VERSION else return apps.filter max__application__in [amo.FIREFOX.id amo.ANDROID.id] max__version_int__gte version_int settings.MIN_NOT_D2C_VERSION
def _norm_version version build '' l string.split version '.' if build l.append build try ints map int l except ValueError strings lelse strings map str ints version string.join strings[ 3] '.' return version
def error_from_serialization_exception exception included False type_ collection_name get_model exception.instance id_ primary_key_value exception.instance if exception.message is not None detail exception.messageelse resource 'includedresource' if included else 'resource' detail 'Failedtoserialize{0}oftype{1}andID{2}'detail detail.format resource type_ id_ return error status 500 detail detail
def _get_job_dict_from_job_model model return {'id' model.id 'time_started_msec' model.time_started_msec 'time_finished_msec' model.time_finished_msec 'status_code' model.status_code 'job_type' model.job_type 'is_cancelable' model.is_cancelable 'error' model.error 'human_readable_time_started' '' if model.time_started_msec is None else utils.get_human_readable_time_string model.time_started_msec 'human_readable_time_finished' '' if model.time_finished_msec is None else utils.get_human_readable_time_string model.time_finished_msec }
def get_wsgi_application django.setup set_prefix False return WSGIHandler
def get_page_args pages {}for arg in request.args re_match re.findall 'page_ .* ' arg if re_match pages[re_match[0]] int request.args.get arg return pages
def _cast_to_array_dtype in1 in2 if numpy.issubdtype in2.dtype numpy.float in1 in1.real.astype in2.dtype else in1 in1.astype in2.dtype return in1
def formatException exctype value tb skip 0 lines traceback.format_exception exctype value tb lines [lines[0]] + traceback.format_stack [ - skip + 1 ] + ['---exceptioncaughthere---\n'] + lines[1 ] return lines
def _in x y try return x.isin y except AttributeError if is_list_like x try return y.isin x except AttributeError passreturn x in y
def _check_for_unavailable_sdk _config_vars cflags _config_vars.get 'CFLAGS' '' m re.search '-isysroot\\s+ \\S+ ' cflags if m is not None sdk m.group 1 if not os.path.exists sdk for cv in _UNIVERSAL_CONFIG_VARS if cv in _config_vars and cv not in os.environ flags _config_vars[cv]flags re.sub '-isysroot\\s+\\S+ ? \\s|$ ' '' flags _save_modified_value _config_vars cv flags return _config_vars
def printConnections switches for sw in switches output '%s ' % sw for intf in sw.intfList link intf.linkif link intf1 intf2 link.intf1 link.intf2 remote intf1 if intf1.node ! sw else intf2 output '%s %s ' % remote.node sw.ports[intf] output '\n'
def custom_forward app mapper global_conf None **kw warnings.warn 'errordocuments.custom_forwardhasbeendeprecated;pleaseuseerrordocuments.StatusBasedForward' DeprecationWarning 2 if global_conf is None global_conf {}return _StatusBasedRedirect app mapper global_conf **kw
def is_python_interpreter filename real_filename os.path.realpath filename if not osp.isfile real_filename or encoding.is_text_file real_filename or not is_python_interpreter_valid_name filename return Falsetry proc run_program filename ['-h'] output to_text_string proc.communicate [0] valid 'Optionsandarguments andcorrespondingenvironmentvariables 'if 'usage ' in output and valid in output return Trueelse return Falseexcept return False
def reset_output state None _state.reset
def colorize image hue saturation 1 hsv color.rgb2hsv image hsv[ 1] saturationhsv[ 0] huereturn color.hsv2rgb hsv
def set_emerge_default_opts value return set_var 'EMERGE_DEFAULT_OPTS' value
def CanonicalPathToLocalPath path return utils.SmartStr utils.NormalizePath path
def getLargestCenterOutsetLoopFromLoop loop radius thresholdRatio 0.9 if radius 0.0 return loopradius abs radius points getPointsFromLoop loop radius thresholdRatio centers getCentersFromPoints points globalIntercircleMultiplier * radius largestCenterOutset NonelargestOutsetArea -987654321.0 for center in centers outset getSimplifiedInsetFromClockwiseLoop center radius if isLargeSameDirection outset center radius if euclidean.isPathInsideLoop loop outset ! euclidean.isWiddershins loop centerOutset CenterOutset center outset outsetArea abs euclidean.getAreaLoop outset if outsetArea > largestOutsetArea largestOutsetArea outsetArealargestCenterOutset centerOutsetif largestCenterOutset None return NonelargestCenterOutset.center euclidean.getSimplifiedLoop largestCenterOutset.center radius return largestCenterOutset
@must_have_addon SHORT_NAME 'node' @must_be_addon_authorizer SHORT_NAME def figshare_folder_list node_addon **kwargs return node_addon.get_folders
@lower_builtin 'is' types.Any types.Any def generic_is context builder sig args lhs_type rhs_type sig.argsif lhs_type rhs_type if lhs_type.mutable raise NotImplementedError 'nodefault`is`implementation' else try eq_impl context.get_function ' ' sig except NotImplementedError return cgutils.false_bitelse return eq_impl builder args else return cgutils.false_bit
def upper s return s.upper
def _preparse source f compose _replace_locals _replace_booleans _rewrite_assign assert callable f 'fmustbecallable'return tokenize.untokenize lmap f tokenize_string source
def _assert_shielding raw_sss erm_power shielding_factor meg 'mag' picks pick_types raw_sss.info meg meg ref_meg False if isinstance erm_power BaseRaw picks_erm pick_types raw_sss.info meg meg ref_meg False assert_allclose picks picks_erm erm_power np.sqrt erm_power[picks_erm][0] ** 2 .sum sss_power raw_sss[picks][0].ravel sss_power np.sqrt np.sum sss_power * sss_power factor erm_power / sss_power assert_true factor > shielding_factor 'Shieldingfactor%0.3f<%0.3f' % factor shielding_factor
def type_ return Rebulk .rules TypeProcessor
def CodesearchFeedFromString xml_string return atom.CreateClassFromXMLString CodesearchFeed xml_string
@removals.remove message 'keystoneclientauthpluginsaredeprecated.Usekeystoneauth.' version '2.1.0' removal_version '3.0.0' def load_from_conf_options conf group **kwargs if conf[group].auth_section group conf[group].auth_sectionname conf[group].auth_pluginif not name return Noneplugin_class base.get_plugin_class name plugin_class.register_conf_options conf group return plugin_class.load_from_conf_options conf group **kwargs
def getFilePathsByDirectory directoryName absoluteDirectoryPath os.path.abspath directoryName directory os.listdir directoryName filePaths []for fileName in directory filePaths.append os.path.join absoluteDirectoryPath fileName return filePaths
@locked_functiondef store_in_cache cache_location url response hpath bpath calculate_cache_path cache_location url try outf open hpath 'wb' headers str response.info outf.write headers outf.close outf open bpath 'wb' outf.write response.read outf.close except IOError return Trueelse return False
def served url r requests.get url allow_redirects False return r.status_code 200
def remove_datasource jboss_config name profile None log.debug ' MODULEFUNCTION jboss7.remove_datasource name %s profile %s' name profile operation '/subsystem datasources/data-source {name} remove'.format name name if profile is not None operation '/profile "{profile}"'.format profile profile + operation return __salt__['jboss7_cli.run_operation'] jboss_config operation fail_on_error False
def _millis_to_datetime millis opts diff millis % 1000 + 1000 % 1000 seconds millis - diff / 1000 micros diff * 1000 if opts.tz_aware dt EPOCH_AWARE + datetime.timedelta seconds seconds microseconds micros if opts.tzinfo dt dt.astimezone opts.tzinfo return dtelse return EPOCH_NAIVE + datetime.timedelta seconds seconds microseconds micros
def checks_run_recently request ten_mins datetime.utcnow .replace tzinfo utc - timedelta minutes 10 most_recent StatusCheckResult.objects.filter time_complete__gte ten_mins if most_recent.exists return HttpResponse 'Checksrunning' return HttpResponse 'Checksnotrunning'
def parse_dmraid rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--name' dest 'name' action 'store' parser.add_argument '--dev' dest 'dev' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
def compute_precision tp fp precision tp / T.maximum 1.0 tp + fp return precision
def FakeReadlink path raise OSError errno.EINVAL 'Invalidargument' path
def create_or_resurrect_store f parent name translation_project try store Store.objects.get parent parent name name store.resurrect save False resurrect_units False store_log user 'system' action STORE_RESURRECTED path store.pootle_path store store.id except Store.DoesNotExist store Store.objects.create file f parent parent name name translation_project translation_project return store
def fill_stmt iterable fill_len fill_len + 1overflow Noneit iter iterable while True buffer_ []total_len 0if overflow buffer_.append overflow total_len + len overflow + 1 overflow Nonewhile total_len < fill_len try new_item it.next buffer_.append new_item total_len + len new_item + 1 except StopIteration if buffer_ breakif overflow yield overflow returnif total_len > fill_len overflow buffer_.pop total_len - len overflow - 1 ret ''.join buffer_ assert len ret < fill_len yield ret
def _is_nthpow_residue_bign a n m if primitive_root m is None for prime power in factorint m .items if not _is_nthpow_residue_bign_prime_power a n prime power return Falsereturn Truef totient m k f // igcd f n return pow a k m 1
def capacity_indicator return s3_rest_controller
def LoginRedirect login_url hostname port relative_url outfile hostname os.environ['NGINX_HOST']port os.environ['NGINX_PORT']dest_url 'http //%s %s%s' % hostname port relative_url redirect_url 'http //%s %s%s?%s %s' % hostname port login_url CONTINUE_PARAM urllib.quote dest_url outfile.write 'Status 302Requireslogin\r\n' output_headers []output_headers.append ClearUserInfoCookie for header in output_headers outfile.write header outfile.write 'Location %s\r\n\r\n' % redirect_url
def _PPIGuessPayloadClass p **kargs if len p > 4 t pfh_len struct.unpack '<HH' p[ 4] cls getPPIType t 'default' pfh_len + 4out cls p[ pfh_len] **kargs if out.payload out.payload conf.raw_layer out.payload.load if len p > pfh_len out.payload.payload conf.padding_layer p[pfh_len ] elif len p > pfh_len out.payload conf.padding_layer p[pfh_len ] else out conf.raw_layer p **kargs return out
def fuzzy_and args rv Truefor ai in args ai fuzzy_bool ai if ai is False return Falseif rv rv aireturn rv
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def to_query_str params comma_delimited_lists True prefix True if not params return ''query_str '?' if prefix else '' for k v in params.items if v is True v 'true'elif v is False v 'false'elif isinstance v list if comma_delimited_lists v ' '.join map str v else for list_value in v if list_value is True list_value 'true'elif list_value is False list_value 'false'else list_value str list_value query_str + k + ' ' + list_value + '&' continueelse v str v query_str + k + ' ' + v + '&' return query_str[ -1 ]
def trim_internal x axes olist []for i bd in enumerate x.chunks ilist []for d in bd ilist.append d - axes.get i 0 * 2 olist.append tuple ilist chunks tuple olist return map_blocks partial chunk.trim axes axes x chunks chunks dtype x.dtype
def _find_peaks evoked npeaks from scipy.signal import argrelmaxgfp evoked.data.std axis 0 order len evoked.times // 30 if order < 1 order 1peaks argrelmax gfp order order axis 0 [0]if len peaks > npeaks max_indices np.argsort gfp[peaks] [ - npeaks ]peaks np.sort peaks[max_indices] times evoked.times[peaks]if len times 0 times [evoked.times[gfp.argmax ]]return times
def parse_stories lines only_supporting False data []story []for line in lines line line.decode 'utf-8' .strip nid line line.split '' 1 nid int nid if nid 1 story []if ' DCTB ' in line q a supporting line.split ' DCTB ' q tokenize q substory Noneif only_supporting supporting map int supporting.split substory [story[ i - 1 ] for i in supporting]else substory [x for x in story if x]data.append substory q a story.append '' else sent tokenize line story.append sent return data
def abort global __SCHEDif __SCHED logging.debug 'Terminatingscheduler' __SCHED.running False
def getTopStories maxResults None hdr {'User-Agent' 'Mozilla/5.0'}req urllib2.Request URL headers hdr page urllib2.urlopen req .read soup BeautifulSoup page matches soup.findAll 'td' class_ 'title' matches [m.a for m in matches if m.a and m.text ! u'More' ]matches [HNStory m.text m['href'] for m in matches]if maxResults num_stories min maxResults len matches return random.sample matches num_stories return matches
def estimate_location a scale norm None axis 0 initial None maxiter 30 tol 1e-06 if norm is None norm HuberT if initial is None mu np.median a axis else mu initialfor iter in range maxiter W norm.weights a - mu / scale nmu np.sum W * a axis / np.sum W axis if np.alltrue np.less np.fabs mu - nmu scale * tol return nmuelse mu nmuraise ValueError 'locationestimatorfailedtoconvergein%diterations' % maxiter
def _unpack_asf_image data type size struct.unpack_from '<bi' data pos 5mime ''while data[pos pos + 2 ] ! '\x00\x00' mime + data[pos pos + 2 ]pos + 2pos + 2description ''while data[pos pos + 2 ] ! '\x00\x00' description + data[pos pos + 2 ]pos + 2pos + 2image_data data[pos pos + size ]return mime.decode 'utf-16-le' image_data type description.decode 'utf-16-le'
def detectencoding_unicode input final False prefix '@charset"'if input.startswith prefix pos input.find '"' len prefix if pos > 0 return input[len prefix pos] True elif final or not prefix.startswith input return 'utf-8' False return None False
def show_subnet subnet profile None conn _auth profile return conn.show_subnet subnet
def first_non_none_response responses default None for response in responses if response[1] is not None return response[1]return default
def get_boulder_header key_bytes pub_hex pub_exp re.search 'modulus \\n\\s+00 [a-f0-9\\ \\s]+? \\npublicExponent [0-9]+ ' key_bytes.decode 'utf8' re.MULTILINE | re.DOTALL .groups pub_exp '{0 x}'.format int pub_exp pub_exp '0{0}'.format pub_exp if len pub_exp % 2 else pub_exp header {'alg' 'RS256' 'jwk' {'e' _b64 binascii.unhexlify pub_exp.encode 'utf-8' 'kty' 'RSA' 'n' _b64 binascii.unhexlify re.sub ' \\s| ' '' pub_hex .encode 'utf-8' }}return header
def OPTIMIZE writer segments from whoosh.filedb.filereading import SegmentReaderfor seg in segments reader SegmentReader writer.storage writer.schema seg writer.add_reader reader reader.close return []
def plotting_positions data alpha 0.4 beta 0.4 data ma.array data copy False .reshape 1 -1 n data.count plpos np.empty data.size dtype float plpos[n ] 0plpos[data.argsort [ n]] np.arange 1 n + 1 - alpha / n + 1.0 - alpha - beta return ma.array plpos mask data._mask
def download_video youtube_id format 'mp4' callback None download_url 'http //%s/download/videos/' % settings.CENTRAL_SERVER_HOST + '%s/%s' return videos.download_video youtube_id settings.CONTENT_ROOT download_url format callback
def simulate_request app method 'GET' path '/' query_string None headers None body None file_wrapper None params None params_csv True if not path.startswith '/' raise ValueError "pathmuststartwith'/'" if query_string and query_string.startswith '?' raise ValueError "query_stringshouldnotstartwith'?'" if '?' in path raise ValueError 'pathmaynotcontainaquerystring.Pleaseusethequery_stringparameterinstead.' if query_string is None query_string to_query_str params comma_delimited_lists params_csv prefix False env helpers.create_environ method method path path query_string query_string or '' headers headers body body file_wrapper file_wrapper srmock StartResponseMock validator wsgiref.validate.validator app iterable validator env srmock result Result iterable srmock.status srmock.headers return result
def get_assignment_type user_group course_cohort user_group.cohortreturn course_cohort.assignment_type
def first_found apps apps tuple apps not_found error httplib.NOT_FOUND def first_found_app environ start_response 'Compoundapplicationreturnedfromthefirst_foundfunction.'final_result {}def first_found_start_response status response_headers "Replacementforstart_responseaspassedintofirst_found_app.\n\nCalledbyeachapplicationinappsinsteadoftherealstartresponse.\nCheckstheresponsestatus andifanythingotherthan404 sets'status'\nand'response_headers'infinal_result.\n"status_match _STATUS_PATTERN.match status assert status_match 'Statusmustbeastringbeginningwith3digitnumber.Found %s' % status status_code status_match.group 0 if int status_code httplib.NOT_FOUND returnfinal_result['status'] statusfinal_result['response_headers'] response_headersfor app in apps response app environ first_found_start_response if final_result start_response final_result['status'] final_result['response_headers'] return responsereturn not_found environ start_response return first_found_app
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def getMemorySize try statm open '/proc/self/statm' .readline .split except IOError return Nonereturn int statm[0] * PAGE_SIZE
@bdd.given bdd.parsers.parse 'Iopen{path}' def open_path_given quteproc path quteproc.open_path path new_tab True
def validate_column_specs events next_value_columns previous_value_columns required required_event_fields next_value_columns previous_value_columns received set events.columns missing required - received if missing raise ValueError 'EventsLoadermissingrequiredcolumns{missing}.\nGotColumns {received}\nExpectedColumns {required}'.format missing sorted missing received sorted received required sorted required
def _parse_date_delta value if not value return Nonetry value int value except ValueError passelse delta timedelta seconds value return datetime.now + delta return _parse_date value
@receiver models.signals.post_save sender VerificationDeadline @receiver models.signals.post_delete sender VerificationDeadline def invalidate_deadline_caches sender **kwargs cache.delete VerificationDeadline.ALL_DEADLINES_CACHE_KEY
def get_change_column_query f new desc frappe.db.sql u'desc`tab%s`' % f[u'parent'] for d in desc if d[0] f[u'fieldname'] return u'altertable`tab%s`change`%s``%s`%s' % f[u'parent'] f[u'fieldname'] new d[1]
def str_to_int int_str if int_str is None return Noneint_str re.sub u'[ \\.\\+]' u'' int_str return int int_str
def get_provider name None id None if id is not None provider ALL_PROVIDERS_BY_ID[id] else if name is None name settings.DEFAULT_PAYMENT_PROVIDERprovider ALL_PROVIDERS[name] if provider.name not in settings.PAYMENT_PROVIDERS raise ImproperlyConfigured 'Theprovider{p}isnotoneoftheallowedPAYMENT_PROVIDERS.'.format p provider.name return provider
def reboot zone single False altinit None smf_options None ret {'status' True}boot_options ''if single boot_options '-s{0}'.format boot_options if altinit boot_options '-i{0}{1}'.format altinit boot_options if smf_options boot_options '-m{0}{1}'.format smf_options boot_options if boot_options ! '' boot_options '--{0}'.format boot_options.strip res __salt__['cmd.run_all'] 'zoneadm{zone}reboot{boot_opts}'.format zone '-u{0}'.format zone if _is_uuid zone else '-z{0}'.format zone boot_opts boot_options ret['status'] res['retcode'] 0 ret['message'] res['stdout'] if ret['status'] else res['stderr'] ret['message'] ret['message'].replace 'zoneadm ' '' if ret['message'] '' del ret['message']return ret
def which program def is_exe fpath return os.path.isfile fpath and os.access fpath os.X_OK fpath fname os.path.split program if fpath if is_exe program return programelse for path in os.environ['PATH'].split os.pathsep exe_file os.path.join path program if is_exe exe_file return exe_file
def s3_comments_represent text show_link True text s3_unicode text if len text < 80 return textelif not show_link return '%s...' % text[ 76] else import uuidunique uuid.uuid4 represent DIV DIV text _id unique _class 'hideshowall' _onmouseout "$ '#%s' .hide " % unique A '%s...' % text[ 76] _onmouseover "$ '#%s' .removeClass 'hide' .show " % unique return represent
def makeFailure try 1 / 0 except ZeroDivisionError f failure.Failure return f
def image_meta system_metadata image_meta {}for md_key md_value in system_metadata.iteritems if md_key.startswith 'image_' image_meta[md_key[6 ]] md_valuereturn image_meta
def syspath path prefix True if os.path.__name__ ! 'ntpath' return pathif not isinstance path unicode try path path.decode 'utf8' except UnicodeError encoding sys.getfilesystemencoding or sys.getdefaultencoding path path.decode encoding 'replace' if prefix and not path.startswith WINDOWS_MAGIC_PREFIX if path.startswith u'\\\\' path u'UNC' + path[1 ] path WINDOWS_MAGIC_PREFIX + path return path
def _get_assistive_access cmd 'sqlite3"/Library/ApplicationSupport/com.apple.TCC/TCC.db""SELECT*FROMaccess"'call __salt__['cmd.run_all'] cmd output_loglevel 'debug' python_shell False if call['retcode'] ! 0 comment ''if 'stderr' in call comment + call['stderr']if 'stdout' in call comment + call['stdout']raise CommandExecutionError 'Error {0}'.format comment out call['stdout']return re.findall 'kTCCServiceAccessibility\\| .* \\|[0-9]{1}\\| [0-9]{1} \\|[0-9]{1}\\|' out re.MULTILINE
def get_log_file return _log.name
def _attach_volume module profitbricks datacenter volume server module.params.get 'server' if server if not uuid_match.match server server_list profitbricks.list_servers datacenter for s in server_list['items'] if server s['properties']['name'] server s['id']breaktry return profitbricks.attach_volume datacenter server volume except Exception e get_exception module.fail_json msg 'failedtoattachvolume %s' % str e
def objectSaveHook pythonObject for predicate uuid saver loader in classInfo if predicate pythonObject result saver pythonObject result['__class_uuid__'] str uuid return resultreturn {'unpersistable' True}
def PrintCategories sys.stderr.write ''.join '%s\n' % cat for cat in _ERROR_CATEGORIES sys.exit 0
def test_make_fixed_length_events raw read_raw_fif raw_fname events make_fixed_length_events raw id 1 assert_true events.shape[1] 3 events_zero make_fixed_length_events raw 1 first_samp False assert_equal events_zero[ 0 0 ] 0 assert_array_equal events_zero[ 0] events[ 0] - raw.first_samp tmin tmax raw.times[[0 -1 ]]duration tmax - tmin events make_fixed_length_events raw 1 tmin tmax duration assert_equal events.shape[0] 1 assert_raises ValueError make_fixed_length_events raw 1 tmin tmax - 0.001 duration assert_raises ValueError make_fixed_length_events raw 2.3 assert_raises ValueError make_fixed_length_events 'notraw' 2 assert_raises ValueError make_fixed_length_events raw 23 tmin tmax 'abc'
def trace_method f @functools.wraps f def trace_method_logging_wrapper *args **kwargs if TRACE_METHOD return trace f *args **kwargs return f *args **kwargs return trace_method_logging_wrapper
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def fetch_google uuid fetch_url constants.UrlfetchTestIdentifiers.GOOGLE_URLreturn fetch fetch_url
def hash_params params if isinstance params collections.Container and not isinstance params text_type binary_type if isinstance params collections.Mapping try new_params frozenset params.items except TypeError new_params set for k v in params.items new_params.update k hash_params v new_params frozenset new_params elif isinstance params collections.Set collections.Sequence try new_params frozenset params except TypeError new_params set for v in params new_params.update hash_params v new_params frozenset new_params else new_params frozenset params return new_paramsreturn frozenset params
def _is_number_match_SS number1 number2 try numobj1 parse number1 UNKNOWN_REGION return _is_number_match_OS numobj1 number2 except NumberParseException _ exc _ sys.exc_info if exc.error_type NumberParseException.INVALID_COUNTRY_CODE try numobj2 parse number2 UNKNOWN_REGION return _is_number_match_OS numobj2 number1 except NumberParseException _ exc2 _ sys.exc_info if exc2.error_type NumberParseException.INVALID_COUNTRY_CODE try numobj1 parse number1 None keep_raw_input False _check_region False numobj None numobj2 parse number2 None keep_raw_input False _check_region False numobj None return _is_number_match_OO numobj1 numobj2 except NumberParseException return MatchType.NOT_A_NUMBERreturn MatchType.NOT_A_NUMBER
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def trim_win_path path if sabnzbd.WIN32 and len path > 69 path folder os.path.split path maxlen 69 - len path if len folder > maxlen folder folder[ maxlen]path os.path.join path folder .rstrip '.' return path
def unicode2local p return p
def is_generator obj if isinstance obj types.GeneratorType return TrueCO_GENERATOR 32return bool inspect.isfunction obj or inspect.ismethod obj and obj.func_code.co_flags & CO_GENERATOR
def accumulateClassList classObj attr listObj baseClass None for base in classObj.__bases__ accumulateClassList base attr listObj if baseClass is None or baseClass in classObj.__bases__ listObj.extend classObj.__dict__.get attr []
def merge_recursive obj_a obj_b level False return aggregate obj_a obj_b level map_class AggregatedMap sequence_class AggregatedSequence
def libvlc_media_is_parsed p_md f _Cfunctions.get 'libvlc_media_is_parsed' None or _Cfunction 'libvlc_media_is_parsed' 1 None ctypes.c_int Media return f p_md
def batch_sort input_iterator output_path buffer_size 32000 output_class None if not output_class output_class input_iterator.__class__chunks []try while True current_chunk list islice input_iterator buffer_size if not current_chunk breakcurrent_chunk.sort fd filepath tempfile.mkstemp os.close fd output_chunk output_class filepath chunks.append output_chunk for elem in current_chunk output_chunk.write elem.obj output_chunk.close output_file output_class output_path for elem in heapq.merge *chunks output_file.write elem.obj output_file.close finally for chunk in chunks try chunk.close os.remove chunk.name except Exception pass
def msign x return ma.filled np.sign x 0
def _fastq_solexa_convert_qual in_handle out_handle alphabet None from Bio.SeqIO.QualityIO import phred_quality_from_solexamapping dict chr q + 64 str int round phred_quality_from_solexa q for q in range -5 62 + 1 return _fastq_convert_qual in_handle out_handle mapping
def getIntersectingWithinLoops loop loopList outsetLoop intersectingWithinLoops []for otherLoop in loopList if getIsIntersectingWithinLoop loop otherLoop outsetLoop intersectingWithinLoops.append otherLoop return intersectingWithinLoops
def is_keystone_version_available session version d keystone_discover.Discover session try d.create_client version except discovery_exc.DiscoveryFailure discovery_exc.VersionNotAvailable return Falseelse return True
def ModuleHasValidMainFunction module if hasattr module 'main' and type module.main is types.FunctionType arg_names var_args var_kwargs default_values inspect.getargspec module.main if len arg_names 0 return Trueif default_values is not None and len arg_names len default_values return Truereturn False
def admin_password if 'admin_password' not in DETAILS log.info 'proxy.fx2 Noadmin_passwordinDETAILS returningDelldefault' return 'calvin'return DETAILS.get 'admin_password' 'calvin'
def get_http_searches http_url_req body host false_pos ['i.stack.imgur.com']searched Noneif http_url_req ! None searched re.search http_search_re http_url_req re.IGNORECASE if searched None searched re.search http_search_re body re.IGNORECASE if searched ! None and host not in false_pos searched searched.group 3 try searched searched.decode 'utf8' except UnicodeDecodeError returnif searched in [str num for num in range 0 10 ] returnif len searched > 100 returnmsg 'Searched%s %s' % host unquote searched.encode 'utf8' .replace '+' '' return msg
def username_password_authn environ start_response reference key redirect_uri logger.info 'Theloginpage' headers []resp Response mako_template 'login.mako' template_lookup LOOKUP headers headers argv {'action' '/verify' 'login' '' 'password' '' 'key' key 'authn_reference' reference 'redirect_uri' redirect_uri}logger.info 'do_authenticationargv %s' % argv return resp environ start_response **argv
def get_object_list klass **kwargs queryset _get_queryset klass if hasattr klass 'in_trash' queryset queryset.filter klass.in_trash ! True kwargs specials extract_special_queries kwargs for i in kwargs if type kwargs[i] str queryset queryset.filter func.lower getattr klass i kwargs[i].lower else queryset queryset.filter getattr klass i kwargs[i] obj_list apply_special_queries queryset specials return list obj_list
def parse_gid gid try return int gid except ValueError if grp try return grp.getgrnam gid .gr_gidexcept KeyError raise KeyError 'Groupdoesnotexist %r' % gid raise
def cal rel os.popen 'cal' .read .split '\n' month rel.pop 0 date rel.pop 0 show_calendar month date rel
def run _task
@blueprint.route '/summary' methods ['GET'] def summary job job_from_request if isinstance job dataset_images.ImageClassificationDatasetJob return dataset_images.classification.views.summary job elif isinstance job dataset_images.GenericImageDatasetJob return dataset_images.generic.views.summary job elif isinstance job generic.GenericDatasetJob return generic.views.summary job else raise werkzeug.exceptions.BadRequest 'Invalidjobtype'
def group_by_video list_results result defaultdict list for video subtitles in list_results result[video] + subtitles or [] return result
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
@real_memoizedef is_netbsd return sys.platform.startswith 'netbsd'
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
def run_system_tests options import subprocessmajor_version sys.version_info[0]call_args [sys.executable '-m' 'unittest' '-v' 'gluon.tests']if major_version 2 sys.stderr.write 'Python2.7\n' else sys.stderr.write 'ExperimentalPython3.x.\n' if options.with_coverage has_coverage Falsecoverage_exec 'coverage2' if major_version 2 else 'coverage3' try import coveragehas_coverage Trueexcept sys.stderr.write 'Coveragewasnotinstalled skipping\n' coverage_config_file os.path.join 'gluon' 'tests' 'coverage.ini' coverage_config os.environ.setdefault 'COVERAGE_PROCESS_START' coverage_config_file call_args [coverage_exec 'run' '--rcfile %s' % coverage_config '-m' 'unittest' '-v' 'gluon.tests']if has_coverage ret subprocess.call call_args else ret 256else ret subprocess.call call_args sys.exit ret and 1
def _numpy_zeros m n **options dtype options.get 'dtype' 'float64' if not np raise ImportErrorreturn np.zeros m n dtype dtype
def bucketpanel series bins None by None cat None use_by by is not None use_cat cat is not None if use_by and use_cat raise Exception 'mustspecifybyorcat butnotboth' elif use_by if len by ! 2 raise Exception 'mustprovidetwobucketingseries' xby yby by xbins ybins binsreturn _bucketpanel_by series xby yby xbins ybins elif use_cat xcat ycat catreturn _bucketpanel_cat series xcat ycat else raise Exception 'mustspecifyeithervaluesorcategoriestobucketby'
def survey_getQuestionFromName name series_id s3db current.s3dbsertable s3db.survey_seriesq_ltable s3db.survey_question_listqsntable s3db.survey_questionquery sertable.id series_id & q_ltable.template_id sertable.template_id & q_ltable.question_id qsntable.id & qsntable.name name record current.db query .select qsntable.id qsntable.code qsntable.name qsntable.type q_ltable.posn limitby 0 1 .first if record is None loc_list current.gis.get_all_current_levels for row in loc_list.items if row[1] name return survey_getQuestionFromName row[0] series_id question {}question_row record.survey_questionquestion['qstn_id'] question_row.idquestion['code'] question_row.codequestion['name'] question_row.namequestion['type'] question_row.typequestion['posn'] record.survey_question_list.posnreturn question
def find_paths_breadth_first from_target to_target log log.debug u'Lookingforallpathsfrom{}to{}'.format from_target.address.reference to_target.address.reference if from_target to_target yield [from_target] returnvisited_edges set to_walk_paths deque [[from_target]] while len to_walk_paths > 0 cur_path to_walk_paths.popleft target cur_path[ -1 ]if len cur_path > 1 prev_target cur_path[ -2 ]else prev_target Nonecurrent_edge prev_target target if current_edge not in visited_edges for dep in target.dependencies dep_path cur_path + [dep] if dep to_target yield dep_path else to_walk_paths.append dep_path visited_edges.add current_edge
def fixed_ip_get_by_instance context instance_uuid return IMPL.fixed_ip_get_by_instance context instance_uuid
def namedModule name topLevel __import__ name packages name.split '.' [1 ]m topLevelfor p in packages m getattr m p return m
@transaction.non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def calculate_grades_csv request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id try lms.djangoapps.instructor_task.api.submit_calculate_grades_csv request course_key success_status _ 'Thegradereportisbeingcreated.Toviewthestatusofthereport seePendingTasksbelow.' return JsonResponse {'status' success_status} except AlreadyRunningError already_running_status _ 'Thegradereportiscurrentlybeingcreated.Toviewthestatusofthereport seePendingTasksbelow.Youwillbeabletodownloadthereportwhenitiscomplete.' return JsonResponse {'status' already_running_status}
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def method_name method mname name method if is_class_private_name mname mname '_%s%s' % name method.__self__.__class__ mname return mname
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def check_job_dependencies host_objects job_dependencies host_ids [host.id for host in host_objects]hosts_in_job models.Host.objects.filter id__in host_ids ok_hosts hosts_in_jobfor index dependency in enumerate job_dependencies ok_hosts ok_hosts.filter labels__name dependency failing_hosts set host.hostname for host in host_objects - set host.hostname for host in ok_hosts if failing_hosts raise model_logic.ValidationError {'hosts' 'Host s failedtomeetjobdependencies ' + ' '.join job_dependencies + ' ' + ' '.join failing_hosts }
def get_group_symbol locale LC_NUMERIC return Locale.parse locale .number_symbols.get 'group' u' '
def compute_nb X y Z labels [int t for t in y]ptrain [X[i] for i in range len labels if labels[i] 0 ]ntrain [X[i] for i in range len labels if labels[i] 1 ]poscounts nbsvm.build_dict ptrain [1 2] negcounts nbsvm.build_dict ntrain [1 2] dic r nbsvm.compute_ratio poscounts negcounts trainX nbsvm.process_text X dic r [1 2] devX nbsvm.process_text Z dic r [1 2] return trainX devX
def down iface iface_type if iface_type not in ['slave'] return __salt__['cmd.run'] 'ifdown{0}'.format iface return None
def check_cache_time path max_age if not os.path.isfile path return Falsecache_modified_time os.stat path .st_mtimetime_now time.time if cache_modified_time < time_now - max_age return Falseelse return True
def _setStyle node styleMap fixedStyle ';'.join [ prop + ' ' + styleMap[prop] for prop in styleMap.keys ] if fixedStyle ! '' node.setAttribute 'style' fixedStyle elif node.getAttribute 'style' node.removeAttribute 'style' return node
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def notifier_icon_path return wf .datafile u'Notify.app/Contents/Resources/applet.icns'
def randomRange start 0 stop 1000 seed None randint random.WichmannHill seed .randint if seed is not None else random.randint return int randint start stop
def find_orphaned_vdi_uuids xenapi connected_vdi_uuids set _find_vdis_connected_to_vm xenapi connected_vdi_uuids all_vdi_uuids set _find_all_vdis_and_system_vdis xenapi all_vdi_uuids connected_vdi_uuids orphaned_vdi_uuids all_vdi_uuids - connected_vdi_uuids return orphaned_vdi_uuids
def broadcast_dimensions argpairs numblocks sentinels 1 1 consolidate None L concat [zip inds dims for x inds x dims in join first argpairs first numblocks.items ] g groupby 0 L g dict k set [d for i d in v] for k v in g.items g2 dict k v - set sentinels if len v > 1 else v for k v in g.items if consolidate return valmap consolidate g2 if g2 and not set map len g2.values set [1] raise ValueError 'Shapesdonotalign%s' % g return valmap first g2
def fully_decorated request return HttpResponse '<html><body>dummy</body></html>'
def verify_grad op pt n_tests 2 rng None *args **kwargs if rng is None seed_rng rng numpy.randomT.verify_grad op pt n_tests rng *args **kwargs
def _send_bulk_mail recipient_ids sender_id intent email_subject email_html_body sender_email sender_name instance_id None _require_sender_id_is_valid intent sender_id recipients_settings user_services.get_users_settings recipient_ids recipient_emails [user.email for user in recipients_settings]cleaned_html_body html_cleaner.clean email_html_body if cleaned_html_body ! email_html_body log_new_error 'OriginalemailHTMLbodydoesnotmatchcleanedHTMLbody \nOriginal \n%s\n\nCleaned \n%s\n' % email_html_body cleaned_html_body returnraw_plaintext_body cleaned_html_body.replace '<br/>' '\n' .replace '<br>' '\n' .replace '<li>' '<li>-' .replace '</p><p>' '</p>\n<p>' cleaned_plaintext_body html_cleaner.strip_html_tags raw_plaintext_body def _send_bulk_mail_in_transaction instance_id None sender_name_email '%s<%s>' % sender_name sender_email email_services.send_bulk_mail sender_name_email recipient_emails email_subject cleaned_plaintext_body cleaned_html_body if instance_id is None instance_id email_models.BulkEmailModel.get_new_id '' email_models.BulkEmailModel.create instance_id recipient_ids sender_id sender_name_email intent email_subject cleaned_html_body datetime.datetime.utcnow return transaction_services.run_in_transaction _send_bulk_mail_in_transaction instance_id
def get_pid_list return psutil.pids
def smart_translate_item_data item_data if isinstance item_data basestring return _ item_data elif isinstance item_data list return map smart_translate_item_data item_data elif isinstance item_data dict if 'content' in item_data item_data['content'] _ item_data['content'] if item_data['content'] else '' for field field_data in item_data.iteritems if isinstance field_data dict item_data[field] smart_translate_item_data field_data elif isinstance field_data list item_data[field] map smart_translate_item_data field_data return item_data
def inverse_cosine_transform F k x **hints return InverseCosineTransform F k x .doit **hints
def _relative_to_absolute url url url.group 1 .strip '"\'' if not url.startswith 'data ' 'http ' 'https ' '//' url url.replace '../../' settings.STATIC_URL return 'url %s ' % url
def chem_correction melting_temp DMSO 0 fmd 0 DMSOfactor 0.75 fmdfactor 0.65 fmdmethod 1 GC None if DMSO melting_temp - DMSOfactor * DMSO if fmd if fmdmethod 1 melting_temp - fmdfactor * fmd if fmdmethod 2 if GC is None or GC < 0 raise ValueError "'GC'ismissingornegative" melting_temp + 0.453 * GC / 100.0 - 2.88 * fmd if fmdmethod not in 1 2 raise ValueError "'fmdmethod'mustbe1or2" return melting_temp
def poly_below xmin xs ys if any isinstance var np.ma.MaskedArray for var in [xs ys] numpy np.maelse numpy npxs numpy.asarray xs ys numpy.asarray ys Nx len xs Ny len ys if Nx ! Ny raise ValueError u"'xs'and'ys'musthavethesamelength" x xmin * numpy.ones 2 * Nx y numpy.ones 2 * Nx x[ Nx] xsy[ Nx] ysy[Nx ] ys[ -1 ]return x y
@utils.arg 'snapshot' metavar '<snapshot>' help 'IDofthesnapshot.' @utils.arg 'display_name' nargs '?' metavar '<display-name>' help 'Newdisplay-nameforthesnapshot.' @utils.arg '--display-description' metavar '<display-description>' help 'Optionalsnapshotdescription. Default None ' default None @utils.service_type 'monitor' def do_snapshot_rename cs args kwargs {}if args.display_name is not None kwargs['display_name'] args.display_nameif args.display_description is not None kwargs['display_description'] args.display_description_find_monitor_snapshot cs args.snapshot .update **kwargs
def test_activate_after_future_statements script ['#!/usr/bin/envpython' 'from__future__importwith_statement' 'from__future__importprint_function' 'print "Hello world!" ']assert virtualenv.relative_script script ['#!/usr/bin/envpython' 'from__future__importwith_statement' 'from__future__importprint_function' '' "importos;activate_this os.path.join os.path.dirname os.path.realpath __file__ 'activate_this.py' ;exec compile open activate_this .read activate_this 'exec' dict __file__ activate_this ;delos activate_this" '' 'print "Hello world!" ']
def test_enn_fit_sample enn EditedNearestNeighbours random_state RND_SEED X_resampled y_resampled enn.fit_sample X Y X_gt np.array [[ -0.10903849 -0.12085181 ] [0.01936241 0.17799828] [2.59928271 0.93323465] [1.92365863 0.82718767] [0.25738379 0.95564169] [0.78318102 2.59153329] [0.52726792 -0.38735648 ]] y_gt np.array [0 0 1 1 2 2 2] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def generate_histogram qual_fp output_dir score_min 25 verbose True qual_parser parse_qual_score if qual_fp.endswith '.gz' qual_lines gzip_open qual_fp else qual_lines open qual_fp 'U' qual_scores qual_parser qual_lines qual_bins bin_qual_scores qual_scores ave_bins std_dev_bins total_bases_bins suggested_trunc_pos get_qual_stats qual_bins score_min plot_qual_report ave_bins std_dev_bins total_bases_bins score_min output_dir write_qual_report ave_bins std_dev_bins total_bases_bins output_dir suggested_trunc_pos if verbose print 'Suggestednucleotidetruncationposition Noneifquality' + 'scoreaveragedidnotfallbelowtheminimumscoreparameter %s\n' % suggested_trunc_pos
def forecast_data year quarter if ct._check_input year quarter is True ct._write_head data _get_forecast_data year quarter 1 pd.DataFrame df pd.DataFrame data columns ct.FORECAST_COLS df['code'] df['code'].map lambda x str x .zfill 6 return df
def test_table_to_coord from ...table import Table Columnt Table t.add_column Column data [1 2 3] name u'ra' unit u.deg t.add_column Column data [4 5 6] name u'dec' unit u.deg c SkyCoord t[u'ra'] t[u'dec'] assert allclose c.ra.to u.deg [1 2 3] * u.deg assert allclose c.dec.to u.deg [4 5 6] * u.deg
def _fields_list_to_dict fields option_name if isinstance fields collections.Mapping return fieldsif isinstance fields collections.Sequence if not all isinstance field string_type for field in fields raise TypeError '%smustbealistofkeynames eachaninstanceof%s' % option_name string_type.__name__ return dict.fromkeys fields 1 raise TypeError '%smustbeamappingorlistofkeynames' % option_name
def _rep obj expand False out dict obj if isinstance obj beets.library.Item if app.config.get 'INCLUDE_PATHS' False out['path'] util.displayable_path out['path'] else del out['path']try out['size'] os.path.getsize util.syspath obj.path except OSError out['size'] 0return outelif isinstance obj beets.library.Album del out['artpath']if expand out['items'] [_rep item for item in obj.items ]return out
def dmp_ground_content f u K from sympy.polys.domains import QQif not u return dup_content f K if dmp_zero_p f u return K.zero cont v K.zero u - 1 if K QQ for c in f cont K.gcd cont dmp_ground_content c v K else for c in f cont K.gcd cont dmp_ground_content c v K if K.is_one cont breakreturn cont
def _check_pair minterm1 minterm2 index -1 for x i j in enumerate zip minterm1 minterm2 if i ! j if index -1 index xelse return -1 return index
def test_rechunk_blockshape new_shape new_chunks 10 10 4 3 new_blockdims normalize_chunks new_chunks new_shape old_chunks 4 4 2 3 3 3 1 a np.random.uniform 0 1 100 .reshape 10 10 x da.from_array a chunks old_chunks check1 rechunk x chunks new_chunks assert check1.chunks new_blockdims assert np.all check1.compute a
def is_64bit_capable addr_space x86_64_flag_addr addr_space.profile.get_symbol '_x86_64_flag' if x86_64_flag_addr x86_64_flag obj.Object 'int' offset x86_64_flag_addr vm addr_space ret x86_64_flag 1 else ret Truereturn ret
def get_afe_job_id tag match re.search '^ [0-9]+ -.+/.+$' tag if match return match.group 1 return ''
def s3_endpoint_for_region region region _fix_region region if not region or region _S3_REGION_WITH_NO_LOCATION_CONSTRAINT return _S3_REGIONLESS_ENDPOINTelse return _S3_REGION_ENDPOINT % {'region' region}
def GetServerParms host port try int port except port 119opt sabnzbd.cfg.ipv6_servers "...withthefollowingmeaningfor'opt' \nControltheuseofIPv6Usenetserveraddresses.Meaning \n0 don'tuse\n1 usewhenavailableandreachable DEFAULT \n2 forceusage whenSABnzbd'sdetectionfails \n"try ips socket.getaddrinfo host port 0 socket.SOCK_STREAM if opt 2 or opt 1 and sabnzbd.EXTERNAL_IPV6 or opt 1 and sabnzbd.cfg.load_balancing 2 return ipselse return [ip for ip in ips if ' ' not in ip[4][0] ]except if opt 2 or opt 1 and sabnzbd.EXTERNAL_IPV6 or opt 1 and sabnzbd.cfg.load_balancing 2 try return socket.getaddrinfo host port socket.AF_INET6 socket.SOCK_STREAM socket.IPPROTO_IP socket.AI_CANONNAME except passreturn None
def win_service_get name service WindowsService name None service._display_name service._query_config ['display_name']return service
@domain_constructor loss_target 0 def quadratic1 return {'loss' hp.uniform 'x' -5 5 - 3 ** 2 'status' base.STATUS_OK}
def timestamp_parameter timestamp allow_none True if timestamp is None if allow_none return Noneraise ValueError 'TimestampvaluecannotbeNone' if isinstance timestamp datetime.datetime return timestamp.isoformat + 'Z' if isinstance timestamp compat.basestring if not ISO_8601.match timestamp raise ValueError 'Invalidtimestamp %sisnotavalidISO-8601formatteddate' % timestamp return timestampraise ValueError 'Cannotaccepttype%sfortimestamp' % type timestamp
def switchOn sampleRate 48000 outputDevice None bufferSize None t0 core.getTime try global pyoimport pyoglobal haveMichaveMic Trueexcept ImportError msg 'Microphoneclassnotavailable needspyo;seehttp //code.google.com/p/pyo/'logging.error msg raise ImportError msg if pyo.serverCreated sound.pyoSndServer.setSamplingRate sampleRate else sound.init rate sampleRate if outputDevice sound.pyoSndServer.setOutputDevice outputDevice if bufferSize sound.pyoSndServer.setBufferSize bufferSize logging.exp '%s switchon %dhz took%.3fs' % __file__.strip '.py' sampleRate core.getTime - t0
def build_ems_log_message_0 driver_name app_version driver_mode dest 'clusternode' if driver_mode 'cluster' else '7modecontroller' ems_log _build_base_ems_log_message driver_name app_version ems_log['event-id'] '0'ems_log['event-description'] 'OpenStackCinderconnectedto%s' % dest return ems_log
def test_latex_to_png_dvipng_fails_when_no_cmd for command in ['latex' 'dvipng'] yield check_latex_to_png_dvipng_fails_when_no_cmd command
def expand_makefile_vars s vars while 1 m _findvar1_rx.search s or _findvar2_rx.search s if m beg end m.span s s[0 beg] + vars.get m.group 1 + s[end ] else breakreturn s
def GetTimeZoneNames key _winreg.OpenKeyEx _winreg.HKEY_LOCAL_MACHINE TimeZoneInfo.tzRegKey return _RegKeyEnumerator key
def register linter linter.register_checker ExceptionsChecker linter
def get_valid_os_versions os_versions []try for breed in get_valid_breeds os_versions + SIGNATURE_CACHE['breeds'][breed].keys except passreturn uniquify os_versions
def _set_symlink_ownership path user group try __salt__['file.lchown'] path user group except OSError passreturn _check_symlink_ownership path user group
def sync_renderers saltenv 'base' return salt.utils.extmods.sync __opts__ 'renderers' saltenv saltenv [0]
def valid_username user if not isinstance user string_types return Falseif len user > 32 return Falsereturn VALID_USERNAME.match user is not None
def _last_stack_str stack extract_stack for s in stack[ -1 ] if op.join 'vispy' 'gloo' 'buffer.py' not in __file__ breakreturn format_list [s] [0]
def _find_address_range addresses first last addresses[0]for ip in addresses[1 ] if ip._ip last._ip + 1 last ipelse breakreturn first last
def p_word_given_topic word topic beta 0.1 return topic_word_counts[topic][word] + beta / topic_counts[topic] + W * beta
def get_scanner hass config info config[DOMAIN]host info.get CONF_HOST username info.get CONF_USERNAME password info.get CONF_PASSWORD port info.get CONF_PORT scanner NetgearDeviceScanner host username password port return scanner if scanner.success_init else None
def plot_images_separately images fig plt.figure for j in xrange 1 7 ax fig.add_subplot 1 6 j ax.matshow images[ j - 1 ] cmap matplotlib.cm.binary plt.xticks np.array [] plt.yticks np.array [] plt.show
def subSGMLRefs s return re_sgmlrefsub _replSGMLRefs s
def get_bbox_header lbrt rotated False l b r t lbrtif rotated rotate u'%.2f%.2ftranslate\n90rotate' % l + r 0 else rotate u''bbox_info u'%%%%BoundingBox %d%d%d%d' % l b np.ceil r np.ceil t hires_bbox_info u'%%%%HiResBoundingBox %.6f%.6f%.6f%.6f' % l b r t return u'\n'.join [bbox_info hires_bbox_info] rotate
def bool_or_str *text def bool_or_value obj if obj in text return objelse return asbool obj return bool_or_value
@pytest.mark.parametrize u'text expected_tokens' [ u"l'avion" [u"l'" u'avion'] u"j'ai" [u"j'" u'ai'] ] def test_issue768 fr_tokenizer_w_infix text expected_tokens tokens fr_tokenizer_w_infix text assert len tokens 2 assert [t.text for t in tokens] expected_tokens
def add_service_protocol service protocol cmd '--permanent--service {0}--add-protocol {1}'.format service protocol return __firewall_cmd cmd
def make_friedman3 n_samples 100 noise 0.0 random_state None generator check_random_state random_state X generator.rand n_samples 4 X[ 0] * 100X[ 1] * 520 * np.pi X[ 1] + 40 * np.pi X[ 3] * 10X[ 3] + 1y np.arctan X[ 1] * X[ 2] - 1 / X[ 1] * X[ 3] / X[ 0] + noise * generator.randn n_samples return X y
def _check_second_range sec if np.any sec 60.0 warn IllegalSecondWarning sec u'Treatingas0sec +1min' elif sec is None passelif np.any sec < -60.0 or np.any sec > 60.0 raise IllegalSecondError sec
def init_mock_addon short_name user_settings None node_settings None import factoriesuser_settings user_settings or factories.MockAddonUserSettings node_settings node_settings or factories.MockAddonNodeSettings settings.ADDONS_REQUESTED.append short_name addon_config AddonConfig short_name short_name full_name short_name owners ['User' 'Node'] categories ['Storage'] user_settings_model user_settings node_settings_model node_settings models [user_settings node_settings] settings.ADDONS_AVAILABLE_DICT[addon_config.short_name] addon_configsettings.ADDONS_AVAILABLE.append addon_config return addon_config
def expect_failure_with_message message def test_decorator func def test_decorated self *args **kwargs self.assertRaisesRegexp segmentio.EventValidationError message func self *args **kwargs self.assert_no_events_emitted return test_decoratedreturn test_decorator
def test_pprint_nameless_col col table.Column [1.0 2.0] assert str col .startswith 'None'
def show_quickpanel captions entries show_cancel False if show_cancel Quickpanel CancelEntriesQuickpanelelse Quickpanel EntriesQuickpanelQuickpanel captions entries .show_quickpanel
def transfer_accept context transfer_id user_id project_id return IMPL.transfer_accept context transfer_id user_id project_id
def null_formatter view value return Markup '<i>NULL</i>'
def change_password username password _xml '<RIBCLVERSION "2.0">\n<LOGINUSER_LOGIN "adminname"PASSWORD "password">\n<USER_INFOMODE "write">\n<MOD_USERUSER_LOGIN "{0}">\n<PASSWORDvalue "{1}"/>\n</MOD_USER>\n</USER_INFO>\n</LOGIN>\n</RIBCL>'.format username password return __execute_cmd 'Change_password' _xml
def _image_tag_delete_all context image_id delete_time None session None tags_updated_count _image_child_entry_delete_all models.ImageTag image_id delete_time session return tags_updated_count
def sanitize_name raw_value value force_text raw_value value unicodedata.normalize 'NFKC' value value re.sub '[^\\w\\s._-]' '' value flags re.U .strip return mark_safe re.sub '[-\\s]+' '-' value flags re.U
def _infer_fill_value val if not is_list_like val val [val]val np.array val copy False if is_datetimelike val return np.array 'NaT' dtype val.dtype elif is_object_dtype val.dtype dtype lib.infer_dtype _ensure_object val if dtype in ['datetime' 'datetime64'] return np.array 'NaT' dtype _NS_DTYPE elif dtype in ['timedelta' 'timedelta64'] return np.array 'NaT' dtype _TD_DTYPE return np.nan
def EmailCheck email if not EMAIL_RE.match email raise ValueError _ 'Notavalidemail %s' % email return email
def _CheckFacetDepth depth if depth is None return Noneelse return _CheckInteger depth 'depth' zero_ok False upper_bound MAXIMUM_DEPTH_FOR_FACETED_SEARCH
def post_save_user_group instance raw created **kwargs from cms.utils.permissions import get_current_usercreator get_current_user if not creator or not created or creator.is_anonymous returnpage_user PageUserGroup group_ptr_id instance.pk created_by creator page_user.__dict__.update instance.__dict__ page_user.save
def disable_module module if is_module_enabled module run_as_root 'a2dismod%s' % module
def test_monitor_based_save_best_cv handle filename tempfile.mkstemp skip_if_no_sklearn trainer yaml_parse.load test_yaml_monitor_based_save_best_cv % {'save_path' filename} trainer.main_loop os.remove filename
@gof.local_optimizer [sparse.AddSD] def local_addsd_ccode node if isinstance node.op sparse.AddSD and theano.config.cxx new_node AddSD_ccode format node.inputs[0].type.format *node.inputs return [new_node]return False
@register.simple_tag takes_context True def no_params_with_context context return 'no_params_with_context-Expectedresult contextvalue %s ' % context['value']
def sm_flavor_delete context sm_flavor_id return IMPL.sm_flavor_delete context sm_flavor_id
def OSXGetRawDevice path device_map GetMountpoints path utils.SmartUnicode path mount_point path utils.NormalizePath path '/' result rdf_paths.PathSpec pathtype rdf_paths.PathSpec.PathType.OS while mount_point try result.path fs_type device_map[mount_point]if fs_type in ['ext2' 'ext3' 'ext4' 'vfat' 'ntfs' 'Apple_HFS' 'hfs' 'msdos'] result.pathtype rdf_paths.PathSpec.PathType.OSelse result.pathtype rdf_paths.PathSpec.PathType.UNSETpath utils.NormalizePath path[len mount_point ] return result path except KeyError mount_point os.path.dirname mount_point
def add_source zone source permanent True if source in get_sources zone permanent log.info 'Sourceisalreadyboundtozone.' cmd '--zone {0}--add-source {1}'.format zone source if permanent cmd + '--permanent'return __firewall_cmd cmd
def user_has_language_set request if hasattr request u'session' and request.session.get LANGUAGE_SESSION_KEY is not None return Trueif LANGUAGE_COOKIE_NAME in request.COOKIES return Truereturn False
def norm_l21_tf Z shape n_orient if Z.shape[0] Z2 Z.reshape *shape l21_norm np.sqrt stft_norm2 Z2 .reshape -1 n_orient .sum axis 1 l21_norm l21_norm.sum else l21_norm 0.0return l21_norm
def _AddPropertiesForExtensions descriptor cls extension_dict descriptor.extensions_by_namefor extension_name extension_field in extension_dict.iteritems constant_name extension_name.upper + '_FIELD_NUMBER' setattr cls constant_name extension_field.number
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def format_freshdesk_ticket_creation_message ticket cleaned_description convert_html_to_markdown ticket.description content '%s<%s>created[ticket#%s] %s \n\n' % ticket.requester_name ticket.requester_email ticket.id ticket.url content + '~~~quote\n%s\n~~~\n\n' % cleaned_description content + 'Type **%s**\nPriority **%s**\nStatus **%s**' % ticket.type ticket.priority ticket.status return content
def base64_len s groups_of_3 leftover divmod len s 3 n groups_of_3 * 4 if leftover n + 4return n
@run_oncedef _load_sqlalchemy_models keystone_root os.path.normpath os.path.join os.path.dirname __file__ '..' '..' '..' for root dirs files in os.walk keystone_root root root[len keystone_root ]if root.endswith 'backends' and 'sql.py' in files module_root 'keystone.%s' % root.replace os.sep '.' .lstrip '.' module_components module_root.split '.' module_without_backends ''for x in range 0 len module_components - 1 module_without_backends + module_components[x] + '.' module_without_backends module_without_backends.rstrip '.' module_name module_root + '.sql' __import__ module_name
def validate_location_uri location if not location raise exception.BadStoreUri _ 'Invalidlocation %s' % location elif location.startswith 'http //' 'https //' return locationelif location.startswith 'file ///' 'filesystem ///' msg _ 'Filebasedimportsarenotallowed.Pleaseuseanon-localsourceofimagedata.' raise exception.BadStoreUri msg else supported ['http']msg _ 'Thegivenuriisnotvalid.Pleasespecifyavalidurifromthefollowinglistofsupporteduri% supported s' % {'supported' supported} raise urllib.error.URLError msg
def build_fragments_list boot_info res []segment_run_table boot_info[u'segments'][0]segment_run_entry segment_run_table[u'segment_run'][0]n_frags segment_run_entry[1]fragment_run_entry_table boot_info[u'fragments'][0][u'fragments']first_frag_number fragment_run_entry_table[0][u'first']for i frag_number in zip range 1 n_frags + 1 itertools.count first_frag_number res.append 1 frag_number return res
def staff_level mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepoutput s3_rest_controller return output
def _typecheck name value *types if not types types unicode if not isinstance value types raise TypeError 'expected{}for{} got{}'.format 'or'.join [t.__name__ for t in types] name repr value return value
def _map_rect_to_scene self rect return self.sceneTransform .mapRect rect
def gen_column_names n col_names list DEFAULT_COLUMN_NAMES if n < len col_names return list take n col_names else n_left n - len col_names labels [''.join item for item in take n_left itertools.product DEFAULT_COLUMN_NAMES DEFAULT_COLUMN_NAMES ]col_names.extend labels return col_names
def carray ptr shape dtype None from .typing.ctypes_utils import from_ctypestry ptr ptr._as_parameter_except AttributeError passif dtype is not None dtype np.dtype dtype if isinstance ptr ctypes.c_void_p if dtype is None raise TypeError 'explicitdtyperequiredforvoid*argument' p ptrelif isinstance ptr ctypes._Pointer ptrty from_ctypes ptr.__class__ assert isinstance ptrty types.CPointer ptr_dtype as_dtype ptrty.dtype if dtype is not None and dtype ! ptr_dtype raise TypeError "mismatchingdtype'%s'forpointer%s" % dtype ptr dtype ptr_dtypep ctypes.cast ptr ctypes.c_void_p else raise TypeError 'expectedactypespointer got%r' % ptr nbytes dtype.itemsize * np.product shape dtype np.intp return _get_array_from_ptr p nbytes dtype .reshape shape
def fix_win_sys_argv encoding global _SYS_ARGV_PROCESSEDif _SYS_ARGV_PROCESSED return Falsefrom ctypes import byref c_int POINTER windll WINFUNCTYPEfrom ctypes.wintypes import LPCWSTR LPWSTRGetCommandLineW WINFUNCTYPE LPWSTR 'GetCommandLineW' windll.kernel32 CommandLineToArgvW WINFUNCTYPE POINTER LPWSTR LPCWSTR POINTER c_int 'CommandLineToArgvW' windll.shell32 argc c_int 0 argv_unicode CommandLineToArgvW GetCommandLineW byref argc argv [argv_unicode[i].encode encoding 'replace' for i in xrange 0 argc.value ]if not hasattr sys 'frozen' argv argv[1 ]while len argv > 0 arg argv[0]if not arg.startswith u'-' or arg u'-' breakargv argv[1 ]if arg u'-m' breakif arg u'-c' argv[0] u'-c'breaksys.argv argv_SYS_ARGV_PROCESSED Truereturn True
def CheckForQuestionPending task vm task.info.entityif vm is not None and isinstance vm vim.VirtualMachine qst vm.runtime.questionif qst is not None raise TaskBlocked 'Taskblocked UserInterventionrequired'
def wait_for_unit_state reactor docker_client unit_name expected_activation_states def is_in_states units for unit in units if unit.name unit_name if unit.activation_state in expected_activation_states return Truedef check_if_in_states responded docker_client.list responded.addCallback is_in_states return respondedreturn loop_until reactor check_if_in_states
def check_bitdepth_colortype bitdepth colortype if bitdepth not in 1 2 4 8 16 raise FormatError 'invalidbitdepth%d' % bitdepth if colortype not in 0 2 3 4 6 raise FormatError 'invalidcolourtype%d' % colortype if colortype & 1 and bitdepth > 8 raise FormatError 'Indexedimages colourtype%d cannothavebitdepth>8 bitdepth%d .Seehttp //www.w3.org/TR/2003/REC-PNG-20031110/#table111.' % bitdepth colortype if bitdepth < 8 and colortype not in 0 3 raise FormatError 'Illegalcombinationofbitdepth %d andcolourtype %d .Seehttp //www.w3.org/TR/2003/REC-PNG-20031110/#table111.' % bitdepth colortype
def load_confs conf_source None if conf_source is None conf_source _configs_from_dir get_desktop_root 'conf' conf configobj.ConfigObj for in_conf in conf_source conf.merge in_conf return conf
def installed name enabled True ret {'name' name 'result' True 'comment' '' 'changes' {}}is_installed __salt__['assistive.installed'] name if is_installed is_enabled __salt__['assistive.enabled'] name if enabled ! is_enabled __salt__['assistive.enable'] name enabled ret['comment'] 'Updatedenableto{0}'.format enabled else ret['comment'] 'Alreadyinthecorrectstate'else __salt__['assistive.install'] name enabled ret['comment'] 'Installed{0}intotheassistiveaccesspanel'.format name return ret
def _scale_normalize X X make_nonnegative X row_diag np.asarray 1.0 / np.sqrt X.sum axis 1 .squeeze col_diag np.asarray 1.0 / np.sqrt X.sum axis 0 .squeeze row_diag np.where np.isnan row_diag 0 row_diag col_diag np.where np.isnan col_diag 0 col_diag if issparse X n_rows n_cols X.shaper dia_matrix row_diag [0] shape n_rows n_rows c dia_matrix col_diag [0] shape n_cols n_cols an r * X * c else an row_diag[ np.newaxis] * X * col_diag return an row_diag col_diag
def _add_p_tags raw_body return '<p>{raw_body}</p>'.format raw_body raw_body
def is_parsed_result_successful parsed_result return parsed_result['ResponseMetadata']['HTTPStatusCode'] < 300
def GetLocalTimeZone tzRegKey 'SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation'key _winreg.OpenKeyEx _winreg.HKEY_LOCAL_MACHINE tzRegKey local _RegKeyDict key fixStandardTime local['StandardName'] local['DaylightName'] and local['StandardBias'] local['DaylightBias'] keyName ['StandardName' 'TimeZoneKeyName'][ sys.getwindowsversion > 6 ]standardName local[keyName]standardName __TimeZoneKeyNameWorkaround standardName return TimeZoneInfo standardName fixStandardTime
def _filter_domain_id_from_parents domain_id tree new_tree Noneif tree parent children next iter tree.items if parent ! domain_id new_tree {parent _filter_domain_id_from_parents domain_id children }return new_tree
def all_not_none iterable for element in iterable if element is None return Falsereturn True
def test_call_accepts_func_single_pos_passes @accepts int def foo int_1 passt time.time for i in range 0 10000 foo 5 return time.time - t
def _interfaces ifaddrs ifaddrs_p if getifaddrs pointer ifaddrs < 0 raise OSError results []try while ifaddrs if ifaddrs[0].ifa_addr family ifaddrs[0].ifa_addr[0].sin_familyif family AF_INET addr cast ifaddrs[0].ifa_addr POINTER sockaddr_in elif family AF_INET6 addr cast ifaddrs[0].ifa_addr POINTER sockaddr_in6 else addr Noneif addr packed ''.join map chr addr[0].sin_addr.in_addr[ ] packed _maybeCleanupScopeIndex family packed results.append ifaddrs[0].ifa_name family inet_ntop family packed ifaddrs ifaddrs[0].ifa_nextfinally freeifaddrs ifaddrs return results
def _find root thread_count 10 relative False follow False threads []results {}errors {}done threading.Event work queue.Queue work.put os.path.abspath root [] if not relative root Noneargs root follow done work results errors for i in range thread_count t threading.Thread target _find_worker args args t.daemon Truet.start threads.append t work.join done.set for t in threads t.join return results errors
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def test_instantiation_FileLink fl display.FileLink 'example.txt'
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def remove_header headers name name name.lower i 0result Nonewhile i < len headers if headers[i][0].lower name result headers[i][1]del headers[i]continuei + 1return result
def get_yaml_basepath if _handler_dir is None set_builtins_dir DEFAULT_DIR return _handler_dir
def resource_remove_path path if path not in resource_paths returnLogger.debug 'Resource remove<%s>frompathlist' % path resource_paths.remove path
def libvlc_set_app_id p_instance id version icon f _Cfunctions.get 'libvlc_set_app_id' None or _Cfunction 'libvlc_set_app_id' 1 1 1 1 None None Instance ctypes.c_char_p ctypes.c_char_p ctypes.c_char_p return f p_instance id version icon
def _number_desc_for_type metadata num_type if num_type PhoneNumberType.PREMIUM_RATE return metadata.premium_rateelif num_type PhoneNumberType.TOLL_FREE return metadata.toll_freeelif num_type PhoneNumberType.MOBILE return metadata.mobileelif num_type PhoneNumberType.FIXED_LINE or num_type PhoneNumberType.FIXED_LINE_OR_MOBILE return metadata.fixed_lineelif num_type PhoneNumberType.SHARED_COST return metadata.shared_costelif num_type PhoneNumberType.VOIP return metadata.voipelif num_type PhoneNumberType.PERSONAL_NUMBER return metadata.personal_numberelif num_type PhoneNumberType.PAGER return metadata.pagerelif num_type PhoneNumberType.UAN return metadata.uanelif num_type PhoneNumberType.VOICEMAIL return metadata.voicemailelse return metadata.general_desc
def _safeFormat fmtString fmtDict try text fmtString % fmtDict except KeyboardInterrupt raiseexcept try text 'Invalidformatstringorunformattableobjectinlogmessage %r %s' % fmtString fmtDict except try text 'UNFORMATTABLEOBJECTWRITTENTOLOGwithfmt%r MESSAGELOST' % fmtString except text 'PATHOLOGICALERRORINBOTHFORMATSTRINGANDMESSAGEDETAILS MESSAGELOST'if _PY3 if isinstance text bytes text text.decode 'utf-8' elif isinstance text unicode text text.encode 'utf-8' return text
@not_implemented_for 'undirected' @not_implemented_for 'multigraph' def is_tournament G return all v in G[u] ^ u in G[v] for u v in combinations G 2 and G.number_of_selfloops 0
def cache_translations objects languages None meta None if not objects return objectslanguages set languages or if meta is None meta objects[0]._parler_meta.rootxlate_model meta.modelobject_map dict object.pk object for object in objects languages.update set object._current_language for object in objects master_ids object_map.keys for master_ids in batch master_ids 950 for translation in xlate_model.objects.filter master_id__in master_ids language_code__in languages master object_map[translation.master_id]master._translations_cache[xlate_model][translation.language_code] translationsetattr translation translation.__class__.master.cache_name master return objects
def sanityTest vm vm.sendline 'sudo-nmn--testpingall' if vm.expect ['0%dropped' pexpect.TIMEOUT] timeout 45 0 log '*SanitycheckOK' else log '*SanitycheckFAILED' log '*Sanitycheckoutput ' log vm.before
def get_num_actions env gym.make game num_actions env.action_space.nreturn num_actions
def _if_none_match_passes target_etag etags if not target_etag return Trueelif etags ['*'] return Falseelse target_etag target_etag.strip 'W/' etags etag.strip 'W/' for etag in etags return target_etag not in etags
def parse_keywords strings [] keywords {}for string in strings if ' ' in string funcname indices string.split ' ' else funcname indices string None if funcname not in keywords if indices inds []for x in indices.split ' ' if x[ -1 ] 'c' inds.append int x[ -1 ] 'c' else inds.append int x indices tuple inds keywords[funcname] indicesreturn keywords
def add_defaults var fun case_sensitive False var_items set DEFAULT_VARIABLES fun_items set DEFAULT_FUNCTIONS var_items.update var fun_items.update fun if not case_sensitive var_items set k.lower for k in var_items fun_items set k.lower for k in fun_items return var_items fun_items
def _resumeOS value hashDBRetrieve HASHDB_KEYS.OS if not value returnos valueif os and os ! 'None' infoMsg "resumingback-endDBMSoperatingsystem'%s'" % os logger.info infoMsg if conf.os and conf.os.lower ! os.lower message "youprovided'%s'asback-endDBMSoperating" % conf.os message + 'system butfromapastscaninformationonthe'message + 'targetURLsqlmapassumestheback-endDBMS'message + 'operatingsystemis%s.' % os message + 'Doyoureallywanttoforcetheback-endDBMS'message + 'OSvalue?[y/N]'test readInput message default 'N' if not test or test[0] in 'n' 'N' conf.os oselse conf.os osBackend.setOs conf.os
def check_serialize msg json.dumps msg
def UnpackIntSet data if len data > 13 and data[ 4] '\xff\xff\xff\xff' return set bitmask_to_intlist zlib.decompress data[4 ] else return set struct.unpack '<' + 'I' * len data // 4 data
def get_project_root_name root Path settings.PROJECT_ROOT if root.name '' root root.parentreturn root.name
def get_captcha_challenge http_body captcha_base_url 'http //www.google.com/accounts/' contains_captcha_challenge Falsecaptcha_parameters {}for response_line in http_body.splitlines if response_line.startswith 'Error CaptchaRequired' contains_captcha_challenge Trueelif response_line.startswith 'CaptchaToken ' captcha_parameters['token'] response_line[13 ]elif response_line.startswith 'CaptchaUrl ' captcha_parameters['url'] '%s%s' % captcha_base_url response_line[11 ] if contains_captcha_challenge return captcha_parameterselse return None
def _check_valid_version npm_version distutils.version.LooseVersion salt.modules.cmdmod.run 'npm--version' output_loglevel 'quiet' valid_version distutils.version.LooseVersion '1.2' if npm_version < valid_version raise CommandExecutionError "'npm'isnotrecentenough {0}<{1} .PleaseUpgrade.".format npm_version valid_version
def get_setup_section app module label icon config get_config app module for section in config if section.get u'label' _ u'Setup' return {u'label' label u'icon' icon u'items' section[u'items']}
def is_distributed_router router try requested_router_type router.extra_attributes.distributedexcept AttributeError requested_router_type router.get 'distributed' if validators.is_attr_set requested_router_type return requested_router_typereturn cfg.CONF.router_distributed
def check_password password encoded setter None preferred u'default' if not password or not is_password_usable encoded return Falsepreferred get_hasher preferred hasher identify_hasher encoded must_update hasher.algorithm ! preferred.algorithm is_correct hasher.verify password encoded if setter and is_correct and must_update setter password return is_correct
def _VarintEncoder local_chr chrdef EncodeVarint write value bits value & 127 value >> 7while value write local_chr 128 | bits bits value & 127 value >> 7return write local_chr bits return EncodeVarint
def test_coffee data.coffee
def set_attributes name attributes region None key None keyid None profile None ret Trueconn _get_conn region region key key keyid keyid profile profile queue_obj conn.get_queue name if not queue_obj log.error 'Queue{0}doesnotexist.'.format name ret Falseif isinstance attributes string_types attributes json.loads attributes for attr val in six.iteritems attributes attr_set queue_obj.set_attribute attr val if not attr_set msg 'Failedtosetattribute{0} {1}onqueue{2}'log.error msg.format attr val name ret Falseelse msg 'Setattribute{0} {1}onqueue{2}'log.info msg.format attr val name return ret
def remote_docker client_ip docker_host *args return remote_command client_ip 'DOCKER_TLS_VERIFY 1' 'DOCKER_HOST {}'.format docker_host 'docker' + args
@service DOMAIN SERVICE_FLASH def flash_service hass call if not TARGET_ID returnif core.is_on hass TARGET_ID core.turn_off hass TARGET_ID time.sleep 10 core.turn_on hass TARGET_ID else core.turn_on hass TARGET_ID time.sleep 10 core.turn_off hass TARGET_ID
def validate_auth_mechanism_properties option value value validate_string option value props {}for opt in value.split ' ' try key val opt.split ' ' except ValueError raise ValueError 'authmechanismpropertiesmustbekey valuepairslikeSERVICE_NAME mongodb not%s.' % opt if key not in _MECHANISM_PROPS raise ValueError '%sisnotasupportedauthmechanismproperty.Mustbeoneof%s.' % key tuple _MECHANISM_PROPS if key 'CANONICALIZE_HOST_NAME' props[key] validate_boolean_or_string key val else props[key] valreturn props
def loopbackTLSConnection trustRoot privateKeyFile chainedCertFile None class ContextFactory object def getContext self '\nCreateacontextfortheserversideoftheconnection.\n\n@return anSSLcontextusingacertificateandkey.\n@rtype C{OpenSSL.SSL.Context}\n'ctx SSL.Context SSL.TLSv1_METHOD if chainedCertFile is not None ctx.use_certificate_chain_file chainedCertFile ctx.use_privatekey_file privateKeyFile ctx.check_privatekey return ctxserverOpts ContextFactory clientOpts sslverify.OpenSSLCertificateOptions trustRoot trustRoot return _loopbackTLSConnection serverOpts clientOpts
def longTest testMethod def newTestMethod *args **kwargs if TestOptionParser.__long__ is None raise Exception 'TestOptionParsermustbeusedinordertouse@longTestdecorator.' if TestOptionParser.__long__ return testMethod *args **kwargs else msg 'Skippinglongtest %s' % testMethod.__name__ return unittest.skip msg testMethod *args **kwargs return newTestMethod
def setGridLogger setLoggerClass GridLogger
def query_tasks session if session.config['singletons'] for item in session.lib.items session.query task SingletonImportTask None item for task in task.handle_created session yield task else for album in session.lib.albums session.query log.debug u'yieldingalbum{0} {1}-{2}' album.id album.albumartist album.album items list album.items for item in items item.id Noneitem.album_id Nonetask ImportTask None [album.item_dir ] items for task in task.handle_created session yield task
def random_ascii length 20 ascii_only False return _join_chars string.ascii_letters length
@register.simple_tag takes_context False def explicit_no_context arg return 'explicit_no_context-Expectedresult %s' % arg
def setlocale category locale None if locale and type locale is not type '' locale normalize _build_localename locale return _setlocale category locale
def makeStack element layers []for child in element.childNodes if child.nodeType child.ELEMENT_NODE if child.tagName 'stack' stack makeStack child layers.append stack elif child.tagName 'layer' layer makeLayer child layers.append layer else raise Exception 'Unknownelement"%s"' % child.tagName print >>sys.stderr 'Makingastackwith%dlayers' % len layers return Stack layers
def is_ratelimited request name rate method ['POST'] skip_if lambda r False if skip_if request or request.user.has_perm 'sumo.bypass_ratelimit' request.limited Falseelse ratelimit.helpers.is_ratelimited request increment True ip False rate rate keys user_or_ip name if request.limited if hasattr request 'user' and request.user.is_authenticated key 'user"{}"'.format request.user.username else ip request.META.get 'HTTP_X_CLUSTER_CLIENT_IP' request.META['REMOTE_ADDR'] key 'anonymoususer {} '.format ip Record.objects.info 'sumo.ratelimit' '{key}hittheratelimitfor{name}' key key name name return request.limited
def _prepare values clip True out None if clip return np.clip values 0.0 1.0 out out elif out is None return np.array values copy True else out[ ] np.asarray values return out
def code_gen blocks decl ''head ''tail ''for block in blocks decl + block.declarehead head + '\n{\n%s' % block.behavior tail '%s\n}\n' % block.cleanup + tail return decl + head + tail
def setPrivacyList disp list resp disp.SendAndWaitForResponse Iq 'set' NS_PRIVACY payload [list] if isResultNode resp return 1
def tensorproduct *args if len args 0 return S.Oneif len args 1 return _arrayfy args[0] if len args > 2 return tensorproduct tensorproduct args[0] args[1] *args[2 ] a b map _arrayfy args if not isinstance a NDimArray or not isinstance b NDimArray return a * b al list a bl list b product_list [ i * j for i in al for j in bl]return ImmutableDenseNDimArray product_list a.shape + b.shape
def wassuccessful_patch result return make_instancemethod TextTestResult.wasSuccessful result
def staff_org_site_json table s3db.hrm_human_resourceotable s3db.org_organisationquery table.person_id request.args[0] & table.organisation_id otable.id records db query .select table.site_id otable.id otable.name response.headers['Content-Type'] 'application/json'return records.json
def _filter_documents request queryset flatten True type_filters request.GET.getlist 'type' None sort request.GET.get 'sort' '-last_modified' search_text request.GET.get 'text' None return __filter_documents type_filters sort search_text queryset flatten
def robust_scale X axis 0 with_centering True with_scaling True quantile_range 25.0 75.0 copy True s RobustScaler with_centering with_centering with_scaling with_scaling quantile_range quantile_range copy copy if axis 0 return s.fit_transform X else return s.fit_transform X.T .T
def certificate_downloadable_status student course_key current_status certificate_status_for_student student course_key response_data {'is_downloadable' False 'is_generating' True if current_status['status'] in [CertificateStatuses.generating CertificateStatuses.error] else False 'is_unverified' True if current_status['status'] CertificateStatuses.unverified else False 'download_url' None 'uuid' None}if current_status['status'] CertificateStatuses.downloadable response_data['is_downloadable'] Trueresponse_data['download_url'] current_status['download_url'] or get_certificate_url student.id course_key response_data['uuid'] current_status['uuid']return response_data
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_resize_revert cs args _find_server cs args.server .revert_resize
def get_mcp_version driver location location driver.ex_get_location_by_id location if 'MCP2.0' in location.name return '2.0'return '1.0'
@_noconds_ True def _hankel_transform f r k nu name simplify True from sympy import besseljF integrate f * besselj nu k * r * r r 0 oo if not F.has Integral return _simplify F simplify True if not F.is_Piecewise raise IntegralTransformError name f 'couldnotcomputeintegral' F cond F.args[0]if F.has Integral raise IntegralTransformError name f 'integralinunexpectedform' return _simplify F simplify cond
def _instantiate_proxy_tuple proxy bindings None if proxy in bindings return bindings[proxy]else if proxy.callable do_not_recurse obj proxy.keywords['value']else if len proxy.positionals > 0 raise NotImplementedError 'positionalargumentsnotyetsupportedinproxyinstantiation' kwargs dict k _instantiate v bindings for k v in six.iteritems proxy.keywords obj checked_call proxy.callable kwargs try obj.yaml_src proxy.yaml_srcexcept AttributeError passbindings[proxy] objreturn bindings[proxy]
def IsBlockInNameSpace nesting_state is_forward_declaration if is_forward_declaration return len nesting_state.stack > 1 and isinstance nesting_state.stack[ -1 ] _NamespaceInfo return len nesting_state.stack > 1 and nesting_state.stack[ -1 ].check_namespace_indentation and isinstance nesting_state.stack[ -2 ] _NamespaceInfo
def getFaces geometryOutput faces []addFaces geometryOutput faces return faces
def test_elemwise4 shape 3 4 a tcn.shared_constructor theano._asarray numpy.random.rand *shape dtype 'float32' 'a' b tensor.fvector c tensor.fvector f pfunc [b c] [] updates [ a a + b.dimshuffle 'x' 0 * c.dimshuffle 0 'x' ] mode mode_with_gpu has_elemwise Falsefor i node in enumerate f.maker.fgraph.toposort has_elemwise has_elemwise or isinstance node.op tensor.Elemwise assert not has_elemwise f theano._asarray numpy.random.rand 4 dtype 'float32' theano._asarray numpy.random.rand 3 dtype 'float32'
def user_is_admin user_db is_system_admin user_is_system_admin user_db user_db if is_system_admin return Trueis_admin user_has_role user_db user_db role SystemRole.ADMIN if is_admin return Truereturn False
@flake8extdef check_builtins_gettext logical_line tokens filename lines noqa if noqa returnmodulename os.path.normpath filename .split '/' [0]if '%s/tests' % modulename in filename returnif os.path.basename filename in 'i18n.py' '_i18n.py' returntoken_values [t[1] for t in tokens]i18n_wrapper '%s._i18n' % modulename if '_' in token_values i18n_import_line_found Falsefor line in lines split_line [elm.rstrip ' ' for elm in line.split ]if len split_line > 1 and split_line[0] 'from' and split_line[1] i18n_wrapper and '_' in split_line i18n_import_line_found Truebreakif not i18n_import_line_found msg 'N341 _frompythonbuiltinsmoduleisused.Use_from%sinstead.' % i18n_wrapper yield 0 msg
def add_rule name localport protocol 'tcp' action 'allow' dir 'in' ret {'name' name 'result' True 'changes' {} 'comment' ''}commit Falsecurrent_rules __salt__['firewall.get_rule'] name if not current_rules commit Trueret['changes'] {'newrule' name}if __opts__['test'] ret['result'] not commit or None return retif commit ret['result'] __salt__['firewall.add_rule'] name localport protocol action dir if not ret['result'] ret['comment'] 'Couldnotaddrule'else ret['comment'] 'Arulewiththatnamealreadyexists'return ret
def insertion_sort collection for index in range 1 len collection while 0 < index and collection[index] < collection[ index - 1 ] collection[index] collection[ index - 1 ] collection[ index - 1 ] collection[index] index - 1return collection
def _instance_name instance return getattr instance 'OS-EXT-SRV-ATTR instance_name' None
def _clip_warp_output input_image output_image order mode cval clip if clip and order ! 0 min_val input_image.min max_val input_image.max preserve_cval mode 'constant' and not min_val < cval < max_val if preserve_cval cval_mask output_image cval np.clip output_image min_val max_val out output_image if preserve_cval output_image[cval_mask] cval
def assert_error response status_code headers None **kwargs headers headers or {} def error_cmp response_body body return isinstance response_body dict and set response_body.keys set list body.keys + ['error'] and all response_body.get k v for k v in body.items assert_json_response response status_code kwargs headers error_cmp
def get_valid_domains domains valid_domains []for domain in domains try valid_domains.append util.enforce_domain_sanity domain except errors.ConfigurationError continuereturn valid_domains
def remove_prefix string prefix if string.startswith prefix return string[len prefix ]else return string
def bbox_to_array arr label 0 max_bboxes 64 bbox_width 16 arr pad_bbox arr max_bboxes bbox_width return arr[np.newaxis ]
def createEncoder encoder MultiEncoder encoder.addMultipleEncoders {'consumption' {'fieldname' u'consumption' 'type' 'ScalarEncoder' 'name' u'consumption' 'minval' 0.0 'maxval' 100.0 'clipInput' True 'w' 21 'n' 500} 'timestamp_timeOfDay' {'fieldname' u'timestamp' 'type' 'DateEncoder' 'name' u'timestamp_timeOfDay' 'timeOfDay' 21 9.5 }} return encoder
def freeze_includes import pyimport _pytestresult list _iter_all_modules py result + list _iter_all_modules _pytest return result
def isbuiltin object return isinstance object types.BuiltinFunctionType
def detect stream try json.loads stream return Trueexcept ValueError return False
def get_profile_model if not getattr settings u'ACCOUNTS_PROFILE_MODEL' None raise ProfileNotConfiguredtry return apps.get_model settings.ACCOUNTS_PROFILE_MODEL except ValueError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELmustbeoftheform'app_label.model_name'" except LookupError raise ImproperlyConfigured u"ACCOUNTS_PROFILE_MODELreferstomodel'%s'thathasnotbeeninstalled" % settings.ACCOUNTS_PROFILE_MODEL
def notify_merge_failure subproject error status subscriptions Profile.objects.subscribed_merge_failure subproject.project users set mails []for subscription in subscriptions mails.append subscription.notify_merge_failure subproject error status users.add subscription.user_id for owner in subproject.project.owners.all mails.append owner.profile.notify_merge_failure subproject error status mails.append get_notification_email u'en' u'ADMINS' u'merge_failure' subproject {u'subproject' subproject u'status' status u'error' error} send_mails mails
def betweenness_sequence creation_sequence normalized True cs creation_sequenceseq []lastchar 'd'dr float cs.count 'd' irun 0drun 0dlast 0.0for i c in enumerate cs if c 'd' b dlast + irun - 1 * irun / dr + 2 * irun * i - drun - irun / dr drun + 1else if lastchar 'd' dlast bdr - drundrun 0irun 0b 0irun + 1seq.append float b lastchar cif normalized order len cs scale 1.0 / order - 1 * order - 2 seq [ s * scale for s in seq]return seq
def urlsafe_b64decode s return b64decode s '-_'
def test_iht_sample_wrong_X iht InstanceHardnessThreshold random_state RND_SEED iht.fit X Y assert_raises RuntimeError iht.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def get_patterns_for_title path title app apphook_pool.get_apphook title.page.application_urls url_patterns []for pattern_list in get_app_urls app.get_urls title.page title.language if path and not path.endswith '/' path + '/'page_id title.page.idurl_patterns + recurse_patterns path pattern_list page_id return url_patterns
def add_certificate_exception course_key student certificate_exception if len CertificateWhitelist.get_certificate_white_list course_key student > 0 raise ValueError _ 'Student username/email {user} alreadyincertificateexceptionlist.' .format user student.username certificate_white_list __ CertificateWhitelist.objects.get_or_create user student course_id course_key defaults {'whitelist' True 'notes' certificate_exception.get 'notes' '' } generated_certificate GeneratedCertificate.eligible_certificates.filter user student course_id course_key status CertificateStatuses.downloadable .first exception dict {'id' certificate_white_list.id 'user_email' student.email 'user_name' student.username 'user_id' student.id 'certificate_generated' generated_certificate and generated_certificate.created_date.strftime '%B%d %Y' 'created' certificate_white_list.created.strftime '%A %B%d %Y' } return exception
def _add_var var value makeconf _get_makeconf layman 'source/var/lib/layman/make.conf'fullvar '{0} "{1}"'.format var value if __salt__['file.contains'] makeconf layman cmd ['sed' '-i' '/{0}/i\\{1}'.format layman.replace '/' '\\/' fullvar makeconf]__salt__['cmd.run'] cmd else __salt__['file.append'] makeconf fullvar
def _minimize_dogleg fun x0 args jac None hess None **trust_region_options if jac is None raise ValueError 'Jacobianisrequiredfordoglegminimization' if hess is None raise ValueError 'Hessianisrequiredfordoglegminimization' return _minimize_trust_region fun x0 args args jac jac hess hess subproblem DoglegSubproblem **trust_region_options
def copy_to_master registry xml_parent data cm XML.SubElement xml_parent 'com.michelin.cio.hudson.plugins.copytoslave.CopyToMasterNotifier' cm.set 'plugin' 'copy-to-slave' XML.SubElement cm 'includes' .text ' '.join data.get 'includes' [''] XML.SubElement cm 'excludes' .text ' '.join data.get 'excludes' [''] mappings [ 'run-after-result' 'runAfterResultFinalised' True 'destination' 'destinationFolder' '' ]helpers.convert_mapping_to_xml cm data mappings fail_required True if data.get 'destination' '' XML.SubElement cm 'overrideDestinationFolder' .text 'true'
def datetime_to_timestamp x if isinstance x datetime return timestamp x return x
def get_data_files dirs results []for directory in dirs for root dirs files in os.walk directory files [os.path.join root file_ for file_ in files]results.append root files return results
def DetectExecutablePaths source_values vars_map None detector CreateWindowsRegistryExecutablePathsDetector vars_map vars_map for source_value in source_values for result in detector.Detect source_value yield result
def check_executable executable logger logging.getLogger __name__ logger.debug "Checkingexecutable'%s'..." executable executable_path find_executable executable found executable_path is not None if found logger.debug "Executable'%s'found '%s'" executable executable_path else logger.debug "Executable'%s'notfound" executable return found
def test_takes_args assert not hug.introspect.takes_args function_with_kwargs assert hug.introspect.takes_args function_with_args assert not hug.introspect.takes_args function_with_neither assert hug.introspect.takes_args function_with_both
def normalize_kernel_dimensions griddim blockdim def check_dim dim name if not isinstance dim tuple list dim [dim]else dim list dim if len dim > 3 raise ValueError '%smustbeasequenceof1 2or3integers got%r' % name dim for v in dim if not isinstance v numbers.Integral raise TypeError '%smustbeasequenceofintegers got%r' % name dim while len dim < 3 dim.append 1 return dimgriddim check_dim griddim 'griddim' blockdim check_dim blockdim 'blockdim' return griddim blockdim
def np_where cond x y return np.where cond x y
def _construct_target_list targets target_entries []for entry in targets if not isinstance entry Gtk.TargetEntry entry Gtk.TargetEntry.new *entry target_entries.append entry return target_entries
def append_random_bottlecap_phrase message bottlecap Nonetry wp WikiPage.get Frontpage g.wiki_page_gold_bottlecaps split_list re.split '^[*-]' wp.content flags re.MULTILINE choices [item.strip for item in split_list if item.strip ]if len choices bottlecap choice choices except NotFound passif bottlecap message + '\n\n>' + bottlecap return message
def get_lazy_gettext domain def _lazy_gettext msg 'CreateandreturnaMessageobject.\n\nMessageencapsulatesastringsothatwecantranslateitlaterwhen\nneeded.\n'return Message msg domain return _lazy_gettext
def get_edge_attributes G name if G.is_multigraph edges G.edges keys True data True else edges G.edges data True return {x[ -1 ] x[ -1 ][name] for x in edges if name in x[ -1 ] }
def get_logger global _loggerif not _logger import logging atexitif hasattr atexit 'unregister' atexit.unregister _exit_function atexit.register _exit_function else atexit._exithandlers.remove _exit_function {} atexit._exithandlers.append _exit_function {} _check_logger_class _logger logging.getLogger LOGGER_NAME return _logger
def get_edit_filetypes pygments_exts _get_pygments_extensions favorite_exts ['.py' '.R' '.jl' '.ipynb' '.md' '.pyw' '.pyx' '.C' '.CPP']other_exts [ext for ext in pygments_exts if ext not in favorite_exts ]all_exts tuple favorite_exts + other_exts text_filetypes _ 'Supportedtextfiles' all_exts return [text_filetypes] + EDIT_FILETYPES
def generateVersionFileData version if version.prerelease is not None prerelease ' prerelease %r' % version.prerelease else prerelease ''data '#Thisisanauto-generatedfile.Donoteditit.\nfromtwisted.pythonimportversions\nversion versions.Version %r %s %s %s%s \n' % version.package version.major version.minor version.micro prerelease return data
def parse_atomic source info saved_flags info.flagstry subpattern _parse_pattern source info source.expect ' ' finally info.flags saved_flagssource.ignore_space bool info.flags & VERBOSE return Atomic subpattern
def _create_entry entry_body updated_str datetime.utcnow .isoformat if datetime.utcnow .utcoffset is None updated_str + '+00 00'entry_start '<?xmlversion "1.0"encoding "utf-8"standalone "yes"?>\n<entryxmlns d "http //schemas.microsoft.com/ado/2007/08/dataservices"xmlns m "http //schemas.microsoft.com/ado/2007/08/dataservices/metadata"xmlns "http //www.w3.org/2005/Atom">\n<title/><updated>{updated}</updated><author><name/></author><id/>\n<contenttype "application/xml">\n{body}</content></entry>'return entry_start.format updated updated_str body entry_body
def sudo_popen *args **kwargs user kwargs.get 'user' None full_command [SUDO_PATH SUDO_PRESERVE_ENVIRONMENT_ARG]if user full_command.extend [SUDO_USER_ARG user] full_command.extend args log.info 'Abouttoexecutethefollowingsudocommand-[%s]' % ''.join full_command p Popen full_command shell False stdout PIPE stderr PIPE return p
def create_sitemap app exception if not app.config['html_theme_options'].get 'base_url' '' or exception is not None or not app.sitemap_links returnfilename app.outdir + '/sitemap.xml' print 'Generatingsitemap.xmlin%s' % filename root ET.Element 'urlset' root.set 'xmlns' 'http //www.sitemaps.org/schemas/sitemap/0.9' for link in app.sitemap_links url ET.SubElement root 'url' ET.SubElement url 'loc' .text linkET.ElementTree root .write filename
def getMin first second return min first second
def enable_dbc *args if not ENABLE_DBC return Falsetry from logilab.aspects.weaver import weaverfrom logilab.aspects.lib.contracts import ContractAspectexcept ImportError sys.stderr.write 'Warning logilab.aspectsisnotavailable.Contractsdisabled.' return Falsefor arg in args weaver.weave_module arg ContractAspect return True
def _check_and_uninstall_python ret python user None ret _python_installed ret python user user if ret['result'] if ret['default'] __salt__['pyenv.default'] 'system' runas user if __salt__['pyenv.uninstall_python'] python runas user ret['result'] Trueret['changes'][python] 'Uninstalled'ret['comment'] 'Successfullyremovedpython'return retelse ret['result'] Falseret['comment'] 'Failedtouninstallpython'return retelse ret['result'] Trueret['comment'] 'python{0}isalreadyabsent'.format python return ret
@blueprint.route '/jobs/<job_id>/table_data.json' methods ['GET'] def job_table_data job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' model_output_fields set return flask.jsonify {'job' json_dict job model_output_fields }
def mlab_tempfile dir None valid_name re.compile u'^\\w+$' for n in range 100 f tempfile.NamedTemporaryFile suffix u'.m' prefix u'tmp_matlab_' dir dir fname os.path.splitext os.path.basename f.name [0]if valid_name.match fname breakf.close else raise ValueError u'Couldnotmaketempfileafter100tries' return f
@register_useless@register_canonicalize@register_specialize@gof.local_optimizer [T.Rebroadcast] def local_useless_rebroadcast node if isinstance node.op T.Rebroadcast x node.inputs[0]if numpy.all x.broadcastable node.outputs[0].broadcastable return [x]else new_axis {}for dim bc in list node.op.axis.items if x.broadcastable[dim] ! bc new_axis[dim] bcif new_axis node.op.axis returnelse r T.Rebroadcast *list new_axis.items x copy_stack_trace node.outputs r return [r]
def addresses_from_address_family address_family return Addresses tuple address_family.addressables.keys
def pperm_above accessing_obj accessed_obj *args **kwargs return perm_above _to_player accessing_obj accessed_obj *args **kwargs
def apply_user_permissions doctype ptype user None role_permissions get_role_permissions frappe.get_meta doctype user user return role_permissions.get u'apply_user_permissions' {} .get ptype
def all_estimates reviews k 1 reviews reviews.astype float k - 1 nusers nmovies reviews.shapeestimates np.zeros_like reviews for u in range nusers ureviews np.delete reviews u axis 0 ureviews - ureviews.mean 0 ureviews / ureviews.std 0 + 1e-05 ureviews ureviews.T.copy for m in np.where reviews[u] > 0 [0] estimates[ u m ] nn_movie ureviews reviews u m k return estimates
def _check_psd_data inst tmin tmax picks proj from ..io.base import BaseRawfrom ..epochs import BaseEpochsfrom ..evoked import Evokedif not isinstance inst BaseEpochs BaseRaw Evoked raise ValueError 'epochsmustbeaninstanceofEpochs Raw orEvoked.Gottype{0}'.format type inst time_mask _time_mask inst.times tmin tmax sfreq inst.info['sfreq'] if picks is None picks _pick_data_channels inst.info with_ref_meg False if proj inst inst.copy .apply_proj sfreq inst.info['sfreq']if isinstance inst BaseRaw start stop np.where time_mask [0][[0 -1 ]] data times inst[picks start stop + 1 ]elif isinstance inst BaseEpochs data inst.get_data [ picks][ time_mask]elif isinstance inst Evoked data inst.data[picks][ time_mask]return data sfreq
def blend *cols **kwargs return Blend *cols **kwargs
def discretize_linear_1D model x_range x np.arange x_range[0] - 0.5 x_range[1] + 0.5 values_intermediate_grid model x return 0.5 * values_intermediate_grid[1 ] + values_intermediate_grid[ -1 ]
def _ar_transparams params newparams 1 - np.exp - params / 1 + np.exp - params .copy tmp 1 - np.exp - params / 1 + np.exp - params .copy for j in range 1 len params a newparams[j]for kiter in range j tmp[kiter] - a * newparams[ j - kiter - 1 ] newparams[ j] tmp[ j]return newparams
def get_password vm_ return config.get_cloud_config_value 'password' vm_ __opts__ default config.get_cloud_config_value 'passwd' vm_ __opts__ search_global False search_global False
def add_bgp_error_metadata code sub_code def_desc 'unknown' if _EXCEPTION_REGISTRY.get code sub_code is not None raise ValueError 'BGPSExceptionwithcode%dandsub-code%dalreadydefined.' % code sub_code def decorator subclass 'Setsclassconstantsforexceptioncodeandsub-code.\n\nIfgivenclassissub-classofBGPSExceptionwesetsclassconstants.\n'if issubclass subclass BGPSException _EXCEPTION_REGISTRY[ code sub_code ] subclasssubclass.CODE codesubclass.SUB_CODE sub_codesubclass.DEF_DESC def_descreturn subclassreturn decorator
@abortsdef test_aborts_on_nonexistent_roles merge [] ['badrole'] [] {}
def getWindowGivenTextRepository fileName gcodeText repository skein SkeinlayerSkein skein.parseGcode fileName gcodeText repository return SkeinWindow repository skein
def iflatten x for el in x if is_listlike el for el_ in iflatten el yield el_ else yield el
def corner_shi_tomasi image sigma 1 Axx Axy Ayy structure_tensor image sigma response Axx + Ayy - np.sqrt Axx - Ayy ** 2 + 4 * Axy ** 2 / 2 return response
def send_reset_password_instructions user token generate_reset_password_token user reset_link url_for_security 'reset_password' token token _external True send_mail config_value 'EMAIL_SUBJECT_PASSWORD_RESET' user.email 'reset_instructions' user user reset_link reset_link reset_password_instructions_sent.send app._get_current_object user user token token
def _patch_stopall for patch in list _patch._active_patches patch.stop
def nested_parse_with_titles state content node surrounding_title_styles state.memo.title_stylessurrounding_section_level state.memo.section_levelstate.memo.title_styles []state.memo.section_level 0try return state.nested_parse content 0 node match_titles 1 finally state.memo.title_styles surrounding_title_stylesstate.memo.section_level surrounding_section_level
def guess_ext fname sniff_order is_multi_byte False file_ext Nonefor datatype in sniff_order '\nSomeclassesmaynothaveasnifffunction whichisok.Infact the\nTabularandTextclassesare2examplesofclassesthatshouldneverhave\nasnifffunction.Sincetheseclassesaredefaultclasses theycontain\nfewrulestofilteroutdataofotherformats sotheyshouldbecalled\nfromthisfunctionafterallotherdatatypesinsniff_orderhavenotbeen\nsuccessfullydiscovered.\n'try if datatype.sniff fname file_ext datatype.file_extbreakexcept passif file_ext 'tsv' if is_column_based fname ' DCTB ' 1 is_multi_byte is_multi_byte file_ext 'tabular'if file_ext is not None return file_extheaders get_headers fname None is_binary Falseif is_multi_byte is_binary Falseelse for hdr in headers for char in hdr is_binary util.is_binary char if is_binary breakif is_binary breakif is_binary return 'data'if is_column_based fname ' DCTB ' 1 is_multi_byte is_multi_byte return 'tabular'return 'txt'
def filter_query_params_key remove_params def filter url return filter_query_params url remove_params return filter
def retina_figure fig **kwargs pngdata print_figure fig fmt 'retina' **kwargs if pngdata is None return w h _pngxy pngdata metadata {'width' w // 2 'height' h // 2 }return pngdata metadata
def get_tenant keystone name tenants [x for x in keystone.tenants.list if x.name name ]count len tenants if count 0 raise KeyError 'Nokeystonetenantswithname%s' % name elif count > 1 raise ValueError '%dtenantswithname%s' % count name else return tenants[0]
def make_top_env build_dir os.environ['LC_ALL'] 'C'top_env SCons.Environment.Environment ENV os.environ top_env.EnsureSConsVersion 2 0 top_env.Decider 'MD5-timestamp' top_env.SetOption 'implicit_cache' 1 top_env.SetOption 'max_drift' 1 top_env.VariantDir build_dir '.' duplicate 0 return top_env
def my_calibration sz row col szfx 2555 * col / 2592 fy 2586 * row / 1936 K diag [fx fy 1] K[ 0 2 ] 0.5 * col K[ 1 2 ] 0.5 * row return K
def request_app_setup hass config add_devices config_path discovery_info None configurator get_component 'configurator' def fitbit_configuration_callback callback_data 'Theactionstodowhenourconfigurationcallbackiscalled.'config_path hass.config.path FITBIT_CONFIG_FILE if os.path.isfile config_path config_file config_from_file config_path if config_file DEFAULT_CONFIG error_msg "Youdidn'tcorrectlymodifyfitbit.conf" 'pleasetryagain' configurator.notify_errors _CONFIGURING['fitbit'] error_msg else setup_platform hass config add_devices discovery_info else setup_platform hass config add_devices discovery_info start_url '{}{}'.format hass.config.api.base_url FITBIT_AUTH_CALLBACK_PATH description 'PleasecreateaFitbitdeveloperappat\nhttps //dev.fitbit.com/apps/new.\nFortheOAuth2.0ApplicationTypechoosePersonal.\nSettheCallbackURLto{}.\nTheywillprovideyouaClientIDandsecret.\nTheseneedtobesavedintothefilelocatedat {}.\nThencomebackhereandhitthebelowbutton.\n'.format start_url config_path submit 'IhavesavedmyClientIDandClientSecretintofitbit.conf.'_CONFIGURING['fitbit'] configurator.request_config hass 'Fitbit' fitbit_configuration_callback description description submit_caption submit description_image '/static/images/config_fitbit_app.png'
def _write_stc filename tmin tstep vertices data fid open filename 'wb' fid.write np.array 1000 * tmin dtype '>f4' .tostring fid.write np.array 1000 * tstep dtype '>f4' .tostring fid.write np.array vertices.shape[0] dtype '>u4' .tostring fid.write np.array vertices dtype '>u4' .tostring fid.write np.array data.shape[1] dtype '>u4' .tostring fid.write np.array data.T dtype '>f4' .tostring fid.close
def fix value return value + 2 ** 32 if value < 0 else value
def alias_diff refcounts_before refcounts_after return set t for t in refcounts_after if refcounts_after[t] > refcounts_before.get t -1
def binom_tost_reject_interval low upp nobs alpha 0.05 x_low stats.binom.isf alpha nobs low + 1 x_upp stats.binom.ppf alpha nobs upp - 1 return x_low x_upp
def data_profiling_required f @wraps f def decorated_function *args **kwargs if current_app.config['LOGIN_DISABLED'] or not current_user.is_anonymous and current_user.data_profiling return f *args **kwargs else flash 'Thispagerequiresdataprofilingprivileges' 'error' return redirect url_for 'admin.index' return decorated_function
def _url path '' return HTTP_BASE_URL + path
@task queue 'web' def update_search version_pk commit delete_non_commit_files True version Version.objects.get pk version_pk if version.project.is_type_sphinx page_list process_all_json_files version build_dir False elif version.project.is_type_mkdocs page_list process_mkdocs_json version build_dir False else log.error 'Unknowndocumentationtype %s' version.project.documentation_type returnlog_msg ''.join [page['path'] for page in page_list] log.info ' SearchIndex SendingData %s[%s]' version.project.slug log_msg index_search_request version version page_list page_list commit commit project_scale 0 page_scale 0 section False delete delete_non_commit_files
def demo_update_two filename f get_contents filename if not len f.strip return ''f f + '\n' return f
def filter_err status application 'app' ticket 'tkt' routes THREAD_LOCAL.routesif status > 399 and routes.routes_onerror keys set '%s/%s' % application status '%s/*' % application '*/%s' % status '*/*' for key redir in routes.routes_onerror if key in keys if redir '!' breakelif '?' in redir url redir + '&' + 'code %s&ticket %s' % status ticket else url redir + '?' + 'code %s&ticket %s' % status ticket return urlreturn status
def cython_protocol_handler colparser from cassandra.row_parser import make_recv_results_rowsclass FastResultMessage ResultMessage '\nCythonversionofResultMessagethathasafasterimplementationof\nrecv_results_row.\n'code_to_type dict v k for k v in ResultMessage.type_codes.items recv_results_rows classmethod make_recv_results_rows colparser class CythonProtocolHandler _ProtocolHandler '\nUseFastResultMessagetodecodequeryresultmessagemessages.\n'my_opcodes _ProtocolHandler.message_types_by_opcode.copy my_opcodes[FastResultMessage.opcode] FastResultMessagemessage_types_by_opcode my_opcodescol_parser colparserreturn CythonProtocolHandler
def add_markdown_cell work_notebook text markdown_cell {'cell_type' 'markdown' 'metadata' {} 'source' [rst2md text ]}work_notebook['cells'].append markdown_cell
def _conv_comp comp first last chs ccomp dict ctfkind np.array [comp[first]['coeff_type']] save_calibrated False _add_kind ccomp n_col comp[first]['ncoeff']n_row last - first + 1 col_names comp[first]['sensors'][ n_col]row_names [comp[p]['sensor_name'] for p in range first last + 1 ]data np.empty n_row n_col for ii coeffs in enumerate comp[first last + 1 ] data[ii ] coeffs['coeffs'][ ]ccomp['data'] dict row_names row_names col_names col_names data data nrow len row_names ncol len col_names mk 'proper_gain' 'qgain' _calibrate_comp ccomp chs row_names col_names mult_keys mk flip True return ccomp
def anon_url *url url u''.join map str url uri_pattern u'^https? //'unicode_uri_pattern re.compile uri_pattern re.UNICODE if not re.search unicode_uri_pattern url url u'http //' + url return u'{}{}'.format sickrage.srCore.srConfig.ANON_REDIRECT url
def _determine_scaling_policies scaling_policies scaling_policies_from_pillar pillar_scaling_policies copy.deepcopy __salt__['config.option'] scaling_policies_from_pillar {} if not scaling_policies and len pillar_scaling_policies > 0 scaling_policies pillar_scaling_policiesreturn scaling_policies
def pickByDistribution distribution r None if r is None r randomx r.uniform 0 sum distribution for i d in enumerate distribution if x < d return ix - d
def truncated_tetrahedron_graph create_using None G path_graph 12 create_using G.add_edges_from [ 0 2 0 9 1 6 3 11 4 11 5 7 8 10 ] G.name 'TruncatedTetrahedronGraph'return G
@_FFI.callback u'bool ExternContext* TypeConstraint* TypeId* ' def extern_satisfied_by context_handle constraint_id cls_id c _FFI.from_handle context_handle return c.from_id constraint_id.id_ .satisfied_by_type c.from_id cls_id.id_
def dict_from_expr expr **args rep opt _dict_from_expr expr build_options args return rep opt.gens
def index_groups request group_form forms.GroupCreateForm request.POST or None if group_form.is_valid group group_form.save group.curators.add request.user.userprofile group.add_member request.user.userprofile GroupMembership.MEMBER return redirect reverse 'groups group_edit' args [group.url] query Group.get_non_functional_areas template 'groups/index_groups.html'context {'group_form' group_form}return _list_groups request template query context
def wps_execute_layer_attribute_statistics layer_name field url '%s/ows' % ogc_server_settings.LOCATION request render_to_string 'layers/wps_execute_gs_aggregate.xml' {'layer_name' 'geonode %s' % layer_name 'field' field} response http_post url request timeout ogc_server_settings.TIMEOUT username ogc_server_settings.credentials.username password ogc_server_settings.credentials.password exml etree.fromstring response result {}for f in ['Min' 'Max' 'Average' 'Median' 'StandardDeviation' 'Sum'] fr exml.find f if fr is not None result[f] fr.textelse result[f] 'NA'count exml.find 'Count' if count is not None result['Count'] int count.text else result['Count'] 0result['unique_values'] 'NA'return result
def set_extend l index item emptyValue None if index > len l l + [emptyValue] * index - len self + 1 l[index] item
def braycurtis u v u _validate_vector u v _validate_vector v dtype np.float64 return abs u - v .sum / abs u + v .sum
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def cell_update context cell_name values return IMPL.cell_update context cell_name values
def is_valid_device dev regex re.compile '/dev/sd[a-z]$' try return regex.match dev is not None except TypeError return False
def get_elliptic_curve name for curve in get_elliptic_curves if curve.name name return curveraise ValueError 'unknowncurvename' name
@cronjobs.registerdef reindex_users_that_contributed_yesterday if settings.STAGE returntoday datetime.now yesterday today - timedelta days 1 user_ids list Answer.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter reviewed__gte yesterday reviewed__lt today .values_list 'reviewer_id' flat True index_task.delay UserMappingType list set user_ids
def getargvalues frame args varargs varkw getargs frame.f_code return ArgInfo args varargs varkw frame.f_locals
def get_limited_to_project headers global _ENFORCERif not _ENFORCER _ENFORCER policy.Enforcer if not _ENFORCER.enforce 'context_is_admin' {} {'roles' headers.get 'X-Roles' '' .split ' ' } return headers.get 'X-Tenant-Id'
def gettempprefix return template
def find_paste_config if CONF.paste_deploy.config_file paste_config CONF.paste_deploy.config_filepaste_config_value paste_configif not os.path.isabs paste_config paste_config CONF.find_file paste_config elif CONF.config_file paste_config CONF.config_file[0]paste_config_value paste_configelse paste_config CONF.find_file 'keystone.conf' paste_config_value 'keystone.conf'if not paste_config or not os.path.exists paste_config raise exception.ConfigFileNotFound config_file paste_config_value return paste_config
def issue owner repository number return gh.issue owner repository number
def Screen if Turtle._screen is None Turtle._screen _Screen return Turtle._screen
def find_system_symbol img instruction_addr sdk_info None return DSymSymbol.objects.lookup_symbol instruction_addr instruction_addr image_addr img['image_addr'] image_vmaddr img['image_vmaddr'] uuid img['uuid'] cpu_name get_cpu_name img['cpu_type'] img['cpu_subtype'] object_path img['name'] sdk_info sdk_info
def post_form_view request return post_form_response
def _delete_ntp_servers servers return __salt__['ntp.delete_servers'] commit False *servers
def _is_credit_requirement xblock required_methods ['get_credit_requirement_namespace' 'get_credit_requirement_name' 'get_credit_requirement_display_name']for method_name in required_methods if not callable getattr xblock method_name None LOGGER.error 'XBlock%sismarkedasacreditrequirementbutdoesnotimplement%s' unicode xblock method_name return Falsereturn True
def gf_sub_ground f a p K if not f a - a % p else a f[ -1 ] - a % p if len f > 1 return f[ -1 ] + [a] if not a return []else return [a]
def depend log '*Installingpackagedependencies' run 'sudoapt-get-qyupdate' run 'sudoapt-get-qyinstallkvmcloud-utilsgenisoimageqemu-kvmqemu-utilse2fsprogscurlpython-setuptoolsmtoolszip' run 'sudoeasy_installpexpect'
def opts_pkg ret {}ret.update __opts__ ret['grains'] __grains__return ret
def no_assert_equal_true_false logical_line _start_re re.compile 'assert Not ?Equal\\ True|False ' _end_re re.compile 'assert Not ?Equal\\ .* \\s+ True|False \\ $' if _start_re.search logical_line or _end_re.search logical_line yield 0 'N355 assertEqual A True|False assertEqual True|False A assertNotEqual A True|False orassertEqual True|False A sentencesmustnotbeused.UseassertTrue A orassertFalse A instead'
def _parse_optional fh optional {'StartKernData' _parse_kern_pairs 'StartComposites' _parse_composites}d {'StartKernData' {} 'StartComposites' {}}for line in fh line line.rstrip if not line continuekey line.split [0]if key in optional d[key] optional[key] fh l d['StartKernData'] d['StartComposites'] return l
def no_prereq_install vals {'0' False '1' True 'true' True 'false' False}val os.environ.get 'NO_PREREQ_INSTALL' 'False' .lower try return vals[val]except KeyError return False
@register.inclusion_tag u'bootstrap3/pagination.html' def bootstrap_pagination page **kwargs pagination_kwargs kwargs.copy pagination_kwargs[u'page'] pagereturn get_pagination_context **pagination_kwargs
def _parse_belongs_to key belongs_to inventory for item in belongs_to if key not in inventory[item]['children'] appended du.append_if array inventory[item]['children'] item key if appended logger.debug 'Added%sto%s' key item
@ensure_csrf_cookiedef update_session_language request if request.method 'PATCH' data json.loads request.body language data.get LANGUAGE_KEY settings.LANGUAGE_CODE if request.session.get LANGUAGE_SESSION_KEY None ! language request.session[LANGUAGE_SESSION_KEY] unicode language return HttpResponse 200
def _inet_pton_win address_family ip_string addr sockaddr addr.sa_family address_familyaddr_size ctypes.c_int ctypes.sizeof addr str_to_addr ctypes.windll.ws2_32.WSAStringToAddressAif str_to_addr ip_string address_family None ctypes.byref addr ctypes.byref addr_size ! 0 raise socket.error ctypes.FormatError if address_family socket.AF_INET return ctypes.string_at addr.ipv4_addr 4 if address_family socket.AF_INET6 return ctypes.string_at addr.ipv6_addr 16 raise socket.error 'unknownaddressfamily'
def register_sizes regs in_sizes sizes {}bigger {}smaller {}for l in regs for r s in zip l in_sizes sizes[r] sfor r in l bigger[r] [r_ for r_ in l if sizes[r_] > sizes[r] or r r_ ]smaller[r] [r_ for r_ in l if sizes[r_] < sizes[r] ]return lists.concat regs sizes bigger smaller
def idz_copycols A k idx A np.asfortranarray A return _id.idz_copycols A k idx
def _complex_expand_series context builder ty initial x coefs assert ty in types.complex_domain binary_sig typing.signature * [ty] * 3 accum context.make_complex builder ty value initial ONE context.get_constant ty.underlying_float 1.0 for coef in reversed coefs constant context.get_constant ty.underlying_float coef value numbers.complex_mul_impl context builder binary_sig [x accum._getvalue ] accum._setvalue value accum.real builder.fadd ONE builder.fmul accum.real constant accum.imag builder.fmul accum.imag constant return accum._getvalue
def s_lego lego_type value None options {} name 'LEGO_%08x' % len blocks.CURRENT.names if not legos.BIN.has_key lego_type raise sex.SullyRuntimeError 'INVALIDLEGOTYPESPECIFIED %s' % lego_type lego legos.BIN[lego_type] name blocks.CURRENT value options blocks.CURRENT.push lego blocks.CURRENT.pop
def logsumexp x axis None return LogSumExp axis x
def get_test_uids offset 0 count 1 pootle_path '^/language0/' from pootle_store.constants import TRANSLATEDfrom pootle_store.models import Unitunits Unit.objects.filter store__pootle_path__regex pootle_path .filter state TRANSLATED begin units.count / 2 + offset return list units[begin begin + count ].values_list 'pk' flat True
def nanmin a axis None out None keepdims False res core.nanmin a axis axis out out keepdims keepdims if content.isnan res .any warnings.warn 'All-NaNsliceencountered' RuntimeWarning return res
def _construct_divmod_result left result index name dtype constructor left._constructorreturn constructor result[0] index index name name dtype dtype constructor result[1] index index name name dtype dtype
def parse_enum key value enumeration return parse_enum_csv key value enumeration 1 [0]
def _int_from_json value field if _not_null value field return int value
def licensed cmd 'cscriptC \\Windows\\System32\\slmgr.vbs/dli'out __salt__['cmd.run'] cmd return 'LicenseStatus Licensed' in out
def get_docker_version_info result Noneif is_service_running 'docker' version_info yaml.safe_load get_version_output '/usr/bin/docker' 'version' if 'Server' in version_info result {'api_version' version_info['Server']['APIversion'] 'version' version_info['Server']['Version']}return result
@rule u' ?u .* https? //\\S+ .*' def title_auto bot trigger if re.match bot.config.core.prefix + u'title' trigger returnif u'safety_cache' in bot.memory and trigger in bot.memory[u'safety_cache'] if bot.memory[u'safety_cache'][trigger][u'positives'] > 1 returnurls re.findall url_finder trigger if len urls 0 returnresults process_urls bot trigger urls bot.memory[u'last_seen_url'][trigger.sender] urls[ -1 ]for title domain in results[ 4] message u'[%s]-%s' % title domain if message ! trigger bot.say message
def repr_attrs instance *attrs orig_repr_template '<{0.__class__.__module__}.{0.__class__.__name__}objectat{1 #x}'if attrs repr_template orig_repr_template + ' ' + ' '.join ['{0} {{0.{0}}}'.format attr for attr in attrs] repr_template + '>'orig_repr_template + '>'try return repr_template.format instance id instance except Exception return orig_repr_template.format instance id instance
def _nsort roots separated False if not all r.is_number for r in roots raise NotImplementedErrorkey [[i.n 2 .as_real_imag [0] for i in r.as_real_imag ] for r in roots]if any i._prec 1 for k in key for i in k raise NotImplementedError 'couldnotcomputerootwithprecision' key [ 1 if i else 0 r i for r i in key]key sorted zip key roots if separated r []i []for im _ _ v in key if im i.append v else r.append v return r i _ roots zip *key return list roots
def check_extras dist attr value try for k v in value.items if ' ' in k k m k.split ' ' 1 if pkg_resources.invalid_marker m raise DistutilsSetupError 'Invalidenvironmentmarker ' + m list pkg_resources.parse_requirements v except TypeError ValueError AttributeError raise DistutilsSetupError "'extras_require'mustbeadictionarywhosevaluesarestringsorlistsofstringscontainingvalidproject/versionrequirementspecifiers."
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def saveimage filename im if len im.shape 3 cv2.imwrite filename 255 * im[ -1 ] else cv2.imwrite filename 255 * im
def ValidateXsrfToken token action user_str _MakeUserStr token_obj memcache.get token namespace MEMCACHE_NAMESPACE if not token_obj return False token_str token_action token_objif user_str ! token_str or action ! token_action return Falsereturn True
def make_csrf_token req session_id ts None ts '%x' % ts if ts is not None else time.time payload [req.server.secret session_id ts]return '%s-%s' % ts b64w sha512b64 '-'.join payload
@skip_unless_environ 'GALAXY_TEST_INCLUDE_SLOW' def test_conda_resolution_failure base_path mkdtemp prefix 'x' * 80 try job_dir os.path.join base_path '000' dependency_manager DependencyManager base_path resolver CondaDependencyResolver dependency_manager auto_init True auto_install True use_path_exec False conda_context resolver.conda_contextassert len list conda_util.installed_conda_targets conda_context 0 dependency resolver.resolve name 'samtools' version None type 'package' job_directory job_dir assert dependency.shell_commands None is None installed_targets list conda_util.installed_conda_targets conda_context assert len installed_targets 0 finally shutil.rmtree base_path
def enable_module module if not is_module_enabled module run_as_root 'a2enmod%s' % module
def get_cluster_host req params cluster_version None if cluster_version is not False and req.api_version_request.matches cluster_version cluster_name params.get 'cluster' msg _ 'Oneandonlyoneofclusterandhostmustbeset.' else cluster_name Nonemsg _ 'Hostfieldismissing.' host params.get 'host' if bool cluster_name bool host raise exception.InvalidInput reason msg return cluster_name host
def _CreateStyleFromConfigParser config section 'yapf' if config.has_section 'yapf' else 'style' if config.has_option 'style' 'based_on_style' based_on config.get 'style' 'based_on_style' .lower base_style _STYLE_NAME_TO_FACTORY[based_on] elif config.has_option 'yapf' 'based_on_style' based_on config.get 'yapf' 'based_on_style' .lower base_style _STYLE_NAME_TO_FACTORY[based_on] else base_style _GLOBAL_STYLE_FACTORY for option value in config.items section if option.lower 'based_on_style' continueoption option.upper if option not in _STYLE_OPTION_VALUE_CONVERTER raise StyleConfigError 'Unknownstyleoption"{0}"'.format option try base_style[option] _STYLE_OPTION_VALUE_CONVERTER[option] value except ValueError raise StyleConfigError "'{}'isnotavalidsettingfor{}.".format value option return base_style
def _get_inst ip port return _servers.get ip port None
def _elements_to_dict data position obj_end opts result opts.document_class pos positionfor key value pos in _iterate_elements data position obj_end opts result[key] valueif pos ! obj_end raise InvalidBSON 'badobjectorelementlength' return result
def calculate_results sim_params env data_portal splits None txns None commissions None txns txns or [] splits splits or {} commissions commissions or {} perf_tracker perf.PerformanceTracker sim_params get_calendar 'NYSE' env results []for date in sim_params.sessions for txn in filter lambda txn txn.dt date txns perf_tracker.process_transaction txn try commissions_for_date commissions[date]for comm in commissions_for_date perf_tracker.process_commission comm except KeyError passtry splits_for_date splits[date]perf_tracker.handle_splits splits_for_date except KeyError passmsg perf_tracker.handle_market_close date data_portal perf_tracker.position_tracker.sync_last_sale_prices date False data_portal msg['account'] perf_tracker.get_account True results.append copy.deepcopy msg return results
def get_values_for_names names default_value None result {}kvp_dbs KeyValuePair.get_by_names names names name_to_kvp_db_map {}for kvp_db in kvp_dbs name_to_kvp_db_map[kvp_db.name] kvp_db.valuefor name in names result[name] name_to_kvp_db_map.get name default_value return result
def maybe_unroll_group g try size len g.tasks except TypeError try size g.tasks.__length_hint__ except AttributeError TypeError return gelse return list g.tasks [0] if size 1 else g else return g.tasks[0] if size 1 else g
def pid_by_open_file path if is_available 'lsof' results call GET_PID_BY_FILE_LSOF % path [] if len results 1 pid results[0].strip if pid.isdigit return int pid return None
@deprecated u'2.1' def allequal seq if len seq < 2 return Trueval seq[0]for i in xrange 1 len seq thisval seq[i]if thisval ! val return Falsereturn True
def _extract_argmax_and_embed embedding output_projection None update_embedding True def loop_function prev _ 'functionthatfeedpreviousmodeloutputratherthangroundtruth.'if output_projection is not None prev tf.nn.xw_plus_b prev output_projection[0] output_projection[1] prev_symbol tf.argmax prev 1 emb_prev tf.nn.embedding_lookup embedding prev_symbol if not update_embedding emb_prev tf.stop_gradient emb_prev return emb_prevreturn loop_function
def parse_metadata_state_descriptions state_string result {}state_string state_string.strip if state_string cols map strip state_string.split ';' for c in cols colname vals map strip c.split ' ' 1 vals map strip vals.split ' ' result[colname] set vals return result
def get_auth_from_url url if url url unquote url parsed urlparse url return parsed.username parsed.password else return '' ''
def unmanagedDLL twain Environment.GetEnvironmentVariable 'SystemRoot' + '\\twain.dll' File.Copy twain DLLS_DIR + '\\twain.dll'
def dset_sheet dataset ws _package dataset._package dicts False for i sep in enumerate dataset._separators _offset i_package.insert sep[0] + _offset sep[1] for i row in enumerate _package for j col in enumerate row if i 0 and dataset.headers ws.write i j col bold ws.panes_frozen Truews.horz_split_pos 1elif len row < dataset.width ws.write i j col bold else try if '\n' in col ws.write i j col wrap else ws.write i j col except TypeError ws.write i j col
def _find_dumb_path challbs preferences path []for i challb in enumerate challbs supported next True for pref_c in preferences if isinstance challb.chall pref_c False if supported path.append i else _report_no_chall_path return path
def _get_top_docs count top_qs WikiDocumentVisits.objects.select_related 'document' .filter period LAST_90_DAYS .order_by '-visits' [ count]return [v.document for v in top_qs]
def Array typecode_or_type size_or_initializer **kwds from multiprocessing.sharedctypes import Arrayreturn Array typecode_or_type size_or_initializer **kwds
def _is_task name value return is_classic_task name value or is_task_object value
def cache_page *args **kwargs if len args ! 1 or callable args[0] raise TypeError 'cache_pagehasasinglemandatorypositionalargument timeout' cache_timeout args[0]cache_alias kwargs.pop 'cache' None key_prefix kwargs.pop 'key_prefix' None if kwargs raise TypeError 'cache_pagehastwooptionalkeywordarguments cacheandkey_prefix' return decorator_from_middleware_with_args CacheMiddleware cache_timeout cache_timeout cache_alias cache_alias key_prefix key_prefix
def _add_runner_options_for_opt parser opt_name include_deprecated True conf _RUNNER_OPTS[opt_name]if conf.get 'deprecated' and not include_deprecated returnswitches conf.get 'switches' or [] for args kwargs in switches kwargs dict kwargs deprecated_aliases kwargs.pop 'deprecated_aliases' None kwargs['dest'] opt_nameif kwargs.get 'callback' kwargs.setdefault 'action' 'callback' kwargs.setdefault 'nargs' 1 kwargs.setdefault 'type' 'string' if kwargs.get 'action' 'append' kwargs['default'] []else kwargs['default'] Noneparser.add_option *args **kwargs if deprecated_aliases and include_deprecated help 'Deprecatedalias%sfor%s' % 'es' if len deprecated_aliases > 1 else '' args[ -1 ] parser.add_option *deprecated_aliases **combine_dicts kwargs dict help help
def open_file filename mode 'r' encoding None errors 'strict' lazy False atomic False if lazy return LazyFile filename mode encoding errors atomic atomic f should_close open_stream filename mode encoding errors atomic atomic if not should_close f KeepOpenFile f return f
def _make_key_value_map entity property_names value_map dict name [] for name in property_names for prop in entity.property_list if prop.name in value_map value_map[prop.name ].append datastore_types.PropertyValueToKeyValue prop.value if datastore_types.KEY_SPECIAL_PROPERTY in value_map value_map[datastore_types.KEY_SPECIAL_PROPERTY] [datastore_types.ReferenceToKeyValue entity.key ]return value_map
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def equal_any *values return IMPL.equal_any *values
def ver global _verif not _ver p subprocess.Popen ['git' '--version'] stdout subprocess.PIPE gvs p.stdout.read _git_wait 'git--version' p m re.match 'gitversion \\S+.\\S+ ' gvs if not m raise GitError 'git--versionweirdoutput %r' % gvs _ver tuple m.group 1 .split '.' needed '1' '5' '3' '1' if _ver < needed raise GitError 'gitversion%sorhigherisrequired;youhave%s' % '.'.join needed '.'.join _ver return _ver
def render_doc thing title 'PythonLibraryDocumentation %s' forceload 0 object name resolve thing forceload desc describe object module inspect.getmodule object if name and '.' in name desc + 'in' + name[ name.rfind '.' ] elif module and module is not object desc + 'inmodule' + module.__name__ if type object is _OLD_INSTANCE_TYPE object object.__class__elif not inspect.ismodule object or inspect.isclass object or inspect.isroutine object or inspect.isgetsetdescriptor object or inspect.ismemberdescriptor object or isinstance object property object type object desc + 'object'return title % desc + '\n\n' + text.document object name
@task@cmdopts [ 'suite ' 's' 'Testsuitetorun' 'coverage' 'c' 'Runtestundercoverage' ] @timeddef test_js_run options options.mode 'run'test_js options
def getBottomPaths paths bottom 999999999.9for path in paths for point in path bottom min bottom point.z return bottom
def normaltest a axis 0 a axis _chk_asarray a axis s _ skewtest a axis k _ kurtosistest a axis k2 s * s + k * k return NormaltestResult k2 distributions.chi2.sf k2 2
def svnadmin_available return os.path.exists django.conf.settings.SVNADMIN_PATH
def ensure_csrf_cookie_cross_domain func def _inner *args **kwargs if args request args[0]request.META['CROSS_DOMAIN_CSRF_COOKIE_USED'] Truereturn ensure_csrf_cookie func *args **kwargs return _inner
def yield_dynamic_descriptor_descendants descriptor user_id module_creator None stack [descriptor]while len stack > 0 next_descriptor stack.pop stack.extend get_dynamic_descriptor_children next_descriptor user_id module_creator yield next_descriptor
def sensitivity_score y_true y_pred labels None pos_label 1 average 'binary' sample_weight None s _ _ sensitivity_specificity_support y_true y_pred labels labels pos_label pos_label average average warn_for 'sensitivity' sample_weight sample_weight return s
def url_to_parts url scheme urlparse url .schemeschemeless url[ len scheme + 3 ]parts urlparse u'http //' + schemeless path parts.path or u'' path path[1 ] if path and path[0] u'/' else path return urlparts scheme unquote parts.hostname or u'' or None parts.port unquote parts.username or u'' or None unquote parts.password or u'' or None unquote path or u'' or None dict parse_qsl parts.query
def Thing2Literal o d return string_literal o d
def _get_display_cls format dummy lambda *args **kwargs None try import IPython.display as displayexcept ImportError return dummyif format in IPYTHON_NO_DISPLAY_FORMATS return dummyelif format in IPYTHON_IMAGE_FORMATS return partial display.Image format format elif format 'svg' return display.SVGelse raise ValueError "Unknownformat'%s'passedto`dot_graph`" % format
def parse_call_group source info ch pos if ch 'R' group '0'else group ch + source.get_while DIGITS source.expect ' ' return CallGroup info group pos
def _api_test_osd name output kwargs logging.info 'SendingOSDnotification' res sabnzbd.notifier.send_notify_osd 'SABnzbd' T 'TestNotification' return report output error res
def proplist root fn result []for path in propfiles root fn try f open path except IOError continuewhile 1 line f.readline if line.startswith 'END' breakassert line.startswith 'K' L int line.split [1] key f.read L result.append key f.readline line f.readline assert line.startswith 'V' L int line.split [1] value f.read L f.readline f.close return result
def user_media_path what default os.path.join settings.MEDIA_ROOT what key '{0}_PATH'.format what.upper return getattr settings key default
def getAllPages referenceable methodName *args **kw d defer.Deferred referenceable.callRemote methodName CallbackPageCollector d.callback *args **kw return d
def _process_image_annotations image return {'faces' _make_faces_from_pb image.face_annotations 'labels' _make_entity_from_pb image.label_annotations 'landmarks' _make_entity_from_pb image.landmark_annotations 'logos' _make_entity_from_pb image.logo_annotations 'properties' _make_image_properties_from_pb image.image_properties_annotation 'safe_searches' _make_safe_search_from_pb image.safe_search_annotation 'texts' _make_entity_from_pb image.text_annotations }
def sampled live_config_var def sampled_decorator fn @functools.wraps fn def sampled_fn *a **kw if random.random > g.live_config[live_config_var] return Noneelse return fn *a **kw return sampled_fnreturn sampled_decorator
def _json_format_dict data pretty False if pretty return json.dumps data sort_keys True indent 2 else return json.dumps data
def is_bulk_request request content_type request.content_typereturn 'ext bulk' in content_type
def parse_firstboot rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--enable' '--enabled' dest 'enable' action 'store_true' parser.add_argument '--disable' '--disabled' dest 'disable' action 'store_true' parser.add_argument '--reconfig' dest 'reconfig' action 'store_true' args clean_args vars parser.parse_args rules parser Nonereturn args
def cell_with_item cell_name item if cell_name is None return itemreturn cell_name + _CELL_ITEM_SEP + str item
def _invalidate_string_dtypes dtype_set non_string_dtypes dtype_set - _string_dtypes if non_string_dtypes ! dtype_set raise TypeError "stringdtypesarenotallowed use'object'instead"
@receiver COURSE_CERT_AWARDED sender GeneratedCertificate def create_course_badge sender user course_key status **kwargs course_badge_check user course_key
def inputvars a return [v for v in inputs makeiter a if isinstance v tt.TensorVariable ]
def write_features_to_file filename locs desc savetxt filename hstack locs desc
def pwDecode epw if not epw.startswith EncodeMarker return epwreturn base64.b64decode epw[3 ].encode u'ascii' [32 -32 ].decode u'utf-8'
def is_valid_med med return isinstance med numbers.Integral and 0 < med < 4294967295
def _ValidateSourcesForOSX spec all_sources if spec.get 'type' None ! 'static_library' returnbasenames {}for source in all_sources name ext os.path.splitext source is_compiled_file ext in ['.c' '.cc' '.cpp' '.cxx' '.m' '.mm' '.s' '.S'] if not is_compiled_file continuebasename os.path.basename name basenames.setdefault basename [] .append source error ''for basename files in basenames.iteritems if len files > 1 error + '%s %s\n' % basename ''.join files if error print 'staticlibrary%shasseveralfileswiththesamebasename \n' % spec['target_name'] + error + 'libtoolonOSXwillgenerate' + 'warningsforthem.' raise GypError 'Duplicatebasenamesinsourcessection seelistabove'
def _get_epochs_delayed_ssp raw read_raw_fif raw_fname events read_events event_name picks _get_picks raw reject dict mag 4e-12 epochs_delayed_ssp Epochs raw events[ 10] event_id tmin tmax picks picks proj 'delayed' reject reject return epochs_delayed_ssp
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def makeGetpass *passphrases passphrases iter passphrases def fakeGetpass _ return next passphrases return fakeGetpass
def wait_for_http_server host port for i in range 10 conn httplib.HTTPConnection host port conn.request 'GET' '/' if conn.getresponse .status 200 breaktime.sleep 0.1 else template "TestHTTPserveronhost%sandport%sdidnotreturn'200OK'after10tries"message template % host port raise Exception message
def creategroup name primary_cluster_id replication_group_description wait None region None key None keyid None profile None ret {'name' name 'result' None 'comment' '' 'changes' {}}is_present __salt__['boto_elasticache.group_exists'] name region key keyid profile if not is_present if __opts__['test'] ret['comment'] 'Replication{0}issettobecreated.'.format name ret['result'] Nonecreated __salt__['boto_elasticache.create_replication_group'] name primary_cluster_id replication_group_description wait region key keyid profile if created config __salt__['boto_elasticache.describe_replication_group'] name region key keyid profile ret['changes']['old'] Noneret['changes']['new'] configret['result'] Trueelse ret['result'] Falseret['comment'] 'Failedtocreate{0}replicationgroup.'.format name else ret['comment'] '{0}replicationgroupexists.'.format name ret['result'] Truereturn ret
def _list_files folder pattern for root folders files in os.walk folder for filename in files if fnmatch.fnmatch filename pattern yield os.path.join root filename
def get_socket_inherit socket try if iswindows import win32api win32conflags win32api.GetHandleInformation socket.fileno return bool flags & win32con.HANDLE_FLAG_INHERIT else import fcntlflags fcntl.fcntl socket.fileno fcntl.F_GETFD return not bool flags & fcntl.FD_CLOEXEC except import tracebacktraceback.print_exc
def find_sockdir for dir in SEARCH_DIRS for dirpath dirnames dirfiles in os.walk dir followlinks True for name in dirfiles if utils.is_sockfile os.path.join dirpath name and 'PGSQL' in name return dirpath
def CopyToClipboard string hWnd lib.GetConsoleWindow if lib.OpenClipboard hWnd cstring ffi.new 'char[]' string size ffi.sizeof cstring hGlobal lib.GlobalAlloc lib.GMEM_MOVEABLE size buffer lib.GlobalLock hGlobal lib.memcpy buffer cstring size lib.GlobalUnlock hGlobal res lib.EmptyClipboard res lib.SetClipboardData lib.CF_TEXT buffer lib.CloseClipboard
def test_train_predict3 import tempfilesp SequencePattern 'sorted' in_seq_len 10 out_seq_len 10 tempdir tempfile.mkdtemp ts2s TFLearnSeq2Seq sp seq2seq_model 'embedding_attention' data_dir tempdir name 'attention' tf.reset_default_graph ts2s.train num_epochs 1 num_points 1000 weights_output_fn 1 weights_input_fn 0 assert os.path.exists ts2s.weights_output_fn tf.reset_default_graph sp SequencePattern 'sorted' in_seq_len 20 out_seq_len 8 tf.reset_default_graph ts2s TFLearnSeq2Seq sp seq2seq_model 'embedding_attention' data_dir 'DATA' name 'attention' verbose 1 x np.random.randint 0 9 20 prediction y ts2s.predict x weights_input_fn 1 assert len prediction 8 os.system 'rm-rf%s' % tempdir
def asBytes obj if isinstance obj list return map asBytes obj elif isinstance obj dict return dict asBytes k asBytes v for k v in obj.items elif isinstance obj unicode return obj.encode 'utf-8' else return obj
def get_edit_filters edit_filetypes get_edit_filetypes return _get_filters edit_filetypes
def get_hasher algorithm 'default' if hasattr algorithm 'algorithm' return algorithmelif algorithm 'default' return get_hashers [0]else hashers get_hashers_by_algorithm try return hashers[algorithm]except KeyError raise ValueError "Unknownpasswordhashingalgorithm'%s'.DidyouspecifyitinthePASSWORD_HASHERSsetting?" % algorithm
def __kwargs_option_to_dict raw_value kwargs {}if raw_value for binding in raw_value.split ' ' name value binding.split ' ' if value.lower 'true' value Trueelif value.lower 'false' value Falseelif value.isdigit value int value kwargs[name] valuereturn kwargs
def get_confirmation question while True response input u'%s y/n ' % question .lower if re.match u'^[yn]' response is not None breakprint u"Incorrectoption'%s'" % response return response[0] u'y'
def _get_linux_adapter_name_and_ip_address mac_address network_adapters _get_linux_network_adapters return _get_adapter_name_and_ip_address network_adapters mac_address
@synchronized IO_LOCK def save_data data _id path do_pickle True silent False if not silent logging.debug 'Savingdatafor%sin%s' _id path path os.path.join path _id try _f open path 'wb' if do_pickle if cfg.use_pickle pickler pickle.Pickler _f 2 else pickler cPickle.Pickler _f 2 pickler.dump data _f.flush _f.close pickler.clear_memo del picklerelse _f.write data _f.flush _f.close except logging.error T 'Saving%sfailed' path logging.info 'Traceback ' exc_info True
def _get_priceful request item quantity if hasattr item 'get_price_info' if hasattr item 'is_variation_parent' if item.is_variation_parent return item.get_cheapest_child_price_info request quantity return item.get_price_info request quantity quantity if hasattr item 'get_total_cost' return item.get_total_cost request.basket assert isinstance item Priceful return item
def get_parent_pid return psutil.Process .ppid
@apply_to_text_filedef typogrify_sans_widont data if typo is None req_missing ['typogrify'] 'usethetypogrify_sans_widontfilter' data _normalize_html data data typo.amp data data typo.smartypants data data typo.initial_quotes data return data
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
@raises ValueError def test_randomize_corrmat_tail_error a rs.randn 3 30 algo.randomize_corrmat a 'hello'
def getSliceElementZ sliceElement idValue sliceElement.attributeDictionary['id'].strip return float idValue[len 'z ' ].strip
def _module_to_dict module omittable lambda k k.startswith '_' return dict [ k repr v for k v in module.__dict__.items if not omittable k ]
def can_delete cc_content context return _is_author_or_privileged cc_content context
def acl_group_add_hosts id hosts group models.AclGroup.smart_get id group.check_for_acl_violation_acl_group hosts models.Host.smart_get_bulk hosts group.hosts.add *hosts group.on_host_membership_change
def _getitem_array1d context builder arrayty array idx wraparound ptr cgutils.get_item_pointer builder arrayty array [idx] wraparound wraparound return load_item context builder arrayty ptr
def disable_profiling profile service signal frame current_time strftime '%Y%m%d%H%M%S' path FilePath '/var/lib/flocker' path path.child 'profile-{service}-{current_time}'.format service service current_time current_time profile.dump_stats path.path
def is_abstract node return ABSTRACT.match node.name
def InsertNodesAfter new_nodes target for node in reversed new_nodes _InsertNodeAt node target after True
def get_recipients doc fetched_from_email_account False recipients split_emails doc.recipients if recipients recipients filter_email_list doc recipients [] return recipients
def get_safe_settings settings_dict {}for k in dir settings if k.isupper settings_dict[k] cleanse_setting k getattr settings k return settings_dict
def _lin_field_coeff surf mult rmags cosmags ws bins n_jobs parallel p_fun _ parallel_func _do_lin_field_coeff n_jobs nas np.array_splitcoeffs parallel p_fun surf['rr'] t tn ta rmags cosmags ws bins for t tn ta in zip nas surf['tris'] n_jobs nas surf['tri_nn'] n_jobs nas surf['tri_area'] n_jobs return mult * np.sum coeffs axis 0
def run_crawler projects get_projects for file_path project in projects.items logging.info u'Processing%s' % file_path if api_key is not None try add_ohloh_metadata project except logging.warning u'SkippingOhlohmetadataforproject%s' % project[u'name'] save_project project file_path logging.info u'Writingtotables' write_to_table projects logging.info u'Done!'
def Dot return Leaf token.DOT '.'
def get_log_format server _DEFAULT_SERVER log_format_types get_log_format_types format_id _get_wmi_setting 'IIsSmtpServerSetting' 'LogPluginClsid' server for key in log_format_types if str format_id log_format_types[key] return key_LOG.warning 'Unabletodeterminelogformat.' return None
def _full_live_path cli_config lineagename return os.path.join cli_config.live_dir lineagename
def activity_funding return s3_rest_controller
def _shared_login request csession request.sessionplayer request.usersesslogin csession.get 'logged_in' None if csession.session_key is None csession.save elif player.is_authenticated if not sesslogin csession['logged_in'] player.idelif sesslogin player PlayerDB.objects.get id sesslogin try authenticate autologin player login request player except AttributeError logger.log_trace
def is_valid_email email return '@' in email and '.' in email
def _normalize_dataframe dataframe index data dataframe[index].dropna grouped data.groupby index sort False counted grouped[index].count averaged counted.mean axis 1 return averaged
def latest_stable_version get metadata loads get environ.get 'LE_AUTO_JSON_URL' 'https //pypi.python.org/pypi/certbot/json' return str max LooseVersion r for r in metadata['releases'].iterkeys if re.match '^[0-9.]+$' r
def set_stay_open new_stay_open global stay_openstay_open new_stay_open
def empty_if_none fn def wrapper value if value is None return ''return fn value return wrapper
def get_repository_metadata_by_repository_id_changeset_revision app id changeset_revision metadata_only False if metadata_only repository_metadata get_repository_metadata_by_changeset_revision app id changeset_revision if repository_metadata and repository_metadata.metadata return repository_metadata.metadatareturn Nonereturn get_repository_metadata_by_changeset_revision app id changeset_revision
def get_cmdclass cmdclass versioneer.get_cmdclass try from wheel.bdist_wheel import bdist_wheelexcept ImportError bdist_wheel Noneif bdist_wheel is not None cmdclass['bdist_wheel'] bdist_wheelreturn cmdclass
def is_torrent_or_nzb_file filename if not isinstance filename str unicode return Falsereturn filename.rpartition u'.' [2].lower in [u'nzb' u'torrent']
def get_instance_public_methods instance instance_members inspect.getmembers instance instance_methods {}for name member in instance_members if not name.startswith '_' if inspect.ismethod member instance_methods[name] memberreturn instance_methods
def register_service_by_type request url request.POST.get 'url' type request.POST.get 'type' url _clean_url url services Service.objects.filter base_url url if services.count > 0 return type server _verify_service_type url type if type 'WMS' or type 'OWS' return _process_wms_service url type None None wms server elif type 'REST' return _register_arcgis_url url None None None
def manual_variable_initialization value global _MANUAL_VAR_INIT_MANUAL_VAR_INIT value
def strFile p f caseSensitive True buf type p buf_len max len p 2 ** 2 ** 2 ** 2 if not caseSensitive p p.lower while 1 r f.read buf_len - len p if not caseSensitive r r.lower bytes_read len r if bytes_read 0 return Falsel len buf + bytes_read - buf_len if l < 0 buf buf + r else buf buf[l ] + r if buf.find p ! -1 return True
def get_content b None c request.controller f request.function l 'en' format 'markmin' def openfile import ospath os.path.join request.folder 'private' 'content' l c f b + '.' + format return open_file path mode 'r' try openedfile openfile except Exception IOError l 'en'openedfile openfile if format 'markmin' html MARKMIN str T openedfile.read markmin_dict else html str T openedfile.read openedfile.close return html
def ckplayer_get_info_by_xml ckinfo e ET.XML ckinfo video_dict {'title' '' 'links' [] 'size' 0 'flashvars' ''}if '_text' in dictify e ['ckplayer']['info'][0]['title'][0] video_dict['title'] dictify e ['ckplayer']['info'][0]['title'][0]['_text'].strip if '_text' in dictify e ['ckplayer']['video'][0]['size'][0] video_dict['size'] sum [int i['size'][0]['_text'] for i in dictify e ['ckplayer']['video']] if '_text' in dictify e ['ckplayer']['video'][0]['file'][0] video_dict['links'] [i['file'][0]['_text'].strip for i in dictify e ['ckplayer']['video']]if '_text' in dictify e ['ckplayer']['flashvars'][0] video_dict['flashvars'] dictify e ['ckplayer']['flashvars'][0]['_text'].strip return video_dict
def convert_DateProperty model prop kwargs if prop.auto_now or prop.auto_now_add return Nonereturn f.DateField format '%Y-%m-%d' **kwargs
def test_eager_does_upgrade_dependecies_when_no_longer_satisfied script script.pip_install_local 'simple 1.0' expect_error True result script.pip_install_local '--upgrade' '--upgrade-strategy eager' 'require_simple' expect_error True assert script.site_packages / 'require_simple-1.0-py%s.egg-info' % pyversion not in result.files_deleted 'shouldhaveinstalledrequire_simple 1.0'assert script.site_packages / 'simple-3.0-py%s.egg-info' % pyversion in result.files_created 'shouldhaveinstalledsimple 3.0'assert script.site_packages / 'simple-1.0-py%s.egg-info' % pyversion in result.files_deleted 'shouldhaveuninstalledsimple 1.0'
def safe_str_cmp a b if isinstance a text_type a a.encode 'utf-8' if isinstance b text_type b b.encode 'utf-8' if _builtin_safe_str_cmp is not None return _builtin_safe_str_cmp a b if len a ! len b return Falserv 0if PY2 for x y in izip a b rv | ord x ^ ord y else for x y in izip a b rv | x ^ y return rv 0
def check_index ind dimension if isinstance ind list x np.array ind if x > dimension .any or x < - dimension .any raise IndexError 'Indexoutofbounds%s' % dimension elif isinstance ind slice returnelif ind > dimension raise IndexError 'Indexisnotsmallerthandimension%d> %d' % ind dimension elif ind < - dimension msg 'Negativeindexisnotgreaterthannegativedimension%d< -%d'raise IndexError msg % ind dimension
def cinder_todo_format physical_line pos physical_line.find 'TODO' pos1 physical_line.find 'TODO ' pos2 physical_line.find '#' if pos ! pos1 and pos2 > 0 and pos2 < pos return pos 'CINDERN101 UseTODO NAME '
def RunInTransaction function *args **kwargs return RunInTransactionOptions None function *args **kwargs
def get_temp_imagefilename url img _urlopen url .read im Image.open BytesIO img f tempfile.NamedTemporaryFile delete False suffix '.png' fname f.namef.close im.save fname 'PNG' return fname
@staticmethoddef PythonPartial func *args **keywords def newfunc *fargs **fkeywords newkeywords keywords.copy newkeywords.update fkeywords return func * args + fargs **newkeywords newfunc.func funcnewfunc.args argsnewfunc.keywords keywordsreturn newfunc
def all_collectors return COLLECTORS.itervalues
def directory path use_sudo False owner '' group '' mode '' func use_sudo and run_as_root or run if not is_dir path func 'mkdir-p"% path s"' % locals if owner and _owner path use_sudo ! owner or group and _group path use_sudo ! group func 'chown% owner s % group s"% path s"' % locals if mode and _mode path use_sudo ! mode func 'chmod% mode s"% path s"' % locals
def debug host 'localhost' port 6000 authkey 'secretpassword' init host port authkey qdb.do_debug
def theilslopes y x None alpha 0.95 y ma.asarray y .flatten if x is None x ma.arange len y dtype float else x ma.asarray x .flatten if len x ! len y raise ValueError 'Incompatiblelengths! %s<>%s ' % len y len x m ma.mask_or ma.getmask x ma.getmask y y._mask x._mask my y.compressed x x.compressed .astype float return stats_theilslopes y x alpha alpha
def _gem command ruby None runas None gem_bin None cmdline [ gem_bin or 'gem' ] + command if gem_bin is None if __salt__['rvm.is_installed'] runas runas return __salt__['rvm.do'] ruby cmdline runas runas if not salt.utils.is_windows and __salt__['rbenv.is_installed'] runas runas if ruby is None return __salt__['rbenv.do'] cmdline runas runas else return __salt__['rbenv.do_with_ruby'] ruby cmdline runas runas ret __salt__['cmd.run_all'] cmdline runas runas python_shell False if ret['retcode'] 0 return ret['stdout']else raise CommandExecutionError ret['stderr']
def get_steps_pkg distribution package_source PackageSource if distribution not in PACKAGED_CLIENT_DISTRIBUTIONS raise UsageError 'Distribution%rnotsupported.Availabledistributions %s' % distribution ' '.join PACKAGED_CLIENT_DISTRIBUTIONS package_manager DOCKER_IMAGES[distribution].package_managersteps [ensure_minimal_setup package_manager task_cli_pkg_install distribution package_source ]return steps
def uml_format source language css_class return u'<preclass "%s"><code>%s</code></pre>' % css_class _escape source
def dead_code_elimination graph du ud for node in graph.rpo for i ins in node.get_loc_with_ins [ ] reg ins.get_lhs if reg is not None if reg i not in du if ins.is_call ins.remove_defined_var elif ins.has_side_effect continueelse update_chain graph i du ud graph.remove_ins i
def execute_from_command_line argv None utility ManagementUtility argv utility.execute
def transform_to_group_ids group_names mapping_id identity_api resource_api def resolve_domain domain "Returndomainid.\n\nInputisadictionarywithadomainidentifiedeitherbya``id``ora\n``name``.Inthelattercasesystemwillattempttofetchdomainobject\nfromthebackend.\n\n returns domain'sid\n rtype str\n\n"domain_id domain.get 'id' or resource_api.get_domain_by_name domain.get 'name' .get 'id' return domain_idfor group in group_names try group_dict identity_api.get_group_by_name group['name'] resolve_domain group['domain'] yield group_dict['id'] except exception.GroupNotFound raise exception.MappedGroupNotFound group_id group['name'] mapping_id mapping_id
def get_theme_sass_dirs system theme_dir if system not in 'lms' 'cms' raise ValueError '"system"musteitherbe"lms"or"cms"' dirs []system_sass_dir path system / 'static' / 'sass' sass_dir theme_dir / system / 'static' / 'sass' css_dir theme_dir / system / 'static' / 'css' dependencies SASS_LOOKUP_DEPENDENCIES.get system [] if sass_dir.isdir css_dir.mkdir_p dirs.append {'sass_source_dir' system_sass_dir 'css_destination_dir' css_dir 'lookup_paths' dependencies + [ sass_dir / 'partials' system_sass_dir / 'partials' system_sass_dir] } dirs.append {'sass_source_dir' sass_dir 'css_destination_dir' css_dir 'lookup_paths' dependencies + [ sass_dir / 'partials' system_sass_dir / 'partials' system_sass_dir] } return dirs
def p_declaration_list_1 t pass
def transfer_get context transfer_id return IMPL.transfer_get context transfer_id
def validate_configuration configuration schema {'$schema' 'http //json-schema.org/draft-04/schema#' 'type' 'object' 'required' ['version' 'control-service' 'dataset'] 'properties' {'version' {'type' 'number' 'maximum' 1 'minimum' 1} 'control-service' {'type' 'object' 'required' ['hostname'] 'properties' {'hostname' {'type' 'string' 'format' 'hostname'} 'port' {'type' 'integer'}}} 'dataset' {'type' 'object' 'properties' {'backend' {'type' 'string'}} 'required' ['backend']} 'logging' {'type' 'object'}}}v Draft4Validator schema format_checker FormatChecker v.validate configuration
def get_dataset_backend test_case backend environ.get 'FLOCKER_ACCEPTANCE_VOLUME_BACKEND' if backend is None raise SkipTest 'Setacceptancetestingvolumebackendusingthe' + 'FLOCKER_ACCEPTANCE_VOLUME_BACKENDenvironmentvariable.' return backend_loader.get backend
def check_is_left name lhs rhs _split_left_right name if lhs.endswith u'/1' return Trueelif rhs.startswith u'1 ' return Trueelif rhs.endswith u'/1' return Truereturn False
def enable_caching _option _opt_str _value _parser debug.debug 'EnablingCaching' global CACHECACHE CacheTree CacheStorage invalidator Invalidator config.CACHE True
def _regexify_subfmts subfmts new_subfmts []for subfmt_tuple in subfmts subfmt_in subfmt_tuple[1]for strptime_code regex in u'%Y' u' ?P<year>\\d\\d\\d\\d ' u'%m' u' ?P<mon>\\d{1 2} ' u'%d' u' ?P<mday>\\d{1 2} ' u'%H' u' ?P<hour>\\d{1 2} ' u'%M' u' ?P<min>\\d{1 2} ' u'%S' u' ?P<sec>\\d{1 2} ' subfmt_in subfmt_in.replace strptime_code regex if u'%' not in subfmt_in subfmt_tuple subfmt_tuple[0] re.compile subfmt_in + u'$' subfmt_tuple[2] new_subfmts.append subfmt_tuple return tuple new_subfmts
def help_stream s '' * 2 usage '\n'usage + s + grey u'\u266a' + 'Switchingstreams\n' usage + s * 2 + light_green 'switchpublic#AKB' + 'willswitchtopublicstreamandfollow"' + light_yellow 'AKB' + '"keyword.\n' usage + s * 2 + light_green 'switchmine' + 'willswitchtoyourpersonalstream.\n' usage + s * 2 + light_green 'switchmine-f' + 'willprompttoenterthefilter.\n' usage + s * 3 + light_yellow 'Onlynicks' + 'filterwilldecidenickswillbeINCLUDEONLY.\n' usage + s * 3 + light_yellow 'Ignorenicks' + 'filterwilldecidenickswillbeEXCLUDE.\n' usage + s * 2 + light_green 'switchlist' + "willswitchtoaTwitterlist'sstream.Youwillbeaskedforlistname\n" printNicely usage
def strip_eps_font filename inf open filename filecache []in_ttf Falsefor line in inf if 'Bitstream' in line line line.replace 'BitstreamVeraSans-Roman' 'Arial' if line.startswith '%%BeginFont' in_ttf Trueif line.startswith '%%EndFont' in_ttf Falsecontinueif in_ttf continueelse filecache.append line inf.close ouf open filename 'w+' ouf.write ''.join filecache ouf.close
def add_edited_exploration_id user_id exploration_id user_contributions get_user_contributions user_id strict False if not user_contributions create_user_contributions user_id [] [exploration_id] elif exploration_id not in user_contributions.edited_exploration_ids user_contributions.edited_exploration_ids.append exploration_id user_contributions.edited_exploration_ids.sort _save_user_contributions user_contributions
def XcodeVersion global XCODE_VERSION_CACHEif XCODE_VERSION_CACHE return XCODE_VERSION_CACHEtry version_list GetStdout ['xcodebuild' '-version'] .splitlines if len version_list < 2 raise GypError 'xcodebuildreturnedunexpectedresults' except version CLTVersion if version version re.match ' \\d\\.\\d\\.?\\d* ' version .groups [0]else raise GypError 'NoXcodeorCLTversiondetected!' version_list [version '']version version_list[0]build version_list[ -1 ]version version.split [ -1 ].replace '.' '' version version + '0' * 3 - len version .zfill 4 if build build build.split [ -1 ]XCODE_VERSION_CACHE version build return XCODE_VERSION_CACHE
def _filter_nodes superclass all_nodes _all_nodes node_names node.__name__ for node in all_nodes if issubclass node superclass return frozenset node_names
def get_interface_language try locale_language locale.getdefaultlocale [0]except ValueError locale_language DEFAULT_LANGUAGElanguage DEFAULT_LANGUAGEif locale_language is not None spyder_languages get_available_translations for lang in spyder_languages if locale_language lang language locale_languagebreakelif locale_language.startswith lang or lang.startswith locale_language language langbreakreturn language
def _plugin_replace_role name contents plugins for p in plugins role_hook p.get_role_hook name if role_hook return role_hook contents return ' {0} `{1}`'.format name contents
def wrap_things *things if not things return []wrapped [Wrapped thing for thing in things]if hasattr things[0] 'add_props' things[0].add_props c.user wrapped return wrapped
def destroy_resource resource try resource.destroy except err None 'Destroyingresource.'
def backend_cache_page handler cache_time None cache_name None if not cache_time cache_time settings.CACHE_TIMEif not cache_name cache_name 'default'if caching_is_enabled @condition last_modified_func partial calc_last_modified cache_name cache_name @cache_control no_cache True @cache_page cache_time cache cache_name def backend_cache_page_wrapper_fn request *args **kwargs return handler request *args **kwargs else def backend_cache_page_wrapper_fn request *args **kwargs return handler request *args **kwargs return backend_cache_page_wrapper_fn
def threshold_niblack image window_size 15 k 0.2 m s _mean_std image window_size return m - k * s
def get_fontconfig_fonts fontext u'ttf' fontext get_fontext_synonyms fontext return [fname for fname in _call_fc_list if os.path.splitext fname [1][1 ] in fontext ]
def test_make_imbalance_invalid_ratio y_ np.zeros X.shape[0] y_[0] 1ratio 0.5assert_raises ValueError make_imbalance X y_ ratio
def recursive_sort obj if isinstance obj dict for v in obj.values recursive_sort v elif isinstance obj list obj.sort for i in obj recursive_sort i return obj
def install_rbenv name user None ret {'name' name 'result' None 'comment' '' 'changes' {}}if __opts__['test'] ret['comment'] 'Rbenvissettobeinstalled'return retreturn _check_and_install_rbenv ret user
def _get_version_from_pkg_info package_name try pkg_info_file open 'PKG-INFO' 'r' except IOError OSError return Nonetry pkg_info email.message_from_file pkg_info_file except email.MessageError return Noneif pkg_info.get 'Name' None ! package_name return Nonereturn pkg_info.get 'Version' None
def vstack tables join_type u'outer' metadata_conflicts u'warn' tables _get_list_of_tables tables if len tables 1 return tables[0]col_name_map OrderedDict out _vstack tables join_type col_name_map _merge_col_meta out tables col_name_map metadata_conflicts metadata_conflicts _merge_table_meta out tables metadata_conflicts metadata_conflicts return out
def reduce_list data_set seen set return [item for item in data_set if item not in seen and not seen.add item ]
def _init_log log_dir desktop.log.basic_logging PROC_NAME log_dir if os.geteuid 0 desktop.log.chown_log_dir g_user_uid g_user_gid
def skip_if_windows reason def decorator func return unittest.skipIf platform.system not in ['Darwin' 'Linux'] reason func return decorator
def _compat_name new_name compat_name None if compat_name is not None assert 'slave' in compat_name.lower assert new_name '' or 'worker' in new_name.lower new_namereturn compat_namecompat_replacements {'worker' 'slave' 'Worker' 'Slave'}compat_name new_nameassert 'slave' not in compat_name.lower assert 'worker' in compat_name.lower for new_word old_word in iteritems compat_replacements compat_name compat_name.replace new_word old_word assert compat_name ! new_name assert 'slave' in compat_name.lower assert 'worker' not in compat_name.lower return compat_name
def will_expire certificate days ret {}if os.path.isfile certificate try ret['path'] certificateret['check_days'] dayscert _get_certificate_obj certificate _check_time datetime.datetime.utcnow + datetime.timedelta days days _expiration_date cert.get_not_after .get_datetime ret['cn'] _parse_subject cert.get_subject ['CN']if _expiration_date.strftime '%Y-%m-%d%H %M %S' < _check_time.strftime '%Y-%m-%d%H %M %S' ret['will_expire'] Trueelse ret['will_expire'] Falseexcept ValueError passreturn ret
def get_script_header script_text executable sys_executable wininst False from distutils.command.build_scripts import first_line_refirst script_text + '\n' .splitlines [0]match first_line_re.match first options ''if match options match.group 1 or '' if options options '' + options if wininst executable 'python.exe'else executable nt_quote_arg executable hdr '#!% executable s% options s\n' % locals if unicode hdr 'ascii' 'ignore' .encode 'ascii' ! hdr if options if options.strip .startswith '-' options '-x' + options.strip [1 ] else options '-x'executable fix_jython_executable executable options hdr '#!% executable s% options s\n' % locals return hdr
def get_restart_freeze ret salt.utils.mac_utils.execute_return_result 'systemsetup-getrestartfreeze' return salt.utils.mac_utils.validate_enabled salt.utils.mac_utils.parse_return ret 'on'
def normalize_argv args size 0 args list args for idx val in enumerate args if to_int val is not None args[idx] to_int val if size and idx size return args[ idx]if size 0 return argsfor i in range len args size args + [None]return args
def get_cpu_temp res os.popen 'vcgencmdmeasure_temp' .readline t_cpu float res.replace 'temp ' '' .replace "'C\n" '' return t_cpu
def compare a b if HAVE_COMPARE_DIGEST return hmac.compare_digest a b result len a ^ len b for i in xrange len b result | ord a[ i % len a ] ^ ord b[i] return result 0
def GetOutputFile return rl.console
def fixb2context root root.unbind_class 'Text' '<B2>' root.unbind_class 'Text' '<B2-Motion>' root.unbind_class 'Text' '<<PasteSelection>>'
def _make_subtarget targetctx flags subtargetoptions {}if flags.boundcheck subtargetoptions['enable_boundcheck'] Trueif flags.nrt subtargetoptions['enable_nrt'] Trueerror_model callconv.create_error_model flags.error_model targetctx subtargetoptions['error_model'] error_modelreturn targetctx.subtarget **subtargetoptions
def cache_required func def wrapper self *args **kwargs if not self.has_cached_criterias log.debug u'Nonecacheddata.Synchronizing...' self.synchronize_database return func self *args **kwargs return wrapper
def _get_tz tz zone tslib.get_timezone tz if zone is None zone tslib.tot_seconds tz.utcoffset return zone
def _SeqIO_to_alignment_iterator handle format alphabet None seq_count None from Bio import SeqIOassert format in SeqIO._FormatToIterator if seq_count seq_record_iterator SeqIO.parse handle format alphabet records []for record in seq_record_iterator records.append record if len records seq_count yield MultipleSeqAlignment records alphabet records []if records raise ValueError 'Checkseq_countargument notenoughsequences?' else records list SeqIO.parse handle format alphabet if records yield MultipleSeqAlignment records alphabet
@salt.utils.decorators.which 'rar' def rar rarfile sources template None cwd None runas None if isinstance sources string_types sources [s.strip for s in sources.split ' ' ]cmd ['rar' 'a' '-idp' '{0}'.format rarfile ]cmd.extend sources return __salt__['cmd.run'] cmd cwd cwd template template runas runas python_shell False .splitlines
def clear BACKEND.clear
def test_topicsread topic user topicsread TopicsRead topicsread.user_id user.idtopicsread.topic_id topic.idtopicsread.forum_id topic.forum_idtopicsread.last_read datetime.utcnow topicsread.save assert topicsread is not None topicsread.delete topicsread TopicsRead.query.filter_by topic_id topicsread.topic_id .first assert topicsread is None
def test_line_split sp completer.CompletionSplitter t [ 'runsome/scrip' '' 'some/scrip' 'runscripts/er' 'ror.pyfoo' 'scripts/er' 'echo$HOM' '' 'HOM' 'printsys.pa' '' 'sys.pa' 'print sys.pa' '' 'sys.pa' "execfile 'scripts/er" '' 'scripts/er' 'a[x.' '' 'x.' 'a[x.' 'y' 'x.' 'cd"some_file/' '' 'some_file/' ]check_line_split sp t check_line_split sp [map str p for p in t]
def init_mappings mappings for sectname section in mappings.items for optname mapping in section.items default mapping.save_default log.config.vdebug 'Saveddefaultfor{}->{} {!r}'.format sectname optname default value config.get sectname optname log.config.vdebug 'Setting{}->{}to{!r}'.format sectname optname value mapping.set value
def _studio_wrap_xblock xblock view frag context display_name_only False if not context.get 'is_pages_view' None and view in PREVIEW_VIEWS root_xblock context.get 'root_xblock' is_root root_xblock and xblock.location root_xblock.location is_reorderable _is_xblock_reorderable xblock context template_context {'xblock_context' context 'xblock' xblock 'show_preview' context.get 'show_preview' True 'content' frag.content 'is_root' is_root 'is_reorderable' is_reorderable 'can_edit' context.get 'can_edit' True 'can_edit_visibility' context.get 'can_edit_visibility' True 'can_add' context.get 'can_add' True }html render_to_string 'studio_xblock_wrapper.html' template_context frag wrap_fragment frag html return frag
def pass_through info inner *args **kw __traceback_info__ inforeturn inner *args **kw
def decorated_dummy dec name warnings.warn 'Thefunction`decorated_dummy`isdeprecatedsinceIPython4.0' DeprecationWarning stacklevel 2 dummy lambda None dummy.__name__ namereturn dec dummy
def print_event e event_dict {'retweet' notify_retweet 'favorite' notify_favorite 'unfavorite' notify_unfavorite 'follow' notify_follow 'list_member_added' notify_list_member_added 'list_member_removed' notify_list_member_removed 'list_user_subscribed' notify_list_user_subscribed 'list_user_unsubscribed' notify_list_user_unsubscribed}event_dict.get e['event'] lambda *args None e
def peep_hash argv parser OptionParser usage 'usage %proghashfile[file...]' description 'Printapeephashlineforoneormorefiles forexample "#sha256 oz42dZy6Gowxw8AelDtO4gRgTW_xPdooH484k7I5EOY".' _ paths parser.parse_args args argv if paths for path in paths print '#sha256 ' hash_of_file path return ITS_FINE_ITS_FINEelse parser.print_usage return COMMAND_LINE_ERROR
def _atanh p x prec R p.ringone R 1 c [one]p2 rs_square p x prec for k in range 1 prec c.append one / 2 * k + 1 s rs_series_from_list p2 c x prec s rs_mul s p x prec return s
def matcher pattern txt if txt.endswith pattern txt txt[ txt.rfind pattern ].strip return not txt or txt.endswith '"' else return False
def random_powerlaw_tree_sequence n gamma 3 seed None tries 100 if seed is not None random.seed seed z nx.utils.powerlaw_sequence n exponent gamma zseq [min n max int round s 0 for s in z]z nx.utils.powerlaw_sequence tries exponent gamma swap [min n max int round s 0 for s in z]for deg in swap if 2 * n - sum zseq 2 return zseqindex random.randint 0 n - 1 zseq[index] swap.pop raise nx.NetworkXError 'Exceededmax %d attemptsforavalidtreesequence.' % tries
def run_on_appengine gdata_service store_tokens True single_user_mode False deadline None gdata_service.http_client AppEngineHttpClient deadline deadline gdata_service.token_store AppEngineTokenStore gdata_service.auto_store_tokens store_tokensgdata_service.auto_set_current_token single_user_modereturn gdata_service
def histogram_async image_data rpc None image Image image_data return image.histogram_async rpc
def placement_init global _ENFORCER_PLACEMENTif not _ENFORCER_PLACEMENT rules policy.Rules.load jsonutils.dumps {'placement' 'role admin'} _ENFORCER_PLACEMENT policy.Enforcer CONF rules rules use_conf False
def _ip_range_splitter ips block_size 256 out []count 0for ip in ips out.append ip['address'] count + 1if count > block_size - 1 yield out out []count 0if out yield out
def impl_ret_untracked ctx builder retty ret return ret
def usage parser.print_help sys.exit 2
def get_vm_id kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theget_vm_idfunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None if name is None raise SaltCloudSystemExit 'Theget_vm_idfunctionrequiresaname.' try ret list_nodes [name]['id']except KeyError raise SaltCloudSystemExit "TheVM'{0}'couldnotbefound.".format name return ret
def trim_str string max_len concat_char if len string > max_len return string[ max_len - len concat_char ] + concat_char return string
def _sniffnfix_pg9_hex value try if value[0] 'x' return binascii.unhexlify value[1 ] elif value.startswith '\\x' return binascii.unhexlify value[2 ] else return valueexcept Exception return value
def import_no_db_in_virt logical_line filename if 'nova/virt' in filename and not filename.endswith 'fake.py' if logical_line.startswith 'fromnovaimportdb' yield 0 'N307 nova.dbimportnotallowedinnova/virt/*'
def _precord_model klass further_classes set if issubclass klass PRecord attr_name '_precord_fields'else attr_name '_pclass_fields'record {u'category' u'record' u'fields' {}}for name field_info in getattr klass attr_name .items record[u'fields'][name] sorted fqpn cls for cls in field_info.type for cls in field_info.type further_classes.add cls return record further_classes
def grouped_correlation_formatter bt rhos pvals f_rhos f_pvals f_hs grouping_category category_values md_key header ['OTU'] + [ 'Rho_%s %s' % grouping_category c for c in category_values] + [ 'Pval_%s %s' % grouping_category c for c in category_values] + ['Fisherpopulationcorrelation' 'Fishercombinedp' 'Homogeneitypval' md_key] num_lines len f_rhos lines [' DCTB '.join header ]for i in range num_lines tmp_rhos [x[i] for x in rhos]tmp_pvals [x[i] for x in pvals]tmp [bt.ids axis 'observation' [i]] + tmp_rhos + tmp_pvals + [f_rhos[i]] + [f_pvals[i]] + [f_hs[i]] lines.append ' DCTB '.join map str tmp nls _add_metadata bt md_key lines return nls
def make_environment_relocatable home_dir home_dir lib_dir inc_dir bin_dir path_locations home_dir activate_this os.path.join bin_dir 'activate_this.py' if not os.path.exists activate_this logger.fatal "Theenvironmentdoesn'thaveafile%s--pleasere-runvirtualenvonthisenvironmenttoupdateit" % activate_this fixup_scripts home_dir bin_dir fixup_pth_and_egg_link home_dir
def get_network_adapter_type adapter_type if adapter_type 'vmxnet' return vim.vm.device.VirtualVmxnet elif adapter_type 'vmxnet2' return vim.vm.device.VirtualVmxnet2 elif adapter_type 'vmxnet3' return vim.vm.device.VirtualVmxnet3 elif adapter_type 'e1000' return vim.vm.device.VirtualE1000 elif adapter_type 'e1000e' return vim.vm.device.VirtualE1000e
def _quotify mystr quote '"'l len mystr for i in range l if mystr[i] '\\' and i + 1 < l and mystr[ i + 1 ] "'" quote "'"breakelif mystr[i] '\\' and i + 1 < l and mystr[ i + 1 ] '"' quote '"'breakelif mystr[i] "'" quote '"'breakelif mystr[i] '"' quote "'"breakreturn quote + mystr + quote
def addgroup name group name _cmd_quote name group _cmd_quote group .lstrip "'" .rstrip "'" user info name if not user return Falseif group in user['groups'] return Truecmd 'netlocalgroup"{0}"{1}/add'.format group name ret __salt__['cmd.run_all'] cmd python_shell True return ret['retcode'] 0
def solve_discrete_lyapunov a q complex_step False eye np.eye a.shape[0] if not complex_step aH a.conj .transpose aHI_inv np.linalg.inv aH + eye b np.dot aH - eye aHI_inv c 2 * np.dot np.dot np.linalg.inv a + eye q aHI_inv return solve_sylvester b.conj .transpose b - c else aH a.transpose aHI_inv np.linalg.inv aH + eye b np.dot aH - eye aHI_inv c 2 * np.dot np.dot np.linalg.inv a + eye q aHI_inv return solve_sylvester b.transpose b - c
def summarize text ratio 0.2 word_count None split False sentences _clean_text_by_sentences text if len sentences 0 logger.warning 'Inputtextisempty.' returnif len sentences 1 raise ValueError 'inputmusthavemorethanonesentence' if len sentences < INPUT_MIN_LENGTH logger.warning 'Inputtextisexpectedtohaveatleast' + str INPUT_MIN_LENGTH + 'sentences.' corpus _build_corpus sentences most_important_docs summarize_corpus corpus ratio ratio if word_count is None else 1 extracted_sentences _extract_important_sentences sentences corpus most_important_docs word_count extracted_sentences.sort key lambda s s.index return _format_results extracted_sentences split
def custom_check cmd ignore_retcode False p custom_popen cmd out err p.communicate if p.returncode and not ignore_retcode raise RarExecError 'Check-runfailed' return out
def test_allknn_fit allknn AllKNN random_state RND_SEED allknn.fit X Y assert_equal allknn.min_c_ 0 assert_equal allknn.maj_c_ 2 assert_equal allknn.stats_c_[0] 4 assert_equal allknn.stats_c_[1] 16 assert_equal allknn.stats_c_[2] 20
def _split_ref_line line fields line.rstrip '\n\r' .split '' if len fields ! 2 raise PackedRefsException 'invalidrefline%r' % line sha name fieldsif not valid_hexsha sha raise PackedRefsException 'Invalidhexsha%r' % sha if not check_ref_format name raise PackedRefsException 'invalidrefname%r' % name return sha name
def _guess_day_first_parameter groups if _is_int groups[0] and valid_year int groups[0][ 4] return Falseelif _is_int groups[ -1 ] and valid_year int groups[ -1 ][ -4 ] return Trueelif _is_int groups[0] and int groups[0][ 2] > 31 return Falseelif _is_int groups[ -1 ] and int groups[ -1 ][ -2 ] > 31 return True
def _get_user_info user None if not user user __salt__['config.option'] 'user' userinfo __salt__['user.info'] user if not userinfo if user 'salt' userinfo _get_user_info else raise SaltInvocationError 'User{0}doesnotexist'.format user return userinfo
def generate_relationship base direction return_fn attrname local_cls referred_cls **kw if return_fn is backref return return_fn attrname **kw elif return_fn is relationship return return_fn referred_cls **kw else raise TypeError 'Unknownrelationshipfunction %s' % return_fn
def _if_unmodified_since_passes last_modified if_unmodified_since return last_modified and last_modified < if_unmodified_since
def lorem parser token bits list token.split_contents tagname bits[0]common bits[ -1 ] ! 'random' if not common bits.pop if bits[ -1 ] in 'w' 'p' 'b' method bits.pop else method 'b'if len bits > 1 count bits.pop else count '1'count parser.compile_filter count if len bits ! 1 raise template.TemplateSyntaxError 'Incorrectformatfor%rtag' % tagname return LoremNode count method common
def check_children options for col in all_living_collectors now int time.time if col.interval 0 and col.last_datapoint < now - options.allowed_inactivity_time LOG.warning 'Terminatingcollector%safter%dsecondsofinactivity' col.name now - col.last_datapoint col.shutdown if not options.remove_inactive_collectors register_collector Collector col.name col.interval col.filename col.mtime col.lastspawn
def collapseNestedLists items pieces []for i in items if i is None pieces.extend ['' 'NIL'] elif isinstance i DontQuoteMe int long pieces.extend ['' networkString str i ] elif isinstance i bytes unicode if _needsLiteral i pieces.extend ['' '{' intToBytes len i '}' IMAP4Server.delimiter i] else pieces.extend ['' _quote i ] elif hasattr i 'read' d i.read pieces.extend ['' '{' intToBytes len d '}' IMAP4Server.delimiter d] else pieces.extend ['' ' ' + collapseNestedLists i + ' ' ] return ''.join pieces[1 ]
def approx_hess_cs x f epsilon None args kwargs {} n len x h _get_epsilon x 3 epsilon n ee np.diag h hess np.outer h h n len x for i in range n for j in range i n hess[ i j ] f * x + 1j * ee[i ] + ee[j ] + args **kwargs - f * x + 1j * ee[i ] - ee[j ] + args **kwargs .imag / 2.0 / hess[ i j ] hess[ j i ] hess[ i j ]return hess
def list_ports zone permanent True cmd '--zone {0}--list-ports'.format zone if permanent cmd + '--permanent'return __firewall_cmd cmd .split
def strongRandom size return os.urandom size
@receiver job_was_rejected def on_job_was_rejected sender job rejecting_user **kwargs send_job_review_message job rejecting_user 'jobs/email/job_was_rejected_subject.txt' 'jobs/email/job_was_rejected.txt'
def broadcast_chunks *chunkss if len chunkss 1 return chunkss[0]n max map len chunkss chunkss2 [ 1 * n - len c + c for c in chunkss]result []for i in range n step1 [c[i] for c in chunkss2]if all c 1 for c in step1 step2 step1else step2 [c for c in step1 if c ! 1 ]if len set step2 ! 1 raise ValueError 'Chunksdonotalign %s' % str step2 result.append step2[0] return tuple result
def _crop_image_vertically img target_height x y img.sizewhile y > target_height slice_height min y - target_height 10 bottom img.crop 0 y - slice_height x y top img.crop 0 0 x slice_height if _image_entropy bottom < _image_entropy top img img.crop 0 0 x y - slice_height else img img.crop 0 slice_height x y x y img.sizereturn img
def get url conn urlopen url resp conn.read conn.close return resp
def _LongestRun seq value off -1 max_run 0i 0while i < len seq run 0while i + run < len seq and seq[ i + run ] value run + 1if run > max_run off imax_run runi + 1 + run return off max_run
def incorporate_methods source destination methods default None wrapper None override False for method in methods if hasattr destination method and not override raise AttributeError 'Cannotaddmethod{!r}'.format method + "todestinationobjectasitalreadyexists.Topreventthiserrorset'override True'." if hasattr source method if wrapper is None setattr destination method getattr source method else setattr destination method wrapper source method else setattr destination method None
def from_time year 0 month 0 day 0 hours 0 minutes 0 seconds 0 microseconds 0 timezone 0 return '20151224113047.000000-480'
def encode string encoding None if type string is not ustr return stringreturn string.encode encoding or u'utf-8' u'replace'
def _process_long_opt option_parser rargs values dests arg rargs.pop 0 if ' ' in arg opt next_arg arg.split ' ' 1 rargs.insert 0 next_arg else opt argopt option_parser._match_long_opt opt option option_parser._long_opt[opt]rargs_before_processing [x for x in rargs]if option.takes_value nargs option.nargsif nargs 1 value rargs.pop 0 else value tuple rargs[0 nargs] del rargs[0 nargs]else value Noneoption.process opt value values option_parser if dests is None or option.dest in dests length_difference len rargs_before_processing - len rargs for item in [opt] + rargs_before_processing[ length_difference] yield option.dest item
def _get_head_types pat if isinstance pat pytree.NodePattern pytree.LeafPattern if pat.type is None raise _EveryNodereturn set [pat.type] if isinstance pat pytree.NegatedPattern if pat.content return _get_head_types pat.content raise _EveryNodeif isinstance pat pytree.WildcardPattern r set for p in pat.content for x in p r.update _get_head_types x return rraise Exception "Ohno!Idon'tunderstandpattern%s" % pat
def isiterable obj return hasattr obj '__iter__'
def init mpstate return CmdlongModule mpstate
def _decode_string_escape_py3 str_ return codecs.decode str_ 'unicode_escape'
def IndexYamlForQuery kind ancestor props serialized_yaml []serialized_yaml.append '-kind %s' % kind if ancestor serialized_yaml.append 'ancestor yes' if props serialized_yaml.append 'properties ' for name direction in props serialized_yaml.append '-name %s' % name if direction DESCENDING serialized_yaml.append 'direction desc' return '\n'.join serialized_yaml
def parse_taxonomy_to_otu_metadata lines labels ['taxonomy' 'score'] process_fs [taxa_split float] result {}for line in lines line line.strip fields line.split ' DCTB ' id_ fields[0].split [0]result[id_] {}for i field in enumerate fields[1 ] try label labels[i]except IndexError continuetry value process_fs[i] field except IndexError raise ValueError 'Toofewprocessfunctionsprovided n %d .' % len process_fs result[id_][label] valuereturn result
def ode_nth_linear_euler_eq_nonhomogeneous_variation_of_parameters eq func order match returns 'sol' x func.args[0]f func.funcr matchgensol ode_nth_linear_euler_eq_homogeneous eq func order match returns 'both' match.update gensol r[ -1 ] r[ -1 ] / r[ode_order eq f x ] sol _solve_variation_of_parameters eq func order match return Eq f x r['sol'].rhs + sol.rhs - r['sol'].rhs * r[ode_order eq f x ]
def column_family_definition keyspace column_family sys _sys_mgr try return vars sys.get_keyspace_column_families keyspace [column_family] except Exception log.debug 'InvalidKeyspace/CFcombination' return None
def _run_in_namespace f *args namespace namespace_manager.get_namespace try namespace_manager.set_namespace LOG_NAMESPACE return f *args finally namespace_manager.set_namespace namespace
def probability_of qty user_settings if qty in ['exercise' 'video'] return sqrt user_settings['effort_level'] * 3 * user_settings['time_in_program'] if qty 'completed' return 0.33 * user_settings['effort_level'] + 0.66 * user_settings['speed_of_learning'] * 2 * user_settings['time_in_program'] if qty 'attempts' return 0.33 * user_settings['effort_level'] + 0.55 * user_settings['time_in_program'] / probability_of 'completed' user_settings / 5
def _randint seed None if seed is None return random.randintelif isinstance seed int return random.Random seed .randintelif is_sequence seed seed list seed seed.reverse def give a b seq seed a b as_int a as_int b w b - a if w < 0 raise ValueError '_randintgotemptyrange' try x seq.pop except AttributeError raise ValueError '_randintexpectsalist-likesequence' except IndexError raise ValueError '_randintsequencewastooshort' if a < x < b return xelse return give a b seq return giveelse raise ValueError '_randintgotanunexpectedseed'
def chgid name gid root None pre_info info name if gid pre_info['gid'] return Truecmd ['usermod' '-g' '{0}'.format gid name]if root is not None cmd.extend '-R' root __salt__['cmd.run'] cmd python_shell False return info name .get 'gid' gid
def module_disabled module disable_module module reload_service 'apache2'
def html_quote string return '"%s"' % html_escape string .replace '\n' '%#10;' .replace '\r' '&#13;' .replace ' DCTB ' '&#9;'
def _get_result_type result if result.testsRun ! 1 raise ValueError '%rhasrun%dtests 1expected' % result result.testsRun total sum map len [result.errors result.failures result.unexpectedSuccesses result.expectedFailures result.skip_reasons] if total > 1 raise ValueError '%rhasmorethanonekindofresult %rfound' % result total if len result.errors > 0 return _ResultType.errorelif len result.failures > 0 return _ResultType.failureelif len result.unexpectedSuccesses > 0 return _ResultType.unexpected_successelif len result.expectedFailures > 0 return _ResultType.expected_failureelif len result.skip_reasons > 0 return _ResultType.skipelse return _ResultType.success
def profiled func @wraps func def wrapped_func *args **kwargs fn func.__name__ + '.profile' prof cProfile.Profile retval prof.runcall func *args **kwargs prof.dump_stats fn return retvalreturn wrapped_func
def ensureMinimal requiredVersion if _versionTuple psychopy.__version__ < _versionTuple requiredVersion msg _translate 'Requiredminimalversion`{}`notmet {} .' raise RuntimeError msg.format requiredVersion psychopy.__version__ return psychopy.__version__
def column *args **kwargs responsive kwargs.pop 'responsive' None sizing_mode kwargs.pop 'sizing_mode' 'fixed' children kwargs.pop 'children' None if responsive sizing_mode _convert_responsive responsive _verify_sizing_mode sizing_mode children _handle_children children children *args col_children []for item in children if isinstance item LayoutDOM item.sizing_mode sizing_modecol_children.append item else raise ValueError 'OnlyLayoutDOMitemscanbeinsertedintoacolumn.\nTriedtoinsert %softype%s' % item type item return Column children col_children sizing_mode sizing_mode **kwargs
def get_extra_args extra {}if py_version > 3 extra['use_2to3'] Truereturn extra
def null_list pages size res []for page in pages if size > 4096 size - 4096else page page[ size]for s in page.split '\x00' if s ! '' res.append s return res
def test_no_shadowed_builtins driver create_clidriver help_command driver.create_help_command top_level_params set driver.create_help_command .arg_table errors []for command_name command_obj in help_command.command_table.items sub_help command_obj.create_help_command if hasattr sub_help 'command_table' for sub_name sub_command in sub_help.command_table.items op_help sub_command.create_help_command arg_table op_help.arg_tablefor arg_name in arg_table if any p.startswith arg_name for p in top_level_params errors.append 'Shadowing/Prefixingatopleveloption %s.%s.%s' % command_name sub_name arg_name if errors raise AssertionError '\n' + '\n'.join errors
def get_fullnames ret frappe.db.sql u'selectname full_nameasfullname \n DCTB DCTB DCTB user_imageasimage gender email username\n DCTB DCTB fromtabUserwhereenabled 1anduser_type! "WebsiteUser"' as_dict 1 d {}for r in ret d[r.name] rreturn d
def load_tables words []utable numpy.load path_to_tables + 'utable.npy' btable numpy.load path_to_tables + 'btable.npy' f open path_to_tables + 'dictionary.txt' 'rb' for line in f words.append line.decode 'utf-8' .strip f.close utable OrderedDict zip words utable btable OrderedDict zip words btable return utable btable
@pytest.mark.parametrize u'text1 text2' [ u'phantom' u'opera' ] def test_vocab_lexeme_hash en_vocab text1 text2 lex1 en_vocab[text1]lex2 en_vocab[text2]lexes {lex1 lex1 lex2 lex2}assert lexes[lex1].orth_ text1 assert lexes[lex2].orth_ text2
def is_css_file path ext os.path.splitext path [1].lower return ext in [u'.css']
def color text color_code readline False if sys.platform 'win32' and os.getenv 'TERM' ! 'xterm' return str text if readline return '\x01\x1b[%dm\x02%s\x01\x1b[0m\x02' % color_code text return '\x1b[%dm%s\x1b[0m' % color_code text
def set_buildoverrides_facts facts if 'buildoverrides' in facts buildoverrides facts['buildoverrides']if 'config' in buildoverrides if 'admission_plugin_config' not in facts['master'] facts['master']['admission_plugin_config'] dict facts['master']['admission_plugin_config'].update buildoverrides['config'] return facts
def cholesky a lower False l u _cholesky a if lower return lelse return u
def encodeString string encodedString ''try for char in string octal '%o' % ord char encodedString + '\\' + 3 - len octal * '0' + octal except return -1 'Errorencodingstring' return 0 encodedString
def get_channel_layer alias u'default' if django.VERSION[1] > 9 django.setup set_prefix False else django.setup return channel_layers[alias].channel_layer
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def swap16 value return value & 255 << 8 | value >> 8
def is_shadowed identifier ip return identifier in ip.user_ns or identifier in ip.user_global_ns or identifier in ip.ns_table['builtin'] or iskeyword identifier
def copymode src dst if hasattr os 'chmod' st os.stat src mode stat.S_IMODE st.st_mode os.chmod dst mode
def _sweep_poly_phase t poly intpoly polyint poly phase 2 * pi * polyval intpoly t return phase
def genlaguerre n alpha monic False if alpha < -1 raise ValueError 'alphamustbe>-1' if n < 0 raise ValueError 'nmustbenonnegative.' if n 0 n1 n + 1 else n1 n x w mu0 roots_genlaguerre n1 alpha mu True wfunc lambda x exp - x * x ** alpha if n 0 x w [] [] hn _gam n + alpha + 1 / _gam n + 1 kn -1 ** n / _gam n + 1 p orthopoly1d x w hn kn wfunc 0 inf monic lambda x eval_genlaguerre n alpha x return p
def imul a b a * breturn a
def test_stratified_dataset_k_fold skip_if_no_sklearn mapping {'dataset_iterator' 'StratifiedDatasetKFold'}test_yaml test_yaml_dataset_iterator % mapping trainer yaml_parse.load test_yaml trainer.main_loop
def LoginServiceRedirect dest_url endpoint ah_url outfile redirect_url '%s?%s %s' % endpoint CONTINUE_PARAM urllib.quote '%s?%s %s' % ah_url CONTINUE_PARAM dest_url outfile.write 'Status 302RedirectingtologinserviceURL\r\n' outfile.write 'Location %s\r\n' % redirect_url outfile.write '\r\n'
def tuple2keyevent past_event return QKeyEvent *past_event
def _convert_to_idn url parts list urlparse.urlsplit url try parts[1].encode u'ascii' except UnicodeEncodeError host parts[1].rsplit u' ' 1 newhost []port u''if len host 2 port host.pop for h in host[0].split u'.' newhost.append h.encode u'idna' .decode u'utf-8' parts[1] u'.'.join newhost if port parts[1] + u' ' + port return urlparse.urlunsplit parts else return url
def limited func def f standard False **args insert_pos len inline_stack.names res func **args if len res > LINE_LEN_LIMIT name inline_stack.require u'LONG' inline_stack.names.pop inline_stack.names.insert insert_pos name res u'def%s var var \nreturn%s\n' % name res inline_stack.define name res return name + u' ' else return resf.__dict__[u'standard'] funcreturn f
def entry_choices user page for entry in wizard_pool.get_entries if entry.user_has_add_permission user page page yield entry.id entry.title
def make_spiral num_points 100 num_turns 4 height 12 radius 2.0 xnot None ynot None znot None coords_list []znot -4 if znot is None else znot xnot radius if xnot is None else xnot ynot 0 if ynot is None else ynot theta_not np.arctan2 ynot xnot coords_list.append xnot ynot znot for point in range num_points znot + height / num_points theta_not + 2 * np.pi * num_turns / num_points xnot np.cos theta_not * radius ynot np.sin theta_not * radius coords_list.append xnot ynot znot return coords_list
def monthdelta date delta m y date.month + delta % 12 date.year + date.month + delta - 1 // 12 if not m m 12d min date.day [31 29 if y % 4 0 and not y % 400 0 else 28 31 30 31 30 31 31 30 31 30 31][ m - 1 ] return date.replace day d month m year y
def string_camelcase string return CAMELCASE_INVALID_CHARS.sub '' string.title
def rel_href src dst src_dir os.path.dirname src return os.path.relpath dst src_dir
def key_value minion_id pillar pillar_key 'redis_pillar' key_type __salt__['redis.key_type'] minion_id if key_type 'string' return {pillar_key __salt__['redis.get_key'] minion_id }elif key_type 'hash' return {pillar_key __salt__['redis.hgetall'] minion_id }elif key_type 'list' list_size __salt__['redis.llen'] minion_id if not list_size return {}return {pillar_key __salt__['redis.lrange'] minion_id 0 list_size - 1 }elif key_type 'set' return {pillar_key __salt__['redis.smembers'] minion_id }elif key_type 'zset' set_size __salt__['redis.zcard'] minion_id if not set_size return {}return {pillar_key __salt__['redis.zrange'] minion_id 0 set_size - 1 }return {}
def assert_array_identical a b assert_array_equal a b assert_equal a.dtype.type b.dtype.type
def get_all_objects gc.collect gcl gc.get_objects olist {}_getr gcl olist del olist[id olist ]del olist[id gcl ]del olist[id sys._getframe ]return olist
def _get_mri_header fname import nibabel as nibimg nib.load fname try return img.headerexcept AttributeError return img.get_header
def for_int_dtypes_combination names 'dtype' no_bool False full None if no_bool types _int_dtypeselse types _int_bool_dtypesreturn for_dtypes_combination types names full
def chown_for_id_maps path id_maps uid_maps_str ' '.join [_id_map_to_config id_map for id_map in id_maps if isinstance id_map vconfig.LibvirtConfigGuestUIDMap ] gid_maps_str ' '.join [_id_map_to_config id_map for id_map in id_maps if isinstance id_map vconfig.LibvirtConfigGuestGIDMap ] execute 'nova-idmapshift' '-i' '-u' uid_maps_str '-g' gid_maps_str path run_as_root True
def changeset_revision_reviewed_by_user user repository changeset_revision for review in repository.reviews if review.changeset_revision changeset_revision and review.user user return Truereturn False
def empty_assets_db return tmp_assets_db equities None
def javadoc registry xml_parent data root XML.SubElement xml_parent 'hudson.tasks.JavadocArchiver' if 'directory' in data XML.SubElement root 'javadocDir' .text data.get 'directory' '' XML.SubElement root 'keepAll' .text str data.get 'keep-all-successful' False .lower
def is_symbolic_batch batch return _is_batch_all batch lambda x isinstance x theano.gof.Variable
def hosting_service_url_test_view request repo_id return HttpResponse str repo_id
def reverse_bisect_left a x lo 0 hi None if lo < 0 raise ValueError 'lomustbenon-negative' if hi is None hi len a while lo < hi mid lo + hi // 2 if x > a[mid] hi midelse lo mid + 1 return lo
def get_installed_categories shop return configuration.get shop SAMPLE_CATEGORIES_KEY or []
def make_variant_item_code template_item_code variant if variant.item_code returnabbreviations []for attr in variant.attributes item_attribute frappe.db.sql u'selecti.numeric_values v.abbr\n DCTB DCTB DCTB from`tabItemAttribute`ileftjoin`tabItemAttributeValue`v\n DCTB DCTB DCTB DCTB on i.name v.parent \n DCTB DCTB DCTB wherei.name % attribute sandv.attribute_value % attribute_value s' {u'attribute' attr.attribute u'attribute_value' attr.attribute_value} as_dict True if not item_attribute returnif item_attribute[0].numeric_values returnabbreviations.append item_attribute[0].abbr if abbreviations variant.item_code u'{0}-{1}'.format template_item_code u'-'.join abbreviations if variant.item_code variant.item_name variant.item_code
@constructordef argmin x axis None keepdims False x as_tensor_variable x str_x_type str x.dtype if str_x_type.startswith 'float' or str_x_type in int_dtypes return argmax - x axis axis keepdims keepdims else raise NotImplementedError
def imt token i None m None t None clss itypes [t] if t and not isinstance t list else t mpatterns [m] if m and not isinstance m list else m if token is None return Falseelif clss and isinstance token clss return Trueelif mpatterns and any token.match *pattern for pattern in mpatterns return Trueelif types and any [ token.ttype in ttype for ttype in types] return Trueelse return False
def write_logline logfile msg timestamp_format None msg msg.rstrip '\n' if timestamp_format msg prepend_timestamp msg timestamp_format logfile.write msg + '\n'
def get_profile_pictures_by_user_ids user_ids user_settings_models user_models.UserSettingsModel.get_multi user_ids result {}for model in user_settings_models if model result[model.id] model.profile_picture_data_urlelse result[model.id] Nonereturn result
def init_addon app addon_name routes True import_path 'website.addons.{0}'.format addon_name addon_module importlib.import_module import_path data vars addon_module data['description'] settings.ADDONS_DESCRIPTION.get addon_name '' data['url'] settings.ADDONS_URL.get addon_name None return AddonConfig **{key.lower value for key value in data.iteritems }
def queue_instances instances for instance_id in instances node _get_node instance_id instance_id for name in node if instance_id node[name]['instanceId'] __utils__['cloud.cache_node'] node[name] __active_provider_name__ __opts__
def getTransferredSurroundingLoops insides loop transferredSurroundings []for insideIndex in xrange len insides - 1 -1 -1 insideSurrounding insides[insideIndex]if isPathInsideLoop loop insideSurrounding.boundary transferredSurroundings.append insideSurrounding del insides[insideIndex]return transferredSurroundings
def get_same_name_files files_path_list filename same_name_files []for fname in files_path_list if filename os.path.basename fname same_name_files.append path_components fname return same_name_files
def _pad input _len len input if _len Card.length return inputelif _len > Card.length strlen _len % Card.length if strlen 0 return inputelse return input + '' * Card.length - strlen else strlen _len % Card.length return input + '' * Card.length - strlen
def send_flowgram_to_socket identifier flowgram socket trim False if trim flowgram flowgram.getQualityTrimmedFlowgram if not hasattr flowgram 'spaced_flowgram' spaced_flowgram_seq ''.join map str flowgram.flowgram flowgram.spaced_flowgram spaced_flowgram_seqelse spaced_flowgram_seq flowgram.spaced_flowgramdata '%s%d%s\n' % identifier len flowgram spaced_flowgram_seq save_send socket data
def disable_trace global app_or_defaultapp_or_default _app_or_default
@mock_opsworks@mock_ec2def test_ec2_integration opsworks boto3.client u'opsworks' region_name u'us-east-1' stack_id opsworks.create_stack Name u'S1' Region u'us-east-1' ServiceRoleArn u'service_arn' DefaultInstanceProfileArn u'profile_arn' [u'StackId']layer_id opsworks.create_layer StackId stack_id Type u'custom' Name u'S1L1' Shortname u'S1L1' [u'LayerId']instance_id opsworks.create_instance StackId stack_id LayerIds [layer_id] InstanceType u't2.micro' [u'InstanceId']ec2 boto3.client u'ec2' region_name u'us-east-1' reservations ec2.describe_instances [u'Reservations']assert reservations.should.be.emptyopsworks.start_instance InstanceId instance_id reservations ec2.describe_instances [u'Reservations']reservations[0][u'Instances'].should.have.length_of 1 instance reservations[0][u'Instances'][0]opsworks_instance opsworks.describe_instances StackId stack_id [u'Instances'][0]instance[u'InstanceId'].should.equal opsworks_instance[u'Ec2InstanceId'] instance[u'PrivateIpAddress'].should.equal opsworks_instance[u'PrivateIp']
def _get_track_function_for_task student xmodule_instance_args None source_page 'x_module_task' request_info xmodule_instance_args.get 'request_info' {} if xmodule_instance_args is not None else {} task_info {'student' student.username 'task_id' _get_task_id_from_xmodule_args xmodule_instance_args }return lambda event_type event task_track request_info task_info event_type event page source_page
def state_name sname return sname.split '.' 1 [0]
def pop_percentile image selem out None mask None shift_x False shift_y False p0 0 p1 1 return _apply percentile_cy._pop image selem out out mask mask shift_x shift_x shift_y shift_y p0 p0 p1 p1
def _get_truncated_setting_value value max_length None if isinstance value basestring and max_length is not None and len value > max_length return value[0 max_length] True else return value False
def load_biosql_ini DBTYPE if not os.path.isfile 'biosql.ini' raise MissingExternalDependencyError 'BioSQLtestconfigurationfilebiosql.inimissing seebiosql.ini.sample ' config configparser.ConfigParser config.read 'biosql.ini' DBHOST config.get DBTYPE 'dbhost' DBUSER config.get DBTYPE 'dbuser' DBPASSWD config.get DBTYPE 'dbpasswd' TESTDB config.get DBTYPE 'testdb' return DBHOST DBUSER DBPASSWD TESTDB
def check_ignore_error ignore_error stderr if not ignore_error or not stderr return Falseif not isinstance ignore_error six.string_types ignore_error '|'.join ignore_error if re.search ignore_error stderr return Truereturn False
def destroy instance_id call None if call 'function' raise SaltCloudSystemExit 'Thedestroyactionmustbecalledwith-d --destroy -aor--action.' instance_data show_instance instance_id call 'action' name instance_data['instance_name']__utils__['cloud.fire_event'] 'event' 'destroyinginstance' 'salt/cloud/{0}/destroying'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] params {'action' 'TerminateInstances' 'zone' _get_specified_zone provider get_configured_provider 'instances.1' instance_id}result query params __utils__['cloud.fire_event'] 'event' 'destroyedinstance' 'salt/cloud/{0}/destroyed'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def merge_section_dicts lower higher for name in higher if name in lower lower[name].update higher[name] ignore_defaults True else lower[name] higher[name]return lower
def check_ambigous flowgram max_allowed 4 if max_allowed < 3 raise ValueError 'Errorincallingcheck_ambigous.max_allowedshouldbeatleast3' count 0for signal in flowgram.flowgram if signal < 0.5 count + 1if count > max_allowed return Trueelse count 0return False
def fixed_ip_count_by_project context project_id session None return IMPL.fixed_ip_count_by_project context project_id session session
def get_dirs_in_path file_path names os.listdir file_path result []for name in names full_path os.path.join file_path name if not os.path.isdir full_path continueresult.append full_path return result
def reorder_coords coords sample_ids order try result array [coords[sample_ids.index sample_id ] for sample_id in order] except ValueError raise ValueError 'UnknownsampleID %s' % sample_id return result
def testEnabledDataStore psychopy_mon_name 'testMonitor'exp_code 'gap_endo_que'io launchHubServer psychopy_monitor_name psychopy_mon_name experiment_code exp_code display io.devices.displayprint 'DisplayPsychopyMonitorName ' display.getPsychopyMonitorName print 'DisplayDefaultEyeDistance ' display.getDefaultEyeDistance print 'DisplayPhysicalDimensions ' display.getPhysicalDimensions from pprint import pprintprint 'ExperimentMetadata ' pprint io.getExperimentMetaData print '\nSessionMetadata ' pprint io.getSessionMetaData io.quit
def getDoubledRoundZ overhangingSegment segmentRoundZ endpoint overhangingSegment[0]roundZ endpoint.point - endpoint.otherEndpoint.point roundZ * segmentRoundZif abs roundZ 0.0 return complex if roundZ.real < 0.0 roundZ * -1.0 roundZLength abs roundZ return roundZ * roundZ / roundZLength
def mask_password cmd if len cmd > 3 and cmd[0] 'raidcom' and cmd[1] '-login' tmp list cmd tmp[3] strutils.mask_dict_password {'password' ''} .get 'password' else tmp cmdreturn ''.join [six.text_type c for c in tmp]
def in6_getscope addr if in6_isgladdr addr or in6_isuladdr addr scope IPV6_ADDR_GLOBALelif in6_islladdr addr scope IPV6_ADDR_LINKLOCALelif in6_issladdr addr scope IPV6_ADDR_SITELOCALelif in6_ismaddr addr if in6_ismgladdr addr scope IPV6_ADDR_GLOBALelif in6_ismlladdr addr scope IPV6_ADDR_LINKLOCALelif in6_ismsladdr addr scope IPV6_ADDR_SITELOCALelif in6_ismnladdr addr scope IPV6_ADDR_LOOPBACKelse scope -1 elif addr ' 1' scope IPV6_ADDR_LOOPBACKelse scope -1 return scope
def _get_classifier lang cls lang 'Perl' and PerlClassifier or UDLClassifier return cls
def get_ca_certs_path CA_CERTS ['/opt/datadog-agent/embedded/ssl/certs/cacert.pem' os.path.join os.path.dirname tornado.__file__ 'ca-certificates.crt' '/etc/ssl/certs/ca-certificates.crt']for f in CA_CERTS if os.path.exists f return freturn None
def jpxEncode stream encodedStream ''return -1 'JpxEncodenotsupportedyet'
def _compute_breadcrumbs path show_hidden False breadcrumbs []breadcrumbs.append '[root]' '/' path_parts path.split '/' [1 -1 ]full_path '/'for part in path_parts full_path + part + '/' url_append ''if show_hidden url_append '?hidden 1'breadcrumbs.append part full_path + url_append return breadcrumbs
def test_constant_folding x tensor.dvector mode theano.compile.get_mode 'FAST_COMPILE' .excluding 'fusion' f theano.function [x] [ x * 2 x + x ] mode mode topo f.maker.fgraph.toposort assert len topo 2 x tensor.constant 3 assert x.ndim 0 mode theano.compile.get_mode 'FAST_COMPILE' .excluding 'fusion' f theano.function [] [ x * 2 x + x ] mode mode topo f.maker.fgraph.toposort assert len topo 2 assert all [isinstance n.op DeepCopyOp for n in topo]
def restart_process name run_as_root 'supervisorctlrestart% name s' % locals
def bigaddrspacetest f def wrapper self if max_memuse < MAX_Py_ssize_t if verbose sys.stderr.write 'Skipping%sbecauseofmemoryconstraint\n' % f.__name__ else return f self return wrapper
def calc_circumcenters tetrahedrons num tetrahedrons.shape[0]a np.concatenate tetrahedrons np.ones num 4 1 axis 2 sums np.sum tetrahedrons ** 2 axis 2 d np.concatenate sums[ np.newaxis] a axis 2 dx np.delete d 1 axis 2 dy np.delete d 2 axis 2 dz np.delete d 3 axis 2 dx np.linalg.det dx dy - np.linalg.det dy dz np.linalg.det dz a np.linalg.det a nominator np.vstack dx dy dz denominator 2 * a return nominator / denominator .T
def _handleModelRunnerException jobID modelID jobsDAO experimentDir logger e msg StringIO.StringIO print >>msg 'Exceptionoccurredwhilerunningmodel%s %r %s ' % modelID e type e traceback.print_exc None msg completionReason jobsDAO.CMPL_REASON_ERRORcompletionMsg msg.getvalue logger.error completionMsg if type e is not InvalidConnectionException jobsDAO.modelUpdateResults modelID results None numRecords 0 if type e JobFailException workerCmpReason jobsDAO.jobGetFields jobID ['workerCompletionReason'] [0]if workerCmpReason ClientJobsDAO.CMPL_REASON_SUCCESS jobsDAO.jobSetFields jobID fields dict cancel True workerCompletionReason ClientJobsDAO.CMPL_REASON_ERROR workerCompletionMsg ' '.join str i for i in e.args useConnectionID False ignoreUnchanged True return completionReason completionMsg
def rfft inp norm None s inp.shape[1 ]cond_norm _unitary norm scaling 1if cond_norm 'ortho' scaling T.sqrt s.prod .astype inp.dtype return rfft_op inp s / scaling
def parseParam line if line '' return None '' elif line[0 1] ! '"' mode 1else mode 2res ''io BytesIO line if mode 2 io.read 1 while 1 a io.read 1 if a '"' if mode 2 io.read 1 return res io.read elif a '\\' a io.read 1 if a '' return None line elif a '' if mode 1 return res io.read else return None line elif a '' if mode 1 return res io.read res + a
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def get_active_web_certificate course is_preview_mode None certificates getattr course 'certificates' '{}' configurations certificates.get 'certificates' [] for config in configurations if config.get 'is_active' or is_preview_mode return configreturn None
def getHeuristicCharEncoding page retVal detect page ['encoding']if retVal infoMsg "heuristicsdetectedwebpagecharset'%s'" % retVal singleTimeLogMessage infoMsg logging.INFO retVal return retVal
@task@needs 'clean' 'clean_bootstrap' def nuke for d in [options.superpack.builddir options.installers.releasedir] if os.path.exists d shutil.rmtree d
def paste_deploy_app paste_config_file app_name conf setup_paste_factories conf try return deploy.loadapp 'config %s' % paste_config_file name app_name finally teardown_paste_factories
def test_sub_module defs jedi.Script 'fromjedi.apiimportclasses;classes' .goto_definitions assert [d.full_name for d in defs] ['jedi.api.classes'] defs jedi.Script 'importjedi.api;jedi.api' .goto_definitions assert [d.full_name for d in defs] ['jedi.api']
def getAdapterFactory fromInterface toInterface default self globalRegistryif not isinstance fromInterface interface.InterfaceClass fromInterface declarations.implementedBy fromInterface factory self.lookup1 fromInterface toInterface if factory is None factory defaultreturn factory
def fake_plug_vifs *args **kwargs pass
def _brick_get_connector_properties multipath False enforce_multipath False return DEFAULT_CONNECTOR
def DrtVariableExpression variable if is_indvar variable.name return DrtIndividualVariableExpression variable elif is_funcvar variable.name return DrtFunctionVariableExpression variable elif is_eventvar variable.name return DrtEventVariableExpression variable else return DrtConstantExpression variable
def test_ada_init ratio 'auto'ada ADASYN ratio ratio random_state RND_SEED assert_equal ada.random_state RND_SEED
def has_roles var roles match_all False var_roles getattr var.tag 'roles' [] matches any isinstance var_role role.__class__ for var_role in var_roles for role in roles return all matches if match_all else any matches
def get_port_from_device device LOG.debug _ 'get_port_from_device called' session db.get_session sg_binding_port sg_db.SecurityGroupPortBinding.port_idquery session.query models_v2.Port sg_db.SecurityGroupPortBinding.security_group_id query query.outerjoin sg_db.SecurityGroupPortBinding models_v2.Port.id sg_binding_port query query.filter models_v2.Port.id.startswith device port_and_sgs query.all if not port_and_sgs returnport port_and_sgs[0][0]plugin manager.QuantumManager.get_plugin port_dict plugin._make_port_dict port port_dict['security_groups'] []for port_in_db sg_id in port_and_sgs if sg_id port_dict['security_groups'].append sg_id port_dict['security_group_rules'] []port_dict['security_group_source_groups'] []port_dict['fixed_ips'] [ip['ip_address'] for ip in port['fixed_ips']]return port_dict
def call_fp_intrinsic builder name args mod builder.moduleintr lc.Function.intrinsic mod name [a.type for a in args] return builder.call intr args
def _execute q table context model context['model']session model.Sessionreturn session.execute q
def trg_redirect uid res_type res_id new_rid cr assert isinstance new_rid long int return WorkflowService.new cr uid res_type res_id .redirect new_rid
def versionstring build True extra True if build first 3else first 2s '.'.join str n for n in __version__[ first] if build and extra s + ''.join str n for n in __version__[3 ] return s
def simpleOpenIDTransformer endpoint if 'http //openid.net/signon/1.0' not in endpoint.type_uris return Nonedelegates list endpoint.service_element.findall '{http //openid.net/xmlns/1.0}Delegate' assert len delegates 1 delegate delegates[0].textreturn endpoint.uri delegate
def subrange_exercise mult lb ub m MultisetPartitionTraverser assert m.count_partitions mult m.count_partitions_slow mult ma MultisetPartitionTraverser mc MultisetPartitionTraverser md MultisetPartitionTraverser a_it ma.enum_range mult lb ub b_it part_range_filter multiset_partitions_taocp mult lb ub c_it part_range_filter mc.enum_small mult ub lb sum mult d_it part_range_filter md.enum_large mult lb 0 ub for sa sb sc sd in zip_longest a_it b_it c_it d_it assert compare_multiset_states sa sb assert compare_multiset_states sa sc assert compare_multiset_states sa sd
def capture_output environ start_response application warnings.warn 'wsgilib.capture_outputhasbeendeprecatedinfavorofwsgilib.intercept_output' DeprecationWarning 2 data []output StringIO def replacement_start_response status headers exc_info None if data data[ ] []data.append status data.append headers start_response status headers exc_info return output.writeapp_iter application environ replacement_start_response try for item in app_iter output.write item finally if hasattr app_iter 'close' app_iter.close if not data data.append None if len data < 2 data.append None data.append output.getvalue return data
def addGeometryList elementNode faces for face in faces faceElement xml_simple_reader.ElementNode face.addToAttributes faceElement.attributes faceElement.localName 'face'faceElement.parentNode elementNodeelementNode.childNodes.append faceElement
def make_fastq_single in_fasta quals out_fp label_transform split_lib_transform outfile open out_fp 'w' for rec seq_id in iter_fastq in_fasta quals label_transform outfile.write rec + '\n' outfile.close
def _get_code_w_scope data position obj_end opts element_name code_end position + _UNPACK_INT data[position position + 4 ] [0] code position _get_string data position + 4 code_end opts element_name scope position _get_object data position code_end opts element_name if position ! code_end raise InvalidBSON 'scopeoutsideofjavascriptcodeboundaries' return Code code scope position
@get '/scan/<taskid>/log' def scan_log taskid json_log_messages list if taskid not in DataStore.tasks logger.warning '[%s]InvalidtaskIDprovidedtoscan_log ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} for time_ level message in DataStore.current_db.execute 'SELECTtime level messageFROMlogsWHEREtaskid ?ORDERBYidASC' taskid json_log_messages.append {'time' time_ 'level' level 'message' message} logger.debug '[%s]Retrievedscanlogmessages' % taskid return jsonize {'success' True 'log' json_log_messages}
def get_parsed text return str TemplateParser text
def assertDimensions self x y w h win None if win is None win self.c.windowinfo win.info assert info['x'] x infoassert info['y'] y infoassert info['width'] w infoassert info['height'] h info
def _get_title_from_contents meta_data piece meta_data[ ]title Nonefor i line in enumerate piece if re_rst_title.findall line and i > 0 title meta_data[ i - 1 ].strip breakif re_rst_title.findall line and i > 0 and re_rst_title.findall meta_data[ i + 2 ] title meta_data[ i + 1 ].strip breakif re_md_title.findall line title re_md_title.findall line [0]breakreturn title
def pythonize_name name s1 _first_cap_regex.sub '\\1_\\2' name s2 _number_cap_regex.sub '\\1_\\2' s1 return _end_cap_regex.sub '\\1_\\2' s2 .lower
def computeNearestNeighbor username users distances []for user in users if user ! username distance manhattan users[user] users[username] distances.append distance user distances.sort return distances
def parse_human_timedelta s cal parsedatetime.Calendar dttm dttm_from_timtuple datetime.now .timetuple d cal.parse s dttm [0]d datetime d.tm_year d.tm_mon d.tm_mday d.tm_hour d.tm_min d.tm_sec return d - dttm
def Deterministic name var model None model modelcontext model var.name model.name_for name model.deterministics.append var model.add_random_variable var return var
def get_declared_fields bases attrs with_base_fields True fields [ field_name attrs.pop field_name for field_name obj in attrs.items if isinstance obj Field ]fields.sort lambda x y cmp x[1].creation_counter y[1].creation_counter if with_base_fields for base in bases[ -1 ] if hasattr base 'base_fields' fields base.base_fields.items + fields else for base in bases[ -1 ] if hasattr base 'declared_fields' fields base.declared_fields.items + fields return SortedDict fields
def apply_parallel function array chunks None depth 0 mode None extra_arguments extra_keywords {} if not dask_available raise RuntimeError "Couldnotimport'dask'.Pleaseinstallusing'pipinstalldask'" if chunks is None shape array.shapetry ncpu cpu_count except NotImplementedError ncpu 4chunks _get_chunks shape ncpu if mode 'wrap' mode 'periodic'elif mode 'symmetric' mode 'reflect'elif mode 'edge' mode 'nearest'def wrapped_func arr return function arr *extra_arguments **extra_keywords darr da.from_array array chunks chunks return darr.map_overlap wrapped_func depth boundary mode .compute
def send_followup_email_for_monthly_fee_payment email event_name date amount payment_url send_email to email action MONTHLY_PAYMENT_FOLLOWUP_EMAIL subject MAILS[MONTHLY_PAYMENT_FOLLOWUP_EMAIL]['subject'].format event_name event_name date date html MAILS[MONTHLY_PAYMENT_FOLLOWUP_EMAIL]['message'].format event_name event_name date date payment_url payment_url amount amount app_name get_settings ['app_name']
def name_to_cat fname cat None if cat is None and fname.startswith '{{' n fname.find '}}' if n > 2 cat fname[2 n].strip fname fname[ n + 2 ].strip logging.debug 'Job%shascategory%s' fname cat return fname cat
def ec2_add_priv_launch_key argument_table operation_model session **kwargs argument_table['priv-launch-key'] LaunchKeyArgument session operation_model 'priv-launch-key'
def get_account_by_id account_id account Account.query.filter Account.id account_id .first manager_class account_registry.get account.account_type.name account manager_class ._load account db.session.expunge account return account
def attr_gt accessing_obj accessed_obj *args **kwargs return attr accessing_obj accessed_obj *args **{'compare' 'gt'}
def get_object_range page page_size max_id 5start min page - 1 * page_size max_id end min start + page_size max_id + 1 return range start end
def sign_int message dkey n return decrypt_int message dkey n
def submittable_timestamp timestamp return str timezone.localtime timestamp .split u'.' [0]
def get_portaudio_version return pa.get_version
def _strip_exc exc return re.sub '^Command[\\\'"].+[\\\'"]failed ' '' exc.strerror
def header_elements fieldname fieldvalue if not fieldvalue return []result []for element in fieldvalue.split ' ' if fieldname.startswith 'Accept' or fieldname 'TE' hv AcceptElement.from_str element else hv HeaderElement.from_str element result.append hv return list reversed sorted result
def make_model_tuple model try if isinstance model tuple model_tuple modelelif isinstance model str app_label model_name model.split '.' model_tuple app_label model_name.lower else model_tuple model._meta.app_label model._meta.model_name assert len model_tuple 2 return model_tupleexcept ValueError AssertionError raise ValueError "Invalidmodelreference'%s'.Stringmodelreferencesmustbeoftheform'app_label.ModelName'." % model
def restore_echo fdesc sys.stdin.fileno attrs termios.tcgetattr fdesc attrs[3] attrs[3] | termios.ECHO termios.tcsetattr fdesc termios.TCSADRAIN attrs
def get_return_value answer gateway_client target_id None name None if is_error answer [0] if len answer > 1 type answer[1]value OUTPUT_CONVERTER[type] answer[2 ] gateway_client if answer[1] REFERENCE_TYPE raise Py4JJavaError u'Anerroroccurredwhilecalling{0}{1}{2}.\n'.format target_id u'.' name value else raise Py4JError u'Anerroroccurredwhilecalling{0}{1}{2}.Trace \n{3}\n'.format target_id u'.' name value else raise Py4JError u'Anerroroccurredwhilecalling{0}{1}{2}'.format target_id u'.' name else type answer[1]if type VOID_TYPE returnelse return OUTPUT_CONVERTER[type] answer[2 ] gateway_client
def abspardir path return osp.abspath osp.join path os.pardir
def copy_globals source globs only_names None ignore_missing_names False names_to_ignore dunder_names_to_keep '__implements__' '__all__' '__imports__' cleanup_globs True if only_names if ignore_missing_names items k getattr source k _NONE for k in only_names else items k getattr source k for k in only_names else items iteritems source.__dict__ copied []for key value in items if value is _NONE continueif key in names_to_ignore continueif key.startswith '__' and key not in dunder_names_to_keep continueglobs[key] valuecopied.append key if cleanup_globs if 'copy_globals' in globs del globs['copy_globals']return copied
def _group_or_org_revision_list context data_dict model context['model']id _get_or_bust data_dict 'id' group model.Group.get id if group is None raise NotFoundrevision_dicts []for revision object_revisions in group.all_related_revisions revision_dicts.append model.revision_as_dict revision include_packages False include_groups False return revision_dicts
def normalize b a num den b a den np.atleast_1d den num np.atleast_2d _align_nums num if den.ndim ! 1 raise ValueError 'Denominatorpolynomialmustberank-1array.' if num.ndim > 2 raise ValueError 'Numeratorpolynomialmustberank-1orrank-2array.' if np.all den 0 raise ValueError 'Denominatormusthaveatleastonnonzeroelement.' den np.trim_zeros den 'f' num den num / den[0] den / den[0] leading_zeros 0for col in num.T if np.allclose col 0 atol 1e-14 leading_zeros + 1else breakif leading_zeros > 0 warnings.warn 'Badlyconditionedfiltercoefficients numerator theresultsmaybemeaningless' BadCoefficients if leading_zeros num.shape[1] leading_zeros - 1num num[ leading_zeros ]if num.shape[0] 1 num num[0 ]return num den
def _create_poller operation try operation_name operation['name']except KeyError raise MalformedOperation u'Failedtoparseoperation couldnotfindkeynamein {}'.format operation if 'zone' in operation zone_url_parts unicode operation['zone'] .split '/' try project zone_url_parts[ -3 ]zone zone_url_parts[ -1 ]except IndexError raise MalformedOperation "'zone'keyofoperationhadunexpectedform {}.\nExpected' .*/ ?<project>/zones/<zone>'.\nFulloperation {}.".format operation['zone'] operation return ZoneOperationPoller zone unicode zone project unicode project operation_name unicode operation_name else try project unicode operation['selfLink'] .split '/' [ -4 ]except KeyError raise MalformedOperation u'Failedtoparseglobaloperation couldnotfindkeyselfLinkin {}'.format operation except IndexError raise MalformedOperation "'selfLink'keyofoperationhadunexpectedform {}.\nExpected' .*/ ?<project>/global/operations/<name>'.\nFulloperation {}.".format operation['selfLink'] operation return GlobalOperationPoller project unicode project operation_name unicode operation_name
def getID lang None if lang val langelse try val prefs.app['locale']except KeyError val locale.GetLocale if not val val codeFromWxId[wx.LANGUAGE_DEFAULT]try language wxIdFromCode[val]except KeyError logging.error 'locale%snotknowntowx.Locale usingdefault' % val language wx.LANGUAGE_DEFAULTreturn language val
def providerIsAuthoritative providerID canonicalID lastbang canonicalID.rindex '!' parent canonicalID[ lastbang]return parent providerID
def S_all_hac x d nlags 1 r np.zeros d.shape[1] r[0] 1weights weights_bartlett nlags return aggregate_cov x d r r weights weights
def compileFeatureRE name featureRE list parser.featureContentRE featureRE.insert 2 name featureRE.insert 6 name return re.compile ''.join featureRE
def _is_reviewer locale user from kitsune.wiki.models import Localetry locale_team Locale.objects.get locale locale except Locale.DoesNotExist log.warning 'Localenotcreatedfor%s' % locale return Falsereturn user in locale_team.reviewers.all
def wrap text width 70 **kwargs w TextWrapper width width **kwargs return w.wrap text
def is_builtin name if name in builtins return Trueif name in SPECIAL_BUILTINS return Truereturn False
def _replacestrings source match re.search 'var* _\\w+ \\ \\[" .*? "\\];' source re.DOTALL if match varname strings match.groups startpoint len match.group 0 lookup strings.split '" "' variable '%s[%%d]' % varname for index value in enumerate lookup source source.replace variable % index '"%s"' % value return source[startpoint ]return source
def list_states saltenv 'base' return _client .list_states saltenv
def get_cache_base suffix None if suffix is None suffix '.distlib'if os.name 'nt' and 'LOCALAPPDATA' in os.environ result os.path.expandvars '$localappdata' else result os.path.expanduser '~' if os.path.isdir result usable os.access result os.W_OK if not usable logger.warning 'Directoryexistsbutisnotwritable %s' result else try os.makedirs result usable Trueexcept OSError logger.warning 'Unabletocreate%s' result exc_info True usable Falseif not usable result tempfile.mkdtemp logger.warning 'Defaultlocationunusable using%s' result return os.path.join result suffix
def change_assembly_version registry xml_parent data cav_builder_tag 'org.jenkinsci.plugins.changeassemblyversion.ChangeAssemblyVersion'cav XML.SubElement xml_parent cav_builder_tag XML.SubElement cav 'task' .text data.get 'version' '1.0.0' XML.SubElement cav 'assemblyFile' .text str data.get 'assembly-file' 'AssemblyInfo.cs'
def _get_proto use_ssl config.get_cloud_config_value 'use_ssl' get_configured_provider __opts__ search_global False default True if use_ssl is True return 'https'return 'http'
def params_from_doc func doc inspect.getdoc func cfg yaml.load doc for task in cfg for module params in task.items for k v in params.items if k in ['nics'] and type v str params[k] [v]task[module] collections.defaultdict str params return cfg[0]['os_server']
def remove_certificate_exception course_key student try certificate_exception CertificateWhitelist.objects.get user student course_id course_key except ObjectDoesNotExist raise ValueError _ 'Certificateexception user {user} doesnotexistincertificatewhitelist.Pleaserefreshthepageandtryagain.' .format user student.username try generated_certificate GeneratedCertificate.objects.get user student course_id course_key generated_certificate.invalidate log.info u'Certificateinvalidatedfor%sincourse%swhenremovedfromcertificateexceptionlist' student.username course_key except ObjectDoesNotExist passcertificate_exception.delete
def p_statement_list_2 t pass
@event u'manager.startup' def load_taskless manager SimplePersistence.load
def getproxies_environment proxies {}for name value in os.environ.items name name.lower if value and name[ -6 ] '_proxy' proxies[name[ -6 ]] valuereturn proxies
def unregister_file path pkg None conn None if conn is None conn init conn.execute 'DELETEFROMfilesWHEREpath ?' path
def _remove_identity_node graph node portinputs portoutputs _node_ports graph node for field connections in list portoutputs.items if portinputs _propagate_internal_output graph node field connections portinputs else _propagate_root_output graph node field connections graph.remove_nodes_from [node] logger.debug u'Removedtheidentitynode%sfromthegraph.' % node
def datasets_for_lddas trans lddas dataset_ids [x.dataset_id for x in lddas]datasets trans.sa_session.query trans.app.model.Dataset .filter trans.app.model.Dataset.id.in_ dataset_ids .all return datasets
@depends HAS_PYVMOMI def get_vsan_enabled host username password protocol None port None host_names None service_instance salt.utils.vmware.get_service_instance host host username username password password protocol protocol port port host_names _check_hosts service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_config host_ref.config.vsanHostConfigif vsan_config is None msg "VSANSystemConfigManagerisunsetforhost'{0}'.".format host_name log.debug msg ret.update {host_name {'Error' msg}} else ret.update {host_name {'VSANEnabled' vsan_config.enabled}} return ret
def get_courses_accessible_to_user request if GlobalStaff .has_user request.user courses in_process_course_actions _accessible_courses_summary_list request else try courses in_process_course_actions _accessible_courses_list_from_groups request except AccessListFallback courses in_process_course_actions _accessible_courses_summary_list request return courses in_process_course_actions
def sortAKAsBySimilarity movie title _titlesOnly True _preferredLang None language movie.guessLanguage m_title movie['title'].lower l_title title.lower if isinstance l_title unicode l_title l_title.encode 'utf8' scores []score difflib.SequenceMatcher None m_title.encode 'utf8' l_title .ratio scores.append score movie['title'] None for language aka in akasLanguages movie m_title aka.lower if isinstance m_title unicode m_title m_title.encode 'utf8' score difflib.SequenceMatcher None m_title l_title .ratio if _preferredLang and _preferredLang language score + 1scores.append score aka language scores.sort reverse True if _titlesOnly return [x[1] for x in scores]return scores
def create_epoch_x points epoch_freq minibatch_markers epoch_axis if epoch_axis x np.zeros points last_e 0for e_idx e in enumerate minibatch_markers e_minibatches e - last_e if e_idx + 1 % epoch_freq 0 x[ e_idx // epoch_freq ] e_idx + e_minibatches - 1 // e_minibatches last_e eelse x minibatch_markers[ epoch_freq - 1 epoch_freq] - 1 return x
def format_p_value_for_num_iters p num_iters if num_iters < 10 return 'Toofewiterstocomputep-value num_iters %d ' % num_iters decimal_places int log10 num_iters + 1 result '%1.' + '%df' % decimal_places % p return result
def projective_rule_parse_demo grammar DependencyGrammar.fromstring u"\n'scratch'->'cats'|'walls'\n'walls'->'the'\n'cats'->'the'\n" print grammar pdp ProjectiveDependencyParser grammar trees pdp.parse [u'the' u'cats' u'scratch' u'the' u'walls'] for tree in trees print tree
def buildTagMap default *args built {}for portion in args if hasattr portion 'items' for k v in portion.items built[k] velif isList portion for k in portion built[k] defaultelse built[portion] defaultreturn built
def ycbcr2rgb ycbcr arr ycbcr.copy arr[... 0] - 16arr[... 1] - 128arr[... 2] - 128return _convert rgb_from_ycbcr arr
def default_opener filename from subprocess import callcmds {'darwin' ['open'] 'linux2' ['xdg-open'] 'win32' ['cmd.exe' '/C' 'start' '']}cmd cmds[sys.platform] + [filename] call cmd
def _remove_complex_types dictionary for k v in six.iteritems dictionary if isinstance v dict dictionary[k] _remove_complex_types v elif hasattr v 'to_eng_string' dictionary[k] v.to_eng_string return dictionary
def create_api_key import timetry from hashlib import md5except ImportError from md5 import md5import randomt str time.time r str random.random m md5 t m.update r return m.hexdigest
@lru_cache 1024 def get_block env blockhash assert isinstance env Env blk rlp.decode env.db.get blockhash Block env env return CachedBlock.create_cached blk
def MapToRanks t pairs enumerate t sorted_pairs sorted pairs key itemgetter 1 ranked enumerate sorted_pairs resorted sorted ranked key lambda trip trip[1][0] ranks [ trip[0] + 1 for trip in resorted]return ranks
def _reciprocity_iter G nodes n G.nbunch_iter nodes for node in n pred set G.predecessors node succ set G.successors node overlap pred & succ n_total len pred + len succ if n_total 0 yield node None else reciprocity 2.0 * float len overlap / float n_total yield node reciprocity
def registerDOMImplementation name factory registered[name] factory
def _get_course_id store course_data return store.make_course_key course_data['org'] course_data['number'] course_data['run']
def approx_fprime x f eps None *args if eps is None eps np.sqrt np.finfo ca.float_ .eps grad np.zeros_like x step np.zeros_like x for idx in np.ndindex x.shape step[idx] eps * max abs x[idx] 1.0 grad[idx] f * x + step + args - f * x - step + args / 2 * step[idx] step[idx] 0.0return grad
def __consolidate node results node_data node.to_dict node_data_copy {}for key in node_data value node_data[key]if value ! '<<inherit>>' if isinstance value dict node_data_copy[key] value.copy elif isinstance value list node_data_copy[key] value[ ]else node_data_copy[key] valuefor field in node_data_copy data_item node_data_copy[field]if field in results fielddata results[field]if isinstance fielddata dict results[field].update data_item.copy elif isinstance fielddata list or isinstance fielddata tuple results[field].extend data_item results[field] uniquify results[field] elif field ! 'distro' results[field] data_itemelse results[field] data_itemdict_removals results 'kernel_options' dict_removals results 'kernel_options_post' dict_removals results 'autoinstall_meta' dict_removals results 'template_files' dict_removals results 'boot_files' dict_removals results 'fetchable_files'
def points_to_document_view url required_locale None try return not not _doc_components_from_url url required_locale required_locale except _NotDocumentView return False
def iter_strides_c_contig arr shape None shape arr.shape if shape is None else shape itemsize arr.itemsizedef gen yield itemsize sum 1for s in reversed shape[1 ] sum * s yield sum * itemsize for i in reversed list gen yield i
def _init_bind_completion log.completion.debug 'Initializingbindcompletion.' model miscmodels.BindCompletionModel _instances[usertypes.Completion.bind] model
def __listAllBridgesUnix deviceList {}numDevices staticLib.LJUSB_GetDevCount 1281 for i in xrange numDevices try device openLabJack 1281 1 firstFound False devNumber i + 1 device.close deviceList[str device.serialNumber ] device.__dict__except LabJackException passreturn deviceList
def DeleteIndex index _Call 'DeleteIndex' index api_base_pb.VoidProto
def _create_carefully path fd os.open path os.O_CREAT | os.O_EXCL | os.O_RDWR 438 try return open path 'rb+' finally os.close fd
def assert_alerts ea_inst calls assert ea_inst.rules[0]['alert'][0].alert.call_count len calls for call_num call_args in enumerate ea_inst.rules[0]['alert'][0].alert.call_args_list assert not any [ match['@timestamp'] not in calls[call_num] for match in call_args[0][0]] assert len call_args[0][0] len calls[call_num]
def fileglob pathname return [g for g in glob.glob pathname if os.path.isfile g ]
def install_upgrade package upgrade False progress_hook None global hook_download_filenameif upgrade operation '[up]upgrading'else operation '[in]installing'logger.info "{0}'{1}'to{2}".format operation package.name dataset_data_path remote_src package.sourcepackage.where dataset_data_pathcached Falseif not cached hook_download_filename remote_srctemp_filename download_from_url remote_src filename None progress_hook progress_hook else passlogger.info "[in]runninginstallscriptsforpackage'{0}'".format package.name install_package package temp_filename dataset_data_path update_installed_list 'i' package
def _TestTerminateAccount tester user_cookie request_dict validator tester.validator user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict actual_dict tester.SendRequest 'terminate_account' user_cookie request_dict op_dict tester._DeriveNotificationOpDict user_id device_id request_dict validator.ValidateTerminateAccount user_id op_dict tester._CompareResponseDicts 'terminate_account' user_id request_dict {} actual_dict return actual_dict
def _getAccessibleAttribute attributeName if attributeName in globalAccessibleAttributeDictionary return globalAccessibleAttributeDictionary[attributeName]return None
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
def memory_info process pmem getattr process 'memory_info' None or process.get_memory_info return pmem.rss pmem.vms
def pci_device_prop_match pci_dev specs def _matching_devices spec return all pci_dev.get k v for k v in spec.items return any _matching_devices spec for spec in specs
def isWindowsDriveLetterPath filepath return re.search '\\A[\\w]\\ ' filepath is not None
def _transliterate u xlate u unicodedata.normalize 'NFD' u u u''.join [ u'' if _is_unicode_combining x else x for x in u] u _translate u xlate return unicode u
def _active_mounts_solaris ret for line in __salt__['cmd.run_stdout'] 'mount-v' .split '\n' comps re.sub '\\s+' '' line .split ret[comps[2]] {'device' comps[0] 'fstype' comps[4] 'opts' _resolve_user_group_names comps[5].split '/' }return ret
def _reduce_code code return marshal.version imp.get_magic marshal.dumps code
def files_re_match_multiline file1 file2 attributes None local_file open file1 'U' .read if attributes is None attributes {}if attributes.get 'sort' False history_data open file2 'U' .readlines history_data.sort history_data ''.join history_data else history_data open file2 'U' .read assert re.match local_file history_data re.MULTILINE 'MultilineRegularexpressiondidnotmatchdatafile'
def _get_course_key course_key_or_id return CourseKey.from_string course_key_or_id if isinstance course_key_or_id basestring else course_key_or_id
def _create_gpg user None gnupghome None if not gnupghome gnupghome _get_user_gnupghome user if GPG_1_3_1 gpg gnupg.GPG homedir gnupghome else gpg gnupg.GPG gnupghome gnupghome return gpg
def UninstallModule conf_module_name params options log lambda *args None loader_dll GetLoaderModuleName conf_module_name False _PatchParamsModule params loader_dll False Uninstall params options log 1 'Uninstallationcomplete.'
def _decode_and_join_header header separator u'' if not header return headerreturn separator.join unicode s c or 'us-ascii' for s c in email.header.decode_header header
def _link token result return None
def get_table_description cursor table_name cursor.execute 'SELECT*FROM%sLIMIT1' % quote_name table_name return cursor.description
def remote_api_shell servername appid path secure rpc_server_factory os.environ['AUTH_DOMAIN'] 'appscale'remote_api_stub.ConfigureRemoteApi appid path auth_func servername servername save_cookies True secure secure rpc_server_factory rpc_server_factory remote_api_stub.MaybeInvokeAuthentication os.environ['SERVER_SOFTWARE'] 'Development remote_api_shell /1.0'if not appid appid os.environ['APPLICATION_ID']sys.ps1 '%s>' % appid if readline is not None readline.parse_and_bind 'tab complete' atexit.register lambda readline.write_history_file HISTORY_PATH if os.path.exists HISTORY_PATH readline.read_history_file HISTORY_PATH if '' not in sys.path sys.path.insert 0 '' preimported_locals {'memcache' memcache 'urlfetch' urlfetch 'users' users 'db' db 'ndb' ndb}code.interact banner BANNER local preimported_locals
def split_path_mapping volume_path drive volume_config splitdrive volume_path if u' ' in volume_config host container volume_config.split u' ' 1 return container drive + host else return volume_path None
def copy_xxmodule_c directory filename _get_xxmodule_path if filename is None raise unittest.SkipTest 'cannotfindxxmodule.c testmustruninthepythonbuilddir ' shutil.copy filename directory
def _unpack_user v uv v.uservalue email unicode uv.email .decode 'utf-8' auth_domain unicode uv.auth_domain .decode 'utf-8' obfuscated_gaiaid uv.obfuscated_gaiaid .decode 'utf-8' obfuscated_gaiaid unicode obfuscated_gaiaid federated_identity Noneif uv.has_federated_identity federated_identity unicode uv.federated_identity .decode 'utf-8' value users.User email email _auth_domain auth_domain _user_id obfuscated_gaiaid federated_identity federated_identity return value
def _get_mysql_db_version from django.db import connectionconn connection.cursor conn.execute 'SELECTVERSION ' version conn.fetchone return version and str version[0] or ''
def merge_list old new if not old return newif isinstance new list old.extend new return oldelse return ' '.join [old new]
def extract_param_pairs params prefix '' keyname '' valuename '' plist extract_param_list params prefix kvs [ p[keyname] p[valuename] for p in plist if keyname in p and valuename in p ]return dict kvs
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def mpf_norm mpf prec sign man expt bc mpfif not man if not bc return _mpf_zeroelse return mpffrom mpmath.libmp.backend import MPZrv mpf_normalize sign MPZ man expt bc prec rnd return rv
def extrapolate_statistics scope c {}for k v in list scope.items if isinstance v dict v extrapolate_statistics v elif isinstance v list tuple v [extrapolate_statistics record for record in v]elif hasattr v '__call__' v v scope c[k] vreturn c
def set_invalid_utime path try os.utime path -1 -100000000000 except OSError OverflowError os.utime path -1 -1
def un_camel_case s return re.sub ' ?< \\w [A-Z] ' '\\1' s
def cql_typename casstypename return lookup_casstype casstypename .cql_parameterized_type
def create_directory repo remote_path repoif repo.startswith 'ssh //' _ remote_path parse_ssh_path repo repo_run_command repo 'mkdir-p%s' % remote_path cd False
def p_abstract_declarator_3 t pass
def s_group name values group primitives.group name values blocks.CURRENT.push group
def _create_params parent argslist_list def check_python2_nested_param node '\nPython2allowsparamstolooklike``defx a b c `` whichis\nbasicallyawayofunpackingtuplesinparams.Python3hasditched\nthisbehavior.Jedicurrentlyjustignoresthoseconstructs.\n'return node.type 'tfpdef' and node.children[0] ' ' try first argslist_list[0]except IndexError return []if first.type in 'name' 'tfpdef' if check_python2_nested_param first return [first]else return [Param [first] parent ]elif first '*' return [first]else children first.childrennew_children []start 0for end child in enumerate children + [None] 1 if child is None or child ' ' param_children children[start end]if param_children if check_python2_nested_param param_children[0] new_children + param_childrenelif param_children[0] '*' and param_children[1] ' ' new_children + param_childrenelse new_children.append Param param_children parent start endreturn new_children
def compile_user_lists files user source_node node move {key [] for key in constants.NOTIFICATION_TYPES}warn {key [] for key in constants.NOTIFICATION_TYPES}remove {key [] for key in constants.NOTIFICATION_TYPES}if len files 0 move warn remove categorize_users user 'file_updated' source_node 'file_updated' node for file_path in files path file_path.strip '/' t_move t_warn t_remove categorize_users user path + '_file_updated' source_node path + '_file_updated' node for notification in constants.NOTIFICATION_TYPES move[notification] list set move[notification] .union set t_move[notification] warn[notification] list set warn[notification] .union set t_warn[notification] remove[notification] list set remove[notification] .union set t_remove[notification] return move warn remove
def to_str value if sys.version_info[0] > 2 retval str value else retval to_str_py27 value return retval
def _format_block_device_mapping bdm keys 'deviceName' 'device_name' 'virtualName' 'virtual_name' item {}for name k in keys if k in bdm item[name] bdm[k]if bdm.get 'no_device' item['noDevice'] Trueif 'snapshot_id' in bdm or 'volume_id' in bdm ebs_keys 'snapshotId' 'snapshot_id' 'snapshotId' 'volume_id' 'volumeSize' 'volume_size' 'deleteOnTermination' 'delete_on_termination' ebs {}for name k in ebs_keys if k in bdm if k 'snapshot_id' ebs[name] ec2utils.id_to_ec2_snap_id bdm[k] elif k 'volume_id' ebs[name] ec2utils.id_to_ec2_vol_id bdm[k] else ebs[name] bdm[k]assert 'snapshotId' in ebs item['ebs'] ebsreturn item
def get_head repo_path try ref open os.path.join repo_path '.git' 'HEAD' 'r' .read .strip [5 ].split '/' branch ref[ -1 ]commit open os.path.join repo_path '.git' *ref 'r' .read .strip [ 7]return branch commit except return None
def gpuarray_shared_constructor value name None strict False allow_downcast None borrow False broadcastable None target notset if target 'gpu' or target 'cpu' raise TypeError 'notforme' if not isinstance value numpy.ndarray pygpu.gpuarray.GpuArray raise TypeError 'ndarrayorGpuArrayrequired' if target is notset target Noneif not move_to_gpu value raise TypeError 'WedonotmovethatdatabydefaulttotheGPU' try get_context target except ContextNotDefined if target is None raise TypeError 'Nodefaultcontextandnocontextspecified' raiseif broadcastable is None broadcastable False * value.ndim type GpuArrayType value.dtype broadcastable context_name target deviceval pygpu.gpuarray.array value copy not borrow context type.context return GpuArraySharedVariable type type value deviceval name name strict strict
def get_subnet_name ret salt.utils.mac_utils.execute_return_result 'systemsetup-getlocalsubnetname' return salt.utils.mac_utils.parse_return ret
def remez numtaps bands desired weight None Hz 1 type 'bandpass' maxiter 25 grid_density 16 try tnum {'bandpass' 1 'differentiator' 2 'hilbert' 3}[type]except KeyError raise ValueError "Typemustbe'bandpass' 'differentiator' or'hilbert'" if weight is None weight [1] * len desired bands np.asarray bands .copy return sigtools._remez numtaps bands desired weight tnum Hz maxiter grid_density
def get_dataset_ids deployment for node in deployment.nodes.values for manifestation in node.manifestations.values yield manifestation.dataset.dataset_id
def serve_static request path insecure False **kwargs if not django_settings.DEBUG and not insecure raise ImproperlyConfigured u"Thestaticfilesviewcanonlybeusedindebugmodeorifthe--insecureoptionof'runserver'isused" if not settings.PIPELINE_ENABLED and settings.PIPELINE_COLLECTOR_ENABLED default_collector.collect request files [path] return serve request path document_root django_settings.STATIC_ROOT **kwargs
@not_implemented_for 'undirected' def attracting_components G scc list nx.strongly_connected_components G cG nx.condensation G scc for n in cG if cG.out_degree n 0 yield scc[n]
def ids_from_fasta_lines lines ids []for line in lines if not line.startswith '>' continueid id_from_fasta_label_line line ids.append id return ids
def create_file_system name performance_mode 'generalPurpose' keyid None key None profile None region None **kwargs import osimport base64creation_token base64.b64encode os.urandom 46 ['-' '_'] tags {'Key' 'Name' 'Value' name}client _get_conn key key keyid keyid profile profile region region response client.create_file_system CreationToken creation_token PerformanceMode performance_mode if 'FileSystemId' in response client.create_tags FileSystemId response['FileSystemId'] Tags tags if 'Name' in response response['Name'] namereturn response
def save_sections sections default_section sections['default']try if bool default_section.get 'save' 'false' conf_writer ConfWriter str default_section.get 'config' Constants.default_coafile else returnexcept ValueError conf_writer ConfWriter str default_section.get 'save' '.coafile' conf_writer.write_sections sections conf_writer.close
def rword length 5 s ''for i in range length if i % 2 0 t _consonantselse t _vowelss + random.choice t return s
def test_from_castra_with_selection castra pytest.importorskip 'castra' blosc pytest.importorskip 'blosc' if LooseVersion blosc.__version__ '1.3.0' or LooseVersion castra.__version__ < '0.1.8' pytest.skip df pd.DataFrame {'x' ['a' 'b' 'c' 'd'] 'y' [2 3 4 5]} index pd.Index [1.0 2.0 3.0 4.0] name 'ind' a dd.from_pandas df 2 b dd.from_castra a.to_castra assert_eq b[ b.y > 3 ].x df[ df.y > 3 ].x
def temperature_energy return [ si.K si.eV lambda x x / _si.e.value / _si.k_B lambda x x * _si.e.value / _si.k_B ]
def raises *exceptions valid 'or'.join [e.__name__ for e in exceptions] def decorate func name func.__name__def newfunc *arg **kw try func *arg **kw except exceptions passexcept raiseelse message '%s didnotraise%s' % name valid raise AssertionError message newfunc make_decorator func newfunc return newfuncreturn decorate
def remove_taps module brew_path taps failed unchanged removed msg False 0 0 '' for tap in taps failed changed msg remove_tap module brew_path tap if failed breakif changed removed + 1else unchanged + 1if failed msg 'removed %d unchanged %d error ' + msg msg msg % removed unchanged elif removed changed Truemsg 'removed %d unchanged %d' % removed unchanged else msg 'removed %d unchanged %d' % removed unchanged return failed changed msg
def writable_connection_pool account_id pool_size 1 pool_map dict return _get_connection_pool account_id pool_size pool_map False
def cr_context method method._api 'cr_context'return method
def create_api_error_from_http_exception e response e.responsetry explanation response.json ['message']except ValueError explanation response.content.strip cls APIErrorif response.status_code 404 if explanation and 'Nosuchimage' in str explanation or 'notfound doesnotexistornoreadaccess' in str explanation cls ImageNotFoundelse cls NotFoundraise cls e response response explanation explanation
def print_list extracted_list file None if file is None file sys.stderrfor filename lineno name line in extracted_list _print file 'File"%s" line%d in%s' % filename lineno name if line _print file '%s' % line.strip
def spawn_personal_stream args stuff None g['keyword'] g['listname'] ''g['PREFIX'] u2str emojize format_prefix th threading.Thread target stream args c['USER_DOMAIN'] args g['original_name'] th.daemon Trueth.start
def compile_device_template pyfunc debug False inline False from .descriptor import CUDATargetDescdft DeviceFunctionTemplate pyfunc debug debug inline inline class device_function_template AbstractTemplate key dftdef generic self args kws assert not kws return dft.compile args typingctx CUDATargetDesc.typingctxtypingctx.insert_user_function dft device_function_template return dft
def _siftdown_max heap startpos pos newitem heap[pos]while pos > startpos parentpos pos - 1 >> 1 parent heap[parentpos]if cmp_lt parent newitem heap[pos] parentpos parentposcontinuebreakheap[pos] newitem
def decint raw forward True val 0byts bytearray src bytearray raw if not forward src.reverse for bnum in src byts.append bnum & 127 if bnum & 128 breakif not forward byts.reverse for byte in byts val << 7val | bytereturn val len byts
def _abort msgs if not isinstance msgs list msgs [msgs]for msg in msgs log.error msg sys.stderr.write msg + '\n\n' sys.stderr.write 'Buildfailed.Seelogfileforfurtherdetails.\n' sys.exit 1
def _raise_if_duplicate_entry_error integrity_error engine_name def get_columns_from_uniq_cons_or_name columns uniqbase 'uniq_'if not columns.startswith uniqbase if engine_name 'postgresql' return [columns[ columns.index '_' + 1 columns.rindex '_' ]]return [columns]return columns[len uniqbase ].split '0' [1 ]if engine_name not in ['mysql' 'sqlite' 'postgresql'] returnm _DUP_KEY_RE_DB[engine_name].match integrity_error.message if not m returncolumns m.group 1 if engine_name 'sqlite' columns columns.strip .split ' ' else columns get_columns_from_uniq_cons_or_name columns raise exception.DBDuplicateEntry columns integrity_error
def testWithNoKwargs io launchHubServer keyboard io.devices.keyboardprint print '**PRESSAKEYTOCONTINUE.....' while not keyboard.getEvents io.wait 0.25 print 'AKeyboardEventwasDetected;exitingTest.' io.quit
def BuildServerConf keys vimsupport.GetVimGlobalsKeys server_conf {}for key in keys if not key.startswith YCM_VAR_PREFIX continuenew_key key[len YCM_VAR_PREFIX ]new_value vimsupport.VimExpressionToPythonType u'g ' + key server_conf[new_key] new_valuereturn server_conf
def handle text mic profile messages ["I'msorry couldyourepeatthat?" 'Myapologies couldyoutrysayingthatagain?' 'Saythatagain?' 'Ibegyourpardon?']message random.choice messages mic.say message
def minute_to_session column close_locs data out if column 'open' _minute_to_session_open close_locs data out elif column 'high' _minute_to_session_high close_locs data out elif column 'low' _minute_to_session_low close_locs data out elif column 'close' _minute_to_session_close close_locs data out elif column 'volume' _minute_to_session_volume close_locs data out return out
def getBaseURL req name req.META['HTTP_HOST']try name name[ name.index ' ' ]except passtry port int req.META['SERVER_PORT'] except port 80proto req.META['SERVER_PROTOCOL']if 'HTTPS' in proto proto 'https'else proto 'http'if port in [80 443] or not port port ''else port ' %s' % port url '%s //%s%s/' % proto name port return url
def filter_blobnames_for_prefix candidates prefix sep matches set if not prefix for name in candidates if name '*' continueif sep in name matches.add name[ name.index sep ] True else matches.add name False else sep_len len sep sepped_prefix sep.join prefix for name in candidates if name '*' continueif name.startswith sepped_prefix + sep subname name[ len sepped_prefix + sep_len ]if sep in subname subname subname[ subname.index sep ]is_partial_match Trueelse is_partial_match Falsematches.add subname is_partial_match return matches
def _has_constant_term p x R p.ringiv R.gens.index x zm R.zero_monoma [0] * R.ngens a[iv] 1miv tuple a for expv in p if monomial_min expv miv zm return Truereturn False
def is_exp_summary_editable exp_summary user_id None return user_id is not None and user_id in exp_summary.editor_ids or user_id in exp_summary.owner_ids or exp_summary.community_owned
def validate_equal_length *args length len args[0] if any len lst ! length for lst in args raise exceptions.PlotlyError 'Oops!Yourdatalistsorndarraysshouldbethesamelength.'
def print_timing msg None debug False prefix msgif isinstance msg types.FunctionType prefix msg.func_namedef wrap_f func *arg **kargs 'Rawtimingfunction'time1 time.time res func *arg **kargs time2 time.time msg '%stook%0.3fmins' % prefix time2 - time1 / 60.0 if debug log.debug msg else log.info msg return resif isinstance msg types.FunctionType return decorator.decorator wrap_f msg else return decorator.decorator wrap_f
def build_resources options verify_nodejs builder Builder '.' options if '.' in options.directories builder.build_all else builder.build_dirs options.directories
def must_have_write_permission_or_public_wiki func @functools.wraps func def wrapped *args **kwargs _inject_nodes kwargs wiki kwargs['node'].get_addon 'wiki' if wiki and wiki.is_publicly_editable return func *args **kwargs else return must_have_permission 'write' func *args **kwargs return wrapped
def group_snapshot_create context values return IMPL.group_snapshot_create context values
def _example_short_number_for_cost region_code cost metadata PhoneMetadata.short_metadata_for_region region_code if metadata is None return U_EMPTY_STRINGdesc Noneif cost ShortNumberCost.TOLL_FREE desc metadata.toll_freeelif cost ShortNumberCost.STANDARD_RATE desc metadata.standard_rateelif cost ShortNumberCost.PREMIUM_RATE desc metadata.premium_rateelse passif desc is not None and desc.example_number is not None return desc.example_numberreturn U_EMPTY_STRING
def _is_path_in_directories filename directories fixed_path os.path.normcase os.path.abspath filename for parent in directories fixed_parent os.path.normcase os.path.abspath parent if os.path.commonprefix [fixed_path fixed_parent] fixed_parent return Truereturn False
def recv_item_json try item_id request.args[0]except raise HTTP 400 current.xml.json_message False 400 'Novalueprovided!' stable s3db.org_sitertable s3db.inv_recvittable s3db.inv_track_itemrtable.date.represent lambda dt dt[ 10] query ittable.req_item_id item_id & rtable.id ittable.recv_id & rtable.site_id stable.id & rtable.status s3db.inv_ship_status['RECEIVED'] & ittable.deleted False records db query .select rtable.id rtable.date stable.name ittable.quantity output '[%s %s' % json.dumps dict id str T 'Received' quantity '#' records.json [1 ] response.headers['Content-Type'] 'application/json'return output
def service_get_by_args context host binary return IMPL.service_get_by_args context host binary
def _symlink_check name target force user group pchanges {}if not os.path.exists name and not __salt__['file.is_link'] name pchanges['new'] namereturn None 'Symlink{0}to{1}issetforcreation'.format name target pchanges if __salt__['file.is_link'] name if __salt__['file.readlink'] name ! target pchanges['change'] namereturn None 'Link{0}targetissettobechangedto{1}'.format name target pchanges else result Truemsg 'Thesymlink{0}ispresent'.format name if not _check_symlink_ownership name user group result Nonepchanges['ownership'] '{0} {1}'.format *_get_symlink_ownership name msg + ' buttheownershipofthesymlinkwouldbechangedfrom{2} {3}to{0} {1}'.format user group *_get_symlink_ownership name return result msg pchanges else if force return None 'Thefileordirectory{0}issetforremovaltomakewayforanewsymlinktargeting{1}'.format name target pchanges return False 'Fileordirectoryexistswherethesymlink{0}shouldbe.Didyoumeantouseforce?'.format name pchanges
@deprecated Version 'Twisted' 11 0 0 'inspect.getmro' def allYourBase classObj baseClass None l []_accumulateBases classObj l baseClass return l
def _format_date dt return '%s %02d%s%04d%02d %02d %02dGMT' % ['Mon' 'Tue' 'Wed' 'Thu' 'Fri' 'Sat' 'Sun'][dt.weekday ] dt.day ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec'][ dt.month - 1 ] dt.year dt.hour dt.minute dt.second
def copytodir src dstdir dst pathjoin dstdir os.path.basename src copy src dst
def ylabel s *args **kwargs return gca .set_ylabel s *args **kwargs
def get_signals signums return dict s signal.getsignal s for s in signums
def stack_search start expand mode 'bfs' build_inv False if mode not in 'bfs' 'dfs' raise ValueError 'modeshouldbebfsordfs' mode rval_set set rval_list list if mode 'bfs' start_pop start.popleftelse start_pop start.popexpand_inv {}while start l start_pop if id l not in rval_set rval_list.append l rval_set.add id l expand_l expand l if expand_l if build_inv for r in expand_l expand_inv.setdefault r [] .append l start.extend expand_l assert len rval_list len rval_set if build_inv return rval_list expand_inv return rval_list
def copula_bv_min u v return np.minimum u v
def calculate_mantl_vars func @wraps func def inner *args **kwargs name attrs groups func *args **kwargs if attrs.get u'role' u'' u'control' attrs[u'consul_is_server'] Trueelse attrs[u'consul_is_server'] Falseif attrs.get u'publicly_routable' False groups.append u'publicly_routable' return name attrs groups return inner
def fcontext_add_or_delete_policy action name filetype None sel_type None sel_user None sel_level None if action not in ['add' 'delete'] raise SaltInvocationError 'Actionssupportedare"add"and"delete" not"{0}".'.format action cmd 'semanagefcontext--{0}'.format action if filetype is not None _validate_filetype filetype cmd + '--ftype{0}'.format filetype if sel_type is not None cmd + '--type{0}'.format sel_type if sel_user is not None cmd + '--seuser{0}'.format sel_user if sel_level is not None cmd + '--range{0}'.format sel_level cmd + '' + re.escape name return __salt__['cmd.run_all'] cmd
def _make_task_name cls addons None base_name '.'.join [cls.__module__ cls.__name__] extra ''if addons extra ';%s' % ' '.join [str a for a in addons] return base_name + extra
def global_date_format date formatted_date getdate date .strftime u'%d%B%Y' return formatted_date.startswith u'0' and formatted_date[1 ] or formatted_date
def oauth_enabled decorated_function None scopes None **decorator_kwargs def curry_wrapper wrapped_function @wraps wrapped_function def enabled_wrapper request *args **kwargs return_url decorator_kwargs.pop 'return_url' request.get_full_path user_oauth django_util.UserOAuth2 request scopes return_url setattr request django_util.oauth2_settings.request_prefix user_oauth return wrapped_function request *args **kwargs return enabled_wrapperif decorated_function return curry_wrapper decorated_function else return curry_wrapper
def OAuthAuthorizeTokenCGI method parameters outfile oauth_callback GetFirst parameters _OAUTH_CALLBACK_PARAM '' if method 'GET' outfile.write 'Status 200\r\n' outfile.write 'Content-Type text/html\r\n' outfile.write '\r\n' outfile.write RenderTokenApprovalTemplate oauth_callback elif method 'POST' if oauth_callback outfile.write 'Status 302RedirectingtocallbackURL\r\n' outfile.write 'Location %s\r\n' % oauth_callback outfile.write '\r\n' else outfile.write 'Status 200\r\n' outfile.write 'Content-Type text/html\r\n' outfile.write '\r\n' outfile.write RenderTokenApprovedTemplate else outfile.write 'Status 400Unsupportedmethod\r\n'
def cert_get_serial cert return cert.serial
@cached_query SubredditQueryCache def get_spam_filtered_links sr_id return Link._query Link.c.sr_id sr_id Link.c._spam True Link.c.verdict ! 'mod-removed' sort db_sort 'new'
def run_network_interacting_from_args *a **kw return retry_effect_with_timeout run_from_args *a **kw timeout _TIMEOUT.total_seconds
def is_ip_addr value if not isinstance value string_type raise VdtTypeError value value value.strip try dottedQuadToNum value except ValueError raise VdtValueError value return value
def estimate_sigma im average_sigmas False multichannel False if multichannel nchannels im.shape[ -1 ]sigmas [estimate_sigma im[... c] multichannel False for c in range nchannels ]if average_sigmas sigmas np.mean sigmas return sigmaselif im.shape[ -1 ] < 4 msg 'imageissize{0}onthelastaxis butmultichannelisFalse.Ifthisisacolorimage pleasesetmultichanneltoTrueforpropernoiseestimation.'warn msg.format im.shape[ -1 ] coeffs pywt.dwtn im wavelet 'db2' detail_coeffs coeffs[ 'd' * im.ndim ]return _sigma_est_dwt detail_coeffs distribution 'Gaussian'
def extract_live_config config plugins live_config config._sections['live_config'].copy del live_config['__name__']parsed ConfigValueParser live_config parsed.add_spec Globals.live_config_spec for plugin in plugins parsed.add_spec plugin.live_config return parsed
def get_cluster_addr_for_job_submission if is_yarn if get_yarn .LOGICAL_NAME.get return get_yarn .LOGICAL_NAME.get conf get_cluster_conf_for_job_submission if conf is None return Nonereturn '%s %s' % conf.HOST.get conf.PORT.get
def sortLoopsInOrderOfArea isDescending loops loops.sort key euclidean.getAreaLoopAbsolute reverse isDescending
def _init_command_completion log.completion.debug 'Initializingcommandcompletion.' model miscmodels.CommandCompletionModel _instances[usertypes.Completion.command] model
def cmdline pid return psutil.Process pid .cmdline
def test_dpi dpi get_dpi assert dpi > 0.0 assert isinstance dpi float
def _filter_crowd_proposals roidb crowd_thresh for ix entry in enumerate roidb overlaps entry['gt_overlaps'].toarray crowd_inds np.where overlaps.max axis 1 -1 [0]non_gt_inds np.where entry['gt_classes'] 0 [0]if len crowd_inds 0 or len non_gt_inds 0 continueiscrowd [int True for _ in xrange len crowd_inds ]crowd_boxes ds_utils.xyxy_to_xywh entry['boxes'][crowd_inds ] non_gt_boxes ds_utils.xyxy_to_xywh entry['boxes'][non_gt_inds ] ious COCOmask.iou non_gt_boxes crowd_boxes iscrowd bad_inds np.where ious.max axis 1 > crowd_thresh [0]overlaps[non_gt_inds[bad_inds] ] -1 roidb[ix]['gt_overlaps'] scipy.sparse.csr_matrix overlaps return roidb
def _check_ldev ldev_info ldev existing_ref if ldev_info['sts'] ! NORMAL_STS msg utils.output_log MSG.INVALID_LDEV_FOR_MANAGE raise exception.ManageExistingInvalidReference existing_ref existing_ref reason msg vol_attr set ldev_info['vol_attr'] if not ldev_info['vol_type'].startswith 'OPEN-V' or len vol_attr < 2 or not vol_attr.issubset _PERMITTED_TYPES msg utils.output_log MSG.INVALID_LDEV_ATTR_FOR_MANAGE ldev ldev ldevtype utils.NVOL_LDEV_TYPE raise exception.ManageExistingInvalidReference existing_ref existing_ref reason msg if ldev_info['vol_size'] % utils.GIGABYTE_PER_BLOCK_SIZE msg utils.output_log MSG.INVALID_LDEV_SIZE_FOR_MANAGE ldev ldev raise exception.ManageExistingInvalidReference existing_ref existing_ref reason msg if ldev_info['num_port'] msg utils.output_log MSG.INVALID_LDEV_PORT_FOR_MANAGE ldev ldev raise exception.ManageExistingInvalidReference existing_ref existing_ref reason msg
def do_translate message translation_function global _defaulteol_message message and message.replace str u'\r\n' str u'\n' .replace str u'\r' str u'\n' or None t getattr _active u'value' None if t is not None result getattr t translation_function eol_message else if _default is None from django.conf import settings_default translation settings.LANGUAGE_CODE result getattr _default translation_function eol_message if isinstance message SafeData return mark_safe result return result
def age_restricted content_limit age_limit if age_limit is None return Falseif content_limit is None return Falsereturn age_limit < content_limit
def choplist n seq r []for x in seq r.append x if len r n yield tuple r r []return
def sort_thing_ids_by_data_value type_id thing_ids value_name limit None desc False thing_table data_table get_thing_table type_id join thing_table.join data_table data_table.c.thing_id thing_table.c.thing_id query sa.select [thing_table.c.thing_id] sa.and_ thing_table.c.thing_id.in_ thing_ids thing_table.c.deleted False thing_table.c.spam False data_table.c.key value_name .select_from join sort_column data_table.c.valueif desc sort_column sa.desc sort_column query query.order_by sort_column if limit query query.limit limit rows query.execute return Results rows lambda row row.thing_id
def test_noeffect_keys superConsole.SendKeys 'outputRedirectStart{ }True{ }{ENTER}' testRegex ''superConsole.SendKeys '{BACKSPACE}{DELETE}{HOME}{LEFT}print"start"{ENTER}' testRegex + 'start'superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex
@register.filterdef comment_filter comment_text filter_func settings.COMMENT_FILTERif not filter_func def filter_func s return linebreaksbr urlize s autoescape True autoescape True elif not callable filter_func filter_func import_dotted_path filter_func return filter_func comment_text
def make_vals val klass klass_inst None prop None part False base64encode False cinst Noneif isinstance val dict cinst klass .loadd val base64encode base64encode else try cinst klass .set_text val except ValueError if not part cis [make_vals sval klass klass_inst prop True base64encode for sval in val]setattr klass_inst prop cis else raiseif part return cinstelif cinst cis [cinst]setattr klass_inst prop cis
def assert_element_text output path verify_assertions_function children text xml_find_text output path verify_assertions_function text children
def statistic return s3_rest_controller
def get_requester auth_context pecan.request.context.get 'auth' None user_db auth_context.get 'user' None if auth_context else None if not user_db LOG.warn 'authisdisabled fallingbacktosystem_user' username cfg.CONF.system_user.userelse username user_db.namereturn username
def html_override_tool apiopts cherrypy.config['apiopts']request cherrypy.requesturl_blacklist apiopts.get 'app_path' '/app' apiopts.get 'static_path' '/static' if 'app' not in cherrypy.config['apiopts'] returnif request.path_info.startswith url_blacklist returnif request.headers.get 'Accept' '*/*' returntry wants_html cherrypy.lib.cptools.accept 'text/html' except cherrypy.HTTPError returnelse if wants_html ! 'text/html' returnraise cherrypy.InternalRedirect apiopts.get 'app_path' '/app'
def get_http_connect account_func container_func object_func def http_connect ipaddr port device partition method path headers None query_string None a c o split_path path 1 3 True if o func object_funcelif c func container_funcelse func account_funcresp func ipaddr port device partition method path headers headers query_string query_string return respreturn http_connect
def find_maltparser parser_dirname if os.path.exists parser_dirname _malt_dir parser_dirnameelse _malt_dir find_dir parser_dirname env_vars u'MALT_PARSER' malt_dependencies [u'' u'' u'']_malt_jars set find_jars_within_path _malt_dir _jars set os.path.split jar [1] for jar in _malt_jars malt_dependencies set [u'log4j.jar' u'libsvm.jar' u'liblinear-1.8.jar'] assert malt_dependencies.issubset _jars assert any filter lambda i i.startswith u'maltparser-' and i.endswith u'.jar' _jars return list _malt_jars
def plot_top_left image image[14 ] np.zeros 14 28 image[ 14 ] np.zeros 28 14 fig plt.figure ax fig.add_subplot 1 1 1 ax.matshow image cmap matplotlib.cm.binary plt.xticks np.array [] plt.yticks np.array [] plt.show
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
def get_crypto_hiddenimports try modname 'Crypto.Cipher._AES'import_aes modname except ImportError modname 'Crypto.Cipher.AES'import_aes modname return modname
def test_type for c in Script 'importos;os.path.' .completions assert c.type
def set_manageiq_facts_if_unset facts if 'common' not in facts if 'version_gte_3_1_or_1_1' not in facts['common'] raise OpenShiftFactsInternalError 'Invalidinvocation Therequiredfactsarenotset' if 'use_manageiq' not in facts['common'] facts['common']['use_manageiq'] facts['common']['version_gte_3_1_or_1_1']return facts
def FakeORM *args if not args in _orm_cache _orm_cache[args] _FakeORM *args return _orm_cache[args]
def test_moon data.moon
def blackmanharris M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym w _cos_win M [0.35875 0.48829 0.14128 0.01168] return _truncate w needs_trunc
def tb_iter tb while tb is not None yield tb tb tb.tb_next
def save_positions_recursively_up user request field_data_cache xmodule course None current_module xmodulewhile current_module parent_location modulestore .get_parent_location current_module.location parent Noneif parent_location parent_descriptor modulestore .get_item parent_location parent get_module_for_descriptor user request parent_descriptor field_data_cache current_module.location.course_key course course if parent and hasattr parent 'position' save_child_position parent current_module.location.name current_module parent
def _raw_input_contains_national_prefix raw_input national_prefix region_code nnn normalize_digits_only raw_input if nnn.startswith national_prefix try return is_valid_number parse nnn[len national_prefix ] region_code except NumberParseException return Falsereturn False
def fold_arg_vars typevars args vararg kws n_pos_args len args kwds [kw for kw var in kws]argtypes [typevars[a.name] for a in args]argtypes + [typevars[var.name] for kw var in kws]if vararg is not None argtypes.append typevars[vararg.name] if not all a.defined for a in argtypes returnargs tuple a.getone for a in argtypes pos_args args[ n_pos_args]if vararg is not None if not isinstance args[ -1 ] types.BaseTuple raise TypeError '*argsinfunctioncallshouldbeatuple got%s' % args[ -1 ] pos_args + args[ -1 ].typesargs args[ -1 ]kw_args dict zip kwds args[n_pos_args ] return pos_args kw_args
def _execute2 *args **kargs cmd args[1 -3 ] if args[0] 'raidcom' else args result EXECUTE_TABLE2.get cmd CMD_SUCCEED return result
def build_simple_test command_name return build_schema_test name str command_name + u'Tests' schema {u'$ref' u'/endpoints.json#/definitions/' + command_name } schema_store SCHEMAS failing_instances {'additionalProperties' [{u'Err' u'' u'Extra' u''} {u'Result' u'hello'}] 'required' [{}] 'type' [[] u'' None {u'Err' 1} {u'Err' {}} {u'Err' None}]} passing_instances [{u'Err' u''} {u'Err' u'Somethingwentwrong!'}]
def _responds result_type data None msg '' return {'result' result_type_map[result_type] 'message' msg 'data' {} if not data else data }
def notify_new_comment unit comment user report_source_bugs mails []subscriptions Profile.objects.subscribed_new_comment unit.translation.subproject.project comment.language user for subscription in subscriptions mails.append subscription.notify_new_comment unit comment user if comment.language is None and report_source_bugs ! u'' send_notification_email u'en' report_source_bugs u'new_comment' unit.translation {u'unit' unit u'comment' comment u'subproject' unit.translation.subproject} user user send_mails mails
def _ln_gamma_function alpha if alpha < 0 raise ValueErrorx alphaf 0if x < 7 f 1z xwhile z < 7 f * zz + 1x zf - log f z 1 / x * x return f + x - 0.5 * log x - x + 0.918938533204673 + -0.000595238095238 * z + 0.000793650793651 * z - 0.002777777777778 * z + 0.083333333333333 / x
def _makePackages parent attributes result attrs {}for name value in list attributes.items if parent is None if isinstance value dict module ModuleType name module.__dict__.update _makePackages module value result result[name] moduleelse result[name] valueelif isinstance value dict module ModuleType parent.__name__ + '.' + name module.__dict__.update _makePackages module value result result[ parent.__name__ + '.' + name ] moduleattrs[name] moduleelse attrs[name] valuereturn attrs
def time_zones_for_number numobj ntype number_type numobj if ntype PhoneNumberType.UNKNOWN return _UNKNOWN_TIME_ZONE_LISTelif not _can_be_geocoded ntype return _country_level_time_zones_for_number numobj return time_zones_for_geographical_number numobj
def _get_handler_methods handler methods []for method in get_app .allowed_methods if getattr handler _normalize_handler_method method None methods.append method return methods
def random_normal return inverse_normal_cdf random.random
def merge_series target other function operator.add missing object results []for x y in itertools.izip_longest target other fillvalue missing assert x is not missing and y is not missing 'seriesmustbesamelength'assert x[0] y[0] 'seriestimestampsmustmatch'results.append x[0] function x[1] y[1] return results
def splitpasswd user global _passwdprogif _passwdprog is None import re_passwdprog re.compile '^ [^ ]* .* $' re.S match _passwdprog.match user if match return match.group 1 2 return user None
def private_api f f.private_api Truereturn f
def _active_mounts_openbsd ret for line in __salt__['cmd.run_stdout'] 'mount-v' .split '\n' comps re.sub '\\s+' '' line .split parens re.findall '\\ .*? \\ ' line re.DOTALL if len parens > 1 nod __salt__['cmd.run_stdout'] 'ls-l{0}'.format comps[0] nod ''.join nod.split .split '' ret[comps[3]] {'device' comps[0] 'fstype' comps[5] 'opts' _resolve_user_group_names parens[1].split ' ' 'major' str nod[4].strip ' ' 'minor' str nod[5] 'device_uuid' parens[0]}else ret[comps[2]] {'device' comps[0] 'fstype' comps[4] 'opts' _resolve_user_group_names parens[0].split ' ' }return ret
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def SetLocationList diagnostics vim.eval u'setloclist 0 {0} '.format json.dumps diagnostics
def get_course_enrollment_info course_id include_expired False course_key CourseKey.from_string course_id try course CourseOverview.get_from_id course_key except CourseOverview.DoesNotExist msg u'Requestedenrollmentinformationforunknowncourse{course}'.format course course_id log.warning msg raise CourseNotFoundError msg else return CourseSerializer course include_expired include_expired .data
def volume_type_qos_associate context type_id qos_specs_id return IMPL.volume_type_qos_associate context type_id qos_specs_id
def _astroid_bootstrapping astroid_builtin None if astroid_builtin is None from logilab.common.compat import builtinsastroid_builtin Astroid_BUILDER.inspect_build builtins for cls node_cls in CONST_CLS.items if cls is type None proxy build_class 'NoneType' proxy.parent astroid_builtinelse proxy astroid_builtin.getattr cls.__name__ [0]if cls in dict list set tuple node_cls._proxied proxyelse _CONST_PROXY[cls] proxy
def morgue morgue_tabs [ T 'MorgueDetails' '' T 'Bodies' 'body' ]rheader S3ResourceHeader [[ T 'Morgue' 'name' ]] tabs morgue_tabs def prep r s3db.gis_location_filter r if r.interactive and r.id and not r.component field r.table.obsoletefield.readable field.writable Truereturn Trues3.prep prepoutput s3_rest_controller rheader rheader return output
def theano_parzen data mu sigma x dataa x.dimshuffle 0 'x' 1 - mu.dimshuffle 'x' 0 1 / sigma E log_mean_exp -0.5 * a ** 2 .sum 2 Z mu.shape[1] * T.log sigma * numpy.sqrt numpy.pi * 2 return E - Z
def test_columnize_long size 11items [ l * size for l in 'abc']for row_first in [True False] out text.columnize items row_first row_first displaywidth size - 1 nt.assert_equal out '\n'.join items + [''] 'row_first {0}'.format row_first
def decrypt_aes secret key sha SHA256.new sha.update key for _i in range 1 1000 + 1 sha.update secret[28 60] aeskey sha.digest data ''for i in range 60 len secret 16 aes AES.new aeskey AES.MODE_CBC '\x00' * 16 buf secret[i i + 16 ]if len buf < 16 buf + 16 - len buf * '\x00' data + aes.decrypt buf return data
def _combine_details detailses result {}for details in detailses gather_details details result return pmap result
def read_number s start_position m _READ_NUMBER_VALUE.match s start_position if not m or not m.group 1 or m.group 2 raise ReadError 'number' start_position if m.group 2 return float m.group m.end else return int m.group m.end
def mxp_parse text text text.replace '&' '&amp;' .replace '<' '&lt;' .replace '>' '&gt;' text LINKS_SUB.sub MXP_SEND text return text
def date_from_relative_day base_date time dow base_date datetime base_date.year base_date.month base_date.day time time.lower dow dow.lower if time 'this' or time 'coming' num HASHWEEKDAYS[dow]return this_week_day base_date num elif time 'last' or time 'previous' num HASHWEEKDAYS[dow]return previous_week_day base_date num elif time 'next' or time 'following' num HASHWEEKDAYS[dow]return next_week_day base_date num
def name dev return info dev .get 'N' None
def test_cubic_prec Chart datas chart Chart interpolate 'cubic' interpolation_precision 200 chart make_data chart datas chart_low Chart interpolate 'cubic' interpolation_precision 5 chart_low make_data chart datas assert len chart.render > len chart_low.render
def extractTextTagContent page page page or '' if REFLECTED_VALUE_MARKER in page page re.sub ' ?si [^\\s>]*%s[^\\s<]*' % REFLECTED_VALUE_MARKER '' page return filter None _.group 'result' .strip for _ in re.finditer TEXT_TAG_REGEX page
def _coil_trans_to_loc coil_trans coil_trans coil_trans.astype np.float64 return np.roll coil_trans.T[ 3] 1 0 .flatten
def topic_list request slug template_name 'groups/topics/topic_list.html' group get_object_or_404 Group slug slug is_active True topic_list GroupTopic.objects.filter group group is_active True return render request template_name {'group' group 'topic_list' topic_list}
def enrollment_mode_display mode verification_status course_id show_image Falseimage_alt ''enrollment_title ''enrollment_value ''display_mode _enrollment_mode_display mode verification_status course_id if display_mode DISPLAY_VERIFIED if verification_status in [VERIFY_STATUS_NEED_TO_VERIFY VERIFY_STATUS_SUBMITTED] enrollment_title _ 'Yourverificationispending' enrollment_value _ 'Verified PendingVerification' show_image Trueimage_alt _ 'IDverificationpending' elif verification_status VERIFY_STATUS_APPROVED enrollment_title _ "You'reenrolledasaverifiedstudent" enrollment_value _ 'Verified' show_image Trueimage_alt _ 'IDVerifiedRibbon/Badge' elif display_mode DISPLAY_HONOR enrollment_title _ "You'reenrolledasanhonorcodestudent" enrollment_value _ 'HonorCode' elif display_mode DISPLAY_PROFESSIONAL enrollment_title _ "You'reenrolledasaprofessionaleducationstudent" enrollment_value _ 'ProfessionalEd' return {'enrollment_title' unicode enrollment_title 'enrollment_value' unicode enrollment_value 'show_image' show_image 'image_alt' unicode image_alt 'display_mode' _enrollment_mode_display mode verification_status course_id }
def delete_files cookie tokens filelist url ''.join [const.PAN_API_URL 'filemanager?channel chunlei&clienttype 0&web 1&opera delete' '&bdstoken ' tokens['bdstoken']] data 'filelist ' + encoder.encode_uri_component json.dumps filelist req net.urlopen url headers {'Content-type' const.CONTENT_FORM_UTF8 'Cookie' cookie.header_output } data data.encode if req content req.datareturn json.loads content.decode else return None
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def expose_api_raw func return expose_api func to_json False
def get_host_name_for_vm session instance host_ref get_host_ref_for_vm session instance return session._call_method vutil 'get_object_property' host_ref 'name'
@register_canonicalize@register_specialize@gof.local_optimizer [T.TensorFromScalar] def local_tensor_scalar_tensor node if isinstance node.op T.TensorFromScalar s node.inputs[0]if s.owner and isinstance s.owner.op T.ScalarFromTensor t s.owner.inputs[0]return [t]
def gf_exquo f g p K q r gf_div f g p K if not r return qelse raise ExactQuotientFailed f g
def random_normal_variable shape mean scale dtype None name None seed None if dtype is None dtype floatx shape tuple map int shape tf_dtype _convert_string_dtype dtype if seed is None seed np.random.randint 1000000000.0 value tf.random_normal_initializer mean scale dtype tf_dtype seed seed shape return variable value dtype dtype name name
def _get_terminal_size_linux def ioctl_GWINSZ fd 'ioctl_GWINSZ.'try import fcntlimport termioscr struct.unpack 'hh' fcntl.ioctl fd termios.TIOCGWINSZ '1234' return crexcept passcr ioctl_GWINSZ 0 or ioctl_GWINSZ 1 or ioctl_GWINSZ 2 if not cr or cr 0 0 try fd os.open os.ctermid os.O_RDONLY cr ioctl_GWINSZ fd os.close fd except passif not cr or cr 0 0 try cr os.environ['LINES'] os.environ['COLUMNS'] except returnreturn int cr[1] int cr[0]
def cpu_usage return _GetSystemStats .cpu
def _symlink src dest try os.symlink src dest except OSError warn 'Couldnotcreatesymboliclink%s.Checkthatyourpartitionhandlessymboliclinks.Thefilewillbecopiedinstead.' % dest shutil.copy src dest
def _add_image collection image image_prep {'id' image.id 'name' image.name 'created_at' image.created_at 'file' image.file 'min_disk' image.min_disk 'min_ram' image.min_ram 'owner' image.owner 'protected' image.protected 'status' image.status 'tags' image.tags 'updated_at' image.updated_at 'visibility' image.visibility}for attr in ['container_format' 'disk_format' 'size'] if attr in image image_prep[attr] image[attr]if type collection is dict collection[image.name] image_prepelif type collection is list collection.append image_prep else msg '"collection"is{0}'.format type collection + 'insteadofdictorlist.' log.error msg raise TypeError msg return collection
def get_num_con_cat con_by_sample cat_by_sample num_con_cat defaultdict float num_con 0for sample connects in con_by_sample.items sample_categories cat_by_sample[sample]for s_con in connects if s_con not in cat_by_sample.keys continuefor s_cat con_cat in zip sample_categories cat_by_sample[s_con] if s_cat con_cat num_con_cat[s_cat[0]] + 0.5num_con + 0.5return num_con_cat num_con
def login_redirect request ignorable_nexts u'' if u'mezzanine.accounts' in settings.INSTALLED_APPS from mezzanine.accounts import urlsignorable_nexts + urls.SIGNUP_URL urls.LOGIN_URL urls.LOGOUT_URL next next_url request or u'' if next in ignorable_nexts next settings.LOGIN_REDIRECT_URLif next u'/accounts/profile/' next get_script_prefix else try next reverse next except NoReverseMatch passreturn redirect next
def allow_api_profiling handler if not settings.DEBUG return handlerelse def aap_wrapper_fn request *args **kwargs response handler request *args **kwargs if not request.is_ajax and response['Content-Type'] 'application/json' response.content '<body>%s</body>' % response.content response['Content-Type'] 'text/html'return responsereturn aap_wrapper_fn
def eccentricity jd T jd - jd1950 / 36525.0 p -1.26e-07 -4.193e-05 0.01673011 return np.polyval p T
def greenthread_yield dbapi_con con_record greenthread.sleep 0
def getCodeFromParamStr val tmp re.sub '^ \\$ +' '' val tmp2 re.sub ' [^\\\\] \\$ +' '\\1' tmp return re.sub '[\\\\]\\$' '$' tmp2
def parsePrimitiveCategory chunks primitives families var if chunks[0] u'var' if chunks[1] is None if var is None var CCGVar return var var catstr chunks[0]if catstr in families cat cvar families[catstr]if var is None var cvarelse cat cat.substitute [ cvar var ] return cat var if catstr in primitives subscrs parseSubscripts chunks[1] return PrimitiveCategory catstr subscrs var raise AssertionError u"String'" + catstr + u"'isneitherafamilynorprimitivecategory."
def rational_polynomial2 data return data[0] - 3 ** 4 + data[1] - 3 ** 3 - data[1] - 3 / data[1] - 2 ** 4 + 10
def _token_splittable token if '_' in token return Falseelse try return not unicodedata.lookup 'GREEKSMALLLETTER' + token except KeyError passif len token > 1 return Truereturn False
def get_memory_usage pid os.getpid process subprocess.Popen "ps-orss%s|awk'{sum+ $1}END{printsum}'" % pid shell True stdout subprocess.PIPE stdout_list process.communicate [0].split '\n' return int stdout_list[0]
def __remove_pyc_pyo fname if osp.splitext fname [1] '.py' for ending in 'c' 'o' if osp.exists fname + ending os.remove fname + ending
@block_user_agents@login_required@process_document_pathdef select_locale request document_slug document_locale doc get_object_or_404 Document locale document_locale slug document_slug return render request 'wiki/select_locale.html' {'document' doc}
def mark_content_as_spam user by_user for question in Question.objects.filter creator user question.mark_as_spam by_user for answer in Answer.objects.filter creator user answer.mark_as_spam by_user
def styleId_from_name name return {'caption' 'Caption' 'heading1' 'Heading1' 'heading2' 'Heading2' 'heading3' 'Heading3' 'heading4' 'Heading4' 'heading5' 'Heading5' 'heading6' 'Heading6' 'heading7' 'Heading7' 'heading8' 'Heading8' 'heading9' 'Heading9'}.get name name.replace '' ''
def mock_unfrackpath_noop path return path
def read_element_id stream char _read stream 1 byte ord char if byte & 128 return byteelif byte & 64 return unpack '>H' char + _read stream 1 [0]elif byte & 32 b h unpack '>BH' char + _read stream 2 return b * 2 ** 16 + h elif byte & 16 return unpack '>L' char + _read stream 3 [0]else ValueError 'NotanElementID'
def kurtosis iterable sample False a iterable if isinstance iterable list else list iterable return moment a 4 sample / moment a 2 sample ** 2.0 or 1 - 3
def shuffled iterable **kwargs seed kwargs.get 'seed' return sorted list iterable key lambda x random
def _get_stdout stderr False if stderr stream u'stderr'else stream u'stdout'sys_stream getattr sys stream if IPythonIOStream is None return sys_streamipyio_stream getattr ipyio stream if isatty sys_stream and isatty ipyio_stream return ipyio_streamelse return sys_stream
def serve_in_child sock if os.fork 0 try serve_socket sock finally sys.exit
def unexpo intpart fraction expo if expo > 0 f len fraction intpart fraction intpart + fraction[ expo] fraction[expo ] if expo > f intpart intpart + '0' * expo - f elif expo < 0 i len intpart intpart fraction intpart[ expo] intpart[expo ] + fraction if expo < - i fraction '0' * - expo - i + fraction return intpart fraction
def baseTransform val from pybrain.structure.modules.module import Modulefrom inspect import isclassif isinstance val Module return val.nameelif isclass val return val.__name__else return str val
def resolve_relation scope_model relation if relation RECURSIVE_RELATIONSHIP_CONSTANT relation scope_modelif isinstance relation str if '.' not in relation relation '%s.%s' % scope_model._meta.app_label relation return relation
def _item_to_resource_record_set iterator resource return ResourceRecordSet.from_api_repr resource iterator.zone
def drive_test test_driver_class test_driver test_driver_class sys.exit test_driver.run
def getTranslatedComplexPath path translateComplex translatedComplexPath []for point in path translatedComplexPath.append point + translateComplex return translatedComplexPath
def mlsd conn path '' facts None facts facts or [] if facts conn.sendcmd 'OPTSMLST' + ';'.join facts + ';' if path cmd 'MLSD%s' % path else cmd 'MLSD'lines []conn.retrlines cmd lines.append for line in lines facts_found _ name line.rstrip ftplib.CRLF .partition '' entry {}for fact in facts_found[ -1 ].split ';' key _ value fact.partition ' ' entry[key.lower ] value yield name entry
def addMenuEntitiesToMenu menu menuEntities for menuEntity in menuEntities menuEntity.addToMenu menu
def powershell registry xml_parent data ps XML.SubElement xml_parent 'hudson.plugins.powershell.PowerShell' XML.SubElement ps 'command' .text data
def getNearestPointOnSegment segmentBegin segmentEnd point segmentDifference segmentEnd - segmentBegin if abs segmentDifference < 0.0 return segmentBeginpointMinusSegmentBegin point - segmentBegin beginPlaneDot getDotProduct pointMinusSegmentBegin segmentDifference differencePlaneDot getDotProduct segmentDifference segmentDifference intercept beginPlaneDot / differencePlaneDot intercept max intercept 0.0 intercept min intercept 1.0 return segmentBegin + segmentDifference * intercept
def _partitions_of_index_values divisions values if divisions[0] is None msg 'CannotuseloconDataFramewithoutknowndivisions'raise ValueError msg results defaultdict list values pd.Index values dtype object for val in values i bisect.bisect_right divisions val div min len divisions - 2 max 0 i - 1 results[div].append val return results
def test_feature_first_scenario_tag_extraction feature Feature.from_string FEATURE22 assert that feature.scenarios[0].tags .deep_equals ['onetag']
def _safe_postlogin_redirect redirect_to safehost default_redirect '/' if is_safe_url url redirect_to host safehost return redirect redirect_to return redirect default_redirect
def decode_bits received_bitvec rec received_bitvecsyn numpy.dot DEFAULT_H rec % 2 try err numpy.array DEFAULT_SYNDROME_LUT[tuple syn ] except KeyError return None 4 corrected rec + err % 2 return corrected numpy.sum err
def _unquote_or_none s if s is None return sreturn url_unescape s encoding None plus False
@utils.arg '--all-tenants' action 'store_const' const 1 default 0 help _ 'Stopserver s inanothertenantbyname Adminonly .' @utils.arg 'server' metavar '<server>' nargs '+' help _ 'NameorIDofserver s .' def do_stop cs args find_args {'all_tenants' args.all_tenants}utils.do_action_on_many lambda s _find_server cs s **find_args .stop args.server _ 'Requesttostopserver%shasbeenaccepted.' _ 'Unabletostopthespecifiedserver s .'
def var_tag var tag var.tagif hasattr tag 'trace' and len tag.trace and len tag.trace[0] 4 if isinstance tag.trace[0][0] tuple list path line _ src tag.trace[0][ -1 ]else path line _ src tag.trace[0]path os.path.basename path path path.replace '<' '' path path.replace '>' '' src src.encode return [path line src]else return None
def _iscount X X np.asarray X remainder np.logical_and np.logical_and np.all X % 1.0 0 axis 0 X.var 0 ! 0 np.all X > 0 axis 0 dummy _isdummy X remainder np.where remainder [0].tolist for idx in dummy remainder.remove idx return np.array remainder
def find_lexer_class name if name in _lexer_cache return _lexer_cache[name]for module_name lname aliases _ _ in LEXERS.itervalues if name lname _load_lexers module_name return _lexer_cache[name]for cls in find_plugin_lexers if cls.name name return cls
def get_upload_to instance filename return instance.get_upload_to filename
def discount_episode_rewards rewards [] gamma 0.99 discounted_r np.zeros_like rewards dtype np.float32 running_add 0for t in reversed xrange 0 rewards.size if rewards[t] ! 0 running_add 0running_add running_add * gamma + rewards[t] discounted_r[t] running_addreturn discounted_r
def url_is_embeddable_image url parsed_url UrlParser url if parsed_url.path_extension .lower in {'jpg' 'gif' 'png' 'jpeg'} if parsed_url.hostname not in g.known_image_domains return Falsereturn Truereturn False
def test_vector_sympy v1 3 * j assert v1 j * 3 assert v1.components {j 3} v2 3 * i + 4 * j + 5 * k v3 2 * i + 4 * j + i + 4 * k + k assert v3 v2 assert v3.__hash__ v2.__hash__
@_docstring 'recording' def get_recording_by_id id includes [] release_status [] release_type [] params _check_filter_and_make_params 'recording' includes release_status release_type return _do_mb_query 'recording' id includes params
def getAllFilesIn dir tag '' extension '.pickle' allfiles os.listdir dir res []for f in allfiles if f[ - len extension ] extension and f[ len tag ] tag res.append f[ - len extension ] return res
def RegisterClassFactories clsids flags None clsctx None if flags is None flags pythoncom.REGCLS_MULTIPLEUSE | pythoncom.REGCLS_SUSPENDED if clsctx is None clsctx pythoncom.CLSCTX_LOCAL_SERVERret []for clsid in clsids if clsid[0] not in ['-' '/'] factory pythoncom.MakePyFactory clsid regId pythoncom.CoRegisterClassObject clsid factory clsctx flags ret.append factory regId return ret
def get_boundary return 'b08c02-53d780-e2bc43-1d5278-a3c0d9-a5c0d9'
def split_addresses email_string_list return [f for f in [s.strip for s in email_string_list.split u' ' ] if f]
def module_by_name module_name_ def construct import univention.admin.modulesinit_modules module univention.admin.modules.get module_name_ univention.admin.modules.init uldap position_base_dn module return modulereturn _singleton 'module/%s' % module_name_ construct
@requires_application def test_functionality_proxy _test_basics 'gl2debug'
def col_update fid uid body url build_url RESOURCE id fid route 'col' params make_params uid uid return request 'put' url json body params params
def list_share cookie tokens uk page 1 num 100start 100 * page - 1 url ''.join [const.PAN_URL 'pcloud/feed/getsharelist?' '&t ' util.timestamp '&categor 0&auth_type 1&request_location share_home' '&start ' str start '&limit ' str num '&query_uk ' str uk '&channel chunlei&clienttype 0&web 1' '&bdstoken ' tokens['bdstoken']] req net.urlopen url headers {'Cookie' cookie.header_output 'Referer' const.SHARE_REFERER} if req content req.datareturn json.loads content.decode else return None
@open_file 0 mode 'rb' def read_pajek path encoding 'UTF-8' lines line.decode encoding for line in path return parse_pajek lines
def create_swap_disk vm_ linode_id swap_size None kwargs {}if not swap_size swap_size get_swap_size vm_ kwargs.update {'LinodeID' linode_id 'Label' vm_['name'] 'Type' 'swap' 'Size' swap_size} result _query 'linode' 'disk.create' args kwargs return _clean_data result
def map_references value field actual_course_key if not value return valueif isinstance field Reference return value.map_into_course actual_course_key if isinstance field ReferenceList return [sub.map_into_course actual_course_key for sub in value]if isinstance field ReferenceValueDict return {key ele.map_into_course actual_course_key for key ele in value.iteritems }return value
def logSumExp A B out None if out is None out numpy.zeros A.shape indicator1 A > B indicator2 numpy.logical_not indicator1 out[indicator1] A[indicator1] + numpy.log1p numpy.exp B[indicator1] - A[indicator1] out[indicator2] B[indicator2] + numpy.log1p numpy.exp A[indicator2] - B[indicator2] return out
def get_comment_list parser token return CommentListNode.handle_token parser token
def parse_prototype text m re_symbol.match text if not m raise ValueError 'Invalidfunctionnameforexportprototype' s m.start 0 e m.end 0 symbol text[s e]functype text[ e + 1 ]return symbol functype
def sanitize_filename filename if isinstance filename str unicode filename re.sub u'[\\\\/\\*]' u'-' filename filename re.sub u'[ "<>|?]' u'' filename filename re.sub u'\u2122' u'' filename filename filename.strip u'.' return filenamereturn u''
def generate_hash txt None length None import hashlib timefrom .utils import random_stringdigest hashlib.sha224 txt or u'' + repr time.time + repr random_string 8 .hexdigest if length digest digest[ length]return digest
def wsgi_path_item environ name try return environ['wsgiorg.routing_args'][1][name]except KeyError IndexError return None
def dedent content content force_text content whitespace_counts [ len line - len line.lstrip u'' for line in content.splitlines [1 ] if line.lstrip ]tab_counts [ len line - len line.lstrip u' DCTB ' for line in content.splitlines [1 ] if line.lstrip ]if whitespace_counts whitespace_pattern u'^' + u'' * min whitespace_counts content re.sub re.compile whitespace_pattern re.MULTILINE u'' content elif tab_counts whitespace_pattern u'^' + u' DCTB ' * min whitespace_counts content re.sub re.compile whitespace_pattern re.MULTILINE u'' content return content.strip
def _tkerror err pass
def getGNUTranslatorGcodeFileTypeTuples fileTypeTuples getTranslatorFileTypeTuples fileTypeTuples.append 'Gcodetextfiles' '*.gcode' fileTypeTuples.sort return fileTypeTuples
def _service_by_name name services _available_services name name.lower if name in services return services[name]for service in six.itervalues services if service['file_path'].lower name return service basename ext os.path.splitext service['filename'] if basename.lower name return servicereturn False
def _get_pkgng_version jail None chroot None root None cmd _pkg jail chroot root + ['--version'] return __salt__['cmd.run'] cmd .strip
def fullcascade attr doc '' def getter self return getattr self._items[0] attr def setter self value for item in self setattr item attr value return property fget getter fset setter doc doc
@then u'weseerecordupdated' def step_see_record_updated context _expect_exact context u'UPDATE1' timeout 2
def handle_var value context if isinstance value FilterExpression or isinstance value Variable return value.resolve context stringval QUOTED_STRING.search value if stringval return stringval.group u'noquotes' try return Variable value .resolve context except VariableDoesNotExist return value
def change_user_cookie_security secure remember if secure set_secure_session_cookie remember else delete_secure_session_cookie if not c.user_is_loggedin returnuser_name c.user.namesecurable PRIVATE_SESSION_COOKIES + [ user_name + '_' + c_name for c_name in PRIVATE_USER_COOKIES] for name cookie in c.cookies.iteritems if name in securable cookie.secure secureif name in PRIVATE_SESSION_COOKIES if name ! '_options' cookie.httponly Trueif remember and name g.login_cookie cookie.expires NEVERcookie.dirty True
def master_open try master_fd slave_fd os.openpty except AttributeError OSError passelse slave_name os.ttyname slave_fd os.close slave_fd return master_fd slave_name return _open_terminal
def new_parser_harness results_dirpath if not path.exists results_dirpath raise BadResultsDirectoryErrorkeyval_path path.join results_dirpath KEYVAL job_keyval utils.read_keyval keyval_path status_version job_keyval[STATUS_VERSION]parser status_lib.parser status_version job parser.make_job results_dirpath status_log_filepath path.join results_dirpath 'status.log' if not path.exists status_log_filepath raise BadResultsDirectoryErrorreturn ParserHarness parser job job_keyval status_version status_log_filepath
def _execute_task arg cache dsk None if isinstance arg list return [_execute_task a cache for a in arg]elif istask arg func args arg[0] arg[1 ] args2 [_execute_task a cache for a in args]return func *args2 elif not ishashable arg return argelif arg in cache return cache[arg]else return arg
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def disable_quota_volume name cmd 'volumequota{0}disable'.format name if not _gluster cmd return Falsereturn True
def sync_rheader r tabs [] if r.representation 'html' if r.tablename 'sync_repository' T current.Trepository r.recordif r.component and r.component_name 'log' and not r.component_id purge_log A T 'Removealllogentries' _href r.url method 'delete' else purge_log ''if repository if repository.url or repository.apitype 'filesync' and repository.path tabs.append T 'ManualSynchronization' 'now' rheader_tabs s3_rheader_tabs r tabs rheader DIV TABLE TR TH '%s ' % T 'Name' repository.name TH '' purge_log TR TH 'URL ' repository.url TH '' '' rheader_tabs return rheaderreturn None
def var_to_list var if isinstance var list return varif not var return []return [var]
def create_patch_viewer grid_shape vis_chains m pv PatchViewer grid_shape vis_chains.shape[1 3] is_color vis_chains.shape[ -1 ] 3 for i in xrange m pv.add_patch vis_chains[i ] rescale False return pv
def update_blog_supernav latest_entry BlogEntry.objects.filter feed_id 1 .latest rendered_box _render_blog_supernav latest_entry box Box.objects.get label 'supernav-python-blog' box.content rendered_boxbox.save
def _percentDecode text try quotedBytes text.encode 'ascii' except UnicodeEncodeError return textunquotedBytes urlunquote quotedBytes try return unquotedBytes.decode 'utf-8' except UnicodeDecodeError return text
def own_metadata module return module.get_explicitly_set_fields_by_scope Scope.settings
def richardson A k n N s S.Zerofor j in range 0 N + 1 s + A.subs k Integer n + j .doit * n + j ** N * -1 ** j + N / factorial j * factorial N - j return s
def column_or_1d y warn False shape np.shape y if len shape 1 return np.ravel y if len shape 2 and shape[1] 1 if warn warnings.warn 'Acolumn-vectorywaspassedwhena1darraywasexpected.Pleasechangetheshapeofyto n_samples forexampleusingravel .' DataConversionWarning stacklevel 2 return np.ravel y raise ValueError 'badinputshape{0}'.format shape
def _item_to_row iterator resource return _row_from_json resource iterator.schema
@parse_data@set_databasedef get_content_parents ids None **kwargs if ids Parent Item.alias parent_values Item.select Parent .join Parent on Item.parent Parent.pk .where Item.id.in_ ids .distinct if parent_values is None parent_values list return parent_valueselse return list
def equateRectangularDotX point returnValue point.x returnValue
def extract_client_header rewrited_headers {}dbgprint 'BrowserRequestHeaders ' request.headers for head_name head_value in request.headers head_name_l head_name.lower if head_name_l in 'host' 'content-length' continueelif head_name_l 'content-type' and head_value '' continueelif head_name_l 'accept-encoding' and 'br' in head_value or 'sdch' in head_value _str_buff ''if 'gzip' in head_value _str_buff + 'gzip 'if 'deflate' in head_value _str_buff + 'deflate'if _str_buff rewrited_headers[head_name_l] _str_buffcontinueelse rewrited_headers[head_name_l] client_requests_text_rewrite head_value if head_name_l 'cookie' rewrited_headers[head_name_l] regex_remove__zmirror_verify__header.sub '' rewrited_headers[head_name_l] dbgprint 'FilteredBrowserRequestHeaders ' rewrited_headers return rewrited_headers
def nicheSchematas type size rept int size / type return [ '#' * i * rept + '1' * rept + '#' * type - i - 1 * rept for i in range type ]
def combine_cmds *cmds cmd combine_values *cmds if cmd is None return Noneelif isinstance cmd string_types return shlex_split cmd else return list cmd
def generate_datafile_old number_items 1000 from utils import get_names generate_datasetfrom pprint import pprintfilename 'samples.py'dataset generate_dataset number_items fo open filename 'wb' fo.write '#!/usr/bin/envpython\n' fo.write '#-*-coding utf-8-*-\n' fo.write '#Brainaetic http //www.thenetplanet.com\n\n' fo.write 'SAMPLES ' pprint dataset fo fo.close print '%sgeneratedwith%dsamples' % filename number_items
def getTwistPrecisionRadians elementNode return math.radians getTwistPrecision elementNode
def register linter linter.register_checker ExceptionsChecker linter
def map_type cffi_type kind getattr cffi_type 'kind' '' if kind 'union' raise TypeError 'NosupportforCFFIunion' elif kind 'function' if cffi_type.ellipsis raise TypeError 'varargfunctionisnotsupported' restype map_type cffi_type.result argtypes [map_type arg for arg in cffi_type.args]return templates.signature restype *argtypes elif kind 'pointer' pointee cffi_type.itemif pointee.kind 'void' return types.voidptrelse return types.CPointer map_type pointee else result _type_map .get cffi_type if result is None raise TypeError cffi_type return result
def update_site_backward apps schema_editor Site apps.get_model u'sites' u'Site' Site.objects.update_or_create id settings.SITE_ID defaults {u'domain' u'example.com' u'name' u'example.com'}
def pycodestylemod_add_ignore ignore_code if ignore_code not in pycodestylemod.DEFAULT_IGNORE default_ignore pycodestylemod.DEFAULT_IGNORE.split ' ' default_ignore.append ignore_code pycodestylemod.DEFAULT_IGNORE ' '.join default_ignore
def dtype_info_name dtype dtype np.dtype dtype if dtype.kind in 'S' 'U' length re.search ' \\d+ ' dtype.str .group 1 type_name STRING_TYPE_NAMES[ not six.PY2 dtype.kind ]out type_name + length else out dtype.namereturn out
def not_implemented_for *graph_types @decoratordef _not_implemented_for f *args **kwargs graph args[0]terms {'directed' graph.is_directed 'undirected' not graph.is_directed 'multigraph' graph.is_multigraph 'graph' not graph.is_multigraph }match Truetry for t in graph_types match match and terms[t] except KeyError raise KeyError 'useoneormoreof' 'directed undirected multigraph graph' if match raise nx.NetworkXNotImplemented 'notimplementedfor%stype' % ''.join graph_types else return f *args **kwargs return _not_implemented_for
def subscribe_to_collection user_id collection_id subscriptions_model user_models.UserSubscriptionsModel.get user_id strict False if not subscriptions_model subscriptions_model user_models.UserSubscriptionsModel id user_id if collection_id not in subscriptions_model.collection_ids subscriptions_model.collection_ids.append collection_id subscriptions_model.put
def test_cleanup_after_install script data script.pip 'install' '--no-index' '--find-links %s' % data.find_links 'simple' build script.venv_path / 'build' src script.venv_path / 'src' assert not exists build 'build/dirstillexists %s' % build assert not exists src 'unexpectedsrc/direxists %s' % src script.assert_no_temp
def model_dependencies model checked_models None depends set checked_models checked_models or set for field in model._meta.fields + model._meta.many_to_many depends.update field_dependencies field checked_models for base in model.__bases__ if issubclass base models.Model and hasattr base '_meta' and not base._meta.abstract depends.add base new_to_check depends - checked_models while new_to_check checked_model new_to_check.pop if checked_model model or checked_model in checked_models continuechecked_models.add checked_model deps model_dependencies checked_model checked_models for dep in deps if dep not in depends and dep not in new_to_check and dep not in checked_models new_to_check.add dep depends.add dep return depends
def run_twisted apps port static_dir '.' interface '0.0.0.0' import twisted.web.serverimport twisted.web.staticfrom twisted.web.resource import Resourcefrom twisted.web.wsgi import WSGIResourcefrom twisted.internet import reactorif static_dir ! None static_dir os.path.abspath static_dir logging.info 'registeringstaticfolder%ron/' % static_dir root twisted.web.static.File static_dir else root Resource for app url in apps resource WSGIResource reactor reactor app logging.info 'registering%ron/%s' % app url root.putChild url resource site twisted.web.server.Site root reactor.listenTCP port site interface interface logging.info 'listeningon %s %d' % interface port return reactor.run
def args arg_list parser argparse.ArgumentParser usage '% prog s' description 'OpenStackInventoryGenerator' epilog 'InventoryGeneratorLicensed"Apache2.0"' parser.add_argument '--config' help 'Pathcontainingtheuserdefinedconfigurationfiles' required False default None parser.add_argument '--list' help 'Listallentries' action 'store_true' parser.add_argument '--check' help "Configurationcheckonly don'tgenerateinventory" action 'store_true' parser.add_argument '-d' '--debug' help 'Outputdebugmessagestologfile.Fileisappendedto notoverwritten' action 'store_true' default False parser.add_argument '-e' '--environment' help 'Directorythatcontainsthebaseenv.ddirectory.\nDefaultsto<OSA_ROOT>/playbooks/inventory/.' required False default os.path.dirname __file__ return vars parser.parse_args arg_list
def get_limited_to_project headers global _ENFORCERif not _ENFORCER _ENFORCER policy.Enforcer if not _ENFORCER.enforce 'context_is_admin' {} {'roles' headers.get 'X-Roles' '' .split ' ' } return headers.get 'X-Tenant-Id'
def dest_namespace name return name.replace '-' '_' + '_'
def MAX ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.MAX timeperiod
def overwrite_novel_deltas baseline deltas dates get_indexes dates.searchsortednovel_idx get_indexes deltas[TS_FIELD_NAME].values 'right' - get_indexes deltas[AD_FIELD_NAME].values 'left' < 1 novel_deltas deltas.loc[novel_idx]non_novel_deltas deltas.loc[ ~ novel_idx ]cat pd.concat baseline novel_deltas ignore_index True copy False cat.sort_values TS_FIELD_NAME inplace True return cat non_novel_deltas
def compare_files self result_file ref_file self.assertEqual result_file.src ref_file.src self.assertEqual result_file.dest ref_file.dest self.assertEqual result_file.compare_key ref_file.compare_key self.assertEqual result_file.size ref_file.size self.assertEqual result_file.last_update ref_file.last_update self.assertEqual result_file.src_type ref_file.src_type self.assertEqual result_file.dest_type ref_file.dest_type self.assertEqual result_file.operation_name ref_file.operation_name
def _test_args import pandas as pdreturn {'start' pd.Timestamp '2013-10-07' tz 'utc' 'end' pd.Timestamp '2013-11-30' tz 'utc' 'capital_base' 100000}
def tamper payload **kwargs retVal ''if payload retVal '%s%ssp_password' % payload '--' if not any _ if _ in payload else None for _ in '#' '--' else '' return retVal
def readbytes filename buffersize 1024 infile open filename 'rb' for byte in filebytes infile buffersize yield byte
def squeeze a axis None return a.squeeze axis
def lineagename_for_filename config_filename if not config_filename.endswith '.conf' raise errors.CertStorageError 'renewalconfigfilenamemustendin.conf' return os.path.basename config_filename[ - len '.conf' ]
def filterAuthorizedKeys fp for line in fp line line.rstrip '\n' if line COMMENT continueif _COMMAND_RE.match line continue yield line
def companion a a np.atleast_1d a if a.ndim ! 1 raise ValueError 'Incorrectshapefor`a`.`a`mustbeone-dimensional.' if a.size < 2 raise ValueError 'Thelengthof`a`mustbeatleast2.' if a[0] 0 raise ValueError 'Thefirstcoefficientin`a`mustnotbezero.' first_row - a[1 ] / 1.0 * a[0] n a.sizec np.zeros n - 1 n - 1 dtype first_row.dtype c[0] first_rowc[ list range 1 n - 1 list range 0 n - 2 ] 1return c
def get_single_color_func color old_r old_g old_b ImageColor.getrgb color rgb_max 255.0 h s v colorsys.rgb_to_hsv old_r / rgb_max old_g / rgb_max old_b / rgb_max def single_color_func word None font_size None position None orientation None font_path None random_state None 'Randomcolorgeneration.\n\nAdditionalcoloringmethod.Itpicksarandomvaluewithhueand\nsaturationbasedonthecolorgiventothegeneratingfunction.\n\nParameters\n----------\nword font_size position orientation ignored.\n\nrandom_state random.RandomobjectorNone default None \nIfarandomobjectisgiven thisisusedforgeneratingrandom\nnumbers.\n\n'if random_state is None random_state Random r g b colorsys.hsv_to_rgb h s random_state.uniform 0.2 1 return 'rgb { .0f} { .0f} { .0f} '.format r * rgb_max g * rgb_max b * rgb_max return single_color_func
def get_mode path if not os.path.exists path return ''func_name '{0}.get_mode'.format __virtualname__ if __opts__.get 'fun' '' func_name log.info 'Thefunction{0}shouldnotbeusedonWindowssystems;seefunctiondocsfordetails.ThevaluereturnedisalwaysNone.'.format func_name return None
@check_db_locksdef api_request app *api_path **kwargs base_url app.hub.server.urlheaders kwargs.setdefault 'headers' {} if 'Authorization' not in headers headers.update auth_header app.db 'admin' url ujoin base_url 'api' *api_path method kwargs.pop 'method' 'get' f getattr requests method resp f url **kwargs assert "frame-ancestors'self'" in resp.headers['Content-Security-Policy'] assert ujoin app.hub.server.base_url 'security/csp-report' in resp.headers['Content-Security-Policy'] assert 'http' not in resp.headers['Content-Security-Policy'] return resp
def secondary_with_tags_server_selector tag_sets selection return apply_tag_sets tag_sets secondary_server_selector selection
def prepare_js_for_gettext js def escape_quotes m 'Usedinaregextoproperlyescapedoublequotes.'s m.group 0 if s '"' return '\\"'else return slexer JsLexer c []for name tok in lexer.lex js if name 'regex' tok '"REGEX"'elif name 'string' if tok.startswith "'" guts re.sub '\\\\.|.' escape_quotes tok[1 -1 ] tok '"' + guts + '"' elif name 'id' tok tok.replace '\\' 'U' c.append tok return ''.join c
def BuildBudgetOperations batch_job_helper budget_operations [{'xsi_type' 'BudgetOperation' 'operand' {'name' 'Batchbudget#%s' % uuid.uuid4 'budgetId' batch_job_helper.GetId 'amount' {'microAmount' '50000000'} 'deliveryMethod' 'STANDARD'} 'operator' 'ADD'}]return budget_operations
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def list_nodes conn None call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodesfunctionmustbecalledwith-for--function.' ret {}nodes list_nodes_full conn call for node in nodes ret[node] {'name' node}for prop in 'id' 'image' 'size' 'state' 'private_ips' 'public_ips' ret[node][prop] nodes[node].get prop return ret
def exec_python *args **kwargs cmdargs kwargs __wrap_python args kwargs return exec_command *cmdargs **kwargs
def req_req_drivers row if hasattr row 'req_req' row row.req_reqtry req_ref row.req_reftype row.typeexcept AttributeError return Noneif type 1 s3db current.s3dbstable s3db.inv_sendquery stable.deleted ! True & stable.req_ref req_ref drivers current.db query .select stable.driver_name stable.driver_phone stable.vehicle_plate_no if drivers drivers [ '%s%s%s' % driver.driver_name or '' driver.driver_phone or '' driver.vehicle_plate_no or '' for driver in drivers]return ' '.join drivers return current.messages['NONE']
def check_server host port ajax if host.lower 'localhost' and sabnzbd.AMBI_LOCALHOST return badParameterResponse T 'Warning LOCALHOSTisambiguous usenumericalIP-address.' ajax if GetServerParms host int_conv port return ''else return badParameterResponse T 'Serveraddress"%s %s"isnotvalid.' % host port ajax
def atoi s try return int s or '0' except ValueError return 0
def getopenfilename parent None caption '' basedir '' filters '' selectedfilter '' options None return _qfiledialog_wrapper 'getOpenFileName' parent parent caption caption basedir basedir filters filters selectedfilter selectedfilter options options
def pluralize word pos NOUN custom {} return word + 's'
def extend_safe target source for elt in source if elt not in target target.append elt
def _alarms_present name alarms alarms_from_pillar region key keyid profile tmp __salt__['config.option'] alarms_from_pillar {} if alarms tmp dictupdate.update tmp alarms merged_return_value {'name' name 'result' True 'comment' '' 'changes' {}}for _ info in six.iteritems tmp info['name'] name + '' + info['name'] info['attributes']['description'] name + '' + info['attributes']['description'] info['attributes']['dimensions'] {'LoadBalancerName' [name]}kwargs {'name' info['name'] 'attributes' info['attributes'] 'region' region 'key' key 'keyid' keyid 'profile' profile}results __states__['boto_cloudwatch_alarm.present'] **kwargs if not results.get 'result' merged_return_value['result'] results['result']if results.get 'changes' {} ! {} merged_return_value['changes'][info['name']] results['changes']if 'comment' in results merged_return_value['comment'] + results['comment']return merged_return_value
def get_org_prefs orgname None profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.get '{0}/api/org/preferences'.format profile['grafana_url'] auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def topology func *args **kwargs argtypes [GEOM_PTR]if args argtypes + argsfunc.argtypes argtypesfunc.restype kwargs.get 'restype' GEOM_PTR func.errcheck kwargs.get 'errcheck' check_geom return func
def stream_download cookie tokens path url ''.join [const.PCS_URL_D 'file?method download' '&path ' encoder.encode_uri_component path '&app_id 250528'] req net.urlopen_without_redirect url headers {'Cookie' cookie.header_output } if req return reqelse return None
def rastrigin individual return 10 * len individual + sum gene * gene - 10 * cos 2 * pi * gene for gene in individual
def get_image_file_path instance return os.path.join CONF.instances_path instance['name'] 'disk'
def _VerboseLevel return _cpplint_state.verbose_level
def colgen *lstcol **kargs if len lstcol < 2 lstcol * 2trans kargs.get 'trans' lambda x y z x y z while 1 for i in range len lstcol for j in range len lstcol for k in range len lstcol if i ! j or j ! k or k ! i yield trans lstcol[ i + j % len lstcol ] lstcol[ j + k % len lstcol ] lstcol[ k + i % len lstcol ]
def test_reset_dhist _ip.run_cell 'tmp [dfordin_dh]' _ip.magic 'cd' + os.path.dirname nt.__file__ _ip.magic 'cd-' nt.assert_true len _ip.user_ns['_dh'] > 0 _ip.magic 'reset-fdhist' nt.assert_equal len _ip.user_ns['_dh'] 0 _ip.run_cell '_dh [dfordintmp]'
def describe_token_expr expr if ' ' in expr type value expr.split ' ' 1 if type 'name' return valueelse type exprreturn _describe_token_type type
def connect_s3 access_key None secret_key None node_settings None if node_settings is not None if node_settings.external_account is not None access_key secret_key node_settings.external_account.oauth_key node_settings.external_account.oauth_secret connection S3Connection access_key secret_key calling_format OrdinaryCallingFormat return connection
def oo_combine_dict data in_joiner ' ' out_joiner '' if not isinstance data dict raise errors.AnsibleFilterError '|failedexpectsfirstparamisadict[oo_combine_dict].Got%s.Type %s' % str data str type data return out_joiner.join [in_joiner.join [k str v ] for k v in data.items ]
def worktree_state head u'HEAD' update_index False display_untracked True paths None if update_index git.update_index refresh True staged unmerged staged_deleted staged_submods diff_index head paths paths modified unstaged_deleted modified_submods diff_worktree paths untracked display_untracked and untracked_files paths paths or [] if unmerged unmerged_set set unmerged modified [path for path in modified if path not in unmerged_set ]upstream_changed diff_upstream head staged.sort modified.sort unmerged.sort untracked.sort upstream_changed.sort return {u'staged' staged u'modified' modified u'unmerged' unmerged u'untracked' untracked u'upstream_changed' upstream_changed u'staged_deleted' staged_deleted u'unstaged_deleted' unstaged_deleted u'submodules' staged_submods | modified_submods }
def lookup_object spec parts target spec.split ' ' if ' ' in spec else spec None module __import__ parts for part in parts.split '.' [1 ] + [target] if target else [] module getattr module part return module
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def check_environment if os.getenv 'TRAVIS' 'true' is_travis Truenon_pr os.getenv 'TRAVIS_PULL_REQUEST' 'false' and os.getenv 'TRAVIS_BRANCH' 'master' else is_travis non_pr Falsereturn is_travis non_pr
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def lab2lch lab lch _prepare_lab_array lab a b lch[... 1] lch[... 2] lch[... 1] lch[... 2] _cart2polar_2pi a b return lch
def unique_modules directory found {}for entry in sorted os.listdir directory if entry.startswith '_' continuemodule is_module entry if module if module not in found found[module] entry yield module elif is_package os.path.join directory entry if entry not in found found[entry] entry yield entry
def get_pkg_name args pkg_path recipes_dir args.recipes_dirinput_dir os.path.dirname os.path.join recipes_dir pkg_path recipe_meta MetaData input_dir return recipe_meta.get_value 'package/name'
def readDouble data try number struct.unpack '>d' data[0 8] [0]rest data[8 ]return number rest except struct.error print 'Error toofewbytesfordouble' data len data return 0 data
def peer2str addr if isinstance addr IPv4Address res u'tcp4 {0} {1}'.format addr.host addr.port elif _HAS_IPV6 and isinstance addr IPv6Address res u'tcp6 {0} {1}'.format addr.host addr.port elif isinstance addr UNIXAddress res u'unix {0}'.format addr.name elif isinstance addr PipeAddress res u'<pipe>'else res u'? {0}'.format addr return res
def int_coercable string try int string return Trueexcept ValueError return False
def _calc_end text start if len text 1 new_end start + Position 0 len text[0] else new_end Position start.line + len text - 1 len text[ -1 ] return new_end
def _compute_targets rois overlaps labels gt_inds np.where overlaps 1 [0]if len gt_inds 0 return np.zeros rois.shape[0] 5 dtype np.float32 ex_inds np.where overlaps > cfg.TRAIN.BBOX_THRESH [0]ex_gt_overlaps bbox_overlaps np.ascontiguousarray rois[ex_inds ] dtype np.float np.ascontiguousarray rois[gt_inds ] dtype np.float gt_assignment ex_gt_overlaps.argmax axis 1 gt_rois rois[gt_inds[gt_assignment] ]ex_rois rois[ex_inds ]targets np.zeros rois.shape[0] 5 dtype np.float32 targets[ ex_inds 0 ] labels[ex_inds]targets[ex_inds 1 ] bbox_transform ex_rois gt_rois return targets
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def trunc s length if not s return ''if len s > length return s[ length - 4 ] + '...' return s
def addTwistPortions interpolationTwist remainderPortionDirection twistPrecision lastPortionDirection interpolationTwist.portionDirections[ -1 ]if remainderPortionDirection.portion lastPortionDirection.portion returnlastTwist interpolationTwist.getYByPortion lastPortionDirection remainderTwist interpolationTwist.getYByPortion remainderPortionDirection twistSegments int math.floor abs remainderTwist - lastTwist / twistPrecision if twistSegments < 1 returnportionDifference remainderPortionDirection.portion - lastPortionDirection.portion twistSegmentsPlusOne float twistSegments + 1 for twistSegment in xrange twistSegments additionalPortion portionDifference * float twistSegment + 1 / twistSegmentsPlusOne portionDirection PortionDirection lastPortionDirection.portion + additionalPortion interpolationTwist.portionDirections.append portionDirection
def support_enumeration g return list support_enumeration_gen g
def playMovieInWindow theWindow theFile movieBox theMovie loadMovie theFile theMovie.SetMovieBox movieBox theMovie.GoToBeginningOfMovie theMovie.MoviesTask 0 theMovie.StartMovie while not theMovie.IsMovieDone and not Evt.Button theMovie.MoviesTask 0
def _GetGroupByKey entity property_names return frozenset prop.name prop.value .SerializeToString for prop in entity.property_list if prop.name in property_names
def write_metadata_tag stream metadata SCRIPT_TAG '\x12'FLV_TAG_HEADER_LEN 11if metadata stream.write SCRIPT_TAG write_unsigned_int_24 stream len metadata stream.write '\x00\x00\x00\x00\x00\x00\x00' stream.write metadata write_unsigned_int stream FLV_TAG_HEADER_LEN + len metadata
def generatePersistentJobGUID return 'JOB_UUID1-' + str uuid.uuid1
def get_all_params layer unwrap_shared True **tags layers get_all_layers layer params chain.from_iterable l.get_params unwrap_shared unwrap_shared **tags for l in layers return utils.unique params
@must_be_logged_indef user_choose_mailing_lists auth **kwargs user auth.userjson_data escape_html request.get_json if json_data for list_name subscribe in json_data.items if list_name settings.OSF_HELP_LIST update_osf_help_mails_subscription user user subscribe subscribe else update_mailchimp_subscription user list_name subscribe else raise HTTPError http.BAD_REQUEST data dict message_long "Mustprovideadictionaryoftheformat{'mailinglistname' Boolean}" user.save all_mailing_lists {}all_mailing_lists.update user.mailchimp_mailing_lists all_mailing_lists.update user.osf_mailing_lists return {'message' 'Successfullyupdatedmailinglists' 'result' all_mailing_lists} 200
def blockcut expr rowsizes colsizes rowbounds bounds rowsizes colbounds bounds colsizes return BlockMatrix [[MatrixSlice expr rowbound colbound for colbound in colbounds] for rowbound in rowbounds]
@transaction.non_atomic_requests@require_POSTdef generate_user_cert request course_id if not request.user.is_authenticated log.info u'Anonusertryingtogeneratecertificatefor%s' course_id return HttpResponseBadRequest _ 'Youmustbesignedinto{platform_name}tocreateacertificate.' .format platform_name configuration_helpers.get_value 'PLATFORM_NAME' settings.PLATFORM_NAME student request.usercourse_key CourseKey.from_string course_id course modulestore .get_course course_key depth 2 if not course return HttpResponseBadRequest _ 'Courseisnotvalid' if not is_course_passed course None student request return HttpResponseBadRequest _ 'Yourcertificatewillbeavailablewhenyoupassthecourse.' certificate_status certs_api.certificate_downloadable_status student course.id if certificate_status['is_downloadable'] return HttpResponseBadRequest _ 'Certificatehasalreadybeencreated.' elif certificate_status['is_generating'] return HttpResponseBadRequest _ 'Certificateisbeingcreated.' else certs_api.generate_user_certificates student course.id course course generation_mode 'self' _track_successful_certificate_generation student.id course.id return HttpResponse
def fixcommand c forbidden_characters ['-']c c.lower for char in forbidden_characters c c.replace char '' if c 'def' return 'qdef'return c
def import_status handler host None core_name None verbose False if not _is_master and _get_none_or_value host is None errors ['solr.import_statuscanonlybecalledby"master"minions']return _get_return_dict False errors errors extra ['command status']if verbose extra.append 'verbose true' url _format_url handler host host core_name core_name extra extra return _http_request url
def _fastq_illumina_convert_fastq_solexa in_handle out_handle alphabet None from Bio.SeqIO.QualityIO import solexa_quality_from_phredmapping ''.join [chr 0 for ascii in range 0 64 ] + [chr 64 + int round solexa_quality_from_phred q for q in range 0 62 + 1 ] + [chr 0 for ascii in range 127 256 ] assert len mapping 256 return _fastq_generic in_handle out_handle mapping
def extra_padding_x original_size padding return _resize original_size 0 padding padding
def to_unicode value if not isinstance value six.string_types raise ValueError 'Value"%s"mustbeastring.' % value if not isinstance value six.text_type value six.u value return value
def writeFeatureFile font path fout open path 'w' fout.write font.features.text fout.close
def _check_balances cursor b cursor.all "\nselectp.username expected balanceasactual\nfrom \nselectusername sum a asexpected\nfrom \nselectparticipantasusername sum amount asa\nfromexchanges\nwhereamount>0\nand status 'unknown'orstatus 'succeeded' \ngroupbyparticipant\n\nunionall\n\nselectparticipantasusername sum amount-fee asa\nfromexchanges\nwhereamount<0\nand status 'unknown'orstatus<>'failed' \ngroupbyparticipant\n\nunionall\n\nselecttipperasusername sum -amount asa\nfromtransfers\ngroupbytipper\n\nunionall\n\nselectparticipantasusername sum amount asa\nfrompayments\nwheredirection 'to-participant'\ngroupbyparticipant\n\nunionall\n\nselectparticipantasusername sum -amount asa\nfrompayments\nwheredirection 'to-team'\ngroupbyparticipant\n\nunionall\n\nselecttippeeasusername sum amount asa\nfromtransfers\ngroupbytippee\n asfoo\ngroupbyusername\n asfoo2\njoinparticipantsponp.username foo2.username\nwhereexpected<>p.balance\n" assert len b 0 'conflictingbalances {}'.format b
def tmpdir global _tmpdirif not _tmpdir def cleanup shutil.rmtree _tmpdir import atexitatexit.register cleanup _tmpdir os.path.join tempfile.gettempdir 'anki_temp' if not os.path.exists _tmpdir os.mkdir _tmpdir return _tmpdir
def _args_to_val func args from .google_imports import gqlvals []for arg in args if isinstance arg int long basestring val Parameter arg elif isinstance arg gql.Literal val arg.Get else raise TypeError 'Unexpectedarg %r ' % arg vals.append val if func 'nop' if len vals ! 1 raise TypeError '"nop"requiresexactlyonevalue' return vals[0]pfunc ParameterizedFunction func vals if pfunc.is_parameterized return pfuncelse return pfunc.resolve {} {}
def test_docs_generated botocore_session botocore.session.get_session session boto3.Session region_name 'us-east-1' for service_name in session.get_available_services generated_docs ServiceDocumenter service_name session session .document_service generated_docs generated_docs.decode 'utf-8' client boto3.client service_name 'us-east-1' yield _assert_has_title generated_docs client yield _assert_has_client_documentation generated_docs service_name client try paginator_model botocore_session.get_paginator_model service_name yield _assert_has_paginator_documentation generated_docs service_name client sorted paginator_model._paginator_config except DataNotFoundError passif client.waiter_names waiter_model botocore_session.get_waiter_model service_name yield _assert_has_waiter_documentation generated_docs service_name client waiter_model if service_name in session.get_available_resources resource boto3.resource service_name 'us-east-1' yield _assert_has_resource_documentation generated_docs service_name resource
@then 'thecommandoutputshouldcontainlogrecordsfromcategories' def step_command_output_should_contain_log_records_from_categories context assert context.table 'REQUIRE context.table'context.table.require_column 'category' record_schema context.log_record_row_schemaLogRecordTable.annotate_with_row_schema context.table record_schema step_command_output_should_contain_log_records context context.table.remove_columns ['level' 'message']
def _out_file fn handle logSys.debug handle '----' + fn + '----' for line in fileinput.input fn line line.rstrip '\n' handle line handle '-' * 30
def get_conv_gradweights_shape_1axis image_shape top_shape border_mode subsample dilation if None in [image_shape top_shape border_mode subsample dilation] return Noneif subsample ! 1 or border_mode 'half' return Noneif border_mode 'full' kernel_shape top_shape - image_shape elif border_mode 'valid' kernel_shape image_shape - top_shape else if border_mode < 0 raise ValueError 'border_modemustbe> 0' kernel_shape image_shape + 2 * border_mode - top_shape if dilation > 1 kernel_shape kernel_shape / dilation return kernel_shape + 1
def normalize_lat_lng arg if isinstance arg dict if 'lat' in arg and 'lng' in arg return arg['lat'] arg['lng'] if 'latitude' in arg and 'longitude' in arg return arg['latitude'] arg['longitude'] if _is_list arg return arg[0] arg[1] raise TypeError 'Expectedalat/lngdictortuple butgot%s' % type arg .__name__
def csv_header print_ 'ServerID Sponsor ServerName Timestamp Distance Ping Download Upload' sys.exit 0
def type_callable func from .typing.templates import CallableTemplate infer infer_globalif not callable func and not isinstance func str raise TypeError '`func`shouldbeafunctionorstring' try func_name func.__name__except AttributeError func_name str func def decorate typing_func def generic self return typing_func self.context name '%s_CallableTemplate' % func_name bases CallableTemplate class_dict dict key func generic generic template type name bases class_dict infer template if hasattr func '__module__' infer_global func types.Function template return decorate
def SetConnectKwargs **kwargs global _connect_kwargs_connect_kwargs dict kwargs
def filter_by_latest_metadata_changeset_revision_that_has_invalid_tools trans repository repository_metadata get_latest_repository_metadata_if_it_includes_invalid_tools trans repository if repository_metadata is not None return repository_metadata.changeset_revisionreturn None
def resolve code if not code return None None if not isinstance code basestring raise ValueError 'Invalidlanguagecodespecifiedbyparser' code re.split '[^a-z]' code.lower [0][ 3]for spec in codes if code in spec[ -1 ] return code spec[ -1 ] return code u'Unknown %r ' % code
def get_image_meta_from_headers response result {}properties {}if hasattr response 'getheaders' headers response.getheaders else headers response.headers.items for key value in headers key str key.lower if key.startswith 'x-image-meta-property-' field_name key[len 'x-image-meta-property-' ].replace '-' '_' properties[field_name] value or None elif key.startswith 'x-image-meta-' field_name key[len 'x-image-meta-' ].replace '-' '_' result[field_name] value or None result['properties'] propertiesif 'size' in result try result['size'] int result['size'] except ValueError raise exception.Invalidfor key in 'is_public' 'deleted' 'protected' if key in result result[key] bool_from_string result[key] return result
def ask_for_port sys.stderr.write '\n---Availableports \n' ports []for n port desc hwid in enumerate sorted comports 1 sys.stderr.write '---{ 2} { 20}{}\n'.format n port desc ports.append port while True port raw_input '---Enterportindexorfullname ' try index int port - 1 if not 0 < index < len ports sys.stderr.write '---Invalidindex!\n' continueexcept ValueError passelse port ports[index]return port
def normalize_data_query_bounds lower upper time tz lower - datetime.timedelta days 1 if time is not None return normalize_data_query_time lower time tz normalize_data_query_time upper time tz return lower upper
def flatten expr new new cls expr.__class__args []for arg in expr.args if arg.__class__ cls args.extend arg.args else args.append arg return new expr.__class__ *args
def in6_ismgladdr str return in6_isincluded str 'ff0e ' 16
def guard_top_only NzbQueue.do.set_top_only cfg.top_only
def _get_default_route version subnet if subnet.get 'gateway' and subnet['gateway'].get 'address' gateway subnet['gateway']['address']else return []if version 4 return [{'network' '0.0.0.0' 'netmask' '0.0.0.0' 'gateway' gateway}]elif version 6 return [{'network' ' ' 'netmask' ' ' 'gateway' gateway}]
def additions_mount mount_point tempfile.mkdtemp ret __salt__['mount.mount'] mount_point '/dev/cdrom' if ret is True return mount_pointelse raise OSError ret
def req_item_onaccept form form_vars form.varsreq_id form_vars.get 'req_id' None if not req_id req_id s3_get_last_record_id 'req_req' if not req_id raise HTTP 500 'Cannotgetreq_id' req_update_status req_id item_id form_vars.get 'item_id' None db current.dbcitable db.supply_catalog_itemcats db citable.item_id item_id .select citable.item_category_id rictable db.req_req_item_categoryfor cat in cats item_category_id cat.item_category_idquery rictable.deleted False & rictable.req_id req_id & rictable.item_category_id item_category_id exists db query .select rictable.id limitby 0 1 if not exists rictable.insert req_id req_id item_category_id item_category_id
def _log_multivariate_normal_density_tied X means covars cv np.tile covars means.shape[0] 1 1 return _log_multivariate_normal_density_full X means cv
def _find_milestone_revisions config milestone branch None script alembic_script.ScriptDirectory.from_config config return [ m.revision label for m in _get_revisions script for label in m.branch_labels or [None] if milestone in getattr m.module 'neutron_milestone' [] and branch is None or branch in m.branch_labels ]
def os_detection_exec exec_method try linux1 exec_method 'echo-nw3af' linux2 exec_method 'head-n1/etc/passwd' except BaseFrameworkException passelse if 'w3af' in linux1 and linux2.count ' ' > 3 om.out.debug 'IdentifiedremoteOSasLinux returning"linux".' return 'linux'try win1 exec_method 'type%SYSTEMROOT%\\win.ini' win2 exec_method 'echo/?' except BaseFrameworkException passelse if '[fonts]' in win1 and 'ECHO' in win2 om.out.debug 'IdentifiedremoteOSasWindows returning"windows".' return 'windows'raise BaseFrameworkException 'Failedtoget/identifytheremoteOS.'
def fmt_search value search_match if search_match caseless re.compile re.escape search_match re.IGNORECASE for variation in re.findall caseless value value re.sub caseless u'<spanclass "hlmatch">{0}</span>'.format variation value return value
@register.inclusion_tag 'zinnia/tags/dummy.html' def get_draft_entries number 5 template 'zinnia/tags/entries_draft.html' return {'template' template 'entries' Entry.objects.filter status DRAFT [ number]}
def populate_xheaders request response model object_id from django.conf import settingsif request.META.get 'REMOTE_ADDR' in settings.INTERNAL_IPS or hasattr request 'user' and request.user.is_active and request.user.is_staff response['X-Object-Type'] '%s.%s' % model._meta.app_label model._meta.object_name.lower response['X-Object-Id'] str object_id
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _find_spec_from_path name path None if name not in sys.modules return _find_spec name path else module sys.modules[name]if module is None return Nonetry spec module.__spec__except AttributeError raise ValueError '{}.__spec__isnotset'.format name else if spec is None raise ValueError '{}.__spec__isNone'.format name return spec
def EvaluatePrefix prefix path_regex if path_regex.match prefix return 'MATCH'path_regex_string path_regex.patternif not path_regex_string.startswith KNOWN_PATH_REGEX_PREFIX logging.warning 'Unrecognizedregexformat beingpessimistic %s' path_regex_string return 'POSSIBLE'literal_prefix _LiteralPrefix path_regex_string[len KNOWN_PATH_REGEX_PREFIX ] if literal_prefix.startswith prefix return 'POSSIBLE'if prefix.startswith literal_prefix return 'POSSIBLE'return 'NO_MATCH'
def address_book_to_list address_book ab.ABAddressBook.sharedAddressBook people address_book.people return [ab_person_to_dict person for person in people]
def debug_src src pm False globs None testsrc script_from_examples src debug_script testsrc pm globs
def testdoc_cli arguments TestDoc .execute_cli arguments
def getArcPath elementNode begin elementNode.getPreviousVertex Vector3 end evaluate.getVector3FromElementNode elementNode largeArcFlag evaluate.getEvaluatedBoolean True elementNode 'largeArcFlag' radius lineation.getComplexByPrefix elementNode 'radius' complex 1.0 1.0 sweepFlag evaluate.getEvaluatedBoolean True elementNode 'sweepFlag' xAxisRotation math.radians evaluate.getEvaluatedFloat 0.0 elementNode 'xAxisRotation' arcComplexes svg_reader.getArcComplexes begin.dropAxis end.dropAxis largeArcFlag radius sweepFlag xAxisRotation path []if len arcComplexes < 1 return []incrementZ end.z - begin.z / float len arcComplexes z begin.zfor pointIndex in xrange len arcComplexes pointComplex arcComplexes[pointIndex]z + incrementZpath.append Vector3 pointComplex.real pointComplex.imag z if len path > 0 path[ -1 ] endreturn path
def extra_view_dispatch request view theme get_current_theme request view_func get_view_by_name theme view if not view_func msg '%s/%s Notfound' % getattr theme 'identifier' None view return HttpResponseNotFound msg return view_func request
def windowSequenceEval DS winsz result si_old 0idx 0x []y []seq_res []for i si in enumerate DS['sequence_index'][1 ].astype int tar DS['target'][ si - 1 ]curr_x si_oldcorrect 0.0wrong 0.0while curr_x < si x.append curr_x if result[idx] tar correct + 1.0y + [1.0 1.0]else wrong + 1.0y + [0.0 0.0]idx + 1curr_x + winszx.append curr_x seq_res.append 100.0 * correct / correct + wrong print 'sequence%dcorrect %g12.2%%' % i seq_res[ -1 ] seq_res array seq_res print 'totalfractionofcorrectsequences ' 100.0 * float seq_res > 0.5 .sum / seq_res.size
def new data None return SHA224Hash .new data
def valid_any_uri item try part urlparse.urlparse item except Exception raise NotValid 'AnyURI' if part[0] 'urn' and part[1] '' return Truereturn True
def require name version None def decorator obj @functools.wraps obj def func_wrapped *args **kwargs if is_installed name version return obj *args **kwargs else msg '"%s"in"%s"requires"%s'msg msg % obj obj.__module__ name if not version is None msg + '%s' % version raise ImportError msg + '"' return func_wrappedreturn decorator
def get_infile filename if filename.endswith '.gz' fin GzipFile filename 'rb' else fin open filename 'U' return fin
def freecpu return node_info ['free_cpus']
def getNewRepository return FillRepository
def hincrbyfloat key field increment 1.0 host None port None db None password None server _connect host port db password return server.hincrbyfloat key field amount increment
def get_dev_count_for_disk_bus disk_bus if disk_bus 'ide' return 4else return 26
@click.command 'renew-lets-encrypt' def renew_lets_encrypt from bench.config.lets_encrypt import renew_certsrenew_certs
def make_img_name file_ext '.png' fn []for i in range 0 30 fn.append choice ALPHABET return ''.join fn + file_ext
def md5_shard word return 'server%d' % ord hashlib.md5 word .digest [ -1 ] % 4
def cc_plugin name srcs [] deps [] warning 'yes' defs [] incs [] optimize [] prefix None suffix None extra_cppflags [] extra_linkflags [] allow_undefined True **kwargs target CcPlugin name srcs deps warning defs incs optimize prefix suffix extra_cppflags extra_linkflags allow_undefined blade.blade kwargs blade.blade.register_target target
def random_layout G center None dim 2 import numpy as np G center _process_params G center dim shape len G dim pos np.random.random shape + center pos pos.astype np.float32 pos dict zip G pos return pos
def set_activity_type_requires tablename sector_ids attable s3db.project_activity_typeif sector_ids atstable s3db.project_activity_type_sectorrows db .select attable.id atstable.sector_id left atstable.on attable.id atstable.activity_type_id activity_type_ids [row.project_activity_type.id for row in rows if not row.project_activity_type_sector.sector_id or row.project_activity_type_sector.sector_id in sector_ids ]else activity_type_ids []s3db[tablename].activity_type_id.requires IS_EMPTY_OR IS_ONE_OF db 'project_activity_type.id' s3base.S3Represent lookup 'project_activity_type' filterby 'id' filter_opts activity_type_ids sort True
@receiver SignalHandler.course_deleted def _listen_for_course_delete sender course_key **kwargs CourseOverview.objects.filter id course_key .delete from cms.djangoapps.contentstore.courseware_index import CourseAboutSearchIndexerCourseAboutSearchIndexer.remove_deleted_items course_key
def makeBadRequest code BAD_REQUEST **result return BadRequest code result
def SetGlobalStyle style global _styleglobal _GLOBAL_STYLE_FACTORYfactory _GetStyleFactory style if factory _GLOBAL_STYLE_FACTORY factory_style style
def render_template_string source **context ctx _app_ctx_stack.topctx.app.update_template_context context return _render ctx.app.jinja_env.from_string source context ctx.app
def api_version f @wraps f def wrapped *args **kwargs rv f *args **kwargs rv.headers[u'API-Version'] __version__return rvreturn wrapped
def _sameFrag f g if hasattr f 'cbDefn' or hasattr g 'cbDefn' or hasattr f 'lineBreak' or hasattr g 'lineBreak' return 0for a in 'fontName' 'fontSize' 'textColor' 'backColor' 'rise' 'underline' 'strike' 'link' if getattr f a None ! getattr g a None return 0return 1
def _replace_tab_with_space line escapechar quotechar newline []in_quote Falselastchar 'NONE'for char in line if char quotechar and lastchar ! escapechar in_quote not in_quote if char ' DCTB ' and not in_quote char ''lastchar charnewline.append char return ''.join newline
def make_vector raise NotImplementedError 'TODO implementthisfunction.'
def _allow_CTRL_C_other pass
def safe_getattr object name default try return getattr object name default except Exception return default
def metadef_namespace_get context namespace_name session None session session or get_session return metadef_namespace_api.get context namespace_name session
def test_value_formatter line Line value_formatter lambda x str x + u '\xe2\x80\xb0' line.add '_' [ 10 ** 4 10 ** 5 23 * 10 ** 4 ] q line.render_pyquery assert len q '.y.axis.guides' 11 assert q '.axis.ytext' .map texts list map lambda x str x + u '\xe2\x80\xb0' map float range 20000 240000 20000
def _python_installed ret python user None default __salt__['pyenv.default'] runas user for version in __salt__['pyenv.versions'] user if version python ret['result'] Trueret['comment'] 'Requestedpythonexists.'ret['default'] default python breakreturn ret
def score_match pattern mimetype EXACT_TYPE 1ANY_TYPE 0.7EXACT_SUBTYPE 1VND_SUBTYPE 0.9ANY_SUBTYPE 0.8score 0if pattern[0] mimetype[0] score + EXACT_TYPEelif pattern[0] u'*' score + ANY_TYPEelse return 0if pattern[1] mimetype[1] score + EXACT_SUBTYPEelif pattern[1] u'*' or mimetype[1] u'*' score + ANY_SUBTYPEelse pattern_subtype pattern[1].split u'+' mimetype_subtype mimetype[1].split u'+' if len mimetype_subtype > 1 if len pattern_subtype > 1 if pattern_subtype[1] mimetype_subtype[1] score + VND_SUBTYPEelif pattern_subtype[0] mimetype_subtype[1] score + VND_SUBTYPEelif len pattern_subtype > 1 if pattern_subtype[1] mimetype_subtype[0] score + VND_SUBTYPEreturn score
def test_listwriter lst []writer html.ListWriter lst for i in range 5 writer.write i for ch in 'abcde' writer.write ch assert lst [0 1 2 3 4 'a' 'b' 'c' 'd' 'e']
def unparse input_dict output None encoding 'utf-8' full_document True short_empty_elements False **kwargs if full_document and len input_dict ! 1 raise ValueError 'Documentmusthaveexactlyoneroot.' must_return Falseif output is None output StringIO must_return Trueif short_empty_elements content_handler XMLGenerator output encoding True else content_handler XMLGenerator output encoding if full_document content_handler.startDocument for key value in input_dict.items _emit key value content_handler full_document full_document **kwargs if full_document content_handler.endDocument if must_return value output.getvalue try value value.decode encoding except AttributeError passreturn value
def min_uuid_from_time timestamp return uuid_from_time timestamp 141289400074368 128
def bzr_wc_target_exists_plain_force test 'bzr_wc_target_exists_plain_force'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric.api import runfrom fabtools.files import is_dirfrom fabtools import requirerun 'mkdir%s' % wt assert not is_dir path.join wt '.bzr' require.bazaar.working_copy REMOTE_URL wt force True assert_wc_exists wt
def _get_bti_dev_t adjust 0.0 translation 0.0 0.02 0.11 flip_t np.array [[0.0 -1.0 0.0] [1.0 0.0 0.0] [0.0 0.0 1.0]] rad np.deg2rad adjust adjust_t np.array [[1.0 0.0 0.0] [0.0 np.cos rad - np.sin rad ] [0.0 np.sin rad np.cos rad ]] m_nm_t np.eye 4 m_nm_t[ 3 3] np.dot flip_t adjust_t m_nm_t[ 3 3] translationreturn m_nm_t
def prep_jid nocache False passed_jid None if passed_jid is None jid salt.utils.jid.gen_jid else jid passed_jidcb_ _get_connection try cb_.add str jid {'nocache' nocache} ttl _get_ttl except couchbase.exceptions.KeyExistsError if passed_jid is None return prep_jid nocache nocache return jid
def validate_read_preference dummy value if not isinstance value _ServerMode raise TypeError '%risnotareadpreference.' % value return value
def mpl_palette name n_colors 6 brewer_qual_pals {'Accent' 8 'Dark2' 8 'Paired' 12 'Pastel1' 9 'Pastel2' 8 'Set1' 9 'Set2' 8 'Set3' 12}if name.endswith '_d' pal ['#333333']pal.extend color_palette name.replace '_d' '_r' 2 cmap blend_palette pal n_colors as_cmap True else cmap getattr mpl.cm name if name in brewer_qual_pals bins np.linspace 0 1 brewer_qual_pals[name] [ n_colors]else bins np.linspace 0 1 n_colors + 2 [1 -1 ]palette list map tuple cmap bins [ 3] return _ColorPalette palette
def gentoo_mirrors_contains value return var_contains 'GENTOO_MIRRORS' value
def add_nexusport_binding port_id vlan_id switch_ip instance_id LOG.debug _ 'add_nexusport_binding called' session db.get_session binding nexus_models_v2.NexusPortBinding port_id vlan_id switch_ip instance_id session.add binding session.flush return binding
def educate_quotes s s single_quote_start_re.sub '&#8217;' s s double_quote_start_re.sub '&#8221;' s s double_quote_sets_re.sub '&#8220;&#8216;' s s single_quote_sets_re.sub '&#8216;&#8220;' s s decade_abbr_re.sub '&#8217;' s s opening_single_quotes_regex.sub '\\1&#8216;' s s closing_single_quotes_regex.sub '\\1&#8217;' s s closing_single_quotes_regex_2.sub '\\1&#8217;\\2' s s s.replace "'" '&#8216;' s opening_double_quotes_regex.sub '\\1&#8220;' s s closing_double_quotes_regex.sub '&#8221;' s s closing_double_quotes_regex_2.sub '\\1&#8221;' s return s.replace '"' '&#8220;'
def _get_gcp_libcloud_credentials service_account_email None credentials_file None project_id None if service_account_email is None or credentials_file is None try import secretsdisplay.deprecated msg "secretsfilefoundat'%s'.Thismethodofspecifyingcredentialsisdeprecated.PleaseuseenvvarsorAnsibleYAMLfilesinstead" % secrets.__file__ version 2.5 except ImportError secrets Noneif hasattr secrets 'GCE_PARAMS' if not service_account_email service_account_email secrets.GCE_PARAMS[0]if not credentials_file credentials_file secrets.GCE_PARAMS[1]keyword_params getattr secrets 'GCE_KEYWORD_PARAMS' {} if not project_id project_id keyword_params.get 'project' None return service_account_email credentials_file project_id
def copy_to_ram storage import shutilram RamStorage for name in storage.list f storage.open_file name r ram.create_file name shutil.copyfileobj f.file r.file f.close r.close return ram
def _groupListBy l index tmpd {}for item in l tmpd.setdefault item[index] [] .append item res tmpd.values return res
def b str_or_bytes if not isinstance str_or_bytes bytes return str_or_bytes.encode 'ascii' else return str_or_bytes
def get_user return os.getenv 'REMOTE_USER'
def get_to_timestamp_base base if base < FreqGroup.FR_BUS return FreqGroup.FR_DAYif FreqGroup.FR_HR < base < FreqGroup.FR_SEC return FreqGroup.FR_SECreturn base
def classmethod2func class_ method_ return '%s.%s' % class2func class_ method2func method_
def funshion_id_to_urls id html get_content 'http //pm.funshion.com/v5/media/play/?id {id}&cl aphone&uc 5'.format id id return select_url_from_video_api html
def make_low_rank_matrix n_samples 100 n_features 100 effective_rank 10 tail_strength 0.5 random_state None generator check_random_state random_state n min n_samples n_features u _ linalg.qr generator.randn n_samples n mode 'economic' v _ linalg.qr generator.randn n_features n mode 'economic' singular_ind np.arange n dtype np.float64 low_rank 1 - tail_strength * np.exp -1.0 * singular_ind / effective_rank ** 2 tail tail_strength * np.exp -0.1 * singular_ind / effective_rank s np.identity n * low_rank + tail return np.dot np.dot u s v.T
def CheckForCopyright filename lines error for line in range 1 min len lines 11 if re.search 'Copyright' lines[line] re.I breakelse error filename 0 'legal/copyright' 5 'Nocopyrightmessagefound.Youshouldhavealine "Copyright[year]<CopyrightOwner>"'
def _normalize_handler_method method return method.lower .replace '-' '_'
def _scrub_empty_str_values dct keys_to_scrub for key in keys_to_scrub if key in dct and dct[key] '' del dct[key]
def border_crossing return s3_rest_controller rheader s3db.transport_rheader
def parse_monitor_message msg if len msg ! 2 or len msg[0] ! 6 raise RuntimeError 'Invalideventmessageformat %s' % msg event {'event' struct.unpack ' hi' msg[0] [0] 'value' struct.unpack ' hi' msg[0] [1] 'endpoint' msg[1]}return event
def define_delta name description manager counters counter _DeltaCounter name description manager.register counter return counter
def bdate_range start None end None periods None freq 'B' tz None normalize True name None closed None **kwargs return DatetimeIndex start start end end periods periods freq freq tz tz normalize normalize name name closed closed **kwargs
def _default_conflict_solver match conflicting_match if len conflicting_match.initiator < len match.initiator return conflicting_matchelif len match.initiator < len conflicting_match.initiator return matchreturn None
def list_upgrades refresh False root None **kwargs upgrades {}cmd ['pacman' '-S' '-p' '-u' '--print-format' '%n%v']if root is not None cmd.extend '-r' root if refresh cmd.append '-y' call __salt__['cmd.run_all'] cmd python_shell False output_loglevel 'trace' if call['retcode'] ! 0 comment ''if 'stderr' in call comment + call['stderr']if 'stdout' in call comment + call['stdout']if comment comment ' ' + comment raise CommandExecutionError 'Errorlistingupgrades' + comment else out call['stdout']for line in salt.utils.itertools.split out '\n' try pkgname pkgver line.split except ValueError continueif pkgname.lower 'downloading' and '.db' in pkgver.lower continueupgrades[pkgname] pkgverreturn upgrades
def set_collection_path_collation apps schema_editor if schema_editor.connection.vendor u'postgresql' schema_editor.execute u'\nALTERTABLEwagtailcore_collectionALTERCOLUMNpathTYPEVARCHAR 255 COLLATE"C"\n'
def reduced_min_part_size f import moto.s3.models as s3modelorig_size s3model.UPLOAD_PART_MIN_SIZE@wraps f def wrapped *args **kwargs try s3model.UPLOAD_PART_MIN_SIZE REDUCED_PART_SIZEreturn f *args **kwargs finally s3model.UPLOAD_PART_MIN_SIZE orig_sizereturn wrapped
def get_module_hash src_code key to_hash [l.strip for l in src_code.split '\n' ]if key[0] to_hash + list map str key[0] c_link_key key[1]error_msg 'ThisshouldnothappenunlesssomeonemodifiedthecodethatdefinestheCLinkerkey inwhichcaseyoushouldensurethispieceofcodeisstillvalid andthisAssertionErrormayberemovedormodifiedtoaccomodatethischange 'assert c_link_key[0] 'CLinker.cmodule_key' error_msgfor key_element in c_link_key[1 ] if isinstance key_element tuple to_hash + list key_element elif isinstance key_element string_types if key_element.startswith 'md5 ' breakelif key_element.startswith 'NPY_ABI_VERSION 0x' or key_element.startswith 'c_compiler_str ' to_hash.append key_element else raise AssertionError error_msg else raise AssertionError error_msg return hash_from_code '\n'.join to_hash
def _GenerateRequestLogId sec int _request_time usec int 1000000 * _request_time - sec h hashlib.sha1 str _request_id .digest [ 4]packed struct.Struct '>LL' .pack sec usec return binascii.b2a_hex packed + h
def global_reaching_centrality G weight None normalized True if nx.is_negatively_weighted G weight weight raise nx.NetworkXError 'edgeweightsmustbepositive' total_weight G.size weight weight if total_weight < 0 raise nx.NetworkXError 'SizeofGmustbepositive' if weight is not None as_distance lambda u v d total_weight / d.get weight 1 shortest_paths nx.shortest_path G weight as_distance else shortest_paths nx.shortest_path G centrality local_reaching_centralitylrc [centrality G node paths paths weight weight normalized normalized for node paths in shortest_paths.items ]max_lrc max lrc return sum max_lrc - c for c in lrc / len G - 1
def bokeh_pull name rawtext text lineno inliner options None content None app inliner.document.settings.env.apptry issue_num int text if issue_num < 0 raise ValueErrorexcept ValueError msg inliner.reporter.error 'Githubpullrequestnumbermustbeanumbergreaterthanorequalto1;"%s"isinvalid.' % text line lineno prb inliner.problematic rawtext rawtext msg return [prb] [msg] node make_gh_link_node app rawtext 'pull' 'pullrequest' 'pull' str issue_num options return [node] []
def send_catch_log signal Any sender Anonymous *arguments **named dont_log named.pop 'dont_log' _IgnoredException spider named.get 'spider' None responses []for receiver in liveReceivers getAllReceivers sender signal try response robustApply receiver signal signal sender sender *arguments **named if isinstance response Deferred logger.error 'Cannotreturndeferredsfromsignalhandler % receiver s' {'receiver' receiver} extra {'spider' spider} except dont_log result Failure except Exception result Failure logger.error 'Errorcaughtonsignalhandler % receiver s' {'receiver' receiver} exc_info True extra {'spider' spider} else result responseresponses.append receiver result return responses
def aggregate_values_from_key host_state key_name aggrlist host_state.aggregatesreturn {aggr.metadata[key_name] for aggr in aggrlist if key_name in aggr.metadata }
def rand_text_alpha length bad '' chars upperAlpha + lowerAlpha return rand_base length bad set chars
def _extract_graph_and_keys vals dsk {}keys []for v in vals if hasattr v '_dasks' for d in v._dasks dsk.update d else dsk.update v.dask keys.append v._keys return dsk keys
def get_create_job_common_args local_args arg_names _ _ _ inspect.getargspec create_job_common return dict item for item in local_args.iteritems if item[0] in arg_names
def update_inc initial key count initial initial or {} initial[key] count + initial.get key 0 return initial
def yaml_load source loader yaml.Loader def construct_yaml_str self node u'\nOverridethedefaultstringhandlingfunctiontoalwaysreturn\nunicodeobjects.\n'return self.construct_scalar node class Loader loader u'\nDefineacustomloaderderivedfromthegloballoadertoleavethe\ngloballoaderunaltered.\n'Loader.add_constructor u'tag yaml.org 2002 str' construct_yaml_str try return yaml.load source Loader finally if hasattr source u'close' source.close
def fetch_and_delete_entities database table schema first_key entities_only False backoff_timeout 30batch_size 1000last_key first_key + '\x00' + TERMINATING_STRING logging.debug 'Deletingapplicationdataintherange {0}-{1}'.format first_key last_key db DatastoreFactory.getDatastore database if entities_only and table METADATA_TABLE returnlogging.info 'Deletingdatafrom{0}'.format table start_inclusive Truewhile True try entities db.range_query table schema first_key last_key batch_size start_inclusive start_inclusive if not entities logging.info 'Noentitiesfoundfor{}'.format table breakfor ii in entities db.batch_delete table ii.keys logging.info 'Deleted{0}entities'.format len entities first_key entities[ -1 ].keys [0]start_inclusive Falseexcept AppScaleDBConnectionError logging.exception 'Errorwhiledeletingdata' time.sleep backoff_timeout
def dvr_due_followups r S3Request 'dvr' 'case_activity' args [] get_vars {} r.customise_resource resource r.resourcequery FS 'followup' True & FS 'followup_date' < datetime.datetime.utcnow .date & FS 'completed' ! True & FS 'person_id$dvr_case.archived' False resource.add_filter query return resource.count
def round_corner radius fill corner Image.new u'L' radius radius 0 draw ImageDraw.Draw corner draw.pieslice 0 0 radius * 2 radius * 2 180 270 fill fill return corner
def _MaybeSetupTransaction request keys return _GetConnection ._set_request_transaction request
def _base module conf_file disable_gpg_check disablerepo enablerepo base dnf.Base _configure_base module base conf_file disable_gpg_check _specify_repositories base disablerepo enablerepo base.fill_sack load_system_repo 'auto' return base
def getPackedGeometryOutputByLoop elementNode sideLoop sideLoop.rotate elementNode return getGeometryOutputByManipulation elementNode sideLoop
def action_peek_json body try decoded jsonutils.loads body except ValueError msg _ 'cannotunderstandJSON' raise exception.MalformedRequestBody reason msg if len decoded ! 1 msg _ 'toomanybodykeys' raise exception.MalformedRequestBody reason msg return list decoded.keys [0]
def new_db_session return create_session application.database_engine autoflush True autocommit False
def _cook_slots period increment width height tdiff datetime.timedelta minutes increment num period.end - period.start .seconds / tdiff.seconds s period.startslots []for i in range num sl period.get_time_slot s s + tdiff sl.top int height / float num * i sl.height int height / float num slots.append sl s s + tdiff return slots
def group_update_db context group host cluster_name group.update {'host' host 'updated_at' timeutils.utcnow 'cluster_name' cluster_name} group.save return group
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def S_ISLNK mode return S_IFMT mode S_IFLNK
def _get_duration element return element._stopped - element._started .seconds if hasattr element '_started' else None
def _get_new_state_file_name zone return STATE_FILENAME + '.' + zone
def diff_document resource_def old_doc new_doc diff {}fields list resource_def['schema'].keys + [app.config['VERSION'] app.config['LATEST_VERSION'] resource_def['id_field'] app.config['LAST_UPDATED'] app.config['DATE_CREATED'] app.config['ETAG'] app.config['LINKS']] if resource_def['soft_delete'] is True fields.append app.config['DELETED'] for field in fields if field in new_doc and field not in old_doc or new_doc[field] ! old_doc[field] diff[field] new_doc[field]for field in app.config['VERSION_DIFF_INCLUDE'] if field in new_doc diff[field] new_doc[field]return diff
def compute_ukbench_score src imlist nbr_images len imlist pos zeros nbr_images 4 for i in range nbr_images pos[i] [ w[1] - 1 for w in src.query imlist[i] [ 4]]score array [ pos[i] // 4 i // 4 for i in range nbr_images ] * 1.0 return sum score / nbr_images
def GenerateBlobKey time_func time.time random_func random.random timestamp str time_func tries 0while tries < 10 number str random_func digester hashlib.md5 digester.update timestamp digester.update number blob_key base64.urlsafe_b64encode digester.digest datastore_key datastore.Key.from_path blobstore.BLOB_INFO_KIND blob_key namespace '' try datastore.Get datastore_key tries + 1except datastore_errors.EntityNotFoundError return blob_keyreturn None
def fromurl url ps PatchSet urlopen url if ps.errors 0 return psreturn False
@click.group def cli_app pass
def test_overloading assert A & B And A B assert A | B Or A B assert A & B | C Or And A B C assert A >> B Implies A B assert A << B Implies B A assert ~ A Not A assert A ^ B Xor A B
def get_global_id *args **kargs raise _stub_error
def _update_all_uuids_to_ids t_images t_image_members t_image_properties images list t_images.select .execute new_id 1for image in images old_id image['id']t_images.update .where t_images.c.id old_id .values id new_id .execute t_image_members.update .where t_image_members.c.image_id old_id .values image_id new_id .execute t_image_properties.update .where t_image_properties.c.image_id old_id .values image_id new_id .execute t_image_properties.update .where and_ or_ t_image_properties.c.name 'kernel_id' t_image_properties.c.name 'ramdisk_id' t_image_properties.c.value old_id .values value new_id .execute new_id + 1
def test_Number_new assert Number 1 is S.One assert Number 2 .__class__ is Integer assert Number -622 .__class__ is Integer assert Number 5 3 .__class__ is Rational assert Number 5.3 .__class__ is Float assert Number '1' is S.One assert Number '2' .__class__ is Integer assert Number '-622' .__class__ is Integer assert Number '5/3' .__class__ is Rational assert Number '5.3' .__class__ is Float raises ValueError lambda Number 'cos' raises TypeError lambda Number cos a Rational 3 5 assert Number a is a
def get_numbered_constants eq num 1 start 1 prefix 'C' if isinstance eq Expr eq [eq]elif not iterable eq raise ValueError 'ExpectedExproriterablebutgot%s' % eq atom_set set .union *[i.free_symbols for i in eq] ncs numbered_symbols start start prefix prefix exclude atom_set Cs [next ncs for i in range num ]return Cs[0] if num 1 else tuple Cs
def _rec_inflate g M v i K if not v return dup_inflate g M[i] K if M[i] < 0 raise IndexError 'allM[i]mustbepositive got%s' % M[i] w j v - 1 i + 1 g [_rec_inflate c M w j K for c in g]result [g[0]]for coeff in g[1 ] for _ in range 1 M[i] result.append dmp_zero w result.append coeff return result
def format msg *attr if DISABLE_COLOR_SUPPORT return msgif RESET in msg return ''.join [format comp *attr for comp in msg.split RESET ] encodings []for text_attr in attr text_attr encoding stem.util.str_tools._to_camel_case text_attr None encoding FG_ENCODING.get text_attr encoding encoding BG_ENCODING.get text_attr encoding encoding ATTR_ENCODING.get text_attr encoding if encoding encodings.append encoding if encodings prefix suffix CSI % ';'.join encodings RESET if Attr.READLINE_ESCAPE in attr prefix '\x01%s\x02' % prefix suffix '\x01%s\x02' % suffix return prefix + msg + suffix else return msg
def generate_clone_url_from_repo_info_tup app repo_info_tup toolshed name owner changeset_revision prior_installation_required only_if_compiling_contained_td parse_repository_dependency_tuple repo_info_tup tool_shed_url get_tool_shed_url_from_tool_shed_registry app toolshed return util.build_url tool_shed_url pathspec ['repos' owner name]
def response_httprepr response s 'HTTP/1.1%d%s\r\n' % response.status RESPONSES.get response.status '' if response.headers s + response.headers.to_string + '\r\n' s + '\r\n's + response.bodyreturn s
def _lnB alpha return np.sum gammaln alpha - gammaln np.sum alpha
def create_bias_variable name shape initializer tf.constant_initializer value 0.0 dtype tf.float32 return tf.Variable initializer shape shape name
def get_random_string length 12 allowed_chars u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' if not using_sysrandom random.seed hashlib.sha256 u'%s%s%s' % random.getstate time.time settings.SECRET_KEY .encode u'utf-8' .digest return u''.join [random.choice allowed_chars for i in range length ]
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def get_valid_perms doctype None roles get_roles perms get_perms_for roles custom_perms get_perms_for roles u'CustomDocPerm' doctypes_with_custom_perms list set [d.parent for d in custom_perms] for p in perms if not p.parent in doctypes_with_custom_perms custom_perms.append p if doctype return [p for p in custom_perms if p.parent doctype ]else return custom_perms
def check_reserved_word attr_name if datastore_types.RESERVED_PROPERTY_NAME.match attr_name raise ReservedWordError "Cannotdefineproperty.Allnamesbothbeginningandendingwith'__'arereserved." if attr_name in _RESERVED_WORDS or attr_name in dir Model raise ReservedWordError "Cannotdefinepropertyusingreservedword'% attr_name s'.Ifyouwouldliketousethisnameinthedatastoreconsiderusingadifferentnamelike% attr_name s_andaddingname '% attr_name s'totheparameterlistofthepropertydefinition." % locals
def mangle ident argtys return PREFIX + mangle_identifier ident + mangle_args argtys
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def path_subst path mapping newpath []plen len path n 0while n < plen result path[n]if result '%' for key value in mapping if path.startswith key n and not path.startswith '%ext' n n + len key - 1 result valuebreaknewpath.append result n + 1return ''.join newpath
def _is_unorderable_exception e if PY36 return "'>'notsupportedbetweeninstancesof" in str e elif PY3 return 'unorderable' in str e return False
def _finalize_ufunc_signature cres args return_type if return_type is None if cres.objectmode raise TypeError 'returntypemustbespecifiedforobjectmode' else return_type cres.signature.return_typeassert return_type ! types.pyobject return return_type *args
def test_hosts_decorator_overrides_env_hosts_with_task_decorator_first @task@hosts 'bar' def command passeq_hosts command ['bar'] env {'hosts' ['foo']}
def storage_factory klass location base_url return klass location location base_url base_url
def gcc_llvm if gcc_llvm.is_llvm is None try p_out output_subprocess_Popen [theano.config.cxx '--version'] output p_out[0] + p_out[1] except OSError output b '' gcc_llvm.is_llvm b 'llvm' in output return gcc_llvm.is_llvm
def _print_report job_info for ji in job_info print '%-15s%13sfor%17s %s ' % ji['cluster_id'] ji['state'] _format_timedelta ji['time'] ji['name']
def print_obj obj lib fmt None album isinstance obj library.Album fmt _pick_format album fmt if isinstance fmt Template template fmtelse template Template fmt print_ obj.evaluate_template template
def is_process_started_by_init result Falseinit_pid 1if os.getppid init_pid result Truereturn result
def convert_password context password password password or '' if six.PY3 and isinstance password bytes password password.decode 'utf-8' meta {}for i in range CHUNKS meta[ 'password_%d' % i ] password[ CHUNK_LENGTH]password password[CHUNK_LENGTH ]return meta
def split_provision value global _provision_rxif _provision_rx is None _provision_rx re.compile ' [a-zA-Z_]\\w* ? \\.[a-zA-Z_]\\w* * ? \\s*\\ \\s* [^ \\s]+ \\s*\\ ?$' value value.strip m _provision_rx.match value if not m raise ValueError 'illegalprovidesspecification %r' % value ver m.group 2 or None if ver ver distutils.version.StrictVersion ver return m.group 1 ver
def test_rus_sample_wt_fit rus RandomUnderSampler random_state RND_SEED assert_raises RuntimeError rus.sample X Y
def test_shift_schedule backend_default lr_init 0.1interval 1sch ShiftSchedule interval for epoch in range 10 lr sch.get_learning_rate learning_rate lr_init epoch epoch assert np.allclose lr lr_init / 2 ** epoch
def attach_usage_plan_to_apis plan_id apis region None key None keyid None profile None return _update_usage_plan_apis plan_id apis 'add' region region key key keyid keyid profile profile
@pytest.mark.parametrize 'env expected' [ {'FOO' 'bar'} '' {'FOO' 'bar' 'LC_ALL' 'baz'} 'LC_ALL baz' {'LC_ALL' 'baz' 'PYTHONFOO' 'fish'} 'LC_ALL baz\nPYTHONFOO fish' {'DE' 'KDE' 'DESKTOP_SESSION' 'plasma'} 'DE KDE\nDESKTOP_SESSION plasma' {'QT5_IM_MODULE' 'fcitx' 'QT_IM_MODULE' 'fcitx'} 'QT_IM_MODULE fcitx' {'LANGUAGE' 'foo' 'LANG' 'en_US.UTF-8'} 'LANG en_US.UTF-8' {'FOO' 'bar' 'QUTE_BLAH' '1'} 'QUTE_BLAH 1' ] ids lambda e e[1] def test_get_environment_vars monkeypatch env expected for key in os.environ.copy monkeypatch.delenv key for k v in env.items monkeypatch.setenv k v assert crashdialog._get_environment_vars expected
def _handle_picks epochs if any 'ICA' in k for k in epochs.ch_names picks pick_types epochs.info misc True ref_meg False exclude [] else picks pick_types epochs.info meg True eeg True eog True ecg True seeg True ecog True ref_meg False fnirs True exclude [] return picks
def outer a b out None n a.sizem b.sizeret_shape n m if out is None return core.tensordot_core a b None n m 1 ret_shape if out.size ! n * m raise ValueError 'Outputarrayhasaninvalidsize' if out.flags.c_contiguous return core.tensordot_core a b out n m 1 ret_shape else out[ ] core.tensordot_core a b None n m 1 ret_shape return out
@FileSystem.in_directory current_directory 'django' 'brocolis' def test_harvest_uses_test_runner status out run_scenario 'leaves' 'disabled' assert_equals status 0 out assert 'Customtestrunnerenabled.' in out
def getIsIdentityTetragrid tetragrid for column in xrange 4 for row in xrange 4 if column row if tetragrid[column][row] ! 1.0 return Falseelif tetragrid[column][row] ! 0.0 return Falsereturn True
def json_convert *kinds def register_json_converter function for kind in kinds json_converters[kind] functionreturn functionreturn register_json_converter
def copyfileobj src dst length None if length 0 returnif length is None shutil.copyfileobj src dst returnBUFSIZE 16 * 1024 blocks remainder divmod length BUFSIZE for b in xrange blocks buf src.read BUFSIZE if len buf < BUFSIZE raise IOError 'endoffilereached' dst.write buf if remainder ! 0 buf src.read remainder if len buf < remainder raise IOError 'endoffilereached' dst.write buf return
def chunk_xml xml depth 0 data etree.tostring xml root xml.findall 'add' and 'add' or 'delete' content_length len data if content_length < _CHUNK_SIZE yield data else depth + 1print 'WARNING Chunking depth %s ' % depth half len xml / 2 left_half xmlright_half etree.Element root right_half.append xml[half ] for chunk in chunk_xml left_half depth depth yield chunk for chunk in chunk_xml right_half depth depth yield chunk
@register_opt @local_optimizer [tensor.SpecifyShape GpuFromHost] def local_gpu_specifyShape_0 node if isinstance node.op tensor.SpecifyShape input node.inputs[0]if input.owner and isinstance input.owner.op HostFromGpu return [host_from_gpu tensor.specify_shape as_cuda_ndarray_variable input *node.inputs[1 ] ]if isinstance node.op GpuFromHost host_input node.inputs[0]if host_input.owner and isinstance host_input.owner.op tensor.SpecifyShape specifyshape_node host_input.ownerreturn [tensor.specify_shape as_cuda_ndarray_variable specifyshape_node.inputs[0] *specifyshape_node.inputs[1 ] ]return False
def delete_url url _cache.del_cached_url url
def pack_object_header type_num delta_base size header []c type_num << 4 | size & 15 size >> 4while size header.append c | 128 c size & 127 size >> 7header.append c if type_num OFS_DELTA ret [ delta_base & 127 ]delta_base >> 7while delta_base delta_base - 1ret.insert 0 128 | delta_base & 127 delta_base >> 7header.extend ret elif type_num REF_DELTA assert len delta_base 20 header + delta_basereturn bytearray header
def memoize_autodiff func cache {}@wraps func def memoizer op_tree be next_error None "\nIfparamsinthecaches returnresultsdirectly.Othewise addtocache\nandreturntheresults.\n\nArguments \nop_tree OpTreeNode theop-treetosupplytothefunc.\nbe Backend computationbackendtosupplytothefunc.\nnext_error TensororOpTreeNode optional nextlayer'serrorto\nsupplytothefunc.\n"key op_tree.key be next_error if key not in cache cache[key] func op_tree be next_error return cache[key]return memoizer
def isInferenceAvailable return any isTechniqueAvailable _ for _ in PAYLOAD.TECHNIQUE.BOOLEAN PAYLOAD.TECHNIQUE.STACKED PAYLOAD.TECHNIQUE.TIME
def _generateInferenceArgs options tokenReplacements inferenceType options['inferenceType']optionInferenceArgs options.get 'inferenceArgs' None resultInferenceArgs {}predictedField _getPredictedField options [0]if inferenceType in InferenceType.TemporalNextStep InferenceType.TemporalAnomaly assert predictedField "InferenceType'%s'needsapredictedFieldspecifiedintheinferenceArgsdictionary" % inferenceType if optionInferenceArgs if options['dynamicPredictionSteps'] altOptionInferenceArgs copy.deepcopy optionInferenceArgs altOptionInferenceArgs['predictionSteps'] '$REPLACE_ME'resultInferenceArgs pprint.pformat altOptionInferenceArgs resultInferenceArgs resultInferenceArgs.replace "'$REPLACE_ME'" '[predictionSteps]' else resultInferenceArgs pprint.pformat optionInferenceArgs tokenReplacements['\\$INFERENCE_ARGS'] resultInferenceArgstokenReplacements['\\$PREDICTION_FIELD'] predictedField
def getAlterationFileLineBlindly fileName return ' <alterationFile> %s </alterationFile> ' % fileName
def compute_fps f x x0 0 dir 1 hyper True order 4 rational True full False f sympify f x sympify x if not f.has x return Nonex0 sympify x0 if dir '+' dir S.Oneelif dir '-' dir - S.One elif dir not in [S.One - S.One ] raise ValueError "Dirmustbe'+'or'-'" else dir sympify dir return _compute_fps f x x0 dir hyper order rational full
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def _handle_stream_line line line json.loads line if 'error' in line content 'ERROR ' + line['error'] else content line.get 'stream' '' for streamline in content.split '\n' if streamline yield streamline
def _get_headers params return {'Authorization' 'OAuth{oauth}'.format oauth params['api_key'] }
def write_events filename event_list check_fname filename 'events' '.eve' '-eve.fif' '-eve.fif.gz' '-eve.lst' '-eve.txt' ext splitext filename [1].lower if ext '.fif' or ext '.gz' fid start_file filename start_block fid FIFF.FIFFB_MNE_EVENTS write_int fid FIFF.FIFF_MNE_EVENT_LIST event_list.T end_block fid FIFF.FIFFB_MNE_EVENTS end_file fid else f open filename 'w' for e in event_list f.write '%6d%6d%3d\n' % tuple e f.close
def atol s base 10 return _long s base
def mean_bilateral image selem out None mask None shift_x False shift_y False s0 10 s1 10 return _apply bilateral_cy._mean image selem out out mask mask shift_x shift_x shift_y shift_y s0 s0 s1 s1
def no_admin_disabled f @functools.wraps f def wrapper *args **kw addon kw.get 'addon' if addon and addon.status amo.STATUS_DISABLED raise http.Http404 return f *args **kw return wrapper
def mocksignature func mock None skipfirst False if mock is None mock Mock signature func _getsignature func skipfirst src 'lambda% signature s _mock_ % signature s ' % {'signature' signature} funcopy eval src dict _mock_ mock _copy_func_details func funcopy funcopy.mock mockreturn funcopy
def avg_pool3d input kernel_size stride None return _functions.thnn.AvgPool3d kernel_size stride input
def is_position_sup pos1 pos2 return pos1 > pos2
def getArcDistance relativeLocation splitLine halfPlaneLineDistance 0.5 * abs relativeLocation.dropAxis 2 radius getDoubleFromCharacterSplitLine 'R' splitLine if radius None iFloat getDoubleFromCharacterSplitLine 'I' splitLine jFloat getDoubleFromCharacterSplitLine 'J' splitLine radius abs complex iFloat jFloat angle 0.0if radius > 0.0 halfPlaneLineDistanceOverRadius halfPlaneLineDistance / radius if halfPlaneLineDistance < radius angle 2.0 * math.asin halfPlaneLineDistanceOverRadius else angle math.pi * halfPlaneLineDistanceOverRadius return abs complex angle * radius relativeLocation.z
def s3_fullname_bulk record_ids [] truncate True db current.dbptable db.pr_personquery ptable.id.belongs record_ids rows db query .select ptable.id ptable.first_name ptable.middle_name ptable.last_name represents {}for row in rows fname mname lname '' '' '' if row.first_name fname row.first_name.strip if row.middle_name mname row.middle_name.strip if row.last_name lname row.last_name.strip represent s3_format_fullname fname mname lname truncate represents[row.id] representreturn represents
@pytest.hookimpl tryfirst True hookwrapper True def pytest_runtest_makereport item call outcome yield rep outcome.get_result setattr item 'rep_' + rep.when rep
def notify_about_instance_action context instance host action phase None binary 'nova-compute' exception None ips _get_instance_ips instance flavor flavor_notification.FlavorPayload instance.flavor fault priority _get_fault_and_priority_from_exc exception payload instance_notification.InstanceActionPayload instance instance fault fault ip_addresses ips flavor flavor notification instance_notification.InstanceActionNotification context context priority priority publisher notification_base.NotificationPublisher context context host host binary binary event_type notification_base.EventType object 'instance' action action phase phase payload payload notification.emit context
def pure_nash_brute_gen g for a in np.ndindex *g.nums_actions if g.is_nash a yield a
def a_is_not_b a b return a is not b
def lowstate_file_refs chunks refs {}for chunk in chunks saltenv 'base'crefs []for state in chunk if state '__env__' saltenv chunk[state]elif state 'saltenv' saltenv chunk[state]elif state.startswith '__' continuecrefs.extend salt_refs chunk[state] if crefs if saltenv not in refs refs[saltenv] []refs[saltenv].append crefs return refs
def test_double_install_fail script data result script.pip 'install' 'pip *' 'pip 7.1.2' expect_error True msg "Doublerequirementgiven pip 7.1.2 alreadyinpip * name 'pip' "assert msg in result.stderr
def _parallel_fit_estimator estimator X y sample_weight if sample_weight is not None estimator.fit X y sample_weight else estimator.fit X y return estimator
def _coordinateSign hemisphere return 1 if hemisphere in 'NE' else -1
def dmp_raise f l u K if not l return fif not u if not f return dmp_zero l k l - 1 return [dmp_ground c k for c in f]v u - 1 return [dmp_raise c l v K for c in f]
def test_fk5_galactic fk5 FK5 ra 1 * u.deg dec 2 * u.deg direct fk5.transform_to Galactic indirect fk5.transform_to FK4 .transform_to Galactic assert direct.separation indirect .degree < 1e-10 direct fk5.transform_to Galactic indirect fk5.transform_to FK4NoETerms .transform_to Galactic assert direct.separation indirect .degree < 1e-10
def execute_section section global_bear_list local_bear_list print_results cache log_printer console_printer try running_processes int section['jobs'] except ValueError log_printer.warn "Unabletoconvertsetting'jobs'intoanumber.FallingbacktoCPUcount." running_processes get_cpu_count except IndexError running_processes get_cpu_count processes arg_dict instantiate_processes section local_bear_list global_bear_list running_processes cache log_printer console_printer console_printer logger_thread LogPrinterThread arg_dict['message_queue'] log_printer processes.append logger_thread for runner in processes runner.start try return process_queues processes arg_dict['control_queue'] arg_dict['local_result_dict'] arg_dict['global_result_dict'] arg_dict['file_dict'] print_results section cache log_printer console_printer console_printer arg_dict['local_result_dict'] arg_dict['global_result_dict'] arg_dict['file_dict'] finally logger_thread.running Falsefor runner in processes runner.join
def _build_regex_range ws True invert False exclude None if exclude is None exclude []regex ''in_range Falselast Nonelast_added Nonedef valid_char char if char in exclude result Falseelif ws result _is_printable char else result _is_printable char and unicodedata.category char ! 'Zs' if invert is True return not result return resultfor c in _get_all_chars if valid_char c if not in_range regex + re.escape c last_added cin_range Trueelse if in_range and last ! last_added regex + '-' + re.escape last in_range Falselast celse if in_range regex + '-' + re.escape c return regex
def _cert_base_path cacert_path None return cert_base_path cacert_path
def missing name jail None return name not in get_all jail
def indexFromCoordinates coordinates dimensions index 0for i dimension in enumerate dimensions index * dimensionindex + coordinates[i]return index
@positional def get_version_data session url authenticated None headers {'Accept' 'application/json'}resp session.get url headers headers authenticated authenticated try body_resp resp.json except ValueError passelse try return body_resp['versions']['values']except KeyError TypeError passtry return body_resp['versions']except KeyError passtry return [body_resp['version']]except KeyError passerr_text resp.text[ 50] + '...' if len resp.text > 50 else resp.text msg _ 'InvalidResponse-Badversiondatareturned %s' % err_text raise exceptions.DiscoveryFailure msg
def _parseLocalVariables line paren '-*-'start line.find paren + len paren end line.rfind paren if start -1 or end -1 raise ValueError '%rnotavalidlocalvariabledeclaration' % line items line[start end].split ';' localVars {}for item in items if len item.strip 0 continuesplit item.split ' ' if len split ! 2 raise ValueError '%rcontainsinvaliddeclaration%r' % line item localVars[split[0].strip ] split[1].strip return localVars
def KeywordAnalyzer lowercase False commas False if commas tokenizer CommaSeparatedTokenizer else tokenizer SpaceSeparatedTokenizer if lowercase tokenizer tokenizer | LowercaseFilter return tokenizer
def uts s encoding errors if errors 'utf-8' try return s.encode encoding 'strict' except UnicodeEncodeError x []for c in s try x.append c.encode encoding 'strict' except UnicodeEncodeError x.append c.encode 'utf8' return ''.join x else return s.encode encoding errors
def _make_int_array return array.array str u'i'
def allresults tree leaf yieldify return treeapply tree {list branch.multiplex tuple branch.chain} leaf leaf
def latest_version *names **kwargs refresh salt.utils.is_true kwargs.pop 'refresh' True if refresh refresh_db def get_version pkg_info return pkg_info['versions']['stable'] or pkg_info['versions']['devel'] versions_dict dict key get_version val for key val in six.iteritems _info *names if len names 1 return next six.itervalues versions_dict else return versions_dict
def writeValueListToRepositoryWriter repositoryWriter setting repositoryWriter.write setting.name for item in setting.value if item ! '[]' repositoryWriter.write globalSpreadsheetSeparator repositoryWriter.write item repositoryWriter.write '\n'
@decorators.api_view ['GET'] @decorators.permission_classes permissions.AllowAny @decorators.renderer_classes JSONRenderer def cname request host request.GET.get 'host' if not host return Response {'error' 'hostGETargrequired'} status status.HTTP_400_BAD_REQUEST host clean_url host slug cname_to_slug host return Response {'host' host 'slug' slug}
def check_dist import platformtry return platform.linux_distribution [0].lower .strip except AttributeError return platform.dist [0].lower .strip
def loadMimeTypes mimetype_locations None init mimetypes.init init mimetype_locations mimetypes.types_map.update {'.conf' 'text/plain' '.diff' 'text/plain' '.flac' 'audio/x-flac' '.java' 'text/plain' '.oz' 'text/x-oz' '.swf' 'application/x-shockwave-flash' '.wml' 'text/vnd.wap.wml' '.xul' 'application/vnd.mozilla.xul+xml' '.patch' 'text/plain'} return mimetypes.types_map
def dvi_match_query body_id ptable s3db.pr_personntable s3db.pr_notebtable s3db.dvi_bodyquery ptable.deleted False & ptable.missing True & ntable.pe_id ptable.pe_id & ntable.status 1 body btable[body_id]if not body return queryif body.date_of_recovery q ntable.timestmp < body.date_of_recovery | ntable.timestmp None query query & q if body.age_group and body.age_group ! 1 q ptable.age_group None | ptable.age_group 1 | ptable.age_group body.age_group query query & q if body.gender and body.gender ! 1 q ptable.gender None | ptable.gender 1 | ptable.gender body.gender return query
def python_version return _sys_version [1]
def test_tps az np.linspace 0.0 2 * np.pi 20 endpoint False pol np.linspace 0 np.pi 12 [1 -1 ]sph np.array np.meshgrid 1 az pol indexing 'ij' sph.shape 3 -1 assert_equal sph.shape[1] 200 source _sph_to_cart sph.T destination source.copy destination * 2destination[ 0] + 1warp SphericalSurfaceWarp .fit source[ 2] destination[ 2] destination_est warp.transform source assert_allclose destination_est destination atol 0.01
def GetClassForCLSID clsid clsid str clsid if CLSIDToClass.HasClass clsid return CLSIDToClass.GetClass clsid mod GetModuleForCLSID clsid if mod is None return Nonetry return CLSIDToClass.GetClass clsid except KeyError return None
def draw_scree_graph dir_path data_file_link background_color label_color generate_eps data dimensions len data['coord'][3] props {}props['title'] 'PCoAScreePlot First%sdimensions ' % dimensions props['ylabel'] 'FractionofVariance'props['xlabel'] 'Principalcomponent'xy_coords {}x_points [x for x in range dimensions ]c_data [ float x / 100.0 for x in data['coord'][3]]xy_coords['Variance'] x_points c_data 'o' 'r' cum_var [c_data[0]]for ix in range dimensions - 1 cum_var.append cum_var[ix] + c_data[ ix + 1 ] xy_coords['Cumulativevariance'] x_points cum_var 's' 'b' img_src eps_link make_line_plot dir_path data_file_link background_color label_color xy_coords xy_coords props props x_len 4.5 y_len 4.5 generate_eps generate_eps return IMG_SRC % img_src eps_link
def get_available_backends manager ExtensionManager namespace BACKENDS_NAMESPACE invoke_on_load False return manager.names
def winrm_cmd session command flags **kwargs log.debug 'ExecutingWinRMcommand {0}{1}'.format command flags r session.run_cmd command flags return r.status_code
def create_script command import osimport os.path as pathimport subprocessimport tempfile fd script_file tempfile.mkstemp prefix 'lxc-attach-script' f os.fdopen fd 'wb' try f.write ATTACH_TEMPLATE % {'container_command' command} f.flush finally f.close os.chmod script_file int '0700' 8 stdout_file os.fdopen tempfile.mkstemp prefix 'lxc-attach-script-log' [0] 'ab' stderr_file os.fdopen tempfile.mkstemp prefix 'lxc-attach-script-err' [0] 'ab' try subprocess.Popen [script_file] stdout stdout_file stderr stderr_file .communicate finally stderr_file.close stdout_file.close os.remove script_file
def _req_environ_property environ_field def getter self return self.environ.get environ_field None def setter self value if isinstance value unicode self.environ[environ_field] value.encode 'utf-8' else self.environ[environ_field] valuereturn property getter setter doc 'Getandsetthe%spropertyintheWSGIenvironment' % environ_field
def detect_face face_file max_results 4 image_content face_file.read batch_request [{'image' {'content' base64.b64encode image_content .decode 'utf-8' } 'features' [{'type' 'FACE_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service.images .annotate body {'requests' batch_request} response request.execute return response['responses'][0]['faceAnnotations']
@pytest.mark.parametrize u'position' u'subpixel_index' zip test_positions test_position_indices def test_subpixel_indices position subpixel_index assert np.all subpixel_indices position subsampling subpixel_index
def frucht_graph create_using None G cycle_graph 7 create_using G.add_edges_from [[0 7] [1 7] [2 8] [3 9] [4 9] [5 10] [6 10] [7 11] [8 11] [8 9] [10 11]] G.name 'FruchtGraph'return G
def _get_config app_version current_config_version development _inspect_environment global _cached_configif development and _new_request or not _cached_config _cached_config _fetch_from_local_file or Config if _cached_config.ah__conf__version < current_config_version newconfig _fetch_latest_from_memcache app_version if not newconfig or newconfig.ah__conf__version < current_config_version newconfig _fetch_latest_from_datastore app_version _cached_config newconfig or _cached_config return _cached_config
def fix_win_codec try codecs.lookup 'cp65001' return Falseexcept LookupError codecs.register lambda name name 'cp65001' and codecs.lookup 'utf-8' or None return True
def rrCellChangeOrder a TpPd pd 6 b MessageType mesType 8 c CellDescription d NcModeAndSpareHalfOctets packet a / b / c / d return packet
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def extract_metadata name seps name.count '-' artist title Noneif seps 1 pos name.find '-' artist name[ pos].strip title name[ pos + 3 ].strip else title name.strip return dict artist artist title title
def properties options None return default_api.properties options
def update_dme username password dme_id ip_address dme_url 'https //www.dnsmadeeasy.com/servlet/updateip'dme_url + '?username %s&password %s&id %s&ip %s's urllib.request.urlopen dme_url % username password dme_id ip_address return s.read
def backup_get_all_by_host context host return IMPL.backup_get_all_by_host context host
def timetrace message idstring tracemessage 'TEST_MESSAGE' final False if message.startswith tracemessage try prefix tlast t0 message.split None 2 tlast t0 float tlast float t0 except IndexError ValueError t0 time tlast t0t1 t0else t1 time print '**timetrace %s dT %fs total %fs.' % idstring t1 - tlast t1 - t0 if final message '****%s total%f ****' % tracemessage t1 - t0 else message '%s%f%f' % tracemessage t1 t0 return message
def top_clusters tree k def item node return node.is_leaf - node.value.height node heap [item tree ]while len heap < k _ cl heap[0]if cl.is_leaf assert all n.is_leaf for _ n in heap break key cl heapq.heappop heap left right cl.left cl.right heapq.heappush heap item left heapq.heappush heap item right return [n for _ n in heap]
def img_as_ubyte image force_copy False return convert image np.uint8 force_copy
def stylesheet_params **kwargs result {}for key val in kwargs.items if isinstance val basestring val _etree.XSLT.strparam val elif val is None raise TypeError 'Nonenotallowedasastylesheetparameter' elif not isinstance val _etree.XPath val unicode val result[key] valreturn result
def java_test name srcs deps [] resources [] source_encoding None warnings None main_class 'org.junit.runner.JUnitCore' exclusions [] testdata [] target_under_test '' **kwargs target JavaTest name srcs deps resources source_encoding warnings main_class exclusions testdata target_under_test kwargs blade.blade.register_target target
def get_locale_from_lang lang if not lang or lang 'dbg' lang 'en'return Locale translation.to_locale lang
def site_config_dir appname None appauthor None version None multipath False if sys.platform in ['win32' 'darwin'] path site_data_dir appname appauthor if appname and version path os.path.join path version else path os.getenv 'XDG_CONFIG_DIRS' '/etc/xdg' pathlist [os.path.expanduser x.rstrip os.sep for x in path.split os.pathsep ]if appname if version appname os.path.join appname version pathlist [os.sep.join [x appname] for x in pathlist]if multipath path os.pathsep.join pathlist else path pathlist[0]return path
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def check_balances minimum 100 min_float float minimum result get_balances if result['accountbalance'] < min_float return Falsereturn True
def prepare_roidb imdb roidb imdb.roidbfor i in xrange len imdb.image_index roidb[i]['image'] imdb.image_path_at i gt_overlaps roidb[i]['gt_overlaps'].toarray max_overlaps gt_overlaps.max axis 1 max_classes gt_overlaps.argmax axis 1 roidb[i]['max_classes'] max_classesroidb[i]['max_overlaps'] max_overlapszero_inds np.where max_overlaps 0 [0]assert all max_classes[zero_inds] 0 nonzero_inds np.where max_overlaps > 0 [0]assert all max_classes[nonzero_inds] ! 0
def _get_slogdet_diag_walker a if isinstance a.dtype types.Complex @register_jitabledef cmplx_diag_walker n a sgn csgn sgn + 0j acc 0.0for k in range n absel np.abs a[ k k ] csgn csgn * a[ k k ] / absel acc acc + np.log absel return csgn acc return cmplx_diag_walkerelse @register_jitabledef real_diag_walker n a sgn acc 0.0for k in range n v a[ k k ]if v < 0.0 sgn - sgn v - v acc acc + np.log v return sgn + 0.0 acc return real_diag_walker
def _add_implied_job_id d if not d.get 'job_id' if d.get 'task_id' d['job_id'] _to_job_id d['task_id'] elif d.get 'application_id' d['job_id'] _to_job_id d['application_id']
def distutils_scheme dist_name user False home None root None from distutils.dist import Distributionscheme {}d Distribution {'name' dist_name} d.parse_config_files i d.get_command_obj 'install' create True i.user user or i.user i.home home or i.home i.root root or i.root i.finalize_options for key in SCHEME_KEYS scheme[key] getattr i 'install_' + key if running_under_virtualenv scheme['headers'] os.path.join sys.prefix 'include' 'site' 'python' + sys.version[ 3] dist_name if root is not None scheme['headers'] os.path.join root os.path.abspath scheme['headers'] [1 ] return scheme
@pytest.mark.usefixtures 'back_up_rc' def test_get_user_config_valid user_config_path custom_config shutil.copy 'tests/test-config/valid-config.yaml' user_config_path conf config.get_user_config assert conf custom_config
def openSerial port 0 rate 19200 timeout 1 snap.openSerial port port rate rate tout timeout
def between expr lower_bound upper_bound expr _literal_as_binds expr return expr.between lower_bound upper_bound
@notification_handlerdef simple_push notification registrations PushNotificationRegistration.objects.filter creator notification.owner for reg in registrations _send_simple_push reg.push_url notification.id
@_get_clientdef task_delete client task_id session None return client.task_delete task_id task_id session session
def _get_metadata_from_file meta_data meta {}if not meta_data return metaif not meta_data[0] meta_data meta_data[1 ]for i line in enumerate meta_data if not line breakmatch re_meta line if match[0] meta[match[0]] match[1]if u'title' not in meta t _get_title_from_contents meta_data if t is not None meta[u'title'] treturn meta
def export_table bigquery cloud_storage_path project_id dataset_id table_id export_format 'CSV' num_retries 5 compression 'NONE' job_data {'jobReference' {'projectId' project_id 'jobId' str uuid.uuid4 } 'configuration' {'extract' {'sourceTable' {'projectId' project_id 'datasetId' dataset_id 'tableId' table_id} 'destinationUris' [cloud_storage_path] 'destinationFormat' export_format 'compression' compression}}}return bigquery.jobs .insert projectId project_id body job_data .execute num_retries num_retries
def test_rgb_to_hsl_part_15 assert rgb_to_hsl 0 51 0 120 100 10 assert rgb_to_hsl 0 102 0 120 100 20 assert rgb_to_hsl 0 153 0 120 100 30 assert rgb_to_hsl 0 204 0 120 100 40 assert rgb_to_hsl 0 255 0 120 100 50 assert rgb_to_hsl 51 255 51 120 100 60 assert rgb_to_hsl 102 255 102 120 100 70 assert rgb_to_hsl 153 255 153 120 100 80 assert rgb_to_hsl 204 255 204 120 100 90
def ckeditor_config request default_config EditorToolbar.objects.filter name 'default' if default_config.exists code default_config[0].codeelse code ''context {'editor_config' code 'redirect_pattern' REDIRECT_CONTENT 'allowed_tags' ''.join ALLOWED_TAGS }return render request 'wiki/ckeditor_config.js' context content_type 'application/x-javascript'
def colors pass
def test_unpack_http_url_with_urllib_response_without_content_type data _real_session PipSession def _fake_session_get *args **kwargs resp _real_session.get *args **kwargs del resp.headers['Content-Type']return respsession Mock session.get _fake_session_geturi path_to_url data.packages.join 'simple-1.0.tar.gz' link Link uri temp_dir mkdtemp try unpack_http_url link temp_dir download_dir None session session assert set os.listdir temp_dir set ['PKG-INFO' 'setup.cfg' 'setup.py' 'simple' 'simple.egg-info'] finally rmtree temp_dir
def publish_parts source source_path None source_class io.StringInput destination_path None reader None reader_name 'standalone' parser None parser_name 'restructuredtext' writer None writer_name 'pseudoxml' settings None settings_spec None settings_overrides None config_section None enable_exit_status None output pub publish_programmatically source source source_path source_path source_class source_class destination_class io.StringOutput destination None destination_path destination_path reader reader reader_name reader_name parser parser parser_name parser_name writer writer writer_name writer_name settings settings settings_spec settings_spec settings_overrides settings_overrides config_section config_section enable_exit_status enable_exit_status return pub.writer.parts
def enqueue_feedback_message_batch_email_task user_id taskqueue_services.enqueue_task feconf.TASK_URL_FEEDBACK_MESSAGE_EMAILS {'user_id' user_id} feconf.DEFAULT_FEEDBACK_MESSAGE_EMAIL_COUNTDOWN_SECS
def _validate_sr radius if isinstance radius Quantity sr_angle radius.to u.degree else sr_angle radius * u.degree return sr_angle.value
def libvlc_video_get_spu_delay p_mi f _Cfunctions.get 'libvlc_video_get_spu_delay' None or _Cfunction 'libvlc_video_get_spu_delay' 1 None ctypes.c_int64 MediaPlayer return f p_mi
def required_module_list docstring None if not docstring return []ret []modules parse_docstring docstring .get 'deps' [] for mod in modules try imp.find_module mod except ImportError ret.append mod return ret
def set_all_param_values layer values **tags params get_all_params layer **tags if len params ! len values raise ValueError 'mismatch got%dvaluestoset%dparameters' % len values len params for p v in zip params values if p.get_value .shape ! v.shape raise ValueError 'mismatch parameterhasshape%rbutvaluetosethasshape%r' % p.get_value .shape v.shape else p.set_value v
def get_rotation_change_value label return _check_range_and_return 'rotationchange' label -4 4
def factory name u'root' **kwargs if name not in registry raise Exception u"Askedunknownvalidator'%s'" % name return registry[name] **kwargs
def new_canvas *args **kwargs allnums _pylab_helpers.Gcf.figs.keys num max allnums + 1 if allnums else 1 FigureClass kwargs.pop 'FigureClass' Figure figure FigureClass *args **kwargs canvas FigureCanvas figure fig_manager FigureManagerQT canvas num return fig_manager.canvas
def _GetFieldByName message_descriptor field_name try return message_descriptor.fields_by_name[field_name]except KeyError raise ValueError 'Protocolmessagehasno"%s"field.' % field_name
def _bytes_chr_py3 i return bytes [i]
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u''.join choice chars for x in range length
def get_remote_login ret salt.utils.mac_utils.execute_return_result 'systemsetup-getremotelogin' enabled salt.utils.mac_utils.validate_enabled salt.utils.mac_utils.parse_return ret return enabled 'on'
def _primitive f p ring f.ringdom ring.domaink ring.ngenscoeffs {}for monom coeff in f.iterterms if monom[ -1 ] not in coeffs coeffs[monom[ -1 ]] {}coeffs[monom[ -1 ]][monom[ -1 ]] coeffcont []for coeff in iter coeffs.values cont gf_gcd cont gf_from_dict coeff p dom p dom yring ring.clone symbols ring.symbols[ k - 1 ] contf yring.from_dense cont .trunc_ground p return contf f.quo contf.set_ring ring
def eval_js js e EvalJs return e.eval js
def get_context_loop_positions context try loop_counter context['forloop']['counter']except KeyError return 0 0 try page context['page_obj']except KeyError return loop_counter loop_counter total_loop_counter page.number - 1 * page.paginator.per_page + loop_counter return total_loop_counter loop_counter
def period_range start None end None periods None freq 'D' name None return PeriodIndex start start end end periods periods freq freq name name
def isintlike x if not isscalarlike x return Falsetry return bool int x x except TypeError ValueError return False
def test_fnpickling_class tmpdir fn str tmpdir.join 'test2.pickle' obj1 'astring'obj2 ToBePickled obj1 fnpickle obj2 fn res fnunpickle fn assert res obj2
def add_to_recent_scan name md5 url try db_obj RecentScansDB.objects.filter MD5 md5 if not db_obj.exists new_db_obj RecentScansDB NAME name MD5 md5 URL url TS timezone.now new_db_obj.save except PrintException '[ERROR]AddingScanURLtoDatabase'
def _build_editable_options req regexp re.compile '[\\?#&] ?P<name>[^& ]+ ?P<value>[^& ]+ ' matched regexp.findall req if matched ret dict for option in matched name value optionif name in ret raise Exception '%soptionalreadydefined' % name ret[name] valuereturn retreturn None
def has_ever_registered user_id user_settings get_user_settings user_id strict True return bool user_settings.username and user_settings.last_agreed_to_terms
def update_status msg **redis_kwargs pid getpid red StrictRedis **redis_kwargs key 'pid-%d-statuses' % pid msg '%.6f%s' % time msg red.lpush key msg red.expire key 60 * 60 red.ltrim key 0 _keep
def dir_setup test_dir pkg temp_dir tempfile.mkdtemp 'temp' config_dir tempfile.mkdtemp 'config' work_dir tempfile.mkdtemp 'work' os.chmod temp_dir constants.CONFIG_DIRS_MODE os.chmod config_dir constants.CONFIG_DIRS_MODE os.chmod work_dir constants.CONFIG_DIRS_MODE test_configs pkg_resources.resource_filename pkg os.path.join 'testdata' test_dir shutil.copytree test_configs os.path.join temp_dir test_dir symlinks True return temp_dir config_dir work_dir
def feed_data func new_name *args **kwargs @wraps func def wrapper self return func self *args **kwargs wrapper.__name__ new_nameif func.__doc__ try wrapper.__doc__ func.__doc__.format *args **kwargs except IndexError KeyError passreturn wrapper
def elu x alpha 1.0 res tf.nn.elu x if alpha 1 return reselse return tf.where x > 0 res alpha * res
def _graph_connected_component graph node_id n_node graph.shape[0]if sparse.issparse graph graph graph.tocsr connected_nodes np.zeros n_node dtype np.bool nodes_to_explore np.zeros n_node dtype np.bool nodes_to_explore[node_id] Truefor _ in range n_node last_num_component connected_nodes.sum np.logical_or connected_nodes nodes_to_explore out connected_nodes if last_num_component > connected_nodes.sum breakindices np.where nodes_to_explore [0]nodes_to_explore.fill False for i in indices if sparse.issparse graph neighbors graph[i].toarray .ravel else neighbors graph[i]np.logical_or nodes_to_explore neighbors out nodes_to_explore return connected_nodes
def validate_weigher weigher weight_classes CONF.filter_scheduler.weight_classesif 'nova.scheduler.weights.all_weighers' in weight_classes return Truereturn weigher in weight_classes
def getBusFreq if importCtypesFailed return Falsemib ctypes.c_int * 2 CTL_HW HW_BUS_FREQ val ctypes.c_int intSize ctypes.c_int ctypes.sizeof val cocoa.sysctl ctypes.byref mib 2 ctypes.byref val ctypes.byref intSize 0 0 return val.value
def grouper n iterable fillvalue None args [iter iterable ] * n return it.izip_longest fillvalue fillvalue *args
def get_recent **redis_kwargs pid getpid red StrictRedis **redis_kwargs processes []messages []for key in red.keys 'pid-*-statuses' try now time pid int key.split '-' [1] msgs [msg.split '' 1 for msg in red.lrange key 0 _keep ]msgs [ now - float t pid msg for t msg in msgs]except continueelse messages + msgsprocesses + msgs[ 1]messages.sort processes.sort return processes messages
def gaussian x mean stddev tmp -0.5 * sum x - mean / stddev ** 2 return np.exp tmp / np.power 2.0 * np.pi 0.5 * len x * stddev
def _read_double fid n 1 return np.fromfile fid '>f8' n
def _get_certificate_obj cert if isinstance cert M2Crypto.X509.X509 return certtext _text_or_file cert text get_pem_entry text pem_type 'CERTIFICATE' return M2Crypto.X509.load_cert_string text
def make_simp z def simp expr 'Efficientlysimplifytherationalfunction``expr``.' numer denom expr.as_numer_denom c numer denom poly numer z .cancel poly denom z return c * numer.as_expr / denom.as_expr return simp
@pytest.mark.skipif u'notHAS_SCIPY' def test_poisson_conf_frequentist_confidence_gehrels nlh np.array [ 0 0 1.841 1 0.173 3.3 2 0.708 4.638 3 1.367 5.918 4 2.086 7.163 5 2.84 8.382 6 3.62 9.584 7 4.419 10.77 8 5.232 11.95 9 6.057 13.11 10 6.891 14.27 ] assert_allclose funcs.poisson_conf_interval nlh[ 0] interval u'frequentist-confidence' nlh[ 1 ].T rtol 0.001 atol 0.001
def get_challenge_for_url url if not url raise ValueError 'URLcannotbeNone' url parse.urlparse url return _cache.get url.netloc
def loopbackAsync server client pumpPolicy identityPumpPolicy serverToClient _LoopbackQueue clientToServer _LoopbackQueue server.makeConnection _LoopbackTransport serverToClient client.makeConnection _LoopbackTransport clientToServer return _loopbackAsyncBody server serverToClient client clientToServer pumpPolicy
@taskdef linkcheck ctx build ctx builder 'linkcheck'
@pytest.mark.skipif 'notHAS_BLEACH' def test_multicolumn_write_escape col1 [1 2 3]col2 [ 1.0 1.0 2.0 2.0 3.0 3.0 ]col3 [ '<a></a>' '<a></a>' 'a' '<b></b>' 'b' 'b' 'c' 'c' 'c' ]table Table [col1 col2 col3] names 'C1' 'C2' 'C3' expected '<html>\n<head>\n<metacharset "utf-8"/>\n<metacontent "text/html;charset UTF-8"http-equiv "Content-type"/>\n</head>\n<body>\n<table>\n<thead>\n<tr>\n<th>C1</th>\n<thcolspan "2">C2</th>\n<thcolspan "3">C3</th>\n</tr>\n</thead>\n<tr>\n<td>1</td>\n<td>1.0</td>\n<td>1.0</td>\n<td><a></a></td>\n<td><a></a></td>\n<td>a</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2.0</td>\n<td>2.0</td>\n<td><b></b></td>\n<td>b</td>\n<td>b</td>\n</tr>\n<tr>\n<td>3</td>\n<td>3.0</td>\n<td>3.0</td>\n<td>c</td>\n<td>c</td>\n<td>c</td>\n</tr>\n</table>\n</body>\n</html>\n'out html.HTML htmldict {'raw_html_cols' 'C3'} .write table [0].strip assert out expected.strip
@condition etag_func lambda r WEAK_ETAG def etag_view_weak request return HttpResponse FULL_RESPONSE
def manual_id singleton prompt u'Enter{0}ID '.format 'recording' if singleton else 'release' return input_ prompt .strip
def plural s number suffix 's' return s.format number number s suffix if number % 100 ! 1 else ''
def requires_partial expr if not isinstance expr.free_symbols collections.Iterable return len set expr.variables > 1 return sum not s.is_integer for s in expr.free_symbols > 1
def close_git_review_requests payload server_url review_id_to_commits_map defaultdict list branch_name payload.get u'branch' if not branch_name return review_id_to_commits_mapcommits payload.get u'commits' [] for commit in commits commit_hash commit.get u'id' commit_message commit.get u'message' review_request_id get_review_request_id commit_message server_url commit_hash commit_entry u'%s %s ' % branch_name commit_hash[ 7] review_id_to_commits_map[review_request_id].append commit_entry close_all_review_requests review_id_to_commits_map
def get_current_app frame None if frame None frame inspect.currentframe .f_backwhile frame module inspect.getmodule frame.f_code if not module raise Exception 'Nomoduleforcode%s frame%s .Perhapsyouhaveanold' + '.pycfilehangingaround?' % repr frame.f_code repr frame app get_app_for_module module if app return appframe frame.f_backreturn None
def getNewDerivation elementNode return GridDerivation elementNode
def DevOnly field return field if settings.DEV_MODE else None
def create_unbound_method func cls if six.PY2 return MethodType func None cls if six.PY3 return func
def has_pairs profile return len profile > 0 and isinstance profile[0] list
def test_double_install script data result script.pip 'install' 'pip' 'pip' expect_error False msg "Doublerequirementgiven pip alreadyinpip name 'pip' "assert msg not in result.stderr
def python_version_tuple if hasattr sys 'version_info' return sys.version_info[ 3]return tuple string.split _sys_version [1] '.'
@requires_pyopengl def test_glplus gl.use_gl 'gl+' fnames set [name for name in dir gl if name.startswith 'gl' ] assert len fnames.difference function_names .difference ['gl2'] > 50 cnames set [name for name in dir gl if name.startswith 'GL' ] assert len cnames.difference constant_names > 50 gl.use_gl 'gl2' _test_function_names gl _test_constant_names gl
def get_commit_dates refs repo_dir None result []for ref in refs commit get_commit_items ref cp repo_dir result.append commit.author_sec return result
def fix_review_counts LocalSiteProfile.objects.update direct_incoming_request_count None total_incoming_request_count None pending_outgoing_request_count None total_outgoing_request_count None starred_public_request_count None Group.objects.update incoming_request_count None
def _collect_assets_cmd system **kwargs try if kwargs[COLLECTSTATIC_LOG_DIR_ARG] is None collectstatic_stdout_str ''else collectstatic_stdout_str '>{output_dir}/{sys}-collectstatic.log'.format output_dir kwargs[COLLECTSTATIC_LOG_DIR_ARG] sys system except KeyError collectstatic_stdout_str '>/dev/null'return collectstatic_stdout_str
def load_certificate_request type buffer if isinstance buffer _text_type buffer buffer.encode 'ascii' bio _new_mem_buf buffer if type FILETYPE_PEM req _lib.PEM_read_bio_X509_REQ bio _ffi.NULL _ffi.NULL _ffi.NULL elif type FILETYPE_ASN1 req _lib.d2i_X509_REQ_bio bio _ffi.NULL else raise ValueError 'typeargumentmustbeFILETYPE_PEMorFILETYPE_ASN1' if req _ffi.NULL _raise_current_error x509req X509Req.__new__ X509Req x509req._req _ffi.gc req _lib.X509_REQ_free return x509req
def variable_from_module module variable None default None if not module return defaultmod mod_import module if variable result []for var in make_iter variable if var result.append mod.__dict__.get var default else result [val for key val in mod.__dict__.items if not key.startswith '_' or ismodule val ]if len result 1 return result[0]return result
def get_default_config key try path os.path.dirname __file__ + '/colorset/config' data load_config path return data[key]except raise Exception 'Thisconfigkeydoesnotexistindefault.'
def gep_inbounds builder ptr *inds **kws return gep builder ptr inbounds True *inds **kws
def sql_flush style connection only_django False reset_sequences True allow_cascade False if only_django tables connection.introspection.django_table_names only_existing True include_views False else tables connection.introspection.table_names include_views False seqs connection.introspection.sequence_list if reset_sequences else statements connection.ops.sql_flush style tables seqs allow_cascade return statements
def create_menu menu_items parent None nodes []default_fn import_string settings.OSCAR_DASHBOARD_DEFAULT_ACCESS_FUNCTION for menu_dict in menu_items try label menu_dict['label']except KeyError raise ImproperlyConfigured 'Nolabelspecifiedformenuitemindashboard' children menu_dict.get 'children' [] if children node Node label label icon menu_dict.get 'icon' None access_fn menu_dict.get 'access_fn' default_fn create_menu children parent node else node Node label label icon menu_dict.get 'icon' None url_name menu_dict.get 'url_name' None url_kwargs menu_dict.get 'url_kwargs' None url_args menu_dict.get 'url_args' None access_fn menu_dict.get 'access_fn' default_fn if parent is None nodes.append node else parent.add_child node return nodes
def quitServer ignored reactor.stop
def make_signature func spec signature func if spec.defaults is None n_wo_defaults len spec.args defaults '' * n_wo_defaults else n_wo_defaults len spec.args - len spec.defaults defaults '' * n_wo_defaults + spec.defaults args []for i var default in enumerate zip spec.args defaults args.append var if default '' else var + ' ' + repr default if spec.varargs args.append '*' + spec.varargs if spec.keywords args.append '**' + spec.keywords return args spec.args
@dec.onlyif_unicode_pathsdef test_unicode_cwd wd tempfile.mkdtemp suffix u'\u20ac' old_wd os.getcwd os.chdir wd try app BaseIPythonApplication app.init_profile_dir app.init_config_files app.load_config_file suppress_errors False finally os.chdir old_wd
def set_enrollment_attributes user_id course_id attributes _data_api .add_or_update_enrollment_attr user_id course_id attributes
def choose_names installer if installer is None logger.debug 'Noinstaller pickingnamesmanually' return _choose_names_manually domains list installer.get_all_names names get_valid_domains domains if not names return _choose_names_manually 'Nonameswerefoundinyourconfigurationfiles.' code names _filter_names names if code display_util.OK and names return nameselse return []
def core_freq_config_set kodi_setting all_settings try version PiVersion except IOError version 'PiB'if version 'PiB' if int kodi_setting 250 return 'remove_this_line'elif version 'Pi2' if int kodi_setting 450 return 'remove_this_line'return kodi_setting
def logsumexp x axis None return LogSumExp axis x
def test_no_stdlib_collections2 import collectionsmatplotlib import_module 'matplotlib' __import__kwargs {'fromlist' ['collections']} min_module_version '1.1.0' catch RuntimeError if matplotlib assert collections ! matplotlib.collections
def removed_participants original_participants update_participants original_table {part['email'] part.get 'name' for part in original_participants if 'email' in part }update_table {part['email'] part.get 'name' for part in update_participants if 'email' in part }ret []for email in original_table if email not in update_table ret.append dict email email name original_table[email] return ret
def clear BACKEND.clear
def bound_socket *args **kwargs sock SOCKET_SOCKET *args **kwargs sock.bind SOURCE 0 return sock
def read_subject_names path folder_names []for dirname dirnames filenames in os.walk path for subdirname in dirnames folder_names.append subdirname return folder_names
def addon_can_be_signed validation summary validation.get 'signing_summary' {} return summary.get 'low' 0 0 and summary.get 'medium' 0 0 and summary.get 'high' 0 0
def metadata request return {'display_version' getattr settings 'DISPLAY_VERSION' False 'version' getattr settings 'VERSION' 'N/A' 'shop_name' settings.OSCAR_SHOP_NAME 'shop_tagline' settings.OSCAR_SHOP_TAGLINE 'homepage_url' settings.OSCAR_HOMEPAGE 'use_less' getattr settings 'USE_LESS' False 'language_neutral_url_path' strip_language_code request 'google_analytics_id' getattr settings 'GOOGLE_ANALYTICS_ID' None }
def test_nonunique_prefix_completion superConsole.SendKeys 'outputRedirectStart{ }{ }{ENTER}' testRegex ''superConsole.SendKeys 'printy{TAB}{ENTER}' superConsole.SendKeys 'printy{TAB}{TAB}{ENTER}' testRegex + ' yorickyak|yakyorick 'superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex AreEqual removePrompts getTestOutput [1] []
def _bad_copy bad_request err_msg bad_request.messagereturn err_msg.startswith 'Nofilefoundinrequest. POST' and 'copyTo' in err_msg
def Time2Internaldate date_time if isinstance date_time int float dt datetime.fromtimestamp date_time timezone.utc .astimezone elif isinstance date_time tuple try gmtoff date_time.tm_gmtoffexcept AttributeError if time.daylight dst date_time[8]if dst -1 dst time.localtime time.mktime date_time [8]gmtoff - time.timezone time.altzone [dst] else gmtoff - time.timezone delta timedelta seconds gmtoff dt datetime tzinfo timezone delta *date_time[ 6] elif isinstance date_time datetime if date_time.tzinfo is None raise ValueError 'date_timemustbeaware' dt date_timeelif isinstance date_time str and date_time[0] date_time[ -1 ] '"' '"' return date_timeelse raise ValueError 'date_timenotofaknowntype' fmt '"%d-{}-%Y%H %M %S%z"'.format Months[dt.month] return dt.strftime fmt
def _sh_complex_to_real sh order if order 0 return np.real sh else return np.sqrt 2.0 * np.real if order > 0 else np.imag sh
def addsitepackages known_paths for sitedir in getsitepackages if os.path.isdir sitedir addsitedir sitedir known_paths return known_paths
def unsetenv name os.environ[name] ''del os.environ[name]
def avail_images call None if call 'action' raise SaltCloudSystemExit 'Theavail_imagesfunctionmustbecalledwith-for--function orwiththe--list-imagesoption' server user password _get_xml_rpc auth ' '.join [user password] image_pool server.one.imagepool.info auth -2 -1 -1 [1]images {}for image in _get_xml image_pool images[image.find 'NAME' .text] _xml_to_dict image return images
def enable name **kwargs cmd '/usr/sbin/svcadmenable{0}'.format name return not __salt__['cmd.retcode'] cmd python_shell False
def _format_str *args return_tuple []for i in args r repr i if isinstance i bytes or isinstance i unicode and '\n' in i stripped ''if isinstance i unicode and r.startswith 'u' stripped r[0]r r[1 ]elif isinstance i bytes and r.startswith 'b' stripped r[0]r r[1 ]quote_char r[0]assert quote_char in "'" '"' quote_charassert r[0] r[ -1 ] r r[1 -1 ]r stripped + 3 * quote_char + '\\\n' + re.sub ' ?<!\\\\ \\\\\\\\ * \\\\n' '\\1\\n' r + 3 * quote_char r re.sub '\\n' '\\\\n\\\\\\n' r return_tuple.append r return tuple return_tuple
def sum_bilateral image selem out None mask None shift_x False shift_y False s0 10 s1 10 return _apply bilateral_cy._sum image selem out out mask mask shift_x shift_x shift_y shift_y s0 s0 s1 s1
@bp.route '/desert' def desert page force_int request.args.get 'page' 1 0 if not page return abort 404 paginator Topic.query.filter_by reply_count 0 .order_by Topic.id.desc .paginate page paginator.items fill_topics paginator.items return render_template 'topic/topics.html' paginator paginator endpoint 'topic.desert'
def find_window_for_buffer_name cli buffer_name from prompt_toolkit.interface import CommandLineInterfaceassert isinstance cli CommandLineInterface from .containers import Windowfrom .controls import BufferControlfor l in cli.layout.walk cli if isinstance l Window and isinstance l.content BufferControl if l.content.buffer_name buffer_name return l
def parse_ng86 lines results sequences []for line in lines line_floats_res re.findall '-*\\d+\\.\\d+' line line_floats [float val for val in line_floats_res]matrix_row_res re.match '^ [^\\s]+? ? \\s+-?\\d+\\.\\d+|\\s*$|-1.0000\\s*\\ ' line if matrix_row_res is not None seq_name matrix_row_res.group 1 .strip sequences.append seq_name results[seq_name] {}for i in range 0 len line_floats 3 NG86 {}NG86['omega'] line_floats[i]NG86['dN'] line_floats[ i + 1 ]NG86['dS'] line_floats[ i + 2 ]results[seq_name][sequences[ i // 3 ]] {'NG86' NG86}results[sequences[ i // 3 ]][seq_name] {'NG86' NG86}return results sequences
def _prep_pull __context__['dockerng._pull_status'] [x[ 12] for x in images all True ]
def make_logentry_elements maxrevision doc xml.dom.minidom.parseString make_changes_output maxrevision return doc.getElementsByTagName 'logentry'
def technical_500_response request exc_type exc_value tb reporter ExceptionReporter request exc_type exc_value tb html reporter.get_traceback_html return HttpResponseServerError html mimetype 'text/html'
def dolog fmt *args logfp.write fmt % args + '\n'
def dup_eval f a K if not a return dup_TC f K result K.zerofor c in f result * aresult + creturn result
def normalizeName name if isinstance name unicode joiner u'%s%s'else joiner '%s%s'sname name.split ' ' if len sname 2 name joiner % sname[1] sname[0] return name
def _to_job_id task_id return 'job_' + '_'.join task_id.split '_' [1 3]
def _is_dns_subdomain name dns_subdomain re.compile '^[a-z0-9\\.-]{1 253}$' if dns_subdomain.match name log.debug 'Name {0}isvalidDNSsubdomain'.format name return Trueelse log.debug 'Name {0}isnotvalidDNSsubdomain'.format name return False
def organization_delete context data_dict return _group_or_org_delete context data_dict is_org True
def test_strip s '<scri<script>pt>alert 1 </scr</script>ipt>'eq_ 'pt&gt;alert 1 ipt&gt;' clean s strip True s '<scri<scri<script>pt>pt>alert 1 </script>'eq_ 'pt&gt;pt&gt;alert 1 ' clean s strip True
def _do_overwrite fs path copy_data path_dest path + '._hue_new' copy_data path_dest cur_stats fs.stats path try fs.do_as_superuser fs.chmod path_dest stat_module.S_IMODE cur_stats['mode'] except logging.exception 'Couldnotchmodnewfile%stomatcholdfile%s' % path_dest path try fs.do_as_superuser fs.chown path_dest cur_stats['user'] cur_stats['group'] except logging.exception 'Couldnotchownnewfile%stomatcholdfile%s' % path_dest path fs.remove path skip_trash True fs.rename path_dest path
def edit_profile request form_class success_url None template_name 'profiles/private/edit_profile.html' extra_context None try profile_obj request.user.profileexcept ObjectDoesNotExist return HttpResponseRedirect reverse 'profiles_profile_create' if success_url is None success_url reverse 'profiles_profile_detail' kwargs {'username' request.user.username} if request.method 'POST' form form_class data request.POST files request.FILES instance profile_obj if form.is_valid form.save return HttpResponseRedirect success_url else form form_class instance profile_obj if extra_context is None extra_context {}context RequestContext request for key value in extra_context.items context[key] callable value and value or value return render_to_response template_name {'form' form 'profile' profile_obj 'user' profile_obj.user} context_instance context
def _contains_block_level_tag el if el.tag in block_level_tags or el.tag in block_level_container_tags return Truefor child in el if _contains_block_level_tag child return Truereturn False
def _is_cluster_volume cluster_id ebs_volume if ebs_volume.tags is not None actual_cluster_id [tag['Value'] for tag in ebs_volume.tags if tag['Key'] CLUSTER_ID_LABEL ]if actual_cluster_id [actual_cluster_id] actual_cluster_idtry actual_cluster_id UUID hex actual_cluster_id except ValueError INVALID_FLOCKER_CLUSTER_ID flocker_cluster_id actual_cluster_id volume_id ebs_volume.id .write return Falseif actual_cluster_id cluster_id return Truereturn False
def rearrange_by_divisions df column divisions max_branch None shuffle None partitions df[column].map_partitions set_partitions_pre divisions divisions meta pd.Series [0] df2 df.assign _partitions partitions df3 rearrange_by_column df2 '_partitions' max_branch max_branch npartitions len divisions - 1 shuffle shuffle df4 df3.drop '_partitions' axis 1 df4 df3.map_partitions drop_columns '_partitions' df.columns.dtype return df4
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def search_relationship session instance relation filters None sort None group_by None model get_model instance related_model get_related_model model relation query session_query session related_model relationship getattr instance relation primary_keys set primary_key_value inst for inst in relationship if not primary_keys return query.filter FALSE query query.filter primary_key_value related_model .in_ primary_keys return search session related_model filters filters sort sort group_by group_by _initial_query query
def cluster_node_add node extra_args None cmd ['pcs' 'cluster' 'node' 'add']cmd + [node]if isinstance extra_args list tuple cmd + extra_argsreturn __salt__['cmd.run_all'] cmd output_loglevel 'trace' python_shell False
def delete_cache_security_group name region None key None keyid None profile None **args return _delete_resource name name_param 'CacheSecurityGroupName' desc 'cachesecuritygroup' res_type 'cache_security_group' region region key key keyid keyid profile profile **args
def fetch_stream_from_url url config data None handlers None return_code return_message response open_url url config data data handlers handlers if return_code and return_code http_client_.OK return responseelse raise URLFetchError return_message
def _check_for_changes entity_type ret existing modified ret['result'] Trueif isinstance existing dict and isinstance modified dict if 'generation' in modified['content'].keys del modified['content']['generation']if 'generation' in existing['content'].keys del existing['content']['generation']if cmp modified['content'] existing['content'] 0 ret['comment'] '{entity_type}iscurrentlyenforcedtothedesiredstate.Nochangesmade.'.format entity_type entity_type else ret['comment'] '{entity_type}wasenforcedtothedesiredstate.Note Onlyparametersspecifiedwereenforced.Seechangesfordetails.'.format entity_type entity_type ret['changes']['old'] existing['content']ret['changes']['new'] modified['content']elif cmp modified existing 0 ret['comment'] '{entity_type}iscurrentlyenforcedtothedesiredstate.Nochangesmade.'.format entity_type entity_type else ret['comment'] '{entity_type}wasenforcedtothedesiredstate.Note Onlyparametersspecifiedwereenforced.Seechangesfordetails.'.format entity_type entity_type ret['changes']['old'] existingret['changes']['new'] modifiedreturn ret
def tone freq 440 sec 2 rate 44100 vol 0.99 samples sec * rate time_steps np.arange 0.0 1.0 1.0 / samples scaling 2 * np.pi * freq * sec return np.sin time_steps * scaling * vol
def parse_cost_term source cost coeff parse_count source ch source.get if ch not in 'dis' raise ParseError if ch in cost raise error 'repeatedfuzzycost' source.string source.pos cost[ch] int coeff or 1
def getAndClear node nodeId result get node nodeId if result clearNode result return result
def make_service options def make_stub 'Helperfunctionformakingastubtotalktoservice.'credentials_path options.get 'credentials_path' None http httplib2.Http http apiclient.http.set_user_agent http 'SpinnakerStackdriverAgent/0.001' if credentials_path logging.info 'UsingStackdriverCredentialsfrom"%s"' credentials_path credentials ServiceAccountCredentials.from_json_keyfile_name credentials_path scopes StackdriverMetricsService.WRITE_SCOPE else logging.info 'UsingStackdriverCredentialsfromapplicationdefault.' credentials GoogleCredentials.get_application_default http credentials.authorize http return apiclient.discovery.build 'monitoring' 'v3' http http return StackdriverMetricsService make_stub options
def test_none_Constant o1 Constant NoneTypeT None name 'NoneConst' o2 Constant NoneTypeT None name 'NoneConst' assert o1.equals o2 assert NoneConst.equals o1 assert o1.equals NoneConst assert NoneConst.equals o2 assert o2.equals NoneConst import six.moves.cPickle as pickleimport theanofrom theano import tensorx tensor.vector 'x' y tensor.argmax x kwargs {}if theano.config.mode in ['DebugMode' 'DEBUG_MODE'] kwargs {'mode' 'FAST_RUN'}f theano.function [x] [y] **kwargs pickle.loads pickle.dumps f
def user_data_dir appname None appauthor None version None roaming False if system 'win32' if appauthor is None appauthor appnameconst roaming and 'CSIDL_APPDATA' or 'CSIDL_LOCAL_APPDATA' path os.path.normpath _get_win_folder const if appname if appauthor is not False path os.path.join path appauthor appname else path os.path.join path appname elif system 'darwin' path os.path.expanduser '~/Library/ApplicationSupport/' if appname path os.path.join path appname else path os.getenv 'XDG_DATA_HOME' os.path.expanduser '~/.local/share' if appname path os.path.join path appname if appname and version path os.path.join path version return path
def reshape_unchecked a shape strides raise NotImplementedError
def get_id_token params urllib.urlencode {'grant_type' 'urn ietf params oauth grant-type jwt-bearer' 'assertion' generate_jwt } headers {'Content-Type' 'application/x-www-form-urlencoded'}conn httplib.HTTPSConnection 'www.googleapis.com' conn.request 'POST' '/oauth2/v4/token' params headers res json.loads conn.getresponse .read conn.close return res['id_token']
def getFloatByPrefixSide defaultValue elementNode prefix side if elementNode None return defaultValueif side ! None key prefix + 'OverSide' if key in elementNode.attributes defaultValue euclidean.getFloatFromValue evaluate.getEvaluatedValueObliviously elementNode key * side return evaluate.getEvaluatedFloat defaultValue elementNode prefix
def test_monitoring_batch_size trainer yaml_parse.load test_yaml trainer.main_loop
def normcase s if not isinstance s bytes str raise TypeError "normcase argumentmustbestrorbytes not'{}'".format s.__class__.__name__ return s.replace _get_altsep s _get_sep s .lower
def test_lowercase_html dirty u'<EMCLASS "FOO">BAR</EM>'clean u'<emclass "FOO">BAR</em>'eq_ clean bleach.clean dirty attributes ['class']
@handle_response_format@treeio_login_required@module_admin_required def index_perspectives request response_format 'html' query _get_filter_query request.GET perspectives Perspective.objects.filter query .order_by 'name' filters FilterForm request.user.profile 'perspective' request.GET message request.session.pop 'message' '' return render_to_response 'core/administration/index_perspectives' {'perspectives' perspectives 'filters' filters 'message' message} context_instance RequestContext request response_format response_format
def unescape s assert isinstance s basestring s s.replace ' DCTB ' ' ' s s.replace '\\ ' ' ' s s.replace '\\n' '\n' s s.replace '\\\\' '\\' return s
def index_exists index hosts None profile None es _get_instance hosts profile try if not isinstance index list index [index]if es.indices.exists index index return Trueelse return Falseexcept elasticsearch.exceptions.NotFoundError return Noneexcept elasticsearch.exceptions.ConnectionError return Nonereturn None
def launch_arrayeditor data title '' xlabels None ylabels None dlg ArrayEditor assert dlg.setup_and_check data title xlabels xlabels ylabels ylabels dlg.show dlg.accept return dlg.get_value
def get_completion_badge course_id user from student.models import CourseEnrollmentbadge_classes CourseEnrollment.objects.filter user user course_id course_id .order_by '-is_active' if not badge_classes return Nonemode badge_classes[0].modecourse modulestore .get_course course_id if not course.issue_badges return Nonereturn BadgeClass.get_badge_class slug course_slug course_id mode issuing_component '' criteria criteria course_id description badge_description course mode course_id course_id mode mode display_name course.display_name image_file_handle CourseCompleteImageConfiguration.image_for_mode mode
def convert_md_to_rst md_path rst_temp_path command 'pandoc--write rst--output %s%s' % rst_temp_path md_path print 'convertingwithpandoc %sto%s\n-->%s' % md_path rst_temp_path command if os.path.exists rst_temp_path os.remove rst_temp_path os.system command if not os.path.exists rst_temp_path s 'Errorrunning %s\nDidyouinstallpandocperthe%sdocstring?' % command __file__ sys.exit s return read rst_temp_path
def execsitecustomize try import sitecustomizeexcept ImportError passexcept Exception if sys.flags.verbose sys.excepthook *sys.exc_info else print >>sys.stderr "'importsitecustomize'failed;use-vfortraceback"
def destroy instance_id call None if call 'function' raise SaltCloudSystemExit 'Thedestroyactionmustbecalledwith-d --destroy -aor--action.' instance_data show_instance instance_id call 'action' name instance_data['instance_name']__utils__['cloud.fire_event'] 'event' 'destroyinginstance' 'salt/cloud/{0}/destroying'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] params {'action' 'TerminateInstances' 'zone' _get_specified_zone provider get_configured_provider 'instances.1' instance_id}result query params __utils__['cloud.fire_event'] 'event' 'destroyedinstance' 'salt/cloud/{0}/destroyed'.format name args {'name' name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def snmp_wrapper a_device oid snmp_dict snmp_preprocessor a_device oid snmp_data snmp_get_oid_v3 **snmp_dict return snmp_extract snmp_data
def closing_tag state text i formats user_data ch text[i]if ch in space_chars return [ 1 None ]pos text.find u'>' i if pos -1 return [ len text - i formats[u'bad-closing'] ]state.parse NORMALnum pos - i + 1 ans [ 1 formats[u'end_tag'] ]if num > 1 ans.insert 0 num - 1 formats[u'bad-closing'] add_tag_data user_data TagEnd pos False False return ans
def delay delay callback *args **kwargs return reactor.callLater delay callback *args **kwargs
def _make_key args kwds typed kwd_mark object fasttypes set int str frozenset type None sorted sorted tuple tuple type type len len key argsif kwds sorted_items sorted kwds.items key + kwd_markfor item in sorted_items key + itemif typed key + tuple type v for v in args if kwds key + tuple type v for k v in sorted_items elif len key 1 and type key[0] in fasttypes return key[0]return _HashedSeq key
@ship.command 'new' @click.argument 'name' def ship_new name click.echo 'Createdship%s' % name
def getComplexByCommaString valueCommaString try splitLine valueCommaString.replace ' ' '' .split return complex float splitLine[0] float splitLine[1] except passreturn None
def util from pants.backend.docgen.tasks import markdown_to_html_utilsreturn markdown_to_html_utils
def copy_asset source destination excluded lambda path False context None renderer None if not os.path.exists source returnensuredir destination if os.path.isfile source copy_asset_file source destination context renderer returnfor root dirs files in walk source reldir relative_path source root for dir in dirs[ ] if excluded posixpath.join reldir dir dirs.remove dir else ensuredir posixpath.join destination reldir dir for filename in files if not excluded posixpath.join reldir filename copy_asset_file posixpath.join root filename posixpath.join destination reldir context renderer
def default_connection_selector connection app_blame return handlers.BaseConnectionHandler
@blueprint.route '/<job_id>.json' methods ['GET'] @blueprint.route '/<job_id>' methods ['GET'] def show job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' related_jobs scheduler.get_related_jobs job if request_wants_json return flask.jsonify job.json_dict True elif isinstance job model_images.ImageClassificationModelJob return model_images.classification.views.show job related_jobs related_jobs elif isinstance job model_images.GenericImageModelJob return model_images.generic.views.show job related_jobs related_jobs else raise werkzeug.exceptions.BadRequest 'Invalidjobtype'
def test_scenario_sentences_can_be_solved scenario Scenario.from_string OUTLINED_SCENARIO assert_equals len scenario.solved_steps 12 expected_sentences ['GivenIhaveentered20intothecalculator' 'AndIhaveentered30intothecalculator' 'WhenIpressadd' 'Thentheresultshouldbe50onthescreen' 'GivenIhaveentered2intothecalculator' 'AndIhaveentered5intothecalculator' 'WhenIpressadd' 'Thentheresultshouldbe7onthescreen' 'GivenIhaveentered0intothecalculator' 'AndIhaveentered40intothecalculator' 'WhenIpressadd' 'Thentheresultshouldbe40onthescreen']for step expected_sentence in zip scenario.solved_steps expected_sentences assert_equals type step Step assert_equals step.sentence expected_sentence
def save_workbook workbook filename writer ExcelWriter workbook writer.save filename return True
def remove_comments css iemac Falsepreserve Falsecomment_start css.find '/*' while comment_start > 0 preserve css[ comment_start + 2 comment_start + 3 ] '!' comment_end css.find '*/' comment_start + 2 if comment_end < 0 if not preserve css css[ comment_start]breakelif comment_end > comment_start + 2 if css[ comment_end - 1 ] '\\' comment_start comment_end + 2 iemac Trueelif iemac comment_start comment_end + 2 iemac Falseelif not preserve css css[ comment_start] + css[ comment_end + 2 ] else comment_start comment_end + 2 comment_start css.find '/*' comment_start return css
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
def add_toolbar_item_for_plugins toolbar_action global TOOLBAR_ITEMS_PLUGINSTOOLBAR_ITEMS_PLUGINS.append toolbar_action
def _onResize width height if height 0 height 1GL.glViewport 0 0 width height GL.glMatrixMode GL.GL_PROJECTION GL.glLoadIdentity GL.glOrtho -1 1 -1 1 -1 1 GL.glMatrixMode GL.GL_MODELVIEW GL.glLoadIdentity
def ieerstr2tree s chunk_types [u'LOCATION' u'ORGANIZATION' u'PERSON' u'DURATION' u'DATE' u'CARDINAL' u'PERCENT' u'MONEY' u'MEASURE'] root_label u'S' m _IEER_DOC_RE.match s if m return {u'text' _ieer_read_text m.group u'text' root_label u'docno' m.group u'docno' u'doctype' m.group u'doctype' u'date_time' m.group u'date_time' u'headline' _ieer_read_text m.group u'headline' root_label }else return _ieer_read_text s root_label
def format_exc limit None try etype value tb sys.exc_info return ''.join format_exception etype value tb limit finally etype value tb None
def pos_tag tokens tagset None lang 'eng' tagger _get_tagger lang return _pos_tag tokens tagset tagger
def _allocations_dict allocations key_fetcher resource_provider None allocation_data collections.defaultdict dict for allocation in allocations key key_fetcher allocation if 'resources' not in allocation_data[key] allocation_data[key]['resources'] {}resource_class allocation.resource_classallocation_data[key]['resources'][resource_class] allocation.usedif not resource_provider generation allocation.resource_provider.generationallocation_data[key]['generation'] generationresult {'allocations' allocation_data}if resource_provider result['resource_provider_generation'] resource_provider.generationreturn result
def get_issues project 'statsmodels/statsmodels' state 'closed' pulls False which 'pulls' if pulls else 'issues' url 'https //api.github.com/repos/%s/%s?state %s&per_page %i' % project which state PER_PAGE return get_paged_request url headers make_auth_header
def dict_to_packet_out d po of.ofp_packet_out po.buffer_id d.get 'buffer_id' -1 po.in_port _fix_of_int d.get 'in_port' of.OFPP_NONE actions d.get 'actions' [] actions [dict_to_action a for a in actions]po.actions actionsif 'output' in d a of.ofp_action_output port _fix_of_int d['output'] po.actions.append a if 'data' in d data dict_to_packet d['data'] if hasattr data 'pack' data data.pack po.data datareturn po
@jit nopython True cache True def lemke_howson_tbl tableaux bases init_pivot max_iter init_player 0for k in bases[0] if k init_pivot init_player 1breakpls [init_player 1 - init_player ]pivot init_pivot m n tableaux[1].shape[0] tableaux[0].shape[0] slack_starts m 0 argmins np.empty max m n dtype np.int_ converged Falsenum_iter 0while True for pl in pls row_min lex_min_ratio_test tableaux[pl] pivot slack_starts[pl] argmins pivoting tableaux[pl] pivot row_min bases[pl][row_min] pivot pivot bases[pl][row_min] num_iter + 1if pivot init_pivot converged Truebreakif num_iter > max_iter breakelse continuebreakreturn converged num_iter
def snapshot_created name ami_name instance_name wait_until_available True wait_timeout_seconds 300 **kwargs ret {'name' name 'result' True 'comment' '' 'changes' {}}if not __salt__['boto_ec2.create_image'] ami_name ami_name instance_name instance_name **kwargs ret['comment'] 'FailedtocreatenewAMI{ami_name}'.format ami_name ami_name ret['result'] Falsereturn retret['comment'] 'CreatednewAMI{ami_name}'.format ami_name ami_name ret['changes']['new'] {ami_name ami_name}if not wait_until_available return retstarttime time while True images __salt__['boto_ec2.find_images'] ami_name ami_name return_objs True **kwargs if images and images[0].state 'available' breakif time - starttime > wait_timeout_seconds if images ret['comment'] 'AMIstillinstate{state}aftertimeout'.format state images[0].state else ret['comment'] 'AMIwithname{ami_name}notfoundaftertimeout.'.format ami_name ami_name ret['result'] Falsereturn retsleep 5 return ret
def get_client_login_token http_body return gdata.gauth.get_client_login_token_string http_body
def generate_yml filename specs def _to_builtin elements 'Recursivelyconvertelementstobuilt-intypes'result []for e in elements if isinstance e ebml.MasterElement result.append e.id e.type e.name e.level e.position e.size _to_builtin e.data else result.append e.id e.type e.name e.level e.position e.size None if isinstance e.data io.BytesIO else e.data return resultvideo io.open os.path.join TEST_DIR filename 'rb' yml io.open os.path.join EBML_VALIDATION_DIR filename + '.yml' 'w' yaml.safe_dump _to_builtin ebml.parse video specs yml
def bucket_url suffix return 'gs //{}/{}/{}'.format BUCKET_NAME TEST_FOLDER suffix
def verify_log opts level LOG_LEVELS.get str opts.get 'log_level' .lower logging.NOTSET if level < logging.INFO log.warning 'Insecureloggingconfigurationdetected!Sensitivedatamaybelogged.'
def name_match match skey get_key __opts__ return skey.name_match match
def AsValidator validator if isinstance validator str unicode return Regex validator type validator if isinstance validator type return Type validator if isinstance validator list tuple set return Options *tuple validator if isinstance validator Validator return validatorelse raise AttributeDefinitionError '%sisnotavalidvalidator' % str validator
def multipart_byteranges_to_document_iters input_file boundary read_chunk_size 4096 for headers body in mime_to_document_iters input_file boundary read_chunk_size first_byte last_byte length parse_content_range headers.get 'content-range' yield first_byte last_byte length headers.items body
def ll actual predicted actual np.array actual predicted np.array predicted err np.seterr all 'ignore' score - actual * np.log predicted + 1 - actual * np.log 1 - predicted np.seterr divide err['divide'] over err['over'] under err['under'] invalid err['invalid'] if type score np.ndarray score[np.isnan score ] 0elif np.isnan score score 0return score
def get_cflags return get_var 'CFLAGS'
def check_executable executable logger logging.getLogger __name__ logger.debug "Checkingexecutable'%s'..." executable executable_path find_executable executable found executable_path is not None if found logger.debug "Executable'%s'found '%s'" executable executable_path else logger.debug "Executable'%s'notfound" executable return found
def libvlc_event_type_name event_type f _Cfunctions.get 'libvlc_event_type_name' None or _Cfunction 'libvlc_event_type_name' 1 None ctypes.c_char_p ctypes.c_uint return f event_type
def update_credential tenant_id credential_id new_user_name None new_password None session db.get_session try cred session.query network_models_v2.Credential .filter_by tenant_id tenant_id .filter_by credential_id credential_id .one if new_user_name cred['user_name'] new_user_nameif new_password cred['password'] new_passwordsession.merge cred session.flush return credexcept exc.NoResultFound raise c_exc.CredentialNotFound credential_id credential_id tenant_id tenant_id
def find_related_module package related_name try importlib.import_module package except ImportError package _ _ package.rpartition u'.' if not package raisetry pkg_path importlib.import_module package .__path__except AttributeError returntry _imp.find_module related_name pkg_path except ImportError returnreturn importlib.import_module u'{0}.{1}'.format package related_name
def IndexesXmlToIndexDefinitions xml_str parser IndexesXmlParser return parser.Parse xml_str
def set_werkzeug_log_color from django.core.management.color import color_stylefrom werkzeug.serving import WSGIRequestHandlerfrom werkzeug._internal import _log_style color_style _orig_log WSGIRequestHandler.logdef werk_log self type message *args try msg '%s--[%s]%s' % self.address_string self.log_date_time_string message % args http_code str args[1] except return _orig_log type message *args if http_code[0] '2' msg _style.HTTP_SUCCESS msg elif http_code[0] '1' msg _style.HTTP_INFO msg elif http_code '304' msg _style.HTTP_NOT_MODIFIED msg elif http_code[0] '3' msg _style.HTTP_REDIRECT msg elif http_code '404' msg _style.HTTP_NOT_FOUND msg elif http_code[0] '4' msg _style.HTTP_BAD_REQUEST msg else msg _style.HTTP_SERVER_ERROR msg _log type msg WSGIRequestHandler.log werk_log
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def filter_koan_names lines for line in lines line line.strip if line.startswith '#' continueif line yield line return
def start_introspection_server global INTROSPECTION_SERVERif INTROSPECTION_SERVER is None if DEBUG_INTROSPECTION import timetime_str 'Loggingtime %s' % time.ctime time.time logging.debug ' ' * len time_str logging.debug time_str logging.debug ' ' * len time_str INTROSPECTION_SERVER IntrospectionServer INTROSPECTION_SERVER.start return INTROSPECTION_SERVER
def certbot_version build_script_dir return re.search '^__version__ [\'"] .+ [\'"].*' file_contents join dirname build_script_dir 'certbot' '__init__.py' re.M .group 1
def has_valid_signature method headers_dict body_dict access_key secret_key _ expected_signature _ generate_signed_message method headers_dict body_dict access_key secret_key authorization headers_dict['Authorization'] auth_token post_signature authorization.split ' ' _ post_access_key auth_token.split if post_access_key ! access_key log.error 'Postedaccesskeydoesnotmatchours' log.debug 'Theiraccess %s;Ouraccess %s' post_access_key access_key return Falseif post_signature ! expected_signature log.error 'Postedsignaturedoesnotmatchexpected' log.debug 'Theirsig %s;Expected %s' post_signature expected_signature return Falsereturn True
def delete_from_backend context uri **kwargs loc location.get_location_from_uri uri store get_store_from_uri context uri loc try return store.delete loc except NotImplementedError raise exception.StoreDeleteNotSupported
def next_power_of_2 n n - 1shift 1while n + 1 & n n | n >> shift shift * 2return max 4 n + 1
def _import module reload 'False' from sympy.external import import_moduletry namespace namespace_default translations import_commands MODULES[module]except KeyError raise NameError "'%s'modulecan'tbeusedforlambdification" % module if namespace ! namespace_default if reload namespace.clear namespace.update namespace_default else returnfor import_command in import_commands if import_command.startswith 'import_module' module eval import_command if module is not None namespace.update module.__dict__ continueelse try exec_ import_command {} namespace continueexcept ImportError passraise ImportError "can'timport'%s'with'%s'command" % module import_command for sympyname translation in translations.items namespace[sympyname] namespace[translation]if 'Abs' not in namespace namespace['Abs'] abs
def copy_sample_files app sample_files tool_path None sample_files_copied None dest_path None filenames_not_to_copy ['tool_data_table_conf.xml.sample']sample_files_copied util.listify sample_files_copied for filename in sample_files filename_sans_path os.path.split filename [1]if filename_sans_path not in filenames_not_to_copy and filename not in sample_files_copied if tool_path filename os.path.join tool_path filename if is_data_index_sample_file filename copy_sample_file app filename dest_path dest_path
def sanitize_for_filename text default None out []for c in text if c in valid_filename_chars out.append c else out.append '_' out ''.join out if out in invalid_filenames if default is None return sanitize_for_filename str unique_id return defaultreturn out
def _make_path *parts return u'/' + u'/'.join quote_plus _escape p ' *' for p in parts if p not in SKIP_IN_PATH
def _parse url defaultPort None url url.strip parsed http.urlparse url scheme parsed[0]path urlunparse '' '' + parsed[2 ] if defaultPort is None if scheme 'https' defaultPort 443else defaultPort 80 host port parsed[1] defaultPort if ' ' in host host port host.split ' ' try port int port except ValueError port defaultPortif path '' path '/'return scheme host port path
def fix_route53_ids params model **kwargs input_shape model.input_shapeif not input_shape or not hasattr input_shape 'members' returnmembers [name for name shape in input_shape.members.items if shape.name in ['ResourceId' 'DelegationSetId'] ]for name in members if name in params orig_value params[name]params[name] orig_value.split '/' [ -1 ]logger.debug '%s%s->%s' name orig_value params[name]
def input_thread log stdin is_alive quit close_before_term done Falseclosed Falsealive Truewriters [stdin]while writers and alive _ to_write _ select.select [] writers [] 1 if to_write log.debug '%rreadyformoreinput' stdin done stdin.write if done writers []if close_before_term stdin.close closed True alive _ is_alive while alive quit.wait 1 alive _ is_alive if not closed stdin.close
def sector def prep r s3db.gis_location_filter r return Trues3.prep prepreturn s3_rest_controller
def getRotateMatrixTetragrid prefix xmlElement rotateMatrix Matrix zAngle getRemovedFloatByKeys ['axisclockwisez' 'observerclockwisez' 'z'] prefix xmlElement zAngle - getRemovedFloatByKeys ['axiscounterclockwisez' 'observercounterclockwisez'] prefix xmlElement if zAngle ! 0.0 rotateMatrix.matrixTetragrid rotateMatrix.getOtherTimesSelf getDiagonalSwitchedTetragrid - zAngle [0 1] .matrixTetragridxAngle getRemovedFloatByKeys ['axisclockwisex' 'observerclockwisex' 'x'] prefix xmlElement xAngle - getRemovedFloatByKeys ['axiscounterclockwisex' 'observercounterclockwisex'] prefix xmlElement if xAngle ! 0.0 rotateMatrix.matrixTetragrid rotateMatrix.getOtherTimesSelf getDiagonalSwitchedTetragrid - xAngle [1 2] .matrixTetragridyAngle getRemovedFloatByKeys ['axiscounterclockwisey' 'observerclockwisey' 'y'] prefix xmlElement yAngle - getRemovedFloatByKeys ['axisclockwisey' 'observercounterclockwisey'] prefix xmlElement if yAngle ! 0.0 rotateMatrix.matrixTetragrid rotateMatrix.getOtherTimesSelf getDiagonalSwitchedTetragrid yAngle [0 2] .matrixTetragridreturn rotateMatrix.matrixTetragrid
def speed_elemwise_collapse2 shape 30 40 50 600 a cuda_ndarray.CudaNdarray theano._asarray numpy.random.rand *shape dtype 'float32' a theano._asarray numpy.random.rand *shape dtype 'float32' a2 tcn.shared_constructor a 'a' a3 a2[ 2]b tcn.CudaNdarrayType False False False False c a3 + b * tensor.exp 1 + b ** a3 f pfunc [b] [c] mode mode_with_gpu v theano._asarray numpy.random.rand *shape dtype 'float32' v v[ 2]v cuda_ndarray.CudaNdarray v time.time for i in range 100 f v time.time
def multidict ordered_pairs d defaultdict list for k v in ordered_pairs d[k].append v for k v in d.items if len v 1 d[k] v[0]return dict d
@env.catch_exceptionsdef reload_changes changes resources changes.get_changed_resources moved _get_moved_resources changes current env.curbuf.numberfor f in resources bufnr env.var 'bufnr "%s" ' % f.real_path env.goto_buffer bufnr path env.curbuf.nameif f in moved path moved[f].real_pathenv.debug 'Reload' f.real_path path bufnr env.goto_file path 'e!' force True env.message '%shasbeenchanged.' % f.real_path history True env.goto_buffer current
def whitespace_around_named_parameter_equals logical_line tokens parens 0no_space Falseprev_end Nonemessage 'E251unexpectedspacesaroundkeyword/parameterequals'for token_type text start end line in tokens if no_space no_space Falseif start ! prev_end yield prev_end message elif token_type tokenize.OP if text ' ' parens + 1elif text ' ' parens - 1elif parens and text ' ' no_space Trueif start ! prev_end yield prev_end message prev_end end
def file_upload_view_verify request form_data request.POST.copy form_data.update request.FILES for key value in form_data.items if key.endswith '_hash' continueif key + '_hash' not in form_data continuesubmitted_hash form_data[ key + '_hash' ]if isinstance value UploadedFile new_hash hashlib.sha1 value.read .hexdigest else new_hash hashlib.sha1 value .hexdigest if new_hash ! submitted_hash return HttpResponseServerError largefile request.FILES['file_field2']obj FileModel obj.testfile.save largefile.name largefile return HttpResponse ''
@CELERY_APP.taskdef send_ccx_course_published course_key course_key CourseLocator.from_string course_key for ccx in CustomCourseForEdX.objects.filter course_id course_key try ccx_key CCXLocator.from_course_locator course_key unicode ccx.id except InvalidKeyError log.info 'Attempttopublishcoursewithdeprecatedid.Course %s.CCX %s' course_key ccx.id continueresponses SignalHandler.course_published.send sender ccx course_key ccx_key for rec response in responses log.info 'Signalfiredwhencourseispublished.Receiver %s.Response %s' rec response
def list_first rs return rs[0] if len rs 1 else None
def set_template path template context defaults saltenv 'base' **kwargs path __salt__['cp.get_template'] path path dest None template template saltenv saltenv context context defaults defaults **kwargs return set_file path saltenv **kwargs
def console_pool_get_all_by_host_type context host console_type return IMPL.console_pool_get_all_by_host_type context host console_type
def retry jenkins_session url params print 'Retrying{}'.format url if params jenkins_session.post url + '/buildWithParameters' data params else jenkins_session.post url + '/build'
def creates_models model def decorated func @wraps func @writes_models model def wrapped data field if field raise NotImplementedError 'Mustusethewrites_modelsdecoratortoupdatemodels' return func data return decorated
def parse_token_stream stream soft_delimiter hard_delimiter return [[sum len token for token in sentence_it for sentence_it in split_at block_it soft_delimiter ] for block_it in split_at stream hard_delimiter ]
def validate_api_key_and_source api_key_in_headers api_key_query_params if not api_key_in_headers and not api_key_query_params LOG.audit 'APIkeyisnotfoundinheaderorqueryparameters.' raise exceptions.ApiKeyNotProvidedError 'APIkeyisnotprovided.' if api_key_in_headers LOG.audit 'APIkeyprovidedinheaders' if api_key_query_params LOG.audit 'APIkeyprovidedinqueryparameters' return validate_api_key api_key_in_headers or api_key_query_params
def is_process_started_by_superserver result Falsestdin_fd sys.__stdin__.fileno if is_socket stdin_fd result Truereturn result
def wrap_rolling func method_name @wraps func def rolling arg window *args **kwargs warnings.warn 'DeprecationWarning dd.rolling_{0}isdeprecatedandwillberemovedinafutureversion replacewithdf.rolling ... .{0} ... '.format method_name rolling_kwargs {}method_kwargs {}for k v in kwargs.items if k in {'min_periods' 'center' 'win_type' 'axis' 'freq'} rolling_kwargs[k] velse method_kwargs[k] vrolling arg.rolling window **rolling_kwargs return getattr rolling method_name *args **method_kwargs return rolling
def _create_eeg_els chs return [_create_eeg_el ch for ch in chs]
def step_1c w if len w > 2 and w.endswith 'y' 'Y' and is_consonant w[ -2 ] return w[ -1 ] + 'i' return w
def rotate_dimensions num_dims src_dim dest_dim dim_list range num_dims step 1 if dest_dim > src_dim else -1 for x in xrange src_dim dest_dim step dim_list[x] dim_list[ x + step ] dim_list[ x + step ] dim_list[x] return dim_list
def test_bootstrap_units data rs.randn 50 ids np.repeat range 10 5 bwerr rs.normal 0 2 10 bwerr bwerr[ids]data_rm data + bwerr seed 77boots_orig algo.bootstrap data_rm random_seed seed boots_rm algo.bootstrap data_rm units ids random_seed seed nose.tools.assert_greater boots_rm.std boots_orig.std
def ConvertStringsToColumnHeaders proposed_headers headers []for input_string in proposed_headers sanitized input_string.lower .replace '_' '' .replace ' ' '' .replace '' '' header_count headers.count sanitized if header_count > 0 headers.append '%s_%i' % sanitized header_count + 1 else headers.append sanitized return headers
def ftp_publisher registry xml_parent data ftp XML.SubElement xml_parent 'com.zanox.hudson.plugins.FTPPublisher' ftp.set 'plugin' 'ftppublisher' entries XML.SubElement ftp 'entries' if 'uploads' in data upload_mapping [ 'file-path' 'filePath' '' 'source-file' 'sourceFile' '' ]for upload in data['uploads'] entry XML.SubElement entries 'com.zanox.hudson.plugins.Entry' helpers.convert_mapping_to_xml entry upload upload_mapping fail_required True mapping [ 'site-name' 'siteName' None 'use-timestamps' 'useTimestamps' False 'flatten-files' 'flatten' False 'skip-publishing' 'skip' False ]helpers.convert_mapping_to_xml ftp data mapping fail_required True
def common_instructions profile if has_pairs profile and profile inst_list profile[ -1 ]else inst_list profileresult [ op opcode.opname[op] count for op count in enumerate inst_list if count > 0 ]result.sort key operator.itemgetter 2 reverse True return result
def prlctl sub_cmd args None runas None cmd ['prlctl' sub_cmd]if args cmd.extend _normalize_args args return __salt__['cmd.run'] cmd runas runas
def webapi_token_deleted_cb instance **kwargs mail_webapi_token instance u'deleted'
def normalize b a num den b a den np.atleast_1d den num np.atleast_2d _align_nums num if den.ndim ! 1 raise ValueError 'Denominatorpolynomialmustberank-1array.' if num.ndim > 2 raise ValueError 'Numeratorpolynomialmustberank-1orrank-2array.' if np.all den 0 raise ValueError 'Denominatormusthaveatleastonnonzeroelement.' den np.trim_zeros den 'f' num den num / den[0] den / den[0] leading_zeros 0for col in num.T if np.allclose col 0 atol 1e-14 leading_zeros + 1else breakif leading_zeros > 0 warnings.warn 'Badlyconditionedfiltercoefficients numerator theresultsmaybemeaningless' BadCoefficients if leading_zeros num.shape[1] leading_zeros - 1num num[ leading_zeros ]if num.shape[0] 1 num num[0 ]return num den
def askdirectory **options return apply DirectoryBrowser options .show
def proceed request if request.user.is_authenticated return submit request agreement_form forms.DevAgreementForm {'read_dev_agreement' True} instance None request request return render request 'submit/terms.html' {'step' 'terms' 'agreement_form' agreement_form 'proceed' True}
def Cache fn def fnCache *args **kwargs 'Cachefunction'key args and tuple args or None kwargs and frozenset kwargs.items or None if key not in fn.__cached__ fn.__cached__[key] cache fn *args **kwargs else cache fn.__cached__[key]return cachedef ResetCache 'Resetcache'fn.__cached__ {}setattr fn '__cached__' {} setattr fn '__resetcache__' ResetCache fnCache.__name__ fn.__name__fnCache.__doc__ fn.__doc__fnCache.__dict__.update fn.__dict__ return fnCache
def _format_plugin_info_table info_table column_lengths info_table.insert 0 _separator ' ' column_lengths info_table.insert 1 'Plugin' 'Description' info_table.insert 2 _separator '-' column_lengths info_table.append _separator ' ' column_lengths
def get_local_addresses_async target '198.41.0.4' addresses []local_ip get_local_ip_for target if local_ip addresses.append local_ip if sys.platform 'cygwin' d _cygwin_hack_find_addresses target else d _find_addresses_via_config def _collect res for addr in res if addr ! '0.0.0.0' and not addr in addresses addresses.append addr return addressesd.addCallback _collect return d
def inplace_column_scale X scale if isinstance X sp.csc_matrix inplace_csr_row_scale X.T scale elif isinstance X sp.csr_matrix inplace_csr_column_scale X scale else _raise_typeerror X
def _build_convergence_loop_table I ConvergenceLoopInputsO ConvergenceLoopOutputsS ConvergenceLoopStatestable TransitionTable table table.addTransition S.STOPPED I.STATUS_UPDATE [O.STORE_INFO O.CONVERGE] S.CONVERGING table table.addTransitions S.CONVERGING {I.STATUS_UPDATE [O.STORE_INFO] S.CONVERGING I.STOP [] S.CONVERGING_STOPPING I.SLEEP [O.SCHEDULE_WAKEUP] S.SLEEPING } table table.addTransitions S.CONVERGING_STOPPING {I.STATUS_UPDATE [O.STORE_INFO] S.CONVERGING I.SLEEP [] S.STOPPED } table table.addTransitions S.SLEEPING {I.WAKEUP [O.CLEAR_WAKEUP O.CONVERGE] S.CONVERGING I.STOP [O.CLEAR_WAKEUP] S.STOPPED I.STATUS_UPDATE [O.STORE_INFO O.UPDATE_MAYBE_WAKEUP] S.SLEEPING } return table
def arctan x return Arctan x
def isplit string sep ' DCTB \n\x0b\x0c\r' a []for ch in string if ch not in sep a.append ch continueif a yield ''.join a a []if a yield ''.join a
def htsafe text text smart_unicode text safe_string smart_unicode sanitizer.clean_html text return Markup safe_string
def apply_matches d some_map list d.values [0]keys some_map.keys if 'tag' in keys and not equal_fields d 'tag' returnif 'artist' in keys if equal_fields d 'artist' artist some_map['artist']title_field 'title'elif equal_fields d 'title' artist some_map['title']title_field 'artist'else returnfor item in d if not item.artist item.artist artistelse title_field 'title'for item in d if bad_title item.title item.title six.text_type d[item][title_field] if 'track' in d[item] and item.track 0 item.track int d[item]['track']
@image_comparison baseline_images [u'EventCollection_plot__default'] def test__EventCollection__get_segments _ coll props generate_EventCollection_plot check_segments coll props[u'positions'] props[u'linelength'] props[u'lineoffset'] props[u'orientation']
def _default_response_times A n vals linalg.eigvals A r min abs real vals if r 0.0 r 1.0tc 1.0 / r t linspace 0.0 7 * tc n return t
def bottom_up_once rule fns basic_fns return do_one lambda expr sall bottom_up rule fns fns expr rule
def get_entity_key prefix pb return dbconstants.KEY_DELIMITER.join [prefix str encode_index_pb pb ]
def detachNBD nbd srun 'qemu-nbd-d' + nbd
def wait_until_condition browser condition timeout 10 frequency 1.0 WebDriverWait browser.driver timeout timeout poll_frequency frequency ignored_exceptions ElementNotVisibleException StaleElementReferenceException .until lambda x condition browser
def test_ast_good_lambda can_compile u' lambda[] ' can_compile u' lambda[]1 '
def _is_number_geographical numobj num_type number_type numobj return num_type PhoneNumberType.FIXED_LINE or num_type PhoneNumberType.FIXED_LINE_OR_MOBILE or numobj.country_code in _GEO_MOBILE_COUNTRIES and num_type PhoneNumberType.MOBILE
def FindRendererForObject rdf_obj return ValueRenderer rdf_obj
def setLoggerClass loggingClass assert issubclass loggingClass ILogger 'loggingClassmustsubclassILogger'global _LoggerClass_LoggerClass loggingClass
def _can_be_internationally_dialled numobj metadata PhoneMetadata.metadata_for_region region_code_for_number numobj None if metadata is None return Truensn national_significant_number numobj return not _is_number_matching_desc nsn metadata.no_international_dialling
def parse_graphml graphml_string node_type str reader GraphMLReader node_type node_type glist list reader string graphml_string return glist[0]
def unmountvolume volume putaway volume
def convert_timedelta obj if not PY2 and isinstance obj bytes bytearray obj obj.decode 'ascii' m TIMEDELTA_RE.match obj if not m return Nonetry groups list m.groups groups[ -1 ] _convert_second_fraction groups[ -1 ] negate -1 if groups[0] else 1 hours minutes seconds microseconds groups[1 ]tdelta datetime.timedelta hours int hours minutes int minutes seconds int seconds microseconds int microseconds * negate return tdeltaexcept ValueError return None
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def time_openpyxl_optimised start_time clock workbook openpyxl.workbook.Workbook optimized_write True worksheet workbook.create_sheet for row in range row_max // 2 string_data [ 'Row %dCol %d' % row col for col in range col_max ]worksheet.append string_data num_data [ row + col for col in range col_max ]worksheet.append num_data workbook.save 'openpyxl_opt.xlsx' elapsed clock - start_time print_elapsed_time 'openpyxl optimised ' elapsed
def disassociate_qos_specs context specs_id type_id try get_qos_specs context specs_id db.qos_specs_disassociate context specs_id type_id except db_exc.DBError LOG.exception _LE 'DBerror ' LOG.warning _LW 'Failedtodisassociateqosspecs% id swithtype % vol_type_id s' dict id specs_id vol_type_id type_id raise exception.QoSSpecsDisassociateFailed specs_id specs_id type_id type_id
def _search_param_in_docstr docstr param_str patterns [re.compile p % re.escape param_str for p in DOCSTRING_PARAM_PATTERNS]found Nonefor pattern in patterns match pattern.search docstr if match found [_strip_rst_role match.group 1 ]breakif found is not None return foundfound _search_param_in_numpydocstr docstr param_str if found is not None return foundreturn []
def test_add_to_end a dedent '\nclassAbc \ndefabc self \nself.x 3\n\nclassTwo Abc \ndefh self \nself\n' b 'defg self \nself.'assert jedi.Script a 8 12 'example.py' .completions assert jedi.Script a + b path 'example.py' .completions a a[ -1 ] + '.\n' assert jedi.Script a 8 13 'example.py' .completions assert jedi.Script a + b path 'example.py' .completions
def CheckedEval file_contents ast compiler.parse file_contents assert isinstance ast Module c1 ast.getChildren assert c1[0] is None assert isinstance c1[1] Stmt c2 c1[1].getChildren assert isinstance c2[0] Discard c3 c2[0].getChildren assert len c3 1 return CheckNode c3[0] []
def d3write fct path *args **kwargs formatter PyDotFormatter *args **kwargs graph formatter fct graph.write_dot path
def bit_length intval assert isinstance intval INT_TYPES if intval > 0 return len bin intval - 2 else return len bin - intval - 1 - 2
def execute_string buf **kw fp StringIO buf kw['source'] ['<stringbuffer>']if not kw.has_key 'no_reset' kw['no_reset'] True_execute_script fp **kw
def odnoklassniki_oauth_sig data client_secret suffix md5 '{0 s}{1 s}'.format data['access_token'] client_secret .encode 'utf-8' .hexdigest check_list sorted ['{0 s} {1 s}'.format key value for key value in data.items if key ! 'access_token' ] return md5 ''.join check_list + suffix .encode 'utf-8' .hexdigest
def _process_os_dirs starting_dir template_linters options summary_results out for root dirs files in os.walk starting_dir if is_skip_dir SKIP_DIRS root del dirscontinuedirs.sort key lambda s s.lower _process_os_dir root files template_linters options summary_results out
def build_path_result_tests name return build_schema_test name str name + u'Tests' schema {u'$ref' u'/endpoints.json#/definitions/' + name } schema_store SCHEMAS failing_instances {'additionalProperties' [{u'Err' u'' u'Mountpoint' u'/x' u'extra' u'y'} {u'Result' u'hello'}] 'required' [{} {u'Mountpoint' u'/x'}] 'type' [[] u'' None]} passing_instances [{u'Err' u'Somethingwentwrong.'} {u'Err' u'' u'Mountpoint' u'/x/'}]
def unregister_auth_backend backend_cls warn u'reviewboard.accounts.backends.unregister_auth_backend isdeprecated.Usereviewboard.accounts.backends.auth_backends.unregister instead.' DeprecationWarning auth_backends.unregister backend_cls
def truncate_title title if not title return _ u' none ' if len title > 25 return u'%s...' % title[ 22] return title
def _compare_acl current desired region key keyid profile ocid _get_canonical_id region key keyid profile return __utils__['boto3.json_objs_equal'] current _acl_to_grant desired ocid
def _import_db engine SQLITE global MySQLdbglobal sqliteif engine MYSQL import MySQLdbwarnings.simplefilter 'ignore' MySQLdb.Warning if engine SQLITE try import sqlite3.dbapi2 as sqliteexcept import pysqlite2.dbapi2 as sqlite
def pairs item_list for i item1 in enumerate item_list for item2 in item_list[ i + 1 ] yield item1 item2
def pretty_match match string underline_char '^' start match.start end match.end string _LINE_RGX.sub linesep string start_line_pos string.rfind linesep 0 start if start_line_pos -1 start_line_pos 0result []else result [string[ start_line_pos]]start_line_pos + len linesep offset start - start_line_pos underline '' * offset + underline_char * end - start end_line_pos string.find linesep end if end_line_pos -1 string string[start_line_pos ]result.append string result.append underline else end string[ end_line_pos + len linesep ]string string[start_line_pos end_line_pos]result.append string result.append underline result.append end return linesep.join result .rstrip
def _print_hat _self expr return '\\hat{%s}' % str expr.args[0] .lower
def moduleMovedForSplit origModuleName newModuleName moduleDesc projectName projectURL globDict warnings.warn 'moduleMovedForSplitisdeprecatedsinceTwisted9.0.' DeprecationWarning stacklevel 2
def _save_nodes workflow nodes for node in nodes if node.node_type is 'kill' continuetry Node.objects.get workflow workflow node_type node.node_type name node.name except Node.DoesNotExist node.save
def p_optend p if len p 2 p[0] p[1]else p[0] None
def initial_has_dependencies tree to_process has_dependencies []for n in tree.nontips include_self True if n not in to_process has_dependencies.append n return has_dependencies
def mark_safe s if isinstance s SafeData return sif isinstance s str or isinstance s Promise and s._delegate_str return SafeString s if isinstance s unicode Promise return SafeUnicode s return SafeString str s
def uuid4 if _uuid_generate_random _buffer ctypes.create_string_buffer 16 _uuid_generate_random _buffer return UUID bytes _buffer.raw try import osreturn UUID bytes os.urandom 16 version 4 except import randombytes [chr random.randrange 256 for i in range 16 ]return UUID bytes bytes version 4
def get_doc_hooks if not hasattr local u'doc_events_hooks' hooks get_hooks u'doc_events' {} out {}for key value in hooks.iteritems if isinstance key tuple for doctype in key append_hook out doctype value else append_hook out key value local.doc_events_hooks outreturn local.doc_events_hooks
def get_size_from_backend context uri loc location.get_location_from_uri uri store get_store_from_uri context uri loc return store.get_size loc
def drop_redundant_messages messages sorted_messages sorted messages key len reverse True filtered_messages set for message in sorted_messages for filtered_message in filtered_messages if message in filtered_message breakelse filtered_messages.add message return filtered_messages
def _get_etree_type etree e etree.fromstring '<foo/>' return _get_type e
def render_template_string source **context ctx _app_ctx_stack.topctx.app.update_template_context context return _render ctx.app.jinja_env.from_string source context ctx.app
def from_edgelist edgelist create_using None G _prep_create_using create_using G.add_edges_from edgelist return G
def scala_test name srcs deps [] resources [] source_encoding None warnings None testdata [] **kwargs target ScalaTest name srcs deps resources source_encoding warnings testdata kwargs blade.blade.register_target target
def alchemy_to_dict obj if not obj return Noned {}for c in obj.__table__.columns value getattr obj c.name if type value datetime value value.isoformat d[c.name] valuereturn d
def isabs s s splitdrive s [1]return len s > 0 and s[ 1] in _get_bothseps s
def is_exiting return _exiting or _exiting is None
@memoizedef check key ver return check_version get key ver
def pval_lf Dmax n if n > 100 Dmax * n / 100.0 ** 0.49 n 100pval np.exp -7.01256 * Dmax ** 2 * n + 2.78019 + 2.99587 * Dmax * np.sqrt n + 2.78019 - 0.122119 + 0.974598 / np.sqrt n + 1.67997 / n return pval
def glBufferData target data usage if isinstance data int size datadata ctypes.c_voidp 0 else if not data.flags['C_CONTIGUOUS'] or not data.flags['ALIGNED'] data data.copy 'C' data_ datasize data_.nbytesdata data_.ctypes.datares _lib.glBufferData target size data usage
def propagate method1 method2 if method1 for attr in INHERITED_ATTRS if hasattr method1 attr and not hasattr method2 attr setattr method2 attr getattr method1 attr return method2
def flatten_fieldsets fieldsets field_names []for name opts in fieldsets for field in opts[u'fields'] if type field tuple field_names.extend field else field_names.append field return field_names
def pth path return 'img/icons/ratings/' + path
def heapreplace heap item returnitem heap[0]heap[0] item_siftup heap 0 return returnitem
@doctest_decodef full_path startPath files files list_strings files base os.path.split startPath [0]return [os.path.join base f for f in files]
def new_scratch_view window text new_view window.new_file new_view.set_scratch True if is_ST3 new_view.run_command 'append' {'characters' text} else new_edit new_view.begin_edit new_view.insert new_edit 0 text new_view.end_edit new_edit return new_view
def collapse_braces src_text nesting 0start_index 0collapsed_src_text u''for index char in enumerate src_text if nesting 0 collapsed_src_text + charif char u'{' if nesting 0 start_index index + 1 nesting + 1if char u'}' if nesting > 0 nesting - 1if nesting 0 collapsed_src_text + charif nesting ! 0 collapsed_src_text + src_text[start_index ]return collapsed_src_text
def make_paginated_api_response results None count 0 num_pages 0 next_link None previous_link None return {'pagination' {'next' next_link 'previous' previous_link 'count' count 'num_pages' num_pages} 'results' results or [] }
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def copy_index_matrix A B index index_rows False index_cols False is_diagonal False inplace False prefix None if prefix is None prefix find_best_blas_type A B [0]copy prefix_copy_index_matrix_map[prefix]if not inplace B np.copy B order 'F' try if not A.is_f_contig raise ValueError except A np.asfortranarray A copy A B np.asfortranarray index index_rows index_cols is_diagonal return B
def attributes_checker item attributes None try attrgetter *attributes item return Trueexcept AttributeError return False
def remove_callable dic for key value in dic.items if callable value del dic[key]return dic
def test_read_no_header_names_NoHeader table '\n|John|555-1234|192.168.1.10|\n|Mary|555-2134|192.168.1.12|\n|Bob|555-4527|192.168.1.9|\n'dat ascii.read table Reader ascii.FixedWidthNoHeader names 'Name' 'Phone' 'TCP' assert_equal tuple dat.dtype.names 'Name' 'Phone' 'TCP' assert_equal dat[1][0] 'Mary' assert_equal dat[0][1] '555-1234' assert_equal dat[2][2] '192.168.1.9'
def renewal_file_for_certname config certname path os.path.join config.renewal_configs_dir '{0}.conf'.format certname if not os.path.exists path raise errors.CertStorageError 'Nocertificatefoundwithname{0} expected{1} .'.format certname path return path
def gradient image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._gradient image selem out out mask mask shift_x shift_x shift_y shift_y
def key_to_english key english ''for index in range 0 len key 8 subkey key[index index + 8 ]skbin _key2bin subkey p 0for i in range 0 64 2 p p + _extract skbin i 2 skbin _key2bin subkey + chr p << 6 & 255 for i in range 0 64 11 english english + wordlist[_extract skbin i 11 ] + '' return english[ -1 ]
def _check_mrk_version header tags ['BrainVisionDataExchangeMarkerFile Version1.0' 'BrainVisionDataExchangeMarkerFile Version2.0']if header not in tags raise ValueError 'Currentlyonlysupport%r not%rContactMNE-Developersforsupport.' % str tags header
def onGlobalBasesDel key DEBUG_MSG 'onGlobalBasesDel %s' % key
def safe_repr fmt *args **kwargs if not is_py3 fmt fmt.decode 'utf-8' out fmt.format *args **kwargs return out.encode 'utf-8' else return fmt.format *args **kwargs
def skip_doctest f f.skip_doctest Truereturn f
def _quote_escape item rex_sqlquote re.compile "'" re.M return rex_sqlquote.sub "''" item
def angle2trig theta c cos theta * pi / 180 s sin theta * pi / 180 return c s - s c
@frappe.whitelist def delete_items import jsonil json.loads frappe.form_dict.get u'items' doctype frappe.form_dict.get u'doctype' for i d in enumerate il try frappe.delete_doc doctype d if len il > 5 frappe.publish_realtime u'progress' dict progress [ i + 1 len il ] title _ u'Deleting{0}' .format doctype user frappe.session.user except Exception pass
def tag_detail request slug template_name 'blog/tag_detail.html' **kwargs tag get_object_or_404 Tag name__iexact slug return list_detail.object_list request queryset TaggedItem.objects.get_by_model Post tag .filter status 2 extra_context {'tag' tag} template_name template_name **kwargs
def rrInitialisationRequest a TpPd pd 6 b MessageType mesType 60 c CiphKeySeqNrAndMacModeAndChannelCodingRequest e MobileStationClassmark2 f Tlli g ChannelRequestDescription h GprsMeasurementResults packet a / b / c / e / f / g / h return packet
def default_argv return ['--quick' '--colors NoColor' '--no-term-title' '--no-banner' '--autocall 0']
def cherrypy_logging log_path log_handler log cherrypy.loglog.access_file ''log.error_file ''maxBytes getattr log 'rot_maxBytes' 524288 backupCount getattr log 'rot_backupCount' 3 fname getattr log 'rot_error_file' log_path h log_handler fname 'a' maxBytes backupCount h.setLevel logging.DEBUG h.setFormatter cherrypy._cplogging.logfmt log.error_log.addHandler h
def _unwrap_dict dictionary index_string index index_string.split ' ' for k in index dictionary dictionary[k]return dictionary
def libvlc_audio_get_track p_mi f _Cfunctions.get 'libvlc_audio_get_track' None or _Cfunction 'libvlc_audio_get_track' 1 None ctypes.c_int MediaPlayer return f p_mi
def lcm a b tmp_a awhile tmp_a % b ! 0 tmp_a + areturn tmp_a
def _serialize_blobs artifact blobs {}for blob in artifact.metadata.attributes.blobs.values serialized_blob []if isinstance blob declarative.ListAttributeDefinition for b in blob.get_value artifact or [] serialized_blob.append {'size' b.size 'locations' b.locations 'checksum' b.checksum 'item_key' b.item_key} else b blob.get_value artifact if not b continueserialized_blob.append {'size' b.size 'locations' b.locations 'checksum' b.checksum 'item_key' b.item_key} blobs[blob.name] serialized_blobreturn blobs
def get url conn urlopen url resp conn.read conn.close return resp
def get_model_from_url_params app_name model_name model registry.get_by_natural_key app_name model_name if model is None raise Http404return model
def make_linear_colorscale colors scale 1.0 / len colors - 1 return [[ i * scale color] for i color in enumerate colors ]
def pagebreak type 'page' orient 'portrait' validtypes ['page' 'section']if type not in validtypes tmpl 'Pagebreakstyle"%s"notimplemented.Validstyles %s.'raise ValueError tmpl % type validtypes pagebreak makeelement 'p' if type 'page' run makeelement 'r' br makeelement 'br' attributes {'type' type} run.append br pagebreak.append run elif type 'section' pPr makeelement 'pPr' sectPr makeelement 'sectPr' if orient 'portrait' pgSz makeelement 'pgSz' attributes {'w' '12240' 'h' '15840'} elif orient 'landscape' pgSz makeelement 'pgSz' attributes {'h' '12240' 'w' '15840' 'orient' 'landscape'} sectPr.append pgSz pPr.append sectPr pagebreak.append pPr return pagebreak
def hello1 return 'HelloWorld'
def get_timezone zone None if zone is None return LOCALTZif not isinstance zone string_types return zonetry return _pytz.timezone zone except _pytz.UnknownTimeZoneError raise LookupError 'Unknowntimezone%s' % zone
def lang_exists cursor lang query "SELECTlannameFROMpg_languageWHERElanname '%s'" % lang cursor.execute query return cursor.rowcount > 0
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def test_tab_completion_delete qtmodeltester fake_web_tab qtbot app_stub win_registry tabbed_browser_stubs tabbed_browser_stubs[0].tabs [fake_web_tab QUrl 'https //github.com' 'GitHub' 0 fake_web_tab QUrl 'https //wikipedia.org' 'Wikipedia' 1 fake_web_tab QUrl 'https //duckduckgo.com' 'DuckDuckGo' 2 ]tabbed_browser_stubs[1].tabs [fake_web_tab QUrl 'https //wiki.archlinux.org' 'ArchWiki' 0 ]model miscmodels.TabCompletionModel qtmodeltester.data_display_may_return_none Trueqtmodeltester.check model view _mock_view_index model 0 1 qtbot qtbot.add_widget view model.delete_cur_item view actual [tab.url for tab in tabbed_browser_stubs[0].tabs]assert actual [QUrl 'https //github.com' QUrl 'https //duckduckgo.com' ]
@float32_floatXdef test_stochasatic_pool_samples ds 3stride 3rng numpy.random.RandomState 220 data rng.uniform 0 10 size 1 ds ds 1 .astype 'float32' x theano.tensor.tensor4 s_max stochastic_max_pool_c01b x ds ds stride stride f theano.function [x] s_max mode mode_with_gpu samples []for i in xrange 300 samples.append numpy.asarray f data [ 0 0 0 0 ] counts Counter samples data data.reshape ds * ds data.sort data data[ -1 ]for i in range len data - 1 assert counts[data[i]] > counts[data[ i + 1 ]]
def test_epochs_copy raw events picks _get_data epochs Epochs raw events[ 5] event_id tmin tmax picks picks preload True reject reject flat flat copied epochs.copy assert_array_equal epochs._data copied._data epochs Epochs raw events[ 5] event_id tmin tmax picks picks preload False reject reject flat flat copied epochs.copy data epochs.get_data copied_data copied.get_data assert_array_equal data copied_data
def next_rising_utc hass entity_id None entity_id entity_id or ENTITY_ID state hass.states.get ENTITY_ID try return dt_util.parse_datetime state.attributes[STATE_ATTR_NEXT_RISING] except AttributeError KeyError return None
def get_rollback name return _proxy_cmd 'get_rollback' name
def _prepare_lab_array arr arr np.asarray arr shape arr.shapeif shape[ -1 ] < 3 raise ValueError 'Inputarrayhaslessthan3colorchannels' return dtype.img_as_float arr force_copy True
def GetChildNodeText node child_tag default '' for child in node.getchildren if GetTag child child_tag return child.text or default return default
def get_python_inc plat_specific 0 prefix None if prefix is None prefix plat_specific and EXEC_PREFIX or PREFIX if os.name 'posix' if python_build buildir os.path.dirname sys.executable if plat_specific inc_dir buildirelse srcdir os.path.abspath os.path.join buildir get_config_var 'srcdir' inc_dir os.path.join srcdir 'Include' return inc_dirreturn os.path.join prefix 'include' 'python' + get_python_version elif os.name 'nt' return os.path.join prefix 'include' elif os.name 'os2' return os.path.join prefix 'Include' else raise DistutilsPlatformError "Idon'tknowwherePythoninstallsitsCheaderfilesonplatform'%s'" % os.name
def prepare_commentdoc s result []lines [line.strip for line in s.expandtabs .splitlines ]for line in lines if line.startswith '# ' line line[2 ]if line and line[0] '' line line[1 ]result.append line if result and result[ -1 ] result.append '' return result
def supportsSReg endpoint return endpoint.usesExtension ns_uri_1_1 or endpoint.usesExtension ns_uri_1_0
def cipheringModeCommand a TpPd pd 6 b MessageType mesType 53 c RrCause d CipherModeSettingAndcipherResponse packet a / b / c / d return packet
def resolve_i18n_message message messages locale default_locale None if not message or not isinstance message basestring return messagematch MSG_RE.match message if match is None return messagelocale find_language locale if default_locale default_locale find_language default_locale msgid match.group 'msgid' default {'message' message}if locale in messages message messages[locale].get msgid default elif default_locale in messages message messages[default_locale].get msgid default if not isinstance message dict return default['message']return message['message']
def save_auto data filename pass
def merge_service_dicts_from_files base override version new_service merge_service_dicts base override version if u'extends' in override new_service[u'extends'] override[u'extends']elif u'extends' in base new_service[u'extends'] base[u'extends']return new_service
def _extract_variants address variants_str def entries for entry in variants_str.split u' ' key _ value entry.partition u' ' if not key or not value raise ValueError u'Invalidvariantsafterthe@in {}'.format address yield key value return tuple entries
def call_hook message attachment None color 'good' short False identifier None channel None username None icon_emoji None base_url 'https //hooks.slack.com/services/'if not identifier identifier _get_hook_id url _urljoin base_url identifier if not message log.error 'messageisrequiredoption' if attachment payload {'attachments' [{'fallback' message 'color' color 'pretext' message 'fields' [{'value' attachment 'short' short}]}]}else payload {'text' message}if channel payload['channel'] channelif username payload['username'] usernameif icon_emoji payload['icon_emoji'] icon_emojidata _urlencode {'payload' json.dumps payload ensure_ascii False } result salt.utils.http.query url method 'POST' data data status True if result['status'] < 201 return Trueelse return {'res' False 'message' result.get 'body' result['status'] }
def unsafe f f.unsafe_callable Truereturn f
def get_wake_on_network ret salt.utils.mac_utils.execute_return_result 'systemsetup-getwakeonnetworkaccess' return salt.utils.mac_utils.validate_enabled salt.utils.mac_utils.parse_return ret 'on'
def do_reverse value if isinstance value string_types return value[ -1 ]try return reversed value except TypeError try rv list value rv.reverse return rvexcept TypeError raise FilterArgumentError 'argumentmustbeiterable'
def set_option option invalue return _ldap_function_call None _ldap.set_option option invalue
def ghost x depth boundary depth2 coerce_depth x.ndim depth boundary2 coerce_boundary x.ndim boundary depth_values [depth2.get i 0 for i in range x.ndim ]for d c in zip depth_values x.chunks if d > min c raise ValueError 'Theoverlappingdepth%dislargerthanyour\nsmallestchunksize%d.Rechunkyourarray\nwithalargerchunksizeorachunksizethat\nmoreevenlydividestheshapeofyourarray.' % d min c x2 boundaries x depth2 boundary2 x3 ghost_internal x2 depth2 trim dict k v * 2 if boundary2.get k 'none' ! 'none' else 0 for k v in depth2.items x4 chunk.trim x3 trim return x4
def TimeSeries data None x None y None builder_type LineBuilder **kws builder_type BUILDER_TYPES.get builder_type builder_type kws['x'] xkws['y'] yreturn create_and_build builder_type data **kws
def sync_from_db f @functools.wraps f def wrapper self *args **kwargs if self._time_to_sync self._cell_db_sync return f self *args **kwargs return wrapper
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def description_of file name 'stdin' u UniversalDetector for line in file u.feed line u.close result u.resultif result['encoding'] return '%s %swithconfidence%s' % name result['encoding'] result['confidence'] else return '%s noresult' % name
def check_id ID name u'ID' config None pos None if ID is not None and not xml_check.check_id ID warn_or_raise W02 W02 name ID config pos return Falsereturn True
def valid_window_lengths underlying_buffer_length return iter range 1 underlying_buffer_length + 1
def add_env url saltenv if not url.startswith 'salt //' return url path senv parse url return create path saltenv
def decrypt_master_key master_key_cipher private_key key RSA.importKey private_key cipher PKCS1_OAEP.new key return cipher.decrypt master_key_cipher
def direct_delete_container node part account container conn_timeout 5 response_timeout 15 headers None if headers is None headers {}path '/%s/%s' % account container add_timestamp 'x-timestamp' not in k.lower for k in headers _make_req node part 'DELETE' path gen_headers headers add_timestamp 'Container' conn_timeout response_timeout
def _tokenize description empty _matchingString u'' description colon _matchingString u' ' description equals _matchingString u' ' description backslash _matchingString u'\\' description current emptyops colon + equals nextOps {colon colon + equals equals colon}iterdesc iter iterbytes description for n in iterdesc if n in iterbytes ops yield _STRING current yield _OP n current emptyops nextOps[n]elif n backslash current + next iterdesc else current + n yield _STRING current
def write_ctf_comp fid comps if len comps < 0 returnstart_block fid FIFF.FIFFB_MNE_CTF_COMP for comp in comps start_block fid FIFF.FIFFB_MNE_CTF_COMP_DATA write_int fid FIFF.FIFF_MNE_CTF_COMP_KIND comp['ctfkind'] if comp.get 'save_calibrated' False write_int fid FIFF.FIFF_MNE_CTF_COMP_CALIBRATED comp['save_calibrated'] if not comp.get 'save_calibrated' True comp deepcopy comp data 1.0 / comp['rowcals'][ None] * comp['data']['data'] * 1.0 / comp['colcals'][None ] comp['data']['data'] datawrite_named_matrix fid FIFF.FIFF_MNE_CTF_COMP_DATA comp['data'] end_block fid FIFF.FIFFB_MNE_CTF_COMP_DATA end_block fid FIFF.FIFFB_MNE_CTF_COMP
def python_compiler return _sys_version [6]
def _rfc3339_nanos_to_datetime dt_str with_nanos _RFC3339_NANOS.match dt_str if with_nanos is None raise ValueError 'Timestamp %r doesnotmatchpattern %r' % dt_str _RFC3339_NANOS.pattern bare_seconds datetime.datetime.strptime with_nanos.group 'no_fraction' _RFC3339_NO_FRACTION fraction with_nanos.group 'nanos' if fraction is None micros 0else scale 9 - len fraction nanos int fraction * 10 ** scale micros nanos // 1000 return bare_seconds.replace microsecond micros tzinfo UTC
def _translate_conductor_summary_view context vol image_id None d {}d['id'] vol['id']d['status'] vol['status']d['size'] vol['size']d['availability_zone'] vol['availability_zone']d['created_at'] vol['created_at']d['display_name'] vol['display_name']d['display_description'] vol['display_description']if vol['conductor_type_id'] and vol.get 'conductor_type' d['conductor_type'] vol['conductor_type']['name']else d['conductor_type'] str vol['conductor_type_id'] LOG.audit _ 'vol %s' vol context context if vol.get 'conductor_metadata' metadata vol.get 'conductor_metadata' d['metadata'] dict item['key'] item['value'] for item in metadata elif vol.get 'metadata' and isinstance vol.get 'metadata' dict d['metadata'] vol['metadata']else d['metadata'] {}if vol.get 'conductor_glance_metadata' d['bootable'] 'true'else d['bootable'] 'false'return d
def get_start_command package result 'gcloud' 'beta' 'emulators' package 'start' extra EXTRA.get package return result + extra
def inherit name objectType clear_existing_acl False ret {'name' name 'result' True 'changes' {} 'comment' ''}tRet __salt__['win_dacl.check_inheritance'] name objectType if tRet['result'] if not tRet['Inheritance'] if __opts__['test'] ret['result'] Noneret['changes']['Inheritance'] 'Enabled'ret['comment'] 'Inheritanceissettobeenabled.'ret['changes']['ExistingACLs'] 'Aresettoberemoved' if clear_existing_acl else 'Aresettobekept' return reteRet __salt__['win_dacl.enable_inheritance'] name objectType clear_existing_acl if eRet['result'] ret['result'] Trueret['changes'] dict ret['changes'] **eRet['changes'] else ret['result'] Falseret['comment'] ''.join [ret['comment'] eRet['comment']] elif __opts__['test'] ret['result'] Noneret['comment'] 'Inheritanceisenabled.'else ret['result'] Falseret['comment'] tRet['comment']return ret
def _pick_error log_interpretation def yield_errors for log_type in 'step' 'history' 'task' errors log_interpretation.get log_type {} .get 'errors' for error in errors or yield error errors _merge_and_sort_errors yield_errors if errors return errors[0]else return None
def get_test_packages all_packages get_package_directories local_diff local_diff_branch parser get_parser args parser.parse_args if args.packages is not UNSET_SENTINEL verify_packages args.packages all_packages return sorted args.packages elif local_diff is not None changed_packages get_changed_packages 'HEAD' local_diff all_packages return follow_dependencies changed_packages all_packages elif in_travis changed_packages get_travis_directories all_packages return follow_dependencies changed_packages all_packages else return all_packages
def enforcedLocalPath relpath dirpath context 'Path' parsed_dir urlparse dirpath parsed_rel urlparse relpath if parsed_rel.scheme not in 'file' '' raise Core.KnownUnknown '%spathmustbealocalfilepath absoluteor"file //" not"%s".' % context relpath if parsed_dir.scheme not in 'file' '' and parsed_rel.scheme ! 'file' raise Core.KnownUnknown '%spathmuststartwith"file //"inaremoteconfiguration "%s"relativeto%s ' % context relpath dirpath if parsed_rel.scheme 'file' return parsed_rel.pathif parsed_dir.scheme 'file' return urljoin parsed_dir.path parsed_rel.path return pathjoin dirpath relpath
def _do_imports components done {}for name in components if name in done continuer _do_import name if r is False return Falsemembers dict inspect.getmembers sys.modules[r] done[name] r sys.modules[r] members return done
@logic.validate logic.schema.default_package_list_schema def current_package_list_with_resources context data_dict model context['model']limit data_dict.get 'limit' offset data_dict.get 'offset' 0 user context['user']if not 'offset' in data_dict and 'page' in data_dict log.warning '"page"parameterisdeprecated.Usethe"offset"parameterinstead' page data_dict['page']if limit offset page - 1 * limit else offset 0_check_access 'current_package_list_with_resources' context data_dict search package_search context {'q' '' 'rows' limit 'start' offset 'include_private' authz.is_sysadmin user } return search.get 'results' []
def _immediately_after node try pos node.treeposition tree node.root current node.parent except AttributeError return []idx len pos - 1 while 0 < idx and pos[idx] len current - 1 idx - 1current current.parent if idx < 0 return []pos list pos[ idx + 1 ] pos[ -1 ] + 1after tree[pos]return [after] + _leftmost_descendants after
def post_detail request slug year month day **kwargs posts Noneif request.user.is_superuser posts Post.objects.all else posts Post.objects.published return date_based.object_detail request year year month month day day date_field 'publish' slug slug queryset posts **kwargs
def test_wheel_no_compiles_pyc script data script.pip 'install' '--no-compile' 'simple.dist 0.1' '--no-index' '--find-links ' + data.find_links exists [os.path.exists script.site_packages_path / 'simpledist/__init__.pyc' ]exists + glob.glob script.site_packages_path / 'simpledist/__pycache__/__init__*.pyc' assert not any exists
@register u'edit-and-execute-command' def edit_and_execute event buff event.current_bufferbuff.open_in_editor event.cli buff.accept_action.validate_and_handle event.cli buff
def usecase5 x N for k in range N print x[k].f1 x.s1[k] x[k].f2
def texinfo check_build if sys.platform ! 'win32' if os.system 'sphinx-build-btexinfo-dbuild/doctrees.build/texinfo' raise SystemExit 'BuildingTexinfofailed.' os.chdir 'build/texinfo' if os.system 'make' raise SystemExit 'RenderingTexinfofailed.' os.chdir '../..' else print 'texinfobuildhasnotbeentestedonwindows'
def fixed_ip_get_by_instance context instance_uuid return IMPL.fixed_ip_get_by_instance context instance_uuid
def test_strongly_typed_events def f global calledcalled Trueglobal calledcalled Falseev IronPythonTest.Events ev.InstanceTest + IronPythonTest.EventTestDelegate f ev.CallInstance AreEqual called True called Falseev.InstanceTest - IronPythonTest.EventTestDelegate f ev.CallInstance AreEqual called False
def reap_fileserver_cache_dir cache_base find_func for saltenv in os.listdir cache_base env_base os.path.join cache_base saltenv for root dirs files in os.walk env_base if len dirs 0 and len files 0 if time.time - os.path.getctime root > 60 os.rmdir root continuefor file_ in files file_path os.path.join root file_ file_rel_path os.path.relpath file_path env_base try filename _ hash_type file_rel_path.rsplit '.' 2 except ValueError log.warning 'Foundinvalidhashfile[{0}]whenattemptingtoreapcachedirectory.'.format file_ continueret find_func filename saltenv saltenv if ret['path'] '' os.unlink file_path
def month_by_abbreviation abbrev try return [s[ 3] for s in ENGLISH_MONTH_NAMES].index abbrev + 1 except ValueError return None
def parse_megam_weights s features_count explicit True if numpy is None raise ValueError 'Thisfunctionrequiresthatnumpybeinstalled' assert explicit 'non-explicitnotsupportedyet'lines s.strip .split '\n' weights numpy.zeros features_count 'd' for line in lines if line.strip fid weight line.split weights[int fid ] float weight return weights
def test_cnot if not mpl skip 'matplotlibnotinstalled' else from sympy.physics.quantum.circuitplot import CircuitPlotc CircuitPlot CNOT 1 0 2 labels labeller 2 assert c.ngates 2 assert c.nqubits 2 assert c.labels ['q_1' 'q_0'] c CircuitPlot CNOT 1 0 2 assert c.ngates 2 assert c.nqubits 2 assert c.labels []
def dup_sub_mul f g h K return dup_sub f dup_mul g h K K
def _find_required_chars block_range full_coverage_required exceptions chars_defined_in_block _defined_characters_in_range block_range if full_coverage_required return chars_defined_in_blockelse if not exceptions return set if exceptions.startswith _EXCEPTION_STARTER exceptions exceptions[len _EXCEPTION_STARTER ]chars_to_exclude _multiple_range_string_to_set exceptions return chars_defined_in_block - chars_to_exclude else chars_to_limit_to _multiple_range_string_to_set exceptions return chars_defined_in_block & chars_to_limit_to
def generate_argument_parser_for_metadata metadata parameters metadata['parameters']parser argparse.ArgumentParser description metadata['description'] for parameter_name parameter_options in parameters.items name parameter_name.replace '_' '-' description parameter_options['description']_type parameter_options['type']required parameter_options.get 'required' False default_value parameter_options.get 'default' None immutable parameter_options.get 'immutable' False if immutable continueargs [ '--%s' % name ]kwargs {'help' description 'required' required}if default_value is not None kwargs['default'] default_valueif _type 'string' kwargs['type'] strelif _type 'integer' kwargs['type'] intelif _type 'boolean' if default_value is False kwargs['action'] 'store_false'else kwargs['action'] 'store_true'parser.add_argument *args **kwargs return parser
def EvalExponentialCdf x lam return 1 - math.exp - lam * x
def _sphinx_version major minor micro level serial sys.version_inforelease '%s%s' % major minor if micro release + '%s' % micro if level 'candidate' release + 'rc%s' % serial elif level ! 'final' release + '%s%s' % level[0] serial return release
def check_course_access course_key user None ip_address None url None if not settings.FEATURES.get 'EMBARGO' return Truecourse_is_restricted RestrictedCourse.is_restricted_course course_key if not course_is_restricted return Trueif user is not None and has_course_author_access user course_key return Trueif ip_address is not None user_country_from_ip _country_code_from_ip ip_address if not CountryAccessRule.check_country_access course_key user_country_from_ip log.info u"Blockinguser%sfromaccessingcourse%sat%sbecausetheuser'sIPaddress%sappearstobelocatedin%s." getattr user 'id' '<NotAuthenticated>' course_key url ip_address user_country_from_ip return Falseif user is not None user_country_from_profile _get_user_country_from_profile user if not CountryAccessRule.check_country_access course_key user_country_from_profile log.info u"Blockinguser%sfromaccessingcourse%sat%sbecausetheuser'sprofilecountryis%s." user.id course_key url user_country_from_profile return Falsereturn True
def single_source_dijkstra G source target None cutoff None weight 'weight' return multi_source_dijkstra G {source} cutoff cutoff target target weight weight
def _set_reply_headers new_message previous_message if previous_message.message_id_header new_message.in_reply_to previous_message.message_id_headerif previous_message.references new_message.references previous_message.references + [previous_message.message_id_header] else new_message.references [previous_message.message_id_header]
def _LogInvalidRunLevels states valid invalid set for state in states if state not in valid invalid.add state if invalid logging.warn 'Invalidinitrunlevel s encountered %s' ' '.join invalid
def sync_modules saltenv 'base' return salt.utils.extmods.sync __opts__ 'modules' saltenv saltenv [0]
def generate_filename_and_delete_previous ffile name before_delete None new_filename ffile.field.generate_filename ffile.instance name try orig_instance ffile.instance.__class__.objects.get id ffile.instance.id orig_field_file getattr orig_instance ffile.field.name orig_filename orig_field_file.nameif orig_filename and new_filename ! orig_filename if before_delete before_delete orig_field_file orig_field_file.delete except ffile.instance.__class__.DoesNotExist passreturn new_filename
def intersection *entities from .entity import GeometryEntityfrom .point import Pointif len entities < 1 return []entities list entities for i e in enumerate entities if not isinstance e GeometryEntity try entities[i] Point e except NotImplementedError raise ValueError '%sisnotaGeometryEntityandcannotbemadeintoPoint' % str e res entities[0].intersection entities[1] for entity in entities[2 ] newres []for x in res newres.extend x.intersection entity res newresreturn res
def get_exog N num_nonconst_covariates cor_length uncorrelated_exog sp.randn N num_nonconst_covariates if cor_length 0 exog uncorrelated_exogelse cov_matrix sp.zeros num_nonconst_covariates num_nonconst_covariates j sp.arange num_nonconst_covariates for i in range num_nonconst_covariates cov_matrix[i ] sp.exp - sp.fabs i - j / cor_length chol linalg.cholesky cov_matrix exog sp.dot uncorrelated_exog chol return exog
def in6_iseui64 x eui64 inet_pton socket.AF_INET6 ' ff fe00 0' x in6_and inet_pton socket.AF_INET6 x eui64 return x eui64
def probabilistic_hough_line img threshold 10 line_length 50 line_gap 10 theta None if img.ndim ! 2 raise ValueError 'Theinputimage`img`mustbe2D.' if theta is None theta np.linspace - np.pi / 2 np.pi / 2 180 return _probabilistic_hough_line img threshold line_length line_gap theta
def test_list_json script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' 'simple2 3.0' result script.pip 'list' '--format json' data json.loads result.stdout assert {'name' 'simple' 'version' '1.0'} in data assert {'name' 'simple2' 'version' '3.0'} in data
def setup_args parser cli.build_arg_parser parser.add_argument '-j' '--uuid' required True help 'UUIDoftheVirtualMachineyouwanttoaddanoteto.' parser.add_argument '-m' '--message' required True help 'Messagetoaddtothenotesfield.' my_args parser.parse_args return cli.prompt_for_password my_args
def dictadd *dicts result {}for dct in dicts result.update dct return result
def near_identical im1 im2 diff ImageChops.difference im1 im2 .histogram for color in diff[2 ] if color return Falsereturn True
def normalize_resource_url resource_url try protocol name split_resource_url resource_url except ValueError protocol u'nltk'name resource_urlif protocol u'nltk' and os.path.isabs name protocol u'file //'name normalize_resource_name name False None elif protocol u'file' protocol u'file //'name normalize_resource_name name False None elif protocol u'nltk' protocol u'nltk 'name normalize_resource_name name True else protocol + u' //'return u''.join [protocol name]
def stopOnError case reactor publisher None if publisher is None from twisted.python import log as publisherrunning [None]def stopIfError event if running and event.get 'isError' running.pop reactor.stop publisher.addObserver stopIfError case.addCleanup publisher.removeObserver stopIfError
def has_pattern try from pattern.en import parsereturn Trueexcept ImportError return False
def import_optional mod_name try return import_module mod_name except ImportError passexcept Exception msg 'Failedtoimportoptionalmodule`{}`'.format mod_name logger.exception msg
def get_default_hparams return HParams batch_size 64 residual_blocks 2 n_couplings 2 n_scale 4 learning_rate 0.001 momentum 0.1 decay 0.001 l2_coeff 5e-05 clip_gradient 100.0 optimizer 'adam' dropout_mask 0 base_dim 32 bottleneck 0 use_batch_norm 1 alternate 1 use_aff 1 skip 1 data_constraint 0.9 n_opt 0
def rootcontext cls cls._enforce_context manager.contextreturn cls
def stub_set_host_enabled context host_name enabled results {True 'enabled' False 'disabled'}if host_name 'notimplemented' raise NotImplementedError elif host_name 'dummydest' raise exception.ComputeHostNotFound host host_name elif host_name 'service_not_available' raise exception.ComputeServiceUnavailable host host_name elif host_name 'host_c2' return results[ not enabled ]else return results[enabled]
def sum_entries operator return lo.LinOp lo.SUM_ENTRIES 1 1 [operator] None
def _write_data writer data data data.replace '&' '&amp;' .replace '<' '&lt;' data data.replace '"' '&quot;' .replace '>' '&gt;' writer.write data
def randompass import randomimport stringrandom.seed lower ''.join random.choice string.ascii_lowercase for x in range 6 upper ''.join random.choice string.ascii_uppercase for x in range 6 number ''.join random.choice string.digits for x in range 6 punct ''.join random.choice string.punctuation for x in range 6 p lower + upper + number + punct return ''.join random.sample p len p
def decode_mailbox_name name def demodify m s m.group if s '+' return '+-'return '+' + s[1 -1 ].replace ' ' '/' + '-' ret MUTF7_SHIFT_RE.sub demodify name try return ret.decode 'utf-7' .encode 'utf-8' except UnicodeDecodeError UnicodeEncodeError return name
def get_seq_lengths seq_lengths bc_counts all_seq_lengths seq_lengths.values all_seq_ids set seq_lengths.keys bad_seq_ids set bc_counts[None] .union set bc_counts['#FAILED'] good_seq_ids all_seq_ids - bad_seq_ids good_seq_lengths map seq_lengths.__getitem__ good_seq_ids return all_seq_lengths good_seq_lengths
def run _task
def ds_add ds days ds datetime.strptime ds '%Y-%m-%d' if days ds ds + timedelta days return ds.isoformat [ 10]
def _genbank_convert_fasta in_handle out_handle alphabet None from Bio.GenBank.Scanner import GenBankScannerrecords GenBankScanner .parse_records in_handle do_features False return SeqIO.write records out_handle 'fasta'
def get_project_root settings_mod __import__ settings.SETTINGS_MODULE {} {} [''] return os.path.dirname os.path.abspath settings_mod.__file__
def stream func @wraps func def wrapped manager *args **kwargs offset limit kwargs.pop '_offset' None kwargs.pop '_limit' None qs func manager *args **kwargs if isinstance qs dict qs manager.public **qs elif isinstance qs list tuple qs manager.public *qs if offset or limit qs qs[offset limit]return qs.fetch_generic_relations return wrapped
def list_cats default True lst [cat['name'] for cat in config.get_ordered_categories ]if default lst.remove '*' lst.insert 0 'Default' return lst
def twinx ax None if ax is None ax gca ax1 ax.twinx draw_if_interactive return ax1
def get_stylesheet_list settings assert not settings.stylesheet and settings.stylesheet_path 'stylesheetandstylesheet_patharemutuallyexclusive.'stylesheets settings.stylesheet_path or settings.stylesheet or [] if not isinstance stylesheets list stylesheets [path.strip for path in stylesheets.split ' ' ]return [find_file_in_dirs path settings.stylesheet_dirs for path in stylesheets]
def numpy_cupy_array_almost_equal decimal 6 err_msg '' verbose True name 'xp' type_check True accept_error False def check_func x y array.assert_array_almost_equal x y decimal err_msg verbose return _make_decorator check_func name type_check accept_error
def search_tree root glob_match ext found_files []for path in glob.glob os.path.join root glob_match if path.endswith ext found_files.append path else for root dirs files in os.walk path for file in files if file.endswith ext found_files.append os.path.join root file return sorted found_files
def test_install_editable_uninstalls_existing_from_path script data to_install data.src.join 'simplewheel-1.0' result script.pip_install_local to_install assert 'Successfullyinstalledsimplewheel' in result.stdout simple_folder script.site_packages / 'simple' result.assert_installed 'simple' editable False assert simple_folder in result.files_created str result.stdout result script.pip 'install' '-e' to_install install_path script.site_packages / 'simplewheel.egg-link' assert install_path in result.files_created str result assert 'Foundexistinginstallation simplewheel1.0' in result.stdout assert 'Uninstallingsimplewheel-' in result.stdout assert 'Successfullyuninstalledsimplewheel' in result.stdout assert simple_folder in result.files_deleted str result.stdout
def execute_action doctype name action **kwargs doc frappe.get_doc doctype name doc.unlock try getattr doc action **kwargs except Exception frappe.db.rollback if frappe.local.message_log msg json.loads frappe.local.message_log[ -1 ] .get u'message' else msg u'<pre><code>' + frappe.get_traceback + u'</pre></code>' doc.add_comment u'Comment' _ u'ActionFailed' + u'<br><br>' + msg doc.notify_update
def secs_to_timestr secs compact False return _SecsToTimestrHelper secs compact .get_value
def process_article args text lemmatize title pageid argstext filter_wiki text if lemmatize result utils.lemmatize text else result tokenize text return result title pageid
def _decrypt_ciphertext cipher translate_newlines False cmd [_get_gpg_exec '--homedir' _get_key_dir '-d']proc Popen cmd stdin PIPE stdout PIPE stderr PIPE shell False decrypted_data decrypt_error proc.communicate input cipher.replace '\\n' '\n' if translate_newlines else cipher if not decrypted_data log.warning 'Couldnotdecryptcipher%s received %s' cipher decrypt_error return cipherelse return str decrypted_data
def find_audio_period aclip t_min 0.1 t_max 2 t_res 0.01 chunksize int t_res * aclip.fps chunk_duration 1.0 * chunksize / aclip.fps v np.array [ c ** 2 .sum for c in aclip.iter_chunks chunksize ] v v - v.mean corrs np.correlate v v mode 'full' [ - len v ]corrs[ int t_min / chunk_duration ] 0corrs[int t_max / chunk_duration ] 0return chunk_duration * np.argmax corrs
def getTricomplexskewX transformWords skewX math.tan math.radians float transformWords[0] return [complex 1.0 0.0 complex skewX 1.0 complex ]
def dictreverse d return dict [ v k for k v in d.iteritems ]
def TR1 rv def f rv if rv.func is sec a rv.args[0]return S.One / cos a elif rv.func is csc a rv.args[0]return S.One / sin a return rvreturn bottom_up rv f
def dup_legendre n K seq [[K.one] [K.one K.zero]]for i in range 2 n + 1 a dup_mul_ground dup_lshift seq[ -1 ] 1 K K 2 * i - 1 i K b dup_mul_ground seq[ -2 ] K i - 1 i K seq.append dup_sub a b K return seq[n]
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def benchmarkFunc iter args def decorator func benchmarkFuncs.append func args iter return funcreturn decorator
def get_filepaths dire return read_in os.path.join dire 'FILEPATHS'
def compare_config return __proxy__['napalm.call'] 'compare_config' **{}
def error_page_404 status message traceback version return '\n<html>\n<head>\n<scripttype "text/javascript">\n<!--\nlocation.href location.protocol+\'//\'+location.hostname+ location.port?\' \'+location.port \'\' +\'/sabnzbd/\';\n//-->\n</script>\n</head>\n<body><br/></body>\n</html>\n'
def notification if c['events'] for e in c['events'] print_event e printNicely '' else printNicely magenta 'Nothingatthistime.'
def qnwcheb n a 1 b 1 return _make_multidim_func _qnwcheb1 n a b
def line2d p0 p1 x0 y0 p0[ 2] x1 y1 p1[ 2]if x0 x1 a -1 b 0c x1elif y0 y1 a 0b 1c - y1 else a y0 - y1 b x0 - x1 c x0 * y1 - x1 * y0 return a b c
def parse_timedelta val if not val return Noneval val.lower if '.' in val val float val return timedelta hours int val minutes 60 * val % 1.0 fHour 'h' in val or ' ' in val fMin 'm' in val or ' ' in val for noise in 'minu teshour ' val val.replace noise '' val val.strip val val.split hr 0.0mi 0val.reverse if fHour hr int val.pop if fMin mi int val.pop if len val > 0 and not hr hr int val.pop return timedelta hours hr minutes mi
def SetVariable output variable_name value output.write 'set ' output.write variable_name output.write '"' output.write CMakeStringEscape value output.write '" \n'
def check_or_raise_id value message u'WAMPmessageinvalid' if type value not in six.integer_types raise ProtocolError u'{0} invalidtype{1}forID'.format message type value if value < 0 or value > 9007199254740992 raise ProtocolError u'{0} invalidvalue{1}forID'.format message value return value
def getString value return str value
def Str *strs if len strs 1 return Str1 strs[0] else result Alt *tuple map Str1 strs result.str 'Str %s ' % ' '.join map repr strs return result
def tgrep_tokenize tgrep_string parser _build_tgrep_parser False if isinstance tgrep_string binary_type tgrep_string tgrep_string.decode return list parser.parseString tgrep_string
def _csr_matrix_indices S m n S.shapefor i in range m for j in range S.indptr[i] S.indptr[ i + 1 ] row_index col_index i S.indices[j] yield row_index col_index
def list_from_csv comma_separated_str if comma_separated_str return [v.strip for v in comma_separated_str.split ' ' if v.strip ]return []
def draw_if_interactive pass
def test_find_number_4 s 'thequickbrownfox54.6jumped'r find_number s assert s[r[0] r[1]] '54.6'
def scan_multilang tokens module_elem tokenizer perl_lexer.PerlMultiLangLexer tokens parser perl_parser.Parser tokenizer lang 'PerlHTML' provide_full_docs gProvideFullDocs parser.moduleName ''parser.parse parse_tree parser.produce_CIX_NoHeader module_elem csl_tokens tokenizer.get_csl_tokens return csl_tokens tokenizer.has_perl_code
def _allocate_data data data_buffer data_shape dtype if data is None if isinstance data_buffer string_types data np.memmap data_buffer mode 'w+' dtype dtype shape data_shape else data np.zeros data_shape dtype dtype return data
def escape_md_section text snob False text md_backslash_matcher.sub '\\\\\\1' text if snob text md_chars_matcher_all.sub '\\\\\\1' text text md_dot_matcher.sub '\\1\\\\\\2' text text md_plus_matcher.sub '\\1\\\\\\2' text text md_dash_matcher.sub '\\1\\\\\\2' text return text
def embed_id x W ignore_label None return EmbedIDFunction ignore_label ignore_label x W
def sort_fasta_by_abundance fasta_lines fasta_out_f seq_index {}count 0for seq_id seq in parse_fasta fasta_lines count + 1try seq_index[seq].append seq_id except KeyError seq_index[seq] [seq_id]seqs []for k v in seq_index.items seqs.append len v k v del seq_index[k]seqs.sort for count seq seq_ids in seqs[ -1 ] for seq_id in seq_ids fasta_out_f.write '>%s\n%s\n' % seq_id seq
def oo_pods_match_component pods deployment_type component if not isinstance pods list raise errors.AnsibleFilterError 'failedexpectstofilteronalist' if not isinstance deployment_type string_types raise errors.AnsibleFilterError 'failedexpectsdeployment_typetobeastring' if not isinstance component string_types raise errors.AnsibleFilterError 'failedexpectscomponenttobeastring' image_prefix 'openshift/origin-'if deployment_type in ['enterprise' 'online' 'openshift-enterprise'] image_prefix 'openshift3/ose-'elif deployment_type 'atomic-enterprise' image_prefix 'aep3_beta/aep-'matching_pods []image_regex image_prefix + component + '.*' for pod in pods for container in pod['spec']['containers'] if re.search image_regex container['image'] matching_pods.append pod breakreturn matching_pods
def move_in_stack move_up frame Frame.get_selected_python_frame while frame if move_up iter_frame frame.older else iter_frame frame.newer if not iter_frame breakif iter_frame.is_python_frame if iter_frame.select iter_frame.print_summary returnframe iter_frameif move_up print 'Unabletofindanolderpythonframe' else print 'Unabletofindanewerpythonframe'
def maintenance period 'daily' maintenance Noneresult 'NotImplementedError'templates settings.get_template if templates ! 'default' template_location settings.get_template_location if not isinstance templates tuple list templates templates for template in templates[ -1 ] package 'applications.%s.%s.templates.%s' % appname template_location template name 'maintenance'try maintenance getattr __import__ package fromlist [name] name except ImportError AttributeError passelse breakif maintenance is None try from templates.default import maintenanceexcept ImportError passif maintenance is not None if period 'daily' result maintenance.Daily db.commit return result
def SecondsSince timestamp return time.time - timestamp
def safe_indexing X indices if hasattr X 'iloc' try return X.iloc[indices]except ValueError warnings.warn 'Copyinginputdataframeforslicing.' DataConversionWarning return X.copy .iloc[indices]elif hasattr X 'shape' if hasattr X 'take' and hasattr indices 'dtype' and indices.dtype.kind 'i' return X.take indices axis 0 else return X[indices]else return [X[idx] for idx in indices]
def all_templates templates defaultdict list for category descriptor in XBlock.load_classes if not hasattr descriptor 'templates' continuetemplates[category] descriptor.templates return templates
def strip_html_content_to_text html_content text_content re.sub ' \\s|&nbsp;|// +' '' html_to_text html_content text_content re.sub '<!\\[CDATA\\[.*\\]\\]>' '' text_content text_content re.sub '<!--.*-->' '' text_content return text_content
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
def copy_location new_node old_node for attr in 'lineno' 'col_offset' if attr in old_node._attributes and attr in new_node._attributes and hasattr old_node attr setattr new_node attr getattr old_node attr return new_node
def find_variant name version None prod Nonefor prod in SUPPORTED_VARIANTS if prod.name name if version is None return prod prod.latest_version for v in prod.versions if v.name version return prod v return None None
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def test_bad_module_all testsdir os.path.dirname __file__ sys.path.insert 0 testsdir try results module_completion 'frombad_allimport' nt.assert_in 'puppies' results for r in results nt.assert_is_instance r str finally sys.path.remove testsdir
def ipfunc return 'ipfunc'
def filter_oauth_params params is_oauth lambda kv kv[0].startswith u'oauth_' if isinstance params dict return list filter is_oauth list params.items else return list filter is_oauth params
def quote c assert isinstance c bytes and len c 1 c ord c return ESCAPE + bytes HEX[ c // 16 ] HEX[ c % 16 ]
def gcd *a if len a > 1 return reduce gcd2 a if hasattr a[0] '__iter__' return reduce gcd2 a[0] return a[0]
def test_evoked_baseline evoked read_evokeds fname condition 0 baseline None evoked EvokedArray np.ones_like evoked.data evoked.info evoked.times[0] evoked.apply_baseline None None assert_allclose evoked.data np.zeros_like evoked.data
def naive_grouped_rowwise_apply data group_labels func func_args out None if out is None out np.empty_like data for row label_row out_row in zip data group_labels out for label in np.unique label_row locs label_row label out_row[locs] func row[locs] *func_args return out
def sanitize_filename filename if isinstance filename str unicode filename re.sub u'[\\\\/\\*]' u'-' filename filename re.sub u'[ "<>|?]' u'' filename filename re.sub u'\u2122' u'' filename filename filename.strip u'.' return filenamereturn u''
def multi_constructor_import loader tag_suffix node if '.' not in tag_suffix raise yaml.YAMLError "!import tagsuffixcontainsno'.'" return try_to_import tag_suffix
def nova_docstring_multiline_start physical_line previous_logical tokens if is_docstring physical_line previous_logical pos max [physical_line.find i for i in START_DOCSTRING_TRIPLE] if len tokens 0 and pos ! -1 and len physical_line pos + 4 if physical_line.strip in START_DOCSTRING_TRIPLE return pos 'N404 multilinedocstringshouldstartwithasummary'
def _is_import_valid documents return isinstance documents list and all isinstance d dict for d in documents and all all k in d for k in 'pk' 'model' 'fields' for d in documents and all all k in d['fields'] for k in 'uuid' 'owner' for d in documents
def rebuild_node doctype parent left parent_field from frappe.utils import nown now right left + 1 result frappe.db.sql u'SELECTnameFROM`tab%s`WHERE`%s` %s' % doctype parent_field u'%s' parent for r in result right rebuild_node doctype r[0] right parent_field frappe.db.sql u'UPDATE`tab{0}`SETlft %s rgt %s modified %s\n DCTB DCTB WHEREname %s'.format doctype left right n parent return right + 1
def parse_neighbors_graph neighbors vars [] graph defaultdict list for var in vars graph[var] []specs [spec.split ' ' for spec in neighbors.split ';' ]for v v_neighbors in specs v v.strip graph.setdefault v [] for u in v_neighbors.split graph[v].append u graph[u].append v return graph
@deprecated 'Thefunctionsample_gaussianisdeprecatedin0.18andwillberemovedin0.20.Usenumpy.random.multivariate_normalinstead.' def sample_gaussian mean covar covariance_type 'diag' n_samples 1 random_state None _sample_gaussian mean covar covariance_type 'diag' n_samples 1 random_state None
def p4_system cmd real_cmd p4_build_cmd cmd expand isinstance real_cmd six.string_types retcode subprocess.call real_cmd shell expand if retcode raise CalledProcessError retcode real_cmd
@pytest.mark.skipif 'notHAS_YAML' def test_ecsv_astropy_objects_in_meta t QTable [ [1 2] * u.m [4 5]] names ['a' 'b'] tm _get_time c SkyCoord [[1 2] [3 4]] [[5 6] [7 8]] unit 'deg' frame 'fk4' obstime Time '2016-01-02' location EarthLocation 1000 2000 3000 unit u.km unit u.m / u.s t.meta {'tm' tm 'c' c 'unit' unit}out StringIO t.write out format 'ascii.ecsv' t2 QTable.read out.getvalue format 'ascii.ecsv' compare_time tm t2.meta['tm'] compare_coord c t2.meta['c'] assert t2.meta['unit'] unit
def set_vif_guest_frontend_config conf mac model driver conf.mac_addr macif model is not None conf.model modelif driver is not None conf.driver_name driver
def _get_callback_info callback module_name getattr callback '__module__' None func_name callback.__name__if inspect.ismethod callback class_name reflection.get_class_name callback.__self__ fully_qualified False return [module_name class_name func_name]else return [module_name func_name]
def check_endpoint_url url substitutions dict zip WHITELISTED_PROPERTIES itertools.repeat '' try url.replace '$ ' '% ' % substitutions except KeyError TypeError ValueError raise exception.URLValidationError url
def p_initializer_list_1 t pass
def final_touches s2 r deg_g R s2.row r - 1 for i in range s2.cols if R[ 0 i ] 0 continueelse breakmr s2.cols - i + deg_g + 1 i 0while mr ! 0 and r + i < s2.rows s2[ r + i ] rotate_r R i + 1 i + 1mr - 1return s2
def current_route_path request *elements **kw return request.current_route_path *elements **kw
def _get_vistara_configuration return {'client_id' __opts__['vistara']['client_id'] 'client_key' __opts__['vistara']['client_key'] 'client_secret' __opts__['vistara']['client_secret']}
def set_token unique_key token_str result memcache.set unique_key token_str if not result result memcache.delete unique_key if result 0 return Falseif Token key_name unique_key t token_str .put return Truereturn None
def sync_output saltenv 'base' return salt.utils.extmods.sync __opts__ 'output' saltenv saltenv [0]
def convert_to_uuids migrate_engine primary_table_name foreign_tables revision_table_name None dropped_fk_constraints drop_constraints_and_alter_types primary_table_name foreign_tables revision_table_name add_fk_constraints migrate_engine dropped_fk_constraints primary_table_name create_uuids migrate_engine primary_table_name revision_table_name
def remove_filename_outliers filename return _filename_version_re.sub '<version>/' filename
def redis_key user domain return [ 'ratelimit %s %s %s %s' % type user user.id domain keytype for keytype in ['list' 'zset' 'block']]
def strseq object convert join joinseq if type object in list tuple return join map lambda o c convert j join strseq o c j object else return convert object
def do_lzop_get creds url path decrypt do_retry True blobstore get_blobstore storage.StorageLayout url return blobstore.do_lzop_get creds url path decrypt do_retry do_retry
def split_fasta_on_sample_ids_to_dict seqs result {}for sample_id seq_id seq in split_fasta_on_sample_ids seqs try result[sample_id].append seq_id seq except KeyError result[sample_id] [ seq_id seq ]return result
def RenderToResponse handler template_file template_params template_params _GetDefaultParams template_params rendered _template.render _GetTemplatePath template_file template_params handler.response.out.write rendered
def allow_CORS_GET func @wraps func def _added_header request *args **kwargs response func request *args **kwargs if 'GET' request.method and switch_is_active 'application_ACAO' response['Access-Control-Allow-Origin'] '*'return responsereturn _added_header
def img_to_array img dim_ordering 'default' if dim_ordering 'default' dim_ordering K.image_dim_ordering if dim_ordering not in {'th' 'tf'} raise ValueError 'Unknowndim_ordering ' dim_ordering x np.asarray img dtype 'float32' if len x.shape 3 if dim_ordering 'th' x x.transpose 2 0 1 elif len x.shape 2 if dim_ordering 'th' x x.reshape 1 x.shape[0] x.shape[1] else x x.reshape x.shape[0] x.shape[1] 1 else raise ValueError 'Unsupportedimageshape ' x.shape return x
@register.tag 'timezone' def timezone_tag parser token bits token.split_contents if len bits ! 2 raise TemplateSyntaxError "'%s'takesoneargument timezone " % bits[0] tz parser.compile_filter bits[1] nodelist parser.parse 'endtimezone' parser.delete_first_token return TimezoneNode nodelist tz
def _get_context keyspaces connections if keyspaces if not isinstance keyspaces list tuple raise ValueError 'keyspacesmustbealistoratuple.' if connections if not isinstance connections list tuple raise ValueError 'connectionsmustbealistoratuple.' keyspaces keyspaces if keyspaces else [None] connections connections if connections else [None] return product connections keyspaces
def clean_translations sender **kwargs if hasattr _to_save 'translations' _to_save.translations {}
def _get_brew_commands brew_path_prefix brew_cmd_path brew_path_prefix + BREW_CMD_PATH return [name[ -3 ] for name in os.listdir brew_cmd_path if name.endswith '.rb' '.sh' ]
@facebook_required scope ['publish_actions' 'user_status'] def decorator_example_scope request graph if graph return HttpResponse 'authorized' else return HttpResponse 'userdeniedorerror'
def templates *args return js_helper 'static/scripts/templates/compiled/' *args
def safe_load stream return load stream SafeLoader
def optimize_providers providers tmp_providers {}optimized_providers {}for name data in six.iteritems providers if 'location' not in data data['location'] DEFAULT_LOCATIONif data['location'] not in tmp_providers tmp_providers[data['location']] {}creds data['id'] data['key'] if creds not in tmp_providers[data['location']] tmp_providers[data['location']][creds] {'name' name 'data' data}for location tmp_data in six.iteritems tmp_providers for creds data in six.iteritems tmp_data _id _key creds_name data['name']_data data['data']if _name not in optimized_providers optimized_providers[_name] _datareturn optimized_providers
def set_credit_requirements course_key requirements invalid_requirements _validate_requirements requirements if invalid_requirements invalid_requirements ' '.join invalid_requirements raise InvalidCreditRequirements invalid_requirements try credit_course CreditCourse.get_credit_course course_key course_key except CreditCourse.DoesNotExist raise InvalidCreditCourse old_requirements CreditRequirement.get_course_requirements course_key course_key requirements_to_disable _get_requirements_to_disable old_requirements requirements if requirements_to_disable CreditRequirement.disable_credit_requirements requirements_to_disable for order requirement in enumerate requirements CreditRequirement.add_or_update_course_requirement credit_course requirement order
def dict_merge a b result dict **b for key value in a.items if isinstance value collections.Mapping value dict_merge value result.setdefault key {} result[key] valuereturn result
def getmsg f extra_ns None must_pass False src '\n'.join _pytest._code.Code f .source .lines mod rewrite src code compile mod '<test>' 'exec' ns {}if extra_ns is not None ns.update extra_ns py.builtin.exec_ code ns func ns[f.__name__]try func except AssertionError if must_pass pytest.fail "shouldn'thaveraised" s str sys.exc_info [1] if not s.startswith 'assert' return 'AssertionError ' + s return selse if not must_pass pytest.fail "functiondidn'traiseatall"
@pytest.mark.parametrize 'verbose' [True False] def test_color_yes_collection_on_non_atty testdir verbose testdir.makepyfile "\nimportpytest\n@pytest.mark.parametrize 'i' range 10 \ndeftest_this i \nassert1\n" args ['--color yes']if verbose args.append '-vv' result testdir.runpytest *args assert 'testsessionstarts' in result.stdout.str assert '\x1b[1m' in result.stdout.str assert 'collecting10items' not in result.stdout.str if verbose assert 'collecting...' in result.stdout.str assert 'collected10items' in result.stdout.str
@commands u'setchanneltimeformat' u'setctf' @example u'.setctf%Y-%m-%dT%T%z' def update_channel_format bot trigger if bot.privileges[trigger.sender][trigger.nick] < OP returntformat trigger.group 2 if not tformat bot.reply u'Whatformatdoyouwantmetouse?Tryusinghttp //strftime.nettomakeone.' tz get_timezone bot.db bot.config None None trigger.sender old_format bot.db.get_channel_value trigger.sender u'time_format' bot.db.set_channel_value trigger.sender u'time_format' tformat try timef format_time db bot.db zone tz channel trigger.sender except bot.reply u"Thatformatdoesn'twork.Tryusinghttp //strftime.nettomakeone." bot.db.set_channel_value trigger.sender u'time_format' old_format returnbot.db.set_channel_value trigger.sender u'time_format' tformat bot.reply u'Gotit.Timesinthischannelwillnowappearas%sunlessauserhastheirownformatset. Ifthetimezoneiswrong youmighttrythesettzandchanneltzcommands ' % timef
def bitceil N if hasattr int 'bit_length' return 1 << int N - 1 .bit_length else N int N - 1 for i in [1 2 4 8 16 32] N | N >> i return N + 1
def parse_custom_num_formats root xmlns custom_formats {}num_fmts root.find QName xmlns 'numFmts' .text if num_fmts is not None num_fmt_nodes num_fmts.findall QName xmlns 'numFmt' .text for num_fmt_node in num_fmt_nodes custom_formats[int num_fmt_node.get 'numFmtId' ] num_fmt_node.get 'formatCode' return custom_formats
def pmin_sampled mean var n_samples 1000 rng None if rng is None rng numpy.random.RandomState 232342 samples rng.randn n_samples len mean * numpy.sqrt var + mean winners samples.T samples.min axis 1 .Twincounts winners.sum axis 0 assert wincounts.shape mean.shape return old_div wincounts.astype 'float64' wincounts.sum
def demo_template_statistics postag incremental_stats True template_stats True
def add_defaults var fun case_sensitive False var_items set DEFAULT_VARIABLES fun_items set DEFAULT_FUNCTIONS var_items.update var fun_items.update fun if not case_sensitive var_items set k.lower for k in var_items fun_items set k.lower for k in fun_items return var_items fun_items
def is_detach_process_context_required result Trueif is_process_started_by_init or is_process_started_by_superserver result Falsereturn result
def _parsed_version user None host None port None maintenance_db None password None runas None psql_version version user host host port port maintenance_db maintenance_db password password runas runas if psql_version return distutils.version.LooseVersion psql_version else log.warning 'AttempttoparseversionofPostgresserverfailed.Istheserverresponding?' return None
def gethostbyaddr ip_address return get_hub .resolver.gethostbyaddr ip_address
def minorticks_on gca .minorticks_on
def spawnu *args **kwargs kwargs.setdefault 'encoding' 'utf-8' return spawn *args **kwargs
@hug.get def made_up_hello return 'hello'
def test_save_load_save model DummyModel 1 monitor Monitor.get_monitor model num_examples 2num_features 3num_batches 1batch_size 2dataset DummyDataset num_examples num_features monitor.add_dataset dataset dataset num_batches num_batches batch_size batch_size vis_batch T.matrix mean vis_batch.mean data_specs monitor.model.get_input_space monitor.model.get_input_source monitor.add_channel name 'mean' ipt vis_batch val mean dataset dataset data_specs data_specs saved to_string monitor monitor from_string saved saved_again to_string monitor
def _DecodeValue pb_value val_type if val_type in _STRING_TYPES return _DecodeUTF8 pb_value return pb_value
def broadcast_to array shape return core.broadcast_to array shape
def _skew_symmetric_cross a return np.array [[0.0 - a[2] a[1]] [a[2] 0.0 - a[0] ] [ - a[1] a[0] 0.0]]
def clientFromString reactor description args kwargs _parse description aname args.pop 0 name aname.upper for plugin in getPlugins IStreamClientEndpointStringParser if plugin.prefix.upper name return plugin.parseStreamClient *args **kwargs if name not in _clientParsers raise ValueError 'Unknownendpointtype %r' % aname kwargs _clientParsers[name] *args **kwargs return _endpointClientFactories[name] reactor **kwargs
def encode_params params_dict encoded [ smart_str k smart_str v for k v in params_dict.items ]encoded_dict dict encoded return encoded_dict
def item_um_from_name name for um_pattern in um_patterns m re.search um_pattern name if m um m.group 1 .strip name re.sub um_pattern '' name name re.sub ' $' '' name .strip return name um return name None
def get_rng return _rng
def get_crawl_args message msg message.copy args [unicode_to_str msg['_spider'] ]del msg['_project'] msg['_spider']settings msg.pop 'settings' {} for k v in stringify_dict msg keys_only False .items args + ['-a']args + [ '%s %s' % k v ]for k v in stringify_dict settings keys_only False .items args + ['-s']args + [ '%s %s' % k v ]return args
def list_nictags include_etherstubs True ret {}nictagadm _check_nictagadm cmd '{nictagadm}list-d"|"-p{estubs}'.format nictagadm nictagadm estubs '-L' if not include_etherstubs else '' res __salt__['cmd.run_all'] cmd retcode res['retcode']if retcode ! 0 ret['Error'] res['stderr'] if 'stderr' in res else 'Failedtogetlistofnictags.' else header ['name' 'macaddress' 'link' 'type']for nictag in res['stdout'].splitlines nictag nictag.split '|' nictag_data {}for field in header nictag_data[field] nictag[header.index field ]ret[nictag_data['name']] nictag_datadel ret[nictag_data['name']]['name']return ret
def isImageType t return hasattr t 'im'
def initial_password email if settings.INITIAL_PASSWORD_SALT is not None encoded_key settings.INITIAL_PASSWORD_SALT + email .encode 'utf-8' digest hashlib.sha256 encoded_key .digest return base64.b64encode digest [ 16].decode 'utf-8' else return None
def ndarray_print nd try x nd.tolist except TypeError NotImplementedError x nd.tobytes if isinstance nd ndarray offset nd.offsetflags nd.flagselse offset 'unknown'flags 'unknown'print "ndarray %s shape %s strides %s suboffsets %s offset %s format '%s' itemsize %s flags %s " % x nd.shape nd.strides nd.suboffsets offset nd.format nd.itemsize flags sys.stdout.flush
def service_model service return {'name' service.name 'admin' service.admin 'url' service.url 'prefix' service.server.base_url if service.server else '' 'command' service.command 'pid' service.proc.pid if service.proc else 0 }
def _conn queue queue_dir __opts__['sqlite_queue_dir']db os.path.join queue_dir '{0}.db'.format queue log.debug 'Connectingto {0}'.format db con lite.connect db tables _list_tables con if queue not in tables _create_table con queue return con
def GetRunlevelsNonLSB states if not states return set convert_table {'0' '0' '1' '1' '2' '2' '3' '3' '4' '4' '5' '5' '6' '6' 'S' '1' 's' '1'}_LogInvalidRunLevels states convert_table return set [convert_table[s] for s in states.split if s in convert_table ]
def initTargetSet schemata size test_set []for _ in range size test list random.randint 0 1 for _ in range len schemata for i x in enumerate schemata if x '0' test[i] 0elif x '1' test[i] 1test_set.append test return test_set
def parse_reftuples lh_container rh_container refspecs if not isinstance refspecs list refspecs [refspecs]ret []for refspec in refspecs ret.append parse_reftuple lh_container rh_container refspec return ret
@task@needs 'generate_setup' 'minilib' 'get_source' 'virtualenv' def env_install venv options.virtualenvcall [ path venv.dir / 'bin' / 'easy_install' '.']
def corr2cov corr std corr np.asanyarray corr std_ np.asanyarray std cov corr * np.outer std_ std_ return cov
def p_logical_or_expression_1 t pass
def _get_normal_name orig_enc enc orig_enc[ 12].lower .replace '_' '-' if enc 'utf-8' or enc.startswith 'utf-8-' return 'utf-8'if enc in 'latin-1' 'iso-8859-1' 'iso-latin-1' or enc.startswith 'latin-1-' 'iso-8859-1-' 'iso-latin-1-' return 'iso-8859-1'return orig_enc
def get_pxe_config_file_path instance return os.path.join CONF.baremetal.tftp_root instance['uuid'] 'config'
def parse_type attrtype uattribute attrtype.lower .strip if uattribute[0] '{' return 'nominal'elif uattribute[ len 'real' ] 'real' return 'numeric'elif uattribute[ len 'integer' ] 'integer' return 'numeric'elif uattribute[ len 'numeric' ] 'numeric' return 'numeric'elif uattribute[ len 'string' ] 'string' return 'string'elif uattribute[ len 'relational' ] 'relational' return 'relational'elif uattribute[ len 'date' ] 'date' return 'date'else raise ParseArffError 'unknownattribute%s' % uattribute
def new_thread_mails post users_and_watches post_url add_utm post.thread.get_absolute_url 'kbforums-thread' c {'post' post.content 'post_html' post.content_parsed 'author' post.creator 'host' Site.objects.get_current .domain 'thread' post.thread.title 'forum' post.thread.document.title 'post_url' post_url}return emails_with_users_and_watches subject _lazy u'{forum}-{thread}' text_template 'kbforums/email/new_thread.ltxt' html_template 'kbforums/email/new_thread.html' context_vars c users_and_watches users_and_watches
def to_fs_from_unicode unic if is_unicode unic try string unic.encode FS_ENCODING except UnicodeError TypeError passelse return stringreturn unic
def formatUIDListLines msgs getUidl for i m in enumerate msgs if m is not None uid getUidl i yield '%d%s\r\n' % i + 1 uid
def _stride stride_spec if stride_spec is None return [1 1 1 1]elif isinstance stride_spec int return [1 stride_spec stride_spec 1]elif len stride_spec 1 return [1 stride_spec[0] stride_spec[0] 1]elif len stride_spec 2 return [1 stride_spec[0] stride_spec[1] 1]else assert len stride_spec 4 return stride_spec
def HA1 realm username password algorithm if not realm realm u''return H ' '.join [username.encode 'utf-8' realm.encode 'utf-8' password.encode 'utf-8' ] algorithm
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def compare_version v1 v2 s1 StrictVersion v1 s2 StrictVersion v2 if s1 s2 return 0elif s1 > s2 return -1 else return 1
def proplist root fn result []for path in propfiles root fn try f open path except IOError continuewhile 1 line f.readline if line.startswith 'END' breakassert line.startswith 'K' L int line.split [1] key f.read L result.append key f.readline line f.readline assert line.startswith 'V' L int line.split [1] value f.read L f.readline f.close return result
@cache_permissiondef can_upload_dictionary user project return check_permission user project 'trans.upload_dictionary'
def lock_parent_directory filename timeout 10 return lock_path os.path.dirname filename timeout timeout
def get_os_name_from_eol_chars eol_chars for chars os_name in EOL_CHARS if eol_chars chars return os_name
def test_set_join_node tmpdir os.chdir str tmpdir wf pe.Workflow name u'test' inputspec pe.Node IdentityInterface fields [u'n'] name u'inputspec' inputspec.iterables [ u'n' [1 2 1 3 2] ]pre_join1 pe.Node IncrementInterface name u'pre_join1' wf.connect inputspec u'n' pre_join1 u'input1' join pe.JoinNode SetInterface joinsource u'inputspec' joinfield u'input1' name u'join' wf.connect pre_join1 u'output1' join u'input1' wf.run assert _set_len 3 u'ThejoinSetoutputvalueisincorrect %s.' % _set_len
def test_basic_call_on_method_through_api_instance_coroutine class API object def hello_world self return 'HelloWorld!'api_instance API @hug.call @asyncio.coroutinedef hello_world return api_instance.hello_world assert api_instance.hello_world 'HelloWorld!' assert hug.test.get api '/hello_world' .data 'HelloWorld!'
def _set_window_time slices times t_idx_ [t[ -1 ] for t in slices]return times[t_idx_]
def mrv_max3 f expsf g expsg union expsboth x if not isinstance f SubsSet raise TypeError 'fshouldbeaninstanceofSubsSet' if not isinstance g SubsSet raise TypeError 'gshouldbeaninstanceofSubsSet' if f SubsSet return g expsg elif g SubsSet return f expsf elif f.meets g return union expsboth c compare list f.keys [0] list g.keys [0] x if c '>' return f expsf elif c '<' return g expsg else if c ! ' ' raise ValueError 'cshouldbe ' return union expsboth
def resident since 0.0 return _VmB 'VmRSS ' - since
def test_find_package_not_found result search_packages_info ['abcd3'] assert len list result 0
def hr_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'hrm' 'human_resource'
def p_command_let_bad p p[0] 'BADEXPRESSIONINLET'
def GetUserAgent product_tokens []product_tokens.append 'Google-remote_api/1.0' product_tokens.append appengine_rpc.GetPlatformToken python_version '.'.join str i for i in sys.version_info product_tokens.append 'Python/%s' % python_version return ''.join product_tokens
def dataset_id_from_name name return unicode UUID bytes md5 name.encode u'utf-8' .digest version 4
def _onset_to_seconds raw onset meas_date raw.info['meas_date']if meas_date is None meas_date 0elif not np.isscalar meas_date if len meas_date > 1 meas_date meas_date[0] + meas_date[1] / 1000000.0 else meas_date meas_date[0]if raw.annotations.orig_time is None orig_time meas_dateelse orig_time raw.annotations.orig_time - raw._first_time annot_start orig_time - meas_date + onset return annot_start
def get_exporter name return EXPORTERS[name]
@set_databasedef get_or_create item **kwargs if item return Item.create_or_get **parse_model_data item
def merge_environments environment_files files params param_schemata if not environment_files returnavailable_strategies {}for filename in environment_files raw_env files[filename]parsed_env env_fmt.parse raw_env strategies_in_file parsed_env.pop env_fmt.PARAMETER_MERGE_STRATEGIES {} for section_key section_value in parsed_env.items if section_value if section_key in env_fmt.PARAMETERS env_fmt.PARAMETER_DEFAULTS params[section_key] new_strategies merge_parameters params[section_key] section_value param_schemata strategies_in_file available_strategies filename available_strategies.update new_strategies else params[section_key] merge_map params[section_key] section_value
def presentStimulus direction win.fps startPhase num.random.random if direction 1 frameIndices num.arange 0 4 else frameIndices num.arange 3 -1 -1 for cycles in range cyclesTime for ii in frameIndices thisStim stimFrames[ii]thisStim.setPhase startPhase for n in range nFrames thisStim.draw win.flip win.flip
def _check_fmdump return salt.utils.which 'fmdump'
def find_files roots generated_resources None ignored_patterns IGNORED_PATTERNS ignored_dirs IGNORED_DIRS ignored_path_regexps IGNORED_PATH_REGEXPS allowed_extensions None if generated_resources is None generated_resources set if isinstance roots string_types roots [roots]if isinstance allowed_extensions string_types allowed_extensions set [allowed_extensions] for root in roots for path dirs files in os.walk root path posixpath.normpath path.replace os.sep '/' _remove_ignored_directories path dirs ignored_dirs ignored_path_regexps for filename in files filepath posixpath.join path filename if filename 'generated_resources.txt' _process_generated_resources path filepath generated_resources continueif not all not fnmatch.fnmatch filename x for x in ignored_patterns continueif not _check_allowed_extension filepath allowed_extensions continue yield filepath
def getBottomByPaths paths bottom 9.876543219876543e+17for path in paths for point in path bottom min bottom point.z return bottom
def attempt_bc_correction curr_bc all_bcs barcode_type 'golay_12' corrected_bc get_exact_bc_matches curr_bc all_bcs if corrected_bc return corrected_bc 0 if barcode_type 'golay_12' corrected_bc num_errors decode_golay_12 curr_bc elif barcode_type 'hamming_8' corrected_bc num_errors decode_barcode_8 curr_bc elif barcode_type 0 corrected_bc num_errors '' 0 else corrected_bc num_errors correct_barcode curr_bc all_bcs return corrected_bc num_errors
def partition_list_journal return ceph_cfg.partition_list_journal
def result_to_city result country region if 'city' in result mapbox_city result['city']lookup_args {'name' mapbox_city['name'] 'country' country 'region' region}args {'mapbox_id' mapbox_city['id'] 'lat' mapbox_city['lat'] 'lng' mapbox_city['lon']}args.update lookup_args query Q **lookup_args | Q mapbox_id mapbox_city['id'] city_qs City.objects.filter query .distinct if city_qs.exists if city_qs.count 2 deduplicate_cities city_qs[0] city_qs[1] city_qs.update **args city city_qs[0]else city City.objects.create **args return city
def _generateX random bits while True x _getRandomNumber random bits if 2 < x < 2 ** bits - 2 return x
def executed patchmodule if patchmodule.startswith u'finally ' patchmodule patchmodule.replace u'finally ' u'' done frappe.db.get_value u'PatchLog' {u'patch' patchmodule} return done
def conv3d input filters input_shape None filter_shape None border_mode 'valid' subsample 1 1 1 filter_flip True filter_dilation 1 1 1 input as_tensor_variable input filters as_tensor_variable filters conv_op AbstractConv3d imshp input_shape kshp filter_shape border_mode border_mode subsample subsample filter_flip filter_flip filter_dilation filter_dilation return conv_op input filters
def send_reply exchange req msg producer None retry False retry_policy None **props return producer.publish msg exchange exchange retry retry retry_policy retry_policy **dict {u'routing_key' req.properties[u'reply_to'] u'correlation_id' req.properties.get u'correlation_id' u'serializer' serializers.type_to_name[req.content_type] u'content_encoding' req.content_encoding} **props
def get_line_style line style {}style['alpha'] line.get_alpha if style['alpha'] is None style['alpha'] 1style['color'] color_to_hex line.get_color style['linewidth'] line.get_linewidth style['dasharray'] get_dasharray line style['zorder'] line.get_zorder return style
@utils.arg 'id' metavar '<id>' help _ 'UniqueIDoftheservergrouptoget.' def do_server_group_get cs args server_group cs.server_groups.get args.id _print_server_group_details cs [server_group]
def toggle_log module number file_loc None toggle False mod mod_inst get_mod_num module number if not mod is None and not mod_inst is None and hasattr HOUSE[mod][mod_inst] 'log' if toggle HOUSE[mod][mod_inst].log True file_loc else HOUSE[mod][mod_inst].log False else Error "Moduledoesnothavealoggerordoesn'texist."
def download_and_uncompress_tarball tarball_url dataset_dir filename tarball_url.split '/' [ -1 ]filepath os.path.join dataset_dir filename def _progress count block_size total_size sys.stdout.write '\r>>Downloading%s%.1f%%' % filename float count * block_size / float total_size * 100.0 sys.stdout.flush filepath _ urllib.request.urlretrieve tarball_url filepath _progress print statinfo os.stat filepath print 'Successfullydownloaded' filename statinfo.st_size 'bytes.' tarfile.open filepath 'r gz' .extractall dataset_dir
def get_draft_moderator_action_email intent try require_moderator_email_prereqs_are_satisfied return _get_email_config intent .valueexcept Exception return ''
@post '/option/<taskid>/set' def option_set taskid if taskid not in DataStore.tasks logger.warning '[%s]InvalidtaskIDprovidedtooption_set ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} for option value in request.json.items DataStore.tasks[taskid].set_option option value logger.debug '[%s]Requestedtosetoptions' % taskid return jsonize {'success' True}
def jira registry xml_parent data XML.SubElement xml_parent 'hudson.plugins.jira.JiraIssueUpdater'
def top_contributors_questions start None end None locale None product None count 10 page 1 query AnswerMetricsMappingType.search .facet 'creator_id' filtered True size BIG_NUMBER query query.filter by_asker False query _apply_filters query start end locale product return _get_creator_counts query count page
def _isinfinity num num str num .lower return _infinity_map.get num 0
def _base_args config args ['--debug' '--json-logging' '--no-err-windows']if config.webengine args + ['--backend' 'webengine']else args + ['--backend' 'webkit']args.append 'about blank' return args
def _get_all_recipient_ids exploration_id thread_id author_id exploration_rights rights_manager.get_exploration_rights exploration_id owner_ids set exploration_rights.owner_ids participant_ids get_all_thread_participants exploration_id thread_id sender_id set [author_id] batch_recipient_ids owner_ids - sender_id other_recipient_ids participant_ids - batch_recipient_ids - sender_id return batch_recipient_ids other_recipient_ids
def grid_points_in_poly shape verts return _grid_points_in_poly shape verts
def test_type___clrtype__ Assert hasattr type '__clrtype__' if not is_netstandard Assert 'Getsthe.NETtypewhichis' in type.__clrtype__.__doc__ type.__clrtype__.__doc__ AreEqual type.__clrtype__ type type AreEqual type.__clrtype__ float float AreEqual type.__clrtype__ System.Double float AreEqual type.__clrtype__ float System.Double Assert not type.__clrtype__ float type Assert type.__clrtype__ float ! type
def escape_cell cell cell cell.replace u'\\' u'\\\\' cell cell.replace u'\n' u'\\n' cell cell.replace u'|' u'\\|' return cell
def test_normal_basic yield check_normal_basic False yield check_normal_basic False True yield check_normal_basic True
def _convert_ascii_format format reverse False if reverse recformat kind dtype _dtype_to_recformat format itemsize dtype.itemsizeif kind 'a' return 'A' + str itemsize elif NUMPY2FITS.get recformat 'L' return 'A1'elif kind 'i' width 1 + len str 2 ** itemsize * 8 width max width ASCII_DEFAULT_WIDTHS['I'][0] return 'I' + str width elif kind 'f' if itemsize > 8 format 'D'else format 'E'width '.'.join str w for w in ASCII_DEFAULT_WIDTHS[format] return format + width else format width precision _parse_ascii_tformat format recformat ASCII2NUMPY[format]if format 'I' and width < 4 recformat 'i2'elif format 'A' recformat + str width return recformat
def algorithm_list return ['metagenomeSeq_fitZIG' 'DESeq2_nbinom']
@cleanupdef test__EventCollection__get_lineoffset _ coll props generate_EventCollection_plot assert_equal props[u'lineoffset'] coll.get_lineoffset
def normalize_fieldsets fieldsets result []for name options in fieldsets result.append name normalize_dictionary options return result
def delete_org orgid profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile response requests.delete '{0}/api/orgs/{1}'.format profile['grafana_url'] orgid auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def handle_reset request for rec in Record.objects.outstanding rec.mark_fail 'Cancelled.' return HttpResponseRedirect request.path
def connected return {'out' __proxy__['napalm.ping'] }
def max_layout_dimensions dimensions min_ max [d.min for d in dimensions if d.min is not None ] max_ max [d.max for d in dimensions if d.max is not None ] preferred max [d.preferred for d in dimensions] return LayoutDimension min min_ max max_ preferred preferred
def html_escape t html_escape_table {'&' '&amp;' '"' '&quot;' "'" '&#039;' '>' '&gt;' '<' '&lt;'}return ''.join html_escape_table.get c c for c in t
def _labels_inertia X x_squared_norms centers precompute_distances True distances None n_samples X.shape[0]labels - np.ones n_samples np.int32 if distances is None distances np.zeros shape 0 dtype X.dtype if sp.issparse X inertia _k_means._assign_labels_csr X x_squared_norms centers labels distances distances else if precompute_distances return _labels_inertia_precompute_dense X x_squared_norms centers distances inertia _k_means._assign_labels_array X x_squared_norms centers labels distances distances return labels inertia
def ext_on_list name lst for ext in lst if name.rfind ext > 0 return Truereturn False
def solve_linear_system_LU matrix syms if matrix.rows ! matrix.cols - 1 raise ValueError 'Rowsshouldbeequaltocolumns-1' A matrix[ matrix.rows matrix.rows]b matrix[ matrix.cols - 1 ]soln A.LUsolve b solutions {}for i in range soln.rows solutions[syms[i]] soln[ i 0 ]return solutions
def is_git_repo sourcepath os.path.realpath os.path.join os.path.dirname nipype.__file__ os.path.pardir gitpathgit os.path.join sourcepath u'.git' if os.path.exists gitpathgit return Trueelse return False
def get_rect_ymin data return min data[0][1] data[1][1] data[2][1] data[3][1]
def exec_python *args **kwargs cmdargs kwargs __wrap_python args kwargs return exec_command *cmdargs **kwargs
def _get_table_list from django.db import connection get_introspection_modulecursor connection.cursor return get_introspection_module .get_table_list cursor
def test_dbnull if is_netstandard clr.AddReference 'System.Data.Common' if System.DBNull.Value AssertUnreachable
def rotate_naive lst dist lst[ ] lst[dist len lst ] + lst[0 dist]
def write_forward_meas_info fid info info._check_consistency start_block fid FIFF.FIFFB_MNE_PARENT_MEAS_FILE write_string fid FIFF.FIFF_MNE_FILE_NAME info['meas_file'] if info['meas_id'] is not None write_id fid FIFF.FIFF_PARENT_BLOCK_ID info['meas_id'] meg_head_t info.get 'dev_head_t' info.get 'ctf_head_t' if meg_head_t is None fid.close raise ValueError 'Head<-->sensortransformnotfound' write_coord_trans fid meg_head_t if 'chs' in info write_int fid FIFF.FIFF_NCHAN len info['chs'] for k c in enumerate info['chs'] c deepcopy c c['scanno'] k + 1 write_ch_info fid c if 'bads' in info and len info['bads'] > 0 start_block fid FIFF.FIFFB_MNE_BAD_CHANNELS write_name_list fid FIFF.FIFF_MNE_CH_NAME_LIST info['bads'] end_block fid FIFF.FIFFB_MNE_BAD_CHANNELS end_block fid FIFF.FIFFB_MNE_PARENT_MEAS_FILE
def remove_pad buf if len buf > 0 and len buf % 16 0 encrypted_key buf[ 5]key xor encrypted_key bytes [19 51 123 238 240] dec xor buf key return dec[5 20]
def n name return objc.sel_registerName _utf8 name
def getMininetVersion vm vm.sendline '~/mininet/bin/mn--version' vm.readline version vm.readline .strip return version
def in6_ptop str return inet_ntop socket.AF_INET6 inet_pton socket.AF_INET6 str
def get_pdata_path base_name recurs base_name base_name.replace os.sep '_' return join PYLINT_HOME '%s%s%s' % base_name recurs '.stats'
def decode_return codec 'ascii' def outer f def wrap *args **kwargs res f *args **kwargs if res is not None return res.decode codec return resreturn wrapreturn outer
def quadratic batch_size 128 num_dims 10 stddev 0.01 dtype tf.float32 def build 'Buildslossgraph.'x tf.get_variable 'x' shape [batch_size num_dims] dtype dtype initializer tf.random_normal_initializer stddev stddev w tf.get_variable 'w' shape [batch_size num_dims num_dims] dtype dtype initializer tf.random_uniform_initializer trainable False y tf.get_variable 'y' shape [batch_size num_dims] dtype dtype initializer tf.random_uniform_initializer trainable False product tf.squeeze tf.batch_matmul w tf.expand_dims x -1 return tf.reduce_mean tf.reduce_sum product - y ** 2 1 return build
@decorator.decoratordef convert_masks_to_RGB f clip *a **k if clip.ismask clip clip.to_RGB return f clip *a **k
def find_and_assign_anonymous_cart request queryset Cart.objects.all token request.get_signed_cookie Cart.COOKIE_NAME default None if not token returncart get_anonymous_cart_from_token token token cart_queryset queryset if cart is None returncart.change_user request.user carts_to_close Cart.objects.open .filter user request.user carts_to_close carts_to_close.exclude token token carts_to_close.update status Cart.CANCELED last_status_change now
def common_subexpression expr *exprs if not exprs return exprexprs expr + exprs all_leaves [expr._leaves for expr in exprs]leaves set.intersection *map set all_leaves if not leaves raise ValueError 'Nocommonleavesfoundinexpressions%s' % list exprs pathlist [list path expr leaf for expr in exprs for leaf in leaves]common reduce ordered_intersect pathlist if not common raise ValueError 'Nocommonsubexpressionfoundinpathstoleaf %s' % list map set pathlist return first common
def db_asset_add **kwargs group_id_list kwargs.pop 'groups' asset Asset **kwargs asset.save group_select []for group_id in group_id_list group AssetGroup.objects.filter id group_id group_select.extend group asset.group group_select
def IsSurroundedByBrackets tok paren_count 0brace_count 0sq_bracket_count 0previous_token tok.previous_tokenwhile previous_token if previous_token.value ' ' paren_count - 1elif previous_token.value '}' brace_count - 1elif previous_token.value ']' sq_bracket_count - 1if previous_token.value ' ' if paren_count 0 return Trueparen_count + 1elif previous_token.value '{' if brace_count 0 return Truebrace_count + 1elif previous_token.value '[' if sq_bracket_count 0 return Truesq_bracket_count + 1previous_token previous_token.previous_tokenreturn False
def sanitize_index ind if isinstance ind Number ind2 int ind if ind2 ! ind raise IndexError 'Badindex.Mustbeinteger-like %s' % ind else return ind2if hasattr ind 'tolist' ind ind.tolist if isinstance ind list and ind and isinstance ind[0] bool ind [a for a b in enumerate ind if b]return indif isinstance ind list return [sanitize_index i for i in ind]if isinstance ind slice return slice sanitize_index ind.start sanitize_index ind.stop sanitize_index ind.step if ind is None return indtry return sanitize_index np.array ind .tolist except raise TypeError 'Invalidindextype' type ind ind
def getFilesWithFileTypeWithoutWords fileType words [] fileInDirectory '' filesWithFileType []for filePath in getFilePaths fileInDirectory if isFileWithFileTypeWithoutWords fileType filePath words filesWithFileType.append filePath filesWithFileType.sort return filesWithFileType
def autoencoder_results hidden_units training_data test_inputs actual_test_results mnist_loader.load_data_nn net train_autoencoder hidden_units training_data plot_test_results net test_inputs
def make_test_program_class extra_tests class PystacheTestProgram TestProgram '\nInstantiatinganinstanceofthisclassrunsalltests.\n\n'def createTests self '\nLoadtestsandsetself.testtoaunittest.TestSuiteinstance\n\nCompare--\n\nhttp //docs.python.org/library/unittest.html#unittest.TestSuite\n\n'super PystacheTestProgram self .createTests self.test.addTests extra_tests return PystacheTestProgram
def add_pool_member lb name port pool_name if __opts__['load_balancers'].get lb None username password list __opts__['load_balancers'][lb].values else raise Exception 'Unabletofind`{0}`loadbalancer'.format lb F5 F5Mgmt lb username password F5.add_pool_member name port pool_name return True
def LoadWindowSize section state '' if state state state + '' left win32ui.GetProfileVal section state + 'left' 0 top win32ui.GetProfileVal section state + 'top' 0 right win32ui.GetProfileVal section state + 'right' 0 bottom win32ui.GetProfileVal section state + 'bottom' 0 return left top right bottom
def dmp_irreducible_p f u K _ factors dmp_factor_list f u K if not factors return Trueelif len factors > 1 return Falseelse _ k factors[0]return k 1
def _get_dtype dtype if np.issubdtype dtype np.complexfloating return np.complex_else return np.float_
def _default_logfile exe_name if salt.utils.is_windows tmp_dir os.path.join __opts__['cachedir'] 'tmp' if not os.path.isdir tmp_dir os.mkdir tmp_dir logfile_tmp tempfile.NamedTemporaryFile dir tmp_dir prefix exe_name suffix '.log' delete False logfile logfile_tmp.namelogfile_tmp.close else logfile salt.utils.path_join '/var/log' '{0}.log'.format exe_name return logfile
def textFileLogObserver outFile timeFormat timeFormatRFC3339 def formatEvent event return formatEventAsClassicLogText event formatTime lambda e formatTime e timeFormat return FileLogObserver outFile formatEvent
def entropy image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._entropy image selem out out mask mask shift_x shift_x shift_y shift_y out_dtype np.double
@click.command 'set-url-root' @click.argument 'site' @click.argument 'url-root' def set_url_root site url_root from bench.config.site_config import set_url_rootset_url_root site url_root
def assert_datetime_equal dt1 dt2 allowance 500 assert abs dt1 - dt2 < dt.timedelta milliseconds allowance
def initIterate container generator return container generator
def group_creating_from_src group_id None group_snapshot_id None return IMPL.group_creating_from_src group_id group_snapshot_id
def recurrence_term c f return sum c[i] * f.subs n n + i for i in range len c
def capture_journal reactor host output_file def get_journald_output formatter journald_json_formatter output_file ran run_ssh reactor reactor host host username 'root' command ['journalctl' '--lines' '0' '--output' 'export' '--follow' '-u' 'docker' '-u' 'flocker-control' '-u' 'flocker-dataset-agent' '-u' 'flocker-container-agent' '-u' 'flocker-docker-plugin'] handle_stdout formatter ran.addErrback write_failure logger None ran.addCallback lambda ignored formatter '' return ranreturn loop_until reactor get_journald_output repeat 2.0
def attach_public_projects_same_owner queryset user as_field 'public_projects_same_owner_attr' model queryset.modelif user is None or user.is_anonymous sql 'SELECT0'else sql '\nSELECTCOUNT id \nFROMprojects_projectp_aux\nWHEREp_aux.is_private FalseAND\np_aux.owner_id {tbl}.owner_id\n'sql sql.format tbl model._meta.db_table user_id user.id queryset queryset.extra select {as_field sql} return queryset
def asciify_path path sep_replace if os.altsep path path.replace os.altsep os.sep path_components path.split os.sep for index item in enumerate path_components path_components[index] unidecode item .replace os.sep sep_replace if os.altsep path_components[index] unidecode item .replace os.altsep sep_replace return os.sep.join path_components
def nl s if not isinstance s string_types return sreturn s.replace '\n' os.linesep
@with_sessiondef log_once message logger logging.getLogger u'log_once' once_level logging.INFO suppressed_level f_logger.VERBOSE session None from flexget.manager import managerif not manager log.warning u'DBnotinitialized.log_oncewillnotworkproperly.' logger.log once_level message returndigest hashlib.md5 digest.update message.encode u'latin1' u'replace' md5sum digest.hexdigest if session.query LogMessage .filter_by md5sum md5sum .first logger.log suppressed_level message return Falserow LogMessage md5sum session.add row logger.log once_level message return True
def diagonal a offset 0 axis1 0 axis2 1 return a.diagonal offset axis1 axis2
def get_all_creators_to_which_learner_has_subscribed user_id subscriptions_model user_models.UserSubscriptionsModel.get user_id strict False return subscriptions_model.creator_ids if subscriptions_model else []
def redirect_request_processor page request target page.get_redirect_to_target request if target extra_path request._feincms_extra_context.get u'extra_path' u'/' if extra_path u'/' return HttpResponseRedirect target logger.debug u"Pageredirecton'%s'nottakenbecauseextrapath'%s'present" page.get_absolute_url extra_path raise Http404
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def safe_dumps *args **kwargs try dumped json.dumps allow_nan False *args **kwargs except ValueError obj swap_inf_nan copy.deepcopy args[0] dumped json.dumps obj allow_nan False **kwargs if kwargs.get 'escape_closing_tags' True return dumped.replace '</' '<\\/' return dumped
def SmartUnicode string if type string ! unicode try return string.__unicode__ except AttributeError UnicodeError return str string .decode 'utf8' 'ignore' return string
def hist_fig hist_data plot_height plot_width x_range None epoch_axis True name hdata dh dw bins offset hist_dataif x_range is None x_range 0 dw fig figure plot_height plot_height plot_width plot_width title name x_axis_label x_label epoch_axis x_range x_range y_range offset offset + bins fig.image image [hdata] x [0] y [offset] dw [dw] dh [dh] palette 'Spectral11' return fig
def FindTlbsWithDescription desc ret []items EnumTlbs for item in items if item.desc desc ret.append item return ret
def badfetch_mail msg url parm {'url' url 'msg' msg}return send_with_template 'badfetch' parm
def raw_file request attachment_id filename qs Attachment.objects.select_related 'current_revision' attachment get_object_or_404 qs pk attachment_id if attachment.current_revision is None raise Http404if request.get_host settings.ATTACHMENT_HOST rev attachment.current_revisionif settings.DEBUG rev.file.read rev.file.DEFAULT_CHUNK_SIZE response StreamingHttpResponse rev.file content_type rev.mime_type response['Last-Modified'] convert_to_http_date rev.created try response['Content-Length'] rev.file.sizeexcept OSError passresponse['X-Frame-Options'] 'ALLOW-FROM%s' % settings.DOMAIN return responseelse return redirect attachment.get_file_url permanent True
def summary_stats curve periods total_return curve['networth'][ -1 ]returns curve['returns']pnl curve['networth']sharpe sharpe_ratio returns periods max_dd dd_duration max_drawdown pnl stats [ 'TotalReturn' '%0.2f%%' % total_return - 1.0 * 100.0 'SharpeRatio' '%0.2f' % sharpe 'MaxDrawdown' '%0.2f%%' % max_dd * 100.0 'DrawdownDuration' '%d' % dd_duration ]return stats
def chall_to_challb chall status kwargs {'chall' chall 'uri' chall.typ + '_uri' 'status' status}if status messages.STATUS_VALID kwargs.update {'validated' datetime.datetime.now } return messages.ChallengeBody **kwargs
def get_node_attributes G name return {n d[name] for n d in G.node.items if name in d }
def page_from_word word return page_from_reference Reference word
def AuthSubTokenFromUrl url token TokenFromUrl url if token return 'AuthSubtoken %s' % token return None
def GenerateAuthSubRequestUrl next scopes hd 'default' secure False session True request_url 'https //www.google.com/accounts/AuthSubRequest' include_scopes_in_next True if isinstance scopes list scope ''.join scopes else scope scopesif include_scopes_in_next if next.find '?' > -1 next + '&%s' % urllib.urlencode {SCOPE_URL_PARAM_NAME scope} else next + '?%s' % urllib.urlencode {SCOPE_URL_PARAM_NAME scope} return gdata.auth.GenerateAuthSubUrl next next scope scope secure secure session session request_url request_url domain hd
def getComplexPathByMultiplier multiplier path complexPath []for point in path complexPath.append multiplier * point return complexPath
def get_values cluster if is_leaf cluster return clusterelse return [value for child in get_children cluster for value in get_values child ]
def format_summary_line web_url user base tip branch node revcount tip - base plural 's' if revcount > 1 else '' if web_url shortlog_base_url web_url.rstrip '/' + '/shortlog/' summary_url '{shortlog}{tip}?revcount {revcount}'.format shortlog shortlog_base_url tip tip - 1 revcount revcount formatted_commit_count '[{revcount}commit{s}] {url} '.format revcount revcount s plural url summary_url else formatted_commit_count '{revcount}commit{s}'.format revcount revcount s plural return u'**{user}**pushed{commits}to**{branch}** `{tip} {node}` \n\n'.format user user commits formatted_commit_count branch branch tip tip node node[ 12]
def usergroup_update usrgrpid **connection_args conn_args _login **connection_args try if conn_args method 'usergroup.update'params {'usrgrpid' usrgrpid}params _params_extend params **connection_args ret _query method params conn_args['url'] conn_args['auth'] return ret['result']['usrgrpids']else raise KeyErrorexcept KeyError return ret
def compute_md5 fp buf_size 8192 size None return compute_hash fp buf_size size hash_algorithm md5
def render_cert_by_uuid request certificate_uuid try certificate GeneratedCertificate.eligible_certificates.get verify_uuid certificate_uuid status CertificateStatuses.downloadable return render_html_view request certificate.user.id unicode certificate.course_id except GeneratedCertificate.DoesNotExist raise Http404
def get_monitors_and_dependencies account monitor_names debug False monitors all_monitors account debug monitor_names _find_dependent_monitors monitors monitor_names requested_mons []for mon in monitors if mon.watcher.index in monitor_names requested_mons.append mon return requested_mons
def clean_string text if isinstance text six.string_types return text.translate UNI_SPECIAL_CHARS .strip return text.translate None STR_SPECIAL_CHARS .strip
def addFacesGivenText stlText triangleMesh vertexIndexTable lines archive.getTextLines stlText vertexes []for line in lines if line.find 'vertex' ! -1 vertexes.append getVertexGivenLine line addFacesGivenVertexes triangleMesh vertexIndexTable vertexes
def _stream_requests sample language_code None max_alternatives None profanity_filter None speech_context None single_utterance None interim_results None config_request _make_streaming_request sample language_code language_code max_alternatives max_alternatives profanity_filter profanity_filter speech_context SpeechContext phrases speech_context single_utterance single_utterance interim_results interim_results yield config_request while True data sample.stream.read sample.chunk_size if not data break yield StreamingRecognizeRequest audio_content data
def solve a b try return linalg.solve a b except linalg.LinAlgError return np.dot linalg.pinv a b
def getTokensEndLoc import inspectfstack inspect.stack try for f in fstack[2 ] if f[3] '_parseNoCache' endloc f[0].f_locals['loc']return endlocelse raise ParseFatalException 'incorrectusageofgetTokensEndLoc-mayonlybecalledfromwithinaparseaction' finally del fstack
def CheckProperty request_trusted request_app_id prop indexed True name prop.name value prop.value meaning prop.meaning Check request_trusted or not datastore_types.RESERVED_PROPERTY_NAME.match name "cannotstoreentitywithreservedpropertyname'%s'" % name Check prop.meaning ! entity_pb.Property.INDEX_VALUE 'Entitieswithincompletepropertiescannotbewritten.' is_blob meaning in _BLOB_MEANINGS if indexed Check not is_blob 'BLOB ENITY_PROTOorTEXTproperty' + name + 'mustbeinaraw_propertyfield' max_length datastore_types._MAX_STRING_LENGTHelse if is_blob Check value.has_stringvalue 'BLOB/ENTITY_PROTO/TEXTrawproperty' + name + 'musthaveastringvalue' max_length datastore_types._MAX_RAW_PROPERTY_BYTESif meaning entity_pb.Property.ATOM_LINK max_length datastore_types._MAX_LINK_PROPERTY_LENGTHCheckPropertyValue name value max_length
def list_teams profile 'github' ignore_cache False key 'github.{0} teams'.format _get_config_value profile 'org_name' if key not in __context__ or ignore_cache client _get_client profile organization client.get_organization _get_config_value profile 'org_name' teams_data organization.get_teams teams {}for team in teams_data teams[team.name] {'id' team.id 'slug' team.slug 'description' team._rawData['description'] 'permission' team.permission 'privacy' team._rawData['privacy']}__context__[key] teamsreturn __context__[key]
def generate_ratings addon num for n in range 1 num + 1 username 'testuser-{s}'.format s get_random_string email '{username}@example.com'.format username username user _created UserProfile.objects.get_or_create username email email email defaults {'display_name' email} Review.objects.create addon addon user user rating random.randrange 0 6 title 'TestReview{n}'.format n n body 'reviewtext'
def canonical_free base gens g num_free g g.array_formsize len g if not base return g[ ]transversals get_transversals base gens m len base for x in sorted g[ -2 ] if x not in base base.append x h gfor i transv in enumerate transversals b base[i]h_i [size] * num_free s Nonefor sk in transv.values h1 _af_rmul h sk hi [h1.index ix for ix in range num_free ]if hi < h_i h_i his skif s h _af_rmul h s return h
def floating_ip_get_all_by_project context project_id return IMPL.floating_ip_get_all_by_project context project_id
def iter_topography info layout None on_pick None fig None fig_facecolor 'k' axis_facecolor 'k' axis_spinecolor 'k' layout_scale None return _iter_topography info layout on_pick fig fig_facecolor axis_facecolor axis_spinecolor layout_scale
def get_language_bidi lang get_language if lang is None return Falseelse base_lang get_language .split '-' [0]return base_lang in settings.LANGUAGES_BIDI
def report_similarities sect stats old_stats lines ['' 'now' 'previous' 'difference']lines + table_lines_from_stats stats old_stats 'nb_duplicated_lines' 'percent_duplicated_lines' sect.append Table children lines cols 4 rheaders 1 cheaders 1
def _patch_stopall for patch in list _patch._active_patches patch.stop
def rackconnect vm_ return config.get_cloud_config_value 'rackconnect' vm_ __opts__ default False search_global False
def choose_lines source number seed None generator random if seed is not None generator.seed seed sources source.split '\n' return [generator.choice sources for n in range number ]
def test_arguments def function argument1 argument2 passassert tuple hug.introspect.arguments function_with_kwargs 'argument1' assert tuple hug.introspect.arguments function_with_args 'argument1' assert tuple hug.introspect.arguments function_with_neither 'argument1' 'argument2' assert tuple hug.introspect.arguments function_with_both 'argument1' 'argument2' 'argument3'
@contextfilterdef number_format context value value str value negative Falseaddzero Noneif value[0] '-' value value[1 ]negative Trueif '.' in value point value.rindex '.' if point len value - 2 addzero Trueelse point len value while point < len value - 3 if value[ len value - 1 ] '0' value value[ len value - 1 ]else breakwhile point > 3 value value[ point - 3 ] + ' ' + value[ point - 3 ] point value.index ' ' if addzero value + '0'if negative value '-' + value return value
def _sort_components ica order copy True assert ica.n_components_ len order if copy ica ica.copy ica.mixing_matrix_ ica.mixing_matrix_[ order]ica.unmixing_matrix_ ica.unmixing_matrix_[order ]if isinstance order np.ndarray order list order if ica.exclude ica.exclude [order.index ic for ic in ica.exclude]for k in ica.labels_.keys ica.labels_[k] [order.index ic for ic in ica.labels_[k]]return ica
def check_isinstance obj cls if isinstance obj cls return objraise Exception _ 'Expectedobjectoftype %s' % str cls return cls
def saltversioninfo from salt.version import __version_info__return {'saltversioninfo' list __version_info__ }
def assess assess_tables impact_tables tablename '%s_%s' % module resourcename table db[tablename]def prep r if session.s3.mobile and r.method 'create' and r.interactive redirect URL f 'assess_short_mobile' return Trueresponse.s3.prep preptabs [ T 'EditDetails' None T 'Baselines' 'baseline' T 'Impacts' 'impact' T 'Summary' 'summary' ]rheader lambda r assess_rheader r tabs return s3_rest_controller rheader rheader
@open_file 1 mode 'wb' def write_gml G path stringizer None for line in generate_gml G stringizer path.write line + '\n' .encode 'ascii'
def generate_matches patterns nodes if not patterns yield 0 {} else p rest patterns[0] patterns[1 ] for c0 r0 in p.generate_matches nodes if not rest yield c0 r0 else for c1 r1 in generate_matches rest nodes[c0 ] r {}r.update r0 r.update r1 yield c0 + c1 r
def add_monitor for name function in globals .items if not inspect.isfunction function continueargs inspect.getargspec function [0]if args and name.startswith 'monitor' exec 'pep8.%s %s' % name name
def qos_specs_disassociate_all context qos_specs_id return IMPL.qos_specs_disassociate_all context qos_specs_id
def _error_on_bad_paths fs paths for path in paths if path '-' returnif fs.exists path returnraise ValueError 'Atleastonevalidpathisrequired.Nonefoundin%s' % paths
def validate_host host allowed_hosts for pattern in allowed_hosts pattern pattern.lower match pattern u'*' or pattern.startswith u'.' and host.endswith pattern or host pattern[1 ] or pattern host if match return Truereturn False
def plugin_install app fobj request filename upname apath '../deposit/%s' % filename request try write_file upname fobj.read 'wb' path apath app request w2p_unpack_plugin upname path fix_newlines path return upnameexcept Exception os.unlink upname return False
def _kpost url data headers {'Content-Type' 'application/json'}log.trace 'urlis {0} datais {1}'.format url data ret http.query url method 'POST' header_dict headers data json.dumps data if ret.get 'error' return retelse return json.loads ret.get 'body'
def del_tags name None kwargs None call None instance_id None resource_id None if kwargs is None kwargs {}if 'tags' not in kwargs raise SaltCloudSystemExit 'Atagortagsmustbespecifiedusingtags list of tags' if not name and 'resource_id' in kwargs instance_id kwargs['resource_id']del kwargs['resource_id']if not instance_id instance_id _get_node name ['instanceId']params {'Action' 'DeleteTags' 'ResourceId.1' instance_id}for idx tag in enumerate kwargs['tags'].split ' ' params['Tag.{0}.Key'.format idx ] tagaws.query params setname 'tagSet' location get_location provider get_provider opts __opts__ sigver '4' if resource_id return get_tags resource_id resource_id else return get_tags instance_id instance_id
def fix_namespace raw return NULL_NAMESPACE_REGEX.sub u'\\1' raw
def _parse_quota mount opts cmd 'repquota-vp{0}{1}'.format opts mount out __salt__['cmd.run'] cmd python_shell False .splitlines mode 'header'if '-u' in opts quotatype 'Users'elif '-g' in opts quotatype 'Groups'ret {quotatype {}}for line in out if not line continuecomps line.split if mode 'header' if 'Blockgracetime' in line blockg inodeg line.split ';' blockgc blockg.split ' ' inodegc inodeg.split ' ' ret['BlockGraceTime'] blockgc[ -1 ]ret['InodeGraceTime'] inodegc[ -1 ]elif line.startswith '-' mode 'quotas'elif mode 'quotas' if len comps < 8 continueif not comps[0] in ret[quotatype] ret[quotatype][comps[0]] {}ret[quotatype][comps[0]]['block-used'] comps[2]ret[quotatype][comps[0]]['block-soft-limit'] comps[3]ret[quotatype][comps[0]]['block-hard-limit'] comps[4]ret[quotatype][comps[0]]['block-grace'] comps[5]ret[quotatype][comps[0]]['file-used'] comps[6]ret[quotatype][comps[0]]['file-soft-limit'] comps[7]ret[quotatype][comps[0]]['file-hard-limit'] comps[8]ret[quotatype][comps[0]]['file-grace'] comps[9]return ret
def test_embed embed_dense L.EmbedID 5 10 embed_sparse L.EmbedID 5 10 embed_dense.W.data[ ] np.random.randn 5 10 .astype 'float32' embed_sparse.W.data[ ] np.random.randn 5 10 .astype 'float32' embed_sparse.W.data[ 1 ] / 100000.0dhl_dense_01 dirichlet_likelihood embed_dense alpha 0.1 .datadhl_sparse_01 dirichlet_likelihood embed_sparse alpha 0.1 .datamsg 'Sparsevectorhashigherlikelihoodthandensewithalpha 0.1'assert dhl_sparse_01 > dhl_dense_01 msg
def delta_seconds before after delta after - before return datetime.timedelta.total_seconds delta
def is_accessible_bucket_name bucket_name scope 'https //www.googleapis.com/auth/devstorage.read_write'url 'https //%s.commondatastorage.googleapis.com/' % bucket_name auth_token _ app_identity.get_access_token scope result urlfetch.fetch url method urlfetch.HEAD headers {'Authorization' 'OAuth%s' % auth_token 'x-goog-api-version' '2'} return result and result.status_code 200
def get_instructor_task_history course_id usage_key None student None task_type None instructor_tasks InstructorTask.objects.filter course_id course_id if usage_key is not None or student is not None _ task_key encode_problem_and_student_input usage_key student instructor_tasks instructor_tasks.filter task_key task_key if task_type is not None instructor_tasks instructor_tasks.filter task_type task_type return instructor_tasks.order_by '-id'
def all_weighers if CONF.least_cost_functions is not None or CONF.compute_fill_first_cost_fn_weight is not None LOG.deprecated _ 'least_costhasbeendeprecatedinfavoroftheRAMWeigher.' return least_cost.get_least_cost_weighers return HostWeightHandler .get_all_classes
def decompress data results []while data decomp BZ2Decompressor try res decomp.decompress data except OSError if results breakelse raiseresults.append res if not decomp.eof raise ValueError 'Compresseddataendedbeforetheend-of-streammarkerwasreached' data decomp.unused_datareturn ''.join results
@require_GET@login_required@permission_required 'wiki.add_revisionakismetsubmission' 'wiki.add_documentspamattempt' 'users.add_userban' raise_exception True def spam request yesterday datetime.date.today - datetime.timedelta days 1 data SpamDashboardHistoricalStats .get yesterday if not data return render request 'dashboards/spam.html' {'processing' True} return render request 'dashboards/spam.html' data
def idzr_svd A k A np.asfortranarray A U V S ier _id.idzr_svd A k if ier raise _RETCODE_ERRORreturn U V S
def addXMLFromVertexes depth output vertexes for vertexIndex in xrange len vertexes vertex vertexes[vertexIndex]addXMLFromXYZ depth + 1 vertexIndex output vertex.x vertex.y vertex.z
def extrude filename '' if filename '' extrudeFiles getGCodeFilesWhichAreNotLogFiles returnextrudeFile filename
def pt value return dpi2px value 'pt'
def config_file_provider registry xml_parent data cfp XML.SubElement xml_parent 'org.jenkinsci.plugins.configfiles.builder.ConfigFileBuildStep' cfp.set 'plugin' 'config-file-provider' config_file_provider_builder cfp data
def build_ems_log_message_1 driver_name app_version vserver flexvol_pools aggregate_pools message {'pools' {'vserver' vserver 'aggregates' aggregate_pools 'flexvols' flexvol_pools}}ems_log _build_base_ems_log_message driver_name app_version ems_log['event-id'] '1'ems_log['event-description'] json.dumps message return ems_log
def simpler_string thrift_obj L []for key value in thrift_obj.__dict__.iteritems if value is None continueif hasattr value 'thrift_spec' L.append '%s %s' % key simpler_string value else L.append '%s %r' % key value return '%s %s ' % thrift_obj.__class__.__name__ ' '.join L
def patch_python_logging_handlers logging.StreamHandler StreamHandlerlogging.FileHandler FileHandlerlogging.handlers.SysLogHandler SysLogHandlerlogging.handlers.WatchedFileHandler WatchedFileHandlerlogging.handlers.RotatingFileHandler RotatingFileHandlerif sys.version_info > 3 2 logging.handlers.QueueHandler QueueHandler
def partition lst f save_keys False d collections.OrderedDict for l in lst c f l s d.setdefault c [] s.append l if save_keys return delse return d.values
def schedule_probes probes test False commit True return __salt__['net.load_template'] 'schedule_probes' probes probes test test commit commit
def func name return name
def _apply_user_agent headers user_agent if user_agent is not None if 'user-agent' in headers headers['user-agent'] user_agent + '' + headers['user-agent'] else headers['user-agent'] user_agentreturn headers
@memoizedef check key ver return check_version get key ver
def skip_if_lib_missing libname text None soname ctypes.util.find_library libname if not text text 'lib%s.so' % libname return skipif not soname and ctypes.CDLL soname reason 'required%smissing' % text
def reserve_for_production production_order pass
def SetTargetProperty output target_name property_name values sep '' output.write 'set_target_properties ' output.write target_name output.write 'PROPERTIES' output.write property_name output.write '"' for value in values output.write CMakeStringEscape value output.write sep output.write '" \n'
def lagrange_interpolate x y precision 250 **kwargs n len x - 1 delta_x [ x2 - x1 for x1 x2 in zip x x[1 ] ]for i in range n + 1 yield x[i] y[i] if i n or delta_x[i] 0 continuefor s in range 1 precision X x[i] + s * delta_x[i] / precision s 0for k in range n + 1 p 1for m in range n + 1 if m k continueif x[k] - x[m] p * X - x[m] / x[k] - x[m] s + y[k] * p yield X s
def logmgf_from_counts counts noise_eps l q compute_q_noisy_max counts noise_eps return logmgf_exact q 2.0 * noise_eps l
@pytest.fixture autouse True def prerequisites config_stub fake_save_manager config_stub.data {'general' {'private-browsing' False}}
def evaluate_expression expression context compiled_expr environment.compile_expression expression if isinstance context LazyDict context context.storereturn compiled_expr **context
@not_implemented_for 'directed' def efficiency G u v return 1 / nx.shortest_path_length G u v
def test_show_dots line Line line.add '_' [1 2 3] q line.render_pyquery assert len q '.dots' 3 line.show_dots Falseq line.render_pyquery assert len q '.dots' 0
def provision_rackspace node package_source distribution variants commands []commands.append run_remotely username get_default_username distribution address node.address commands sequence [provision package_source package_source distribution node.distribution variants variants ] return sequence commands
def normpath path slash dot u'/' u'.' if isinstance path unicode else '/' '.' if path '' return dotinitial_slashes path.startswith '/' if initial_slashes and path.startswith '//' and not path.startswith '///' initial_slashes 2comps path.split '/' new_comps []for comp in comps if comp in '' '.' continueif comp ! '..' or not initial_slashes and not new_comps or new_comps and new_comps[ -1 ] '..' new_comps.append comp elif new_comps new_comps.pop comps new_compspath slash.join comps if initial_slashes path slash * initial_slashes + path return path or dot
def get_all_comments q Comment._query sort desc '_date' return make_results q
def _GetAppId request if request.has_app_id return request.app_id else return None
def _ask_for_it_by_name name bits str name .split '.' if len bits > 1 modulename '.'.join bits[ -1 ] else modulename bits[0]module __import__ modulename {} {} bits[ -1 ] if len bits 1 return moduleelse return getattr module bits[ -1 ]
def pr_get_path pe_id s3db current.s3dbatable s3db.pr_affiliationrtable s3db.pr_rolequery atable.deleted ! True & atable.role_id rtable.id & atable.pe_id pe_id & rtable.deleted ! True & rtable.role_type OU roles current.db query .select rtable.id rtable.pe_id rtable.path rtable.role_type multipath S3MultiPath append multipath.appendfor role in roles path S3MultiPath [role.pe_id] if role.path is None ppath pr_role_rebuild_path role else ppath S3MultiPath role.path path.extend role.pe_id ppath cut pe_id for p in path.paths append p return multipath.clean
def make_check exc_type template pred actual funcname if isinstance funcname str def get_funcname _ return funcnameelse get_funcname funcnamedef _check func argname argvalue if pred argvalue raise exc_type template % {'funcname' get_funcname func 'argname' argname 'actual' actual argvalue } return argvaluereturn _check
def _create_players jsonf None if jsonf is None jsonf _player_json_filetry data json.loads open jsonf .read except IOError return {}players {}for playerid in data players[playerid] Player data[playerid] return players
def add_error e saved_errors.append e log '%-70s\n' % e
def setup_fast_link_prog_builder top_env new_link_action MakeAction fast_link_prog_action '$LINKCOMSTR' program SCons.Builder.Builder action new_link_action emitter '$PROGEMITTER' prefix '$PROGPREFIX' suffix '$PROGSUFFIX' src_suffix '$OBJSUFFIX' src_builder 'Object' target_scanner SCons.Scanner.Prog.ProgramScanner top_env['BUILDERS']['Program'] program
def stop_training log_likelihood_change num_iterations if VERBOSE print 'llchange %f' % log_likelihood_change if log_likelihood_change < 0.01 return 1elif num_iterations > 10 return 1else return 0
def normal_power effect_size nobs alpha alternative 'two-sided' sigma 1.0 d effect_sizeif alternative in ['two-sided' '2s'] alpha_ alpha / 2.0 elif alternative in ['smaller' 'larger'] alpha_ alphaelse raise ValueError "alternativehastobe'two-sided' 'larger'" + "or'smaller'" pow_ 0if alternative in ['two-sided' '2s' 'larger'] crit stats.norm.isf alpha_ pow_ stats.norm.sf crit - d * np.sqrt nobs / sigma if alternative in ['two-sided' '2s' 'smaller'] crit stats.norm.ppf alpha_ pow_ + stats.norm.cdf crit - d * np.sqrt nobs / sigma return pow_
def _PropertyName proto_field_name return proto_field_name
def make_meter_query_for_resource start_timestamp start_timestamp_op end_timestamp end_timestamp_op source query None start_rts end_rts get_start_end_rts start_timestamp end_timestamp mq []start_op start_timestamp_op or 'ge' end_op end_timestamp_op or 'lt' if start_rts filter_value start_rts + ' ' + quote source if source else start_rts mq.append _QualifierFilter OP_SIGN_REV[start_op] filter_value if end_rts filter_value end_rts + ' ' + quote source if source else end_rts mq.append _QualifierFilter OP_SIGN_REV[end_op] filter_value if mq meter_q 'AND'.join mq meter_q _QualifierFilter ' ' '' + 'AND' + meter_q query meter_q if not query else query + 'AND' + meter_q return query
@depends HAS_ESX_CLI def get_syslog_config host username password protocol None port None esxi_hosts None cmd 'systemsyslogconfigget'ret {}if esxi_hosts if not isinstance esxi_hosts list raise CommandExecutionError "'esxi_hosts'mustbealist." for esxi_host in esxi_hosts response salt.utils.vmware.esxcli host username password cmd protocol protocol port port esxi_host esxi_host ret.update {esxi_host _format_syslog_config response } else response salt.utils.vmware.esxcli host username password cmd protocol protocol port port ret.update {host _format_syslog_config response } return ret
def rollback_unless_managed if not is_managed connection._rollback else set_dirty
def AdjustCandidateInsertionText candidates def NewCandidateInsertionText to_insert text_after_cursor overlap_len OverlapLength to_insert text_after_cursor if overlap_len return to_insert[ - overlap_len ]return to_inserttext_after_cursor vimsupport.TextAfterCursor if not text_after_cursor return candidatesnew_candidates []for candidate in candidates if isinstance candidate dict new_candidate candidate.copy if u'abbr' not in new_candidate new_candidate[u'abbr'] new_candidate[u'word']new_candidate[u'word'] NewCandidateInsertionText new_candidate[u'word'] text_after_cursor new_candidates.append new_candidate elif isinstance candidate str or isinstance candidate bytes new_candidates.append {u'abbr' candidate u'word' NewCandidateInsertionText candidate text_after_cursor } return new_candidates
def CheckUselessComponentModules virtualenv_interpreter virtualenv_pip os.path.join os.path.dirname virtualenv_interpreter 'pip' component_modules set subprocess.check_output [virtualenv_pip 'freeze'] env GetCleanEnvironment .splitlines client_modules dict x.key x.version for x in pip.get_installed_distributions for component_name in component_modules if ' ' not in component_name continue dist_name version component_name.split ' ' if dist_name in SKIPPED_MODULES continueclient_mod_version client_modules.get dist_name if client_mod_version is not None print 'Uselessclientmodule%s' % dist_name if client_mod_version ! version print 'Conflictingcomponentmoduleversion %s withclientversion %s ' % version client_mod_version
def createPythonObjectBuilder env try pyobj env['BUILDERS']['PythonObject']except KeyError pyobj SCons.Builder.Builder action {} emitter {} prefix '$PYEXTOBJPREFIX' suffix '$PYEXTOBJSUFFIX' src_builder ['CFile' 'CXXFile'] source_scanner SourceFileScanner single_source 1 env['BUILDERS']['PythonObject'] pyobjreturn pyobj
def ssl_protocols_labels return _SSL_PROTOCOLS_LABELS
def rss if not auth.s3_has_role ADMIN auth.permission.fail tablename 'msg_rss'table s3db.msg_rsss3.crud_strings[tablename] Storage title_display T 'RSSPostDetails' title_list T 'RSSPosts' label_list_button T 'ViewRSSPosts' label_delete_button T 'DeletePost' msg_record_deleted T 'RSSPostdeleted' msg_list_empty T 'NoPostsavailable' s3db.configure tablename editable False insertable False list_fields ['id' 'date' 'body'] return s3_rest_controller
def mnc2mvsk args mnc mnc2 mnc3 mnc4 argsmc mncmc2 mnc2 - mnc * mnc mc3 mnc3 - 3 * mc * mc2 + mc ** 3 mc4 mnc4 - 4 * mc * mc3 + 6 * mc * mc * mc2 + mc ** 4 return mc2mvsk mc mc2 mc3 mc4
@interruptabledef xread fh size -1 encoding None errors u'strict' return decode fh.read size encoding encoding errors errors
def _AbsolutePath filename application_root python_lib _ lib suffix filename.partition '$PYTHON_LIB/' if lib filename os.path.join python_lib suffix else filename os.path.join application_root filename if filename.endswith os.sep or os.path.isdir filename filename os.path.join filename '__init__.py' return filename
def figaspect arg isarray hasattr arg 'shape' figsize_min np.array 4.0 2.0 figsize_max np.array 16.0 16.0 if isarray nr nc arg.shape[ 2]arr_ratio float nr / nc else arr_ratio float arg fig_height rcParams['figure.figsize'][1]newsize np.array fig_height / arr_ratio fig_height newsize / min 1.0 * newsize / figsize_min newsize / max 1.0 * newsize / figsize_max newsize np.clip newsize figsize_min figsize_max return newsize
@ignore_warnings category DeprecationWarning def test_fit_predict lrng np.random.RandomState 101 n_samples n_dim n_comps 100 2 2 mu np.array [[8 8]] component_0 lrng.randn n_samples n_dim component_1 lrng.randn n_samples n_dim + mu X np.vstack component_0 component_1 for m_constructor in mixture.GMM mixture.VBGMM mixture.DPGMM model m_constructor n_components n_comps covariance_type 'full' min_covar 1e-07 n_iter 5 random_state np.random.RandomState 0 assert_fit_predict_correct model X model mixture.GMM n_components n_comps n_iter 0 z model.fit_predict X assert np.all z 0 'QuickInitializationFailed!'
def load_dynamic_class fqn subclass if not isinstance fqn basestring return fqncls load_class_from_name fqn if cls subclass or not issubclass cls subclass raise TypeError '%sisnotavalid%s' % fqn subclass.__name__ return cls
def ttest_ind x1 x2 alternative 'two-sided' usevar 'pooled' weights None None value 0 cm CompareMeans DescrStatsW x1 weights weights[0] ddof 0 DescrStatsW x2 weights weights[1] ddof 0 tstat pval dof cm.ttest_ind alternative alternative usevar usevar value value return tstat pval dof
def getTitleFromName title if title[ -1 ] ' ' title title[ -1 ]spaceBracketIndex title.find ' ' if spaceBracketIndex > -1 return title[ spaceBracketIndex]return title
def list_inactive_vms conn __get_conn vms []for id_ in conn.listDefinedDomains vms.append id_ return vms
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def job name jobs _jobs if name in jobs return {'job' jobs[name]}return None
@FileSystem.in_directory current_directory 'django' 'cucumber' def test_django_against_cucumber_django_project status out run_scenario assert 'beforeharvest' in out assert 'afterharvest' in out
def set_p_to_zero pvect i new_pvect T.set_subtensor pvect[i] 0.0 new_pvect new_pvect / new_pvect.sum return new_pvect
def ValidateCertificateHostname cert hostname hosts GetValidHostsForCert cert boto.log.debug 'validatingservercertificate hostname %s certificatehosts %s' hostname hosts for host in hosts host_re host.replace '.' '\\.' .replace '*' '[^.]*' if re.search '^%s$' % host_re hostname re.I return Truereturn False
def get_path_to_egg path lastpath Nonewhile path and path ! lastpath if os.path.splitext path [1].lower '.egg' if os.path.isfile path or os.path.isdir path return pathlastpath pathpath os.path.dirname path return None
def angle point1 point2 angle QLineF point1 point2 .angle if angle > 180 return angle - 360 else return angle
def compile_internal typingctx targetctx library func args return_type flags locals pipeline Pipeline typingctx targetctx library args return_type flags locals return pipeline.compile_extra func
def test_lex_line_counting_multi_inner entry tokenize ' foo\nbar ' [0]inner entry[0]assert inner.start_line 1 assert inner.start_column 2 inner entry[1]assert inner.start_line 2 assert inner.start_column 5
def get_jobs server _connect jobs server.get_jobs if jobs return jobsreturn {}
def model_to_dict instance fields None exclude None from django.db.models.fields.related import ManyToManyFieldopts instance._metadata {}for f in opts.concrete_fields + opts.virtual_fields + opts.many_to_many if not getattr f u'editable' False continueif fields and not f.name in fields continueif exclude and f.name in exclude continueif isinstance f ManyToManyField if instance.pk is None data[f.name] []else data[f.name] list f.value_from_object instance .values_list u'pk' flat True else data[f.name] f.value_from_object instance return data
def mkCompoundFilter parts transformers []filters []for subfilter in parts try subfilter list subfilter except TypeError if hasattr subfilter 'getServiceEndpoints' filters.append subfilter elif hasattr subfilter 'fromBasicServiceEndpoint' transformers.append subfilter.fromBasicServiceEndpoint elif callable subfilter transformers.append subfilter else raise filter_type_errorelse filters.append mkCompoundFilter subfilter if transformers filters.append TransformFilterMaker transformers if len filters 1 return filters[0]else return CompoundFilter filters
def test_unit_division_by_string u1 u.cmus u'kg'assert us / u1 u.Unit us / u1 assert u1 / us u1 / u.Unit us
def timestamp_custom value date_format DATE_STR_FORMAT local True try date dt_util.utc_from_timestamp value if local date dt_util.as_local date return date.strftime date_format except ValueError TypeError return value
def split_arg_string string rv []for match in re.finditer ' \' [^\'\\\\]* ? \\\\.[^\'\\\\]* * \'|" [^"\\\\]* ? \\\\.[^"\\\\]* * "|\\S+ \\s*' string re.S arg match.group .strip if arg[ 1] arg[ -1 ] and arg[ 1] in '"\'' arg arg[1 -1 ].encode 'ascii' 'backslashreplace' .decode 'unicode-escape' try arg type string arg except UnicodeError passrv.append arg return rv
def educateSingleBackticks str str re.sub '`' '&#8216;' str str re.sub "'" '&#8217;' str return str
def ReplaceAll pattern rep s if pattern not in _regexp_compile_cache _regexp_compile_cache[pattern] sre_compile.compile pattern return _regexp_compile_cache[pattern].sub rep s
def get_bumper_settings video bumper_settings copy.deepcopy getattr video 'video_bumper' {} for lang transcript_url in bumper_settings.get 'transcripts' {} .items bumper_settings['transcripts'][lang] transcript_url.replace '/static/' '' return bumper_settings
def extract_command text return text.split [0].split '@' [0][1 ] if is_command text else None
def stde x1 x2 ddof 0 axis 0 x1 np.asanyarray x1 x2 np.asanyarray x2 return np.std x1 - x2 ddof ddof axis axis
@autojitdef mandel x y max_iters i 0c complex x y z 0jfor i in range max_iters z z * z + c if z.real * z.real + z.imag * z.imag > 4 return ireturn 255
def test_generate_accepted_kwargs source_dictionary {'argument1' 1 'argument2' 2 'hey' 'there' 'hi' 'hello'}kwargs hug.introspect.generate_accepted_kwargs function_with_kwargs 'bacon' 'argument1' source_dictionary assert kwargs source_dictionary kwargs hug.introspect.generate_accepted_kwargs function_with_args 'bacon' 'argument1' source_dictionary assert kwargs {'argument1' 1} kwargs hug.introspect.generate_accepted_kwargs function_with_neither 'argument1' 'argument2' source_dictionary assert kwargs {'argument1' 1 'argument2' 2} kwargs hug.introspect.generate_accepted_kwargs function_with_both 'argument1' 'argument2' source_dictionary assert kwargs source_dictionary
def get_test_content_type obj return u'x'
def time_to_seconds x if isinstance x time return x.hour * 60 + x.minute * 60 + x.second * 10 ** 6 + x.microsecond / 10 ** 6 if is_str x return xreturn x and max 0 min x 24 * 3600 - 10 ** -6
def is_sequence_of_booleans obj if not cbook.iterable obj return False_it isinstance x bool for x in obj if all _it return Truereturn False
def _validate_format req values amazon_formats 'aki' 'ari' 'ami' disk_format values.get 'disk_format' container_format values.get 'container_format' if 'disk_format' in values if disk_format not in CONF.image_format.disk_formats msg _ "Invaliddiskformat'%s'forimage." % disk_format raise HTTPBadRequest explanation msg request req if 'container_format' in values if container_format not in CONF.image_format.container_formats msg _ "Invalidcontainerformat'%s'forimage." % container_format raise HTTPBadRequest explanation msg request req if any f in amazon_formats for f in [disk_format container_format] if disk_format is None values['disk_format'] container_formatelif container_format is None values['container_format'] disk_formatelif container_format ! disk_format msg _ "Invalidmixofdiskandcontainerformats.Whensettingadiskorcontainerformattooneof'aki' 'ari' or'ami' thecontaineranddiskformatsmustmatch." raise HTTPBadRequest explanation msg request req
def getchar echo False f _getcharif f is None from ._termui_impl import getchar as freturn f echo
def _build_es_excerpt result first_only False bits [m.strip for m in chain *result.es_meta.highlight.values ]if first_only and bits excerpt bits[0]else excerpt EXCERPT_JOINER.join bits return jinja2.Markup clean_excerpt excerpt
def cap_history_rheader r rheader Noneif r.representation 'html' record r.recordif record T current.Tdb current.dbs3db current.s3dbif r.tablename 'cap_alert_history' alert_id record.iditable s3db.cap_info_historyrow db itable.alert_history_id alert_id .select itable.id limitby 0 1 .first tabs [ T 'AlertDetails' None T 'Information' 'info_history' T 'Area' 'area_history' T 'ResourceFiles' 'resource_history' ]rheader_tabs s3_rheader_tabs r tabs rheader DIV TABLE TR TH '%s ' % T 'Alert' TD A s3db.cap_alert_represent alert_id record _href URL c 'cap' f 'alert' args [alert_id 'update'] rheader_tabs return rheader
def test_epoch_combine_ids raw events picks _get_data epochs Epochs raw events {'a' 1 'b' 2 'c' 3 'd' 4 'e' 5 'f' 32} tmin tmax picks picks preload False events_new merge_events events [1 2] 12 epochs_new combine_event_ids epochs ['a' 'b'] {'ab' 12} assert_equal epochs_new['ab'].name 'ab' assert_array_equal events_new epochs_new.events
def create_or_resurrect_dir tp name parent try directory Directory.objects.get parent parent name name directory.obsolete Falseexcept Directory.DoesNotExist directory Directory name name parent parent tp tp return directory
def rangename3drel book ref3d browx None bcolx None r1c1 0 coords ref3d.coordsrelflags ref3d.relflagsshdesc sheetrangerel book coords[ 2] relflags[ 2] rngdesc rangename2drel coords[2 6] relflags[2 6] browx bcolx r1c1 if not shdesc return rngdescreturn '%s!%s' % shdesc rngdesc
def request_wants_json request best request.accept_mimetypes.best_match ['application/json' 'text/html'] return best 'application/json' and request.accept_mimetypes[best] > request.accept_mimetypes['text/html']
def ffill_across_cols df columns name_map df.ffill inplace True for column in columns column_name name_map[column.name]if column.dtype categorical_dtype df[column_name] df[column.name].where pd.notnull df[column_name] column.missing_value else df[column_name] df[column_name].fillna column.missing_value .astype column.dtype
def test_columns_flag script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' 'simple2 3.0' result script.pip 'list' '--format columns' assert 'Package' in result.stdout str result assert 'Version' in result.stdout str result assert 'simple 1.0 ' not in result.stdout str result assert 'simple1.0' in result.stdout str result assert 'simple23.0' in result.stdout str result
def _reshape_clusters clusters sample_shape if len clusters > 0 and isinstance clusters[0] np.ndarray if clusters[0].dtype bool clusters [c.reshape sample_shape for c in clusters]else clusters [np.unravel_index c sample_shape for c in clusters]return clusters
def get_session_input try display color.B_GREEN + '[' + color.B_YELLOW + 'session' + color.B_GREEN + '][' + color.B_YELLOW + 'number' + color.B_GREEN + ']' + color.B_WHITE + '>' tmp raw_input display module number tmp.split '' if not module is None and not number is None return int module int number except Exception Error 'Mustspecify[module]followedby[number]\n' return None None
def test_real func @functools.wraps func def guard_func *args **kwargs real kwargs.pop '_test_real' None if not real raise Exception 'Forgottomockorpass"_test_real True"to%s' func.__name__ return func *args **kwargs return guard_func
def set_system_info key value obj Noneobj meta.Session.query SystemInfo .filter_by key key .first if obj and obj.value unicode value returnif not obj obj SystemInfo key value else obj.value unicode value from ckan.model import reporev repo.new_revision rev.message 'Set{0}settinginsystem_infotable'.format key meta.Session.add obj meta.Session.commit return True
def create_feed_and_todo add_info_comment **{u'subject' _ u'ERPNextSetupComplete!' }
def xor_key data avoid '\x00\n' size None size size or context.bytes if len data % size log.error 'Datamustbepaddedtosizeforxor_key' words lists.group size data columns [''] * size for word in words for i byte in enumerate word columns[i] + bytealphabet list chr n for n in range 256 if chr n not in avoid result ''for column in columns if context.randomize random.shuffle alphabet for c2 in alphabet if all chr ord c ^ ord c2 in alphabet for c in column result + c2breakelse return Nonereturn result xor data result
def RenderTokenApprovedTemplate return TOKEN_APPROVED_TEMPLATE
def frombuffer mode size data decoder_name 'raw' *args _check_size size if len args 1 and isinstance args[0] tuple args args[0]if decoder_name 'raw' if args warnings.warn "thefrombufferdefaultsmaychangeinafuturerelease;forportability changethecalltoread \nfrombuffer mode size data 'raw' mode 0 1 " RuntimeWarning stacklevel 2 args mode 0 -1 if args[0] in _MAPMODES im new mode 1 1 im im._new core.map_buffer data size decoder_name None 0 args im.readonly 1return imreturn frombytes mode size data decoder_name args
def wrap_non_libcloud_exceptions func @wraps func def decorated_function *args **kwargs try return func *args **kwargs except Exception e sys.exc_info [1]if isinstance e LibcloudError raise eif len args > 1 driver args[0]else driver Nonefault getattr e 'fault' None if fault and getattr fault 'string' None message fault.stringelse message e.messageraise LibcloudError value message driver driver return decorated_function
def _run_command cmd logging.info ''.join cmd pipe subprocess.PIPEproc subprocess.Popen cmd stdin pipe stdout pipe stderr pipe close_fds True out err proc.communicate if proc.returncode is not os.EX_OK raise XenstoreError cmd proc.returncode err out return proc.returncode out
def html2pdf data filename open_file False pdf pisa.CreatePDF six.StringIO data file filename 'wb' if open_file and not pdf.err pisa.startViewer filename return not pdf.err
def exportdb cmd 'udevadminfo--export-db'udev_result __salt__['cmd.run_all'] cmd output_loglevel 'quiet' if udev_result['retcode'] raise CommandExecutionError udev_result['stderr'] return _parse_udevadm_info udev_result['stdout']
def from_prufer_sequence sequence n len sequence + 2 degree Counter chain sequence range n T nx.empty_graph n not_orphaned set index u min k for k in range n if degree[k] 1 for v in sequence T.add_edge u v not_orphaned.add u degree[v] - 1if v < index and degree[v] 1 u velse index u min k for k in range index + 1 n if degree[k] 1 orphans set T - not_orphaned u v orphansT.add_edge u v return T
def getSabAccesMethod host None params {u'mode' u'auth' u'output' u'json'}url urljoin host u'api' data helpers.getURL url params params session session returns u'json' verify False if not data return False data return _checkSabResponse data
def get_interface_stats snmp_device snmp_user stat_type row_number oid_dict {'in_octets' '1.3.6.1.2.1.2.2.1.10' 'out_octets' '1.3.6.1.2.1.2.2.1.16' 'in_ucast_pkts' '1.3.6.1.2.1.2.2.1.11' 'out_ucast_pkts' '1.3.6.1.2.1.2.2.1.17'}if not stat_type in oid_dict.keys raise ValueError 'Invalidvalueforstat_type {}' % stat_type row_number int row_number oid oid_dict[stat_type]oid oid + '.' + str row_number snmp_data snmp_get_oid_v3 snmp_device snmp_user oid return int snmp_extract snmp_data
def depth_first_search node visit lambda node False traversable lambda node edge True _visited None stop visit node _visited _visited or {} _visited[node.id] Truefor n in node.links if stop return Trueif traversable node node.links.edge n is False continueif not n.id in _visited stop depth_first_search n visit traversable _visited return stop
@lower_getattr types.MemoryView 'nbytes' def array_nbytes context builder typ value arrayty make_array typ array arrayty context builder value dims cgutils.unpack_tuple builder array.shape typ.ndim res builder.mul array.nitems array.itemsize return impl_ret_untracked context builder typ res
def add_stokes_axis_to_wcs wcs add_before_ind inds [ i + 1 for i in range wcs.wcs.naxis ]inds.insert add_before_ind 0 newwcs wcs.sub inds newwcs.wcs.ctype[add_before_ind] u'STOKES'newwcs.wcs.cname[add_before_ind] u'STOKES'return newwcs
def security_group_in_use context group_id return IMPL.security_group_in_use context group_id
def succeed_without_changes name ret {'name' name 'changes' {} 'result' True 'comment' 'Success!'}return ret
def python_version_string version None major minor micro release_level serial split_python_version version s '%d.%d' % major minor if micro > 0 s + '.%d' % micro if release_level ! 'final' s + release_level[0]s + '%s' % serial return s
def directories path_list use_sudo False owner '' group '' mode '' for path in path_list directory path use_sudo owner group mode
def recursive_glob path pattern for root dirnames filenames in os.walk path followlinks True for filename in fnmatch.filter filenames pattern yield os.path.join root filename
def base62_encode num alphabet ALPHABET if num 0 return alphabet[0]arr []base len alphabet while num rem num % base num num // base arr.append alphabet[rem] arr.reverse return ''.join arr
def scroll_backward event half False w _current_window_for_event event b event.cli.current_bufferif w and w.render_info info w.render_infoscroll_height info.window_heightif half scroll_height // 2y max 0 b.document.cursor_position_row - 1 height 0while y > 0 line_height info.get_height_for_line y if height + line_height < scroll_height height + line_heighty - 1else breakb.cursor_position b.document.translate_row_col_to_index y 0
def run_conv_nnet2_classif use_gpu seed isize ksize bsize n_train 10 check_isfinite True verbose 0 version -1 utt.seed_rng seed train params x_shape y_shape mode build_conv_nnet2_classif use_gpu use_gpu isize isize ksize ksize n_batch bsize verbose verbose version version check_isfinite check_isfinite xval my_rand *x_shape yval my_rand *y_shape lr theano._asarray 0.01 dtype 'float32' rvals my_zeros n_train for i in xrange n_train rvals[i] train xval yval lr [0]
def _convert_to_array_of_mor mors array_of_mors DataObject array_of_mors.ManagedObjectReference morsreturn array_of_mors
def _iterate_trans_views function **kwargs from scipy.misc import imreadimport matplotlib.pyplot as pltimport mayavifig function **kwargs assert isinstance fig mayavi.core.scene.Scene views [ 90 90 0 90 0 -90 ] fig2 axes plt.subplots 1 len views for view ax in zip views axes mayavi.mlab.view view[0] view[1] tempdir _TempDir temp_fname op.join tempdir 'test.png' if fig.scene is not None fig.scene.save_png temp_fname im imread temp_fname else im np.zeros 2 2 3 ax.imshow im ax.axis 'off' mayavi.mlab.close fig img _fig_to_img fig fig2 return img
def test_fourier_series_square_wave square_wave Piecewise 1 x < pi -1 True s fourier_series square_wave x 0 2 * pi assert s.truncate 3 4 / pi * sin x + 4 / 3 * pi * sin 3 * x + 4 / 5 * pi * sin 5 * x assert s.sigma_approximation 4 4 / pi * sin x * sinc pi / 4 + 4 / 3 * pi * sin 3 * x * sinc 3 * pi / 4
def set_match_strings matchDict value for key in matchDict v matchDict[key]if not isinstance v str continuel len value if v[ l].lower value matchDict['match_type'] keymatchDict['match_string'] v[ l]next_string v[l ]if next_string matchDict['next_string'] next_stringbreakelif key 'addr' and value in v.lower matchDict['match_type'] key pre_string next_string v.lower .split value 1 if pre_string matchDict['pre_string'] v[ len pre_string ]if next_string matchDict['next_string'] v[ len pre_string + l ]matchDict['match_string'] v[len pre_string ][ l]break
def educate_ellipses s return s.replace '...' '&#8230;' .replace '...' '&#8230;'
def datepublisher_response_processor page request response expires page.publication_end_dateif expires is not None delta expires - timezone.now delta int delta.days * 86400 + delta.seconds patch_response_headers response delta
def str_regexes regex_template Template 'matchgroup Normal' + 'start +[uU]\\ ${raw}${sep}+' + 'end +${sep}+' + '${skip}' + '${contains}' skip_regex Template 'skip +\\\\\\\\\\|\\\\${sep}+' for raw in '' '[rR]' for separator in "'" '"' '"""' "'''" if len separator 1 skip skip_regex.substitute sep separator else skip ''contains 'contains pythonEscape' if not raw else '' yield regex_template.substitute raw raw sep separator skip skip contains contains
def getDiagonalSwitchedTetragrid angleDegrees diagonals unitPolar euclidean.getWiddershinsUnitPolar math.radians angleDegrees diagonalSwitchedTetragrid getIdentityMatrixTetragrid for diagonal in diagonals diagonalSwitchedTetragrid[diagonal][diagonal] unitPolar.realdiagonalSwitchedTetragrid[diagonals[0]][diagonals[1]] - unitPolar.imag diagonalSwitchedTetragrid[diagonals[1]][diagonals[0]] unitPolar.imagreturn diagonalSwitchedTetragrid
def validate_api_version version if float version < legacy_api.MIN_VERSION return Falseif float version > legacy_api.MAX_VERSION return Falsereturn True
def crc16 string value 0 crc16_table []for byte in range 256 crc 0for bit in range 8 if byte ^ crc & 1 crc crc >> 1 ^ 40961 else crc >> 1byte >> 1crc16_table.append crc for ch in string value crc16_table[ ord ch ^ value & 255 ] ^ value >> 8 return value
def _get_metrics_jobs date None if not date date UpdateCount.objects.aggregate max Max 'date' ['max']stats {'addon_total_updatepings' lambda UpdateCount.objects.filter date date .aggregate sum Sum 'count' ['sum'] 'collector_updatepings' lambda UpdateCount.objects.get addon settings.ADDON_COLLECTOR_ID date date .count }return stats
def _make_index prob size rv np.random.uniform size size 1 cumprob np.cumsum prob return np.logical_and np.r_[ 0 cumprob[ -1 ] ] < rv rv < cumprob
def add_vecs_to_vocab vocab vectors length len vectors[0][1] vocab.resize_vectors length for word vec in vectors vocab[word].vector vecreturn vocab
def circulant_graph n offsets create_using None G empty_graph n create_using template 'circulant_graph %d [%s] 'G.name template % n ' '.join str j for j in offsets for i in range n for j in offsets G.add_edge i i - j % n G.add_edge i i + j % n return G
def worktree_browser update True settings None view worktree_browser_widget None update update settings settings view.show return view
def sum_outer_product_loop x group_iter mom 0for g in group_iter x_g x[g]mom + np.outer x_g x_g return mom
def evaluate_sents inputs grammar model assignment trace 0 return [[ syn sem model.evaluate u'%s' % sem assignment trace trace for syn sem in interpretations] for interpretations in interpret_sents inputs grammar ]
def configured_cluster_for_nodes reactor certificates nodes dataset_backend dataset_backend_configuration dataset_backend_config_file provider None logging_config None default_volume_size get_default_volume_size dataset_backend_configuration cluster Cluster all_nodes pvector nodes control_node nodes[0] agent_nodes nodes dataset_backend dataset_backend default_volume_size default_volume_size certificates certificates dataset_backend_config_file dataset_backend_config_file configuring perform make_dispatcher reactor configure_cluster cluster dataset_backend_configuration provider logging_config configuring.addCallback lambda ignored cluster return configuring
def object_shasign record False res_model '' res_id None **kw secret request.env['ir.config_parameter'].sudo .get_param 'database.secret' shasign Falsetimestamp int time if record shasign sha1 '%s%s%s%s' % record._name record.id secret timestamp .hexdigest elif res_model and res_id shasign sha1 '%s%s%s%s' % res_model res_id secret timestamp .hexdigest return shasign timestamp
def list2cmdline seq result []needquote Falsefor arg in seq bs_buf []if result result.append '' needquote '' in arg or ' DCTB ' in arg if needquote result.append '"' for c in arg if c '\\' bs_buf.append c elif c '"' result.append '\\' * len bs_buf * 2 bs_buf []result.append '\\"' else if bs_buf result.extend bs_buf bs_buf []result.append c if bs_buf result.extend bs_buf if needquote result.extend bs_buf result.append '"' return ''.join result
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def test_compute_recall tp_pyval 4ys_pyval np.asarray [0 1 1 0 1 1 0] tp sharedX tp_pyval name 'tp' ys sharedX ys_pyval name 'ys_pyval' recall_py tp_pyval / ys_pyval.sum recall compute_recall ys tp assert np.allclose recall.eval recall_py
def _built_in_directive directive directive.directive Truereturn directive
def _retrieve_extra_groups conf key None delimiter ' ' results []for parsed_file in cfg.CONF._cparser.parsed for parsed_item in parsed_file.keys if parsed_item not in cfg.CONF items key and parsed_item.split delimiter if not key or key items[0] results.append parsed_item return results
def getdecoder encoding return lookup encoding .decode
def unique_ancestors node results []try current node.parent except AttributeError return resultswhile current and len current 1 results.append current current current.parent return results
def _order_json data srv new_data OrderedDict for field in FIELD_ORDER[srv[0]] new_data[field] sorted_dict data[field] data.pop field None data OrderedDict sorted data.items key lambda t t[0] for key in data new_data[key] sorted_dict data[key] return new_data
def get_localzone return _get_localzone
def prepend_dev device_name return device_name and '/dev/' + strip_dev device_name
def get_wiki_title wiki_url try content requests.get wiki_url .textreturn content.split 'title' [1].split '-' [0].split '>' [1].strip except return os.path.basename wiki_url .replace '_' ''
def _triangle_coords r geom best r1 geom['r1'][best]tri_nn geom['nn'][best]r12 geom['r12'][best]r13 geom['r13'][best]a geom['a'][best]b geom['b'][best]c geom['c'][best]rr r - r1 z np.sum rr * tri_nn v1 np.sum rr * r12 v2 np.sum rr * r13 det a * b - c * c x b * v1 - c * v2 / det y a * v2 - c * v1 / det return x y z
def normalize_paths value parent os.curdir if not value or isinstance value list return valuepaths []for path in value.split ' ' if '/' in path path os.path.abspath os.path.join parent path paths.append path.rstrip '/' return paths
def localcontext ctx None if ctx is None ctx getcontext return _ContextManager ctx
def _set_read_options request eventual transaction_id if eventual and transaction_id is not None raise ValueError 'eventualmustbeFalsewheninatransaction' opts request.read_optionsif eventual opts.read_consistency _datastore_pb2.ReadOptions.EVENTUALelif transaction_id opts.transaction transaction_id
def _group_type_get_full context id return _group_type_get context id session None inactive False expected_fields 'group_specs' 'projects'
def process_app_global key value options app_globals_from_config_details.get key key get_globals_key key if options if 'name' in options key options['name']value value or options.get 'default' '' data_type options.get 'type' if data_type 'bool' value asbool value elif data_type 'int' value int value elif data_type 'split' value value.split return key value
def get_crawler spidercls None settings_dict None from scrapy.crawler import CrawlerRunnerfrom scrapy.spiders import Spiderrunner CrawlerRunner settings_dict return runner.create_crawler spidercls or Spider
def read_tag_info fid tag _read_tag_header fid if tag is None return Noneif tag.next 0 fid.seek tag.size 1 elif tag.next > 0 fid.seek tag.next 0 return tag
def parse_data function def wrapper *args **kwargs dicts kwargs.get 'dicts' True expanded kwargs.get 'expanded' True output function *args **kwargs if dicts and output try if expanded output map unparse_model_data output.dicts else output [item for item in output.dicts ]except TypeError OperationalError logging.warn 'Nocontentdatabasefilefound' output []return outputreturn wrapper
def test_install_folder_using_slash_in_the_end script script.scratch_path.join 'mock' .mkdir pkg_path script.scratch_path / 'mock' pkg_path.join 'setup.py' .write mock100_setup_py result script.pip 'install' 'mock' + os.path.sep egg_folder script.site_packages / 'mock-100.1-py%s.egg-info' % pyversion assert egg_folder in result.files_created str result
def product_mul self other method 0 from sympy.concrete.products import Productif type self type other if method 0 if self.limits other.limits return Product self.function * other.function *self.limits elif method 1 if simplify self.function - other.function 0 if len self.limits len other.limits 1 i self.limits[0][0]x1 self.limits[0][1]y1 self.limits[0][2]j other.limits[0][0]x2 other.limits[0][1]y2 other.limits[0][2]if i j if x2 y1 + 1 return Product self.function i x1 y2 elif x1 y2 + 1 return Product self.function i x2 y1 return Mul self other
def delete_secondary_backup base_path if not remove '{0}{1}'.format base_path BACKUP_ROLLBACK_SUFFIX logging.warning 'Nosecondarybackuptoremove.Skipping...'
def parse_kconfig data config {}NOT_SET 'isnotset'if not data returnfor line in data.splitlines if NOT_SET in line line line.split NOT_SET 1 [0]name line.strip '#' config[name] Noneif ' ' in line k v line.split ' ' 1 if v 'y' v Trueelif v 'n' v Falseelse try v int v 0 except ValueError passconfig[k] vconfig {k.replace 'CONFIG_' '' v for k v in config.items }return config
def in_top_k predictions targets k predictions_top_k T.argsort predictions [ - k ] result _ theano.map lambda prediction target any equal prediction target sequences [predictions_top_k targets] return result
@snippetdef topic_exists client to_delete TOPIC_NAME 'topic_exists-%d' % _millis topic client.topic TOPIC_NAME to_delete.append topic assert not topic.exists topic.create assert topic.exists
def getwords line line line.replace ' DCTB ' '' .strip return [w for w in line.split '' if w]
def instantiate_descriptor **field_data system get_test_descriptor_system course_key SlashSeparatedCourseKey 'org' 'course' 'run' usage_key course_key.make_usage_key 'html' 'SampleHtml' return system.construct_xblock_from_class HtmlDescriptor scope_ids ScopeIds None None usage_key usage_key field_data DictFieldData field_data
def get_project request project skip_acl False project get_object_or_404 Project slug project if not skip_acl project.check_acl request return project
def get_added_demultiplex_field ids_bcs_added_field fasta_label added_demultiplex_field for curr_bc_added_field in ids_bcs_added_field.keys curr_added_field curr_bc_added_field[1]if added_demultiplex_field 'run_prefix' curr_label_slice fasta_label[0 len curr_added_field ]if curr_label_slice curr_added_field return curr_label_sliceelse if curr_added_field not in fasta_label continuecurr_label_slice fasta_label.split added_demultiplex_field + ' ' [1][0 len curr_added_field ]if curr_label_slice curr_added_field return curr_label_slicereturn None
def report_failure exception raise FailedExecution 'Exceptionencountered.RerunwithloglevelDEBUGand/orcheckElasticsearchlogsformoreinformation.Exception {0}'.format exception
def ensure_fs_mode filepath desired_mode S_IWRITE mode stat filepath [ST_MODE]if not mode & desired_mode chmod filepath mode | desired_mode
def CAN_MODERATE article user return _is_staff_for_article article user
def sympy_config mpl_backend if mpl_backend is not None lines '\nfromsympy.interactiveimportinit_session\ninit_session \n%matplotlib{0}\n'.format mpl_backend else lines '\nfromsympy.interactiveimportinit_session\ninit_session \n'return lines
def GetComment plist global commentslabel plist['Label']comment Noneif label in comments comment comments[label]return comment
def RGS_enum m if m < 1 return 0elif m 1 return 1else return bell m
def guess_lexer _text **options best_lexer [0.0 None]for lexer in _iter_lexerclasses rv lexer.analyse_text _text if rv 1.0 return lexer **options if rv > best_lexer[0] best_lexer[ ] rv lexer if not best_lexer[0] or best_lexer[1] is None raise ClassNotFound 'nolexermatchingthetextfound' return best_lexer[1] **options
@anonymous_csrf@mobile_template 'questions/{mobile/}marketplace_developer_request.html' def marketplace_developer_request request template error_message Noneif request.method 'GET' form MarketplaceDeveloperRequestForm request.user else form MarketplaceDeveloperRequestForm request.user request.POST if form.is_valid try form.submit_ticket return HttpResponseRedirect reverse 'questions.marketplace_aaq_success' except ZendeskError error_message ZENDESK_ERROR_MESSAGEreturn render request template {'form' form 'error_message' error_message}
@_ec_dispatcher.dispatch_for ops.MigrationScript def _migration_script_ops context directive phase version_path cli._get_version_branch_path context.config release cli.CURRENT_RELEASE branch phase autogen_kwargs {}cli._check_bootstrap_new_branch phase version_path autogen_kwargs op ops.MigrationScript new_rev_id ops.UpgradeOps ops [d for d in _assign_directives context directive.upgrade_ops.ops phase ] ops.DowngradeOps ops [] message directive.message **autogen_kwargs if not op.upgrade_ops.is_empty return op
def _generate_failed_chall_msg failed_achalls error failed_achalls[0].errortyp error.typif messages.is_acme_error error typ error.codemsg ['Thefollowingerrorswerereportedbytheserver ']for achall in failed_achalls msg.append '\n\nDomain %s\nType %s\nDetail %s' % achall.domain typ achall.error.detail if typ in _ERROR_HELP msg.append '\n\n' msg.append _ERROR_HELP[typ] return ''.join msg
def get_detail_view_name model return '% model_name s-detail' % {'app_label' model._meta.app_label 'model_name' model._meta.object_name.lower }
def get_installed_products shop return configuration.get shop SAMPLE_PRODUCTS_KEY or []
def set_vif_host_backend_hostdev_pci_config conf pci_slot conf.domain conf.bus conf.slot conf.function pci_utils.get_pci_address_fields pci_slot
def find_tex_file filename format None cmd ['kpsewhich']if format is not None cmd + [ '--format ' + format ]cmd + [filename]matplotlib.verbose.report 'find_tex_file %s %s' % filename cmd 'debug' pipe subprocess.Popen cmd stdout subprocess.PIPE result pipe.communicate [0].rstrip matplotlib.verbose.report 'find_tex_fileresult %s' % result 'debug' return result
def get_descriptors image filtered_coords wid 5 desc []for coords in filtered_coords patch image[ coords[0] - wid coords[0] + wid + 1 coords[1] - wid coords[1] + wid + 1 ].flatten desc.append patch return desc
def running name sig None return status name .get name False
def skip_unless_importable module msg None try __import__ module except ImportError return skip_if True msg else return skip_if False msg
def get_current_timezone_name return _get_timezone_name get_current_timezone
def copytree src dst copydates 1 if os.path.isdir src mkdirs dst files os.listdir src for f in files copytree os.path.join src f os.path.join dst f copydates else copy src dst 1 copydates
def is_ascii_encoding encoding try return codecs.lookup encoding .name 'ascii' except LookupError return False
@patch 'static_replace.staticfiles_storage' autospec True @patch 'static_replace.modulestore' autospec True def test_static_url_with_query mock_modulestore mock_storage mock_storage.exists.return_value Falsemock_modulestore.return_value Mock MongoModuleStore pre_text 'EMBEDsrc "/static/LAlec04_controller.swf?csConfigFile /static/LAlec04_config.xml&name1 value1&name2 value2"'post_text 'EMBEDsrc "/c4x/org/course/asset/LAlec04_controller.swf?csConfigFile %2Fc4x%2Forg%2Fcourse%2Fasset%2FLAlec04_config.xml&name1 value1&name2 value2"'assert_equals post_text replace_static_urls pre_text DATA_DIRECTORY COURSE_KEY
def list_repos basedir None basedirs _normalize_basedir basedir repos {}log.debug 'Searchingforreposin%s' basedirs for bdir in basedirs if not os.path.exists bdir continuefor repofile in os.listdir bdir repopath '{0}/{1}'.format bdir repofile if not repofile.endswith '.repo' continuefilerepos _parse_repo_file repopath [1]for reponame in filerepos.keys repo filerepos[reponame]repo['file'] repopathrepos[reponame] reporeturn repos
def load_npz file loaded np.load file try matrix_format loaded['format']except KeyError raise ValueError 'Thefile{}doesnotcontainasparsematrix.'.format file try cls getattr scipy.sparse '{}_matrix'.format matrix_format except AttributeError raise ValueError 'Unknownmatrixformat"{}"'.format matrix_format if matrix_format in 'csc' 'csr' 'bsr' return cls loaded['data'] loaded['indices'] loaded['indptr'] shape loaded['shape'] elif matrix_format 'dia' return cls loaded['data'] loaded['offsets'] shape loaded['shape'] elif matrix_format 'coo' return cls loaded['data'] loaded['row'] loaded['col'] shape loaded['shape'] else raise NotImplementedError 'Loadisnotimplementedforsparsematrixofformat{}.'.format matrix_format
def coroutine func replace_callback True return _make_coroutine_wrapper func replace_callback True
def add_pair_to_dict key value dictionary if key in dictionary dictionary[key].append value else dictionary[key] [value]
def gemset_list ruby 'default' runas None gemsets []output _rvm_do ruby ['rvm' 'gemset' 'list'] runas runas if output regex re.compile '^ [^]+ ' for line in output.splitlines match regex.match line if match gemsets.append match.group 1 return gemsets
def IsConfirmedCookie confirm_time return confirm_time is not None and util.GetCurrentTimestamp < confirm_time + _CONFIRM_TIME_LIMIT
def dnslookup str if str '' str ''if str[0] in string.digits try value socket.gethostbyaddr str [0]except value 'Lookupfailed'else try value socket.gethostbyname str except value 'Lookupfailed'return value
def init_parser parser argparse.ArgumentParser description 'Restoreapplicationcodeanddata.' main_args parser.add_argument_group 'mainargs' main_args.add_argument '-a' '--app-id' required True help 'TheapplicationIDtorestoredataunder.' main_args.add_argument '-b' '--backup-dir' required True help 'Thebackupdirectorytorestoredatafrom.' main_args.add_argument '-c' '--clear-datastore' required False action 'store_true' default False help 'Startwithacleandatastore.' main_args.add_argument '-d' '--debug' required False action 'store_true' default False help 'Displaydebugmessages.' return parser
def get_all_eip_addresses addresses None allocation_ids None region None key None keyid None profile None return [x.public_ip for x in _get_all_eip_addresses addresses allocation_ids region key keyid profile ]
def find_first_level_groups_span string enclosing opening closing enclosingdepth []result []for i c in enumerate string if c opening depth.append i elif c closing try start depth.pop end iif not depth result.append start end + 1 except IndexError passreturn result
@deprecated u'2.1' def allpairs x return [ s f for i f in enumerate x for s in x[ i + 1 ]]
def real_name magic_func magic_name magic_func.__name__if magic_name.startswith 'magic_' magic_name magic_name[len 'magic_' ]return getattr magic_func 'argcmd_name' magic_name
def createTicketMessage rawTicket HMACKey assert len rawTicket const.TICKET_LENGTH assert len HMACKey const.TICKET_HMAC_KEY_LENGTH padding mycrypto.strongRandom random.randint 0 const.MAX_PADDING_LENGTH - const.TICKET_LENGTH mark mycrypto.HMAC_SHA256_128 HMACKey rawTicket hmac mycrypto.HMAC_SHA256_128 HMACKey rawTicket + padding + mark + util.getEpoch return rawTicket + padding + mark + hmac
def _keygen_callback return
def getNewRepository return FillRepository
def author_name import getpassname getpass.getuser try import pwdlogin namename pwd.getpwnam login [4]name ''.join name.split ' ' if not name name loginexcept passtry name name.decode 'utf-8' except AttributeError passreturn name
def spawn_main pipe_handle parent_pid None tracker_fd None assert is_forking sys.argv if sys.platform 'win32' import msvcrtfrom .reduction import steal_handlenew_handle steal_handle parent_pid pipe_handle fd msvcrt.open_osfhandle new_handle os.O_RDONLY else from . import semaphore_trackersemaphore_tracker._semaphore_tracker._fd tracker_fdfd pipe_handleexitcode _main fd sys.exit exitcode
def process_command command options command_registry for entry in command_registry if command entry.command_name entry.process_commandline_request options returnraise ValueError 'Unknowncommand"{0}".'.format command
def markLocation stream RADIUS 5000stream.seek - RADIUS 1 outputDoc open 'PyPDF2_pdfLocation.txt' 'w' outputDoc.write stream.read RADIUS outputDoc.write 'HERE' outputDoc.write stream.read RADIUS outputDoc.close stream.seek - RADIUS 1
def missing_int L sum_n 0sum_n_less_1 0for i in range len L + 1 sum_n + isum_n_less_1 sum L return sum_n - sum_n_less_1
def onLogWrote logData pass
def test_more_than_one_package result list search_packages_info ['Pip' 'pytest' 'Virtualenv'] assert len result 3
def _getAccessibleAttribute attributeName if attributeName in globalAccessibleAttributeDictionary return globalAccessibleAttributeDictionary[attributeName]return None
def send_email_confirmation request user signup False from .models import EmailAddress EmailConfirmationCOOLDOWN_PERIOD timedelta minutes 3 email user_email user if email try email_address EmailAddress.objects.get_for_user user email if not email_address.verified if app_settings.EMAIL_CONFIRMATION_HMAC send_email Trueelse send_email not EmailConfirmation.objects.filter sent__gt now - COOLDOWN_PERIOD email_address email_address .exists if send_email email_address.send_confirmation request signup signup else send_email Falseexcept EmailAddress.DoesNotExist send_email Trueemail_address EmailAddress.objects.add_email request user email signup signup confirm True assert email_addressif send_email get_adapter request .add_message request messages.INFO 'account/messages/email_confirmation_sent.txt' {'email' email} if signup get_adapter request .stash_user request user_pk_to_url_str user
def trim_custom_directories repo older_than_days None if not repo returnif older_than_days is None older_than_days settings.get_value 'PACKAGES' 'custom_max_age' type int default 40 cmd 'find.-typef-atime+%s-execrm-f{}\\;' % older_than_days repo_run_command repo cmd ignore_status True
def _check_targets y_true y_pred check_consistent_length y_true y_pred type_true type_of_target y_true type_pred type_of_target y_pred y_type set [type_true type_pred] if y_type set ['binary' 'multiclass'] y_type set ['multiclass'] if len y_type > 1 raise ValueError "Can'thandlemixof{0}and{1}".format type_true type_pred y_type y_type.pop if y_type not in ['binary' 'multiclass' 'multilabel-indicator'] raise ValueError '{0}isnotsupported'.format y_type if y_type in ['binary' 'multiclass'] y_true column_or_1d y_true y_pred column_or_1d y_pred if y_type.startswith 'multilabel' y_true csr_matrix y_true y_pred csr_matrix y_pred y_type 'multilabel-indicator'return y_type y_true y_pred
def skip_unless_importable module msg None try __import__ module except ImportError return skip_if True msg else return skip_if False msg
def find_template template_name template_paths config['pylons.app_globals'].template_pathsfor path in template_paths if os.path.exists os.path.join path template_name.encode 'utf-8' return os.path.join path template_name
def do_cli manager options if options.list_action u'all' entry_list_lists options returnif options.list_action u'list' entry_list_list options returnif options.list_action u'show' entry_list_show options returnif options.list_action u'add' entry_list_add options returnif options.list_action u'del' entry_list_del options returnif options.list_action u'purge' entry_list_purge options return
def _search_param_in_docstr docstr param_str patterns [re.compile p % re.escape param_str for p in DOCSTRING_PARAM_PATTERNS]found Nonefor pattern in patterns match pattern.search docstr if match found [_strip_rst_role match.group 1 ]breakif found is not None return foundfound _search_param_in_numpydocstr docstr param_str if found is not None return foundreturn []
def precession_matrix_Capitaine fromepoch toepoch mat_fromto2000 matrix_transpose _precess_from_J2000_Capitaine fromepoch.jyear mat_2000toto _precess_from_J2000_Capitaine toepoch.jyear return np.dot mat_2000toto mat_fromto2000
def _check_mode handle mode ''if hasattr handle 'mode' mode handle.modeif mode 1 returnmode str mode if mode and 'U' in mode.upper raise ValueError 'SFFfilesmustNOTbeopenedinuniversalnewlinesmode.Binarymodeisrecommended althoughonUnixthedefaultmodeisalsofine .' elif mode and 'B' not in mode.upper and sys.platform 'win32' raise ValueError 'SFFfilesmustbeopenedinbinarymodeonWindows'
def optwrap text if not BODY_WIDTH return textassert wrap 'RequiresPython2.3.'result ''newlines 0for para in text.split '\n' if len para > 0 if para[0] is not '' and para[0] is not '-' and para[0] is not '*' for line in wrap para BODY_WIDTH result + line + '\n' result + '\n'newlines 2elif not onlywhite para result + para + '\n' newlines 1elif newlines < 2 result + '\n'newlines + 1return result
def _get_ips networks v4s networks.get 'v4' v6s networks.get 'v6' public_ips []private_ips []if v4s for item in v4s ip_type item.get 'type' ip_address item.get 'ip_address' if ip_type 'public' public_ips.append ip_address if ip_type 'private' private_ips.append ip_address if v6s for item in v6s ip_type item.get 'type' ip_address item.get 'ip_address' if ip_type 'public' public_ips.append ip_address if ip_type 'private' private_ips.append ip_address return public_ips private_ips
def _searchsorted array val side u'left' if hasattr array u'searchsorted' return array.searchsorted val side side begin 0end len array while begin < end mid begin + end // 2 if val > array[mid] begin mid + 1 elif val < array[mid] end midelif side u'right' begin mid + 1 else end midreturn begin
def save_history try readline.write_history_file c['HISTORY_FILENAME'] except pass
def parseFilePaths page if page for regex in FILE_PATH_REGEXES for match in re.finditer regex page absFilePath match.group 'result' .strip page page.replace absFilePath '' if isWindowsDriveLetterPath absFilePath absFilePath posixToNtSlashes absFilePath if absFilePath not in kb.absFilePaths kb.absFilePaths.add absFilePath
def _setDNSCache def _getaddrinfo *args **kwargs if args in kb.cache.addrinfo return kb.cache.addrinfo[args]else kb.cache.addrinfo[args] socket._getaddrinfo *args **kwargs return kb.cache.addrinfo[args]if not hasattr socket '_getaddrinfo' socket._getaddrinfo socket.getaddrinfosocket.getaddrinfo _getaddrinfo
def diff_expression tracked gitcmds.tracked_branch current gitcmds.current_branch if tracked and current ref tracked + u'..' + current else ref u'origin/master..'difftool.diff_expression qtutils.active_window ref
def parse_auth_header header parts header.split if parts[0].lower ! 'bearer' raise CasTokenError 'Unsupportedauthorizationtype' elif len parts 1 raise CasTokenError 'Missingtoken' elif len parts > 2 raise CasTokenError 'Tokencontainsspaces' return parts[1]
def verify_iterator_data assertEqual results count 0for count result in enumerate results 1 params get_all_primitive_params result[0] assertEqual len params len result msg 'Nottherightnumberofcolumns?' for expected actual in zip params result assertEqual actual expected return count
def init mpstate return CmdlongModule mpstate
def debugfile filename args None wdir None post_mortem False debugger pdb.Pdb filename debugger.canonic filename debugger._wait_for_mainpyfile 1debugger.mainpyfile filenamedebugger._user_requested_quit 0if os.name 'nt' filename filename.replace '\\' '/' debugger.run 'runfile %r args %r wdir %r ' % filename args wdir
@receiver SignalHandler.course_published def course_published_handler sender course_key **kwargs if not isinstance course_key CCXLocator send_ccx_course_published.delay unicode course_key
def DumpGC ob ADsGetObject 'GC ' IID_IADsContainer for sub_ob in ob print 'GCob %s %s ' % sub_ob.Name sub_ob.ADsPath
def symptom_minimum_password_age_greater_than_expires_days min_age CONF.security_compliance.minimum_password_ageexpires CONF.security_compliance.password_expires_daysreturn min_age > expires if min_age > 0 and expires > 0 else False
def p_direct_declarator_3 t pass
def values_reducer aggregation_fn return partial reduce_with aggregation_fn
def choice argument values try value argument.lower .strip except AttributeError raise ValueError 'mustsupplyanargument;choosefrom%s' % format_values values if value in values return valueelse raise ValueError '"%s"unknown;choosefrom%s' % argument format_values values
def dfs_absent path cmd_return _hadoop_cmd 'dfs' 'stat' path if 'Nosuchfileordirectory' in cmd_return return Trueelse return False
def configure_cloud_init cloudcfg open '/etc/cloud/cloud.cfg' 'w' cloudcfg.write CLOUD_INIT_CFG cloudcfg.close
def migrate_legacy_obj legacy_guid_file logger.info 'MigratinglegacyGuid{0}'.format legacy_guid_file._id storage_obj get_or_create_storage_file legacy_guid_file.node legacy_guid_file.name _id legacy_guid_file._id guid_obj Guid.load legacy_guid_file._id guid_obj.referent storage_objguid_obj.save return storage_obj
def clean_course_key course_key padding_char return 'course_{}'.format b32encode unicode course_key .replace ' ' padding_char
def PASCALVOC manifest_file manifest_root rois_per_img 256 height 1000 width 1000 inference False CLASSES '__background__' 'aeroplane' 'bicycle' 'bird' 'boat' 'bottle' 'bus' 'car' 'cat' 'chair' 'cow' 'diningtable' 'dog' 'horse' 'motorbike' 'person' 'pottedplant' 'sheep' 'sofa' 'train' 'tvmonitor' do_transforms not inference image_decode_cfg dict height height width width flip_enable do_transforms crop_enable False fixed_aspect_ratio True localization_cfg dict rois_per_image rois_per_img class_names CLASSES scaling_factor 1.0 / 16 return dict manifest_filename manifest_file manifest_root manifest_root type 'image localization' image image_decode_cfg cache_directory get_data_cache_or_nothing subdir 'pascalvoc_cache' shuffle_every_epoch do_transforms shuffle_manifest do_transforms minibatch_size 1 macrobatch_size 100 localization localization_cfg
def resolve_action bundle default_debug None allow_debug True if not settings.DEBUG or not allow_debug return True True if default_debug is None default_debug settings.ASSETS_DEBUGdebug bundle.debug if bundle.debug is not None else default_debug if debug 'merge' return True False elif debug is True return False False elif debug is False return True True else raise ValueError 'Invaliddebugvalue %s' % debug
def image_volume_cache_get_and_update_last_used context image_id **filters return IMPL.image_volume_cache_get_and_update_last_used context image_id **filters
def get_shared_secret_key provider_id secret getattr settings 'CREDIT_PROVIDER_SECRET_KEYS' {} .get provider_id if isinstance secret unicode try secret str secret except UnicodeEncodeError secret Nonelog.error u'Sharedsecretkeyforcreditprovider"%s"containsnon-ASCIIunicode.' provider_id return secret
def is_ipv4_filter ip options None return _is_ipv ip 4 options options
def _service_path name if not SERVICE_DIR raise CommandExecutionError 'Couldnotfindservicedirectory.' return os.path.join SERVICE_DIR name
def new_figure_manager_given_figure num figure canvas FigureCanvasMac figure manager FigureManagerMac canvas num return manager
def _contains_ch_type info ch_type if not isinstance ch_type string_types raise ValueError '`ch_type`isofclass{actual_class}.Itmustbe`str`'.format actual_class type ch_type meg_extras ['mag' 'grad' 'planar1' 'planar2']fnirs_extras ['hbo' 'hbr']valid_channel_types sorted [key for key in _PICK_TYPES_KEYS if key ! 'meg' ] + meg_extras + fnirs_extras if ch_type not in valid_channel_types raise ValueError 'ch_typemustbeoneof%s not"%s"' % valid_channel_types ch_type if info is None raise ValueError 'Cannotcheckforchannelsoftype"%s"becauseinfoisNone' % ch_type return ch_type in [channel_type info ii for ii in range info['nchan'] ]
def test_make_eeg_average_ref_proj raw read_raw_fif raw_fname preload True eeg mne.pick_types raw.info meg False eeg True assert_true not np.all raw._data[eeg].mean axis 0 < 1e-19 car make_eeg_average_ref_proj raw.info reref raw.copy reref.add_proj car reref.apply_proj assert_array_almost_equal reref._data[eeg].mean axis 0 0 decimal 19 raw.info['custom_ref_applied'] Trueassert_raises RuntimeError make_eeg_average_ref_proj raw.info
def dealias dsk keys None dependencies None keys keys or set if not isinstance keys set keys set keys if not dependencies dependencies {k get_dependencies dsk k for k in dsk}aliases set k for k task in dsk.items if ishashable task and task in dsk dsk2 inline dsk aliases inline_constants False for k in aliases.difference keys del dsk2[k]return dsk2
def _convert_to_line_delimits s if not s[0] '[' and s[ -1 ] ']' return ss s[1 -1 ]from pandas.lib import convert_json_to_linesreturn convert_json_to_lines s
@then 'thecommandoutputshouldcontainthefollowinglogrecords' def step_command_output_should_contain_log_records context assert context.table 'REQUIRE context.table'context.table.require_columns ['category' 'level' 'message'] format getattr context 'log_record_format' context.config.logging_format for row in context.table.rows output LogRecordTable.make_output_for_row row format context.execute_steps u'\nThenthecommandoutputshouldcontain \n"""\n{expected_output}\n"""\n'.format expected_output output
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def recursive_keypairs d for name value in sorted d.iteritems if isinstance value dict for subname subvalue in recursive_keypairs value yield '%s %s' % name subname subvalue elif isinstance value tuple list yield name list map lambda x unicode x .encode 'utf-8' value else yield name value
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def _iter_module_files for module in list sys.modules.values if module is None continuefilename getattr module '__file__' None if filename old Nonewhile not os.path.isfile filename old filenamefilename os.path.dirname filename if filename old breakelse if filename[ -4 ] in '.pyc' '.pyo' filename filename[ -1 ] yield filename
def max_pool_2x2 input_ return tf.nn.max_pool input_ ksize [1 2 2 1] strides [1 2 2 1] padding 'SAME'
@addon_view@waffle_switch 'reviews-translate' @non_atomic_requestsdef translate request addon review_id language review get_object_or_404 Review.objects pk review_id addon addon if '-' in language language language.split '-' [0]if request.is_ajax title r _retrieve_translation review.title language body r _retrieve_translation review.body language return http.HttpResponse json.dumps {'title' title 'body' body} status r.status_code else return redirect settings.GOOGLE_TRANSLATE_REDIRECT_URL.format lang language text urlquote review.body safe ''
def CreateLDIF dn record base64_attrs None cols 76 f StringIO ldif_writer LDIFWriter f base64_attrs cols '\n' ldif_writer.unparse dn record s f.getvalue f.close return s
def verify_zmq if zmq is None raise unittest.SkipTest
def gitStatus path cmd gitCmdBase path + ['status' '--porcelain'] return runSubprocess cmd stderr None universal_newlines True
def exit setConfigOptions exitCleanup False atexit._run_exitfuncs if sys.platform 'darwin' for fd in range 3 4096 if fd not in [7] os.close fd else os.closerange 3 4096 os._exit 0
def test_sp2 sp SequencePattern 'sorted' in_seq_len 20 out_seq_len 5 x np.random.randint 0 9 20 y sp.generate_output_sequence x assert len y 5 y_exp sorted x [ 5]assert all y y_exp
def find_all_stacktraces data rv []exc_container data.get 'sentry.interfaces.Exception' if exc_container for exc in exc_container['values'] stacktrace exc.get 'stacktrace' if stacktrace rv.append stacktrace exc stacktrace data.get 'sentry.interfaces.Stacktrace' if stacktrace rv.append stacktrace None threads data.get 'threads' if threads for thread in threads['values'] stacktrace thread.get 'stacktrace' if stacktrace rv.append stacktrace thread return rv
def any2utf8 text errors 'strict' encoding 'utf8' if isinstance text unicode return text.encode 'utf8' return unicode text encoding errors errors .encode 'utf8'
def _create_dispatcher_class cls classname bases dict_ if hasattr cls 'dispatch' dispatch_base cls.dispatch.__class__else dispatch_base _Dispatchevent_names [k for k in dict_ if _is_event_name k ]dispatch_cls type '%sDispatch' % classname dispatch_base {'__slots__' event_names} dispatch_cls._event_names event_namesdispatch_inst cls._set_dispatch cls dispatch_cls for k in dispatch_cls._event_names setattr dispatch_inst k _ClsLevelDispatch cls dict_[k] _registrars[k].append cls for super_ in dispatch_cls.__bases__ if issubclass super_ _Dispatch and super_ is not _Dispatch for ls in super_._events.dispatch._event_descriptors setattr dispatch_inst ls.name ls dispatch_cls._event_names.append ls.name if getattr cls '_dispatch_target' None cls._dispatch_target.dispatch dispatcher cls
def is_hg_installed return programs.find_program 'hg' is not None
def _data_files vendor_libs data [_app_path u'share/git-cola/bin' u'*' _app_path u'share/git-cola/icons' u'*.png' _app_path u'share/git-cola/icons' u'*.svg' _app_path u'share/git-cola/icons/dark' u'*.png' _app_path u'share/git-cola/icons/dark' u'*.svg' _app_path u'share/appdata' u'*.xml' _app_path u'share/applications' u'*.desktop' _app_path u'share/doc/git-cola' u'*.rst' _app_path u'share/doc/git-cola' u'*.html' _package u'cola' _package u'cola.models' _package u'cola.widgets' ]if vendor_libs data.extend [_package u'qtpy' _package u'qtpy._patch' ] data.extend [_app_path localedir u'git-cola.mo' for localedir in glob u'share/locale/*/LC_MESSAGES' ] return data
def parse_list_header value result []for item in parse_http_list value if item[ 1] item[ -1 ] '"' item unquote_header_value item[1 -1 ] result.append item return result
def get_disabled return _get_svc_list status 'DISABLED'
def fill_in_subscriptions apps schema_editor Project apps.get_model u'trans' u'Project' Group apps.get_model u'auth' u'Group' Profile apps.get_model u'accounts' u'Profile' for project in Project.objects.all for owner in project.owners.all try owner.profile.subscriptions.add project except Profile.DoesNotExist passif project.enable_acl try group Group.objects.get name project.name for user in group.user_set.all try user.profile.subscriptions.add project except Profile.DoesNotExist passexcept Group.DoesNotExist pass
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_exercises_from_topics topicId_list exs []for topic in topicId_list if topic exercises get_topic_contents topic_id topic kinds ['Exercise'] [ 5]for e in exercises exs + [e['id']]return exs
def bad_title title for pat in BAD_TITLE_PATTERNS if re.match pat title re.IGNORECASE return Truereturn False
def extract_zip source tempdir tempfile.mkdtemp zip SafeUnzip source try if zip.is_valid zip.extract_to_dest tempdir except rm_local_tmp_dir tempdir raisereturn tempdir
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def pretty_indent elem level 0 i '\n' + level * '' if len elem if not elem.text or not elem.text.strip elem.text i + '' if not elem.tail or not elem.tail.strip elem.tail ifor elem in elem pretty_indent elem level + 1 if not elem.tail or not elem.tail.strip elem.tail ielif level and not elem.tail or not elem.tail.strip elem.tail i
def row_norms X squared False if issparse X if not isinstance X csr_matrix X csr_matrix X norms csr_row_norms X else norms np.einsum 'ij ij->i' X X if not squared np.sqrt norms norms return norms
def display_waypoints wploader map mission_list wploader.view_list polygons wploader.polygon_list map.add_object mp_slipmap.SlipClearLayer 'Mission' for i in range len polygons p polygons[i]if len p > 1 map.add_object mp_slipmap.SlipPolygon 'mission%u' % i p layer 'Mission' linewidth 2 colour 255 255 255 labeled_wps {}for i in range len mission_list next_list mission_list[i]for j in range len next_list if next_list[j] not in labeled_wps map.add_object mp_slipmap.SlipLabel 'miss_cmd%u/%u' % i j polygons[i][j] str next_list[j] 'Mission' colour 0 255 255 labeled_wps[next_list[j]] i j
def gf_from_dict f p K n h max f.keys [] if isinstance n SYMPY_INTS for k in range n -1 -1 h.append f.get k K.zero % p else n nfor k in range n -1 -1 h.append f.get k K.zero % p return gf_trunc h p
def patch_user_model def get_absolute_url self return reverse 'users.profile' args [self.pk] User.get_absolute_url get_absolute_url
def usecase4 x N for k in range N y x[k]print y.f1 x.s1[k] y.f2
def getIsBracketed word if len word < 2 return FalsefirstCharacter word[0]lastCharacter word[ -1 ]if firstCharacter ' ' and lastCharacter ' ' return Truereturn firstCharacter '[' and lastCharacter ']'
def sort_dict_by_values adict return OrderedDict sorted adict.items key lambda item item[1]
def gf_rem f g p K return gf_div f g p K [1]
def encode string encoding None if type string is not ustr return stringreturn string.encode encoding or u'utf-8' u'replace'
def _get_spreadsheet_headers client spreadsheet_key worksheet_id headers []query CellQuery query.max_row '1'query.min_row '1'feed client.GetCellsFeed spreadsheet_key worksheet_id query query visibility 'public' projection 'values' while True for entry in feed.entry headers.append entry.content.text next_link feed.GetNextLink if next_link feed client.Get next_link.href converter SpreadsheetsCellsFeedFromString else breakreturn headers
def store_multiple option opt value parser *args **kwargs for attribute in args setattr parser.values attribute None for key value in kwargs.items setattr parser.values key value
def get_minions log.debug 'sqlite3returner<get_minions>called' conn _get_conn ret None cur conn.cursor sql 'SELECTDISTINCTidFROMsalt_returns'cur.execute sql data cur.fetchall ret []for minion in data ret.append minion[0] _close_conn conn return ret
def _pty_size from fabric.state import win32if not win32 import fcntlimport termiosimport struct default_rows default_cols 24 80 rows cols default_rows default_cols if not win32 and isatty sys.stdout fmt 'HH'buffer struct.pack fmt 0 0 try result fcntl.ioctl sys.stdout.fileno termios.TIOCGWINSZ buffer rows cols struct.unpack fmt result if rows 0 rows default_rowsif cols 0 cols default_colsexcept AttributeError passreturn rows cols
def create_directories for d in config.SECUREDROP_DATA_ROOT config.STORE_DIR config.GPG_KEY_DIR config.TEMP_DIR if not os.path.isdir d os.mkdir d
def update_mappings mappings section option try mapping mappings[section][option]except KeyError returnvalue config.get section option mapping.set value
def storeRow location row country statistic row[2].strip if statistic 'Newcases' returnvalue row[3]if value in None '' '' value Noneelse value int value date_t xlrd.xldate_as_tuple row[4] 0 date '%d-%02d-%02d' % date_t[0] date_t[1] date_t[2] source row[5].strip org get_org_from_db source country if row[6] ! None source_url row[6].strip else source_url ''if statistic not in statistics statistics[statistic] {}if location not in statistics[statistic] statistics[statistic][location] {}statistics[statistic][location][date] [value org source_url]
def test_terminal_summary_warnings_are_displayed testdir testdir.makeconftest "\ndefpytest_terminal_summary terminalreporter \nconfig terminalreporter.config\nconfig.warn 'C1' 'internalwarning' \n" result testdir.runpytest '-rw' result.stdout.fnmatch_lines ['*C1*internalwarning' '* 1pytest-warningsin*']
def update_etag_is_at_header req name if ' ' in name raise ValueError 'Headernamemustnotcontaincommas' existing req.headers.get 'X-Backend-Etag-Is-At' req.headers['X-Backend-Etag-Is-At'] csv_append existing name
def build_ffi_for_binding module_prefix modules pre_include '' post_include '' libraries [] extra_compile_args [] extra_link_args [] types []includes []functions []macros []customizations []for name in modules module_name module_prefix + name __import__ module_name module sys.modules[module_name]types.append module.TYPES macros.append module.MACROS functions.append module.FUNCTIONS includes.append module.INCLUDES customizations.append module.CUSTOMIZATIONS verify_source '\n'.join [pre_include] + includes + [post_include] + functions + customizations ffi build_ffi cdef_source '\n'.join types + functions + macros verify_source verify_source libraries libraries extra_compile_args extra_compile_args extra_link_args extra_link_args return ffi
def g return 5
def getEnumeratorKeysAlwaysList enumerator keys if keys.__class__ ! list return [keys]if len keys 1 return keysreturn getEnumeratorKeysExceptForOneArgument enumerator keys
def reverify_hosts **filter_data hosts models.Host.query_objects filter_data models.AclGroup.check_for_acl_violation_hosts hosts for host in hosts models.SpecialTask.schedule_special_task host models.SpecialTask.Task.VERIFY return list sorted host.hostname for host in hosts
def freqresp system w None n 10000 if isinstance system lti if isinstance system TransferFunction ZerosPolesGain sys systemelse sys system._as_zpk elif isinstance system dlti raise AttributeError 'freqrespcanonlybeusedwithcontinuous-timesystems.' else sys lti *system ._as_zpk if sys.inputs ! 1 or sys.outputs ! 1 raise ValueError 'freqresp requiresaSISO singleinput singleoutput system.' if w is not None worN welse worN nif isinstance sys TransferFunction w h freqs sys.num.ravel sys.den worN worN elif isinstance sys ZerosPolesGain w h freqs_zpk sys.zeros sys.poles sys.gain worN worN return w h
def MultiIndicator pos size dtype x numpy.zeros size dtype dtype if hasattr pos '__iter__' for i in pos x[i] 1else x[pos] 1return x
def besselap N norm 'phase' if abs int N ! N raise ValueError 'Filterordermustbeanonnegativeinteger' if N 0 p []k 1else p 1 / _bessel_zeros N a_last _falling_factorial 2 * N N // 2 ** N if norm in 'delay' 'mag' k a_lastif norm 'mag' norm_factor _norm_factor p k p / norm_factork norm_factor ** - N * a_last elif norm 'phase' p * 10 ** - math.log10 a_last / N k 1else raise ValueError 'normalizationnotunderstood' return asarray [] asarray p dtype complex float k
def get_padding_type kernel_params input_shape output_shape k_h k_w s_h s_w p_h p_w kernel_paramss_o_h np.ceil input_shape.height / float s_h s_o_w np.ceil input_shape.width / float s_w if output_shape.height s_o_h and output_shape.width s_o_w return 'SAME'v_o_h np.ceil input_shape.height - k_h + 1.0 / float s_h v_o_w np.ceil input_shape.width - k_w + 1.0 / float s_w if output_shape.height v_o_h and output_shape.width v_o_w return 'VALID'return None
def DirCheck path path PathCheck path if not os.path.isdir path raise ValueError _ 'Notadirectory %s' % path return path
def get_user_dept request user_id request.user.idif user_id user_dept User.objects.get id user_id .deptreturn user_dept.id
def pagingRequestType1 MobileId_presence 0 a L2PseudoLength b TpPd pd 6 c MessageType mesType 33 d PageModeAndChannelNeeded f MobileId packet a / b / c / d / f if MobileId_presence is 1 g MobileIdHdr ieiMI 23 eightBitMI 0 packet packet / g h P1RestOctets packet packet / h return packet
def deprecate_bear bear bear.old_run bear.rundef warn_deprecation_and_run *args **kwargs logging.warning 'Thebear{}isdeprecated.Use{}instead!'.format bear.__name__ bear.__bases__[0].__name__ return bear.old_run *args **kwargs bear.run warn_deprecation_and_runreturn bear
def test_solve_variable_trajectory t0 k0 tol 0 np.array [5.0] 0.001 results _compute_variable_length_solns model t0 k0 g _termination_condition tol tol for integrator numeric_solution in results.items ti numeric_solution[ 0]analytic_solution solow_analytic_solution ti k0 *valid_params np.testing.assert_allclose numeric_solution analytic_solution diff numeric_solution[ -1 1 ] - solow_steady_state *valid_params nose.tools.assert_less_equal diff tol
def sample_iter_lambdify expr condition None numsamples S.Infinity **kwargs if condition ps pspace Tuple expr condition else ps pspace expr rvs list ps.values fn lambdify rvs expr **kwargs if condition given_fn lambdify rvs condition **kwargs try d ps.sample args [d[rv] for rv in rvs]fn *args if condition given_fn *args except Exception raise TypeError 'Expr/conditiontoocomplexforlambdify' def return_generator count 0while count < numsamples d ps.sample args [d[rv] for rv in rvs]if condition gd given_fn *args if gd ! True and gd ! False raise ValueError 'Conditionsmustnotcontainfreesymbols' if not gd continue yield fn *args count + 1return return_generator
def dnn_gradinput3d kerns topgrad img_shp border_mode 'valid' subsample 1 1 conv_mode 'conv' kerns gpu_contiguous kerns topgrad gpu_contiguous topgrad img_shp theano.tensor.as_tensor_variable img_shp desc GpuDnnConvDesc border_mode border_mode subsample subsample conv_mode conv_mode img_shp kerns.shape out gpu_alloc_empty *img_shp return GpuDnnConv3dGradI kerns topgrad out desc
def pbkdf2_bin data salt iterations 1000 keylen 24 hashfunc None hashfunc hashfunc or hashlib.sha1 mac hmac.new data None hashfunc def _pseudorandom x mac mac h mac.copy h.update x return [ord _ for _ in h.digest ]buf []for block in range 1 - - keylen // mac.digest_size + 1 rv u _pseudorandom salt + _pack_int block for i in range iterations - 1 u _pseudorandom ''.join map chr u rv starmap xor zip rv u buf.extend rv return ''.join map chr buf [ keylen]
def make_validation_result data if not settings.EXPOSE_VALIDATOR_TRACEBACKS if data['error'] data['error'] _ 'Anerroroccurredvalidatingthemanifest.' if data['validation'] for msg in data['validation']['messages'] for k v in msg.items msg[k] escape_all v linkify k in 'message' 'description' return data
def findSystemLibrary name if os.path.isabs name return nameif is_unix return findLibrary name elif is_win return getfullnameof name else return ctypes.util.find_library name
def device_from_request request from mezzanine.conf import settingstry for device _ in settings.DEVICE_USER_AGENTS if device request.COOKIES[u'mezzanine-device'] return deviceexcept KeyError try user_agent request.META[u'HTTP_USER_AGENT'].lower except KeyError passelse try user_agent user_agent.decode u'utf-8' for device ua_strings in settings.DEVICE_USER_AGENTS for ua_string in ua_strings if ua_string.lower in user_agent return deviceexcept AttributeError UnicodeDecodeError UnicodeEncodeError passreturn u''
def get_image_files_from_fobj layer_file layer_file.seek 0 archive_file Archive layer_file tar_file tarfile.open fileobj archive_file files read_tarfile tar_file return files
def format_error error_code message return {'errors' [{'code' error_code 'message' message}]}
def get_available_languages stopword_files os.listdir os.path.join settings.STOPWORDS_DIR two_dig_codes [f.split '-' [1].split '.' [0] for f in stopword_files]for d in two_dig_codes assert len d 2 return two_dig_codes
def irfft x n None axis -1 overwrite_x False tmp _asfarray x if not numpy.isrealobj tmp raise TypeError '1stargumentmustberealsequence' try work_function _DTYPE_TO_RFFT[tmp.dtype]except KeyError raise ValueError 'type%sisnotsupported' % tmp.dtype overwrite_x overwrite_x or _datacopied tmp x return _raw_fft tmp n axis -1 overwrite_x work_function
def test_out_with_nonstring_null table Table [[3]] masked True out StringIO ascii.write table out Writer Ipac fill_values [ masked -99999 ] expected_out '|col0|\n|long|\n||\n|-99999|\n3\n'assert out.getvalue .strip .splitlines expected_out.splitlines
def _build_service test service AgentLoopService reactor MemoryReactorClock deployer ControllableDeployer u'127.0.0.1' [] [] host u'example.com' port 1234 context_factory ClientContextFactory era uuid4 service.cluster_status StubFSM return service
def parse_form_data environ stream_factory None charset 'utf-8' errors 'replace' max_form_memory_size None max_content_length None cls None silent True return FormDataParser stream_factory charset errors max_form_memory_size max_content_length cls silent .parse_from_environ environ
def sanitize_module_name module_name module_name module_name.replace '-' '_' .replace '.' '_' if module_name[0] not in string.ascii_letters module_name 'a' + module_name return module_name
def hardware_report options sys.stdout.write list_hardware return succeed None
@lower_builtin 'getitem' types.Buffer types.Array def fancy_getitem_array context builder sig args aryty idxty sig.args ary idx argsary make_array aryty context builder ary if idxty.ndim 0 idxty idx normalize_index context builder idxty idx res _getitem_array_generic context builder sig.return_type aryty ary idxty idx return impl_ret_borrowed context builder sig.return_type res else return fancy_getitem context builder sig args aryty ary idxty idx
def normalize_paths value parent os.curdir if not value or isinstance value list return valuepaths []for path in value.split ' ' if '/' in path path os.path.abspath os.path.join parent path paths.append path.rstrip '/' return paths
def left_d_threshold_sequence n m cs ['d'] + ['i'] * n - 1 if m < n cs[m] 'd'return csif m > n * n - 1 / 2 raise ValueError 'Toomanyedgesforthismanynodes.' cs[ n - 1 ] 'd'sum n - 1 ind 1while sum < m cs[ind] 'd'sum + indind + 1if sum > m cs[ sum - m ] 'i'return cs
def _unicode string encoding None if isinstance string compat.unicode unicode_string stringelif isinstance string compat.bytes if encoding is None encoding sys.stdin.encodingif encoding is None encoding locale.getpreferredencoding unicode_string string.decode encoding 'ignore' else unicode_string compat.unicode string return unicode_string.replace '\x00' '' .strip
def _solve_abs f symbol domain if not domain.is_subset S.Reals raise ValueError filldedent '\nAbsolutevaluescannotbeinvertedinthe\ncomplexdomain.' p q r Wild 'p' Wild 'q' Wild 'r' pattern_match f.match p * Abs q + r or {} if not pattern_match.get p S.Zero .is_zero f_p f_q f_r pattern_match[p] pattern_match[q] pattern_match[r] q_pos_cond solve_univariate_inequality f_q > 0 symbol relational False q_neg_cond solve_univariate_inequality f_q < 0 symbol relational False sols_q_pos solveset_real f_p * f_q + f_r symbol .intersect q_pos_cond sols_q_neg solveset_real f_p * - f_q + f_r symbol .intersect q_neg_cond return Union sols_q_pos sols_q_neg else return ConditionSet symbol Eq f 0 domain
def rUpdate original updates dictPairs [ original updates ]while len dictPairs > 0 original updates dictPairs.pop for k v in updates.iteritems if k in original and isinstance original[k] dict and isinstance v dict dictPairs.append original[k] v else original[k] v
def is_plural text return text.find PLURAL_SEPARATOR ! -1
def square_soft input_list squared []neg [ x ** 2 for x in input_list if x < 0 ]pos [ x ** 2 for x in input_list if x > 0 ]neg.reverse while len squared ! len input_list if not neg squared.extend pos elif not pos squared.extend neg elif pos[0] > neg[0] squared.append neg.pop 0 else squared.append pos.pop 0 return squared
def _get_tag repo name try return [x for x in _all_tags repo if x[0] name ][0]except IndexError return False
@requires_pandasdef test_to_data_frame for path in [edf_path bdf_path] raw read_raw_edf path stim_channel None preload True _ times raw[0 10]df raw.to_data_frame assert_true df.columns raw.ch_names .all assert_array_equal np.round times * 1000.0 df.index.values[ 10] df raw.to_data_frame index None scalings {'eeg' 10000000000000.0} assert_true 'time' in df.index.names assert_array_equal df.values[ 0] raw._data[0] * 10000000000000.0
@frappe.whitelist def make_width_property_setter doc if isinstance doc basestring doc json.loads doc if doc[u'doctype'] u'PropertySetter' and doc[u'property'] u'width' frappe.get_doc doc .insert ignore_permissions True
def get_gold_and_foreign_reserves rdint vs.random request Request vs.MACRO_URL % vs.P_TYPE['http'] vs.DOMAINS['sina'] rdint vs.MACRO_TYPE[2] 5 200 rdint text urlopen request timeout 10 .read text text.decode 'gbk' regSym re.compile '\\ count .*? \\}' datastr regSym.findall text datastr datastr[0]datastr datastr.split 'data ' [1]js json.loads datastr df pd.DataFrame js columns vs.GOLD_AND_FOREIGN_CURRENCY_RESERVES for i in df.columns df[i] df[i].apply lambda x np.where x is None '--' x return df
def _parse_pkg_string pkg pkg_name separator pkg_ver pkg.partition '-' return pkg_name.strip separator pkg_ver.strip
def upcast_int8_nfunc fn def ret *args **kwargs args list args for i a in enumerate args if getattr a 'dtype' None in 'int8' 'uint8' args[i] a.astype 'float32' return fn *args **kwargs return ret
def symlink_list saltenv 'base' backend None fileserver salt.fileserver.Fileserver __opts__ load {'saltenv' saltenv 'fsbackend' backend}return fileserver.symlink_list load load
def __WCS_unpickle__ cls dct fits_data self cls.__new__ cls self.__dict__.update dct buffer io.BytesIO fits_data hdulist fits.open buffer WCS.__init__ self hdulist[0].header hdulist return self
def install_gem name version None install_args None override_args False return install name version version source 'ruby' install_args install_args override_args override_args
@image_comparison baseline_images [u'tight_layout2'] def test_tight_layout2 fig ax1 ax2 ax3 ax4 plt.subplots nrows 2 ncols 2 example_plot ax1 example_plot ax2 example_plot ax3 example_plot ax4 plt.tight_layout
def _show_normalized_node full_node public_ips full_node.get 'eip' [] if public_ips public_ip public_ips['eip_addr']public_ips [public_ip]private_ips []for vxnet in full_node.get 'vxnets' [] private_ip vxnet.get 'private_ip' None if private_ip private_ips.append private_ip normalized_node {'id' full_node['instance_id'] 'image' full_node['image']['image_id'] 'size' full_node['instance_type'] 'state' full_node['status'] 'private_ips' private_ips 'public_ips' public_ips}return normalized_node
def parseTargetUrl url retVal urlif not re.search '^http[s]* //' retVal re.I and not re.search '^ws[s]* //' retVal re.I if re.search ' 443[/]*$' retVal retVal 'https //' + retVal else retVal 'http //' + retVal return retVal
def generate_shell_test target source env target str target[0] script open target 'w' print >>script '#!/bin/sh'print >>script '#Autogeneratedwrappershellscriptbyblade\n'print >>script 'set-e\n'for s in source print >>script '.%s' % os.path.abspath str s print >>scriptscript.close os.chmod target 493 return None
def _GetSecret io_loop secret print '%s \n%s' % secret _GetSecretsManager .GetSecret secret io_loop.stop
def sum x axis None return Sum axis x
def test_adjust_sigmoid_cutoff_one image np.arange 0 255 4 np.uint8 .reshape 8 8 expected np.array [[1 1 1 2 2 2 2 2] [3 3 3 4 4 4 5 5] [5 6 6 7 7 8 9 10] [10 11 12 13 14 15 16 18] [19 20 22 24 25 27 29 32] [34 36 39 41 44 47 50 54] [57 61 64 68 72 76 80 85] [89 94 99 104 108 113 118 123]] dtype np.uint8 result exposure.adjust_sigmoid image 1 5 assert_array_equal result expected
def get_metrics global NIMETRICS LAST_NIMETRICS SNMPTABLEif time.time - NIMETRICS['time'] > NIMETRICS_CACHE_MAX metrics {}for para in NIPARAMS.keys if para.startswith 'switch_' ipaddr name NIPARAMS[para].split ' ' threading.Thread runSnmp oidDict ipaddr snmpTable SNMPTABLE[ipaddr]newmetrics buildDict oidDict snmpTable name metrics dict newmetrics **metrics LAST_NIMETRICS dict NIMETRICS NIMETRICS {'time' time.time 'data' metrics}return [NIMETRICS LAST_NIMETRICS]
def register linter linter.register_checker ExceptionsChecker linter
@expect_dimensions array 2 def permute_rows seed array rand np.random.RandomState seed return np.apply_along_axis rand.permutation 1 array
def validate_response response content response.contentstatus_code response.status_codetry parsed_content response.json except ValueError message content if content else 'NoContent' raise exceptions.PlotlyRequestError message status_code content message ''if isinstance parsed_content dict error parsed_content.get 'error' if error message errorelif response.ok returnif not message message content if content else 'NoContent' raise exceptions.PlotlyRequestError message status_code content
def _get_user_attempts request ip get_ip request username request.POST.get USERNAME_FORM_FIELD None if USE_USER_AGENT ua request.META.get 'HTTP_USER_AGENT' '<unknown>' [ 255]attempts AccessAttempt.objects.filter user_agent ua ip_address ip username username trusted True else attempts AccessAttempt.objects.filter ip_address ip username username trusted True if not attempts params {'ip_address' ip 'trusted' False}if USE_USER_AGENT params['user_agent'] uaif should_lock_out_by_combination_user_and_ip params['username'] usernameattempts AccessAttempt.objects.filter **params return attempts
def unload_kvm kvm_arch get_kvm_arch def unload_module mod return utils.system 'rmmod%s' % mod unloaded unload_module kvm_arch if not unloaded unloaded unload_module 'kvm' return unloaded
def iso G1 glist for G2 in glist if isomorphic G1 G2 return Truereturn False
def parse_episode_identifier ep_id error Noneidentified_by Noneif isinstance ep_id int if ep_id < 0 error u'sequencetypeepisodemustbehigherthan0'identified_by u'sequence'elif re.match u' ?i ^S\\d{1 4}E\\d{1 3}$' ep_id identified_by u'ep'elif re.match u'\\d{4}-\\d{2}-\\d{2}' ep_id identified_by u'date'else try ep_id int ep_id if ep_id < 0 error u'sequencetypeepisodemustbehigherthan0'identified_by u'sequence'except ValueError error u'`%s`isnotavalidepisodeidentifier.' % ep_id if error raise ValueError error return identified_by
def ensure_ca_filesystem ca_dir ca_folder if not os.path.exists ca_path genrootca_sh_path os.path.abspath os.path.join os.path.dirname __file__ 'CA' 'genrootca.sh' start os.getcwd fileutils.ensure_tree ca_dir os.chdir ca_dir utils.execute 'sh' genrootca_sh_path os.chdir start
def _select_datastore session data_stores best_match datastore_regex None storage_policy None allowed_ds_types ALL_SUPPORTED_DS_TYPES if storage_policy matching_ds _filter_datastores_matching_storage_policy session data_stores storage_policy if not matching_ds return best_matchelse matching_ds data_storesfor obj_content in matching_ds.objects if not hasattr obj_content 'propSet' continuepropdict vm_util.propset_dict obj_content.propSet if _is_datastore_valid propdict datastore_regex allowed_ds_types new_ds ds_obj.Datastore ref obj_content.obj name propdict['summary.name'] capacity propdict['summary.capacity'] freespace propdict['summary.freeSpace'] if best_match is None or new_ds.freespace > best_match.freespace best_match new_dsreturn best_match
def test_cp32527 d {'1' 1 '2' 1 '3' 1 'a7' 1 'a8' 1}d.pop 'a7' d['a8'] 5expected 1actual d.keys .count 'a8' AreEqual actual expected
def shared_floatx value name None borrow False dtype None **kwargs if dtype is None dtype theano.config.floatXreturn theano.shared theano._asarray value dtype dtype name name borrow borrow **kwargs
def get_prerequisite_courses_display course_descriptor pre_requisite_courses []if is_prerequisite_courses_enabled and course_descriptor.pre_requisite_courses for course_id in course_descriptor.pre_requisite_courses course_key CourseKey.from_string course_id required_course_descriptor modulestore .get_course course_key prc {'key' course_key 'display' get_course_display_string required_course_descriptor }pre_requisite_courses.append prc return pre_requisite_courses
def unormalize ustring ignorenonascii None substitute None if ignorenonascii is not None warn 'ignorenonasciiisdeprecated usesubstitutenamedparameterinstead' DeprecationWarning stacklevel 2 if ignorenonascii substitute ''res []for letter in ustring[ ] try replacement MANUAL_UNICODE_MAP[letter]except KeyError replacement _uninormalize 'NFKD' letter [0]if ord replacement > 2 ** 7 if substitute is None raise ValueError "can'tdealwithnon-asciibasedcharacters" replacement substituteres.append replacement return u''.join res
def _set_device_mtu dev mtu None if mtu utils.execute 'ip' 'link' 'set' dev 'mtu' mtu run_as_root True check_exit_code [0 2 254]
def attach_closed_points queryset as_field 'closed_points_attr' model queryset.modelsql 'SELECTSUM projects_points.value \nFROMuserstories_rolepoints\nINNERJOINuserstories_userstoryONuserstories_userstory.id userstories_rolepoints.user_story_id\nINNERJOINprojects_pointsONuserstories_rolepoints.points_id projects_points.id\nWHEREuserstories_userstory.milestone_id {tbl}.idANDuserstories_userstory.is_closed True'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def reset_format_cache global _format_cache _format_modules_cache_format_cache {}_format_modules_cache {}
def access_warn request msg None ai AccessInfo request ai.log logging.WARN msg
def consensus_score a b similarity 'jaccard' if similarity 'jaccard' similarity _jaccardmatrix _pairwise_similarity a b similarity indices linear_assignment 1.0 - matrix n_a len a[0] n_b len b[0] return matrix[ indices[ 0] indices[ 1] ].sum / max n_a n_b
def event_id name encode_types event_types [_canonical_type type_ for type_ in encode_types]event_signature '{event_name} {canonical_types} '.format event_name name canonical_types ' '.join event_types return big_endian_to_int utils.sha3 event_signature
def libvlc_media_list_player_pause p_mlp f _Cfunctions.get 'libvlc_media_list_player_pause' None or _Cfunction 'libvlc_media_list_player_pause' 1 None None MediaListPlayer return f p_mlp
@with_setup prepare_stdout def test_output_when_could_not_find_features_colorless path fs.relpath join abspath dirname __file__ 'no_features' 'unexistent-folder' runner Runner path verbosity 3 no_color True runner.run assert_stdout_lines 'Oops!\ncouldnotfindfeaturesat./%s\n' % path
def _build_tmp_access_args method ip ttl port direction comment opt _get_opt method args '{0}{1}{2}'.format opt ip ttl if port args + '-p{0}'.format port if direction args + '-d{0}'.format direction if comment args + '#{0}'.format comment return args
@treeio_login_required@handle_response_format@_process_mass_opportunity_formdef opportunity_index request response_format 'html' query Q status__hidden False if request.GET if 'status' in request.GET and request.GET['status'] query _get_filter_query request.GET else query query & _get_filter_query request.GET filters OpportunityFilterForm request.user.profile '' request.GET statuses Object.filter_by_request request SaleStatus.objects mode 'r' opportunities Object.filter_by_request request Opportunity.objects.filter query mode 'r' massform OpportunityMassActionForm request.user.profile return render_to_response 'sales/opportunity_index' {'opportunities' opportunities 'filters' filters 'massform' massform 'statuses' statuses} context_instance RequestContext request response_format response_format
@pytest.mark.parametrize 'fmt_name_class' fmt_name_classes def test_roundtrip_masked fmt_name_class fmt_name fmt_cls fmt_name_classif not getattr fmt_cls '_io_registry_can_write' True returnif fmt_name 'html' and not HAS_BEAUTIFUL_SOUP or fmt_name 'fixed_width' returnt simple_table masked True out StringIO fast fmt_name in ascii.core.FAST_CLASSES try ascii.write t out format fmt_name fast_writer fast except ImportError returnkwargs {'names' t.colnames} if 'no_header' in fmt_name else {} t2 ascii.read out.getvalue format fmt_name fast_reader fast guess False **kwargs assert t.colnames t2.colnames for col col2 in zip t.itercols t2.itercols assert col.dtype.kind col2.dtype.kind assert np.all col col2
def ensure_experimental test_fn def wrapper self *args **kwargs JunitTestsConcurrencyIntegrationTest.USE_EXPERIMENTAL_RUNNER Truetest_fn self *args **kwargs JunitTestsConcurrencyIntegrationTest.USE_EXPERIMENTAL_RUNNER Falsetest_fn self *args **kwargs return wrapper
def datestr2num d if cbook.is_string_like d dt dateutil.parser.parse d return date2num dt else return date2num [dateutil.parser.parse s for s in d]
def gf_random n p K return [K.one] + [K int uniform 0 p for i in range 0 n ]
def test_is_int int_enum usertypes.enum 'Enum' ['item'] is_int True no_int_enum usertypes.enum 'Enum' ['item'] assert isinstance int_enum.item int assert not isinstance no_int_enum.item int
def call_method class_obj method *args if method.is_retriever args args[ -1 ]else assert args[ -1 ] is not None 'Noargumentgiven.'if class_obj.__class__.__name__ 'RTorrent' rt_obj class_objelse rt_obj class_obj._rt_objif not method.is_available rt_obj _handle_unavailable_rpc_method method rt_obj m Multicall class_obj m.add method *args ret_value m.call [0]return ret_value
def validate_streamline x y if np is False raise ImportError 'FigureFactory.create_streamlinerequiresnumpy' for index in range len x - 1 if x[ index + 1 ] - x[index] - x[1] - x[0] > 0.0001 raise exceptions.PlotlyError 'xmustbea1dimensional evenlyspacedarray' for index in range len y - 1 if y[ index + 1 ] - y[index] - y[1] - y[0] > 0.0001 raise exceptions.PlotlyError 'ymustbea1dimensional evenlyspacedarray'
def noLongerProvides object interface directlyProvides object directlyProvidedBy object - interface if interface.providedBy object raise ValueError 'Canonlyremovedirectlyprovidedinterfaces.'
def _write_buffer_to_hash buffer_object hash_obj digest_block_size 8192 block buffer_object.read digest_block_size while len block > 0 hash_obj.update block block buffer_object.read digest_block_size
def configure_logging path None global _logging_configuredif _logging_configured return_logging_configured Trueif path is False returnelif path is None path '/tmp/universe-{}.log'.format os.getpid logger.info 'Writinglogstofile %s' path extra_logger.setLevel logging.DEBUG if path '-' returnroot_logger logging.getLogger formatter logging.Formatter '[% asctime s]% message s' handler logging.FileHandler path 'w' encoding 'UTF-8' handler.setFormatter formatter root_logger.addHandler handler extra_logger.propagate Falseextra_logger.addHandler handler
def getSelectedPlugin repository for plugin in repository.unpausePlugins if plugin.value return pluginreturn None
def test_hashable hash interval 1 1 hash interval 1 1 is_valid True hash interval -4 -0.5 hash interval -2 -0.5 hash interval 0.25 8.0
def show_fwrule kwargs None call None if call ! 'function' raise SaltCloudSystemExit 'Theshow_fwrulefunctionmustbecalledwith-for--function.' if not kwargs or 'name' not in kwargs log.error 'Mustspecifynameofnetwork.' return Falseconn get_conn return _expand_item conn.ex_get_firewall kwargs['name']
def _get_exploration_summaries_from_models exp_summary_models exploration_summaries [get_exploration_summary_from_model exp_summary_model for exp_summary_model in exp_summary_models]result {}for exp_summary in exploration_summaries result[exp_summary.id] exp_summaryreturn result
def assert_warnings fn warnings regex False from .assertions import eq_ emits_warningcanary []orig_warn util.warndef capture_warnings *args **kw orig_warn *args **kw popwarn warnings.pop 0 canary.append popwarn if regex assert re.match popwarn args[0] else eq_ args[0] popwarn util.warn util.langhelpers.warn capture_warningsresult emits_warning fn assert canary 'Nowarningwasemitted'return result
def report_flaky_tests output flaky_tests for test in flaky_tests output.write '{}\n'.format test
def kullback_leibler vec1 vec2 num_features None if scipy.sparse.issparse vec1 vec1 vec1.toarray if scipy.sparse.issparse vec2 vec2 vec2.toarray if isbow vec1 and isbow vec2 if num_features ! None dense1 sparse2full vec1 num_features dense2 sparse2full vec2 num_features return entropy dense1 dense2 else max_len max len vec1 len vec2 dense1 sparse2full vec1 max_len dense2 sparse2full vec2 max_len return entropy dense1 dense2 else if len vec1 1 vec1 vec1[0]if len vec2 1 vec2 vec2[0]return scipy.stats.entropy vec1 vec2
def path_glob pattern current_dir None if not current_dir current_dir pathlib.Path.cwd elif not isinstance current_dir pathlib.Path current_dir pathlib.Path str current_dir for p in current_dir.glob pattern yield Path str p
def generate_categories app None type None categories []categories_choices CATEGORIES[app.id][type]for category_choice in categories_choices.values defaults {'slug' category_choice.slug 'db_name' unicode category_choice.name 'application' app.id 'misc' category_choice.misc 'type' type 'weight' category_choice.weight} category created Category.objects.get_or_create id category_choice.id defaults defaults if not created category.db_name defaults.pop 'db_name' category.__dict__.update **defaults category.save categories.append category return categories
def _exp1 p x prec R p.ringp1 R 1 for precx in _giant_steps prec pt p - rs_log p1 x precx tmp rs_mul pt p1 x precx p1 + tmpreturn p1
def summation f *symbols **kwargs return Sum f *symbols **kwargs .doit deep False
def convertXMLElement geometryOutput xmlElement xmlElement.getXMLProcessor .createChildren geometryOutput['shapes'] xmlElement
def datastore_upsert context data_dict schema context.get 'schema' dsschema.datastore_upsert_schema records data_dict.pop 'records' None data_dict errors _validate data_dict schema context if records data_dict['records'] recordsif errors raise p.toolkit.ValidationError errors p.toolkit.check_access 'datastore_upsert' context data_dict if not data_dict.pop 'force' False resource_id data_dict['resource_id']_check_read_only context resource_id data_dict['connection_url'] config['ckan.datastore.write_url']res_id data_dict['resource_id']resources_sql sqlalchemy.text u'SELECT1FROM"_table_metadata"\nWHEREname idANDalias_ofISNULL' results db._get_engine data_dict .execute resources_sql id res_id res_exists results.rowcount > 0 if not res_exists raise p.toolkit.ObjectNotFound p.toolkit._ u'Resource"{0}"wasnotfound.'.format res_id result db.upsert context data_dict result.pop 'id' None result.pop 'connection_url' return result
def _buildResolvers config from twisted.names import client cache hosts ca cl [] [] if config['cache'] ca.append cache.CacheResolver verbose config['verbose'] if config['hosts-file'] cl.append hosts.Resolver file config['hosts-file'] if config['recursive'] cl.append client.createResolver resolvconf config['resolv-conf'] return ca cl
def volume_show name profile None conn _auth profile return conn.volume_show name
def get_topic_similarities_dict topic_similarities_entity recommendations_models.TopicSimilaritiesModel.get recommendations_models.TOPIC_SIMILARITIES_ID strict False if topic_similarities_entity is None topic_similarities_entity _create_default_topic_similarities return json.loads topic_similarities_entity.content
def lol_tuples head ind values dummies if not ind return headif ind[0] not in dummies return lol_tuples head + values[ind[0]] ind[1 ] values dummies else return [lol_tuples head + v ind[1 ] values dummies for v in dummies[ind[0]]]
def _is_dns_label name dns_label re.compile '^[a-z0-9][a-z0-9\\.-]{1 62}$' if dns_label.match name return Trueelse return False
@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def get_coupon_codes request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id coupons Coupon.objects.filter course_id course_id query_features [ 'code' _ 'CouponCode' 'course_id' _ 'CourseId' 'percentage_discount' _ '%Discount' 'description' _ 'Description' 'expiration_date' _ 'ExpirationDate' 'is_active' _ 'IsActive' 'code_redeemed_count' _ 'CodeRedeemedCount' 'total_discounted_seats' _ 'TotalDiscountedSeats' 'total_discounted_amount' _ 'TotalDiscountedAmount' ]db_columns [x[0] for x in query_features]csv_columns [x[1] for x in query_features]coupons_list instructor_analytics.basic.coupon_codes_features db_columns coupons course_id __ data_rows instructor_analytics.csvs.format_dictlist coupons_list db_columns return instructor_analytics.csvs.create_csv_response 'Coupons.csv' csv_columns data_rows
def _create_transport_serializers transport serializers []for serializer_id in transport.serializers if serializer_id u'msgpack' try from autobahn.wamp.serializer import MsgPackSerializerexcept ImportError passelse serializers.append MsgPackSerializer batched True serializers.append MsgPackSerializer elif serializer_id u'json' try from autobahn.wamp.serializer import JsonSerializerexcept ImportError passelse serializers.append JsonSerializer batched True serializers.append JsonSerializer else raise RuntimeError "Unknownserializer'{}'".format serializer_id return serializers
@FileSystem.in_directory current_directory 'django' 'alfaces' def test_excluding_apps_separated_by_comma status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 3--no-color--avoid-apps donothing foobar' assert_equals status 0 out assert 'TestthedjangoappDONOTHING' not in out assert 'TestthedjangoappFOOBAR' not in out
def add_glob_to_array _bondmems result []if isinstance _bondmems list for _entry in _bondmems if re.search '-' _entry _entry 'glob' + _entry result.append _entry return ''.join result return _bondmems
def BinarySIDtoStringSID sid if not sid return ''str_sid_components [ord sid[0] ]if len sid > 8 subauthority_count ord sid[1] identifier_authority struct.unpack '>H' sid[2 4] [0]identifier_authority << 32identifier_authority | struct.unpack '>L' sid[4 8] [0]str_sid_components.append identifier_authority start 8for i in range subauthority_count authority sid[start start + 4 ]if not authority breakif len authority < 4 raise ValueError "InbinarySID'%s' component%dhasbeentruncated.Expected4bytes found%d %s " ' '.join [str ord c for c in sid] i len authority authority str_sid_components.append struct.unpack '<L' authority [0] start + 4return 'S-%s' % '-'.join [str x for x in str_sid_components]
@with_open_mode 'r' @with_sizes 'medium' def read_big_chunks f f.seek 0 while f.read 4096 pass
def _get_per_location_glob tasks outputs regexes paths [o.path for o in outputs]matches [r.search p for r p in zip regexes paths ]for m p t in zip matches paths tasks if m is None raise NotImplementedError "Couldn'tdeducedatehourrepresentationinoutputpath%roftask%s" % p t n_groups len matches[0].groups positions [most_common m.start i m.end i for m in matches [0] for i in range 1 n_groups + 1 ]glob list paths[0] for start end in positions glob glob[ start] + ['[0-9]'] * end - start + glob[end ] return ''.join glob .rsplit '/' 1 [0]
def _ternary_filter ternary_value return ternary_value constants.TERNARY_YES
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def get_bucket_metadata bucket service create_service req service.buckets .get bucket bucket return req.execute
def _check_excludes_includes chs info None allow_bads False from .meas_info import Infoif not isinstance chs list tuple np.ndarray if allow_bads is True if not isinstance info Info raise ValueError 'Supplyaninfoobjectifallow_badsistrue' elif chs ! 'bads' raise ValueError 'Ifchsisastring itmustbe"bads"' else chs info['bads']else raise ValueError 'include/excludemustbelist tuple ndarray or"bads".' + 'Youprovidedtype{0}'.format type chs return chs
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def make_identifier name if isinstance name bytes identifier name.decode 'utf-8' else identifier nameidentifier identifier.lower identifier identifier.replace u'+' u'plus' identifier re.sub u'[_\xe2\x80\x93]+' u'-' identifier identifier re.sub u"['./;\xe2\x80\x99 ]" u'' identifier identifier identifier.replace u'\xc3\xa9' u'e' if identifier.startswith 'route-' identifier 'kalos-' + identifier if not identifier.replace u'-' u'' .isalnum raise ValueError identifier return identifier
def clear_placeholder_cache placeholder lang site_id version int time.time * 1000000 _set_placeholder_cache_version placeholder lang site_id version []
def __GetElementTree protocol server port path sslContext if protocol 'https' kwargs {'context' sslContext} if sslContext else {} conn http_client.HTTPSConnection server port port **kwargs elif protocol 'http' conn http_client.HTTPConnection server port port else raise Exception 'Protocol' + protocol + 'notsupported.' conn.request 'GET' path response conn.getresponse if response.status 200 try tree ElementTree.fromstring response.read return treeexcept ExpatError passreturn None
def remove_module_outliers module if module[ 35] 'sun.reflect.GeneratedMethodAccessor' return 'sun.reflect.GeneratedMethodAccessor'return _java_enhancer_re.sub '\\1<auto>' module
def vocabulary_update context data_dict model context['model']vocab_id data_dict.get 'id' if not vocab_id raise ValidationError {'id' _ 'idnotindata' } vocab model.vocabulary.Vocabulary.get vocab_id if vocab is None raise NotFound _ 'Couldnotfindvocabulary"%s"' % vocab_id data_dict['id'] vocab.idif data_dict.has_key 'name' if data_dict['name'] vocab.name del data_dict['name']_check_access 'vocabulary_update' context data_dict schema context.get 'schema' or schema_.default_update_vocabulary_schema data errors _validate data_dict schema context if errors model.Session.rollback raise ValidationError errors updated_vocab model_save.vocabulary_dict_update data context if not context.get 'defer_commit' model.repo.commit return model_dictize.vocabulary_dictize updated_vocab context
def get_view_content file_name active_window sublime.active_window active_view active_window.active_view if active_view.file_name file_name return _get_view_content active_view view active_window.find_open_file file_name if view return _get_view_content view for window in sublime.windows if window active_window continueview window.find_open_file file_name return _get_view_content view
def CgiDictFromParsedUrl url environ {}if url.port is not None environ['SERVER_PORT'] str url.port elif url.scheme 'https' environ['SERVER_PORT'] '443'elif url.scheme 'http' environ['SERVER_PORT'] '80'environ['QUERY_STRING'] url.queryenviron['SERVER_NAME'] url.hostnameif url.path environ['PATH_INFO'] urlparse.unquote url.path else environ['PATH_INFO'] '/'return environ
def register linter linter.register_checker ExceptionsChecker linter
def status_raw name None user None conf_file None bin_env None ret __salt__['cmd.run_all'] _ctl_cmd 'status' name conf_file bin_env runas user python_shell False return _get_return ret
def parse_uid uid if UIDFieldMixin.UID_SEPARATOR not in uid raise ValueError 'Invaliduid %s' % uid parsed uid.split UIDFieldMixin.UID_SEPARATOR if len parsed < 2 raise ValueError 'Invalidormalformeduid %s' % uid resource_type parsed[0]uid_remainder parsed[1 ]return resource_type uid_remainder
def install_signal_handlers signal.signal signal.SIGTERM _async_terminate signal.signal signal.SIGINT _async_terminate
def feed_view request url feed_dict None if not feed_dict raise django.http.Http404 'Nofeedsareregistered.' try slug param url.split '/' 1 except ValueError slug param url '' try f feed_dict[slug]except KeyError raise django.http.Http404 "Slug%risn'tregistered." % slug try feedgen f slug request .get_feed param except views.FeedDoesNotExist raise django.http.Http404 'Invalidfeedparameters.Slug%risvalid butotherparameters orlackthereof arenot.' % slug response django.http.HttpResponse mimetype feedgen.mime_type feedgen.write response 'utf-8' return response
def bump_cache_for_pk cls pk cache.bump_version '%s-%s' % _get_namespace_prefix cls pk
def getraw timeout None cs []c getch timeout while c ! None cs.append c if c None breakc getch return cs
def _AddOrAppend dictionary key value if key in dictionary existing_value dictionary[key]if isinstance existing_value list existing_value.append value else dictionary[key] [existing_value value]else dictionary[key] value
def zone_type return s3_rest_controller
def accumNpDicts d0 d1 for k in d1 if k in d0 d0[k] + d1[k]else d0[k] d1[k]
def term_job jid return signal_job jid signal.SIGTERM
def apply_choice session task if task.skip returnif task.apply task.apply_metadata plugins.send 'import_task_apply' session session task task task.add session.lib
def outdated_langpacks langpacks get_installed_language_packs force True for langpack in langpacks.itervalues langpackversion LooseVersion langpack.get 'software_version' or SHORTVERSION current_software_version LooseVersion SHORTVERSION if current_software_version > langpackversion yield langpack
def bytes2words data length 8 return np.fromstring data dtype np.uint64
def delete_org_user userid orgname None profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.delete '{0}/api/org/users/{1}'.format profile['grafana_url'] userid auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def show_ikepolicy ikepolicy profile None conn _auth profile return conn.show_ikepolicy ikepolicy
def _AddMockJSONResponse mock_client url response_dict def _CreateResponse request return httpclient.HTTPResponse request 200 headers {'Content-Type' 'application/json'} buffer StringIO json.dumps response_dict mock_client.map url _CreateResponse
def init mpstate return CmdlongModule mpstate
def random_port sock socket.socket socket.AF_INET socket.SOCK_STREAM sock.bind 'localhost' 0 port sock.getsockname [1]sock.close return port
def _convert_params sql params args [sql]if params is not None if hasattr params 'keys' args + [params]else args + [list params ]return args
def _find_build_tool toolname return _find_executable toolname or _read_output '/usr/bin/xcrun-find%s' % toolname or ''
def _create_dispatcher_class cls classname bases dict_ if hasattr cls 'dispatch' dispatch_base cls.dispatch.__class__else dispatch_base _Dispatchevent_names [k for k in dict_ if _is_event_name k ]dispatch_cls type '%sDispatch' % classname dispatch_base {'__slots__' event_names} dispatch_cls._event_names event_namesdispatch_inst cls._set_dispatch cls dispatch_cls for k in dispatch_cls._event_names setattr dispatch_inst k _ClsLevelDispatch cls dict_[k] _registrars[k].append cls for super_ in dispatch_cls.__bases__ if issubclass super_ _Dispatch and super_ is not _Dispatch for ls in super_._events.dispatch._event_descriptors setattr dispatch_inst ls.name ls dispatch_cls._event_names.append ls.name if getattr cls '_dispatch_target' None cls._dispatch_target.dispatch dispatcher cls
def ssh_file opts dest_path contents None kwargs None local_file None if opts.get 'file_transport' 'sftp' 'sftp' return sftp_file dest_path contents kwargs local_file return scp_file dest_path contents kwargs local_file
def is_setuptools_installed python_cmd 'python' version package_version 'setuptools' python_cmd python_cmd return version is not None
def opt options k defval '' try data getattr options k except return defvalreturn n2s data
def instance_get_all_by_grantee_security_groups context group_ids return IMPL.instance_get_all_by_grantee_security_groups context group_ids
def __oneshot_resume when global __PAUSE_ENDif __PAUSE_END is not None and when > __PAUSE_END - 5 and when < __PAUSE_END + 55 __PAUSE_END Nonelogging.debug 'Resumeafterpause-interval' sabnzbd.unpause_all else logging.debug 'Ignoringcancelledresume'
@utils.arg 'aggregate' metavar '<aggregate>' help _ 'NameorIDofaggregate.' @utils.arg 'host' metavar '<host>' help _ 'Thehosttoaddtotheaggregate.' def do_aggregate_add_host cs args aggregate _find_aggregate cs args.aggregate aggregate cs.aggregates.add_host aggregate.id args.host print _ 'Host% host shasbeensuccessfullyaddedforaggregate% aggregate_id s' % {'host' args.host 'aggregate_id' aggregate.id} _print_aggregate_details cs aggregate
def load_source name pathname if six.PY2 import impreturn imp.load_source name pathname else loader importlib.machinery.SourceFileLoader name pathname return loader.load_module name
def fetch_journal_entry db_access key result db_access.batch_get_entity JOURNAL_TABLE [key] JOURNAL_SCHEMA if len result.keys 0 return Noneif JOURNAL_SCHEMA[0] in result.keys [0] ent_string result[0][JOURNAL_SCHEMA[0]]if ent_string dbconstants.TOMBSTONE return Nonereturn entity_pb.EntityProto .ParseFromString ent_string else return None
def DNSServiceRegister flags 0 interfaceIndex kDNSServiceInterfaceIndexAny name None regtype _NO_DEFAULT domain None host None port _NO_DEFAULT txtRecord '' callBack None _NO_DEFAULT.check regtype _NO_DEFAULT.check port port socket.htons port if not txtRecord txtLen txtRecord 1 '\x00' else txtLen txtRecord _string_to_length_and_void_p txtRecord @_DNSServiceRegisterReplydef _callback sdRef flags errorCode name regtype domain context if callBack is not None callBack sdRef flags errorCode name.decode regtype.decode domain.decode _global_lock.acquire try sdRef _DNSServiceRegister flags interfaceIndex name regtype domain host port txtLen txtRecord _callback None finally _global_lock.release sdRef._add_callback _callback return sdRef
def test_hexoct class foo object def __hex__ self return selfdef __oct__ self return selfclass bar def __hex__ self return selfdef __oct__ self return selfAssertError TypeError hex foo AssertError TypeError oct foo AssertError TypeError hex bar AssertError TypeError oct bar
def get_create_or_change_title request instance name_field None if not instance.pk return _ u'New%s' % instance._meta.verbose_name if name_field name getattr instance name_field None else name u'%s' % instance if name return force_text name return _ u'Unnamed%s' % instance._meta.verbose_name
def download_all recommended False restart True to_download _get_available recommended restart for name in to_download download name return list_downloads
def base64_b64decode instr if six.PY3 b salt.utils.to_bytes instr data base64.b64decode b try return salt.utils.to_str data except UnicodeDecodeError return datareturn base64.b64decode instr
def get_netmask ip subnet if ip['version'] 4 return str subnet.as_netaddr .netmask return subnet.as_netaddr ._prefixlen
def dup_invert f g K s h dup_half_gcdex f g K if h [K.one] return dup_rem s g K else raise NotInvertible 'zerodivisor'
def test_cache_size_leq_max_cache_size config_stub tmpdir limit 100config_stub.data {'storage' {'cache-size' limit} 'general' {'private-browsing' False}}disk_cache cache.DiskCache str tmpdir assert disk_cache.maximumCacheSize limit preload_cache disk_cache 'http //www.example.com/' preload_cache disk_cache 'http //qutebrowser.org' preload_cache disk_cache 'http //foo.xxx' preload_cache disk_cache 'http //bar.net' assert disk_cache.expire < limit assert disk_cache.cacheSize < limit + 100
def detect_java_comm names for name in names try mod my_import name mod.SerialPortreturn modexcept ImportError AttributeError passraise ImportError 'NoJavaCommunicationsAPIimplementationfound'
def get_user_data userid profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile response requests.get '{0}/api/users/{1}'.format profile['grafana_url'] userid auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def IsMacBundle flavor spec is_mac_bundle int spec.get 'mac_bundle' 0 ! 0 and flavor 'mac' if is_mac_bundle assert spec['type'] ! 'none' 'mac_bundletargetscannothavetypenone target"%s" ' % spec['target_name'] return is_mac_bundle
def getdata im offset 0 0 **params class Collector object data []def write self data self.data.append data im.load fp Collector try im.encoderinfo params_get_local_header fp im offset 0 ImageFile._save im fp [ 'gif' 0 0 + im.size 0 RAWMODE[im.mode] ] fp.write '\x00' finally del im.encoderinforeturn fp.data
def _smart_subs expr sub_dict expr _crawl expr _tan_repl_func def _recurser expr sub_dict num den _fraction_decomp expr if den ! 1 denom_subbed _recurser den sub_dict if denom_subbed.evalf 0 expr simplify expr else num_subbed _recurser num sub_dict return num_subbed / denom_subbed val _sub_func expr sub_dict if val is not None return valnew_args _recurser arg sub_dict for arg in expr.args return expr.func *new_args return _recurser expr sub_dict
def _expand_subject_public_key_info encoded spki DerSequence .decode encoded nr_elements 2 algo DerSequence .decode spki[0] nr_elements 1 2 algo_oid DerObjectId .decode algo[0] spk DerBitString .decode spki[1] .valueif len algo 1 algo_params Noneelse try DerNull .decode algo[1] algo_params Noneexcept algo_params algo[1]return algo_oid.value spk algo_params
def ppa name auto_accept True keyserver None assert name.startswith 'ppa ' user repo name[4 ].split '/' 2 release float distrib_release if release > 12.04 repo repo.replace '.' '_' auto_accept '--yes' if auto_accept else '' else auto_accept ''if not isinstance keyserver basestring and keyserver keyserver keyserver[0]if keyserver keyserver '--keyserver' + keyserver else keyserver ''distrib distrib_codename source '/etc/apt/sources.list.d/% user s-% repo s-% distrib s.list' % locals if not is_file source if release > 14.04 package 'software-properties-common' else package 'python-software-properties' run_as_root 'add-apt-repository% auto_accept s% keyserver s% name s' % locals pty False update_index
def _masq_config masq if masq is None masq []lines [MASQ_HEADER]for entry in masq entry.setdefault 'interface' 'eth0' entry.setdefault 'address' '-' entry.setdefault 'proto' '-' entry.setdefault 'port' '-' if isinstance entry['source'] list entry['source'] ' '.join entry['source'] lines.append MASQ_FORMAT % entry file '/etc/shorewall/masq' contents ''.join lines use_sudo True
def parse_search_string string criteria {}for match in CRITERION_RX.finditer string field match.group 'field' or '*' criteria[field] match.group 'pattern' return criteria
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def display_menu stdscr menu_y erase_menu stdscr menu_y stdscr.addstr menu_y 4 'Usethecursorkeystomove andspaceorEntertotoggleacell.' stdscr.addstr menu_y + 1 4 'E rasetheboard R andomfill S teponceorC ontinuously Q uit'
def collect_feature_locations paths strict True locations []for path in paths if os.path.isdir path for dirpath dirnames filenames in os.walk path dirnames.sort for filename in sorted filenames if filename.endswith '.feature' location FileLocation os.path.join dirpath filename locations.append location elif path.startswith '@' locations.extend FeatureListParser.parse_file path[1 ] else location FileLocationParser.parse path if not location.filename.endswith '.feature' raise InvalidFilenameError location.filename elif location.exists locations.append location elif strict raise FileNotFoundError path return locations
def asynchronous function *args **kwargs return AsynchronousRequest function *args **kwargs
def lookupService name timeout None return getResolver .lookupService name timeout
def check_solutions eq s diophantine eq factors Mul.make_args eq var list eq.free_symbols var.sort key default_sort_key while s solution s.pop for f in factors if diop_simplify f.subs zip var solution 0 breakelse return Falsereturn True
def temp_db_filename try h test_db_fname tempfile.mkstemp '_BioSQL.db' dir '/dev/shm' except OSError h test_db_fname tempfile.mkstemp '_BioSQL.db' os.close h return test_db_fname
def _should_profile_production_default return False
def idz_diffsnorm m n matveca matveca2 matvec matvec2 its 20 return _id.idz_diffsnorm m n matveca matveca2 matvec matvec2 its
def set_attrib_file path attribs path os.path.join path ATTRIB_FILE try f open path 'w' except returnfor item in attribs f.write '%s\n' % item f.close
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def placeholder *args **kwargs warnings.simplefilter 'default' DeprecationWarning warnings.warn 'ed.placeholder isdeprecated;usetf.placeholder instead.' DeprecationWarning x tf.placeholder *args **kwargs tf.add_to_collection 'PLACEHOLDERS' x return x
def _escape_argspec obj iterable for key value in iterable if hasattr value '__html__' or isinstance value basestring obj[key] escape value return obj
def add_ignored_fields patterns assert isinstance patterns list tuple ignored_fields.extend patterns
def _recv_tag_raw sock s sock.recv 4 * 4 if len s ! 16 raise RuntimeError 'Notenoughbytesreceived somethingiswrong.Makesurethemne_rt_serverisrunning.' tag Tag *np.fromstring s '>i4' n_received 0rec_buff [s]while n_received < tag.size n_buffer min 4096 tag.size - n_received this_buffer sock.recv n_buffer rec_buff.append this_buffer n_received + len this_buffer if n_received ! tag.size raise RuntimeError 'Notenoughbytesreceived somethingiswrong.Makesurethemne_rt_serverisrunning.' buff ''.join rec_buff return tag buff
def getHost ip try return socket.gethostbyaddr ip [0]except Exception return False
def contains_profiler func_tuple has_profiler Falsefor value in func_tuple if isinstance value six.string_types has_profiler | INVALID_PROFILER_FUNC in value return has_profiler
def locate_cuda if 'CUDAHOME' in os.environ home os.environ['CUDAHOME']nvcc pjoin home 'bin' 'nvcc' else default_path pjoin os.sep 'usr' 'local' 'cuda' 'bin' nvcc find_in_path 'nvcc' os.environ['PATH'] + os.pathsep + default_path if nvcc is None raise EnvironmentError 'Thenvccbinarycouldnotbelocatedinyour$PATH.Eitheraddittoyourpath orset$CUDAHOME' home os.path.dirname os.path.dirname nvcc cudaconfig {'home' home 'nvcc' nvcc 'include' pjoin home 'include' 'lib64' pjoin home 'lib64' }for k v in cudaconfig.iteritems if not os.path.exists v raise EnvironmentError 'TheCUDA%spathcouldnotbelocatedin%s' % k v return cudaconfig
def _init_setting_completions log.completion.debug 'Initializingsettingcompletion.' _instances[usertypes.Completion.section] configmodel.SettingSectionCompletionModel _instances[usertypes.Completion.option] {}_instances[usertypes.Completion.value] {}for sectname in configdata.DATA opt_model configmodel.SettingOptionCompletionModel sectname _instances[usertypes.Completion.option][sectname] opt_model_instances[usertypes.Completion.value][sectname] {}for opt in configdata.DATA[sectname] val_model configmodel.SettingValueCompletionModel sectname opt _instances[usertypes.Completion.value][sectname][opt] val_model
def shb response if py3k h response.getheaders else h [] key value None None for line in response.msg.headers if line if line[0] in ' DCTB ' value + line.strip else if key and value h.append key value key value line.split ' ' 1 key key.strip value value.strip if key and value h.append key value return '%s%s' % response.status response.reason h response.read
def diameter G e None if e is None e eccentricity G return max e.values
def enable_plugin name runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user cmd [_get_rabbitmq_plugin 'enable' name]ret __salt__['cmd.run_all'] cmd runas runas python_shell False return _format_response ret 'Enabled'
def set_hostname name commit_changes True ret {'name' name 'changes' {} 'result' True 'comment' ''}ret['changes'] __salt__['junos.set_hostname'] name commit_changes return ret
def get_rand_pass CRYPTOR.gen_rand_pass 20
def get_jobflow_id emr_connection name ret emr_connection.list_clusters cluster_states LIVE_STATES clusters ret.clusterstry return [cluster.id for cluster in clusters if cluster.name name ][0]except IndexError return
def test_str_cat_where_clause sql_with_null t symbol 't' discover sql_with_null s t[ t.amount < 200 ]c1 s.comment.str_cat s.sex sep '--' bres compute c1 sql_with_null return_type pd.Series df_s compute s sql_with_null return_type pd.DataFrame exp df_s.comment.str.cat df_s.sex '--' assert all exp[ ~ exp.isnull ] bres[ ~ bres.isnull ] assert all exp[exp.isnull ].index bres[bres.isnull ].index
def move_secondary_backup base_path source '{0}{1}'.format base_path BACKUP_ROLLBACK_SUFFIX target base_pathif not rename source target logging.warning 'Nosecondarybackuptorestore.Skipping...'
def object_state instance state _inspect_mapped_object instance if state is None raise exc.UnmappedInstanceError instance else return state
def show_user id_ return show_item 'user' id_
@jsonifydef delete_record self arg_dict cmd ['xenstore-rm' '/local/domain/% dom_id s/% path s' % arg_dict ] ret result _run_command cmd return result
def osd_discover return ceph_cfg.osd_discover
def bench_R2 def hermite n y if n 1 return 2 * y if n 0 return 1return 2 * y * hermite n - 1 y - 2 * n - 1 * hermite n - 2 y .expand a hermite 15 y
def read_ path key None profile None result _query 'GET' path profile profile decode True decode_type 'json' data result['dict'].get 'data' {} if key is None return datavalue data.get key if value is None log.error 'Thekeywasnotfound' return value
def read_element_date stream size if size ! 8 raise SizeError size nanoseconds unpack '>q' _read stream 8 [0]return datetime 2001 1 1 0 0 0 0 None + timedelta microseconds nanoseconds // 1000
def passwd_changes attrs None where None return _osquery_cmd table 'passwd_changes' attrs attrs where where
@testing.requires_testing_data@requires_nibabel def test_plot_bem assert_raises IOError plot_bem subject 'bad-subject' subjects_dir subjects_dir assert_raises ValueError plot_bem subject 'sample' subjects_dir subjects_dir orientation 'bad-ori' plot_bem subject 'sample' subjects_dir subjects_dir orientation 'sagittal' slices [25 50] plot_bem subject 'sample' subjects_dir subjects_dir orientation 'coronal' slices [25 50] brain_surfaces 'white' plot_bem subject 'sample' subjects_dir subjects_dir orientation 'coronal' slices [25 50] src src_fname
def test_astronaut astronaut data.astronaut assert_equal astronaut.shape 512 512 3
def _get_used_lun_ids_for_mappings mappings used_luns set map lambda lun int lun['lun'] mappings used_luns.add 0 return used_luns
def execute_streaming_diginorm ifilename fifo utils.get_temp_filename u'fifo' in_dir os.path.dirname fifo script u'normalize-by-median.py'args [u'-C' u'1' u'-k' u'17' u'-o' u'outfile' fifo]os.mkfifo fifo thread threading.Thread target utils.runscript args script args in_dir thread.start ifile io.open ifilename u'rb' fifofile io.open fifo u'wb' chunk ifile.read 8192 while len chunk > 0 fifofile.write chunk chunk ifile.read 8192 fifofile.close thread.join return in_dir + u'/outfile'
def create_normal_player session name password if _throttle session maxlim 5 timeout 5 * 60 session.msg '{RYoumadetoomanyconnectionattempts.Tryagaininafewminutes.{n' return Noneplayer authenticate username name password password if not player session.msg 'Incorrectlogininformationgiven.' _throttle session player PlayerDB.objects.get_player_from_name name if player player.at_failed_login session return Nonebans ServerConfig.objects.conf 'server_bans' if bans and any tup[0] player.name.lower for tup in bans or any tup[2].match session.address for tup in bans if tup[2] string '{rYouhavebeenbannedandcannotcontinuefromhere.\nIfyoufeelthisbanisinerror pleaseemailanadmin.{x'session.msg string session.sessionhandler.disconnect session 'Goodbye!Disconnecting.' return Nonereturn player
def _task_info_get task_id global DATAtry task_info DATA['task_info'][task_id]except KeyError msg _LW 'Couldnotfindtaskinfo%s' % task_id LOG.warn msg raise exception.TaskNotFound task_id task_id return task_info
def get_http_expiry _Expirestype _num if _Expirestype 'd' expire_date datetime.datetime.now + datetime.timedelta days _num elif _Expirestype 'h' expire_date datetime.datetime.now + datetime.timedelta hours _num else expire_date datetime.datetime.now + datetime.timedelta minutes _num return expire_date.strftime '%a %d%b%Y%H %M %SGMT'
@cli.command @click.argument 'result-file' type click.Path exists True required True def plot result_file results_df pd.read_pickle result_file show_draw_result result_file results_df
def _to_ndimage_mode mode mode_translation_dict dict edge 'nearest' symmetric 'reflect' reflect 'mirror' if mode in mode_translation_dict mode mode_translation_dict[mode]return mode
def _pad input _len len input if _len Card.length return inputelif _len > Card.length strlen _len % Card.length if strlen 0 return inputelse return input + '' * Card.length - strlen else strlen _len % Card.length return input + '' * Card.length - strlen
def CheckEmptyBlockBody filename clean_lines linenum error line clean_lines.elided[linenum]matched Match '\\s* for|while|if \\s*\\ ' line if matched end_line end_linenum end_pos CloseExpression clean_lines linenum line.find ' ' if end_pos > 0 and Match ';' end_line[end_pos ] if matched.group 1 'if' error filename end_linenum 'whitespace/empty_conditional_body' 5 'Emptyconditionalbodiesshoulduse{}' else error filename end_linenum 'whitespace/empty_loop_body' 5 'Emptyloopbodiesshoulduse{}orcontinue'
def get_profile_for_user user if not hasattr user u'_mezzanine_profile' profile_model get_profile_model profile_manager profile_model._default_manager.using user._state.db user_field get_profile_user_fieldname profile_model user.__class__ profile created profile_manager.get_or_create **{user_field user} profile.user useruser._mezzanine_profile profilereturn user._mezzanine_profile
@with_devicedef which name which_cmd '\nIFS \nBINARY %s\nP $PATH \nforpathin"${P[@]}";doif[-e"$path/$BINARY"];thenecho"$path/$BINARY";\nbreak\nfi\ndone\n' % name which_cmd which_cmd.strip return process ['sh' '-c' which_cmd] .recvall .strip
def list_delete t slug raw_input light_magenta 'Yourlistthatyouwanttodelete ' rl True try t.lists.destroy slug '-'.join slug.split owner_screen_name g['original_name'] printNicely green slug + 'listisdeleted.' except debug_option printNicely red 'OopssomethingiswrongwithTwitter '
def web_url_for view_name _absolute False _guid False *args **kwargs url url_for 'OsfWebRenderer__{0}'.format view_name *args **kwargs if _guid url _get_guid_url_for url if _absolute return urlparse.urljoin website_settings.DOMAIN url return url
def test_adapthist_scalar img skimage.img_as_ubyte data.moon adapted exposure.equalize_adapthist img kernel_size 64 clip_limit 0.02 assert adapted.min 0.0 assert adapted.max 1.0 assert img.shape adapted.shape full_scale skimage.exposure.rescale_intensity skimage.img_as_float img assert_almost_equal peak_snr full_scale adapted 102.066 3 assert_almost_equal norm_brightness_err full_scale adapted 0.038 3
def remaining_args oldArgs newArgList pattern '\\s+'.join re.escape a for a in newArgList + '\\s*$' matchObj re.search pattern oldArgs return oldArgs[matchObj.start ]
def is_theme_dir _dir theme_sub_directories {'lms' 'cms'}return bool os.path.isdir _dir and theme_sub_directories.intersection os.listdir _dir
def set_default_locale code global _default_localeglobal _supported_locales_default_locale code_supported_locales frozenset list _translations.keys + [_default_locale]
def to_label name capitalize True label name.replace '_' '' if capitalize label label.capitalize return label
def parse_m2m commands ids []for command in commands if isinstance command tuple list if command[0] in 1 4 ids.append command[1] elif command[0] 5 ids []elif command[0] 6 ids list command[2] else ids.append command return ids
def get_os_info_ua filepath '/etc/os-release' if os.path.isfile filepath os_ua _get_systemd_os_release_var 'PRETTY_NAME' filepath filepath if not os_ua os_ua _get_systemd_os_release_var 'NAME' filepath filepath if os_ua return os_uareturn ''.join get_python_os_info
def getProfileSetting name if name in tempOverride return tempOverride[name]global settingsDictionaryif name in settingsDictionary and settingsDictionary[name].isProfile return settingsDictionary[name].getValue traceback.print_stack sys.stderr.write 'Error "%s"notfoundinprofilesettings\n' % name return ''
def _parseUNIX factory address mode '666' backlog 50 lockfile True return address factory {'mode' int mode 8 'backlog' int backlog 'wantPID' bool int lockfile }
def bundle if len request.args 2 s3db.configure 'budget_bundle' update_next URL f 'bundle_kit_item' args request.args[1] return s3_rest_controller rheader s3db.budget_rheader
def test_continuous_error y np.linspace 0 1 15 nm NearMiss random_state RND_SEED version VERSION_NEARMISS assert_warns UserWarning nm.fit X y
def returnConnected server client cio BytesIO sio BytesIO client.makeConnection FileWrapper cio server.makeConnection FileWrapper sio pump IOPump client server cio sio pump.flush pump.flush return pump
def test_allknn_sample_wrong_X allknn AllKNN random_state RND_SEED allknn.fit X Y assert_raises RuntimeError allknn.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def build_auth_sub_data http_request timestamp nonce return '%s%s%s%s' % http_request.method str http_request.uri str timestamp nonce
def get_base_public_api_url if cfg.CONF.auth.api_url api_url get_url_without_trailing_slash cfg.CONF.auth.api_url else LOG.warn '"auth.api_url"configurationoptionisnotconfigured' api_url 'http //%s %s' % cfg.CONF.api.host cfg.CONF.api.port return api_url
def optional_args decorator @wraps decorator def wrapper *args **kwargs def dec f return decorator f *args **kwargs is_decorating not kwargs and len args 1 and callable args[0] if is_decorating f args[0]args []return dec f else return decreturn wrapper
def vb_get_machine name **kwargs vbox vb_get_box machine vbox.findMachine name return vb_xpcom_to_attribute_dict machine 'IMachine' **kwargs
def get_data_path file_name None if file_name is None file_name ''return os.path.join DATA_DIR file_name
def patch_cache_lfu lock_obj import lfu_cacheimport lfu_cache_with_locklfu_lock1lvl lfu_cache_with_lock.create_cache1lvl lock_obj lfu_lock2lvl lfu_cache_with_lock.create_cache2lvl lock_obj __patch lfu_cache 'cache1lvl' lfu_lock1lvl __patch lfu_cache 'cache2lvl' lfu_lock2lvl
def same_domain url1 url2 if not url1.isValid raise InvalidUrlError url1 if not url2.isValid raise InvalidUrlError url2 suffix1 url1.topLevelDomain suffix2 url2.topLevelDomain if suffix1 '' return url1.host url2.host if suffix1 ! suffix2 return Falsedomain1 url1.host [ - len suffix1 ].split '.' [ -1 ]domain2 url2.host [ - len suffix2 ].split '.' [ -1 ]return domain1 domain2
@blueprint.route '/meters' def list_meters_all rq flask.requestmeters rq.storage_conn.get_meters project acl.get_limited_to_project rq.headers metaquery _get_metaquery rq.args return flask.jsonify meters [m.as_dict for m in meters]
def get_string_property device_type property key cf.CFStringCreateWithCString kCFAllocatorDefault property.encode 'mac_roman' kCFStringEncodingMacRoman CFContainer iokit.IORegistryEntryCreateCFProperty device_type key kCFAllocatorDefault 0 output Noneif CFContainer output cf.CFStringGetCStringPtr CFContainer 0 if output is not None output output.decode 'mac_roman' cf.CFRelease CFContainer return output
def reqs *f return [req for subreq in _reqs *f for req in subreq]
def check_object_name name if regex_object_name.match name is None return Falsereturn True
def doc_checksum docstr import hashlibconverted hashlib.sha1 docstr .hexdigest return converted
def set_price_list_and_rate quotation cart_settings _set_price_list quotation cart_settings quotation.price_list_currency quotation.currency quotation.plc_conversion_rate quotation.conversion_rate Nonefor item in quotation.get u'items' item.price_list_rate item.discount_percentage item.rate item.amount Nonequotation.run_method u'set_price_list_and_item_details' if hasattr frappe.local u'cookie_manager' frappe.local.cookie_manager.set_cookie u'selling_price_list' quotation.selling_price_list
def newdir dirs dirs set dirs newdirs set [i for i in os.listdir dname if not os.path.isfile os.path.join dname i ] newdir newdirs.difference dirs if len newdir ! 1 msg "Therewasmorethanonedirectorycreated.Don'tknowwhattodelete."raise Exception msg newdir newdir.pop return newdir
def families root None displayof None if not root root tkinter._default_rootargs if displayof args '-displayof' displayof return root.tk.splitlist root.tk.call 'font' 'families' *args
@login_required@require_http_methods 'POST' @ensure_csrf_cookiedef certificate_activation_handler request course_key_string course_key CourseKey.from_string course_key_string store modulestore try course _get_course_and_check_access course_key request.user except PermissionDenied msg _ 'PermissionDenied Failedinauthenticating{user}' .format user request.user return JsonResponse {'error' msg} status 403 data json.loads request.body is_active data.get 'is_active' False certificates CertificateManager.get_certificates course for certificate in certificates certificate['is_active'] is_activebreakstore.update_item course request.user.id cert_event_type 'activated' if is_active else 'deactivated' CertificateManager.track_event cert_event_type {'course_id' unicode course.id } return HttpResponse status 200
def determine_timestamp item for key in ['creationTimestamp' 'timeCreated'] if key in item return item[key]raise ValueError 'Couldnotdeterminetimestampkeyfor{0}'.format item.get 'kind' item
def register_draft_only model_class fields follow format if revision_manager.is_registered model_class raise RegistrationError '%rhasalreadybeenregisteredwithReversion.' % model_class if model_class._meta.proxy and not revision_manager.is_registered list model_class._meta.parents.keys [0] raise RegistrationError '%risaproxymodel anditsparenthasnotbeenregisteredwithReversion.' % model_class opts model_class._metalocal_fields opts.local_fields + opts.local_many_to_many if fields is None fields [field.name for field in local_fields]fields tuple fields follow tuple follow try registration_info VersionAdapter fields fields follow follow format format for_concrete_model True ignore_duplicates False except TypeError registration_info VersionAdapter model_class registration_info.fields fieldsregistration_info.follow followregistration_info.format formatif hasattr revision_manager '_registration_key_for_model' model_key revision_manager._registration_key_for_model model_class else model_key model_classrevision_manager._registered_models[model_key] registration_info
def parse_dsymutil data module sys_map {}sys_map[module] {}want_lower ['_IdlePML4']type_map {}type_map[module] {}for line in data.splitlines ents line.split match re.search "\\[.*?\\ [^\\ ]+ \\ \\s+[0-9A-Fa-z]+\\s+\\d+\\s+ [0-9A-Fa-f]+ \\s' \\w+ '" line if match sym_type addr name match.groups sym_type sym_type.strip addr int addr 16 if addr 0 or name '' continueif not name in sys_map[module] sys_map[module][name] [ addr sym_type ]oldaddr sys_map[module][name][0][0]if addr < oldaddr and name in want_lower sys_map[module][name] [ addr sym_type ]if not addr in type_map[module] type_map[module][addr] name [sym_type] type_map[module][addr][1].append sym_type return sys_map['kernel']
@require_role 'admin' def idc_list request header_title path1 path2 u'\u67e5\u770bIDC' u'\u8d44\u4ea7\u7ba1\u7406' u'\u67e5\u770bIDC' posts IDC.objects.all keyword request.GET.get 'keyword' '' if keyword posts IDC.objects.filter Q name__contains keyword | Q comment__contains keyword else posts IDC.objects.exclude name 'ALL' .order_by 'id' contact_list p contacts page_range current_page show_first show_end pages posts request return my_render 'jasset/idc_list.html' locals request
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def concat l res []for k in l res.extend k return res
def weightedUtest g1 w1 g2 w2 from scipy.stats.distributions import normimport numpyn1 sum w1 n2 sum w2 u1 0.0for x1 wx1 in zip g1 w1 for x2 wx2 in zip g2 w2 if x1 x2 u1 + 0.5 * wx1 * wx2 elif x1 > x2 u1 + wx1 * wx2 mu n1 * n2 / 2.0 sigu numpy.sqrt n1 * n2 * n1 + n2 + 1 / 12.0 z u1 - mu / sigu conf norm.cdf z return conf
def render s context None if context is None context {}t get_env .from_string s return t.render context
def add_existing_tag tag_name tag_manager tag Tag.objects.get name__iexact tag_name tag_manager.add tag return tag.name
def memory since 0.0 ans get_memory ans / float 1024 ** 2 return ans - since
def multiEvaluate repeat def decorator func def inner *args **kwargs result 0.0for dummy in range repeat result + func *args **kwargs return result / repeat return innerreturn decorator
def is_bytes obj return isinstance obj bytes_type
def sweepB best worst front stairs fstairs [] [] iter_best iter best next_best next iter_best False for h in worst while next_best and h[ 2] < next_best[ 2] insert Truefor i fstair in enumerate fstairs if front[fstair] front[next_best] if fstair[1] > next_best[1] insert Falseelse del stairs[i] fstairs[i]breakif insert idx bisect.bisect_right stairs - next_best[1] stairs.insert idx - next_best[1] fstairs.insert idx next_best next_best next iter_best False idx bisect.bisect_right stairs - h[1] if 0 < idx < len stairs fstair max fstairs[ idx] key front.__getitem__ front[h] max front[h] front[fstair] + 1
def instance_group_get_by_instance context instance_uuid return IMPL.instance_group_get_by_instance context instance_uuid
def _is_quota_refresh_needed quota_usage max_age refresh Falseif quota_usage.in_use < 0 LOG.debug 'in_usehasdroppedbelow0;forcingrefreshforQuotaUsage %s' dict quota_usage refresh Trueelif quota_usage.until_refresh is not None quota_usage.until_refresh - 1if quota_usage.until_refresh < 0 refresh Trueelif max_age and timeutils.utcnow - quota_usage.updated_at .seconds > max_age refresh Truereturn refresh
def is_possible_short_number_for_region short_number region_dialing_from if isinstance short_number PhoneNumber short_number national_significant_number short_number metadata PhoneMetadata.short_metadata_for_region region_dialing_from if metadata is None return Falsegeneral_desc metadata.general_descreturn _is_number_possible_for_desc short_number general_desc
def _parse_empty_args context builder sig args arrshapetype sig.args[0]arrshape args[0]arrtype sig.return_typereturn arrtype _parse_shape context builder arrshapetype arrshape
def get_num_recurring **filter_data return models.RecurringRun.query_count filter_data
def create_contact contact party_type party contact contact.strip .split u'' contact frappe.get_doc {u'doctype' u'Contact' u'first_name' contact[0] u'last_name' len contact > 1 and contact[1] or u'' } contact.append u'links' dict link_doctype party_type link_name party contact.insert
def load_ipython_extension ipython if not ipython.find_line_magic 'sql' ipython.run_line_magic 'load_ext' 'sql' ipython.register_magic_function pgcli_line_magic 'line' 'pgcli'
def test_color_image_unsupported_error img np.zeros 20 20 3 keypoints np.asarray [[7 5] [11 13]] assert_raises ValueError BRIEF .extract img keypoints
def clear_site_cache sender **kwargs instance kwargs[u'instance']try del SITE_CACHE[instance.pk]except KeyError pass
def cublas_shutdown CUDAMatrix.ones 0_cudamat.cublas_shutdown
def SelfReferenceProperty verbose_name None collection_name None **attrs if 'reference_class' in attrs raise ConfigurationError 'Donotprovidereference_classtoself-reference.' return ReferenceProperty _SELF_REFERENCE verbose_name collection_name **attrs
def serve request path document_root None insecure False **kwargs if not settings.DEBUG and not insecure raise ImproperlyConfigured "Thestaticfilesviewcanonlybeusedindebugmodeorifthethe--insecureoptionof'runserver'isused" normalized_path posixpath.normpath urllib.unquote path .lstrip '/' absolute_path finders.find normalized_path if not absolute_path raise Http404 "'%s'couldnotbefound" % path document_root path os.path.split absolute_path return static.serve request path document_root document_root **kwargs
def _ipv6_host host if host.startswith '[' and host.endswith ']' host host.replace '%25' '%' .strip '[]' return host
def get_list json_object parent_node_name child_node_name None if not json_object return []return_list []if isinstance json_object[parent_node_name] list for detail in json_object[parent_node_name] if child_node_name return_list.append detail[child_node_name] else return_list.append detail elif child_node_name return_list.append json_object[parent_node_name][child_node_name] else return_list.append json_object[parent_node_name] return return_list
def add_args_options arg_parser interface inputs interface.input_spec for name spec in sorted interface.inputs.traits transient None .items desc u'\n'.join interface._get_trait_desc inputs name spec [ len name + 2 ]args {}if spec.is_trait_type traits.Bool args[u'action'] u'store_true'if hasattr spec u'mandatory' and spec.mandatory if spec.is_trait_type InputMultiPath args[u'nargs'] u'+'arg_parser.add_argument name help desc **args else if spec.is_trait_type InputMultiPath args[u'nargs'] u'*'arg_parser.add_argument u'--%s' % name dest name help desc **args return arg_parser
def site_prefix scheme u'https' if settings.HTTPS 'on' else u'http' return u'{} //{}'.format scheme settings.SITE_NAME
def is_forest G if len G 0 raise nx.exception.NetworkXPointlessConcept 'Ghasnonodes.' if G.is_directed components nx.weakly_connected_component_subgraphselse components nx.connected_component_subgraphsreturn all len c - 1 c.number_of_edges for c in components G
def _entity_schema_to_prospective_search_schema schema add_entry all_names []for python_type names in schema.items all_names.extend names for name in names model_type _GetModelTypeForEntityType python_type if not model_type continue_add_schema_entry model_type name add_entry if len all_names ! len set all_names duplicate_names all_namesfor name in set all_names duplicate_names.remove name raise SchemaError 'Duplicatenamesinschema %s' % duplicate_names
def select_rows view row_indices command QItemSelectionModel.ClearAndSelect selmodel view.selectionModel model view.model selection QItemSelection for row in row_indices index model.index row 0 selection.select index index selmodel.select selection command | QItemSelectionModel.Rows
def parse_creole markup return creole_parser.generate markup
def set_offload devname **kwargs for param value in kwargs.items if param 'tcp_segmentation_offload' value value 'on' and 1 or 0 try ethtool.set_tso devname value except IOError return 'Notsupported'return show_offload devname
def _is_convertible_to_index other if isinstance other TimedeltaIndex return Trueelif len other > 0 and other.inferred_type not in 'floating' 'mixed-integer' 'integer' 'mixed-integer-float' 'mixed' return Truereturn False
def p_initializer_1 t pass
@command 'encoders?' def show_encs out '%sEncodingprofiles %s\n\n' % c.ul c.w for x e in enumerate g.encoders sel ' %sselected%s ' % c.y c.w if config.ENCODER.get x else '' out + '%2d.%s%s\n' % x e['name'] sel g.content outmessage 'Enter%ssetencoder<num>%stoselectanencoder'g.message message % c.g c.w
def make_touch_strip_mode_message mode mode_bytes if mode TouchStripModes.CUSTOM_PITCHBEND mode_bytes int '1111001' 2 elif mode TouchStripModes.CUSTOM_VOLUME mode_bytes int '0000001' 2 elif mode TouchStripModes.CUSTOM_PAN mode_bytes int '0010001' 2 elif mode TouchStripModes.CUSTOM_DISCRETE mode_bytes int '0011001' 2 elif mode TouchStripModes.CUSTOM_FREE mode_bytes int '0001011' 2 elif mode TouchStripModes.MODWHEEL mode_bytes int '0000100' 2 elif mode TouchStripModes.PITCHBEND mode_bytes int '1111000' 2 else raise RuntimeError 'Touchstripmode%inotsupported' % mode return make_message 23 mode_bytes
def send_notification_center title msg gtype if sabnzbd.DARWIN_VERSION < 8 return T 'Notavailable' tool ncenter_path if tool try command [tool '-title' title '-message' msg '-group' Tx NOTIFICATION.get gtype 'other' ]proc subprocess.Popen command stdout subprocess.PIPE stderr subprocess.PIPE shell False output proc.stdout.read proc.wait if 'Notificationdelivered' in output or 'Removingpreviously' in output output ''except logging.info 'Cannotrunnotifier"%s"' tool logging.debug 'Traceback ' exc_info True output 'Notifiertoolcrashed'else output 'Notifierappnotfound'return output.strip '*\n'
def _bem_specify_coils bem coils coord_frame mults n_jobs coils coord_frame _check_coil_frame coils coord_frame bem rmags cosmags ws bins _concatenate_coils coils lens np.cumsum np.r_[ 0 [len s['rr'] for s in bem['surfs']] ] sol np.zeros bins[ -1 ] + 1 bem['solution'].shape[1] lims np.concatenate [np.arange 0 sol.shape[0] 100 [sol.shape[0]]] for o1 o2 surf mult in zip lens[ -1 ] lens[1 ] bem['surfs'] bem['field_mult'] coeff _lin_field_coeff surf mult rmags cosmags ws bins n_jobs for start stop in zip lims[ -1 ] lims[1 ] sol[start stop] + np.dot coeff[start stop] bem['solution'][o1 o2] sol * multsreturn sol
def choose_string g1 g2 v1 c1 g1 v2 c2 g2if not v1 return g2elif not v2 return g1 v1 v2 v1.strip v2.strip v1l v2l v1.lower v2.lower combined_prob 1 - 1 - c1 * 1 - c2 if v1l v2l return v1 combined_prob elif v1l u'the' + v2l return v1 combined_prob elif v2l u'the' + v1l return v2 combined_prob elif v2l in v1l return v2 combined_prob elif v1l in v2l return v1 combined_prob elif c1 > c2 return v1 c1 - c2 else return v2 c2 - c1
def _gc_rule_from_pb gc_rule_pb rule_name gc_rule_pb.WhichOneof 'rule' if rule_name is None return Noneif rule_name 'max_num_versions' return MaxVersionsGCRule gc_rule_pb.max_num_versions elif rule_name 'max_age' max_age _helpers._duration_pb_to_timedelta gc_rule_pb.max_age return MaxAgeGCRule max_age elif rule_name 'union' return GCRuleUnion [_gc_rule_from_pb rule for rule in gc_rule_pb.union.rules] elif rule_name 'intersection' rules [_gc_rule_from_pb rule for rule in gc_rule_pb.intersection.rules]return GCRuleIntersection rules else raise ValueError 'Unexpectedrulename' rule_name
def _should_retry resp return resp.status_code httplib.REQUEST_TIMEOUT or resp.status_code > 500 and resp.status_code < 600
def unsignedID obj rval _idFunction obj if rval < 0 rval + _HUGEINTreturn rval
def create_engine *args **kwargs strategy kwargs.pop 'strategy' default_strategy strategy strategies.strategies[strategy]return strategy.create *args **kwargs
@float32_floatXdef test_stochasatic_pool_samples ds 3stride 3rng numpy.random.RandomState 220 data rng.uniform 0 10 size 1 ds ds 1 .astype 'float32' x theano.tensor.tensor4 s_max stochastic_max_pool_c01b x ds ds stride stride f theano.function [x] s_max mode mode_with_gpu samples []for i in xrange 300 samples.append numpy.asarray f data [ 0 0 0 0 ] counts Counter samples data data.reshape ds * ds data.sort data data[ -1 ]for i in range len data - 1 assert counts[data[i]] > counts[data[ i + 1 ]]
@not_implemented_for 'undirected' def transitive_reduction G if not is_directed_acyclic_graph G raise nx.NetworkXError 'Transitivereductiononlyuniquelydefinedondirectedacyclicgraphs.' TR nx.DiGraph TR.add_nodes_from G.nodes for u in G u_edges set G[u] for v in G[u] u_edges - {y for x y in nx.dfs_edges G v }TR.add_edges_from u v for v in u_edges return TR
def cython_enums lines []for name in all_names if no_prefix name lines.append 'enum ZMQ_{0}"{0}"'.format name else lines.append 'enum ZMQ_{0}'.format name return dict ZMQ_ENUMS '\n'.join lines
def _win_path_to_bytes path for encoding in 'ASCII' 'MBCS' try return path.encode encoding except UnicodeEncodeError LookupError passreturn path
def _filterargs source argsregex "}\\ ' .* ' * \\d+ * \\d+ *' .* '\\.split\\ '\\|'\\ * \\d+ * .* \\ \\ "args re.search argsregex source re.DOTALL .groups try return args[0] args[3].split '|' int args[1] int args[2] except ValueError raise UnpackingError 'Corruptedp.a.c.k.e.r.data.'
def R p q if p in consonants or q in consonants return R_creturn R_v
def s_num_mutations return blocks.CURRENT.num_mutations
def task_enable_docker_head_repository distribution if is_centos_or_rhel distribution return sequence [put content dedent '[virt7-testing]\nname virt7-testing\nbaseurl http //cbs.centos.org/repos/virt7-testing/x86_64/os/\nenabled 1\ngpgcheck 0\n' path '/etc/yum.repos.d/virt7-testing.repo' ] else raise DistributionNotSupported distribution distribution
@snippetdef topic_subscription client to_delete TOPIC_NAME 'topic_subscription-%d' % _millis SUB_DEFAULTS 'topic_subscription-defaults-%d' % _millis SUB_ACK90 'topic_subscription-ack90-%d' % _millis topic client.topic TOPIC_NAME topic.create to_delete.append topic sub_defaults topic.subscription SUB_DEFAULTS sub_defaults.create to_delete.append sub_defaults expected_names set expected_names.add sub_defaults.full_name sub_ack90 topic.subscription SUB_ACK90 ack_deadline 90 sub_ack90.create to_delete.append sub_ack90 expected_names.add sub_ack90.full_name sub_names set def do_something_with sub sub_names.add sub.full_name for subscription in topic.list_subscriptions do_something_with subscription assert sub_names.issuperset expected_names
def smtp_login email passwd connectfun global _email_from _smtp _smtp_connectdef connect smtp connectfun smtp.login email passwd return smtp_email_from email_smtp_connect connect_smtp _smtp_connect
def _fetch_raw_metadata api_key cache retries environ for page_number in count 1 key 'metadata-page-%d' % page_number try raw cache[key]except KeyError for _ in range retries try raw pd.read_csv format_metadata_url api_key page_number parse_dates ['oldest_available_date' 'newest_available_date'] usecols ['dataset_code' 'name' 'oldest_available_date' 'newest_available_date'] breakexcept ValueError raw pd.DataFrame [] breakexcept Exception passelse raise ValueError 'Failedtodownloadmetadatapage%dafter%dattempts.' % page_number retries cache[key] rawif raw.empty break yield raw
def set_user_password name password **client_args if not user_exists name **client_args log.info "User'{0}'doesnotexist".format name return Falseclient _client **client_args client.set_user_password name password return True
def highlight_faces image faces output_filename im Image.open image draw ImageDraw.Draw im for face in faces box [ v.get 'x' 0.0 v.get 'y' 0.0 for v in face['fdBoundingPoly']['vertices']]draw.line box + [box[0]] width 5 fill '#00ff00' im.save output_filename
def CreateAFF4Object stat_response client_id token sync False stat_response.aff4path aff4_grr.VFSGRRClient.PathspecToURN stat_response.pathspec client_id if stat_response.pathspec.last.stream_name stat_response.st_mode & ~ stat_type_mask stat_response.st_mode | stat.S_IFREGif stat.S_ISDIR stat_response.st_mode ftype standard.VFSDirectoryelse ftype aff4_grr.VFSFilefd aff4.FACTORY.Create stat_response.aff4path ftype mode 'w' token token fd.Set fd.Schema.STAT stat_response fd.Set fd.Schema.PATHSPEC stat_response.pathspec fd.Close sync sync
def tablesample selectable sampling name None seed None return _interpret_as_from selectable .tablesample sampling name name seed seed
def save_design request form type_ design explicit_save authorized_get_design request design.id assert form.saveform.is_valid sub_design_form formif type_ models.HQL design_cls beeswax.design.HQLdesignelif type_ models.IMPALA design_cls beeswax.design.HQLdesignelif type_ models.SPARK from spark.design import SparkDesigndesign_cls SparkDesignsub_design_form form.queryelse raise ValueError _ 'Invaliddesigntype% type s' % {'type' type_} design_obj design_cls sub_design_form query_type type_ name form.saveform.cleaned_data['name']desc form.saveform.cleaned_data['desc']return _save_design request.user design type_ design_obj explicit_save name desc
def dyld_find name executable_path None env None name ensure_utf8 name executable_path ensure_utf8 executable_path for path in dyld_image_suffix_search chain dyld_override_search name env dyld_executable_path_search name executable_path dyld_default_search name env env if os.path.isfile path return pathraise ValueError 'dylib%scouldnotbefound' % name
def _astnode s try import compilerexcept ImportError return eval s p compiler.parse '__tempvalue__ ' + s return p.getChildren [1].getChildren [0].getChildren [1]
def generate_commit_table start_ref end_ref header u'||Author||Summary||Commit||JIRA||ReleaseNotes?||Verified?||'commit_link u'[commit|https //github.com/edx/edx-platform/commit/{sha}]'rows [header]commits get_commits_not_in_prs start_ref end_ref for commit in commits rows.append u'|{author}|{summary}|{commit}|{jira}|{release_notes}|{verified}|'.format author commit.author.email summary commit.summary.replace u'|' u'\\|' commit commit_link.format sha commit.hexsha jira u' '.join parse_ticket_references commit.message release_notes u'' verified u'' return u'\n'.join rows
def host_status hostname None **kwargs if not hostname raise CommandExecutionError 'Missinghostnameparameter' target 'host'numeric kwargs.get 'numeric' data _status_query target hostname enumerate numeric ret {'result' data['result']}if ret['result'] ret['status'] data.get 'json_data' {} .get 'data' {} .get target {} .get 'status' not numeric and 'Unknown' or 2 else ret['error'] data['error']return ret
def squared_error_gradient x_i y_i beta return [ -2 * x_ij * error x_i y_i beta for x_ij in x_i]
def detach_disk name None kwargs None call None if call ! 'action' raise SaltCloudSystemExit 'Thedetach_Diskactionmustbecalledwith-aor--action.' if not name log.error 'Mustspecifyaninstancename.' return Falseif not kwargs or 'disk_name' not in kwargs log.error 'Mustspecifyadisk_nametodetach.' return Falsenode_name namedisk_name kwargs['disk_name']conn get_conn node conn.ex_get_node node_name disk conn.ex_get_volume disk_name __utils__['cloud.fire_event'] 'event' 'detachdisk' 'salt/cloud/disk/detaching' args {'name' node_name 'disk_name' disk_name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] result conn.detach_volume disk node __utils__['cloud.fire_event'] 'event' 'detacheddisk' 'salt/cloud/disk/detached' args {'name' node_name 'disk_name' disk_name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def libvlc_media_player_next_frame p_mi f _Cfunctions.get 'libvlc_media_player_next_frame' None or _Cfunction 'libvlc_media_player_next_frame' 1 None None MediaPlayer return f p_mi
def _add_user user state if not user.is_staff and CourseCreator.objects.filter user user .count 0 entry CourseCreator user user state state entry.save return Truereturn False
def string value value value.replace u'\n' u'\\a' .replace u'\r' u'\\d' .replace u'\x0c' u'\\c' .replace u'"' u'\\"' if value.endswith u'\\' value value[ -1 ] + u'\\\\' return u'"%s"' % value
def extract_args expected *args **kwargs routed_args dict zip expected args for name in kwargs if name not in expected raise KeyError 'invalidinputname {}'.format name elif name in routed_args raise TypeError "gotmultiplevaluesforargument'{}'".format name else routed_args[name] kwargs[name]if set expected ! set routed_args raise ValueError 'missingvaluesforinputs {}'.format [name for name in expected if name not in routed_args ] return OrderedDict key routed_args[key] for key in expected
def mean_absolute_percentage_error y_true y_pred diff tf.abs y_true - y_pred / tf.clip_by_value tf.abs y_true 1e-08 np.inf return 100.0 * tf.reduce_mean diff
@locked_functiondef store_in_cache cache_location url response hpath bpath calculate_cache_path cache_location url try outf open hpath 'wb' headers str response.info outf.write headers outf.close outf open bpath 'wb' outf.write response.read outf.close except IOError return Trueelse return False
def group_member_delete context data_dict None _check_access 'group_member_delete' context data_dict return _group_or_org_member_delete context data_dict
@_api_version 1.21 @_client_version '1.5.0' def remove_volume name response _client_wrapper 'remove_volume' name _clear_context return response
def crowding_distance individuals fitnesses distances collections.defaultdict lambda 0 individuals list individuals n_obj len fitnesses[individuals[0]] for i in range n_obj individuals.sort key lambda x fitnesses[x][i] normalization float fitnesses[individuals[0]][i] - fitnesses[individuals[ -1 ]][i] distances[individuals[0]] 1e+100distances[individuals[ -1 ]] 1e+100tripled list zip individuals individuals[1 -1 ] individuals[2 ] for pre ind post in tripled distances[ind] + fitnesses[pre][i] - fitnesses[post][i] / normalization return distances
def format_image_notification image return {'id' image.image_id 'name' image.name 'status' image.status 'created_at' timeutils.isotime image.created_at 'updated_at' timeutils.isotime image.updated_at 'min_disk' image.min_disk 'min_ram' image.min_ram 'protected' image.protected 'checksum' image.checksum 'owner' image.owner 'disk_format' image.disk_format 'container_format' image.container_format 'size' image.size 'is_public' image.visibility 'public' 'properties' dict image.extra_properties 'tags' list image.tags 'deleted' False 'deleted_at' None}
def _get_xml_rpc vm_ get_configured_provider xml_rpc config.get_cloud_config_value 'xml_rpc' vm_ __opts__ search_global False user config.get_cloud_config_value 'user' vm_ __opts__ search_global False password config.get_cloud_config_value 'password' vm_ __opts__ search_global False server salt.ext.six.moves.xmlrpc_client.ServerProxy xml_rpc return server user password
def _randdm pnts if pnts > 2 D np.random.rand pnts * pnts - 1 / 2 else raise ValueError 'Thenumberofpointsinthedistancematrixmustbeatleast2.' return D
def test_clone_should_rstrip_trailing_slash_in_repo_url mocker clone_dir mocker.patch 'cookiecutter.vcs.is_vcs_installed' autospec True return_value True mock_subprocess mocker.patch 'cookiecutter.vcs.subprocess.check_output' autospec True vcs.clone 'https //github.com/foo/bar/' clone_to_dir clone_dir no_input True mock_subprocess.assert_called_once_with ['git' 'clone' 'https //github.com/foo/bar'] cwd clone_dir stderr subprocess.STDOUT
def encode_params_utf8 params encoded []for k v in params encoded.append k.encode u'utf-8' if isinstance k unicode_type else k v.encode u'utf-8' if isinstance v unicode_type else v return encoded
def _email_check_and_list emails field if isinstance emails types.StringTypes check_email_valid value else for address in iter emails check_email_valid address field
def _chop_end_misc line return re.sub '\\s\\s\\s\\s+.*\\Z' '' line
def indent element level 0 indent ' DCTB ' def empty text return not text or not text.strip def indent_ element level last child_count len element if child_count if empty element.text element.text '\n' + indent * level + 1 if empty element.tail element.tail '\n' + indent * level + -1 if last else 0 for i child in enumerate element indent_ child level + 1 i child_count - 1 elif empty element.tail element.tail '\n' + indent * level + -1 if last else 0 return indent_ element level True
def getLoopsBySegmentsDictionary segmentsDictionary width points []for endpoint in getVerticalEndpoints segmentsDictionary width 0.1 * width width points.append endpoint.point for endpoint in euclidean.getEndpointsFromSegmentTable segmentsDictionary points.append endpoint.point return triangle_mesh.getDescendingAreaOrientedLoops points points width + width
def index_to_one index return dindex_to_1[index]
def pci_devices attrs None where None return _osquery_cmd table 'pci_devices' attrs attrs where where
def cli_plugin_requests config req_inst req_auth config.configuratorreq_inst set_configurator req_inst config.installer req_auth set_configurator req_auth config.authenticator if config.nginx req_inst set_configurator req_inst 'nginx' req_auth set_configurator req_auth 'nginx' if config.apache req_inst set_configurator req_inst 'apache' req_auth set_configurator req_auth 'apache' if config.standalone req_auth set_configurator req_auth 'standalone' if config.webroot req_auth set_configurator req_auth 'webroot' if config.manual req_auth set_configurator req_auth 'manual' logger.debug 'Requestedauthenticator%sandinstaller%s' req_auth req_inst return req_auth req_inst
def dispose event for _ value in DEVICES.items value.netio.stop
def is_style_file filename return STYLE_FILE_PATTERN.match filename is not None
def remove_tagids source return _modify_tagids source False
def sph2cart *args if len args 1 elev args[0][0 ]azim args[0][1 ]radius args[0][2 ]returnAsArray Trueelif len args 3 elev args[0]azim args[1]radius args[2]returnAsArray Falsez radius * numpy.sin radians elev x radius * numpy.cos radians elev * numpy.cos radians azim y radius * numpy.cos radians elev * numpy.sin radians azim if returnAsArray return numpy.asarray [x y z] else return x y z
def get_index_of_first_statement src_text preprocessor_directive u'\\s*#.*?$'pattern_text preprocessor_directivepattern_text + u'|' + multi_line_comment pattern_text + u'|' + single_line_comment pattern_text + u'|' + whitespace pattern re.compile pattern_text re.M | re.S match_iter pattern.finditer src_text index 0for match in match_iter if match.start ! index breakindex match.end return index
def mod_bufsize iface *args **kwargs if __grains__['kernel'] 'Linux' if os.path.exists '/sbin/ethtool' return _mod_bufsize_linux iface *args **kwargs return False
def optional type_ return type_ type None
def capacity_assessment S3SQLInlineComponent s3base.S3SQLInlineComponentcrud_fields ['organisation_id' 'date' 'person_id']cappend crud_fields.appendtable s3db.org_capacity_indicatorrows db table.deleted ! True .select table.id table.section table.header table.number table.name orderby table.number section Nonefor row in rows name 'number%s' % row.number if row.section ! section label section row.sectionelse label ''cappend S3SQLInlineComponent 'data' name name label label fields row.header 'indicator_id' 'rating' 'ranking' filterby dict field 'indicator_id' options row.id multiple False crud_form s3base.S3SQLCustomForm *crud_fields s3db.configure 'org_capacity_assessment' crud_form crud_form return s3_rest_controller
def extract_link_from_set_cookie_header http_response header_name header_value try cookie parse_cookie header_value except raise StopIterationfor key in cookie.keys try path cookie[key]['path']except KeyError continueif path try yield http_response.get_url .url_join path except ValueError msg 'Theapplicationsenta"%s"headerthatw3affailedtocorrectlyparseasanURL theheadervaluewas "%s"'om.out.debug msg % header_name header_value
def mtime path return os.stat path .st_mtime
def eGetRawS Handle pIOType Channel pValue x1 pass
def _get_instance hass try return _INSTANCES[hass]except KeyError _INSTANCES[hass] Configurator hass if DOMAIN not in hass.config.components hass.config.components.append DOMAIN return _INSTANCES[hass]
@bdd.then bdd.parsers.parse 'thepageshouldnotcontaintheplaintext"{text}"' def check_not_contents_plain quteproc text content quteproc.get_content .strip assert text not in content
def html_translate callback value if not value return valuetry parser etree.HTMLParser encoding 'utf-8' trans XMLTranslator callback 'html' parser wrapped '<div>%s</div>' % encode value root etree.fromstring wrapped parser trans.process root[0][0] value trans.get_done [5 -6 ]except ValueError _logger.exception 'CannottranslatemalformedHTML usingsourcevalueinstead' return value
def is_valid_url url if not DISALLOWED_IPS return Trueparsed urlparse url if not parsed.hostname return Falseserver_hostname get_server_hostname if parsed.hostname server_hostname return Truetry ip_addresses set addr for _ _ _ _ addr in socket.getaddrinfo parsed.hostname 0 except socket.gaierror return Falsefor addr in ip_addresses ip_address addr[0]if ip_address server_hostname return Trueip_address ipaddress.ip_address six.text_type ip_address for ip_network in DISALLOWED_IPS if ip_address in ip_network return Falsereturn True
def targets tgt tgt_type 'glob' **kwargs roster_order __opts__.get 'roster_order' 'public' 'private' 'local' cached_data __runner__['cache.grains'] tgt tgt tgt_type tgt_type ret {}for server grains in cached_data.items ret[server] __opts__.get 'roster_defaults' {} .copy ret[server].update {'host' extract_ipv4 roster_order grains.get 'ipv4' [] } return ret
@_api_version 1.21 @_client_version '1.5.0' def volumes filters None response _client_wrapper 'volumes' filters filters _clear_context return response
def _import_module_from_path module_name plugin_path module Noneif PY2 info imp.find_module module_name [plugin_path] if info module imp.load_module module_name *info elif sys.version_info[0 2] < 3 3 loader importlib.machinery.PathFinder.find_module module_name [plugin_path] if loader module loader.load_module module_name else spec importlib.machinery.PathFinder.find_spec module_name [plugin_path] if spec module spec.loader.load_module module_name return module
@cli.resultcallback def process_commands processors stream for processor in processors stream processor stream for _ in stream pass
def edge_expansion G S T None weight None if T is None T set G - set S num_cut_edges cut_size G S T T weight weight return num_cut_edges / min len S len T
def stereo_motorcycle return load 'motorcycle_left.png' load 'motorcycle_right.png' np.load _os.path.join data_dir 'motorcycle_disp.npz' ['arr_0']
def extract_tarball tarball extracted cat_file_to_cmd tarball 'tarxvf-2>/dev/null' return_output True .splitlines dir Nonefor line in extracted line re.sub '^./' '' line if not line or line '.' continuetopdir line.split '/' [0]if os.path.isdir topdir if dir assert dir topdir else dir topdirif dir return direlse raise NameError 'extractingtarballproducednodir'
def dates_from_str dates return lmap date_parser dates
def log2 x ln2 math.log 2.0 try bin_n binary_repr x [1 ]except AssertionError TypeError return math.log x / ln2 else if u'1' in bin_n return math.log x / ln2 else return len bin_n
def fixed_ip_get_by_address context address columns_to_join None return IMPL.fixed_ip_get_by_address context address columns_to_join columns_to_join
def validate_configuration configuration schema {'$schema' 'http //json-schema.org/draft-04/schema#' 'type' 'object' 'required' ['version' 'control-service' 'dataset'] 'properties' {'version' {'type' 'number' 'maximum' 1 'minimum' 1} 'control-service' {'type' 'object' 'required' ['hostname'] 'properties' {'hostname' {'type' 'string' 'format' 'hostname'} 'port' {'type' 'integer'}}} 'dataset' {'type' 'object' 'properties' {'backend' {'type' 'string'}} 'required' ['backend']} 'logging' {'type' 'object'}}}v Draft4Validator schema format_checker FormatChecker v.validate configuration
def like return _distro.like
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def reset noGamma True OK init if noGamma and OK setVideoMode NOGAMMACORRECT
def scale_face face scaled face - face.min scaled / scaled.max return scaled
def test_rmtree_retries tmpdir monkeypatch monkeypatch.setattr shutil 'rmtree' Failer duration 1 .call rmtree 'foo'
def snapshot_create request conf request.bodyif isinstance conf basestring config json.loads conf snapshot MapSnapshot.objects.create config clean_config conf map Map.objects.get id config['id'] return HttpResponse num_encode snapshot.id content_type 'text/plain' else return HttpResponse 'InvalidJSON' content_type 'text/plain' status 500
def get_position_size fd 1 info get_console_screen_buffer_info fd return info.dwCursorPosition.X info.dwCursorPosition.Y info.dwSize.X info.dwSize.Y
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def intersect_chunks old_chunks new_chunks cmo cumdims_label old_chunks 'o' cmn cumdims_label new_chunks 'n' sums [sum o for o in old_chunks]sums2 [sum n for n in old_chunks]if not sums sums2 raise ValueError 'Cannotchangedimensionsfromto%r' % sums2 old_to_new [_intersect_1d _breakpoints cm[0] cm[1] for cm in zip cmo cmn ]cross1 product *old_to_new cross chain tuple product *cr for cr in cross1 return cross
@synchronized NZB_LOCK def save_compressed folder filename data here os.getcwd os.chdir misc.short_path folder if filename.endswith '.nzb' filename + '.gz'else filename + '.nzb.gz'logging.info 'Backingup%s' os.path.join folder filename try f gzip.GzipFile filename 'wb' f.write data f.flush f.close except logging.error T 'Saving%sfailed' os.path.join folder filename logging.info 'Traceback ' exc_info True os.chdir here
def get_proxy *args **kwargs return proxy.ServiceProxy *args **kwargs
def get_extra_values conf _prepend out []out.extend [ _prepend name for name in conf.extra_values] for name in conf.sections if name not in conf.extra_values out.extend get_extra_values conf[name] _prepend + name return out
def test_live_monitoring verify_zmq p mp.Process target train_mlp p.start correct_result set ['train_objective' 'train_y_col_norms_max' 'train_y_row_norms_min' 'train_y_nll' 'train_y_col_norms_mean' 'train_y_max_max_class' 'train_y_min_max_class' 'train_y_row_norms_max' 'train_y_misclass' 'train_y_col_norms_min' 'train_y_row_norms_mean' 'train_y_mean_max_class' 'learning_rate' 'training_seconds_this_epoch' 'total_seconds_last_epoch'] monitor lm.LiveMonitor result set monitor.list_channels .data if result ! correct_result raise ValueError str result assert result correct_result monitor lm.LiveMonitor monitor.update_channels ['train_objective'] start 0 end 2 assert len monitor.channels['train_objective'].val_record 2 monitor lm.LiveMonitor monitor.update_channels ['train_objective'] start 1 end 2 assert len monitor.channels['train_objective'].val_record 1 p.join assert_raises AssertionError monitor.update_channels 0 assert_raises AssertionError monitor.update_channels [] assert_raises AssertionError monitor.update_channels ['train_objective'] start 2 end 1
def number_metadata registry xml_parent data pdef base_metadata registry xml_parent data 'metadata-number' value data.get 'value' '' XML.SubElement pdef 'value' .text value
def header_encode header charset 'iso-8859-1' keep_eols False maxlinelen 76 eol NL if not header return headerif not keep_eols header fix_eols header quoted []if maxlinelen is None max_encoded 100000else max_encoded maxlinelen - len charset - MISC_LEN - 1 for c in header if c '' _max_append quoted '_' max_encoded elif not hqre.match c _max_append quoted c max_encoded else _max_append quoted ' %02X' % ord c max_encoded joiner eol + '' return joiner.join [ ' ?%s?q?%s? ' % charset line for line in quoted]
def _get_value_from_value_pb value_pb value_type value_pb.WhichOneof 'value_type' if value_type 'timestamp_value' result _pb_timestamp_to_datetime value_pb.timestamp_value elif value_type 'key_value' result key_from_protobuf value_pb.key_value elif value_type 'boolean_value' result value_pb.boolean_valueelif value_type 'double_value' result value_pb.double_valueelif value_type 'integer_value' result value_pb.integer_valueelif value_type 'string_value' result value_pb.string_valueelif value_type 'blob_value' result value_pb.blob_valueelif value_type 'entity_value' result entity_from_protobuf value_pb.entity_value elif value_type 'array_value' result [_get_value_from_value_pb value for value in value_pb.array_value.values]elif value_type 'geo_point_value' result GeoPoint value_pb.geo_point_value.latitude value_pb.geo_point_value.longitude elif value_type 'null_value' result Noneelse raise ValueError 'Valueprotobufdidnothaveanyvalueset' return result
def get_maxrate ratelimits size last_func Noneif size size int size for ratesize rate func in ratelimits if size < ratesize breaklast_func funcif last_func return last_func size return None
def _get_int data position dummy0 dummy1 dummy2 end position + 4 return _UNPACK_INT data[position end] [0] end
def get_render_ctx return getattr g '_admin_render_ctx' None
def _split_vars_files data v_vars []v_files []for token in data.iter_tokens pname token.get_name value token.get_value enc_pname smart_str pname encoding DEFAULT_ENCODING if is_file_like value if not value.closed v_files.append enc_pname value else v_vars.append enc_pname '' elif hasattr value 'isFile' v_files.append enc_pname value else value smart_str value encoding DEFAULT_ENCODING v_vars.append enc_pname value return v_vars v_files
def fetch_tracks user page limit network pylast.LastFMNetwork api_key config['lastfm']['api_key'] user_obj CustomUser user network results total_pages user_obj.get_top_tracks_by_page limit limit page page return [{'mbid' track.item.mbid if track.item.mbid else '' 'artist' {'name' track.item.artist.name} 'name' track.item.title 'playcount' track.weight} for track in results] total_pages
def test_translation class TranslationTable tables.Table text tables.Column verbose_name ugettext_lazy u'Text' table TranslationTable [] assert u'Text' table.columns[u'text'].header
def call_kw model name args kwargs method getattr type model name if getattr method '_api' None 'model' return call_kw_model method model args kwargs else return call_kw_multi method model args kwargs
def getDescriptiveExtension gcodeText lines archive.getTextLines gcodeText return '.' + getDescriptionCarve lines + getDescriptionFill lines + getDescriptionMultiply lines + getDescriptionSpeed lines
def test_rgb_to_hsl_part_8 assert rgb_to_hsl 153 153 102 60 20 50 assert rgb_to_hsl 204 204 51 60 60 50 assert rgb_to_hsl 255 255 0 60 100 50
def xpath elem path return elem.xpath path namespaces NS
def consistencygroup_get_all_by_project context project_id filters None marker None limit None offset None sort_keys None sort_dirs None return IMPL.consistencygroup_get_all_by_project context project_id filters filters marker marker limit limit offset offset sort_keys sort_keys sort_dirs sort_dirs
def test_clrtype_returns_existing_python_types global calledclass PySubType1 type passclass PySubType2 PySubType1 passclass PySubType3 PySubType2 PySubType1 passfor x in [bool buffer type range type ''.index type BaseException dict type Ellipsis file float type sys._getframe 0 xrange int long unicode tuple type lambda 3 type None type object.__str__ PySubType1 PySubType2 PySubType3] called Falseclass MyType type def __clrtype__ self global calledcalled Truereturn xclass X object __metaclass__ MyTypeAreEqual called True
def _append_params oauth_params params merged list params merged.extend oauth_params merged.sort key lambda i i[0].startswith 'oauth_' return merged
def volume_get_iscsi_target_num context volume_id return IMPL.volume_get_iscsi_target_num context volume_id
def check_color option opt value if re.match '[a-z0-9]+$' value re.I return valueif re.match '#[a-f0-9]{6}' value re.I return valuemsg 'option%s invalidcolor %r shouldbeeitherhexadecimalvalueorpredefinedcolor'raise OptionValueError msg % opt value
def install_requirements virtualenv_path requirements_file_path pip_path os.path.join virtualenv_path 'bin/pip' cmd [pip_path 'install' '-U' '-r' requirements_file_path]env get_env_for_subprocess_command exit_code stdout stderr run_command cmd cmd env env if exit_code ! 0 raise Exception 'Failedtoinstallrequirementsfrom"%s" %s stderr %s ' % requirements_file_path stdout stderr return True
def _get_epochs_delayed_ssp raw read_raw_fif raw_fname events read_events event_name picks _get_picks raw reject dict mag 4e-12 epochs_delayed_ssp Epochs raw events[ 10] event_id tmin tmax picks picks proj 'delayed' reject reject return epochs_delayed_ssp
def name_extractor subject result subjectfor name in re.findall SUBJECT_FN_MATCHER subject name name.strip '"' if name and RE_NORMAL_NAME.search name result namereturn platform_encode result
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def do_patch_activate_script venv_path script_path os.path.join venv_path 'bin' 'activate' file_obj open script_path lines file_obj.readlines for i line in enumerate lines if line.startswith 'VIRTUAL_ENV ' lines[i] 'VIRTUAL_ENV "%s"\n' % venv_path file_obj.close file_obj open script_path 'w' file_obj.write ''.join lines file_obj.close
def os_script os_ vm_ None opts None minion '' if minion minion salt_config_to_yaml minion if os.path.isabs os_ return __render_script os_ vm_ opts minion if os.path.isabs '{0}.sh'.format os_ return __render_script '{0}.sh'.format os_ vm_ opts minion for search_path in opts['deploy_scripts_search_path'] if os.path.isfile os.path.join search_path os_ return __render_script os.path.join search_path os_ vm_ opts minion if os.path.isfile os.path.join search_path '{0}.sh'.format os_ return __render_script os.path.join search_path '{0}.sh'.format os_ vm_ opts minion return ''
def getSplitLineBeforeBracketSemicolon line bracketSemicolonIndex min line.find ';' line.find ' ' if bracketSemicolonIndex < 0 return line.split return line[ bracketSemicolonIndex].split
def generate_keys local "ssh-keygen-N''-q-trsa-f~/.ssh/sahana_release"
def addTrailingSpace articles _spArticles []_spUnicodeArticles []for article in articles if article[ -1 ] not in "'" '-' article + ''_spArticles.append article _spUnicodeArticles.append article.decode 'utf_8' return _spArticles _spUnicodeArticles
def _is_descriptor_mobile_available descriptor if IgnoreMobileAvailableFlagConfig.is_enabled or descriptor.mobile_available return ACCESS_GRANTEDelse return MobileAvailabilityError
def optimizer_from_config config custom_objects None all_classes {'sgd' SGD 'rmsprop' RMSprop 'adagrad' Adagrad 'adadelta' Adadelta 'adam' Adam 'adamax' Adamax 'nadam' Nadam 'tfoptimizer' TFOptimizer}class_name config['class_name']if custom_objects and class_name in custom_objects cls custom_objects[class_name]elif class_name in get_custom_objects cls get_custom_objects [class_name]else if class_name.lower not in all_classes raise ValueError 'Optimizerclassnotfound ' class_name cls all_classes[class_name.lower ]return cls.from_config config['config']
def enumerate_backends config bpm bpm_from_config config return [plug.name for _ _ plug in bpm.getPluginCandidates ]
def assert_token_equal x y if not tokens_equal x y msg u'Thetokensdiffer {0!r}! {1!r}'.format x y pytest.fail msg return True
def changequery query None **kw if query is None query web.rawinput method 'get' for k v in iteritems kw if v is None query.pop k None else query[k] vout web.ctx.pathif query out + '?' + urlencode query doseq True return out
def reconcile_message new_message session from inbox.models.message import Messageif new_message.nylas_uid is None q session.query Message .filter Message.namespace_id new_message.namespace_id Message.data_sha256 new_message.data_sha256 return q.first if '-' not in new_message.nylas_uid existing_message session.query Message .filter Message.namespace_id new_message.namespace_id Message.nylas_uid new_message.nylas_uid Message.is_created .first version Noneelse expected_public_id version new_message.nylas_uid.split '-' existing_message session.query Message .filter Message.namespace_id new_message.namespace_id Message.public_id expected_public_id Message.is_created .first if existing_message is None return Noneif version is None or int version existing_message.version existing_message.message_id_header new_message.message_id_headerexisting_message.references new_message.referencesexisting_message.parsed_body new_message.parsed_bodyreturn existing_message
def _get_labels node apiserver_url url '{0}/api/v1/nodes/{1}'.format apiserver_url node ret http.query url if 'body' in ret ret json.loads ret.get 'body' elif ret.get 'status' 0 404 return "Node{0}doesn'texist".format node else return retreturn ret.get 'metadata' {} .get 'labels' {}
def p_compound_statement_3 t pass
def _join_chars chars length mult int length / len chars + 1 mult_chars chars * mult return ''.join random.sample mult_chars length
def test_read_normal table '\n#comment withblanklineabove \n \nCol1Col2\n \n1.2"hello"\n2.4\'sworlds\n \n'reader ascii.get_reader Reader ascii.RST dat reader.read table assert_equal dat.colnames ['Col1' 'Col2'] assert_almost_equal dat[1][0] 2.4 assert_equal dat[0][1] '"hello"' assert_equal dat[1][1] "'sworlds"
def validate_storage_type storage_type if storage_type not in VALID_STORAGE_TYPES raise ValueError 'DBInstanceStorageTypemustbeoneof %s' % ' '.join VALID_STORAGE_TYPES return storage_type
def dice_coefficient string1 string2 def bigrams s return set s[i i + 2 ] for i in xrange len s - 1 nx bigrams string1 ny bigrams string2 nt nx.intersection ny return 2.0 * len nt / len nx + len ny or 1
def grp_from_gid gid global _gid_to_grp_cache _name_to_grp_cache entry cached _cache_key_value grp.getgrgid gid _gid_to_grp_cache if entry and not cached _name_to_grp_cache[entry.gr_name] entryreturn entry
def parse_series tokens for token in tokens if token.type 'STRING' raise ValueError 'Stringtokensnotallowedinseries.' s ''.join token.value for token in tokens .strip if s 'odd' return 2 1 elif s 'even' return 2 0 elif s 'n' return 1 0 if 'n' not in s return 0 int s a b s.split 'n' 1 if not a a 1elif a '-' or a '+' a int a + '1' else a int a if not b b 0else b int b return a b
def bundle_item s3.prep lambda r r.representation 's3json' return s3_rest_controller
@frappe.whitelist def get_assessment_details assessment_plan return frappe.get_list u'AssessmentEvaluationCriteria' fields [u'evaluation_criteria' u'maximum_score'] filters {u'parent' assessment_plan} order_by u'idx'
def get_capture_size state maximum 8 planes np.zeros maximum state.size state.size for x y in state.get_legal_moves n_captured 0for neighbor_group in state.get_groups_around x y gx gy next iter neighbor_group if state.liberty_counts[gx][gy] 1 and state.board[ gx gy ] ! state.current_player n_captured + len state.group_sets[gx][gy] planes[ min n_captured maximum - 1 x y ] 1return planes
def getAlias domain try data socket.gethostbyname_ex domain alias repr data[1] return aliasexcept Exception return False
def p4_describe change ds p4CmdList ['describe' '-s' str change ] if len ds ! 1 die 'p4describe-s%ddidnotreturn1result %s' % change str ds d ds[0]if 'p4ExitCode' in d die 'p4describe-s%dexitedwith%d %s' % change d['p4ExitCode'] str d if 'code' in d if d['code'] 'error' die 'p4describe-s%dreturnederrorcode %s' % change str d if 'time' not in d die 'p4describe-s%dreturnedno"time" %s' % change str d return d
def _prepare_topomap pos ax pos_x pos[ 0]pos_y pos[ 1]_hide_frame ax if any [ not pos_y.any not pos_x.any ] raise RuntimeError 'Nopositioninformationfound cannotcomputegeometriesfortopomap.' return pos_x pos_y
def _future_expose_api_anonymous func to_json True return _future_expose_api func to_json to_json user_required False
def instance_mock request cls name None spec_set True **kwargs name name if name is not None else request.fixturename return create_autospec cls _name name spec_set spec_set instance True **kwargs
def latex_output_graph self node graph node['graph']parts node['parts']graph_hash get_graph_hash node name 'inheritance%s' % graph_hash dest_path os.path.abspath os.path.join setup.app.builder.outdir '_images' if not os.path.exists dest_path os.makedirs dest_path pdf_path os.path.abspath os.path.join dest_path name + '.pdf' graph.run_dot ['-Tpdf' '-o%s' % pdf_path ] name parts graph_options {'size' '"6.0 6.0"'} return '\n\\includegraphics{%s}\n\n' % pdf_path
def func name return name
def change_user_password user password user.password encrypt_password password _datastore.put user send_password_changed_notice user password_changed.send app._get_current_object user user._get_current_object
def bad_app return None
def try_parse_field field_name value parser_dict parser parser_dict.get field_name if parser is not None return try_or_none parser value else return value
def base64_decode s if not isinstance s bytes s s.encode 'ascii' 'replace' decoded decodebytes s return decoded
def track_validation_stats json_result addons_linter False result json.loads json_result result_kind 'success' if result['errors'] 0 else 'failure' runner 'linter' if addons_linter else 'validator' statsd.incr 'devhub.{}.results.all.{}'.format runner result_kind listed_tag 'listed' if result['metadata']['listed'] else 'unlisted' signable_tag 'is_signable' if addon_can_be_signed result else 'is_not_signable' statsd.incr 'devhub.{}.results.{}.{}'.format runner listed_tag result_kind statsd.incr 'devhub.{}.results.{}.{}'.format runner listed_tag signable_tag
def formatSize size size int size steps 0sizes ['B' 'KiB' 'MiB' 'GiB' 'TiB']while size > 1000 size / 1024.0steps + 1return '%.2f%s' % size sizes[steps]
def addSparseEndpoints doubleInfillWidth endpoints horizontalSegmentsDictionary horizontalSegmentsDictionaryKey infillSolidity removedEndpoints solidSurfaceThickness surroundingXIntersections segments horizontalSegmentsDictionary[horizontalSegmentsDictionaryKey]for segment in segments addSparseEndpointsFromSegment doubleInfillWidth endpoints horizontalSegmentsDictionary horizontalSegmentsDictionaryKey infillSolidity removedEndpoints segment solidSurfaceThickness surroundingXIntersections
def is_empty_object n last if n.strip return Falselast last.strip markers {' ' ';'}if not last or last[ -1 ] in markers return Falsereturn True
def is_editable_type value return get_color_name value not in UNSUPPORTED_COLOR CUSTOM_TYPE_COLOR
def compute_live_map cfg blocks var_use_map var_def_map live_map {}for offset in blocks.keys live_map[offset] var_use_map[offset]def fix_point_progress return tuple len v for v in live_map.values old_point Nonenew_point fix_point_progress while old_point ! new_point for offset in live_map.keys for inc_blk _data in cfg.predecessors offset live_map[inc_blk] | live_map[offset] - var_def_map[inc_blk] old_point new_pointnew_point fix_point_progress return live_map
def attach_sub item filename item.sub filename
def _copy_np_state r ptr ints index r.get_state [1 3]_helperlib.rnd_set_state ptr index [int x for x in ints] return ints index
def flavor_extra_set request flavor_id metadata flavor novaclient request .flavors.get flavor_id if not metadata return Nonereturn flavor.set_keys metadata
def nice_classname obj if inspect.isclass obj cls_name obj.__name__else cls_name obj.__class__.__name__mod inspect.getmodule obj if mod name mod.__name__if name.startswith 'org.python.core.' name name[len 'org.python.core.' ]return '%s.%s' % name cls_name else return cls_name
def mathjax_for_markdown pelicanobj mathjax_script mathjax_settings config {}config['mathjax_script'] mathjax_scriptconfig['math_tag_class'] 'math'config['auto_insert'] mathjax_settings['auto_insert']try if isinstance pelicanobj.settings.get 'MD_EXTENSIONS' list pelicanobj.settings['MD_EXTENSIONS'].append PelicanMathJaxExtension config else pelicanobj.settings['MARKDOWN'].setdefault 'extensions' [] .append PelicanMathJaxExtension config except sys.excepthook *sys.exc_info sys.stderr.write '\nError-thepelicanmathjaxmarkdownextensionfailedtoconfigure.MathJaxisnon-functional.\n' sys.stderr.flush
def jinja_for_django template_name context None **kw if context is None context {}context_instance kw.pop 'context_instance' request context_instance['request']for d in context_instance.dicts context.update d return jingo.render request template_name context **kw
def colorize_log info_level text if info_level not in LOG_LEVELS.keys raise ValueError 'Wrong`info_level`value %s' % info_level log LOG_LEVELS[info_level]print '[%s%s%s]%s' % log['color'] log['name'] COLORS['std'] text
def normalize_delete_at_timestamp timestamp return '%010d' % min max 0 float timestamp 9999999999
def migrate_up manager if db_utils.auth_tables_exist manager management.setup_environ settings from django.contrib.contenttypes import management as content_managementfrom django.contrib.auth import management as auth_managementfrom django.db import models as db_modelscontent_management.update_all_contenttypes for app in db_models.get_apps auth_management.create_permissions app None 2 manager.execute_script migration_059.UP_SQL
def get_repository_files folder_path contents []for item in os.listdir folder_path if item.startswith '.hg' continuecontents.append item if contents contents.sort return contents
def is_dyad_weight w return is_weight w and all is_dyad f for f in w
def removeGlyphOverlap glyph manager BooleanOperationManager contours glyph.contoursglyph.clearContours manager.union contours glyph.getPointPen
def _logm_superdiag_entry l1 l2 t12 if l1 l2 f12 t12 / l1 elif abs l2 - l1 > abs l1 + l2 / 2 f12 t12 * np.log l2 - np.log l1 / l2 - l1 else z l2 - l1 / l2 + l1 u _unwindk np.log l2 - np.log l1 if u f12 t12 * 2 * np.arctanh z + np.pi * 1j * u / l2 - l1 else f12 t12 * 2 * np.arctanh z / l2 - l1 return f12
def bundle if len request.args 2 s3db.configure 'budget_bundle' update_next URL f 'bundle_kit_item' args request.args[1] return s3_rest_controller rheader s3db.budget_rheader
def join_with_timeout q timeout 2 q.all_tasks_done.acquire try endtime time + timeout while q.unfinished_tasks remaining endtime - time if remaining < 0.0 raise RuntimeError 'Waitingforqueuetocleartimedout' q.all_tasks_done.wait remaining finally q.all_tasks_done.release
def check_geom_offset result func cargs offset -1 check_err result geom ptr_byref cargs offset offset return check_geom geom func cargs
def get_machid mac b '%012x' % uuid.getnode mac re.findall '..' mac mac + ['00' '00']from codecs import encodemac ''.join [encode h 'hex_codec' for h in mac[ -1 ]] ids np.flipud np.fromstring mac np.int32 count 2 return ids
def inheriting_field_data kvs return InheritingFieldData inheritable_names InheritanceMixin.fields.keys kvs kvs
def test_tmpdir_fallback_tox_env testdir monkeypatch monkeypatch.delenv 'USER' raising False monkeypatch.delenv 'USERNAME' raising False testdir.makepyfile '\nimportpytest\ndeftest_some tmpdir \nasserttmpdir.isdir \n' reprec testdir.inline_run reprec.assertoutcome passed 1
def _get_role_name_from_file path dirs path.partsreturn dirs[ dirs.index 'roles' + 1 ]
def _authenticate consumer_key consumer_secret token_data {'client_id' consumer_key 'client_secret' consumer_secret 'grant_type' 'client_credentials' 'scope' 'SMS'}token_resource 'https //api.telstra.com/v1/oauth/token'token_response requests.get token_resource params token_data timeout 10 .json if 'error' in token_response return Falsereturn token_response
def _fast_construct_edges G radius p pos nx.get_node_attributes G 'pos' nodes coords list zip *pos.items kdtree KDTree coords edge_indexes kdtree.query_pairs radius p edges nodes[u] nodes[v] for u v in edge_indexes G.add_edges_from edges
def p_expression_statement t pass
def add_http_if_no_scheme url match re.match '^\\w+ //' url flags re.I if not match parts urlparse url scheme 'http ' if parts.netloc else 'http //' url scheme + url return url
def setup_fast_link_sharelib_builder top_env new_link_actions []new_link_actions.append SCons.Defaults.SharedCheck new_link_actions.append MakeAction fast_link_sharelib_action '$SHLINKCOMSTR' sharedlib SCons.Builder.Builder action new_link_actions emitter '$SHLIBEMITTER' prefix '$SHLIBPREFIX' suffix '$SHLIBSUFFIX' target_scanner SCons.Scanner.Prog.ProgramScanner src_suffix '$SHOBJSUFFIX' src_builder 'SharedObject' top_env['BUILDERS']['SharedLibrary'] sharedlib
def getCanonicalID iname xrd_tree xrd_list xrd_tree.findall xrd_tag xrd_list.reverse try canonicalID xri.XRI xrd_list[0].findall canonicalID_tag [0].text except IndexError return NonechildID canonicalID.lower for xrd in xrd_list[1 ] parent_sought childID[ childID.rindex '!' ]parent xri.XRI xrd.findtext canonicalID_tag if parent_sought ! parent.lower raise XRDSFraud '%rcannotcomefrom%s' % childID parent childID parent_soughtroot xri.rootAuthority iname if not xri.providerIsAuthoritative root childID raise XRDSFraud '%rcannotcomefromroot%r' % childID root return canonicalID
def normalise_email email clean_email email.strip if '@' in clean_email local host clean_email.split '@' return local + '@' + host.lower return clean_email
def test_outputs_taps_check x tensor.fvector 'x' y tensor.fvector 'y' f lambda x y [x] outputs_info {'initial' y 'taps' [0]}assert_raises ValueError theano.scan f x outputs_info outputs_info {'initial' y 'taps' [ -1 -1 ]}assert_raises ValueError theano.scan f x outputs_info print 'done'
def get_current_site_configuration from openedx.core.djangoapps.theming.helpers import get_current_sitesite get_current_site try return getattr site 'configuration' None except SiteConfiguration.DoesNotExist return None
def get_nav_close fund_type 'all' sub_type 'all' ct._write_head nums _get_fund_num ct.SINA_NAV_COUNT_URL % ct.P_TYPE['http'] ct.DOMAINS['vsf'] ct.NAV_CLOSE_KEY ct.NAV_CLOSE_API ct.NAV_CLOSE_T2[fund_type] ct.NAV_CLOSE_T3[sub_type] fund_df _parse_fund_data ct.SINA_NAV_DATA_URL % ct.P_TYPE['http'] ct.DOMAINS['vsf'] ct.NAV_OPEN_KEY ct.NAV_CLOSE_API nums ct.NAV_CLOSE_T2[fund_type] ct.NAV_CLOSE_T3[sub_type] 'close' return fund_df
def test_install_editable_from_hg script tmpdir pkg_path _create_test_package script name 'testpackage' vcs 'hg' args ['install' '-e' 'hg+%s#egg testpackage' % path_to_url pkg_path ]result script.pip *args **{'expect_error' True} result.assert_installed 'testpackage' with_files ['.hg']
def test_show_with_files_not_found script data editable data.packages.join 'SetupPyUTF8' script.pip 'install' '-e' editable result script.pip 'show' '-f' 'SetupPyUTF8' lines result.stdout.splitlines assert len lines 11 assert 'Name SetupPyUTF8' in lines assert 'Version 0.0.0' in lines assert any line.startswith 'Location ' for line in lines assert 'Requires ' in lines assert 'Files ' in lines assert 'Cannotlocateinstalled-files.txt' in lines
def _patch_arrays ARRAYS['data'] {'meta_paths' [ 'traces' ] 'items' list TRACE_NAMES }
def _serialize_item item stream qtutils.serialize_stream stream item.url stream.writeQString item.title qtutils.serialize_stream stream QByteArray stream.writeInt32 0 stream.writeBool False qtutils.serialize_stream stream QUrl stream.writeInt32 0 qtutils.serialize_stream stream item.original_url stream.writeBool False stream.writeInt64 int time.time stream.writeInt 200
def getLiftedOutput derivation geometryOutput xmlElement if derivation.moveType.lower [ 1] 'm' return geometryOutputgeometryOutputVertexes matrix.getConnectionVertexes geometryOutput translation Vector3 0.0 0.0 - euclidean.getBottomPath geometryOutputVertexes euclidean.translateVector3Path geometryOutputVertexes translation return geometryOutput
def _read_typedesc f typedesc {'typecode' _read_long f 'varflags' _read_long f }if typedesc['varflags'] & 2 2 raise Exception 'Systemvariablesnotimplemented' typedesc['array'] typedesc['varflags'] & 4 4 typedesc['structure'] typedesc['varflags'] & 32 32 if typedesc['structure'] typedesc['array_desc'] _read_arraydesc f typedesc['struct_desc'] _read_structdesc f elif typedesc['array'] typedesc['array_desc'] _read_arraydesc f return typedesc
def default_ssl_cacerts return SSL_CACERTS.get
def image_snapshot_revert call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Theimage_snapshot_revertfunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}image_id kwargs.get 'image_id' None image_name kwargs.get 'image_name' None snapshot_id kwargs.get 'snapshot_id' None if snapshot_id is None raise SaltCloudSystemExit "Theimage_snapshot_revertfunctionrequiresa'snapshot_id'tobeprovided." if image_id if image_name log.warning "Boththe'image_id'and'image_name'argumentswereprovided.'image_id'willtakeprecedence." elif image_name image_id get_image_id kwargs {'name' image_name} else raise SaltCloudSystemExit "Theimage_snapshot_revertfunctionrequireseitheran'image_id'oran'image_name'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.image.snapshotrevert auth int image_id int snapshot_id data {'action' 'image.snapshotrevert' 'reverted' response[0] 'snapshot_id' response[1] 'error_code' response[2]}return data
def mock_verify_token testcase patcher mock.patch 'db.Journalist.verify_token' testcase.addCleanup patcher.stop testcase.mock_journalist_verify_token patcher.start testcase.mock_journalist_verify_token.return_value True
@command 'vp' def vp msg util.F 'currentpl' txt util.F 'adviseadd' if g.model else util.F 'advisesearch' failmsg util.F 'plempty' + '' + txt paginatesongs g.active msg msg failmsg failmsg
def render s context None if context is None context {}t get_env .from_string s return t.render context
def basic_extractor document train_set word_features _get_words_from_dataset train_set tokens _get_document_tokens document features dict u'contains {0} '.format word word in tokens for word in word_features return features
def parse_keqv_list l encoded_list [u.encode 'utf-8' for u in l]encoded_parsed urllib2.parse_keqv_list encoded_list return dict k.decode 'utf-8' v.decode 'utf-8' for k v in encoded_parsed.items
def toeplitz c r None c np.asarray c .ravel if r is None r c.conjugate else r np.asarray r .ravel vals np.concatenate r[ -1 0 -1 ] c a b np.ogrid[0 len c len r - 1 -1 -1 ]indx a + b return vals[indx]
def ip6_interfaces if salt.utils.is_proxy return {}ret {}ifaces _get_interfaces for face in ifaces iface_ips []for inet in ifaces[face].get 'inet6' [] if 'address' in inet iface_ips.append inet['address'] for secondary in ifaces[face].get 'secondary' [] if 'address' in secondary iface_ips.append secondary['address'] ret[face] iface_ipsreturn {'ip6_interfaces' ret}
def isBeingWritten filepath ctime max os.path.getctime filepath os.path.getmtime filepath if ctime > time.time - 60 return Truereturn False
def get_hash_from_file hash_path dvd_basename hash_file open hash_path 'r' for line in hash_file.readlines if dvd_basename in line return line.split [0]
def plug_interface cluster lswitch_id port type attachment None lport_obj {}if attachment lport_obj['vif_uuid'] attachmentlport_obj['type'] typereturn _plug_interface cluster lswitch_id port lport_obj
def env_absent name user 'root' name name.strip ret {'name' name 'result' True 'changes' {} 'comment' ''}if __opts__['test'] status _check_cron_env user name ret['result'] Noneif status 'absent' ret['result'] Trueret['comment'] 'Cronenv{0}isabsent'.format name elif status 'present' or status 'update' ret['comment'] 'Cronenv{0}issettoberemoved'.format name return retdata __salt__['cron.rm_env'] user name if data 'absent' ret['comment'] 'Cronenv{0}alreadyabsent'.format name return retif data 'removed' ret['comment'] "Cronenv{0}removedfrom{1}'scrontab".format name user ret['changes'] {user name}return retret['comment'] 'Cronenv{0}foruser{1}failedtocommitwitherror{2}'.format name user data ret['result'] Falsereturn ret
def confusion_matrix rater_a rater_b min_rating None max_rating None assert len rater_a len rater_b if min_rating is None min_rating min rater_a + rater_b if max_rating is None max_rating max rater_a + rater_b num_ratings int max_rating - min_rating + 1 conf_mat [[0 for i in range num_ratings ] for j in range num_ratings ]for a b in zip rater_a rater_b conf_mat[ a - min_rating ][ b - min_rating ] + 1return conf_mat
def make_iprofiledblockdeviceapi_tests profiled_blockdevice_api_factory dataset_size class Tests IProfiledBlockDeviceAPITestsMixin TestCase def setUp self super Tests self .setUp self.api profiled_blockdevice_api_factory self self.dataset_size dataset_sizereturn Tests
def get_body_barycentric_posvel body time ephemeris None return _get_body_barycentric_posvel body time ephemeris
def required_field_attrs self widget attrs field_widget_attrs self widget if self.required and 'required' not in attrs attrs['required'] 'required'return attrs
@task@cmdopts [ 'suite ' 's' 'Testsuitetorun' 'coverage' 'c' 'Runtestundercoverage' ] @timeddef test_js_run options options.mode 'run'test_js options
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def save_to_well_known_file credentials well_known_file None if well_known_file is None well_known_file _get_well_known_file config_dir os.path.dirname well_known_file if not os.path.isdir config_dir raise OSError 'Configdirectorydoesnotexist {0}'.format config_dir credentials_data credentials.serialization_data_save_private_file well_known_file credentials_data
def _invalidate_queue q val None sync True def _qsize len len return 1def _put item passdef _get return valif sync q.mutex.acquire try q.maxsize 2q._qsize _qsizeq._put _putq._get _getq.not_empty.notifyAll q.not_full.notifyAll finally if sync q.mutex.release
def _plot_sensors pos_x pos_y sensors ax from matplotlib.patches import Circleif sensors is True for x y in zip pos_x pos_y ax.add_artist Circle xy x y radius 0.003 color 'k' else ax.plot pos_x pos_y sensors
@add_divider_highlight_group u'background divider' def uptime pl days_format u'{days d}d' hours_format u'{hours d}h' minutes_format u'{minutes d}m' seconds_format u'{seconds d}s' shorten_len 3 try seconds _get_uptime except NotImplementedError pl.warn u'Unabletogetuptime.Youshouldinstallpsutilmodule' return None minutes seconds divmod seconds 60 hours minutes divmod minutes 60 days hours divmod hours 24 time_formatted list filter None [ days_format.format days days if days and days_format else None hours_format.format hours hours if hours and hours_format else None minutes_format.format minutes minutes if minutes and minutes_format else None seconds_format.format seconds seconds if seconds and seconds_format else None ] [0 shorten_len]return u''.join time_formatted .strip
def _convert_string_array data encoding itemsize None if encoding is not None and len data data Series data.ravel .str.encode encoding .values.reshape data.shape if itemsize is None itemsize lib.max_len_string_array _ensure_object data.ravel data np.asarray data dtype 'S%d' % itemsize return data
def modify_label id **data models.Label.smart_get id .update_object data
def _pick_data_or_ica info ch_names [c['ch_name'] for c in info['chs']]if 'ICA' in ' '.join ch_names picks pick_types info exclude [] misc True else picks _pick_data_channels info exclude [] with_ref_meg False return picks
def GetCompilerPath target_list data options build_file _ _ gyp.common.ParseQualifiedTarget target_list[0] make_global_settings_dict data[build_file].get 'make_global_settings' {} for key value in make_global_settings_dict if key in ['CC' 'CXX'] return os.path.join options.toplevel_dir value for key in ['CC_target' 'CC' 'CXX'] compiler os.environ.get key if compiler return compilerreturn 'gcc'
def _combine_args first *rest if hasattr first '__iter__' and not isinstance first TreeElement or isinstance first type or isinstance first basestring or isinstance first dict if rest raise ValueError 'Argumentsmustbeeitherasinglelistoftargets orseparatelyspecifiedtargets e.g.foo t1 t2 t3 butnotboth.' return firstreturn itertools.chain [first] rest
def discover_sourcemap result sourcemap result.headers.get 'sourcemap' result.headers.get 'x-sourcemap' if not sourcemap parsed_body result.body.split '\n' if len parsed_body > 10 possibilities parsed_body[ 5] + parsed_body[ -5 ] else possibilities parsed_bodyfor line in possibilities if line[ 21] in '//#sourceMappingURL ' '//@sourceMappingURL ' sourcemap line[21 ].rstrip if sourcemap if '/*' in sourcemap and sourcemap[ -2 ] '*/' index sourcemap.index '/*' if index 0 raise AssertionError 'react-nativecommentfoundatbadlocation %d %r' % index sourcemap sourcemap sourcemap[ index]sourcemap urljoin result.url sourcemap return sourcemap
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _is_pid_running_on_unix pid try os.kill pid 0 except OSError return Falseelse return True
def test_find_default_import_path test_apps monkeypatch tmpdir monkeypatch.delitem os.environ 'FLASK_APP' raising False assert find_default_import_path None monkeypatch.setitem os.environ 'FLASK_APP' 'notanapp' assert find_default_import_path 'notanapp' tmpfile tmpdir.join 'testapp.py' tmpfile.write '' monkeypatch.setitem os.environ 'FLASK_APP' str tmpfile expect_rv prepare_exec_for_file str tmpfile assert find_default_import_path expect_rv
def prepare_asides_to_store asides_source asides Noneif asides_source asides []for asd in asides_source aside_fields {}for asd_field_key asd_field_val in asd.fields.iteritems aside_fields[asd_field_key] asd_field_val.read_from asd asides.append {'aside_type' asd.scope_ids.block_type 'fields' aside_fields} return asides
def humanDurationNanosec nsec if nsec < 1000 return u'%unsec' % nsec usec nsec divmod nsec 1000 if usec < 1000 return u'%.2fusec' % usec + float nsec / 1000 msec usec divmod usec 1000 if msec < 1000 return u'%.2fms' % msec + float usec / 1000 return humanDuration msec
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def find_vbd_by_number session vm_ref dev_number vbd_refs session.VM.get_VBDs vm_ref requested_device str dev_number if vbd_refs for vbd_ref in vbd_refs try user_device session.VBD.get_userdevice vbd_ref if user_device requested_device return vbd_refexcept session.XenAPI.Failure msg 'ErrorlookingupVBD%sfor%s' % vbd_ref vm_ref LOG.debug msg exc_info True
def cas_login request next_page None required False ret django_cas_login request next_page required if request.user.is_authenticated user request.userUserProfile.objects.get_or_create user user defaults {'name' user.username} return ret
def scale_time_units time_seconds_arr unit if unit u'minutes' return list map lambda x x * 1.0 / 60 time_seconds_arr elif unit u'hours' return list map lambda x x * 1.0 / 60 * 60 time_seconds_arr elif unit u'days' return list map lambda x x * 1.0 / 24 * 60 * 60 time_seconds_arr return time_seconds_arr
def bridge_has_service_port bridge return bridge_has_port bridge is_trunk_service_port
def discardLogs global logfilelogfile NullFile
def test_continuous_error y np.linspace 0 1 15 nm NearMiss random_state RND_SEED version VERSION_NEARMISS assert_warns UserWarning nm.fit X y
def get_document_from_index doc_id index index gae_search.Index index return _search_document_to_dict index.get doc_id
def _validate_coord center if isinstance center SkyCoord icrscoord center.transform_to ICRS .frameelif isinstance center BaseCoordinateFrame icrscoord center.transform_to ICRS else icrscoord ICRS Longitude center[0] unit u.degree Latitude center[1] unit u.degree return icrscoord.ra.degree icrscoord.dec.degree
def get_exploration_snapshots_metadata exploration_id exploration get_exploration_by_id exploration_id current_version exploration.versionversion_nums range 1 current_version + 1 return exp_models.ExplorationModel.get_snapshots_metadata exploration_id version_nums
def _install_instrumented_lookups _install_lookups dict instance_state _instrumentation_factory.state_of instance_dict _instrumentation_factory.dict_of manager_of_class _instrumentation_factory.manager_of_class
def kaiser M beta sym True if _len_guards M return np.ones M M needs_trunc _extend M sym n np.arange 0 M alpha M - 1 / 2.0 w special.i0 beta * np.sqrt 1 - n - alpha / alpha ** 2.0 / special.i0 beta return _truncate w needs_trunc
def needsRunningReactor reactor thunk reactor.callWhenRunning thunk
def dpkg_search_for_binutils arch util packages []try filename 'bin/%s*linux*-%s' % arch util output subprocess.check_output ['dpkg' '-S' filename] for line in output.strip .splitlines package path line.split ' ' 1 packages.append package except OSError passexcept subprocess.CalledProcessError passreturn packages
def screenwords imgdata if config.TESSERACT_CMD is not None proc subprocess.Popen [config.TESSERACT_CMD 'stdin' 'stdout'] stdin subprocess.PIPE stdout subprocess.PIPE proc.stdin.write imgdata proc.stdin.close words set result []size MAXVALLENfor line in proc.stdout if size 0 breakfor word in line.split if word not in words if len word < size words.add word result.append word size - len word else size 0breakif result return result
def _img2arr im assert im.mode 'L' return numpy.reshape numpy.fromstring im.tobytes numpy.ubyte im.size[1] im.size[0]
def user_get user_id None name None profile None **connection_args kstone auth profile **connection_args ret {}if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}try user kstone.users.get user_id except keystoneclient.exceptions.NotFound msg "Couldnotfinduser'{0}'".format user_id log.error msg return {'Error' msg}ret[user.name] dict value getattr user value None for value in dir user if not value.startswith '_' and isinstance getattr user value None six.text_type dict bool str tenant_id getattr user 'tenantId' None if tenant_id ret[user.name]['tenant_id'] tenant_idreturn ret
def entrypoints namespace try from pkg_resources import iter_entry_pointsexcept ImportError return iter [] return ep ep.load for ep in iter_entry_points namespace
def text_string value encoding 'utf-8' if isinstance value bytes return value.decode encoding return value
def ode_sol_simplicity sol func trysolving True if iterable sol for i in sol if ode_sol_simplicity i func trysolving trysolving oo return ooreturn len str sol if sol.has Integral return ooif sol.lhs func and not sol.rhs.has func or sol.rhs func and not sol.lhs.has func return -2 if trysolving try sols solve sol func if not sols raise NotImplementedErrorexcept NotImplementedError passelse return -1 return len str sol
@mobile_template 'questions/{mobile/}marketplace.html' def marketplace request template None return render request template {'categories' MARKETPLACE_CATEGORIES}
def load_backends backends force_load False global BACKENDSCACHEif force_load BACKENDSCACHE {}if not BACKENDSCACHE for auth_backend in backends backend module_member auth_backend if issubclass backend BaseAuth BACKENDSCACHE[backend.name] backendreturn BACKENDSCACHE
def test_init_max_time_mins tpot_obj TPOTClassifier max_time_mins 30 generations 1000 assert tpot_obj.generations 1000000 assert tpot_obj.max_time_mins 30
def unpublish_collection committer_id collection_id _unpublish_activity committer_id collection_id feconf.ACTIVITY_TYPE_COLLECTION
def HT_SINE ds count ret call_talib_with_ds ds count talib.HT_SINE if ret is None ret None None return ret
def _reinstall_default_lookups _install_lookups dict instance_state _default_state_getter instance_dict _default_dict_getter manager_of_class _default_manager_getter _instrumentation_factory._extended False
def plot_specgrams base_dir CHART_DIR plt.clf genres ['classical' 'jazz' 'country' 'pop' 'rock' 'metal']num_files 3 f axes plt.subplots len genres num_files for genre_idx genre in enumerate genres for idx fn in enumerate glob.glob os.path.join GENRE_DIR genre '*.wav' if idx num_files breakaxis axes[ genre_idx idx ]axis.yaxis.set_major_formatter EngFormatter axis.set_title '%ssong%i' % genre idx + 1 plot_specgram axis fn specgram_file os.path.join base_dir 'Spectrogram_Genres.png' plt.savefig specgram_file bbox_inches 'tight' plt.show
def nth n iterable default None return next islice iterable n None default
def maybe_fileno f try return fileno f except FILENO_ERRORS pass
def p_abstract_declarator_opt_1 t pass
@foregrounddef mpl args stdin None from xontrib.mplhooks import showshow
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def drange dstart dend delta step delta.days + delta.seconds / SECONDS_PER_DAY + delta.microseconds / MUSECONDS_PER_DAY f1 _to_ordinalf dstart f2 _to_ordinalf dend return np.arange f1 f2 step
def cosine_distances X Y if X is Y X Y np.asanyarray X else X np.asanyarray X Y np.asanyarray Y if X.shape[1] ! Y.shape[1] raise ValueError 'IncompatibledimensionforXandYmatrices' return 1.0 - ssd.cdist X Y 'cosine'
def _find_closest_point_on_leg p1 p2 p0 if np.all p2 p1 d np.sum p0 - p1 ** 2 return d p1 d21 p2 - p1 d01 p0 - p1 proj np.dot d01 d21 / np.dot d21 d21 if proj < 0 proj 0if proj > 1 proj 1pc p1 + proj * d21 d np.sum pc - p0 ** 2 return d pc
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos.cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos.cmd'] 'delete_config' name matches __salt__['nxos.cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def strip_path fpath if not fpath return fpathtry file_path file_name os.path.split fpath except file_name fpathreturn file_name
def parse_from_strings name code pxds None level None initial_pos None context None allow_struct_enum_decorator False if context is None context StringParseContext name assert isinstance code _unicode 'unicodecodesnippetsonlyplease'encoding 'UTF-8'module_name nameif initial_pos is None initial_pos name 1 0 code_source StringSourceDescriptor name code scope context.find_module module_name pos initial_pos need_pxd False buf StringIO code scanner PyrexScanner buf code_source source_encoding encoding scope scope context context initial_pos initial_pos ctx Parsing.Ctx allow_struct_enum_decorator allow_struct_enum_decorator if level is None tree Parsing.p_module scanner 0 module_name ctx ctx tree.scope scopetree.is_pxd Falseelse tree Parsing.p_code scanner level level ctx ctx tree.scope scopereturn tree
def isleapyear year msg 'isleapyearisdeprecated.Use.is_leap_yearpropertyinstead'warnings.warn msg FutureWarning year np.asarray year return np.logical_or year % 400 0 np.logical_and year % 4 0 year % 100 > 0
def event_fire consul_url None name None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not name raise SaltInvocationError 'Requiredargument"name"ismissing.' if 'dc' in kwargs query_params kwargs['dc']if 'node' in kwargs query_params kwargs['node']if 'service' in kwargs query_params kwargs['service']if 'tag' in kwargs query_params kwargs['tag']function 'event/fire/{0}'.format name res _query consul_url consul_url query_params query_params method 'PUT' function function if res['res'] ret['res'] Trueret['message'] 'Event{0}fired.'.format name ret['data'] ret['data']else ret['res'] Falseret['message'] 'CloningACLitem{0}failed.'.format kwargs['name'] return ret
def _get_annot_fname annot_fname subject hemi parc subjects_dir if annot_fname is not None hemis [op.basename annot_fname [ 2]]if hemis[0] not in ['lh' 'rh'] raise ValueError 'Couldnotdeterminehemispherefromfilename filenamehastostartwith"lh"or"rh".' annot_fname [annot_fname]else if hemi not in ['lh' 'rh' 'both'] raise ValueError 'hemihastobe"lh" "rh" or"both"' if hemi 'both' hemis ['lh' 'rh']else hemis [hemi]subjects_dir get_subjects_dir subjects_dir raise_error True dst op.join subjects_dir subject 'label' '%%s.%s.annot' % parc annot_fname [ dst % hemi_ for hemi_ in hemis]return annot_fname hemis
def make_tmp_name length 8 return ''.join sample list lowercase length
def set_language_changer request func request._language_changer func
def from_dtype dtype if dtype.fields is None try return FROM_DTYPE[dtype]except KeyError if dtype.char in 'SU' return _from_str_dtype dtype if dtype.char in 'mM' return _from_datetime_dtype dtype if dtype.char in 'V' subtype from_dtype dtype.subdtype[0] return types.NestedArray subtype dtype.shape raise NotImplementedError dtype else return from_struct_dtype dtype
def resolve_path path root if not os.path.isabs path path os.path.join root path return path
def expand_tokens tokens equal False for token in tokens for pre in token.pre_tags yield pre if not equal or not token.hide_when_equal if token.trailing_whitespace yield token.html + token.trailing_whitespace else yield token.html for post in token.post_tags yield post
def get_mistral_api_url api_version DEFAULT_API_VERSION if cfg.CONF.mistral.api_url api_url get_url_without_trailing_slash cfg.CONF.mistral.api_url api_url '%s/%s' % api_url api_version else LOG.warn '"mistral.api_url"notset usingauth.api_url' api_url get_full_public_api_url api_version api_version return api_url
def get_simple_version version_string if not version_string return ''return re.sub '[< >]' '' version_string
def get_internal resource **lookup datasource config.DOMAIN[resource]['datasource']aggregation datasource.get 'aggregation' if aggregation return _perform_aggregation resource aggregation['pipeline'] aggregation['options'] else return _perform_find resource lookup
def html_annotate_merge_annotations tokens_old tokens_new s InsensitiveSequenceMatcher a tokens_old b tokens_new commands s.get_opcodes for command i1 i2 j1 j2 in commands if command 'equal' eq_old tokens_old[i1 i2]eq_new tokens_new[j1 j2]copy_annotations eq_old eq_new
def _parse_query query if query is None query 'full'query query.split ' ' return QUERIES[query[0]] *query[1 ]
def tkinter_clipboard_get try from tkinter import Tk TclErrorexcept ImportError raise TryNext 'Gettingtextfromtheclipboardonthisplatformrequirestkinter.' root Tk root.withdraw try text root.clipboard_get except TclError raise ClipboardEmptyfinally root.destroy text py3compat.cast_unicode text py3compat.DEFAULT_ENCODING return text
def time_format value format_string tf TimeFormat value return tf.format format_string
@task def assets ctx dev False watch False if os.getcwd ! HERE os.chdir HERE npm 'npminstall'if not dev npm + '--production'ctx.run npm echo True bower_install ctx webpack ctx clean False watch watch dev dev
def cmd_run module cmd check_rc True return module.run_command cmd.split '' check_rc check_rc
def wildcard_to_regexp instring regexp_string ''if instring[0] ! '*' regexp_string + '^'regexp_string + instring.replace '*' ' .* ' .replace '?' ' .{1} ' if instring[ -1 ] ! '*' regexp_string + '$'return regexp_string
def get_slave_delay name metrics get_metrics [0]if 'rs_status_myState' not in metrics['data'] or metrics['data']['rs_status_myState'] ! 2 result 0else master {}slave {}try for member in metrics['data']['rs_status_members'] if member['state'] 1 master memberif member['name'].split ' ' [0] socket.getfqdn slave memberresult max 0 master['optime']['t'] - slave['optime']['t'] / 1000 except KeyError result 0return result
def merge dict1 dict2 for key val2 in dict2.items if val2 is not None val1 dict1.get key if isinstance val2 dict if val1 is None val1 {}if isinstance val1 Alias val1 val1 val2 elif isinstance val1 tuple alias others val1others others.copy merge others val2 val1 alias others else val1 val1.copy merge val1 val2 else val1 val2dict1[key] val1
def try_set_language lang try django.utils.translation.activate lang if trans_real.catalog ._catalog is None raise Exception 'Invalidlanguage!' except Exception django.utils.translation.activate 'en'
def tick_update_position tick tickxs tickys labelpos for label on in tick.label1 tick.label1On tick.label2 tick.label2On if on label.set_position labelpos tick.tick1On tick.tick2On True False tick.tick1line.set_linestyle u'-' tick.tick1line.set_marker u'' tick.tick1line.set_data tickxs tickys tick.gridline.set_data 0 0
def _compute_gapopen_num hsp gapopen 0for seq_type in 'query' 'hit' seq str getattr hsp seq_type .seq gapopen + len re.findall _RE_GAPOPEN seq return gapopen
def _is_uuid zone return len zone 36 and zone.index '-' 8
def _create_xblock_child_info xblock course_outline graders include_children_predicate NEVER user None course None child_info {}child_category xblock_primary_child_category xblock if child_category child_info {'category' child_category 'display_name' xblock_type_display_name child_category default_display_name child_category }if xblock.has_children and include_children_predicate xblock child_info['children'] [create_xblock_info child include_child_info True course_outline course_outline include_children_predicate include_children_predicate parent_xblock xblock graders graders user user course course for child in xblock.get_children ]return child_info
def handleFriends qry try getUserName except return _skypeError try return _findFriends qry '' False except EnvironmentError return PyFred 'ch.xtin.skypingalfred.error' False .addItem 'skypeupdate' 'skypeupdate' 'NoSkypeFriendsFound' 'Useskypeupdatetocachefriends!' True 'update' .toXML except return PyFred.GenericError
@require_GET@login_required@ensure_csrf_cookiedef manage_user_standing request if not request.user.is_staff raise Http404all_disabled_accounts UserStanding.objects.filter account_status UserStanding.ACCOUNT_DISABLED all_disabled_users [standing.user for standing in all_disabled_accounts]headers ['username' 'account_changed_by']rows []for user in all_disabled_users row [user.username user.standing.changed_by]rows.append row context {'headers' headers 'rows' rows}return render_to_response 'manage_user_standing.html' context
def kdd_mapk actual predicted k 10 return np.mean [kdd_apk a p k for a p in zip actual predicted ]
def _is_scalar e e sympify e if isinstance e Expr if e.is_Integer or e.is_Float or e.is_Rational or e.is_Number or e.is_Symbol and e.is_commutative return Truereturn False
def is_abs_url url regex re.compile '^ ? http|ftp s? // ? ? [A-Z0-9] ? [A-Z0-9-]{0 61}[A-Z0-9] ?\\. + ? [A-Z]{2 6}\\.?|[A-Z0-9-]{2 }\\.? |localhost|\\d{1 3}\\.\\d{1 3}\\.\\d{1 3}\\.\\d{1 3}|\\[?[A-F0-9]* [A-F0-9 ]+\\]? ? \\d+ ? ? /?|[/?]\\S+ $' re.IGNORECASE c_regex re.compile regex return c_regex.search url is not None
def print_terms terms parent for term in terms if type terms[term] ! dict print ' DCTB ' + parent + term else print_terms terms[term] parent + term + '.'
def compute_node_get_all context return IMPL.compute_node_get_all context
def _list_groups request template query context {} sort_form forms.SortForm request.GET show_pagination Falseif sort_form.is_valid query query.order_by sort_form.cleaned_data['sort'] 'name' else query query.order_by 'name' paginator Paginator query settings.ITEMS_PER_PAGE page request.GET.get 'page' 1 try groups paginator.page page except PageNotAnInteger groups paginator.page 1 except EmptyPage groups paginator.page paginator.num_pages if paginator.count > settings.ITEMS_PER_PAGE show_pagination Truedata {'groups' groups 'page' page 'sort_form' sort_form 'show_pagination' show_pagination}data.update context return render request template data
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _CheckListType settings allowed_type name allow_none True if settings is None if not allow_none raise TypeError '%sisNone whichisnotallowed.' % name return settingsif not isinstance settings tuple list raise TypeError '%sisnotalist.' % name if not all isinstance i allowed_type for i in settings type_list list set type setting for setting in settings raise TypeError "%scontainstypesthatdon'tmatch%s %s" % name allowed_type.__name__ type_list return settings
def test_footer_disable_on_table class Table tables.Table name tables.Column country tables.Column footer 'Total ' table Table MEMORY_DATA show_footer False assert table.has_footer is False
def find_vbd_by_number session vm_ref dev_number vbd_refs session.VM.get_VBDs vm_ref requested_device str dev_number if vbd_refs for vbd_ref in vbd_refs try user_device session.VBD.get_userdevice vbd_ref if user_device requested_device return vbd_refexcept session.XenAPI.Failure msg 'ErrorlookingupVBD%sfor%s' % vbd_ref vm_ref LOG.debug msg exc_info True
def metadata_forward if CONF.metadata_host ! '127.0.0.1' iptables_manager.ipv4['nat'].add_rule 'PREROUTING' '-s0.0.0.0/0-d169.254.169.254/32-ptcp-mtcp--dport80-jDNAT--to-destination%s %s' % CONF.metadata_host CONF.metadata_port else iptables_manager.ipv4['nat'].add_rule 'PREROUTING' '-s0.0.0.0/0-d169.254.169.254/32-ptcp-mtcp--dport80-jREDIRECT--to-ports%s' % CONF.metadata_port iptables_manager.apply
def _check_minions_directories pki_dir minions_accepted os.path.join pki_dir salt.key.Key.ACC minions_pre os.path.join pki_dir salt.key.Key.PEND minions_rejected os.path.join pki_dir salt.key.Key.REJ minions_denied os.path.join pki_dir salt.key.Key.DEN return minions_accepted minions_pre minions_rejected minions_denied
def read_element_binary stream size return BytesIO stream.read size
def new data None return SHA224Hash .new data
def _formatparam param value None quote True if value is not None and len value > 0 if isinstance value tuple param + '*'value utils.encode_rfc2231 value[2] value[0] value[1] if quote or tspecials.search value return '%s "%s"' % param utils.quote value else return '%s %s' % param value else return param
def normalize_date date return date.replace tzinfo tz.tzutc
def random_quaternion rand None if rand is None rand numpy.random.rand 3 else assert len rand 3 r1 numpy.sqrt 1.0 - rand[0] r2 numpy.sqrt rand[0] pi2 math.pi * 2.0 t1 pi2 * rand[1] t2 pi2 * rand[2] return numpy.array [ numpy.cos t2 * r2 numpy.sin t1 * r1 numpy.cos t1 * r1 numpy.sin t2 * r2 ]
def getNormals interpolationOffset offset portionDirection normals []portionFrom portionDirection.portion - 0.0001 portionTo portionDirection.portion + 0.0001 if portionFrom > 0.0 normals.append offset - interpolationOffset.getVector3ByPortion PortionDirection portionFrom .getNormalized if portionTo < 1.0 normals.append interpolationOffset.getVector3ByPortion PortionDirection portionTo - offset .getNormalized return normals
def document_delete index doc_type id hosts None profile None es _get_instance hosts profile try if not index_exists index index return Trueelse result es.delete index index doc_type doc_type id id if result.get 'found' False return Trueexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def hexdump src length 16 prefix '' n 0left length // 2 right length - left result []src bytearray src while src s src src[ length] src[length ] l r s[ left] s[left ] hexa '%-*s' % left * 3 ''.join [ '%02x' % x for x in l] hexb '%-*s' % right * 3 ''.join [ '%02x' % x for x in r] lf l.translate FILTER rf r.translate FILTER result.append '%s%04x%s%s%s%s' % prefix n hexa hexb lf.decode rf.decode n + lengthreturn '\n'.join result
def GitFile filename mode 'rb' bufsize -1 if 'a' in mode raise IOError 'appendmodenotsupportedforGitfiles' if '+' in mode raise IOError 'read/writemodenotsupportedforGitfiles' if 'b' not in mode raise IOError 'textmodenotsupportedforGitfiles' if 'w' in mode return _GitFile filename mode bufsize else return io.open filename mode bufsize
def GetCSVGeneratorFactory kind csv_filename batch_size csv_has_header openfile open create_csv_reader csv.reader loader Loader.RegisteredLoader kind loader._Loader__openfile openfileloader._Loader__create_csv_reader create_csv_readerrecord_generator loader.generate_records csv_filename def CreateGenerator request_manager progress_queue progress_generator unused_kinds 'InitializeaUploadWorkItemgenerator.\n\nArgs \nrequest_manager ARequestManagerinstance.\nprogress_queue AProgressQueueinstancetosendprogressinformation.\nprogress_generator AgeneratorofprogressinformationorNone.\nunused_kinds Thekindsbeinggenerated ignoredinthismethod .\n\nReturns \nAnUploadWorkItemGeneratorinstance.\n'return UploadWorkItemGenerator request_manager progress_queue progress_generator record_generator csv_has_header batch_size return CreateGenerator
def CreateParser query input_string antlr3.ANTLRStringStream query lexer QueryLexerWithErrors input_string tokens antlr3.CommonTokenStream lexer parser QueryParserWithErrors tokens return parser
def _time_to_seconds_past_midnight time_expr if time_expr is None return Noneif time_expr.count ' ' 1 time_expr + ' 00' hour minute second [int p 10 for p in time_expr.split ' ' ]return hour * 60 * 60 + minute * 60 + second
def postmap_available already_emitted_warning [] POSTMAP_PATH '/usr/sbin/postmap'if not os.path.exists POSTMAP_PATH if already_emitted_warning passelse already_emitted_warning.append True logger.warn 'postmapbinarynotfoundat{0}.LookinADVANCED_INSTALLATIONforthesectionaboutpostfixformoreinformation.'.format POSTMAP_PATH return Falsereturn True
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def write_pack_header f num_objects f.write 'PACK' f.write struct.pack '>L' 2 f.write struct.pack '>L' num_objects
def sort_by_pval lines ind def _nan_safe_sort line 'Sortlinesbasedonpvalsandforcenanstohaveinfpval.'val float line.split ' DCTB ' [ind] if not isnan val return valelse return infreturn [lines[0]] + sorted lines[1 ] key _nan_safe_sort
def mbasename s base os.path.basename s if base.endswith '.py' base base[ -3 ]if base in set ['base' '__init__'] base os.path.basename os.path.dirname s + '.' + base return base
def bool_false_check value if value.lower in _bool_false value ''return value
def norm_weight nin nout None scale 0.01 ortho True if nout is None nout ninif nout nin and ortho W ortho_weight nin else W scale * numpy.random.randn nin nout return W.astype 'float32'
def checkerboard return load 'chessboard_GRAY.png'
def get_file_list data_dir file_ext file_ext file_ext if isinstance file_ext list else [file_ext] file_names [os.path.join data_dir fn for fn in os.listdir data_dir if any fn.endswith ext for ext in file_ext ]return file_names
def _PutCryptKeyset io_loop secret _GetSecretsManager .PutSecret secret json.dumps secrets.CreateCryptKeyset secret io_loop.stop
def create_vpnservice subnet router name admin_state_up True profile None conn _auth profile return conn.create_vpnservice subnet router name admin_state_up
def LocalTime t time.gmtime year str t.tm_year [ -1 ]month str t.tm_mon if len month 1 month '0' + month return year + month
def _get_container_infos container status base_status.copy client _get_client try container_info client.inspect_container container if container_info _valid status id_ container_info['Id'] out container_info except Exception passif not status['id'] raise CommandExecutionError 'Container_id{0}couldnotberesolvedtoanexistingcontainer'.format container if 'id' not in status['out'] and 'Id' in status['out'] status['out']['id'] status['out']['Id']return status['out']
def sample_from_pvect pvect onehot_sample rng.multinomial n 1 pvals pvect sample onehot_sample.argmax return sample
def _dashCapitalize name return '-'.join [word.capitalize for word in name.split '-' ]
def rebuild s return construct deconstruct s
def get_vswitch_for_vlan_interface session vlan_interface cluster None host_mor vm_util.get_host_ref session cluster vswitches_ret session._call_method vim_util 'get_dynamic_property' host_mor 'HostSystem' 'config.network.vswitch' if not vswitches_ret returnvswitches vswitches_ret.HostVirtualSwitchfor elem in vswitches try for nic_elem in elem.pnic if str nic_elem .split '-' [ -1 ].find vlan_interface ! -1 return elem.nameexcept AttributeError pass
def dmp_abs f u K if not u return dup_abs f K v u - 1 return [dmp_abs cf v K for cf in f]
def test_cleanup_after_egg_info_exception script data result script.pip 'install' '-f' data.find_links '--no-index' 'brokenegginfo 0.1' expect_error True build script.venv_path / 'build' assert not exists build 'build/dirstillexists %s' % result.stdout script.assert_no_temp
def prepare_data seqs labels maxlen None lengths [len s for s in seqs]if maxlen is not None new_seqs []new_labels []new_lengths []for l s y in zip lengths seqs labels if l < maxlen new_seqs.append s new_labels.append y new_lengths.append l lengths new_lengthslabels new_labelsseqs new_seqsif len lengths < 1 return None None None n_samples len seqs maxlen numpy.max lengths x numpy.zeros maxlen n_samples .astype 'int64' x_mask numpy.zeros maxlen n_samples .astype tf.float32 for idx s in enumerate seqs x[ lengths[idx] idx] sx_mask[ lengths[idx] idx] 1.0return x x_mask labels
def test_iradon_angles size 100image np.tri size + np.tri size [ -1 ] nb_angles 200theta np.linspace 0 180 nb_angles endpoint False radon_image_200 radon image theta theta circle False reconstructed iradon radon_image_200 circle False delta_200 np.mean abs _rescale_intensity image - _rescale_intensity reconstructed assert delta_200 < 0.03 nb_angles 80radon_image_80 radon image theta theta circle False s radon_image_80.sum axis 0 assert np.allclose s s[0] rtol 0.01 reconstructed iradon radon_image_80 circle False delta_80 np.mean abs image / np.max image - reconstructed / np.max reconstructed assert delta_80 > delta_200
def list_option s return ListValueComponent.create s
def get_collection_titles_and_categories collection_ids collection_list [ get_collection_from_model e if e else None for e in collection_models.CollectionModel.get_multi collection_ids ]result {}for collection in collection_list if collection is None logging.error 'Couldnotfindcollectioncorrespondingtoid' else result[collection.id] {'title' collection.title 'category' collection.category}return result
@task rate_limit '50/m' def update_denorm *pairs **kw log.info '[%s@%s]Updatingreviewdenorms.' % len pairs update_denorm.rate_limit using kw.get 'using' for addon user in pairs reviews list Review.objects.valid .using using .filter addon addon user user .order_by 'created' if not reviews continuefor idx review in enumerate reviews review.previous_count idxreview.is_latest Falsereviews[ -1 ].is_latest Truefor review in reviews review.save
def regex_filter_in e routes THREAD_LOCAL.routesquery e.get 'QUERY_STRING' None e['WEB2PY_ORIGINAL_URI'] e['PATH_INFO'] + query and '?' + query or '' if routes.routes_in path regex_uri e routes.routes_in 'routes_in' e['PATH_INFO'] rmatch regex_redirect.match path if rmatch raise HTTP int rmatch.group 1 location rmatch.group 2 items path.split '?' 1 e['PATH_INFO'] items[0]if len items > 1 if query query items[1] + '&' + query else query items[1]e['QUERY_STRING'] querye['REQUEST_URI'] e['PATH_INFO'] + query and '?' + query or '' return e
def locscale_grad y loc scale dlldy *args yst y - loc / scale dlldloc - dlldy yst *args / scale dlldscale -1.0 / scale - dlldy yst *args * y - loc / scale ** 2 return dlldloc dlldscale
def basic_check_run_complete_f f filepaths [l.strip for l in f]for fp in filepaths if not exists fp return Falsereturn True
def cache_security_group_exists name region None key None keyid None profile None return bool describe_cache_security_groups name name region region key key keyid keyid profile profile
def zcard key host None port None db None password None server _connect host port db password return server.zcard key
def write_table_fits input output overwrite False table_hdu table_to_hdu input if isinstance output string_types and os.path.exists output if overwrite os.remove output else raise IOError 'Fileexists {0}'.format output table_hdu.writeto output
def __remove_temp_logging_handler if is_logging_configured return__remove_null_logging_handler root_logger logging.getLogger global LOGGING_TEMP_HANDLERfor handler in root_logger.handlers if handler is LOGGING_TEMP_HANDLER root_logger.removeHandler LOGGING_TEMP_HANDLER LOGGING_TEMP_HANDLER Nonebreakif sys.version_info > 2 7 logging.captureWarnings True
def _default_callback_zip src_path fi nfiles sys.stdout.write 'Addingtozip %dof%d %s\n' % fi + 1 nfiles src_path
def validate_mapped_group_ids group_ids mapping_id identity_api for group_id in group_ids try identity_api.get_group group_id except exception.GroupNotFound raise exception.MappedGroupNotFound group_id group_id mapping_id mapping_id
def update_port token public_url port_id mac_address calico_network headers {'Content-Type' 'application/json' 'X-Auth-Token' token}payload {'port' {'allowed_address_pairs' [{'ip_address' calico_network 'mac_address' mac_address}]}}auth_url public_url + 'v2.0/ports/' + port_id r requests.put auth_url headers headers data json.dumps payload parsed_json json.loads r.text if r.status_code ! 200 or 'NeutronError' in parsed_json sys.stderr.write 'ERROR Unabletoupdateport %s\n' % parsed_json['NeutronError'] exit 1 else return r.status_code
def clone_rtcpath_update_rt_as path new_rt_as assert path and new_rt_as if not path or path.route_family ! RF_RTC_UC raise ValueError 'ExpectedRT_NLRIpath' old_nlri path.nlrinew_rt_nlri RouteTargetMembershipNLRI new_rt_as old_nlri.route_target return RtcPath path.source new_rt_nlri path.source_version_num pattrs path.pathattr_map nexthop path.nexthop is_withdraw path.is_withdraw
def isDirectorySetting return settings.getReadRepository PolyfileRepository .directorySetting.value
def _decode_cert_issuer backend ext data_ptr_ptr backend._ffi.new 'constunsignedchar**' value backend._lib.X509_EXTENSION_get_data ext data_ptr_ptr[0] value.datagns backend._lib.d2i_GENERAL_NAMES backend._ffi.NULL data_ptr_ptr value.length if gns backend._ffi.NULL backend._consume_errors raise ValueError "The{0}extensioniscorruptedandcan'tbeparsed".format CRLEntryExtensionOID.CERTIFICATE_ISSUER gns backend._ffi.gc gns backend._lib.GENERAL_NAMES_free return x509.CertificateIssuer _decode_general_names backend gns
def get_ping_payload_size mtu ip_version if not mtu return Noneif ip_version 4 ip_header 20icmp_header 8else ip_header 40icmp_header 4res mtu - ip_header - icmp_header if res < 0 raise lib_exc.BadRequest message 'MTU % mtu distoolowforIPv% ip_version d' % {'mtu' mtu 'ip_version' ip_version} return res
def set_transient widget master relx 0.5 rely 0.3 expose 1 widget.withdraw widget.transient master widget.update_idletasks if master.winfo_ismapped m_width master.winfo_width m_height master.winfo_height m_x master.winfo_rootx m_y master.winfo_rooty else m_width master.winfo_screenwidth m_height master.winfo_screenheight m_x m_y 0w_width widget.winfo_reqwidth w_height widget.winfo_reqheight x m_x + m_width - w_width * relx y m_y + m_height - w_height * rely widget.geometry '+%d+%d' % x y if expose widget.deiconify return widget
def normals vertices indices vertices indices mapping compact vertices indices T vertices[indices]N np.cross T[ 1] - T[ 0] T[ 2] - T[ 0] L np.sqrt np.sum N * N axis 1 L[ L 0 ] 1.0N / L[ np.newaxis]normals np.zeros_like vertices normals[indices[ 0]] + Nnormals[indices[ 1]] + Nnormals[indices[ 2]] + NL np.sqrt np.sum normals * normals axis 1 L[ L 0 ] 1.0normals / L[ np.newaxis]return normals[mapping]
def real_user_or_none user assert user is None or user.is_anonymous or isinstance user get_user_model return user if user and not user.is_anonymous else None
def gelman_rubin mtrace if mtrace.nchains < 2 raise ValueError 'Gelman-Rubindiagnosticrequiresmultiplechainsofthesamelength.' Rhat {}for var in mtrace.varnames x np.array mtrace.get_values var combine False num_samples x.shape[1]B num_samples * np.var np.mean x axis 1 axis 0 ddof 1 W np.mean np.var x axis 1 ddof 1 axis 0 Vhat W * num_samples - 1 / num_samples + B / num_samples Rhat[var] np.sqrt Vhat / W return Rhat
def store_mapping mapping outdir prefix fh open outdir + '/' + prefix + '_mapping.txt' 'w' for key valuelist in mapping.iteritems fh.write '%s ' % key for v in valuelist fh.write ' DCTB %s' % v fh.write '\n' fh.close
def loss_fun logits labels labels tf.cast labels tf.int64 cross_entropy tf.nn.sparse_softmax_cross_entropy_with_logits logits logits labels labels name 'cross_entropy_per_example' cross_entropy_mean tf.reduce_mean cross_entropy name 'cross_entropy' tf.add_to_collection 'losses' cross_entropy_mean return tf.add_n tf.get_collection 'losses' name 'total_loss'
def _missing_warn warnings.warn 'Oneoftheclustersisempty.Re-runkmeanwithadifferentinitialization.'
def list_accounts status result _query action 'accounts' command 'current' return result
def should_move move_opt None return _bool_fallback move_opt config['import']['move'].get bool or config['import']['copy'].get bool
def _check_estimator estimator if not hasattr estimator 'decision_function' and not hasattr estimator 'predict_proba' raise ValueError 'Thebaseestimatorshouldimplementdecision_functionorpredict_proba!'
def _dont_fail_on_exist error if isinstance error AzureConflictHttpError return Falseelse raise error
def short_cycle_task *args **kwargs def decorator f f._short_cycle_task Truef._ticks_between_runs kwargs.pop 'ticks_between_runs' 0 return fif kwargs return decoratorelse return decorator args[0]
def method_overridden method_name klass instance method getattr klass method_name default_method getattr method u'__func__' method return default_method is not getattr instance method_name .__func__
def MetaInformation title authors _ 'Unknown' from calibre.ebooks.metadata.book.base import Metadatami Noneif hasattr title 'title' and hasattr title 'authors' mi titletitle mi.titleauthors mi.authorsreturn Metadata title authors other mi
def random_ip network random.choice ['192.0.2' '198.51.100' '203.0.113'] ip_address '{}.{}'.format network random.randrange 256 return ip_address
def get_view_name view_cls suffix None name view_cls.__name__name formatting.remove_trailing_string name u'View' name formatting.remove_trailing_string name u'ViewSet' name formatting.camelcase_to_spaces name if suffix name + u'' + suffix return name
def generate_private_uuid node wname private_uuid str uuid.uuid1 wiki_key to_mongo_key wname node.wiki_private_uuids[wiki_key] private_uuidnode.save return private_uuid
def _minimal_polynomial_sq p n x from sympy.simplify.simplify import _is_sum_surdsp sympify p n sympify n r _is_sum_surds p if not n.is_Integer or not n > 0 or not _is_sum_surds p return Nonepn p ** Rational 1 n p - xwhile 1 p1 _separate_sq p if p1 is p p p1.subs {x x ** n } breakelse p p1if n 1 p1 Poly p if p.coeff x ** p1.degree x < 0 p - p p p.primitive [1]return pfactors factor_list p [1]result _choose_factor factors x pn return result
def connectionist_temporal_classification x t blank_symbol input_length None label_length None if not isinstance x collections.Sequence raise TypeError 'xmustbealistofVariables' if not isinstance blank_symbol int raise TypeError 'blank_symbolmustbenon-negativeinteger.' assert blank_symbol > 0 assert blank_symbol < x[0].shape[1] assert len x[0].shape 2 if input_length is None xp cuda.get_array_module x[0].data input_length chainer.Variable xp.full len x[0].data len x dtype numpy.int32 volatile 'auto' label_length chainer.Variable xp.full len t.data len t.data[0] dtype numpy.int32 volatile 'auto' return ConnectionistTemporalClassification blank_symbol input_length label_length t *x
def test_api_invite_existing_user client outbox user f.UserFactory.create role f.RoleFactory.create f.MembershipFactory project role.project user role.project.owner is_admin True client.login role.project.owner url reverse 'memberships-list' data {'role' role.pk 'project' role.project.pk 'username' user.email}response client.json.post url json.dumps data assert response.status_code 201 response.dataassert len outbox 1 assert user.memberships.count 1 message outbox[0]assert message.to [user.email] assert 'Addedtotheproject' in message.subject
def deleteDirectory directory subfolderName subDirectory os.path.join directory subfolderName if os.path.isdir subDirectory shutil.rmtree subDirectory
def convert_kernel kernel dim_ordering None if dim_ordering is None dim_ordering K.image_dim_ordering if not 4 < kernel.ndim < 5 raise ValueError 'Invalidkernelshape ' kernel.shape slices [slice None None -1 for _ in range kernel.ndim ]no_flip slice None None slice None None if dim_ordering 'th' slices[ 2] no_flipelif dim_ordering 'tf' slices[ -2 ] no_flipelse raise ValueError 'Invaliddim_ordering ' dim_ordering return np.copy kernel[slices]
def __random_string size 6 return 'RS-' + ''.join random.choice string.ascii_uppercase + string.digits for x in range size
def check_exists manager names type if type TABLE_TYPE info_table 'TABLES'elif type VIEW_TYPE info_table 'VIEWS'else raise Exception 'typeparametermustbeeitherTABLE_TYPEorVIEW_TYPE' query 'SELECTtable_nameFROMinformation_schema.%sWHEREtable_schema %%s' % info_table rows manager.execute query manager.get_db_name existing_names [row[0] for row in rows]for name in names if name not in existing_names raise NameMissingException '%smissingfromdatabase stopping' % name
def generateTinyURL URL target 'http //tinyurl.com/api-create.php?url ' + URL response urllib2.urlopen target return response.read
def term_width fallback config['ui']['terminal_width'].get int try import fcntlimport termiosexcept ImportError return fallbacktry buf fcntl.ioctl 0 termios.TIOCGWINSZ '' * 4 except IOError return fallbacktry height width struct.unpack 'hh' buf except struct.error return fallbackreturn width
def revcmap data data_r {}for key val in six.iteritems data if callable val valnew _reverser val else valnew [ 1.0 - x y1 y0 for x y0 y1 in reversed val ]data_r[key] valnewreturn data_r
def prune_vocab vocab min_reduce trim_rule None result 0old_len len vocab for w in list vocab if not keep_vocab_item w vocab[w] min_reduce trim_rule result + vocab[w]del vocab[w]logger.info 'prunedout%itokenswithcount< %i before%i after%i ' old_len - len vocab min_reduce old_len len vocab return result
@blueprint.route '/resources/<resource>/meters' def list_meters_by_resource resource rq flask.requestmeters rq.storage_conn.get_meters resource resource project acl.get_limited_to_project rq.headers metaquery _get_metaquery rq.args return flask.jsonify meters [m.as_dict for m in meters]
def dateify datestring return denumify datestring 'XXXX-XX-XXXX XX XX'
def has_job name return name in _jobs
def CreateBiddingStrategy client bidding_strategy_service client.GetService 'BiddingStrategyService' version 'v201609' shared_bidding_strategy {'name' 'MaximizeClicks%s' % uuid.uuid4 'biddingScheme' {'xsi_type' 'TargetSpendBiddingScheme' 'bidCeiling' {'microAmount' '2000000'}}}operation {'operator' 'ADD' 'operand' shared_bidding_strategy}response bidding_strategy_service.mutate [operation] new_bidding_strategy response['value'][0]print "Sharedbiddingstrategywithname'%s'andID'%s'oftype'%s'wascreated." % new_bidding_strategy['name'] new_bidding_strategy['id'] new_bidding_strategy['biddingScheme']['BiddingScheme.Type'] return new_bidding_strategy
def test_should_report_multiple_warnings_negative expected [ 'Variableaassignedbeforeglobaldeclaration' 'globala' -1 Warning 'Variablebassignedbeforeglobaldeclaration' 'globalb' -1 Warning ]code 'deffoo \na 2\nglobala\n\ndefbar \nb 2\nglobalb'AssertError AssertionError AreEqual expected compile_file code
def relation *arg **kw return relationship *arg **kw
def gallery request media_type 'image' if media_type 'image' media_qs Image.objects.filter locale request.LANGUAGE_CODE elif media_type 'video' media_qs Video.objects.filter locale request.LANGUAGE_CODE else raise Http404media paginate request media_qs per_page ITEMS_PER_PAGE drafts _get_drafts request.user image drafts['image'][0] if drafts['image'] else None image_form _init_media_form ImageForm request image if request.method 'POST' image_form.is_valid return render request 'gallery/gallery.html' {'media' media 'media_type' media_type 'image_form' image_form 'submitted' request.method 'POST' }
def connected_caveman_graph l k G nx.caveman_graph l k G.name 'connected_caveman_graph %s %s ' % l k for start in range 0 l * k k G.remove_edge start start + 1 G.add_edge start start - 1 % l * k return G
def triu m k 0 return m * 1 - tri m.shape[0] m.shape[1] k k - 1 dtype m.dtype
def key_pair_get_all_by_user context user_id return IMPL.key_pair_get_all_by_user context user_id
def test_suggested_multiple_column_names_with_dot completer complete_event text u'SELECTusers.id users.fromusersu'position len u'SELECTusers.id users.' result set completer.get_completions Document text text cursor_position position complete_event assert set result set testdata.columns u'users'
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def response_httprepr response s 'HTTP/1.1%d%s\r\n' % response.status RESPONSES.get response.status '' if response.headers s + response.headers.to_string + '\r\n' s + '\r\n's + response.bodyreturn s
@register.tag u'filter' def do_filter parser token _ rest token.contents.split None 1 filter_expr parser.compile_filter u'var|%s' % rest for func unused in filter_expr.filters if getattr func u'_decorated_function' func .__name__ in u'escape' u'safe' raise TemplateSyntaxError u'"filter%s"isnotpermitted.Usethe"autoescape"taginstead.' % func.__name__ nodelist parser.parse u'endfilter' parser.delete_first_token return FilterNode filter_expr nodelist
def _validate_inputs image markers mask if not isinstance markers np.ndarray list tuple markers regular_seeds image.shape markers elif markers.shape ! image.shape raise ValueError 'Markers shape%s musthavesameshapeasimage shape%s ' % markers.ndim image.ndim if mask is not None and mask.shape ! image.shape raise ValueError 'maskmusthavesameshapeasimage' if mask is None mask np.ones image.shape bool return image.astype np.float64 markers.astype np.int32 mask.astype np.int8
def get_node_info nodes [{NodeInfoTags.HOST get_br_service_url appscale_info.get_db_master_ip NodeInfoTags.ROLE 'db_master' NodeInfoTags.INDEX None}]index 0for node in appscale_info.get_db_slave_ips host get_br_service_url node if host not in nodes[0].values nodes.append {NodeInfoTags.HOST host NodeInfoTags.ROLE 'db_slave' NodeInfoTags.INDEX index} index + 1index 0for node in appscale_info.get_zk_node_ips nodes.append {NodeInfoTags.HOST get_br_service_url node NodeInfoTags.ROLE 'zk' NodeInfoTags.INDEX index} index + 1return nodes
def hilbert x _cache _cache tmp asarray x if iscomplexobj tmp return hilbert tmp.real + 1j * hilbert tmp.imag n len x omega _cache.get n if omega is None if len _cache > 20 while _cache _cache.popitem def kernel k if k > 0 return 1.0elif k < 0 return -1.0 return 0.0omega convolve.init_convolution_kernel n kernel d 1 _cache[n] omegaoverwrite_x _datacopied tmp x return convolve.convolve tmp omega swap_real_imag 1 overwrite_x overwrite_x
def default_user_agent _implementation platform.python_implementation if _implementation 'CPython' _implementation_version platform.python_version elif _implementation 'PyPy' _implementation_version '%s.%s.%s' % sys.pypy_version_info.major sys.pypy_version_info.minor sys.pypy_version_info.micro if sys.pypy_version_info.releaselevel ! 'final' _implementation_version ''.join [_implementation_version sys.pypy_version_info.releaselevel] elif _implementation 'Jython' _implementation_version platform.python_version elif _implementation 'IronPython' _implementation_version platform.python_version else _implementation_version 'Unknown'return ''.join [ 'python-requests/%s' % __version__ '%s/%s' % _implementation _implementation_version '%s/%s' % platform.system platform.release ]
def file_ attrs None where None return _osquery_cmd table 'file' attrs attrs where where
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def compute_node_search_by_hypervisor context hypervisor_match return IMPL.compute_node_search_by_hypervisor context hypervisor_match
def test_node_joinsource tmpdir os.chdir str tmpdir wf pe.Workflow name u'test' inputspec pe.Node IdentityInterface fields [u'n'] name u'inputspec' inputspec.iterables [ u'n' [1 2] ]join pe.JoinNode SetInterface joinsource inputspec joinfield u'input1' name u'join' assert join.joinsource inputspec.name u'Thejoinsourceisnotsettothenodename.'
def triangulate vertices n len vertices vertices np.asarray vertices zmean vertices[ 2].mean vertices_2d vertices[ 2]segments np.repeat np.arange n + 1 2 [1 -1 ]segments[ -2 ] n - 1 0 if _TRIANGLE_AVAILABLE vertices_2d triangles _triangulate_cpp vertices_2d segments else vertices_2d triangles _triangulate_python vertices_2d segments vertices np.empty len vertices_2d 3 vertices[ 2] vertices_2dvertices[ 2] zmeanreturn vertices triangles
def _loadLinuxSo try l ctypes.CDLL 'liblabjackusb.so' use_errno True except TypeError l ctypes.CDLL 'liblabjackusb.so' l.LJUSB_Stream.errcheck errcheckl.LJUSB_Read.errcheck errcheckreturn l
def get_admin_index app from django.utils.text import capfirstfrom django.db.models import get_modelsoutput []app_models get_models app app_label app_models[0]._meta.app_labeloutput.append '{%%ifperms.%s%%}' % app_label output.append '<divclass "module"><h2>%s</h2><table>' % app_label.title for model in app_models if model._meta.admin output.append MODULE_TEMPLATE % {'app' app_label 'mod' model._meta.module_name 'name' capfirst model._meta.verbose_name_plural 'addperm' model._meta.get_add_permission 'changeperm' model._meta.get_change_permission } output.append '</table></div>' output.append '{%endif%}' return output
def dumps obj key None salt u'django.core.signing' serializer JSONSerializer compress False data serializer .dumps obj is_compressed Falseif compress compressed zlib.compress data if len compressed < len data - 1 data compressedis_compressed Truebase64d b64_encode data if is_compressed base64d '.' + base64d return TimestampSigner key salt salt .sign base64d
def start_replay replay_file_name **kwargs settings ReplaySettings replay_file_name **kwargs _patch_httplib settings _patch_requests settings _patch_urllib3 settings
def register_variable name value __build_rules[name] value
def test_routing_class_based_method_view_with_sub_routing @hug.object.http_methods class EndPoint object def get self return 'hithere!'@hug.object.urls '/home/' def post self return 'bye'assert hug.test.get api 'endpoint' .data 'hithere!' assert hug.test.post api 'home' .data 'bye'
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def alias_command command_table existing_name new_name current command_table[existing_name]_copy_argument command_table existing_name new_name current._UNDOCUMENTED True
def generate_credits component start_date end_date result []for translation in component.translation_set.all authors Change.objects.authors_list translation start_date end_date if not authors continueresult.append {translation.language.name sorted set authors } return result
def setData data global PORTif PORT is None raise RuntimeError 'PortaddressmustbesetusingsetPortAddress' PORT.setData data
def has_instructor_access_for_class user course_id course get_course_overview_with_access user 'staff' course_id return bool has_access user 'staff' course
def test_rgb_to_hsl_part_1 pass
def autolabel rects for rect in rects height rect.get_height ax.text rect.get_x + rect.get_width / 2.0 1.05 * height '%d' % int height ha 'center' va 'bottom'
def color_groups groups colors data_color_order group_num -1 for g in natsort groups if g not in colors group_num + 1if group_num len data_color_order group_num 0colors[g] data_color_order[group_num]
def check_dict ref_dict tst_dict def to_list x if isinstance x tuple x list x if isinstance x list for i xel in enumerate x x[i] to_list xel return xfailed_dict {}for key value in list ref_dict.items newval to_list tst_dict[key] if newval ! value failed_dict[key] value newval return failed_dict
def deny ip return __apf_cmd '-d{0}'.format ip
def _run_suite suite if verbose runner unittest.TextTestRunner sys.stdout verbosity 2 else runner BasicTestRunner result runner.run suite if not result.wasSuccessful if len result.errors 1 and not result.failures err result.errors[0][1]elif len result.failures 1 and not result.errors err result.failures[0][1]else err 'errorsoccurred;runinverbosemodefordetails'raise TestFailed err
def MakeRenewedResponse reference json.loads kVerifyResponseRenewedExpired return json.dumps {'status' 0 'receipt' reference['receipt'] 'latest_receipt' base64.b64encode 'fakeencodedreceipt' 'latest_expired_receipt_info' reference['latest_expired_receipt_info']}
def get_exit_status http_status follow False if 300 < http_status < 399 and not follow return ExitStatus.ERROR_HTTP_3XXelif 400 < http_status < 499 return ExitStatus.ERROR_HTTP_4XXelif 500 < http_status < 599 return ExitStatus.ERROR_HTTP_5XXelse return ExitStatus.OK
def _get_metadata_from_filename_by_regex filename metadata_regexp unslugify_titles lang match re.match metadata_regexp filename meta {}if match for key value in match.groupdict .items k key.lower .strip if k u'title' and unslugify_titles meta[k] unslugify value lang discard_numbers False else meta[k] valuereturn meta
def list_ profile 'splunk' client _get_splunk profile searches [x['name'] for x in client.saved_searches]return searches
def match_rules rules app action for rule in rules.split ' ' rule_app rule_action rule.split ' ' if rule_app '*' or rule_app app if rule_action '*' or rule_action action or action '%' return Truereturn False
@command 'pl\\s+%s' % PL def plist parturl if parturl in g.pafy_pls ytpl plitems g.pafy_pls[parturl]else util.dbg '%sFetchingplaylistusingpafy%s' c.y c.w ytpl pafy.get_playlist2 parturl plitems util.IterSlicer ytpl g.pafy_pls[parturl] ytpl plitems def pl_seg s e return [Video i.videoid i.title i.length for i in plitems[s e]]msg 'ShowingYouTubeplaylist%s' % c.y + ytpl.title + c.w loadmsg 'RetrievingYouTubeplaylist'paginatesongs pl_seg length len ytpl msg msg loadmsg loadmsg
def unstyle text return strip_ansi text
def core_status host None core_name None ret _get_return_dict if not _check_for_cores err ['solr.reload_corecanonlybecalledby"multi-core"minions']return ret.update {'success' False 'errors' err} if _get_none_or_value core_name is None and _check_for_cores success Truefor name in __opts__['solr.cores'] resp reload_core host name if not resp['success'] success Falsedata {name {'data' resp['data']}}ret _update_return_dict ret success data resp['errors'] resp['warnings'] return retextra ['action STATUS' 'core {0}'.format core_name ]url _format_url 'admin/cores' host host core_name None extra extra return _http_request url
def p_declaration_list_2 t pass
def windows_get_fileid path import win32filefrom pywintypes import errorif isbytestring path path path.decode filesystem_encoding try h win32file.CreateFileW path 0 0 None win32file.OPEN_EXISTING win32file.FILE_FLAG_BACKUP_SEMANTICS 0 try data win32file.GetFileInformationByHandle h finally win32file.CloseHandle h except error EnvironmentError return Nonereturn data[4] data[8] data[9]
def _numa_cell_supports_pagesize_request host_cell inst_cell avail_pagesize [page.size_kb for page in host_cell.mempages]avail_pagesize.sort reverse True def verify_pagesizes host_cell inst_cell avail_pagesize inst_cell_mem inst_cell.memory * units.Ki for pagesize in avail_pagesize if host_cell.can_fit_hugepages pagesize inst_cell_mem return pagesizeif inst_cell.pagesize MEMPAGES_SMALL return verify_pagesizes host_cell inst_cell avail_pagesize[ -1 ] elif inst_cell.pagesize MEMPAGES_LARGE return verify_pagesizes host_cell inst_cell avail_pagesize[ -1 ] elif inst_cell.pagesize MEMPAGES_ANY return verify_pagesizes host_cell inst_cell avail_pagesize else return verify_pagesizes host_cell inst_cell [inst_cell.pagesize]
def most_popular_word_reducer user words_and_counts word_counts Counter for word count in words_and_counts word_counts[word] + count word count word_counts.most_common 1 [0] yield user word count
def __csf_cmd cmd csf_cmd '{0}{1}'.format salt.utils.which 'csf' cmd out __salt__['cmd.run_all'] csf_cmd if out['retcode'] ! 0 if not out['stderr'] ret out['stdout']else ret out['stderr']raise CommandExecutionError 'csffailed {0}'.format ret else ret out['stdout']return ret
def is_present name output Popen ['locale' '-a'] stdout PIPE .communicate [0]output to_native output return any fix_case name fix_case line for line in output.splitlines
def get_node_by_name_and_ip module lb_driver name ip nodes lb_driver.ex_get_nodes found_nodes []if not is_ipv4_addr ip module.fail_json msg "Node'%s'ipisnotavalidIPv4address" % ip found_nodes [node for node in nodes if node.name name and node.ip ip ]if len found_nodes 0 return Noneelif len found_nodes 1 return found_nodes[0]else module.fail_json msg "Morethanonenodeofname'%s'found." % name
def _pkl_filepath *args **kwargs py3_suffix kwargs.get 'py3_suffix' '_py3' basename ext splitext args[ -1 ] if sys.version_info[0] > 3 basename + py3_suffixnew_args args[ -1 ] + basename + ext return join *new_args
def default_prefixer request http.HttpRequest request.META['SCRIPT_NAME'] ''prefixer amo.urlresolvers.Prefixer request prefixer.app settings.DEFAULT_APPprefixer.locale settings.LANGUAGE_CODEamo.urlresolvers.set_url_prefix prefixer
def generate_random_id return 'id' + generate_random_string 6
def test_roberts_diagonal1 image np.tri 10 10 0 expected ~ np.tri 10 10 -1 .astype bool | np.tri 10 10 -2 .astype bool .transpose expected _mask_filter_result expected None result filters.roberts image .astype bool assert_close result expected
def render_message tpl_name **context tpl _tpl_lookup.get_template tpl_name return tpl.render **context
@pytest.mark.usefixtures 'clean_system' 'remove_additional_dirs' def test_cookiecutter_input_extra_context monkeypatch monkeypatch.setattr 'cookiecutter.prompt.read_user_variable' lambda var default default main.cookiecutter 'tests/fake-repo-pre' no_input False extra_context {'repo_name' 'fake-project-input-extra'} assert os.path.isdir 'fake-project-input-extra'
def list_master saltenv 'base' prefix '' return __context__['fileclient'].file_list saltenv prefix
def org_root_organisation_name organisation_id if not organisation_id return Nonedb current.dbs3db current.s3dbotable s3db.org_organisationbtable s3db.org_organisation.with_alias 'org_branch_organisation' ltable s3db.org_organisation_branchquery btable.id organisation_id join ltable.deleted ! True & btable.deleted ! True & otable.deleted ! True & btable.id ltable.branch_id & otable.id ltable.organisation_id row db query & join .select otable.id limitby 0 1 .first if row is not None return org_root_organisation_name row.id else row db otable.id organisation_id .select otable.name limitby 0 1 .first if row return row.name
def get_quantifier ch input_iter if ch in '*?+' try ch2 escaped input_iter.next except StopIteration ch2 Noneif ch2 '?' ch2 Noneif ch '+' return 1 ch2 return 0 ch2 quant []while ch ! '}' ch escaped input_iter.next quant.append ch quant quant[ -1 ]values ''.join quant .split ' ' try ch escaped input_iter.next except StopIteration ch Noneif ch '?' ch Nonereturn int values[0] ch
def parse_url_overrides kw anchor ''qs ''app_url Nonehost Nonescheme Noneport Noneif '_query' in kw query kw.pop '_query' if isinstance query string_types qs '?' + url_quote query QUERY_SAFE elif query qs '?' + urlencode query doseq True if '_anchor' in kw anchor kw.pop '_anchor' anchor url_quote anchor ANCHOR_SAFE anchor '#' + anchor if '_app_url' in kw app_url kw.pop '_app_url' if '_host' in kw host kw.pop '_host' if '_scheme' in kw scheme kw.pop '_scheme' if '_port' in kw port kw.pop '_port' return app_url scheme host port qs anchor
@memoize 'missing_traffic' time 60 * 10 def get_missing_traffic start end time_points get_time_points 'hour' start end q Session.query SitewidePageviews.date .filter SitewidePageviews.interval 'hour' .filter SitewidePageviews.date.in_ time_points found [t for t in q]return [t for t in time_points if t not in found ]
def valid_ua_signature request signed_headers 'User-Agent' 'Client-Vendor-ID' signature_header SIGNATURE_UA_HEADER payload '|'.join '{} {}'.format h request.headers.get h or '' for h in signed_headers return valid_signature payload request.headers.get signature_header field 'ua'
def log_handlers opts ret LazyLoader _module_dirs opts 'log_handlers' int_type 'handlers' base_path os.path.join SALT_BASE_PATH 'log' opts tag 'log_handlers' return FilterDictWrapper ret '.setup_handlers'
@receiver pre_delete sender CohortMembership def remove_user_from_cohort sender instance **kwargs instance.course_user_group.users.remove instance.user instance.course_user_group.save
def schema_concat exprs new_fields []for c in exprs schema c.schema[0]if isinstance schema Record new_fields.extend schema.fields elif isinstance schema Unit Option new_fields.append c._name schema else raise TypeError 'AllschemasmusthaveRecordorUnitshape.\nGot%s' % schema return dshape Record new_fields
def libvlc_media_player_set_chapter p_mi i_chapter f _Cfunctions.get 'libvlc_media_player_set_chapter' None or _Cfunction 'libvlc_media_player_set_chapter' 1 1 None None MediaPlayer ctypes.c_int return f p_mi i_chapter
def _dst x type n None axis -1 overwrite_x False normalize None x0 n copy_made __fix_shape x n axis 'DST' if type 1 and n < 2 raise ValueError 'DST-Iisnotdefinedforsize<2' overwrite_x overwrite_x or copy_made nm _get_norm_mode normalize if np.iscomplexobj x0 return _raw_dst x0.real type n axis nm overwrite_x + 1j * _raw_dst x0.imag type n axis nm overwrite_x else return _raw_dst x0 type n axis nm overwrite_x
def render_items_vert items if isinstance items dict items items.items return ' '.join '<b>{}</b> {}'.format key value for key value in items if value is not None and value is not False
def _is_cluster_done cluster return cluster.status.state 'TERMINATING' or hasattr cluster.status.timeline 'enddatetime'
def enable_password_auth sshd_config '/etc/ssh/sshd_config' _update_ssh_setting sshd_config 'PasswordAuthentication' 'yes'
def vol_activity_hours_month row try thisdate row['vol_activity_hours.date']except AttributeError return current.messages['NONE']if not thisdate return current.messages['NONE']month thisdate.monthyear thisdate.yearfirst datetime.date year month 1 return first.strftime '%y-%m'
def isinstancemethod cls obj return _isinstancemethod cls obj
def _handle_convert in_handle in_format out_handle out_format alphabet None try f _converter[ in_format out_format ]except KeyError f Noneif f return f in_handle out_handle alphabet else records SeqIO.parse in_handle in_format alphabet return SeqIO.write records out_handle out_format
def run_shell_job job log 'Runningshelljob.\n' os.chdir job.expt_dir cmd './%s%s' % job.name job_file_for job log "Executingcommand'%s'\n" % cmd sh cmd
@receiver dbsignals.post_save sender Webapp dispatch_uid 'webapp.pre_generate_apk' def pre_generate_apk sender None instance None **kw if kw.get 'raw' returnif not getattr settings 'PRE_GENERATE_APKS' False log.info '[Webapp {a}]APKpre-generationisdisabled.'.format a instance.id returnfrom . import tasksgenerated Falseif instance.status in mkt.WEBAPPS_APPROVED_STATUSES app_devs set d.id for d in instance.device_types if mkt.DEVICE_MOBILE.id in app_devs or mkt.DEVICE_TABLET.id in app_devs tasks.pre_generate_apk.delay instance.id generated Truelog.info '[Webapp {a}]APKpre-generated?{result}'.format a instance.id result 'YES' if generated else 'NO'
def pkcs_emsa_pkcs1_v1_5_encode M emLen h hLen _hashFuncParams[h][0]hFunc _hashFuncParams[h][1]H hFunc M hLeadingDigestInfo _hashFuncParams[h][2]T hLeadingDigestInfo + H tLen len T if emLen < tLen + 11 warning 'pkcs_emsa_pkcs1_v1_5_encode intendedencodedmessagelengthtooshort' return NonePS '\xff' * emLen - tLen - 3 EM '\x00' + '\x01' + PS + '\x00' + T return EM
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def ListTables service project_id tables service.tables .list projectId project_id .execute logging.info json.dumps tables indent 2
def assert_tokens_equal x y if len x ! len y msg u'Thetokenssequenceshavedifferentlengths {0!r}! {1!r}\n'msg + u'#x\n{2}\n\n#y\n{3}'pytest.fail msg.format len x len y pformat x pformat y diffs [ a b for a b in zip x y if not tokens_equal a b ]if len diffs > 0 msg [u'Thetokensequencesdiffer ']for a b in diffs msg + [u'' u'-' + repr a u'+' + repr b ]msg u'\n'.join msg pytest.fail msg return True
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def stack tup axis 0 return concatenate [cupy.expand_dims x axis for x in tup] axis
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def get_path_formats subview None path_formats []subview subview or config['paths'] for query view in subview.items query PF_KEY_QUERIES.get query query path_formats.append query Template view.as_str return path_formats
def educate_dashes_oldschool_inverted s return s.replace '---' '&#8211;' .replace '--' '&#8212;'
def curfft inp norm None s inp.shape[1 ]cond_norm _unitary norm scaling 1if cond_norm 'ortho' scaling T.sqrt s.prod .astype 'float32' return curfft_op inp s / scaling
def convert_time_to_hour_minute hour minute convention if hour is None hour 0if minute is None minute 0if convention is None convention 'am'hour int hour minute int minute if convention 'pm' hour + 12return {'hours' hour 'minutes' minute}
def all return MIGRATIONS.values
def convert_PhoneNumberProperty model prop kwargs return get_TextField kwargs
def leapfrog H q p epsilon n_steps def full_update p q p p + epsilon * H.dlogp q q + epsilon * H.pot.velocity p return p q p p + 0.5 * epsilon * H.dlogp q q + epsilon * H.pot.velocity p if tt.gt n_steps 1 p_seq q_seq _ theano.scan full_update outputs_info [p q] n_steps n_steps - 1 p q p_seq[ -1 ] q_seq[ -1 ] p + 0.5 * epsilon * H.dlogp q return q p
def unstopped tokenstream return t for t in tokenstream if not t.stopped
def OpenDocumentImage doc OpenDocument 'application/vnd.oasis.opendocument.image' doc.image Image doc.body.addElement doc.image return doc
def getTeardropPathByEndStart end radius start xmlElement inclination getInclination end start return getTeardropPath inclination radius xmlElement
def raise_event f @wraps f def decorated *args **kwargs r f *args **kwargs method request.methodif method in 'GET' 'POST' 'PATCH' 'DELETE' 'PUT' event_name 'on_post_' + method resource args[0] if args else None getattr app event_name resource request r if resource getattr app event_name + '_' + resource request r return rreturn decorated
def cov_nearest cov method 'clipped' threshold 1e-15 n_fact 100 return_all False from statsmodels.stats.moment_helpers import cov2corr corr2cov cov_ std_ cov2corr cov return_std True if method 'clipped' corr_ corr_clipped cov_ threshold threshold elif method 'nearest' corr_ corr_nearest cov_ threshold threshold n_fact n_fact cov_ corr2cov corr_ std_ if return_all return cov_ corr_ std_ else return cov_
def _get_format_timedelta64 values nat_rep 'NaT' box False values_int values.astype np.int64 consider_values values_int ! iNaT one_day_nanos 86400 * 1000000000.0 even_days np.logical_and consider_values values_int % one_day_nanos ! 0 .sum 0 all_sub_day np.logical_and consider_values np.abs values_int > one_day_nanos .sum 0 if even_days format 'even_day'elif all_sub_day format 'sub_day'else format 'long'def _formatter x if x is None or lib.checknull x return nat_repif not isinstance x Timedelta x Timedelta x result x._repr_base format format if box result "'{0}'".format result return resultreturn _formatter
def build output worklist force False output_path abspath output source_paths []for f files in worklist source_paths.extend map abspath files update_needed Falseif not os.path.exists output_path if not settings.ASSETS_AUTO_CREATE and not force raise MergeError "'%s'needstobecreated butASSETS_AUTO_CREATEisdisabled" % output else update_needed Trueelif not force update_needed get_updater output_path source_paths if update_needed or force output output_pathtry try for filters files in worklist output merge map abspath files output filters output_path close False finally if hasattr output 'close' output.close except if os.path.exists output_path os.remove output_path raise
def _stc_gen data sfreq tmin combo False vertices [np.arange data.shape[1] np.empty 0 ]for d in data if not combo stc SourceEstimate data d vertices vertices tmin tmin tstep 1 / float sfreq yield stc else arr d[0]stc SourceEstimate data d[1 ] vertices vertices tmin tmin tstep 1 / float sfreq yield arr stc
def get_app_info app_loc if not os.path.isdir app_loc msg 'Notadirectory %s' % app_loc LOG.error msg raise ValueError msg save_cwd os.getcwd os.chdir app_loc try cmdv [common.ENV_PYTHON 'setup.py' '--name' '--version' '--description' '--author']LOG.debug "Running'%s'" % ''.join cmdv popen subprocess.Popen cmdv stdout subprocess.PIPE stderr subprocess.PIPE res popen.wait stdout stderr popen.communicate if res ! 0 LOG.error 'Errorgettingapplicationinfofrom%s \n%s' % app_loc stderr raise OSError stderr LOG.debug 'Commandoutput \n<<<\n%s\n>>>' % stdout return stdout.split '\n' [ 4]finally os.chdir save_cwd
def getFilePaths fileInDirectory '' directoryName os.getcwd if fileInDirectory ! '' directoryName os.path.dirname fileInDirectory absoluteDirectoryPath os.path.abspath directoryName directory os.listdir directoryName filePaths []for fileName in directory filePaths.append os.path.join absoluteDirectoryPath fileName return filePaths
def skill_competencies table s3db.hrm_skillttable s3db.hrm_skill_typertable s3db.hrm_competency_ratingquery table.id request.args[0] & table.skill_type_id ttable.id & rtable.skill_type_id table.skill_type_id records db query .select rtable.id rtable.name orderby ~ rtable.priority response.headers['Content-Type'] 'application/json'return records.json
def test_interacting_iterators class A object def __iter__ cls return clsdef next self return 3class B object def __iter__ cls return A def next self return 2b B AreEqual next b 2
def p_small_stmts p if len p 4 p[0] p[1] + [p[3]] else p[0] [p[1]]
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def load_chromosome chr_name cur_chromosome BasicChromosome.Chromosome chr_name chr_segment_info all_chr_info[chr_name]for seg_info_num in range len chr_segment_info label fill_color scale chr_segment_info[seg_info_num]if seg_info_num 0 cur_segment BasicChromosome.TelomereSegment elif seg_info_num len chr_segment_info - 1 cur_segment BasicChromosome.TelomereSegment 1 else cur_segment BasicChromosome.ChromosomeSegment if label ! '' cur_segment.label labelif fill_color is not None cur_segment.fill_color fill_colorcur_segment.scale scalecur_chromosome.add cur_segment cur_chromosome.scale_num 19return cur_chromosome
def test_pprint_py3_bytes val str 'val' if PY2 else bytes 'val' encoding 'utf-8' blah u'bl\xe4h'.encode 'utf-8' if PY2 else bytes 'bl\xc3\xa4h' encoding 'utf-8' dat np.array [val blah] dtype [ str 'col' 'S10' ] t table.Table dat assert t['col'].pformat ['col' '----' 'val' u'bl\xe4h']
def asciiHexEncode stream try encodedStream stream.encode 'hex' except return -1 'Errorinhexadecimalconversion' return 0 encodedStream
def servejs import gluon.contenttyperesponse.headers['Content-Type'] gluon.contenttype.contenttype '.js' return 'alert "ThisisaJavascriptdocument itisnotsupposedtorun!" ;'
def test_language_russian lang Language 'ru' assert_equals lang.code u'ru' assert_equals lang.name u'Russian' assert_equals lang.native u'\u0420\u0443\u0441\u0441\u043a\u0438\u0439' assert_equals lang.feature u'\u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b' assert_equals lang.scenario u'\u0421\u0446\u0435\u043d\u0430\u0440\u0438\u0439' assert_equals lang.examples u'\u041f\u0440\u0438\u043c\u0435\u0440\u044b|\u0421\u0446\u0435\u043d\u0430\u0440\u0438\u0438' assert_equals lang.scenario_outline u'\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430\u0441\u0446\u0435\u043d\u0430\u0440\u0438\u044f'
def remove_coding text sub_re re.compile u'^#\\s*-\\*-\\s*coding \\s*.*-\\*-$' flags re.MULTILINE return sub_re.sub u'' text
def load_ipython_extension ipython if not ipython.find_line_magic 'sql' ipython.run_line_magic 'load_ext' 'sql' ipython.register_magic_function pgcli_line_magic 'line' 'pgcli'
def lpol2index ar ar np.asarray ar index np.nonzero ar [0]coeffs ar[index]return coeffs index
def custom_generate_access_cookie input_dict flask_request return generate_ip_verify_hash input_dict
def security_group_get context security_group_id columns_to_join None return IMPL.security_group_get context security_group_id columns_to_join
def quit global qdb listener connif qdb sys.settrace None qdb Noneif conn conn.close conn Noneif listener listener.close listener None
def beacon config log.trace 'twilio_txt_msgbeaconstarting' ret []if not all [config['account_sid'] config['auth_token'] config['twilio_number']] return retoutput {}output['texts'] []client TwilioRestClient config['account_sid'] config['auth_token'] messages client.messages.list to config['twilio_number'] log.trace 'Nummessages {0}'.format len messages if len messages < 1 log.trace 'Twiliobeaconhasnotexts' return retfor message in messages item {}item['id'] str message.sid item['body'] str message.body item['from'] str message.from_ item['sent'] str message.date_sent item['images'] []if int message.num_media media client.media message.sid .list if len media for pic in media item['images'].append str pic.uri output['texts'].append item message.delete ret.append output return ret
def getlineno frame return frame.f_lineno
def _GetThisModuleObjectAndName return _GetModuleObjectAndName globals
def write_evokeds fname evoked _write_evokeds fname evoked
def _Renamed tool msvs_name msbuild_name setting_type def _Translate value msbuild_settings msbuild_tool_settings _GetMSBuildToolSettings msbuild_settings tool msbuild_tool_settings[msbuild_name] setting_type.ConvertToMSBuild value _msvs_validators[tool.msvs_name][msvs_name] setting_type.ValidateMSVS_msbuild_validators[tool.msbuild_name][msbuild_name] setting_type.ValidateMSBuild_msvs_to_msbuild_converters[tool.msvs_name][msvs_name] _Translate
def handle_wallclock_metric common_props sample wallclock_samples []wallclock_sample dict common_props wallclock_sample['value'] sample['value']wallclock_samples.append wallclock_sample return wallclock_samples
def errors_from_deserialization_exceptions exceptions included False def _to_error exception detail exception.message status exception.statusreturn error status status detail detail errors list map _to_error exceptions if len errors 1 status errors[0]['status']else status 400return errors_response status errors
@strategy_options.loader_option def baked_lazyload loadopt attr return loadopt.set_relationship_strategy attr {'lazy' 'baked_select'}
def _decimate_surface points triangles reduction if 'DISPLAY' not in os.environ and sys.platform ! 'win32' os.environ['ETS_TOOLKIT'] 'null'try from tvtk.api import tvtkfrom tvtk.common import configure_inputexcept ImportError raise ValueError 'ThisfunctionrequirestheTVTKpackagetobeinstalled' if triangles.max > len points - 1 raise ValueError 'Thetrianglesrefertoundefinedpoints.Pleasecheckyourmesh.' src tvtk.PolyData points points polys triangles decimate tvtk.QuadricDecimation target_reduction reduction configure_input decimate src decimate.update out decimate.outputtris out.polys.to_array return out.points.to_array tris.reshape tris.size / 4 4 [ 1 ]
def constant_time_compare actual expected actual_len len actual expected_len len expected result actual_len ^ expected_len if expected_len > 0 for i in xrange actual_len result | ord actual[i] ^ ord expected[ i % expected_len ] return result 0
def _make_find_query query try query sympify query except SympifyError passif isinstance query type return lambda expr isinstance expr query elif isinstance query Basic return lambda expr expr.match query is not None return query
@pytest.mark.parametrize u'text number' [ u'7am' u'7' u'11p.m.' u'11' ] def test_issue736 en_tokenizer text number tokens en_tokenizer text assert len tokens 2 assert tokens[0].text number
def _gen_tag low return '{0[state]}_|-{0[__id__]}_|-{0[name]}_|-{0[fun]}'.format low
def load_results_dir package_dirpath tgz_filepath path.join package_dirpath RESULTS_DIR_TARBALL if not path.exists tgz_filepath return None None tgz tarfile.open tgz_filepath 'r gz' tmp_dirpath autotemp.tempdir unique_id 'scenario_base' results_dirname tgz.next .nametgz.extract results_dirname tmp_dirpath.name for info in tgz tgz.extract info.name tmp_dirpath.name return tmp_dirpath path.join tmp_dirpath.name results_dirname
def copy_c_string c_string s ctypes.cast c_string ctypes.c_char_p .valuereturn '' + s
def instance_system_metadata_get context instance_uuid return IMPL.instance_system_metadata_get context instance_uuid
def _nth_linear_match eq func order x func.args[0]one_x {x}terms {i S.Zero for i in range -1 order + 1 }for i in Add.make_args eq if not i.has func terms[ -1 ] + ielse c f i.as_independent func if not isinstance f Derivative and set f.variables one_x or f func return Noneelse terms[len f.args[1 ] ] + creturn terms
@cache_control no_cache True def project_badge request project_slug version_slug request.GET.get 'version' LATEST style request.GET.get 'style' 'flat' try version Version.objects.public request.user .get project__slug project_slug slug version_slug except Version.DoesNotExist url 'https //img.shields.io/badge/docs-unknown%20version-yellow.svg?style {style}'.format style style return HttpResponseRedirect url version_builds version.builds.filter type 'html' state 'finished' .order_by '-date' if not version_builds.exists url 'https //img.shields.io/badge/docs-no%20builds-yellow.svg?style {style}'.format style style return HttpResponseRedirect url last_build version_builds[0]if last_build.success color 'brightgreen'else color 'red'url 'https //img.shields.io/badge/docs-%s-%s.svg?style %s' % version.slug.replace '-' '--' color style return HttpResponseRedirect url
def no_freesurfer if Info.version is None return Trueelse return False
def add_uids doctree condition for node in doctree.traverse condition node.uid uuid4 .hex yield node
def post_issue_comment issue comment_text github_auth closed_issue issue.copy closed_issue['state'] 'closed'r requests.post 'https //api.github.com/repos/Khan/khan-exercises/issues/%s/comments' % issue['number'] data json.dumps {'body' comment_text} auth github_auth try r.raise_for_status time.sleep 1 return Trueexcept requests.HTTPError return False
@pick_context_manager_writerdef compute_node_delete context compute_id result model_query context models.ComputeNode .filter_by id compute_id .soft_delete synchronize_session False if not result raise exception.ComputeHostNotFound host compute_id
def generate_key_bytes hash_alg salt key nbytes keydata bytes digest bytes if len salt > 8 salt salt[ 8]while nbytes > 0 hash_obj hash_alg if len digest > 0 hash_obj.update digest hash_obj.update b key hash_obj.update salt digest hash_obj.digest size min nbytes len digest keydata + digest[ size]nbytes - sizereturn keydata
def overload_attribute typ attr from .typing.templates import make_overload_attribute_templatedef decorate overload_func template make_overload_attribute_template typ attr overload_func infer_getattr template return overload_funcreturn decorate
def evtop app None app app_or_default app state app.events.State display CursesMonitor state app display.init_screen refresher DisplayThread display refresher.start try capture_events app state display except Exception refresher.shutdown Truerefresher.join display.resetscreen raiseexcept KeyboardInterrupt SystemExit refresher.shutdown Truerefresher.join display.resetscreen
def recreate_image codebook labels w h d codebook.shape[1]image np.zeros w h d label_idx 0for i in range w for j in range h image[i][j] codebook[labels[label_idx]]label_idx + 1return image
def get_alembic_configs script_locations {}if CONF.subproject script_location _get_subproject_script_location CONF.subproject script_locations[CONF.subproject] script_locationelse for subproject ep in migration_entrypoints.items script_locations[subproject] _get_subproject_script_location subproject configs []project_seq sorted script_locations.keys if len project_seq > 1 and 'neutron' in project_seq project_seq.insert 0 project_seq.pop project_seq.index 'neutron' for project in project_seq config alembic_config.Config neutron_alembic_ini config.set_main_option 'neutron_project' project script_location script_locations[project]config.set_main_option 'script_location' script_location _set_version_locations config config.neutron_config CONFconfigs.append config return configs
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def show_with_diff image reference title plt.figure figsize 5 3.3 plt.subplot 1 2 1 plt.title 'Image' plt.imshow image vmin 0 vmax 1 cmap plt.cm.gray interpolation 'nearest' plt.xticks plt.yticks plt.subplot 1 2 2 difference image - reference plt.title 'Difference norm %.2f ' % np.sqrt np.sum difference ** 2 plt.imshow difference vmin -0.5 vmax 0.5 cmap plt.cm.PuOr interpolation 'nearest' plt.xticks plt.yticks plt.suptitle title size 16 plt.subplots_adjust 0.02 0.02 0.98 0.79 0.02 0.2
def set_default_subparser self name args None subparser_found Falsefor arg in sys.argv[1 ] if arg in ['-h' '--help'] breakelse for x in self._subparsers._actions if not isinstance x argparse._SubParsersAction continuefor sp_name in x._name_parser_map.keys if sp_name in sys.argv[1 ] subparser_found Trueif not subparser_found if args is None sys.argv.insert 1 name else args.insert 0 name
def _is_staff_for_article article user return user.is_staff or user.is_superuser or user_is_article_course_staff user article
def migration_get_by_id_and_instance context migration_id instance_uuid return IMPL.migration_get_by_id_and_instance context migration_id instance_uuid
def get_provider name None id None if id is not None provider ALL_PROVIDERS_BY_ID[id] else if name is None name settings.DEFAULT_PAYMENT_PROVIDERprovider ALL_PROVIDERS[name] if provider.name not in settings.PAYMENT_PROVIDERS raise ImproperlyConfigured 'Theprovider{p}isnotoneoftheallowedPAYMENT_PROVIDERS.'.format p provider.name return provider
def _make_streaming_request sample language_code max_alternatives profanity_filter speech_context single_utterance interim_results config RecognitionConfig encoding sample.encoding sample_rate sample.sample_rate language_code language_code max_alternatives max_alternatives profanity_filter profanity_filter speech_context speech_context streaming_config StreamingRecognitionConfig config config single_utterance single_utterance interim_results interim_results config_request StreamingRecognizeRequest streaming_config streaming_config return config_request
def handshake_in_memory client_conn server_conn client_conn.set_connect_state server_conn.set_accept_state for conn in [client_conn server_conn] try conn.do_handshake except WantReadError passinteract_in_memory client_conn server_conn
def symmetry_bowker table warnings.warn 'Deprecated usestats.TableSymmetryinstead' DeprecationWarning table np.asarray table k k2 table.shapeif k ! k2 raise ValueError 'tableneedstobesquare' upp_idx np.triu_indices k 1 tril table.T[upp_idx]triu table[upp_idx]stat tril - triu ** 2 / tril + triu + 1e-20 .sum df k * k - 1 / 2.0 pval stats.chi2.sf stat df return stat pval df
def _dict_subset keys master_dict return dict [ k v for k v in six.iteritems master_dict if k in keys ]
def get_conn vm_ get_configured_provider driver get_driver Provider.DIMENSIONDATA region config.get_cloud_config_value 'region' vm_ __opts__ user_id config.get_cloud_config_value 'user_id' vm_ __opts__ key config.get_cloud_config_value 'key' vm_ __opts__ if key is not None log.debug 'DimensionDataauthenticatingusingpassword' return driver user_id key region region
def libxml2debug testfunction try import libxml2except ImportError return testfunctiondef newfunc *args **kwargs libxml2.debugMemory 1 testfunction *args **kwargs libxml2.cleanupParser leaked_bytes libxml2.debugMemory 0 assert leaked_bytes 0 'libxml2memoryleakdetected %dbytes' % leaked_bytes if 'LIBXML2_DEBUGLEAKS' in os.environ return newfuncelse return testfunction
@pytest.fixture scope u'session' def celery_worker_parameters return {}
def degree_pearson_correlation_coefficient G x 'out' y 'in' weight None nodes None try import scipy.stats as statsexcept ImportError raise ImportError 'AssortativityrequiresSciPy http //scipy.org/' xy node_degree_xy G x x y y nodes nodes weight weight x y zip *xy return stats.pearsonr x y [0]
def sync_list_settings for key data in frappe.cache .hgetall '_list_settings' .iteritems doctype user key.split ' ' frappe.db.sql 'insertinto__ListSettings user doctype data values %s %s %s \n DCTB DCTB DCTB onduplicatekeyupdatedata %s' user doctype data data
def common_pairs profile if not has_pairs profile return []result [ op1 op2 opcode.opname[op1] opcode.opname[op2] count for op1 op1profile in enumerate profile[ -1 ] for op2 count in enumerate op1profile if count > 0 ]result.sort key operator.itemgetter 2 reverse True return result
def filter_re_replace val pattern repl return re.sub pattern repl str val
def expand_score new_net new_layer net layer old_cl net.params[layer][0].numnew_net.params[new_layer][0].data[ old_cl][...] net.params[layer][0].datanew_net.params[new_layer][1].data[0 0 0 old_cl][...] net.params[layer][1].data
def reorder_missing_matrix matrix missing reorder_rows False reorder_cols False is_diagonal False inplace False prefix None if prefix is None prefix find_best_blas_type matrix [0]reorder prefix_reorder_missing_matrix_map[prefix]if not inplace matrix np.copy matrix order 'F' reorder matrix np.asfortranarray missing reorder_rows reorder_cols is_diagonal return matrix
def is_required question required question.get 'required' False if not required properties question.get 'properties' False if properties and isinstance properties list for item property in enumerate properties if isinstance property dict and property.get 'required' False required Truebreakreturn required
def iscsi_get_nodes cmd 'iscsiadm--modenode'output utils.system_output cmd pattern ' \\d+\\.\\d+\\.\\d+\\.\\d+|\\W {2}\\d\\W \\d+ \\d+\\s+ [\\w\\.\\- \\d]+ 'nodes []if 'Norecordsfound' not in output nodes re.findall pattern output return nodes
def fileList paths relative False folders False if not isinstance paths list paths [paths]files []def append directory name if not name.startswith '.' path os.path.join directory name files.append path for path in paths for directory dirnames filenames in os.walk path followlinks True if folders for dirname in dirnames append directory dirname for filename in filenames append directory filename if relative files map_apply lambda x x[ len path + 1 ] files return files
def get_html_theme_path cur_dir os.path.abspath os.path.dirname os.path.dirname __file__ return cur_dir
def batch_with_dynamic_pad images_and_captions batch_size queue_capacity add_summaries True enqueue_list []for image caption in images_and_captions caption_length tf.shape caption [0]input_length tf.expand_dims tf.sub caption_length 1 0 input_seq tf.slice caption [0] input_length target_seq tf.slice caption [1] input_length indicator tf.ones input_length dtype tf.int32 enqueue_list.append [image input_seq target_seq indicator] images input_seqs target_seqs mask tf.train.batch_join enqueue_list batch_size batch_size capacity queue_capacity dynamic_pad True name 'batch_and_pad' if add_summaries lengths tf.add tf.reduce_sum mask 1 1 tf.scalar_summary 'caption_length/batch_min' tf.reduce_min lengths tf.scalar_summary 'caption_length/batch_max' tf.reduce_max lengths tf.scalar_summary 'caption_length/batch_mean' tf.reduce_mean lengths return images input_seqs target_seqs mask
def mathematica_code expr **settings return MCodePrinter settings .doprint expr
def _Base64EncodeAttachments mime_message for item in mime_message.get_payload if item.get_content_maintype not in ['multipart' 'text'] and 'Content-Transfer-Encoding' not in item encoders.encode_base64 item
def _get_layer_initializers initializers layer_name fields if initializers is None return Noneif isinstance initializers dict and layer_name in initializers return _get_initializers initializers[layer_name] fields return _get_initializers initializers fields
def _rewrite_assign tok toknum tokval tokreturn toknum ' ' if tokval ' ' else tokval
def submit_jobs commands prefix qiime_config load_qiime_config CLUSTER_JOBS_SCRIPT qiime_config['cluster_jobs_fp']if not CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotsetinconfigfile!' if not exists CLUSTER_JOBS_SCRIPT or which CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotin$PATHorprovidedasfullpath!' outfilename join get_qiime_temp_dir '%s_commands.txt' % prefix fh open outfilename 'w' fh.write '\n'.join commands fh.close cmd '%s-ms%s%s' % CLUSTER_JOBS_SCRIPT outfilename prefix system cmd remove outfilename
def template pattern flags 0 return _compile pattern flags | TEMPLATE
def chain_transports *args if len args < 2 raise ValueError 'chain_transportsneedsatleast2transports!' class WrappedTransport TransportWrapper cls_chain list args return WrappedTransport
def get_sprot_raw id return _urlopen 'http //www.uniprot.org/uniprot/%s.txt' % id
def namedObject name classSplit name.split '.' module namedModule '.'.join classSplit[ -1 ] return getattr module classSplit[ -1 ]
def make_cluster_id test_type tmp_uuid uuid4 tagged_cluster_id UUID fields tmp_uuid.time_low tmp_uuid.time_mid tmp_uuid.time_hi_version test_type.value tmp_uuid.clock_seq_low MARKER return tagged_cluster_id
def safe_get_design request design_type design_id None design Noneif design_id is not None design authorized_get_design request design_id if design is None design SavedQuery owner request.user type design_type return design
def wheel_version source_dir try dist [d for d in pkg_resources.find_on_path None source_dir ][0]wheel_data dist.get_metadata 'WHEEL' wheel_data Parser .parsestr wheel_data version wheel_data['Wheel-Version'].strip version tuple map int version.split '.' return versionexcept return False
def _create_image_thumbnail file_path longest_side settings.THUMBNAIL_SIZE pad False original_image Image.open file_path original_image original_image.convert 'RGBA' file_width file_height original_image.size width height _scale_dimensions file_width file_height longest_side resized_image original_image.resize width height Image.ANTIALIAS io StringIO.StringIO if pad padded_image _make_image_square resized_image longest_side padded_image.save io 'PNG' else resized_image.save io 'PNG' return ContentFile io.getvalue
def _enable_atrun __salt__['service.enable'] 'com.apple.atrun' __salt__['service.start'] 'com.apple.atrun' return _atrun_enabled
def fix_log_params targets logger.info 'Migratingregistration_cancelled registration_approved retraction_cancelled embargo_approved embargo_cancelled andembargo_terminatedlogs.' count 0for log in targets node_id log.params['node']node Node.load node_id if node.is_registration log.params['node'] get_registered_from node log.params['registration'] node._idlog.original_node log.params['node']logger.info 'Updatingparamsoflog{}.params[node] {} params[registration] {} andoriginal_node {}'.format log._id log.params['node'] log.params['registration'] log.original_node log.save count + 1logger.info '{}logsmigrated'.format count
def _get_auth_type entity id includes if 'user-tags' in includes or 'user-ratings' in includes return AUTH_YESelif entity.startswith 'collection' if not id return AUTH_YESelse return AUTH_IFSETelse return AUTH_NO
def FormatFunctionCall func *args **kwargs while type func is partial args func.args + args if func.keywords kwargs.update func.keywords func func.funcreturn '%s%s' % func.__name__ FormatArguments *args **kwargs
def remove_job_submit_sidebar_box apps schema_editor Box apps.get_model u'boxes' u'Box' try submit_box Box.objects.get label u'jobs-submitajob' submit_box.delete except Box.DoesNotExist pass
def getInterpretPlugin fileName importPluginFileNames getImportPluginFileNames for importPluginFileName in importPluginFileNames fileTypeDot '.' + importPluginFileName if fileName[ - len fileTypeDot ].lower fileTypeDot importPluginsDirectoryPath getPluginsDirectoryPath pluginModule archive.getModuleWithDirectoryPath importPluginsDirectoryPath importPluginFileName if pluginModule ! None return pluginModuleprint 'Couldnotfindplugintohandle' + fileName return None
def fromXMLname string retval sub '_xFFFF_' '' string def fun matchobj return _fromUnicodeHex matchobj.group 0 retval sub '_x[0-9A-Za-z]+_' fun retval return retval
def has name return __salt__['file.file_exists'] _cert_file name 'cert'
def check_duplicate_segments segments is_partial_func None if is_partial_func is not None segments [s for s in segments if not is_partial_func s ]fully_specifieds [tuple sorted s.items for s in segments]if len set fully_specifieds ! len fully_specifieds raise SegmentsContainDuplicateEntry
def form_for_fields field_list fields SortedDict [ f.name f.formfield for f in field_list if f.editable] return type 'FormForFields' BaseForm {'base_fields' fields}
def ifPlatformSupported f @wraps f def wrapper self *args **kwargs supported platform.getType 'posix' if supported return f self *args **kwargs else e self.assertRaises NotImplementedError SkipTest self.failureException f self *args **kwargs if isinstance e NotImplementedError self.assertTrue str e .startswith 'isRunningisnotimplementedon' return wrapper
def stopDtmfAcknowledge a TpPd pd 3 b MessageType mesType 50 packet a / b return packet
def is_currently_visible_to_students xblock try published modulestore .get_item xblock.location revision ModuleStoreEnum.RevisionOption.published_only except ItemNotFoundError return Falseif published.visible_to_staff_only return Falseif 'detached' not in published._class_tags and published.start is not None return datetime.now UTC > published.start return True
def get_glib_sysconf_dirs if is_win return [os.path.join get_gi_libdir 'GLib' '2.0' 'etc' ]statement "\nimportgi\ngi.require_version 'GLib' '2.0' \nfromgi.repositoryimportGLib\nprint GLib.get_system_config_dirs \n"data_dirs eval_statement statement if not data_dirs logger.error "girepository'GIRepository2.0'notfound.Pleasemakesurelibgirepository-gir2.0resp.lib64girepository-gir2.0isinstalled." return data_dirs
def setup_axes2 fig rect tr PolarAxes.PolarTransform pi np.piangle_ticks [ 0 '$0$' 0.25 * pi '$\\frac{1}{4}\\pi$' 0.5 * pi '$\\frac{1}{2}\\pi$' ]grid_locator1 FixedLocator [v for v s in angle_ticks] tick_formatter1 DictFormatter dict angle_ticks grid_locator2 MaxNLocator 2 grid_helper floating_axes.GridHelperCurveLinear tr extremes 0.5 * pi 0 2 1 grid_locator1 grid_locator1 grid_locator2 grid_locator2 tick_formatter1 tick_formatter1 tick_formatter2 None ax1 floating_axes.FloatingSubplot fig rect grid_helper grid_helper fig.add_subplot ax1 aux_ax ax1.get_aux_axes tr aux_ax.patch ax1.patchax1.patch.zorder 0.9return ax1 aux_ax
def object_name_to_class_name object_name if object_name in TRACE_NAMES return string_to_class_name object_name if object_name in OBJECT_NAME_TO_CLASS_NAME return OBJECT_NAME_TO_CLASS_NAME[object_name]if object_name in ARRAYS return 'list'else return 'dict'
def get_packs_base_paths system_packs_base_path get_system_packs_base_path packs_base_paths cfg.CONF.content.packs_base_paths or '' if packs_base_paths.endswith ' ' packs_base_paths packs_base_paths[ -1 ]result []if system_packs_base_path result.append system_packs_base_path packs_base_paths packs_base_paths.split ' ' result result + packs_base_paths result [path for path in result if path]result list OrderedSet result return result
def addslash method @functools.wraps method def wrapper self *args **kwargs if not self.request.path.endswith '/' if self.request.method in 'GET' 'HEAD' uri self.request.path + '/' if self.request.query uri + '?' + self.request.query self.redirect uri permanent True returnraise HTTPError 404 return method self *args **kwargs return wrapper
def load_all unload_all plugins config.get 'ckan.plugins' '' .split + find_system_plugins if 'synchronous_search' not in plugins and asbool config.get 'ckan.search.automatic_indexing' True log.debug 'Loadingthesynchronoussearchplugin' plugins.append 'synchronous_search' load *plugins
def show_stack name None profile None h_client _auth profile if not name return {'result' False 'comment' 'ParameternamemissingorNone'}try ret {}stack h_client.stacks.get name links {}for link in stack.links links[link['rel']] link['href']ret[stack.stack_name] {'status' stack.stack_status 'id' stack.id 'name' stack.stack_name 'creation' stack.creation_time 'owner' stack.stack_owner 'reason' stack.stack_status_reason 'parameters' stack.parameters 'links' links}ret['result'] Trueexcept exc.HTTPNotFound return {'result' False 'comment' 'Nostack{0}'.format name }return ret
def _isPythonIdentifier string return '' not in string and '.' not in string and '-' not in string
def rsync_ip ip try socket.inet_pton socket.AF_INET6 ip except socket.error return ipelse return '[%s]' % ip
def test_saving_state_exclude_domain_include_entity hass_recorder hass hass_recorder {'include' {'entities' 'test.recorder'} 'exclude' {'domains' 'test'}} states _add_entities hass ['test.recorder' 'test2.recorder'] assert len states 2
def update_qq_api_request_data data {} defaults {'openid' session.get 'qq_openid' 'access_token' session.get 'qq_token' [0] 'oauth_consumer_key' QQ_APP_ID}defaults.update data return defaults
def _stabilizer degree generators alpha orb [alpha]table {alpha list range degree }table_inv {alpha list range degree }used [False] * degree used[alpha] Truegens [x._array_form for x in generators]stab_gens []for b in orb for gen in gens temp gen[b]if used[temp] is False gen_temp _af_rmul gen table[b] orb.append temp table[temp] gen_temptable_inv[temp] _af_invert gen_temp used[temp] Trueelse schreier_gen _af_rmuln table_inv[temp] gen table[b] if schreier_gen not in stab_gens stab_gens.append schreier_gen return [_af_new x for x in stab_gens]
def source_read app docname source if docname ! 'extensions/plugins-toolkit' returnsource_ ''for name thing in inspect.getmembers toolkit custom_docstring toolkit.docstring_overrides.get name if inspect.isfunction thing source_ + format_function name thing docstring custom_docstring elif inspect.ismethod thing source_ + format_function name thing docstring custom_docstring elif inspect.isclass thing source_ + format_class name thing docstring custom_docstring elif isinstance thing types.ObjectType source_ + format_object name thing docstring custom_docstring else assert False "Someoneadded{name} {thing}tothepluginstoolkitandthisSphinxextensiondoesn'tknowhowtodocumentthatyet.Ifyou'rethatsomeone youneedtoaddanewformat_* functionforithereorthedocswon'tbuild.".format name name thing thing source[0] + source_
def convertXMLElement geometryOutput xmlElement xmlElement.getXMLProcessor .createChildren geometryOutput['shapes'] xmlElement
def check_lyrics_fetched lyrics_dirs len [d for d in os.listdir LYRICS_ROOT_DIR if os.path.isdir os.path.join LYRICS_ROOT_DIR d ] return lyrics_dirs > 1
def get_diff_opcode_generator_class return _generator
def has_no_console_errors selenium logs selenium.get_log 'browser' severe_errors [l for l in logs if l.get 'level' 'SEVERE' ]non_network_errors [l for l in severe_errors if l.get 'type' ! 'network' ]if len non_network_errors 0 return Trueelse pytest.fail 'Consoleerrors %s' % non_network_errors if len non_network_errors 0 and len severe_errors ! 0 warn 'Therewereseverenetworkerrors thismayormaynothaveaffectedyourtest %s' % severe_errors canvas selenium.find_element_by_tag_name 'canvas' wait_for_canvas_resize canvas selenium
def double_redirect_view request return HttpResponseRedirect '/permanent_redirect_view/'
def _convert_to_and_validate_length_unit unit allow_dimensionless False try unit u.Unit unit assert unit.is_equivalent u.kpc or allow_dimensionless and unit u.dimensionless_unscaled except TypeError AssertionError raise u.UnitsError u'Unit"{0}"isnotalengthtype'.format unit return unit
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def _RuleExpandPath path input_file path path.replace '$ InputName ' os.path.splitext os.path.split input_file [1] [0] path path.replace '$ InputDir ' os.path.dirname input_file path path.replace '$ InputExt ' os.path.splitext os.path.split input_file [1] [1] path path.replace '$ InputFileName ' os.path.split input_file [1] path path.replace '$ InputPath ' input_file return path
def spherical_in n z derivative False if derivative return _spherical_in_d n z else return _spherical_in n z
def is_encrypted_file file_obj start_pos 0 count -1 current_position file_obj.tell try file_obj.seek start_pos vaulttext file_obj.read count try b_vaulttext to_bytes to_text vaulttext encoding 'ascii' errors 'strict' encoding 'ascii' errors 'strict' except UnicodeError TypeError return Falsefinally file_obj.seek current_position return is_encrypted b_vaulttext
def is_online user return user.lastseen > time_diff
def permutationFilter perm return True
def get_non_shed_tool_panel_configs app config_filenames []for config_filename in app.config.tool_configs tree error_message xml_util.parse_xml config_filename if tree is None continueroot tree.getroot tool_path root.get 'tool_path' None if tool_path is None config_filenames.append config_filename return config_filenames
def spans_to_relative spans prev 0for left right in spans yield left - prev right - left prev right
def get_impl_version_info if get_abbr_impl 'pp' return sys.version_info[0] sys.pypy_version_info.major sys.pypy_version_info.minor else return sys.version_info[0] sys.version_info[1]
def coordinatesFromIndex index dimensions coordinates [0] * len dimensions shifted indexfor i in xrange len dimensions - 1 0 -1 coordinates[i] shifted % dimensions[i] shifted shifted / dimensions[i] coordinates[0] shiftedreturn coordinates
def test_validation_k_fold skip_if_no_sklearn from pylearn2.cross_validation.subset_iterators import ValidationKFoldn 30cv ValidationKFold n for train valid test in cv assert np.unique np.concatenate train valid test .size n assert valid.size n / cv.n_folds assert test.size n / cv.n_folds
def _date_to_datetime value if not isinstance value datetime.date raise TypeError 'Cannotconverttodatetimeexpecteddatevalue;received%s' % value return datetime.datetime value.year value.month value.day
def lint_thread module reporter gui gui.status.text 'processingmodule s 'pylint.lint.Run args [module] reporter reporter exit False gui.msg_queue.put 'DONE'
def make_ref_target_directive ref_type indextemplates None **kwargs class_vars dict ref_type ref_type indextemplates indextemplates class_vars.update kwargs return type 'BB%sRefTargetDirective' % ref_type.capitalize BBRefTargetDirective class_vars
def getEnumeratorKeysExceptForOneArgument enumerator keys if len keys 0 return range 0 len enumerator beginIndex keys[0]endIndex keys[1]if len keys 2 if beginIndex None beginIndex 0if endIndex None endIndex len enumerator return range beginIndex endIndex step keys[2]beginIndexDefault 0endIndexDefault len enumerator if step < 0 beginIndexDefault endIndexDefault - 1 endIndexDefault -1 if beginIndex None beginIndex beginIndexDefaultif endIndex None endIndex endIndexDefaultreturn range beginIndex endIndex step
@cache_permissiondef can_upload_dictionary user project return check_permission user project 'trans.upload_dictionary'
def check_valid sig args kwargs num_pos_only func keyword_exclude sigspec sigif len args < num_pos_only return Falseif keyword_exclude kwargs dict kwargs for item in keyword_exclude kwargs.pop item None try func *args **kwargs return Trueexcept TypeError return False
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _parse_message chunks f BytesIO ''.join chunks k Nonev ''eof Falsefor l in f if l.startswith '' v + l[1 ]else if k is not None yield k v.rstrip '\n' if l '\n' break k v l.split '' 1 else eof Trueif k is not None yield k v.rstrip '\n' yield None None if not eof yield None f.read f.close
def libvlc_audio_output_set p_mi psz_name f _Cfunctions.get 'libvlc_audio_output_set' None or _Cfunction 'libvlc_audio_output_set' 1 1 None ctypes.c_int MediaPlayer ctypes.c_char_p return f p_mi psz_name
def clean_config config patterns comment_out_list []for line in config if line.strip .startswith '#' continueif '#' in line pure_line line[ line.index '#' ]else pure_line lineif pure_line.strip .endswith ' ' comment_out_list.append line continueif any [re.search pat pure_line for pat in patterns] comment_out_list.append line new_config [ line if line not in comment_out_list else '#' + line for line in config]return new_config
def external_script script p1 p2 p3 None p4 None command [script p1 p2 p3 p4]try stup need_shell command creationflags build_command command env fix_env logging.info 'Runninguserscript%s %s %s ' script p1 p2 p subprocess.Popen command shell need_shell stdin subprocess.PIPE stdout subprocess.PIPE stderr subprocess.STDOUT startupinfo stup env env creationflags creationflags except logging.debug 'Failedscript%s Traceback ' script exc_info True return 'Cannotrunscript%s\r\n' % script -1 output p.stdout.read ret p.wait return output ret
def ensure_not_within_tag_definition cursor forward True block offset cursor.block cursor.positionInBlock b boundary next_tag_boundary block offset forward False if b is None return Falseif boundary.is_start if forward block boundary next_tag_boundary block offset if block is not None cursor.setPosition block.position + boundary.offset + 1 return Trueelse cursor.setPosition b.position + boundary.offset return Truereturn False
def batch_inv a return BatchInv a
def setup_environ settings_mod original_settings_path None warnings.warn "The'setup_environ'functionisdeprecated youlikelyneedtoupdateyour'manage.py';pleaseseetheDjango1.4releasenotes https //docs.djangoproject.com/en/dev/releases/1.4/ ." PendingDeprecationWarning if '__init__.py' in settings_mod.__file__ p os.path.dirname settings_mod.__file__ else p settings_mod.__file__ project_directory settings_filename os.path.split p if project_directory os.curdir or not project_directory project_directory os.getcwd project_name os.path.basename project_directory settings_name os.path.splitext settings_filename [0]if settings_name.endswith '$py' settings_name settings_name[ -3 ]if original_settings_path os.environ['DJANGO_SETTINGS_MODULE'] original_settings_pathelse os.environ['DJANGO_SETTINGS_MODULE'] os.environ.get 'DJANGO_SETTINGS_MODULE' '%s.%s' % project_name settings_name sys.path.append os.path.join project_directory os.pardir import_module project_name sys.path.pop return project_directory
def _get_channel channel __salt__['config.get'] 'mattermost.channel' or __salt__['config.get'] 'mattermost channel' return channel
def bounds sizes low 0rv []for size in sizes rv.append low low + size low + sizereturn rv
def rm_known_host user None hostname None config None port None if not hostname return {'status' 'error' 'error' 'hostnameargumentrequired'}full _get_known_hosts_file config config user user if isinstance full dict return fullif not os.path.isfile full return {'status' 'error' 'error' 'Knownhostsfile{0}doesnotexist'.format full }ssh_hostname _hostname_and_port_to_ssh_hostname hostname port cmd ['ssh-keygen' '-R' ssh_hostname '-f' full]cmd_result __salt__['cmd.run'] cmd python_shell False if os.geteuid 0 and user uinfo __salt__['user.info'] user os.chown full uinfo['uid'] uinfo['gid'] return {'status' 'removed' 'comment' cmd_result}
def setsebools pairs persist False if not isinstance pairs dict return {}if persist cmd 'setsebool-P'else cmd 'setsebool'for boolean value in six.iteritems pairs cmd '{0}{1} {2}'.format cmd boolean value return not __salt__['cmd.retcode'] cmd python_shell False
def _translate_interface_attachment_view port_info return {'net_id' port_info['network_id'] 'port_id' port_info['id'] 'mac_addr' port_info['mac_address'] 'port_state' port_info['status'] 'fixed_ips' port_info.get 'fixed_ips' None }
def parse_args_kwargs parser token bits token.contents.split '' if len bits < 1 raise template.TemplateSyntaxError "'%s'takesatleastoneargument" % bits[0] if token.contents[13] '"' end_quote token.contents.index '"' 14 + 1 args [template.Variable token.contents[13 end_quote] ]kwargs_start end_quoteelse try next_space token.contents.index '' 14 kwargs_start next_space + 1 except ValueError next_space Nonekwargs_start Noneargs [template.Variable token.contents[13 next_space] ]kwargs {}kwargs_list token.contents[kwargs_start ].split ' ' for kwargs_item in kwargs_list if ' ' in kwargs_item k v kwargs_item.split ' ' 1 k k.strip kwargs[k] template.Variable v return args kwargs
def exact_div p d allow_divzero False if not isinstance p int long or not isinstance d int long raise TypeError 'unsupportedoperandtype s %rand%r' % type p .__name__ type d .__name__ if d 0 and allow_divzero n 0if p ! n * d raise ValueError 'Nosolutioncouldbefound' else n r divmod p d if r ! 0 raise ValueError 'Nosolutioncouldbefound' assert p n * d return n
def hessian_matrix_eigvals Hxx Hxy Hyy return _image_orthogonal_matrix22_eigvals Hxx Hxy Hyy
def systemInformationType1 a L2PseudoLength l2pLength 21 b TpPd pd 6 c MessageType mesType 25 d CellChannelDescription e RachControlParameters f Si1RestOctets packet a / b / c / d / e / f return packet
def histogram metric_name *args **kwargs if 'tags' in kwargs kwargs['tags'] _clean_tags kwargs['tags'] dog_stats_api.histogram metric_name *args **kwargs
def _channels_changed params len_channels if params['ch_start'] + params['n_channels'] > len_channels params['ch_start'] len_channels - params['n_channels'] if params['ch_start'] < 0 params['ch_start'] 0params['plot_fun']
def resource_type_from_id context resource_id known_types {'i' 'instance' 'r' 'reservation' 'vol' 'volume' 'snap' 'snapshot' 'ami' 'image' 'aki' 'image' 'ari' 'image'}type_marker resource_id.split '-' [0]return known_types.get type_marker
def security_group_destroy context security_group_id return IMPL.security_group_destroy context security_group_id
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit.' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf.classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf.classes_ else clf.classes_ unique_labels classes return Truereturn False
def build_song_rep song md_list [u'title' u'artist' u'album'] divider u'-' filtered filter_song_md song md_list no_singletons False return divider.join filtered
def gf_frobenius_monomial_base g p K n gf_degree g if n 0 return []b [0] * n b[0] [1]if p < n for i in range 1 n mon gf_lshift b[ i - 1 ] p K b[i] gf_rem mon g p K elif n > 1 b[1] gf_pow_mod [K.one K.zero] p g p K for i in range 2 n b[i] gf_mul b[ i - 1 ] b[1] p K b[i] gf_rem b[i] g p K return b
def _asa d1 l d2 xy Line 0 0 slope _slope d1 .intersection Line l 0 slope _slope 180 - d2 [0]return Triangle 0 0 l 0 xy
def printer string quiet False debug False **kwargs if debug and not DEBUG returnif debug out '\x1b[1;30mDEBUG %s\x1b[0m' % string else out stringif not quiet print_ out **kwargs
def netstats return _nodetool 'netstats'
def get_prodoc_entry id cgi 'http //www.expasy.ch/cgi-bin/get-prodoc-entry' return _urlopen '%s?%s' % cgi id
def _build_html_slider slices_range slides_klass slider_id start_value None if start_value is None start_value slices_range[ len slices_range // 2 ]return slider_template.substitute slider_id slider_id klass slides_klass step slices_range[1] - slices_range[0] minvalue slices_range[0] maxvalue slices_range[ -1 ] startvalue start_value
def squeeze_seq seq return sub ' [AGCTacgt] \\1+' '\\1' seq
def ec2_instance_create context instance_uuid id None return IMPL.ec2_instance_create context instance_uuid id
@register_uncanonicalize@gof.local_optimizer [T.Reshape] def local_reshape_dimshuffle node if isinstance node.op T.Reshape input_ node.inputs[0]if input_.owner and isinstance input_.owner.op DimShuffle new_order input_.owner.op.new_orderoffset 0for dim in new_order if dim 'x' continueelif dim ! offset return Falseelse offset + 1return [T.reshape input_.owner.inputs[0] node.inputs[1] ndim node.outputs[0].ndim ]return False
@utils.arg 'os' metavar '<os>' help _ 'TypeofOS.' @utils.arg 'architecture' metavar '<architecture>' help _ 'Typeofarchitecture.' @utils.arg 'version' metavar '<version>' help _ 'Version.' @utils.arg 'url' metavar '<url>' help _ 'URL.' @utils.arg 'md5hash' metavar '<md5hash>' help _ 'MD5hash.' @utils.arg 'hypervisor' metavar '<hypervisor>' default 'xen' help _ 'Typeofhypervisor.' def do_agent_create cs args result cs.agents.create args.os args.architecture args.version args.url args.md5hash args.hypervisor utils.print_dict result.to_dict
def onLoginAppReady INFO_MSG 'onLoginAppReady bootstrapGroupIndex %s bootstrapGlobalIndex %s' % os.getenv 'KBE_BOOTIDX_GROUP' os.getenv 'KBE_BOOTIDX_GLOBAL'
@pytest.mark.parametrize 'parallel' [True False] def test_store_comments parallel read_basic text '\n#headercomment\nabc\n#comment2\n#comment3\n123\n456\n'table read_basic text parallel parallel check_meta True assert_equal table.meta['comments'] ['headercomment' 'comment2' 'comment3']
@utils.arg 'host' metavar '<hostname>' help _ 'Nameofhost.' def do_host_describe cs args result cs.hosts.get args.host columns ['HOST' 'PROJECT' 'cpu' 'memory_mb' 'disk_gb']utils.print_list result columns
def get_python_library_path dlls getImports sys.executable for filename in dlls for name in PYDYLIB_NAMES if os.path.basename filename name if is_win and not os.path.isabs filename filename getfullnameof filename return filenameif is_unix for name in PYDYLIB_NAMES python_libname findLibrary name if python_libname return python_libnameelif is_darwin prefixes [compat.base_prefix os.path.join compat.base_prefix 'lib' ]for prefix in prefixes for name in PYDYLIB_NAMES full_path os.path.join prefix name if os.path.exists full_path return full_pathreturn None
def async_quit global _shutting_down_shutting_down True
def zone_present domain type profile zones libcloud_dns_module.list_zones profile if not type type 'master'matching_zone [z for z in zones if z.domain domain ]if len matching_zone > 0 return state_result True 'Zonealreadyexists' else result libcloud_dns_module.create_zone domain profile type return state_result result 'Creatednewzone'
def allocated_size allocation_unit requested_size allocation_unit int allocation_unit requested_size int requested_size previous_interval_size requested_size // allocation_unit * allocation_unit if previous_interval_size < requested_size return previous_interval_size + allocation_unit else return requested_size
def numberDocument document chapterNumber i 1for node in domhelpers.findNodesNamed document 'h2' label dom.Text label.data '%s.%d' % chapterNumber i node.insertBefore label node.firstChild i + 1
def missing name jail None return name not in get_all jail
def make_fake_client client docker.DockerClient client.api make_fake_api_client return client
def get_enabled jail None ret []service _cmd jail prf _get_jail_path jail if jail else '' for svc in __salt__['cmd.run'] '{0}-e'.format service .splitlines ret.append os.path.basename svc for svc in get_all jail if svc in ret continueif not os.path.exists '{0}/etc/rc.conf.d/{1}'.format prf svc continueif enabled svc jail jail ret.append svc return sorted ret
def num_obs_linkage Z Z np.asarray Z order 'c' is_valid_linkage Z throw True name 'Z' return Z.shape[0] + 1
def render_to_kmz *args **kwargs return HttpResponse compress_kml loader.render_to_string *args **kwargs content_type 'application/vnd.google-earth.kmz'
def create_random_subfolder destination folder_name str uuid.uuid4 if destination.startswith 's3 //' parts destination.split '/' parts.append folder_name return '/'.join parts else parts list os.path.split destination parts.append folder_name path os.path.join *parts os.makedirs path return path
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def invitation_retrieve request response_format 'html' if request.user.username return HttpResponseRedirect '/' email request.REQUEST.get 'email' None key request.REQUEST.get 'key' None if email and key try invitation Invitation.objects.get email email key key except raise Http404else raise Http404if request.POST form InvitationForm invitation request.POST if form.is_valid profile form.save username profile.user.usernamepassword form.cleaned_data['password']user authenticate username username password password if user invitation.delete login request user return HttpResponseRedirect '/' else form InvitationForm invitation return render_to_response 'core/invitation_retrieve' {'invitation' invitation 'form' form} context_instance RequestContext request response_format response_format
def _GetValue value_pb if value_pb.type in _PROTO_FIELDS_STRING_VALUE if value_pb.has_string_value return value_pb.string_value return Noneif value_pb.type document_pb.FieldValue.DATE if value_pb.has_string_value return search_util.DeserializeDate value_pb.string_value return Noneif value_pb.type document_pb.FieldValue.NUMBER if value_pb.has_string_value return float value_pb.string_value return Noneif value_pb.type document_pb.FieldValue.GEO if value_pb.has_geo geo_pb value_pb.geo return GeoPoint latitude geo_pb.lat longitude geo_pb.lng return Noneraise TypeError 'unknownFieldValuetype%d' % value_pb.type
def check_index_exists manager table_name index_name query 'SELECT1FROMinformation_schema.statisticsWHEREtable_schema %sANDtable_name %sANDindex_name %s'rows manager.execute query manager.get_db_name table_name index_name return bool rows
def DocumentListAclEntryFromString xml_string return atom.CreateClassFromXMLString DocumentListAclEntry xml_string
def generate_context name '' argspec '' note '' math False collapse False img_path '' if img_path and os.name 'nt' img_path img_path.replace '\\' '/' context {'math_on' 'true' if math else '' 'name' name 'argspec' argspec 'note' note 'collapse' collapse 'img_path' img_path 'css_path' CSS_PATH 'js_path' JS_PATH 'jquery_path' JQUERY_PATH 'mathjax_path' MATHJAX_PATH 'right_sphinx_version' '' if sphinx.__version__ < '1.1' else 'true' 'platform' sys.platform}return context
def append_cxxflags value return append_var 'CXXFLAGS' value
def split_entry entry a entry.split ' ' d Noneif entry.lower .startswith 'd' d Truea.pop 0 if len a 2 a.append None t e p at t.lower if t.startswith 'u' t 'user'elif t.startswith 'g' t 'group'elif t.startswith 'm' t 'mask'elif t.startswith 'o' t 'other'else t Nonereturn [d t e p]
def isNegInf value return _sign value 1 and _exponent value 2047 and _zero_mantissa value
def test_status status input 'Didtheplot s displaycorrectly? y/n ' while not status.startswith 'y' 'n' print '' status input 'Unexpectedanswer.Pleasetypeyorn.' if status.startswith 'n' ErrorReport input 'Pleasedescribetheproblem ' return ErrorReport
def is_virginica_test fi t reverse example test example[fi] > t if reverse test not test return test
def _pick_bad_channels event params bads params['raw'].info['bads']params['info']['bads'] _select_bads event params bads _plot_update_raw_proj params None
def api_server api_services **kwargs if 'protocols' in kwargs raise TypeError "__init__ gotanunexpectedkeywordargument'protocols'" return _ApiServer api_services **kwargs
def _extract_meta x nonempty False if isinstance x _Frame Scalar return x._meta_nonempty if nonempty else x._meta elif isinstance x list return [_extract_meta _x nonempty for _x in x]elif isinstance x tuple return tuple [_extract_meta _x nonempty for _x in x] elif isinstance x dict res {}for k in x res[k] _extract_meta x[k] nonempty return reselse return x
def _secureEnoughString path secureishString armor sha1 randomBytes 64 .digest [ 16]return _coerceToFilesystemEncoding path secureishString
def register_checker lang u'python' checker None color None priority 1 global NOTIFICATIONS_CHECKERScheckers NOTIFICATIONS_CHECKERS.get lang [] checkers.append checker color priority NOTIFICATIONS_CHECKERS[lang] checkers
def keep_warm_callback event context lambda_handler event {} context context
def set_std_streams_blocking if not fcntl returnfor f in sys.__stdout__ sys.__stderr__ fileno f.fileno flags fcntl.fcntl fileno fcntl.F_GETFL fcntl.fcntl fileno fcntl.F_SETFL flags & ~ os.O_NONBLOCK
def shouldRefresh exList MAX_REFRESH_AGE_SECS 86400cache_db_con db.DBConnection 'cache.db' rows cache_db_con.select 'SELECTlast_refreshedFROMscene_exceptions_refreshWHERElist ?' [exList] if rows lastRefresh int rows[0]['last_refreshed'] return int time.mktime datetime.datetime.today .timetuple > lastRefresh + MAX_REFRESH_AGE_SECS else return True
def convert_to_group_ids groups vpc_id None vpc_name None region None key None keyid None profile None log.debug 'securitygroupcontents{0}pre-conversion'.format groups group_ids []for group in groups group_id get_group_id name group vpc_id vpc_id vpc_name vpc_name region region key key keyid keyid profile profile if not group_id raise CommandExecutionError 'CouldnotresolveSecurityGroupname{0}toaGroupID'.format group else group_ids.append str group_id log.debug 'securitygroupcontents{0}post-conversion'.format group_ids return group_ids
def wavebarrier raise _stub_error
def date_created document return document[config.DATE_CREATED] if config.DATE_CREATED in document else epoch
def uni2html u htmlentities list for c in u ord_c ord c if ord_c < 128 if ord_c > 31 htmlentities.append c else try htmlentities.append '&%s;' % codepoint2name[ord_c] except KeyError passreturn ''.join htmlentities
def validate_resampler_func method args kwargs if len args + len kwargs > 0 if method in RESAMPLER_NUMPY_OPS raise UnsupportedFunctionCall 'numpyoperationsarenotvalidwithresample.Use.resample ... .{func} instead'.format func method else raise TypeError 'toomanyargumentspassedin'
def make_readable fn st os.stat fn st_mode st.st_moderead_all stat.S_IRUSRread_all | stat.S_IRGRPread_all | stat.S_IROTHos.chmod fn st_mode | read_all
def resource_create_default_resource_views context data_dict resource_dict _get_or_bust data_dict 'resource' _check_access 'resource_create_default_resource_views' context data_dict dataset_dict data_dict.get 'package' create_datastore_views paste.deploy.converters.asbool data_dict.get 'create_datastore_views' False return ckan.lib.datapreview.add_views_to_resource context resource_dict dataset_dict view_types [] create_datastore_views create_datastore_views
@check_event_permissionsdef cancel_occurrence request event_id template_name 'schedule/cancel_occurrence.html' *args **kwargs event occurrence get_occurrence event_id *args **kwargs next kwargs.get 'next' None or get_next_url request event.get_absolute_url if request.method ! 'POST' return render_to_response template_name {'occurrence' occurrence 'next' next} context_instance RequestContext request occurrence.cancel return HttpResponseRedirect next
def object_build_methoddescriptor node member localname func build_function getattr member '__name__' None or localname doc member.__doc__ func.args.args Nonenode.add_local_node func localname
def quoteStringArgument argument return argument.replace '\\' '\\\\' .replace ' ' '\\ '
def lastColorizedLine source if not isinstance source bytes source source.encode 'utf-8' w VT102Writer p TokenPrinter w.write .printtokens BytesIO source for token in _tokenize s.readline tokenType string start end line tokenp tokenType string start end line line str w .encode 'utf-8' return line
def vary_on_headers *headers def decorator func @wraps func def inner_func *args **kwargs response func *args **kwargs patch_vary_headers response headers return responsereturn inner_funcreturn decorator
def AreaUnderCurve x y if x.shape[0] ! y.shape[0] raise ValueError 'xandyshouldhavethesameshapetocomputeareaundercurve butx.shape %sandy.shape %s.' % x.shape y.shape if x.shape[0] < 2 raise ValueError 'Atleast2pointsareneededtocomputeareaundercurve butx.shape %s' % x.shape order np.argsort x x x[order]y y[order]h np.diff x area np.sum h * y[1 ] + y[ -1 ] / 2.0 return area
def spatiotemporal_cubes file_tuples shape n_patches numpy.inf rng None frame_lookup FrameLookup [ a b[0] for a b in file_tuples] file_lookup OrderedDict file_tuples patch_length patch_height patch_width shapedone 0rng make_np_rng rng which_method 'random_integers' while done < n_patches frame rng.random_integers 0 len frame_lookup - 1 filename file_length frame_no frame_lookup[frame]if file_length - frame_no < patch_length continue _ video_height video_width file_lookup[filename][ 3]last_row video_height - patch_height last_col video_width - patch_width row rng.random_integers 0 last_row col rng.random_integers 0 last_col patch_slice slice frame_no frame_no + patch_length slice row row + patch_height slice col col + patch_width done + 1 yield filename patch_slice
def list_floating_ips call None if call 'action' raise SaltCloudSystemExit 'Thelist_floating_ipsfunctionmustbecalledwith-for--function orwiththe--list-floating-ipsoption' fetch Truepage 1ret {}while fetch items query method 'floating_ips' command '?page ' + str page + '&per_page 200' for floating_ip in items['floating_ips'] ret[floating_ip['ip']] {}for item in six.iterkeys floating_ip ret[floating_ip['ip']][item] floating_ip[item]page + 1try fetch 'next' in items['links']['pages'] except KeyError fetch Falsereturn ret
def _get_list_of_tables tables from .table import Table Rowif not isinstance tables collections.Sequence tables [tables]if any not isinstance x Table Row for x in tables or len tables 0 raise TypeError u'`tables`argmustbeaTableorsequenceofTablesorRows' tables [ x if isinstance x Table else Table x for x in tables]return tables
def patch_time from gevent.hub import sleepimport timepatch_item time 'sleep' sleep
def get_errno_name n if isinstance n string_t return getattr errno n return n
def get_tab_entry_info entry separator needle index path None None None match_needle re.search ' .*? ' + separator entry match_index re.search separator + ' [0-9]{1} ' entry match_path re.search separator + '[0-9]{1}' + separator + ' .* ' entry if match_needle needle match_needle.group 1 if match_index index int match_index.group 1 if match_path path match_path.group 1 return needle index path
def get_tempurl_keys_from_metadata meta return [get_valid_utf8_str value for key value in meta.items if key.lower in 'temp-url-key' 'temp-url-key-2' ]
def _sanitize_ipv4_mapping ip_str if not ip_str.lower .startswith '0000 0000 0000 0000 0000 ffff ' return ip_strhextets ip_str.split ' ' if '.' in hextets[ -1 ] return ip_stripv4_address '%d.%d.%d.%d' % int hextets[6][0 2] 16 int hextets[6][2 4] 16 int hextets[7][0 2] 16 int hextets[7][2 4] 16 result ' '.join hextets[0 6] result + ' ' + ipv4_address return result
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def convert in_file in_format out_file out_format in_kwargs None out_kwargs None if in_kwargs is None in_kwargs {}if out_kwargs is None out_kwargs {}qresults parse in_file in_format **in_kwargs return write qresults out_file out_format **out_kwargs
def make_substitutions conf r re.compile CONF_VARIABLE_REGEX def sub s depth 0 if depth > 100 logging.warn 'Maxrecursiondepthexceededwhensubstitutingjobconfvalue %s' % s return sm r.search s if m for g in [g for g in m.groups if g in conf ] substr '${%s}' % g s s.replace substr sub conf[g] depth + 1 return sfor k v in conf.items conf[k] sub v return conf
def is_online user return user.lastseen > time_diff
def cholesky_banded ab overwrite_ab False lower False check_finite True if check_finite ab asarray_chkfinite ab else ab asarray ab pbtrf get_lapack_funcs 'pbtrf' ab c info pbtrf ab lower lower overwrite_ab overwrite_ab if info > 0 raise LinAlgError '%d-thleadingminornotpositivedefinite' % info if info < 0 raise ValueError 'illegalvaluein%d-thargumentofinternalpbtrf' % - info return c
@register.inclusion_tag 'authority/permission_request_approve_link.html' takes_context True def permission_request_approve_link context perm user context['request'].userif user.is_authenticated if user.has_perm 'authority.approve_permission_requests' return base_link context perm 'authority-approve-permission-request' return {'url' None}
def dump_body m body body m.body if body is None else body if isinstance body buffer_t body bytes_t body return u'{0} {1}b '.format truncate safe_repr body 1024 len m.body
def run _task
def symptom_keys_in_Fernet_key_repository fernet_utils utils.FernetUtils CONF.fernet_tokens.key_repository CONF.fernet_tokens.max_active_keys return 'fernet' in CONF.token.provider and not fernet_utils.load_keys
@register_opt @local_optimizer [GpuContiguous] def local_gpu_contiguous_gpu_contiguous node if isinstance node.op GpuContiguous inp node.inputs[0]if inp.owner and isinstance inp.owner.op GpuContiguous return [inp]
def enable_log_to_stdout logname log logging.getLogger logname log.setLevel logging.DEBUG ch logging.StreamHandler ch.setLevel logging.DEBUG formatter logging.Formatter u'% asctime s-% name s-% levelname s-% message s' ch.setFormatter formatter log.addHandler ch
def test_root_mean_absolute_error y_real np.array [0.0 1.0 0.0 2.0 3.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_equals 0.0 mean_absolute_error y_real y_pred y_real np.array [3.0 1.0 2.0 1.0 1.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_almost_equals 1.6 mean_absolute_error y_real y_pred
def _loc loc_str expected_seq_length strand if ' ' in loc_str ref loc_str loc_str.split ' ' else ref Nonetry s e loc_str.split '..' except ValueError assert '..' not in loc_str if '^' in loc_str s e loc_str.split '^' if int s + 1 int e pos _pos s elif int s expected_seq_length and e '1' pos _pos s else raise ValueError 'Invalidbetweenlocation%s' % repr loc_str return SeqFeature.FeatureLocation pos pos strand ref ref else s loc_stre loc_strreturn SeqFeature.FeatureLocation _pos s -1 _pos e strand ref ref
def _change_state name action expected *args **kwargs pre state name if action ! 'restart' and pre expected return {'result' False 'state' {'old' expected 'new' expected} 'comment' "Container'{0}'already{1}".format name expected }_client_wrapper action name *args **kwargs _clear_context try post state name except CommandExecutionError post Noneret {'result' post expected 'state' {'old' pre 'new' post}}return ret
def build_fault cls e tb include_traceback False if hasattr cls '_amf_code' code cls._amf_codeelse code cls.__name__details Noneif include_traceback details traceback.format_exception cls e tb return remoting.ErrorFault code code description unicode e details details
def opendir_dialog caption path options QtWidgets.QFileDialog.ShowDirsOnly | QtWidgets.QFileDialog.DontResolveSymlinks return compat.getexistingdirectory parent active_window caption caption basedir path options options
def getHex value return hex value
def atoi s try return int s or '0' except ValueError return 0
def parse_css_data props {}for names values in PROPERTY_DICT.items allowed_values []for value in values if value[0] '<' and value[ -1 ] '>' key value[1 -1 ]if key in COMMON_VALUES allowed_values + COMMON_VALUES[key]else allowed_values.append value allowed_values + ['all' 'inherit' 'initial' 'unset']for name in names.split props[name] sorted allowed_values return props
def test_lex_mangling_bang entry tokenize 'foo!' assert entry [HySymbol 'foo_bang' ] entry tokenize '!' assert entry [HySymbol '!' ] entry tokenize 'im!foo' assert entry [HySymbol 'im!foo' ] entry tokenize '.foo!' assert entry [HySymbol '.foo_bang' ] entry tokenize 'foo.bar!' assert entry [HySymbol 'foo.bar_bang' ] entry tokenize 'foo!.bar' assert entry [HySymbol 'foo_bang.bar' ] entry tokenize '.foo!.bar.baz!' assert entry [HySymbol '.foo_bang.bar.baz_bang' ]
def show_artifact id_ return show_item 'artifact' id_
def my_kde_bandwidth obj fac 1.0 / 5 return np.power obj.n -1.0 / obj.d + 4 * fac
def dyld_image_suffix_search iterator env None suffix dyld_image_suffix env if suffix is None return iteratordef _inject iterator iterator suffix suffix for path in iterator if path.endswith '.dylib' yield path[ - len '.dylib' ] + suffix + '.dylib' else yield path + suffix yield path return _inject
def file_like name return os.path.exists name or os.path.dirname name or name.endswith '.py' or not ident_re.match os.path.splitext name [0]
def _wrappedLogPrefix wrapper wrapped if ILoggingContext.providedBy wrapped logPrefix wrapped.logPrefix else logPrefix wrapped.__class__.__name__return '%s %s ' % logPrefix wrapper.__class__.__name__
def discover_sensors topic payload parts topic.split '/' unit payload.get 'units' '' domain parts[1]if domain 'temperature' name parts[2]if unit 'F' unit TEMP_FAHRENHEITelse unit TEMP_CELSIUSreturn ArwnSensor name 'temp' unit if domain 'barometer' return ArwnSensor 'Barometer' 'pressure' unit if domain 'wind' return ArwnSensor 'WindSpeed' 'speed' unit ArwnSensor 'WindGust' 'gust' unit ArwnSensor 'WindDirection' 'direction' '\xc2\xb0'
def _raw_fft x n axis direction overwrite_x work_function if n is None n x.shape[axis]elif n ! x.shape[axis] x copy_made _fix_shape x n axis overwrite_x overwrite_x or copy_made if n < 1 raise ValueError 'InvalidnumberofFFTdatapoints %d specified.' % n if axis -1 or axis len x.shape - 1 r work_function x n direction overwrite_x overwrite_x else x swapaxes x axis -1 r work_function x n direction overwrite_x overwrite_x r swapaxes r axis -1 return r
def allcap_differential words is_different Falseallcap_words 0for word in words if word.isupper allcap_words + 1cap_differential len words - allcap_words if cap_differential > 0 and cap_differential < len words is_different Truereturn is_different
def get_osarch ret subprocess.Popen 'rpm--eval"%{_host_cpu}"' shell True close_fds True stdout subprocess.PIPE stderr subprocess.PIPE .communicate [0]return ret or 'unknown'
def direct_get_account node part account marker None limit None prefix None delimiter None conn_timeout 5 response_timeout 15 end_marker None reverse None path '/' + account return _get_direct_account_container path 'Account' node part marker marker limit limit prefix prefix delimiter delimiter end_marker end_marker reverse reverse conn_timeout conn_timeout response_timeout response_timeout
def has_handshake_pyrit target capfile if not program_exists 'pyrit' return Falsecmd ['pyrit' '-r' capfile 'analyze']proc Popen cmd stdout PIPE stderr DN proc.wait hit_essid Falsefor line in proc.communicate [0].split '\n' if line '' or line None continueif line.find 'AccessPoint' ! -1 hit_essid line.find " '" + target.ssid + "' " ! -1 and line.lower .find target.bssid.lower ! -1 elif hit_essid and line.find ' good ' ! -1 or line.find ' workable ' ! -1 return Truereturn False
def _get_opt method opts {'allow' '-a' 'deny' '-d' 'unallow' '-ar' 'undeny' '-dr' 'tempallow' '-ta' 'tempdeny' '-td' 'temprm' '-tr'}return opts[method]
def _get_index_and_key nodes position nodes_before [c for c in nodes if c.start_pos < position ]if nodes_before[ -1 ].type 'arglist' nodes_before [c for c in nodes_before[ -1 ].children if c.start_pos < position ]key_str Noneif nodes_before last nodes_before[ -1 ]if last.type 'argument' and last.children[1].end_pos < position key_str last.children[0].valueelif last ' ' key_str nodes_before[ -2 ].valuereturn nodes_before.count ' ' key_str
def public_decrypt pub message verifier salt.utils.rsax931.RSAX931Verifier pub.exportKey 'PEM' return verifier.verify message
def attach_handlers app settings if settings.USE_POSTGRES add_handlers app django_handlers.handlers else add_handlers app mongo_handlers.handlers add_handlers app celery_task_handlers.handlers add_handlers app transaction_handlers.handlers add_handlers app postcommit_handlers.handlers add_handlers app {'before_request' framework.sessions.prepare_private_key} add_handlers app {'before_request' framework.sessions.before_request 'after_request' framework.sessions.after_request} return app
def _prompt_user_variable var_name default_value return click.prompt var_name default default_value
def validate_hooks config validate_hook config.pre_hook 'pre' validate_hook config.post_hook 'post' validate_hook config.renew_hook 'renew'
def paths_to_3d_segments_with_codes paths zs 0 zdir u'z' if not iterable zs zs np.ones len paths * zs segments []codes_list []for path pathz in zip paths zs segs codes path_to_3d_segment_with_codes path pathz zdir segments.append segs codes_list.append codes return segments codes_list
def interfaces4 all False out {}for name addrs in interfaces all all .items addrs [addr for fam addr in addrs if fam socket.AF_INET ]if addrs or all out[name] addrsreturn out
def find_xem_absolute_numbering indexer_id indexer absolute_number if indexer_id is None or absolute_number is None return absolute_numberindexer_id int indexer_id indexer int indexer xem_refresh indexer_id indexer main_db_con db.DBConnection rows main_db_con.select 'SELECTscene_absolute_numberFROMtv_episodesWHEREindexer ?andshowid ?andabsolute_number ?andscene_absolute_number! 0' [indexer indexer_id absolute_number] if rows return int rows[0]['scene_absolute_number']
def _dark_parse_accept_lang_header accept browser_langs parse_accept_lang_header accept django_langs []for lang priority in browser_langs lang CHINESE_LANGUAGE_CODE_MAP.get lang.lower lang django_langs.append lang priority return django_langs
def _increase_indent global _INDENT_INDENT + _INDENT_STEP
def cluster_setup nodes pcsclustername 'pcscluster' extra_args None cmd ['pcs' 'cluster' 'setup']cmd + ['--name' pcsclustername]cmd + nodesif isinstance extra_args list tuple cmd + extra_argsreturn __salt__['cmd.run_all'] cmd output_loglevel 'trace' python_shell False
def dummy pass
def libvlc_audio_output_list_release p_list f _Cfunctions.get 'libvlc_audio_output_list_release' None or _Cfunction 'libvlc_audio_output_list_release' 1 None None ctypes.POINTER AudioOutput return f p_list
def libvlc_get_fullscreen p_mi f _Cfunctions.get 'libvlc_get_fullscreen' None or _Cfunction 'libvlc_get_fullscreen' 1 None ctypes.c_int MediaPlayer return f p_mi
def add_catalog_discover_hack service_type old new _discover._VERSION_HACKS.add_discover_hack service_type old new
def find_scopes_for_services service_names None result_scopes []if service_names is None for service_name scopes in AUTH_SCOPES.iteritems result_scopes.extend scopes else for service_name in service_names result_scopes.extend AUTH_SCOPES[service_name] return result_scopes
def RenderHttpResponse request start_time time.time response HTTP_REQUEST_HANDLER.HandleRequest request total_time time.time - start_time log.LOGGER.LogHttpApiCall request response method_name response.get 'X-API-Method' 'unknown' if response.status_code 200 status 'SUCCESS'elif response.status_code 403 status 'FORBIDDEN'elif response.status_code 404 status 'NOT_FOUND'elif response.status_code 501 status 'NOT_IMPLEMENTED'else status 'SERVER_ERROR'if request.method 'HEAD' metric_name 'api_access_probe_latency'else metric_name 'api_method_latency'stats.STATS.RecordEvent metric_name total_time fields method_name 'http' status return response
def export string template None **extra def wrapped f endpoint f.__module__ + '.' + f.__name__ [16 ]if template is not None old_f fdef f **kwargs rv old_f **kwargs if not isinstance rv Response rv TemplateResponse template ** rv or {} return rvf.__name__ old_f.__name__f.__doc__ old_f.__doc__exported_views[endpoint] f string extra return freturn wrapped
def create_containers logger conf _func_on_containers logger conf 'put_concurrency' client.put_container
def assert_rpm_headers test_case expected_headers rpm_path output check_output ['rpm' '--query' '--info' '--package' rpm_path.path] actual_headers parse_colon_dict output assert_dict_contains test_case expected_headers actual_headers 'MissingRPMHeaders '
def is_running_from_reloader return os.environ.get 'WERKZEUG_RUN_MAIN' 'true'
def detect_range line None if '[' in line return Trueelse return False
def _upgrade_schema engine inspector reflection.Inspector.from_engine engine conn engine.connect if 'task_id' not in [x['name'] for x in inspector.get_columns 'tasks' ] logger.warn 'UpgradingDbTaskHistoryschema Addingtasks.task_id' conn.execute 'ALTERTABLEtasksADDCOLUMNtask_idVARCHAR 200 ' conn.execute 'CREATEINDEXix_task_idONtasks task_id '
def normalize_eols raw_contents lines_list raw_contents.splitlines if lines_list and lines_list[ -1 ] lines_list.append '' return '\n'.join lines_list
@not_implemented_for 'undirected' def dag_longest_path G weight 'weight' default_weight 1 dist {}for v in nx.topological_sort G us [ dist[u][0] + data.get weight default_weight u for u data in G.pred[v].items ]maxu max us key lambda x x[0] if us else 0 v dist[v] maxu if maxu[0] > 0 else 0 v u Nonev max dist key lambda x dist[x][0] path []while u ! v path.append v u vv dist[v][1]path.reverse return path
def determine_how_to_read_input input_obj get_chunk Noneif isinstance input_obj Queue log_msg 'queue'get_chunk get_queue_chunk_reader input_obj elif callable input_obj log_msg 'callable'get_chunk get_callable_chunk_reader input_obj elif hasattr input_obj 'read' log_msg 'filedescriptor'get_chunk get_file_chunk_reader input_obj elif isinstance input_obj basestring log_msg 'string'get_chunk get_iter_string_reader input_obj elif isinstance input_obj bytes log_msg 'bytes'get_chunk get_iter_string_reader input_obj elif isinstance input_obj GeneratorType log_msg 'generator'get_chunk get_iter_chunk_reader iter input_obj else try it iter input_obj except TypeError raise Exception 'unknowninputobject' else log_msg 'generaliterable'get_chunk get_iter_chunk_reader it return get_chunk log_msg
def _block_shape values ndim 1 shape None if values.ndim < ndim if shape is None shape values.shapevalues values.reshape tuple 1 + shape return values
def SetCustomFonts rmldoc for family font filename mode in CustomTTFonts if os.path.isabs filename and os.path.exists filename rmldoc.setTTFontMapping family font filename mode return True
def _open_logfile logfile_base_name timestamp int time.time while True logfile_name '%s.%d-%d.gz' % logfile_base_name timestamp os.getpid if not os.path.exists logfile_name breaktimestamp + 1logfile gzip.GzipFile logfile_name 'w' return logfile
def isiterable obj return hasattr obj '__iter__'
def _create_shape flat_names try _ shape_str flat_names[ -1 ].rsplit '__' 1 except ValueError return return tuple int i + 1 for i in shape_str.split '_'
@blueprint.route '/projects/<project>/meters/<meter>' def list_samples_by_project project meter check_authorized_project project return _list_samples project project meter meter
def _item_to_table iterator resource return Table.from_api_repr resource iterator.dataset
def clique_removal G graph G.copy with_data False c_i i_i ramsey.ramsey_R2 graph cliques [c_i]isets [i_i]while graph graph.remove_nodes_from c_i c_i i_i ramsey.ramsey_R2 graph if c_i cliques.append c_i if i_i isets.append i_i maxiset max isets key len return maxiset cliques
def getAxialMargin circleRadius numberOfSides polygonRadius return polygonRadius * math.sin math.pi / float numberOfSides - circleRadius
def format_to_raw context method None raise NotImplementedError 'rawformatisnotsupportedyet'
def to_choices x return [ y y for y in x]
def setencoding encoding 'ascii'if 0 import localeloc locale.getdefaultlocale if loc[1] encoding loc[1]if 0 encoding 'undefined'if encoding ! 'ascii' sys.setdefaultencoding encoding
def _convert_nn_nl val if val < 20 return to_19_nl[val]for dcap dval in k 20 + 10 * v for v k in enumerate tens_nl if dval + 10 > val if val % 10 return dcap + '-' + to_19_nl[ val % 10 ] return dcap
def test_routing_instance class EndPoint object @hug.objectdef one self return 'one'@hug.objectdef two self return 2hug.object.get EndPoint assert hug.test.get api 'one' .data 'one' assert hug.test.get api 'two' .data 2
def _step_parameters step param_map legacy False param_dict param_map.get step.tool_id {} .copy if legacy param_dict.update param_map.get str step.id {} else param_dict.update param_map.get str step.order_index {} step_uuid step.uuidif step_uuid uuid_params param_map.get str step_uuid {} param_dict.update uuid_params if param_dict if 'param' in param_dict and 'value' in param_dict param_dict[param_dict['param']] param_dict['value']del param_dict['param']del param_dict['value']new_params _flatten_step_params param_dict return new_params
def command from fabtools.require.deb import package as require_deb_packagefrom fabtools.require.rpm import package as require_rpm_packagefrom fabtools.require.portage import package as require_portage_packagefrom fabtools.system import distrib_familyres run 'bzr--version' quiet True if res.failed family distrib_family if family 'debian' require_deb_package 'bzr' elif family 'gentoo' require_portage_package 'bzr' elif family 'redhat' require_rpm_package 'bzr' else raise UnsupportedFamily supported ['debian' 'redhat' 'gentoo']
@treeio_login_required@handle_response_format@_process_mass_formdef index request response_format 'html' if request.GET filters FilterForm request.GET if filters.is_valid query _get_filter_query request.GET else query Q else query Q filters FilterForm events Object.filter_by_request request Event.objects.filter query context _get_default_context request context.update {'events' events 'filters' filters} return render_to_response 'events/index' context context_instance RequestContext request response_format response_format
def find_json raw ret {}for ind in range len raw working '\n'.join raw.splitlines [ind ] try ret json.loads working object_hook decode_dict except ValueError continueif ret return retif not ret raise ValueError
def _m_isenabled if HAS_UPSTART return MagicMock return_value True else return MagicMock return_value False
def _select_namespaces_query context session LOG.debug 'context.is_admin % is_admin s;context.owner % owner s' {'is_admin' context.is_admin 'owner' context.owner} query_ns session.query models.MetadefNamespace if context.is_admin return query_nselse if context.owner is not None query query_ns.filter or_ models.MetadefNamespace.owner context.owner models.MetadefNamespace.visibility 'public' else query query_ns.filter models.MetadefNamespace.visibility 'public' return query
def make_diff_image im1 im2 ds im1.shapees im2.shapediff np.empty max ds[0] es[0] max ds[1] es[1] 4 dtype int diff[... 3] 128diff[... 3] 255diff[ ds[0] ds[1] min ds[2] 3 ] + im1[... 3]diff[ es[0] es[1] min es[2] 3 ] - im2[... 3]diff np.clip diff 0 255 .astype np.ubyte return diff
def get_quantifier ch input_iter if ch in '*?+' try ch2 escaped input_iter.next except StopIteration ch2 Noneif ch2 '?' ch2 Noneif ch '+' return 1 ch2 return 0 ch2 quant []while ch ! '}' ch escaped input_iter.next quant.append ch quant quant[ -1 ]values ''.join quant .split ' ' try ch escaped input_iter.next except StopIteration ch Noneif ch '?' ch Nonereturn int values[0] ch
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def _build_html_image img id div_klass img_klass caption None show True html []add_style u'' if show else u'style "display none"' html.append u'<liclass "%s"id "%s"%s>' % div_klass id add_style html.append u'<divclass "thumbnail">' html.append u'<imgclass "%s"alt ""style "width 90%%;"src "data image/png;base64 %s">' % img_klass img html.append u'</div>' if caption html.append u'<h4>%s</h4>' % caption html.append u'</li>' return u'\n'.join html
def send_emails_to_subscribers creator_id exploration_id exploration_title creator_name user_services.get_username creator_id email_subject '%shaspublishedanewexploration!' % creator_name email_body_template 'Hi%s <br><br>%shaspublishedanewexploration!Youcanplayithere <ahref "https //www.oppia.org/explore/%s">%s</a><br><br>Thanks andhappylearning!<br><br>Bestwishes <br>-TheOppiaTeam<br><br>%s'if not feconf.CAN_SEND_EMAILS log_new_error 'Thisappcannotsendemailstousers.' returnif not feconf.CAN_SEND_SUBSCRIPTION_EMAILS log_new_error 'Thisappcannotsendsubscriptionemailstousers.' returnrecipient_list subscription_services.get_all_subscribers_of_creator creator_id recipients_usernames user_services.get_usernames recipient_list recipients_preferences user_services.get_users_email_preferences recipient_list for index username in enumerate recipients_usernames if recipients_preferences[index].can_receive_subscription_email email_body email_body_template % username creator_name exploration_id exploration_title EMAIL_FOOTER.value _send_email recipient_list[index] feconf.SYSTEM_COMMITTER_ID feconf.EMAIL_INTENT_SUBSCRIPTION_NOTIFICATION email_subject email_body feconf.NOREPLY_EMAIL_ADDRESS
def connect_to_mongodb db host port 27017 tz_aware True user None password None retry_wait_time 0.1 proxy True **kwargs if kwargs.get 'replicaSet' mongo_client_class pymongo.MongoReplicaSetClientelse mongo_client_class pymongo.MongoClientmongo_conn pymongo.database.Database mongo_client_class host host port port tz_aware tz_aware document_class dict **kwargs db if proxy mongo_conn MongoProxy mongo_conn wait_time retry_wait_time if user is not None and password is not None mongo_conn.authenticate user password return mongo_conn
def setAttributeDictionaryToMatrix attributeDictionary matrix4X4 matrixTetragrid getIdentityMatrixTetragrid matrix4X4.matrixTetragrid for row in xrange 4 for column in xrange 4 key getMatrixKey row column attributeDictionary[key] str matrixTetragrid[row][column]
def register_opt2 tracks *tags **kwargs def f local_opt name kwargs and kwargs.pop 'name' or local_opt.__name__ if isinstance local_opt theano.gof.DB opt local_optelse opt theano.gof.local_optimizer tracks local_opt gpu_optimizer2.register name opt 'fast_run' 'gpuarray' *tags return local_optreturn f
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def _rank_dists ranks1 ranks2 ranks1 dict ranks1 ranks2 dict ranks2 for k in ranks1 try yield k ranks1[k] - ranks2[k] except KeyError pass
def Value typecode_or_type *args **kwds from multiprocessing.sharedctypes import Valuereturn Value typecode_or_type *args **kwds
def show_volume kwargs None call None if not kwargs kwargs {}return describe_volumes kwargs call
def course_filename_prefix_generator course_id separator '_' return get_valid_filename unicode separator .join [course_id.org course_id.course course_id.run]
def set_cmap cmap cmap cm.get_cmap cmap rc u'image' cmap cmap.name im gci if im is not None im.set_cmap cmap
def event_location return s3_rest_controller
def remove_admin_access_permissions apps schema_editor ContentType apps.get_model u'contenttypes.ContentType' Permission apps.get_model u'auth.Permission' wagtailadmin_content_type ContentType.objects.get app_label u'wagtailadmin' model u'admin' Permission.objects.filter content_type wagtailadmin_content_type codename u'access_admin' .delete
def busday_count_mask_NaT begindates enddates out None if out is None out empty broadcast begindates enddates .shape dtype float beginmask isnat begindates endmask isnat enddates out busday_count where beginmask _notNaT begindates where endmask _notNaT enddates out out out[ beginmask | endmask ] nanreturn out
def clean_noise output_string for noise in NOISE output_string output_string.replace noise + '\n' '' output_string output_string.replace noise '' return output_string
def tensorhead name typ sym comm 0 matrix_behavior 0 sym tensorsymmetry *sym S TensorType typ sym th S name comm matrix_behavior matrix_behavior return th
def pick_channels_cov orig include [] exclude 'bads' exclude orig['bads'] if exclude 'bads' else exclude sel pick_channels orig['names'] include include exclude exclude res deepcopy orig res['dim'] len sel if not res['diag'] res['data'] orig['data'][sel][ sel]else res['data'] orig['data'][sel]res['names'] [orig['names'][k] for k in sel]res['bads'] [name for name in orig['bads'] if name in res['names'] ]res['eig'] Noneres['eigvec'] Nonereturn res
def _AddMockJSONResponse mock_client url response_dict def _CreateResponse request return httpclient.HTTPResponse request 200 headers {'Content-Type' 'application/json'} buffer StringIO json.dumps response_dict mock_client.map url _CreateResponse
def no_style class dummy def __getattr__ self attr return lambda x x return dummy
def WSGIServer server_address wsgi_app from . import wsgiserverwsgiserver.ssl_adapters {'builtin' 'web.wsgiserver.ssl_builtin.BuiltinSSLAdapter' 'pyopenssl' 'web.wsgiserver.ssl_pyopenssl.pyOpenSSLAdapter'}server wsgiserver.CherryPyWSGIServer server_address wsgi_app server_name 'localhost' def create_ssl_adapter cert key import typescherrypy types.ModuleType 'cherrypy' cherrypy.wsgiserver wsgiserversys.modules['cherrypy'] cherrypysys.modules['cherrypy.wsgiserver'] wsgiserverfrom wsgiserver.ssl_pyopenssl import pyOpenSSLAdapteradapter pyOpenSSLAdapter cert key del sys.modules['cherrypy']del sys.modules['cherrypy.wsgiserver']return adapterif server.ssl_adapter is None and getattr server 'ssl_certificate' None and getattr server 'ssl_private_key' None server.ssl_adapter create_ssl_adapter server.ssl_certificate server.ssl_private_key server.nodelay not sys.platform.startswith 'java' return server
def cfset_to_set cfset count cf.CFSetGetCount cfset buffer c_void_p * count cf.CFSetGetValues cfset byref buffer return set [cftype_to_value c_void_p buffer[i] for i in range count ]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _encode_int name value dummy0 dummy1 if -2147483648 < value < 2147483647 return '\x10' + name + _PACK_INT value else try return '\x12' + name + _PACK_LONG value except struct.error raise OverflowError 'BSONcanonlyhandleupto8-byteints'
def libvlc_media_player_set_equalizer p_mi p_equalizer f _Cfunctions.get 'libvlc_media_player_set_equalizer' None or _Cfunction 'libvlc_media_player_set_equalizer' 1 1 None ctypes.c_int MediaPlayer ctypes.c_void_p return f p_mi p_equalizer
def num_plurals catalog message if not message.pluralizable if not isinstance message.string basestring raise TranslationError 'Foundpluralformsfornon-pluralizablemessage' returnelif catalog is None returnmsgstrs message.stringif not isinstance msgstrs list tuple msgstrs msgstrs if len msgstrs ! catalog.num_plurals raise TranslationError 'Wrongnumberofpluralforms expected%d ' % catalog.num_plurals
def parse_rescue rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--nomount' dest 'nomount' action 'store_true' parser.add_argument '--romount' dest 'romount' action 'store_true' args clean_args vars parser.parse_args rules parser Nonereturn args
def gen_dom_authzr domain unused_new_authzr_uri challs combos True return acme_util.gen_authzr messages.STATUS_PENDING domain challs [messages.STATUS_PENDING] * len challs combos
def _inv_totient_estimate m primes [ d + 1 for d in divisors m if isprime d + 1 ] a b 1 1 for p in primes a * pb * p - 1 L mU int math.ceil m * float a / b P p 2primes []while P < U p nextprime p primes.append p P * pP // pb 1for p in primes[ -1 ] b * p - 1 U int math.ceil m * float P / b return L U
def submit_problem_grade_report request course_key task_type 'grade_problems'task_class calculate_problem_grade_reporttask_input {}task_key ''return submit_task request task_type task_class course_key task_input task_key
def find_title url verify True response requests.get url stream True verify verify headers default_headers try content ''for byte in response.iter_content chunk_size 512 content + byteif '</title>' in content or len content > max_bytes breakcontent content.decode u'utf-8' errors u'ignore' finally response.close content title_tag_data.sub u'<\\1title>' content content quoted_title.sub u'' content start content.find u'<title>' end content.find u'</title>' if start -1 or end -1 returntitle web.decode content[ start + 7 end] title title.strip [ 200]title u''.join title.split title re_dcc.sub u'' title return title or None
def _status_apf status 0table iptc.Table iptc.Table.FILTER for chain in table.chains if 'sanity' in chain.name.lower status 1return True if status else False
def Maxwell name a return rv name MaxwellDistribution a
def underline regions r []for region in regions start region.begin end region.end while start < end r.append sublime.Region start start + 1return r
def ffmpeg_extract_subclip filename t1 t2 targetname None name ext os.path.splitext filename if not targetname T1 T2 [int 1000 * t for t in [t1 t2]]targetname name + '%sSUB%d_%d.%s' name T1 T2 ext cmd [get_setting 'FFMPEG_BINARY' '-y' '-i' filename '-ss' '%0.2f' % t1 '-t' '%0.2f' % t2 - t1 '-vcodec' 'copy' '-acodec' 'copy' targetname]subprocess_call cmd
def _invalidate_queue q val None sync True def _qsize len len return 1def _put item passdef _get return valif sync q.mutex.acquire try q.maxsize 2q._qsize _qsizeq._put _putq._get _getq.not_empty.notifyAll q.not_full.notifyAll finally if sync q.mutex.release
def dot inp matrix if 'int' in inp.dtype and inp.ndim 2 return matrix[inp.flatten ]elif 'int' in inp.dtype return matrix[inp]elif 'float' in inp.dtype and inp.ndim 3 shape0 inp.shape[0]shape1 inp.shape[1]shape2 inp.shape[2]return TT.dot inp.reshape shape0 * shape1 shape2 matrix else return TT.dot inp matrix
def _has_effective_handler logger while True if logger.handlers return Trueif not logger.parent return Falselogger logger.parent
def openExplorer filename if sys.platform 'win32' or sys.platform 'cygwin' subprocess.Popen 'explorer/select "%s"' % filename if sys.platform 'darwin' subprocess.Popen ['open' '-R' filename] if sys.platform.startswith 'linux' if os.path.isfile '/usr/bin/xdg-open' subprocess.Popen ['/usr/bin/xdg-open' os.path.split filename [0]]
def calc_easing_degree_for_proportion proportion return - math.log10 proportion + 1
def get_versioned_asset_url asset_path try locator StaticContent.get_location_from_path asset_path content AssetManager.find locator as_stream True return StaticContent.add_version_to_asset_path asset_path content.content_digest except InvalidKeyError ItemNotFoundError passreturn asset_path
def _get_declared_fields bases attrs fields [ field_name attrs.pop field_name for field_name obj in list six.iteritems attrs if isinstance obj Field ]fields.sort key lambda x x[1].creation_counter for base in bases[ -1 ] if hasattr base 'base_fields' fields list base.base_fields.items + fields return OrderedDict fields
def answer_entrance_exam_problem course request problem user None if not user user request.usergrade_dict {'value' 1 'max_value' 1 'user_id' user.id}field_data_cache FieldDataCache.cache_for_descriptor_descendents course.id user course depth 2 module get_module user request problem.scope_ids.usage_id field_data_cache ._xmodulemodule.system.publish problem 'grade' grade_dict
def is_case_sensitive path is_case_sensitive Falseif not iswindows name1 name2 'calibre_test_case_sensitivity.txt' 'calibre_TesT_CaSe_sensitiVitY.Txt' f1 f2 os.path.join path name1 os.path.join path name2 if os.path.exists f1 os.remove f1 open f1 'w' .close is_case_sensitive not os.path.exists f2 os.remove f1 return is_case_sensitive
def is_bsd return platform.system in 'Darwin' 'FreeBSD' 'OpenBSD'
def re_subm pat repl string r re_compile pat proxy _re_subm_proxy r.sub proxy.__call__ string return r.sub repl string proxy.match
def multislice_assign llst rlst lslices rslices if cmp_structure llst rlst lslices rslices < 0 raise ValueError 'lvalueandrvaluehavedifferentstructures' return m_assign llst rlst lslices rslices
def add_label_dependencies test _log_or_execute repr test test.dependency_labels.clear subject 'cleardependenciesfrom' for label_name in test.dependencies.split ' ' label_name label_name.strip .lower if not label_name continuetry label models.Label.objects.get name label_name except models.Label.DoesNotExist log_dependency_not_found label_name continue_log_or_execute repr label test.dependency_labels.add label subject 'adddependencyto%s' % test.name
def qos_specs_associate context qos_specs_id type_id return IMPL.qos_specs_associate context qos_specs_id type_id
def executeLeftOperations evaluators operationLevel for negativeIndex in xrange - len evaluators -1 evaluatorIndex negativeIndex + len evaluators evaluators[evaluatorIndex].executeLeftOperation evaluators evaluatorIndex operationLevel
def _find_handlers app_names handlers []for module_name in app_names handlers.extend _handlers module_name return handlers
def get_disk_usage d if platform.system 'Linux' try return int subprocess.Popen ['du' '-sb' d] stdout subprocess.PIPE .communicate [0].split [0] except raise CleanupException 'roscleanisnotsupportedonthisplatform' elif platform.system 'FreeBSD' try return int subprocess.Popen ['du' '-sA' d] stdout subprocess.PIPE .communicate [0].split [0] * 1024 except raise CleanupException 'roscleanisnotsupportedonthisplatform' else raise CleanupException 'roscleanisnotsupportedonthisplatform'
def zone_absent domain profile zones libcloud_dns_module.list_zones profile matching_zone [z for z in zones if z.domain domain ]if len matching_zone 0 return state_result True 'Zonealreadyabsent' else result libcloud_dns_module.delete_zone matching_zone[0].id profile return state_result result 'Deletedzone'
def send_catch_log signal Any sender Anonymous *arguments **named dont_log named.pop 'dont_log' _IgnoredException spider named.get 'spider' None responses []for receiver in liveReceivers getAllReceivers sender signal try response robustApply receiver signal signal sender sender *arguments **named if isinstance response Deferred logger.error 'Cannotreturndeferredsfromsignalhandler % receiver s' {'receiver' receiver} extra {'spider' spider} except dont_log result Failure except Exception result Failure logger.error 'Errorcaughtonsignalhandler % receiver s' {'receiver' receiver} exc_info True extra {'spider' spider} else result responseresponses.append receiver result return responses
def roc tests [] x FPR lambda TP TN FP FN float FP / FP + TN or 1 y TPR lambda TP TN FP FN float TP / TP + FN or 1 return sorted [ 0.0 0.0 1.0 1.0 ] + [ x *m y *m for m in tests]
def libvlc_media_new_callbacks instance open_cb read_cb seek_cb close_cb opaque f _Cfunctions.get 'libvlc_media_new_callbacks' None or _Cfunction 'libvlc_media_new_callbacks' 1 1 1 1 1 1 class_result Media ctypes.c_void_p Instance MediaOpenCb MediaReadCb MediaSeekCb MediaCloseCb ctypes.c_void_p return f instance open_cb read_cb seek_cb close_cb opaque
def _get_options raw_options apply_config if not raw_options return parse_args [u''] apply_config apply_config if isinstance raw_options dict options parse_args [u''] apply_config apply_config for name value in raw_options.items if not hasattr options name raise ValueError u"Nosuchoption'{}'".format name expected_type type getattr options name if not isinstance expected_type str unicode if isinstance value str unicode raise ValueError u"Option'{}'shouldnotbeastring".format name setattr options name value else options raw_optionsreturn options
def instance_logger instance echoflag None if instance.logging_name name '%s.%s.%s' % instance.__class__.__module__ instance.__class__.__name__ instance.logging_name else name '%s.%s' % instance.__class__.__module__ instance.__class__.__name__ instance._echo echoflagif echoflag in False None logger logging.getLogger name else logger InstanceLogger echoflag name instance.logger logger
def create_context_manager connection return IMPL.create_context_manager connection connection
def _intc_overflow x msg None if x > iinfo intc .max if msg is None msg '%rcannotfitintoanintc' % x raise OverflowError msg return intc x
def _image_property_update context prop_ref values session None _drop_protected_attrs models.ImageProperty values values['deleted'] Falseprop_ref.update values prop_ref.save session session return prop_ref
def get_vlan vlanid module command 'showvlanid' + vlanid body execute_show_command command module try vlan_table body[0]['TABLE_vlanbriefid']['ROW_vlanbriefid']except TypeError IndexError return {}key_map {'vlanshowbr-vlanid-utf' 'vlan_id' 'vlanshowbr-vlanname' 'name' 'vlanshowbr-vlanstate' 'vlan_state' 'vlanshowbr-shutstate' 'admin_state'}vlan apply_key_map key_map vlan_table value_map {'admin_state' {'shutdown' 'down' 'noshutdown' 'up'}}vlan apply_value_map value_map vlan vlan['mapped_vni'] get_vni vlanid module return vlan
def TaskMessage name id None args kwargs {} callbacks None errbacks None chain None shadow None utc None **options from celery import uuidfrom kombu.serialization import dumpsid id or uuid message Mock name u'TaskMessage-{0}'.format id message.headers {u'id' id u'task' name u'shadow' shadow}embed {u'callbacks' callbacks u'errbacks' errbacks u'chain' chain}message.headers.update options message.content_type message.content_encoding message.body dumps args kwargs embed serializer u'json' message.payload args kwargs embed return message
def _async_raise tid exctype if not inspect.isclass exctype raise TypeError 'Onlytypescanberaised notinstances ' res ctypes.pythonapi.PyThreadState_SetAsyncExc ctypes.c_long tid ctypes.py_object exctype if res 0 raise ValueError 'invalidthreadid' elif res ! 1 ctypes.pythonapi.PyThreadState_SetAsyncExc ctypes.c_long tid None raise SystemError 'PyThreadState_SetAsyncExcfailed'
@dec.skip_without 'pandas' def test_dataframe_key_completion import pandasip get_ipython complete ip.Completer.completeip.user_ns['d'] pandas.DataFrame {'hello' [1] 'world' [2]} _ matches complete line_buffer "d['" nt.assert_in 'hello' matches nt.assert_in 'world' matches
def urlquote_plus url safe u'' return force_text quote_plus force_str url force_str safe
def require_student_from_identifier unique_student_identifier try return get_student_from_identifier unique_student_identifier except User.DoesNotExist raise DashboardError _ 'Couldnotfindstudentmatchingidentifier {student_identifier}' .format student_identifier unique_student_identifier
def set_ssh_key public_key _xml '<RIBCLVERSION "2.0">\n<LOGINUSER_LOGIN "adminname"PASSWORD "password">\n<RIB_INFOMODE "write">\n<IMPORT_SSH_KEY>\n-----BEGINSSHKEY-----\n{0}\n-----ENDSSHKEY-----\n</IMPORT_SSH_KEY>\n</RIB_INFO>\n</LOGIN>\n</RIBCL>'.format public_key return __execute_cmd 'Import_SSH_Publickey' _xml
def get_RMSE results true_params diff results.params.reshape true_params.shape - true_params raw_RMSE sp.sqrt diff ** 2 .sum param_norm sp.sqrt true_params ** 2 .sum return raw_RMSE / param_norm
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def test_blocking_with_whitelist config_stub basedir download_stub data_tmpdir tmpdir filtered_blocked_hosts BLOCKLIST_HOSTS[1 ]blocklist create_blocklist data_tmpdir blocked_hosts filtered_blocked_hosts name 'blocked-hosts' line_format 'one_per_line' config_stub.data {'content' {'host-block-lists' [blocklist] 'host-blocking-enabled' True 'host-blocking-whitelist' WHITELISTED_HOSTS}}host_blocker adblock.HostBlocker host_blocker.read_hosts assert_urls host_blocker
def makeService config if config['file'] quoter quoters.FortuneQuoter [config['file']] else quoter quoters.StaticQuoter config['static'] port int config['port'] factory quoteproto.QOTDFactory quoter return internet.TCPServer port factory
def addModlist entry ignore_attr_types None ignore_attr_types list_dict map string.lower ignore_attr_types or [] modlist []for attrtype in entry.keys if ignore_attr_types.has_key string.lower attrtype continueattrvaluelist filter lambda x x ! None entry[attrtype] if attrvaluelist modlist.append attrtype entry[attrtype] return modlist
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def measure_runtime func def time_taken obj num 'Printsthetimetakenbyfunctorunagivennumberofsamples.\n\nArgs \nobj object.Theclassinstancefuncbelongsto.\nnum int.Thenumberofsamplestorunwith.\n\nReturns \nResultoffunc.\n'start time.time result func obj num end time.time print '%sspent%fsecondsfor%dinstances' % func.__name__ end - start num return resultreturn time_taken
def priority value def decorator target target.priority valuereturn targetreturn decorator
def revdict d return dict v k for k v in iteritems d
@click.command 'lets-encrypt' @click.argument 'site' @click.option '--custom-domain' def setup_letsencrypt site custom_domain from bench.config.lets_encrypt import setup_letsencryptsetup_letsencrypt site custom_domain bench_path '.'
def get_search_regex query ignore_case True regex_text [char for char in query if char ! '' ]regex_text '.*'.join regex_text regex ' {0} '.format regex_text if ignore_case pattern re.compile regex re.IGNORECASE else pattern re.compile regex return pattern
def le_ a b msg None assert a < b msg or '%r! %r' % a b
def lfu_cache maxsize 100 def decorating_function user_function cache {}use_count Counter kwd_mark object @functools.wraps user_function def wrapper *args **kwds key argsif kwds key + kwd_mark + tuple sorted kwds.items use_count[key] + 1try result cache[key]wrapper.hits + 1except KeyError result user_function *args **kwds cache[key] resultwrapper.misses + 1if len cache > maxsize for key _ in nsmallest maxsize // 10 use_count.iteritems key itemgetter 1 del cache[key] use_count[key]return resultdef clear cache.clear use_count.clear wrapper.hits wrapper.misses 0wrapper.hits wrapper.misses 0wrapper.clear clearreturn wrapperreturn decorating_function
def arrayizeValue value if not isListLike value value [value]return value
def test_exit assert usertypes.Exit.ok 0 assert usertypes.Exit.reserved 1
def wait_for_state vmid state timeout 300 start_time time.time node get_vm_status vmid vmid if not node log.error 'wait_for_state NoVMretrievedbasedongivencriteria.' raise SaltCloudExecutionFailurewhile True if node['status'] state log.debug 'Host{0}isnowin"{1}"state!'.format node['name'] state return Truetime.sleep 1 if time.time - start_time > timeout log.debug 'Timeoutreachedwhilewaitingfor{0}tobecome{1}'.format node['name'] state return Falsenode get_vm_status vmid vmid log.debug 'Statefor{0}is "{1}"insteadof"{2}"'.format node['name'] node['status'] state
def get_resource_versions resource_type return _get_cached_tracker .get_resource_versions resource_type
def part rebulk Rebulk .regex_defaults flags re.IGNORECASE abbreviations [dash] validator {'__parent__' seps_surround} prefixes ['pt' 'part']def validate_roman match '\nValidatearomanmatchifsurroundedbyseparators\n parammatch \n typematch \n return \n rtype \n'if int_coercable match.raw return Truereturn seps_surround match rebulk.regex build_or_pattern prefixes + '-? ?P<part>' + numeral + ' ' prefixes prefixes validate_all True private_parent True children True formatter parse_numeral validator {'part' compose validate_roman lambda m 0 < m.value < 100 } return rebulk
def del_connection_info user True section keypath reg_info user try hive _winreg.ConnectRegistry None section key _winreg.OpenKey hive keypath _winreg.DeleteKey key 'api' _winreg.CloseKey key except WindowsError if user del_connection_info user False passfinally _winreg.CloseKey hive
def installReactor reactor import twisted.internetimport sysif 'twisted.internet.reactor' in sys.modules raise error.ReactorAlreadyInstalledError 'reactoralreadyinstalled' twisted.internet.reactor reactorsys.modules['twisted.internet.reactor'] reactor
@with_setup step_runner_environ def test_successful_behave_as_step_passes runnable_step Step.from_string 'GivenIhaveastepwhichcallsthe"defineastep"stepwithbehave_as' runnable_step.run True assert runnable_step.passed
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def upgrade migrate_engine meta MetaData meta.bind migrate_enginevolume_type_projects Table 'volume_type_projects' meta autoload True if migrate_engine.name 'postgresql' sql 'ALTERTABLEvolume_type_projectsALTERCOLUMNdeleted' + 'TYPEINTEGERUSINGdeleted integer' migrate_engine.execute sql else volume_type_projects.c.deleted.alter Integer
def hist x bins 10 ax None **kwargs arglist list signature np.histogram .parameters.keys [1 ]np_hist_kwds dict key kwargs[key] for key in arglist if key in kwargs hist bins histogram x bins **np_hist_kwds if ax is None import matplotlib.pyplot as pltax plt.gca return ax.hist x bins **kwargs
def get_list_payload context builder list_type value payload_type types.ListPayload list_type payload context.nrt.meminfo_data builder value.meminfo ptrty context.get_data_type payload_type .as_pointer payload builder.bitcast payload ptrty return context.make_data_helper builder payload_type ref payload
def askopenfilename **kwargs try from Tkinter import Tkimport tkFileDialog as filedialogexcept ImportError from tkinter import Tk filedialogroot Tk root.withdraw root.update filenames filedialog.askopenfilename **kwargs root.destroy return filenames
def test_adjust_sigmoid_cutoff_half image np.arange 0 255 4 np.uint8 .reshape 8 8 expected np.array [[1 1 2 2 3 3 4 5] [5 6 7 9 10 12 14 16] [19 22 25 29 34 39 44 50] [57 64 72 80 89 99 108 118] [128 138 148 158 167 176 184 192] [199 205 211 217 221 226 229 233] [236 238 240 242 244 246 247 248] [249 250 250 251 251 252 252 253]] dtype np.uint8 result exposure.adjust_sigmoid image 0.5 10 assert_array_equal result expected
@deprecated u'2.1' def unmasked_index_ranges mask compressed True mask mask.reshape mask.size m np.concatenate 1 mask 1 indices np.arange len mask + 1 mdif m[1 ] - m[ -1 ] i0 np.compress mdif -1 indices i1 np.compress mdif 1 indices assert len i0 len i1 if len i1 0 return Noneif not compressed return np.concatenate i0[ np.newaxis] i1[ np.newaxis] axis 1 seglengths i1 - i0 breakpoints np.cumsum seglengths ic0 np.concatenate 0 breakpoints[ -1 ] ic1 breakpointsreturn np.concatenate ic0[ np.newaxis] ic1[ np.newaxis] axis 1
def env *vars **kwargs for v in vars value os.environ.get v None if value return valuereturn kwargs.get 'default' ''
def get_subscribed mailchimp list_id return get_members mailchimp list_id 'subscribed'
def rate rate if rate if isinstance rate basestring ops _ modifier rate.partition '/' return RATE_MODIFIER_MAP[ modifier or 's' ] int ops or 0 return rate or 0 return 0
def addToPathsRecursively paths vector3Lists if vector3Lists.__class__ Vector3 or vector3Lists.__class__.__name__ 'Vector3Index' paths.append [vector3Lists] returnpath []for vector3List in vector3Lists if vector3List.__class__ list addToPathsRecursively paths vector3List elif vector3List.__class__ Vector3 path.append vector3List if len path > 0 paths.append path
def arguments_section args types if len args 0 return ''def serialize_arg idx return serialize_argument_at_idx idx args 'self->arg%d' % idx types parts [serialize_arg i for i in xrange len args ]return '\n DCTB DCTB ' + ' '.join parts + ' '
def motion_string motion return _motion_names.get motion str motion
@dec.onlyif_unicode_pathsdef test_unicode_cwd wd tempfile.mkdtemp suffix u'\u20ac' old_wd os.getcwd os.chdir wd try app BaseIPythonApplication app.init_profile_dir app.init_config_files app.load_config_file suppress_errors False finally os.chdir old_wd
def iokit_devicetree attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'iokit_devicetree' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
@_helpers.positional 3 def credentials_from_clientsecrets_and_code filename scope code message None redirect_uri 'postmessage' http None cache None device_uri None flow flow_from_clientsecrets filename scope message message cache cache redirect_uri redirect_uri device_uri device_uri credentials flow.step2_exchange code http http return credentials
def get_enabled_auth_backends global _enabled_auth_backendsglobal _auth_backend_settingif not _enabled_auth_backends or _auth_backend_setting ! settings.AUTHENTICATION_BACKENDS _enabled_auth_backends []for backend in get_backends if not isinstance backend AuthBackend warn u'Authenticationbackendsshouldinheritfromreviewboard.accounts.backends.AuthBackend.Pleaseupdate%s.' % backend.__class__ for field default in u'name' None u'supports_registration' False u'supports_change_name' False u'supports_change_email' False u'supports_change_password' False if not hasattr backend field warn u"Authenticationbackendsshoulddefinea'%s'attribute.Pleasedefineitin%sorinheritfromAuthBackend." % field backend.__class__ setattr backend field False _enabled_auth_backends.append backend _auth_backend_setting settings.AUTHENTICATION_BACKENDSreturn _enabled_auth_backends
def check_valid_package package cyg_arch 'x86_64' mirrors None if mirrors is None mirrors [{DEFAULT_MIRROR DEFAULT_MIRROR_KEY}]LOG.debug 'CheckingValidMirrors {0}'.format mirrors for mirror in mirrors for mirror_url key in mirror.items if package in _get_all_packages mirror_url cyg_arch return Truereturn False
def get_within_delta key app None txt config_value key app app values txt.split return timedelta **{values[1] int values[0] }
def weighted y return linkage y method 'weighted' metric 'euclidean'
def calc_F R r beta var_beta nobs df from scipy.stats import fhyp np.dot R beta.reshape len beta 1 - r RSR np.dot R np.dot var_beta R.T q len r F np.dot hyp.T np.dot inv RSR hyp .squeeze / q p_value 1 - f.cdf F q nobs - df return F q nobs - df p_value
def create_userstory **kwargs owner kwargs.pop 'owner' None if not owner owner UserFactory.create project kwargs.pop 'project' None if project is None project ProjectFactory.create owner owner defaults {'project' project 'owner' owner 'milestone' MilestoneFactory.create project project owner owner }defaults.update kwargs return UserStoryFactory **defaults
def print_visit_num_pages_goal_details goal_details print '------VisitNumPagesGoal-------' print 'ComparisonType %s' % goal_details.get 'comparisonType' print 'comparisonValue %s' % goal_details.get 'comparisonValue'
def _get_queue_name_prefix return u'ckan {} '.format config[u'ckan.site_id']
def clean_old_jobs serv _get_serv ret None living_jids set serv.keys 'load *' to_remove []for ret_key in serv.keys 'ret *' load_key ret_key.replace 'ret ' 'load ' 1 if load_key not in living_jids to_remove.append ret_key if len to_remove ! 0 serv.delete *to_remove
def type_name value if inspect.isclass value cls valueelse cls value.__class__if cls.__module__ in set [u'builtins' u'__builtin__'] return cls.__name__return u'%s.%s' % cls.__module__ cls.__name__
def _is_xblock_reorderable xblock context try return xblock.location in context['reorderable_items'] except KeyError return False
def get_makefile_filename if _PYTHON_BUILD return os.path.join _PROJECT_BASE 'Makefile' return os.path.join get_path 'platstdlib' 'config' 'Makefile'
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def preferential_attachment G ebunch None def predict u v return G.degree u * G.degree v return _apply_prediction G predict ebunch
def keep_lazy *resultclasses if not resultclasses raise TypeError 'Youmustpassatleastoneargumenttokeep_lazy .' def decorator func lazy_func lazy func *resultclasses @wraps func def wrapper *args **kwargs for arg in list args + list kwargs.values if isinstance arg Promise breakelse return func *args **kwargs return lazy_func *args **kwargs return wrapperreturn decorator
def test_radius_neighbors_boundary_handling X np.array [[1.5] [3.0] [3.01]] radius 3.0for algorithm in ALGORITHMS nbrs neighbors.NearestNeighbors radius radius algorithm algorithm .fit X results nbrs.radius_neighbors [[0.0]] return_distance False assert_equal results.shape 1 assert_equal results.dtype object assert_array_equal results[0] [0 1]
def make_virtual_offset block_start_offset within_block_offset if within_block_offset < 0 or within_block_offset > 65536 raise ValueError 'Require0< within_block_offset<2**16 got%i' % within_block_offset if block_start_offset < 0 or block_start_offset > 281474976710656 raise ValueError 'Require0< block_start_offset<2**48 got%i' % block_start_offset return block_start_offset << 16 | within_block_offset
def _render_tab lst ret []for pre in lst['pre'] ret.append '{0}\n'.format pre for cron in lst['crons'] ret.append '{0}{1}{2}{3}\n'.format cron['path'] cron['mask'] cron['cmd'] TAG return ret
def XOR x y result ''for a b in zip x y if sys.version_info < 3 0 result + chr ord a ^ ord b else result + bytes [ a ^ b ] return result
def _get_firewall_rules firewall_rules ret []for key value in firewall_rules.iteritems if 'protocol' not in firewall_rules[key].keys raise SaltCloudConfigError "Thefirewallrule'{0}'ismissing'protocol'".format key ret.append FirewallRule name key protocol firewall_rules[key].get 'protocol' None source_mac firewall_rules[key].get 'source_mac' None source_ip firewall_rules[key].get 'source_ip' None target_ip firewall_rules[key].get 'target_ip' None port_range_start firewall_rules[key].get 'port_range_start' None port_range_end firewall_rules[key].get 'port_range_end' None icmp_type firewall_rules[key].get 'icmp_type' None icmp_code firewall_rules[key].get 'icmp_code' None return ret
def effective_principals request return request.effective_principals
def _dnsname_match dn hostname max_wildcards 1 pats []if not dn return Falseparts dn.split '.' leftmost parts[0]remainder parts[1 ]wildcards leftmost.count '*' if wildcards > max_wildcards raise CertificateError 'toomanywildcardsincertificateDNSname ' + repr dn if not wildcards return dn.lower hostname.lower if leftmost '*' pats.append '[^.]+' elif leftmost.startswith 'xn--' or hostname.startswith 'xn--' pats.append re.escape leftmost else pats.append re.escape leftmost .replace '\\*' '[^.]*' for frag in remainder pats.append re.escape frag pat re.compile '\\A' + '\\.'.join pats + '\\Z' re.IGNORECASE return pat.match hostname
def project_present name description None enabled True profile None **connection_args return tenant_present name description description enabled enabled profile profile **connection_args
def programme return s3_rest_controller
def cuckoo_init quiet False debug False artwork False test False cur_path os.getcwd os.chdir CUCKOO_ROOT logo check_working_directory check_configs check_version create_structure if artwork import timetry while True time.sleep 1 logo except KeyboardInterrupt returninit_logging if quiet log.setLevel logging.WARN elif debug log.setLevel logging.DEBUG init_modules init_tasks init_yara init_binaries init_rooter init_routing if test returnResultServer os.chdir cur_path
def to_key literal_or_identifier if literal_or_identifier[u'type'] u'Identifier' return literal_or_identifier[u'name']elif literal_or_identifier[u'type'] u'Literal' k literal_or_identifier[u'value']if isinstance k float return unicode float_repr k elif u'regex' in literal_or_identifier return compose_regex k elif isinstance k bool return u'true' if k else u'false' elif k is None return u'null'else return unicode k
def keyring_auth_del **kwargs return ceph_cfg.keyring_auth_del **kwargs
def h2vp v z n 1 if not isinstance n int or n < 0 raise ValueError 'nmustbeanon-negativeinteger.' if n 0 return hankel2 v z else return _bessel_diff_formula v z n hankel2 -1
def _raw_hex_id obj packed struct.pack '@P' id obj return ''.join map _replacer packed
def test_get_phantom_dipoles assert_raises ValueError get_phantom_dipoles 0 assert_raises ValueError get_phantom_dipoles 'foo' for kind in 'vectorview' 'otaniemi' pos ori get_phantom_dipoles kind assert_equal pos.shape 32 3 assert_equal ori.shape 32 3
def generate_themes num owner post_save.disconnect update_search_index sender Addon dispatch_uid 'addons.search.index' user generate_user owner for name category in _yield_name_and_cat num app FIREFOX type ADDON_PERSONA theme create_theme name name generate_addon_user_and_category theme user category generate_theme_images theme generate_translations theme generate_collection theme generate_ratings theme 5
@task.task ignore_result True def remove_share share share._remove
def list_hosts call None if call 'action' raise SaltCloudSystemExit 'Thelist_hostsfunctionmustbecalledwith-for--function.' return avail_locations
def check_extra_requirements pkgname pkgver if pkgver and 'pkg.check_extra_requirements' in __salt__ return __salt__['pkg.check_extra_requirements'] pkgname pkgver return True
@control_command variadic u'task_id' args [ u'signal' text_t ] signature u'<signal>[id1[id2[...[idN]]]]' def terminate state signal task_id **kwargs return revoke state task_id terminate True signal signal
def _trim_files files trim_output count 100if not isinstance trim_output bool count trim_outputif not isinstance trim_output bool and trim_output is False and len files > count files files[ count]files.append 'Listtrimmedafter{0}files.'.format count return files
def commands out []for plugin in find_plugins out + plugin.commands return out
def inv_item_total_weight row try inv_item getattr row 'inv_inv_item' except AttributeError inv_item rowtry quantity inv_item.quantityexcept AttributeError return 0.0try supply_item getattr row 'supply_item' weight supply_item.weightexcept AttributeError itable current.s3db.inv_inv_itemstable current.s3db.supply_itemquery itable.id inv_item.id & itable.item_id stable.id supply_item current.db query .select stable.weight limitby 0 1 .first if not supply_item returnelse weight supply_item.weightif weight is None return current.messages['NONE']else return quantity * weight
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def na_value_for_dtype dtype dtype pandas_dtype dtype if is_datetime64_dtype dtype or is_datetime64tz_dtype dtype or is_timedelta64_dtype dtype return NaTelif is_float_dtype dtype return np.nanelif is_integer_dtype dtype return 0elif is_bool_dtype dtype return Falsereturn np.nan
def describe_api_resource restApiId path region None key None keyid None profile None r describe_api_resources restApiId region region key key keyid keyid profile profile resources r.get 'resources' if resources is None return rfor resource in resources if resource['path'] path return {'resource' resource}return {'resource' None}
def fix_js_args func fcode six.get_function_code func fargs fcode.co_varnames[ fcode.co_argcount - 2 fcode.co_argcount]if fargs 'this' 'arguments' or fargs 'arguments' 'var' return funccode append_arguments six.get_function_code func 'this' 'arguments' return types.FunctionType code six.get_function_globals func func.__name__ closure six.get_function_closure func
def add_sync_methods cls for name in cls.__dict__.keys if name.endswith '_async' sync_name name[ -6 ]if not hasattr cls sync_name setattr cls sync_name _make_sync_method name return cls
def get_level request if hasattr request '_messages' storage request._messageselse storage default_storage request return storage.level
def isLoopIntersectingLoop loop otherLoop for pointIndex in xrange len loop pointBegin loop[pointIndex]pointEnd loop[ pointIndex + 1 % len loop ]if isLineIntersectingLoop otherLoop pointBegin pointEnd return Truereturn False
def tp_write fd buf return get_hub .threadpool.apply_e BaseException _write fd buf
def handle text mic profile messages ["I'msorry couldyourepeatthat?" 'Myapologies couldyoutrysayingthatagain?' 'Saythatagain?' 'Ibegyourpardon?']message random.choice messages mic.say message
def k_clique_communities G k cliques None if k < 2 raise nx.NetworkXError 'k %d kmustbegreaterthan1.' % k if cliques is None cliques nx.find_cliques G cliques [frozenset c for c in cliques if len c > k ]membership_dict defaultdict list for clique in cliques for node in clique membership_dict[node].append clique perc_graph nx.Graph perc_graph.add_nodes_from cliques for clique in cliques for adj_clique in _get_adjacent_cliques clique membership_dict if len clique.intersection adj_clique > k - 1 perc_graph.add_edge clique adj_clique for component in nx.connected_components perc_graph yield frozenset.union *component
def should_shard_by_property_range filters if not filters return Falsefor f in filters if f[1] ! ' ' return Truereturn False
def var_contains var value setval get_var var value value.replace '\\' '' if setval is None return Falsereturn value in setval.split
@click.command 'set-ssl-certificate' @click.argument 'site' @click.argument 'ssl-certificate-path' def set_ssl_certificate site ssl_certificate_path from bench.config.site_config import set_ssl_certificateset_ssl_certificate site ssl_certificate_path
def ParseEnum field value enum_descriptor field.enum_typetry number int value 0 except ValueError enum_value enum_descriptor.values_by_name.get value None if enum_value is None raise ValueError 'Enumtype"%s"hasnovaluenamed%s.' % enum_descriptor.full_name value else enum_value enum_descriptor.values_by_number.get number None if enum_value is None raise ValueError 'Enumtype"%s"hasnovaluewithnumber%d.' % enum_descriptor.full_name number return enum_value.number
def _maybe_raise_exception assert 'OAUTH_ERROR_CODE' in os.environ error os.environ['OAUTH_ERROR_CODE']if error assert 'OAUTH_ERROR_DETAIL' in os.environ error_detail os.environ['OAUTH_ERROR_DETAIL']if error str user_service_pb.UserServiceError.NOT_ALLOWED raise NotAllowedError error_detail elif error str user_service_pb.UserServiceError.OAUTH_INVALID_REQUEST raise InvalidOAuthParametersError error_detail elif error str user_service_pb.UserServiceError.OAUTH_INVALID_TOKEN raise InvalidOAuthTokenError error_detail elif error str user_service_pb.UserServiceError.OAUTH_ERROR raise OAuthServiceFailureError error_detail else raise OAuthServiceFailureError error_detail
def validate_comma_separated value if not re.search u'^[a-zA-Z0-9- \\.]+$' value raise ValidationError u'{}shouldbeacomma-separatedlist'.format value
def passivemode_msg protocol host '127.0.0.1' port 12345 msg '227EnteringPassiveMode %s .' % ftp.encodeHostPort host port return msg.encode protocol._encoding
@check_is_trading@export_as_api@ExecutionContext.enforce_phase EXECUTION_PHASE.HANDLE_BAR EXECUTION_PHASE.SCHEDULED def order_percent id_or_ins percent style None assert 0 < percent < 1 portfolio_value get_simu_exchange .account.portfolio.portfolio_valuereturn order_value id_or_ins portfolio_value * percent style
def traverse_topologically start_node get_parents get_children filter_func None yield_descendants_of_unyielded False return _traverse_generic start_node get_parents get_parents get_children get_children filter_func filter_func yield_descendants_of_unyielded yield_descendants_of_unyielded
def get_algorithm algorithm global _hashesif _hashes is None _setup_hashes if isinstance algorithm str unicode algorithm dns.name.from_text algorithm if sys.hexversion < 33882624 and algorithm HMAC_SHA384 or algorithm HMAC_SHA512 raise NotImplementedError 'TSIGalgorithm' + str algorithm + 'requiresPython2.5.2orlater' try return algorithm.to_digestable _hashes[algorithm] except KeyError raise NotImplementedError 'TSIGalgorithm' + str algorithm + 'isnotsupported'
def serialize_part_xml part_elm return etree.tostring part_elm encoding u'UTF-8' standalone True
def stub_out_http_backend stubs class FakeHTTPConnection object def __init__ self *args **kwargs passdef getresponse self if len FAKE_RESPONSE_STACK return FAKE_RESPONSE_STACK.pop return utils.FakeHTTPResponse def request self *_args **_kwargs passdef close self passdef fake_get_conn_class self *args **kwargs return FakeHTTPConnectionstubs.Set Store '_get_conn_class' fake_get_conn_class
def force_unlock get_lock min_wait 0 max_wait 0.001 timeout 0 release_lock
def get_access_logs config access_log Literal 'access_log' + ZeroOrMore parameter + semicolon access_log.ignore pythonStyleComment for directive in access_log.searchString config .asList path directive[1]if path 'off' or path.startswith 'syslog ' continueformat_name 'combined'if len directive > 2 and ' ' not in directive[2] format_name directive[2] yield path format_name
def fetch_things t_class since until batch_fn None *query_params **extra_query_dict from r2.lib.db.operators import ascif not batch_fn batch_fn lambda x x query_params [ t_class.c._date > since t_class.c._date < until t_class.c._spam True False ] + list query_params query_dict {'sort' asc '_date' 'limit' 100 'data' True}query_dict.update extra_query_dict q t_class._query *query_params **query_dict orig_rules deepcopy q._rules things list q while things things batch_fn things for t in things yield t q._rules deepcopy orig_rules q._after t things list q
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def stringified_dict_contains_value key value str_dict value str value try key_index str_dict.index key + len key + 3 except ValueError return Falsetry comma_index str_dict.index ' ' key_index except ValueError comma_index str_dict.index '}' key_index return str value str_dict[key_index comma_index].strip '"\''
def extract_vars_above *names callerNS sys._getframe 2 .f_localsreturn dict k callerNS[k] for k in names
def make_compute text deps func lambda self safe_eval text SAFE_EVAL_BASE {'self' self} mode 'exec' deps [arg.strip for arg in deps or '' .split ' ' ]return api.depends *deps func
def from_html_one html_code **kwargs tables from_html html_code **kwargs try assert len tables 1 except AssertionError raise Exception 'Morethanone<table>inprovidedHTMLcode!Usefrom_htmlinstead.' return tables[0]
def test_qtable_column_conversion qtab table.QTable [[1 2] [3 4.2]] names ['i' 'f'] assert isinstance qtab['i'] table.column.Column assert isinstance qtab['f'] table.column.Column qtab['i'].unit 'km/s'assert isinstance qtab['i'] u.Quantity assert isinstance qtab['f'] table.column.Column assert isinstance qtab['i'][0] u.Quantity assert isinstance qtab[0]['i'] u.Quantity assert not isinstance qtab['f'][0] u.Quantity assert not isinstance qtab[0]['f'] u.Quantity qtab['f'].unit u.dex u.cm / u.s ** 2 assert isinstance qtab['f'] u.Dex
def test_gen_matrix print __name__ + '.' + test_gen_matrix.__name__ matrices Matrices for matrix_dict in matrices.gen_matrix_dicts x gth_solve matrix_dict['A'] yield StationaryDistSumOne x yield StationaryDistNonnegative x yield StationaryDistEqualToKnown matrix_dict['stationary_dist'] x
def _get_next request next request.POST.get 'next' request.GET.get 'next' request.META.get 'HTTP_REFERER' None if not next next request.pathreturn next
def recent_scans request db_obj RecentScansDB.objects.all .order_by '-TS' context {'title' 'RecentScans' 'entries' db_obj}template 'general/recent.html'return render request template context
def _sort_gens gens **args opt build_options args gens_order wrt {} None if opt is not None gens_order wrt {} opt.wrt for i gen in enumerate opt.sort gens_order[gen] i + 1 def order_key gen gen str gen if wrt is not None try return - len wrt + wrt.index gen gen 0 except ValueError pass name index _re_gen.match gen .groups if index index int index else index 0try return gens_order[name] name index except KeyError passtry return _gens_order[name] name index except KeyError passreturn _max_order name index try gens sorted gens key order_key except TypeError passreturn tuple gens
def query_http_server host port path '' def query req get 'http //{host} {port}{path}'.format host host port port path path timeout SOCKET_TIMEOUT_FOR_POLLING persistent False def failed failure Message.new message_type u'acceptance http_query_failed' reason unicode failure .write return Falsereq.addCallbacks content failed return reqd verify_socket host port d.addCallback lambda _ loop_until reactor query return d
def _check_ne_builtin_clash expr names expr.namesoverlap names & _ne_builtins if overlap s ' '.join map repr overlap raise NumExprClobberingError 'Variablesinexpression"%s"overlapwithbuiltins %s ' % expr s
def _mediainfo_screen_size filename try if mediainfo _media_info mediainfo.parse filename for track in _media_info.tracks if track.track_type u'Video' return track.width track.height except OSError TypeError passreturn None None
def _patch_configdata monkeypatch stubs symbol data collections.OrderedDict [ 'general' sections.KeyValue 'time' value.SettingValue stubs.FakeConfigType 'fast' 'slow' default 'slow' 'Isanillusion.\n\nLunchtimedoublyso.' 'volume' value.SettingValue stubs.FakeConfigType '0' '11' default '11' 'Goesto11' 'ui' sections.KeyValue 'gesture' value.SettingValue stubs.FakeConfigType 'on' 'off' default 'off' 'Waggleyourhandstocontrolqutebrowser' 'mind' value.SettingValue stubs.FakeConfigType 'on' 'off' default 'off' 'Enablemind-controlui experimental ' 'voice' value.SettingValue stubs.FakeConfigType 'on' 'off' default 'off' 'Whethertorespondtovoicecommands' 'searchengines' sections.ValueList stubs.FakeConfigType stubs.FakeConfigType 'DEFAULT' 'https //duckduckgo.com/?q {}' ] monkeypatch.setattr symbol data
def _int_to_enum value enum_klass try return enum_klass value except ValueError return value
def beneficiary s3db.configure 'project_beneficiary' deletable False editable False insertable False list_btn A T 'BeneficiaryReport' _href URL c 'project' f 'beneficiary' args 'report' vars get_vars _class 'action-btn' return s3_rest_controller hide_filter False
def login_notrequired func func.login_notrequired Truereturn func
def up iface iface_type None if iface_type not in ['slave'] return __salt__['cmd.run'] 'iplinkset{0}up'.format iface return None
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def test_alias_args_commented_nargs am _ip.alias_manageralias_name 'comargcount'cmd 'echothisis%%sacommentedoutargandthisisnot%s'am.define_alias alias_name cmd assert am.is_alias alias_name thealias am.get_alias alias_name nt.assert_equal thealias.nargs 1
def flake8ext f f.name __name__return f
def assert_grammar_typechecking grammar_types test_obj class BadType object passfor name objects in grammar_types for obj in objects tmp_obj obj setattr test_obj name tmp_obj nt.assert_equal getattr test_obj name tmp_obj bad_obj BadType nt.assert_raises_regexp ValueError name + '.*' + obj.__name__ setattr test_obj name bad_obj nt.assert_equal getattr test_obj name tmp_obj
def dup_gf_sqf_part f K f dup_convert f K K.dom g gf_sqf_part f K.mod K.dom return dup_convert g K.dom K
def _xml_escape_attr attr skip_single_quote True escaped attr.replace '&' '&amp;' .replace '"' '&quot;' .replace '<' '&lt;' .replace '>' '&gt;' if not skip_single_quote escaped escaped.replace "'" '&#39;' return escaped
@with_setup prepare_stderr def test_try_to_import_terrain sandbox_path ojoin '..' 'sandbox' original_path abspath '.' os.chdir sandbox_path try import lettucereload lettuce raise AssertionError 'TherunnershouldraiseImportError!' except LettuceRunnerError assert_stderr_lines_with_traceback 'Lettucehastriedtoloadtheconventionalenvironmentmodule"terrain"\nbutithaserrors checkitscontentsandtrytorunlettuceagain.\n\nOriginaltracebackbelow \n\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line44 in<module>\nterrain fs.FileSystem._import "terrain" \nFile"% lettuce_fs_file s" line63 in_import\nmodule imp.load_module name fp pathname description \nFile"% terrain_file s" line18\nitisherejusttocauseasyntaxerror\n^\nSyntaxError invalidsyntax\n' % {'lettuce_core_file' abspath join lettuce_dir '__init__.py' 'lettuce_fs_file' abspath join lettuce_dir 'fs.py' 'terrain_file' abspath lettuce_path '..' 'tests' 'functional' 'sandbox' 'terrain.py' } finally os.chdir original_path
@image_comparison baseline_images [u'image_interps'] def test_image_interps X np.arange 100 X X.reshape 5 20 fig plt.figure ax1 fig.add_subplot 311 ax1.imshow X interpolation u'nearest' ax1.set_title u'threeinterpolations' ax1.set_ylabel u'nearest' ax2 fig.add_subplot 312 ax2.imshow X interpolation u'bilinear' ax2.set_ylabel u'bilinear' ax3 fig.add_subplot 313 ax3.imshow X interpolation u'bicubic' ax3.set_ylabel u'bicubic'
def gluechops string key n funcref message ''chops decode64chops string for cpart in chops mpart funcref cpart key n message + int2bytes mpart return message
def shared_floatx_nans shape **kwargs return shared_floatx numpy.nan * numpy.zeros shape **kwargs
def _record_purchase params order ccnum_str params.get 'req_card_number' '' first_digit re.search '\\d' ccnum_str if first_digit ccnum ccnum_str[first_digit.start ]else ccnum '####'if settings.FEATURES.get 'LOG_POSTPAY_CALLBACKS' log.info 'Order%dpurchasedwithparams %s' order.id json.dumps params order.purchase first params.get 'req_bill_to_forename' '' last params.get 'req_bill_to_surname' '' street1 params.get 'req_bill_to_address_line1' '' street2 params.get 'req_bill_to_address_line2' '' city params.get 'req_bill_to_address_city' '' state params.get 'req_bill_to_address_state' '' country params.get 'req_bill_to_address_country' '' postalcode params.get 'req_bill_to_address_postal_code' '' ccnum ccnum cardtype CARDTYPE_MAP[params.get 'req_card_type' '' ] processor_reply_dump json.dumps params
def _cache_provider_details conn None DETAILS['avail_locations'] {}DETAILS['avail_sizes'] {}DETAILS['avail_images'] {}locations avail_locations conn images avail_images conn sizes avail_sizes conn for key location in six.iteritems locations DETAILS['avail_locations'][location['name']] locationDETAILS['avail_locations'][key] locationfor key image in six.iteritems images DETAILS['avail_images'][image['name']] imageDETAILS['avail_images'][key] imagefor key vm_size in six.iteritems sizes DETAILS['avail_sizes'][vm_size['name']] vm_sizeDETAILS['avail_sizes'][key] vm_size
@treeio_login_required@cache_control private True max_age 31536000 def contact_view_picture request contact_id response_format 'html' response HttpResponse content_type 'image/png' render_identicon contact_id * 5000 .save response 'PNG' return response
def _image_member_delete_all context image_id delete_time None session None members_updated_count _image_child_entry_delete_all models.ImageMember image_id delete_time session return members_updated_count
@click.group @click.option '--version' is_flag True is_eager True callback print_bench_version expose_value False def bench_command bench_path '.' import benchfrom bench.app import get_current_frappe_versionfrom bench.utils import setup_loggingbench.set_frappe_version bench_path bench_path setup_logging bench_path bench_path
def parse_url url encoding None if isinstance url ParseResult return urlreturn urlparse to_unicode url encoding
def convert_dash mpl_dash if mpl_dash in DASH_MAP return DASH_MAP[mpl_dash]else return 'solid'
def is_svn_page html return re.search '<title>[^<]*Revision\\d+ ' html and re.search 'Poweredby ? <a[^>]*?> ?Subversion' html re.I
def qos_specs_get_by_name context name return IMPL.qos_specs_get_by_name context name
def unhandledExceptionMessage errMsg 'unhandledexceptionoccurredin%s.Itisrecommendedtoretryyour' % VERSION_STRING errMsg + 'runwiththelatestdevelopmentversionfromofficialGitlab'errMsg + "repositoryat'%s'.Iftheexceptionpersists pleaseopenanewissue" % GIT_PAGE errMsg + "at'%s'" % ISSUES_PAGE errMsg + 'withthefollowingtextandanyotherinformationrequiredto'errMsg + 'reproducethebug.The'errMsg + 'developerswilltrytoreproducethebug fixitaccordingly'errMsg + 'andgetbacktoyou\n'errMsg + 'pocsuiteversion %s\n' % VERSION_STRING[ VERSION_STRING.find '/' + 1 ] errMsg + 'Pythonversion %s\n' % PYVERSION errMsg + 'Operatingsystem %s\n' % PLATFORM errMsg + 'Commandline %s\n' % re.sub '.+?\\bpocsuite.py\\b' 'pocsuite.py' ''.join sys.argv return errMsg
def find_meta meta meta_match re.search '^__{meta}__ [\'\\"] [^\'\\"]* [\'\\"]'.format meta meta META_FILE re.M if meta_match return meta_match.group 1 raise RuntimeError 'Unabletofind__{meta}__string.'.format meta meta
def cc_config append None **kwargs if 'extra_incs' in kwargs extra_incs kwargs['extra_incs']if isinstance extra_incs basestring and '' in extra_incs console.warning '%s cc_config extra_incshasbeenchangedtolist' % blade_config.current_file_name kwargs['extra_incs'] extra_incs.split blade_config.update_config 'cc_config' append kwargs
def _check_1d x if not hasattr x u'shape' or len x.shape < 1 return np.atleast_1d x else try x[ None]return xexcept IndexError TypeError return np.atleast_1d x
def test_copy_doc class A def m1 'Docstringform1'passclass B def m1 passclass C A @copy_doc A.m1 def m1 passassert_equal C.m1.__doc__ 'Docstringform1' assert_raises ValueError copy_doc B.m1 C.m1
def get_google_project result fetch GOOGLE_METADATA_URL + '/project/project-id' google True return result.content if result.ok else None
def test_feature_ptbr_from_string ru Language 'ru' feature Feature.from_string FEATURE language ru assert_equals feature.name u'\u0414\u0435\u043b\u0435\u043d\u0438\u0435\u0447\u0438\u0441\u0435\u043b' assert_equals feature.description u'\u041f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u0441\u043b\u043e\u0436\u043d\u044b\u0439\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043b\u044e\u0434\u0438\u0447\u0430\u0441\u0442\u043e\u0434\u043e\u043f\u0443\u0441\u043a\u0430\u044e\u0442\u043e\u0448\u0438\u0431\u043a\u0438\n\u041d\u0443\u0436\u043d\u043e\u0434\u0430\u0442\u044c\u0438\u043c\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c\u0434\u0435\u043b\u0438\u0442\u044c\u043d\u0430\u043a\u0430\u043b\u044c\u043a\u0443\u043b\u044f\u0442\u043e\u0440\u0435' scenario feature.scenariosassert_equals scenario.name u'\u0426\u0435\u043b\u043e\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u043e\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435' assert_equals scenario.steps[ -1 ].hashes [{u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '100' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '2' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '50'} {u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '28' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '7' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '4'} {u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '0' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '5' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '0'}]
def tan x return Tan x
def detect_worksheets archive content_types read_content_types archive valid_sheets dict path ct for ct path in content_types if ct VALID_WORKSHEET rels dict read_rels archive for sheet in read_sheets archive rel rels[sheet['id']]rel['title'] sheet['name']rel['sheet_id'] sheet['sheetId']rel['state'] sheet.get 'state' 'visible' if '/' + rel['path'] in valid_sheets or 'worksheets' in rel['path'] yield rel
def _get_default_context request types Object.filter_by_request request ItemType.objects.filter parent__isnull True statuses Object.filter_by_request request ItemStatus.objects locations Object.filter_by_request request Location.objects massform MassActionForm request.user.profile context {'statuses' statuses 'types' types 'massform' massform 'locations' locations}return context
def Translation model class Inner models.Model parent models.ForeignKey model related_name u'translations' on_delete models.CASCADE language_code models.CharField _ u'language' max_length 10 choices settings.LANGUAGES default settings.LANGUAGES[0][0] editable len settings.LANGUAGES > 1 class Meta unique_together u'parent' u'language_code' abstract Truedef short_language_code self return short_language_code self.language_code def save self *args **kwargs super Inner self .save *args **kwargs self.parent.purge_translation_cache save.alters_data Truedef delete self *args **kwargs super Inner self .delete *args **kwargs self.parent.purge_translation_cache delete.alters_data Truereturn Inner
def custom_identity_verify identity_dict true_or_false Truereturn true_or_false
def convert_data_size size default_sufix 'B' orders {'B' 1 'K' 1024 'M' 1024 * 1024 'G' 1024 * 1024 * 1024 'T' 1024 * 1024 * 1024 * 1024 }order re.findall ' [BbKkMmGgTt] ' size[ -1 ] if not order size + default_sufixorder [default_sufix]return int float size[0 -1 ] * orders[order[0].upper ]
def memoize_when_activated fun @functools.wraps fun def wrapper self if not wrapper.cache_activated return fun self else try ret cache[fun]except KeyError ret cache[fun] fun self return retdef cache_activate 'Activatecache.'wrapper.cache_activated Truedef cache_deactivate 'Deactivateandclearcache.'wrapper.cache_activated Falsecache.clear cache {}wrapper.cache_activated Falsewrapper.cache_activate cache_activatewrapper.cache_deactivate cache_deactivatereturn wrapper
def widgetbox *args **kwargs responsive kwargs.pop 'responsive' None sizing_mode kwargs.pop 'sizing_mode' 'fixed' children kwargs.pop 'children' None if responsive sizing_mode _convert_responsive responsive _verify_sizing_mode sizing_mode children _handle_children children children *args widget_children []for item in children if isinstance item Widget item.sizing_mode sizing_modewidget_children.append item else raise ValueError 'OnlyWidgetscanbeinsertedintoaWidgetBox.\nTriedtoinsert %softype%s' % item type item return WidgetBox children widget_children sizing_mode sizing_mode **kwargs
def vis_detections im class_name dets thresh 0.3 import matplotlib.pyplot as pltim im[ 2 1 0 ]for i in xrange np.minimum 10 dets.shape[0] bbox dets[i 4]score dets[ i -1 ]if score > thresh plt.cla plt.imshow im plt.gca .add_patch plt.Rectangle bbox[0] bbox[1] bbox[2] - bbox[0] bbox[3] - bbox[1] fill False edgecolor 'g' linewidth 3 plt.title '{}{ .3f}'.format class_name score plt.show
def _ArgbToRgbaTuple argb unsigned_argb argb % 4294967296 return unsigned_argb >> 16 & 255 unsigned_argb >> 8 & 255 unsigned_argb & 255 unsigned_argb >> 24 & 255
def cleanup_repo_url url parsed urlparse url if parsed.username and parsed.password return url.replace u'{0} {1}@'.format parsed.username parsed.password u'' elif parsed.username return url.replace u'{0}@'.format parsed.username u'' return url
def get_host_name hostname get_address_override if not hostname try hostname socket.gethostname except passif not hostname or hostname 'localhost' or hostname.startswith '127.' hostname get_local_address return hostname
def anon_nodename hostname None prefix u'gen' return nodename u''.join [prefix str os.getpid ] hostname or gethostname
def request_token request if not hasattr request '_xblock_token' request._xblock_token uuid.uuid1 .get_hex return request._xblock_token
def pipe_list_synonym name def getter self attr getattr self name if attr return attr.strip u'|' .split u'|' def setter self value if isinstance value str setattr self name value else setattr self name u'|'.join value return synonym name descriptor property getter setter
def must_have_permission permission def wrapper func @functools.wraps func def wrapped *args **kwargs _inject_nodes kwargs node kwargs['node']kwargs['auth'] Auth.from_kwargs request.args.to_dict kwargs user kwargs['auth'].userif user is None raise HTTPError http.UNAUTHORIZED if not node.has_permission user permission raise HTTPError http.FORBIDDEN return func *args **kwargs return wrappedreturn wrapper
def parse_irc_colors string in_string utils.to_str string parsed_string ''parts RE_ANSI_ESCAPES.split in_string + [''] for part sep in zip parts[ 2] parts[1 2] pstring RE_IRC_COLOR.sub sub_irc part parsed_string + '%s%s' % pstring sep[0].strip parsed_string RE_MXP.sub '\\2' parsed_string return parsed_string
def get_int_or_uuid value try uuid.UUID value return valueexcept ValueError AttributeError return int value
def isproperty obj return type obj property
def attach_my_role_permissions queryset user as_field 'my_role_permissions_attr' model queryset.modelif user is None or user.is_anonymous sql "SELECT'{}'"else sql '\nSELECTusers_role.permissions\nFROMprojects_membership\nLEFTJOINusers_userONprojects_membership.user_id users_user.id\nLEFTJOINusers_roleONusers_role.id projects_membership.role_id\nWHEREprojects_membership.project_id {tbl}.idAND\nusers_user.id {user_id}'sql sql.format tbl model._meta.db_table user_id user.id queryset queryset.extra select {as_field sql} return queryset
def CDLSEPARATINGLINES barDs count return call_talib_with_ohlc barDs count talib.CDLSEPARATINGLINES
def to_be_implemented request pagevars {'page_title' 'ToBeImplemented...'}return render request 'tbi.html' pagevars
def list_courses request username org None filter_ None user get_effective_user request.user username return get_courses user org org filter_ filter_
def reps_toposort r r sympify r E []for c1 k1 v1 in enumerate r for c2 k2 v2 in enumerate r if k1 in v2.free_symbols E.append c1 c2 return [r[i] for i in topological_sort range len r E ]
def _normalize_entity value if ndb is not None and isinstance value ndb.Model return Noneif getattr value '_populate_internal_entity' None return value._populate_internal_entity return value
@command 'playurl\\s .*[-_a-zA-Z0-9]{11}[^\\s]* \\s- ? f|a|w ?' def play_url url override override override if override else '_' g.browse_mode 'normal'yt_url url print_title 1 if len g.model 1 play override '1' '_' if g.command_line sys.exit
def _mdata grains {}mdata_list salt.utils.which 'mdata-list' mdata_get salt.utils.which 'mdata-get' grains['hypervisor_uuid'] __salt__['cmd.run'] '{0}sdc server_uuid'.format mdata_get if 'FAILURE' in grains['hypervisor_uuid'] or 'Nometadata' in grains['hypervisor_uuid'] grains['hypervisor_uuid'] 'Unknown'grains['datacenter'] __salt__['cmd.run'] '{0}sdc datacenter_name'.format mdata_get if 'FAILURE' in grains['datacenter'] or 'Nometadata' in grains['datacenter'] grains['datacenter'] 'Unknown'for mdata_grain in __salt__['cmd.run'] mdata_list .splitlines grain_data __salt__['cmd.run'] '{0}{1}'.format mdata_get mdata_grain if mdata_grain 'roles' grain_data grain_data.split ' ' grains['roles'] grain_dataelif not mdata_grain.startswith 'sdc ' if 'mdata' not in grains grains['mdata'] {}mdata_grain mdata_grain.replace '-' '_' mdata_grain mdata_grain.replace ' ' '_' grains['mdata'][mdata_grain] grain_datareturn grains
def quotestrip word if not word return Nonewhile word.startswith "'" and word.endswith "'" or word.startswith '"' and word.endswith '"' word word[1 -1 ]return word
def splitpasswd user global _passwdprogif _passwdprog is None import re_passwdprog re.compile '^ [^ ]* .* $' re.S match _passwdprog.match user if match return match.group 1 2 return user None
def AVGPRICE barDs count return call_talib_with_ohlc barDs count talib.AVGPRICE
def DumpLocalUsers path 'WinNT //%s computer' % local_name ob ADsGetObject path IID_IADsContainer ob.put_Filter ['User' 'Group'] for sub_ob in ob print 'User/Group %s %s ' % sub_ob.Name sub_ob.ADsPath
@validate 'graph' def valid_field_in_graph arch return all child.tag 'field' for child in arch.xpath '/graph/*'
def fake_fetch_image context image instance **kwargs ds_name kwargs.get 'datastore_name' file_path kwargs.get 'file_path' ds_file_path '[' + ds_name + ']' + file_path _add_file ds_file_path
def get_strategy_name return 'store_type'
def check_running_hub lockfilename is_running Falselockfiledict {}try lockfiledict read_lockfile lockfilename except IOError return is_running lockfiledict if u'samp.hub.xmlrpc.url' in lockfiledict try proxy xmlrpc.ServerProxy lockfiledict[u'samp.hub.xmlrpc.url'].replace u'\\' u'' allow_none 1 proxy.samp.hub.ping is_running Trueexcept xmlrpc.ProtocolError is_running Trueexcept SSL_EXCEPTIONS is_running Trueexcept socket.error passreturn is_running lockfiledict
def test_nm3_sample_wt_fit ratio 'auto'nm3 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS assert_raises RuntimeError nm3.sample X Y
def unicode_wrap func *args **kwargs return to_text func *args **kwargs nonstring 'passthru'
def get_or_create_cart_from_request request cart_queryset Cart.objects.all if request.user.is_authenticated return get_or_create_user_cart request.user cart_queryset else token request.get_signed_cookie Cart.COOKIE_NAME default None return get_or_create_anonymous_cart_from_token token cart_queryset
def assignmentComplete a TpPd pd 6 b MessageType mesType 41 c RrCause packet a / b / c return packet
def symmetric_decrypt decrypt_key ciphertext return decrypt_key.Decrypt binascii.unhexlify ciphertext
def JumpToTab tab_number vim.command u'silent!tabn{0}'.format tab_number
def gf_add f g p K if not f return gif not g return fdf gf_degree f dg gf_degree g if df dg return gf_strip [ a + b % p for a b in zip f g ] else k abs df - dg if df > dg h f f[ k] f[k ] else h g g[ k] g[k ] return h + [ a + b % p for a b in zip f g ]
def _zero_triband a lower 0 nrow ncol a.shapeif lower for i in range nrow a[i ncol - i ] 0.0else for i in range nrow a[i 0 i] 0.0return a
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def include_admin_script script_path if not absolute_url_re.match script_path script_path '%s%s' % settings.ADMIN_MEDIA_PREFIX script_path return '<scripttype "text/javascript"src "%s"></script>' % script_path
@box SeriesType def box_series typ val c series make_series c.context c.builder typ value val classobj c.pyapi.unserialize c.pyapi.serialize_object Series indexobj c.box typ.index series.index arrayobj c.box typ.as_array series.values seriesobj c.pyapi.call_function_objargs classobj arrayobj indexobj return seriesobj
def _router_request router method data None if router not in ROUTERS return Falsereq_data json.dumps [dict action router method method data data type 'rpc' tid 1 ] config __salt__['config.option'] 'zenoss' log.debug 'Makingrequesttorouter%swithmethod%s' router method url '{0}/zport/dmd/{1}_router'.format config.get 'hostname' ROUTERS[router] response _session .post url data req_data if re.search 'name "__ac_name"' response.content log.error 'Requestfailed.Badusername/password.' raise Exception 'Requestfailed.Badusername/password.' return json.loads response.content .get 'result' None
@must_be_valid_project@must_have_permission WRITE @must_not_be_registrationdef remove_pointer_from_folder auth node pointer_id **kwargs if pointer_id is None raise HTTPError http.BAD_REQUEST pointer_id node.pointing_at pointer_id pointer Pointer.load pointer_id if pointer is None raise HTTPError http.BAD_REQUEST try node.rm_pointer pointer auth auth except ValueError raise HTTPError http.BAD_REQUEST node.save
def unnotify thing possible_recipients None from r2.lib import butlererror_message 'Unabletounnotifythingoftype %r' % thing notification_handler thing notify_function butler.remove_mention_notification error_message error_message possible_recipients possible_recipients
def buildTagMap default *args built {}for portion in args if hasattr portion 'items' for k v in portion.items built[k] velif isList portion for k in portion built[k] defaultelse built[portion] defaultreturn built
def get_observer settings def observer msg u'Reportdocutils/restmessagestoaNikolauser.\n\nErrorcodemapping \n\n+------+---------+------+----------+\n|dNUM|dNAME|lNUM|lNAME|d docutils l logbook\n+------+---------+------+----------+\n|0|DEBUG|1|DEBUG|\n|1|INFO|2|INFO|\n|2|WARNING|4|WARNING|\n|3|ERROR|5|ERROR|\n|4|SEVERE|6|CRITICAL|\n+------+---------+------+----------+\n'errormap {0 1 1 2 2 4 3 5 4 6}text docutils.nodes.Element.astext msg line msg[u'line'] + settings[u'add_ln'] if u'line' in msg else 0 out u'[{source}{colon}{line}]{text}'.format source settings[u'source'] colon u' ' if line else u'' line line text text settings[u'logger'].log errormap[msg[u'level']] out return observer
def valid_qname val try prefix localpart val.split ' ' return valid_ncname prefix and valid_ncname localpart except ValueError return valid_ncname val
def index_entry_from_stat stat_val hex_sha flags mode None if mode is None mode cleanup_mode stat_val.st_mode return stat_val.st_ctime stat_val.st_mtime stat_val.st_dev stat_val.st_ino mode stat_val.st_uid stat_val.st_gid stat_val.st_size hex_sha flags
def prune_expr lin_op if lin_op.type is lo.VARIABLE return Falseelif lin_op.type in [lo.SCALAR_CONST lo.DENSE_CONST lo.SPARSE_CONST lo.PARAM] return Truepruned_args []is_constant Truefor arg in lin_op.args arg_constant prune_expr arg if not arg_constant is_constant Falsepruned_args.append arg lin_op.args[ ] pruned_args[ ]return is_constant
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def test_custom_inverse_reset class TestModel Model inputs outputs u'y' @propertydef inverse self return models.Shift @staticmethoddef evaluate return 0m TestModel assert isinstance m.inverse models.Shift m.inverse models.Scale assert isinstance m.inverse models.Scale del m.inverseassert isinstance m.inverse models.Shift
def get_browsers html get settings.BROWSERS_STATS_PAGE html html.decode u'windows-1252' html html.split u'<tableclass "w3-table-allnotranslate">' [1]html html.split u'</table>' [0]browsers re.findall u'\\.asp"> .+? <' html re.UNICODE browsers [settings.OVERRIDES.get browser browser for browser in browsers]browsers_statistics re.findall u'td\\sclass "right"> .+? \\s' html re.UNICODE return list zip browsers browsers_statistics
def _init_flow_exceptions global _flow_exceptions_flow_exceptions add_flow_exception datastore_errors.Rollback try from webob import excexcept ImportError passelse add_flow_exception exc.HTTPException
def remotes cwd user None password None redact_auth True ignore_retcode False cwd _expand_path cwd user command ['git' 'remote' '--verbose']ret {}output _git_run command cwd cwd user user password password ignore_retcode ignore_retcode ['stdout']for remote_line in salt.utils.itertools.split output '\n' try remote remote_info remote_line.split None 1 except ValueError continuetry remote_url action remote_info.rsplit None 1 except ValueError continueaction action.lstrip ' ' .rstrip ' ' .lower if action not in 'fetch' 'push' log.warning "Unknownaction'{0}'forremote'{1}'ingitcheckoutlocatedin{2}".format action remote cwd continueif redact_auth remote_url salt.utils.url.redact_http_basic_auth remote_url ret.setdefault remote {} [action] remote_urlreturn ret
def host_delete hostids **connection_args conn_args _login **connection_args try if conn_args method 'host.delete'if not isinstance hostids list params [hostids]else params hostidsret _query method params conn_args['url'] conn_args['auth'] return ret['result']['hostids']else raise KeyErrorexcept KeyError return ret
def set_maxdays name maxdays pre_info info name if maxdays pre_info['max'] return Truecmd 'chage-M{0}{1}'.format maxdays name __salt__['cmd.run'] cmd python_shell False post_info info name if post_info['max'] ! pre_info['max'] return post_info['max'] maxdays return False
def pci_device_get_all_by_parent_addr context node_id parent_addr return IMPL.pci_device_get_all_by_parent_addr context node_id parent_addr
def raw key None if key ret __pillar__.get key {} else ret __pillar__return ret
def render_from_entry template_string entry variables copy entry.store variables[u'now'] datetime.now if hasattr entry u'task' and entry.task is not None if u'task' not in variables variables[u'task'] entry.task.namevariables[u'task_name'] entry.task.namereturn render template_string variables
def _not_a_coeff expr return expr in [S.NaN S.Infinity S.NegativeInfinity S.ComplexInfinity]
def width_from_max_int value return int math.ceil math.log value + 1 2
def get_link_target link target os.readlink link if not os.path.isabs target target os.path.join os.path.dirname link target return os.path.abspath target
@log_list_volumesdef get_blockdevice_volume api blockdevice_id for volume in api.list_volumes if volume.blockdevice_id blockdevice_id return volumeraise UnknownVolume blockdevice_id
def _import_ldap_groups connection groupname_pattern import_members False recursive_import_members False sync_users True import_by_dn False failed_users None if desktop.conf.LDAP.SUBGROUPS.get .lower 'suboordinate' return _import_ldap_suboordinate_groups connection connection groupname_pattern groupname_pattern import_members import_members recursive_import_members recursive_import_members sync_users sync_users import_by_dn import_by_dn failed_users failed_users else return _import_ldap_nested_groups connection connection groupname_pattern groupname_pattern import_members import_members recursive_import_members recursive_import_members sync_users sync_users import_by_dn import_by_dn failed_users failed_users
def _class_cov X y priors None shrinkage None classes np.unique y covs []for group in classes Xg X[ y group ]covs.append np.atleast_2d _cov Xg shrinkage return np.average covs axis 0 weights priors
def waitListening client None server '127.0.0.1' port 80 timeout None runCmd client.cmd if client else partial quietRun shell True if not runCmd 'whichtelnet' raise Exception 'Couldnotfindtelnet' serverIP server if isinstance server basestring else server.IP cmd 'echoA|telnet-eA%s%s' % serverIP port time 0result runCmd cmd while 'Connected' not in result if 'Noroute' in result rtable runCmd 'route' error 'norouteto%s \n%s' % server rtable return Falseif timeout and time > timeout error 'couldnotconnectto%sonport%d\n' % server port return Falsedebug 'waitingfor' server 'tolistenonport' port '\n' info '.' sleep 0.5 time + 0.5result runCmd cmd return True
def _set_user_stylesheet stylesheet shared.get_user_stylesheet .encode 'utf-8' url urlutils.data_url 'text/css;charset utf-8' stylesheet QWebSettings.globalSettings .setUserStyleSheetUrl url
def _section_special_exams course access course_key course.idsection_data {'section_key' 'special_exams' 'section_display_name' _ 'SpecialExams' 'access' access 'course_id' unicode course_key }return section_data
def getPriorityStrict element prio_str element.get 'priority' if prio_str is not None prio_val int prio_str if prio_val > 0 return prio_valelse raise ValueError 'Priorityvaluesmustbenon-negativeintegers' return Max
@testing.requires_testing_data@requires_freesurfer@requires_nibabel def test_vertex_to_mni_fs_nibabel n_check 1000subject 'sample'vertices rng.randint 0 100000 n_check hemis rng.randint 0 1 n_check coords vertex_to_mni vertices hemis subject subjects_dir 'nibabel' coords_2 vertex_to_mni vertices hemis subject subjects_dir 'freesurfer' assert_allclose coords coords_2 atol 0.1
def margulis_gabber_galil_graph n create_using None if create_using is None create_using nx.MultiGraph elif create_using.is_directed or not create_using.is_multigraph msg '`create_using`mustbeanundirectedmultigraph.'raise nx.NetworkXError msg G create_usingG.clear for x y in itertools.product range n repeat 2 for u v in x + 2 * y % n y x + 2 * y + 1 % n y x y + 2 * x % n x y + 2 * x + 1 % n G.add_edge x y u v G.graph['name'] 'margulis_gabber_galil_graph {0} '.format n return G
@testing.requires_testing_data@requires_freesurfer@requires_nibabel def test_source_space_from_label tempdir _TempDir aseg_fname op.join subjects_dir 'sample' 'mri' 'aseg.mgz' label_names get_volume_labels_from_aseg aseg_fname volume_label label_names[int np.random.rand * len label_names ]pos dict assert_raises ValueError setup_volume_source_space 'sample' pos pos volume_label volume_label mri aseg_fname assert_raises RuntimeError setup_volume_source_space 'sample' mri None volume_label volume_label assert_raises ValueError setup_volume_source_space 'sample' volume_label 'HelloWorld!' mri aseg_fname src setup_volume_source_space 'sample' subjects_dir subjects_dir volume_label volume_label mri aseg_fname add_interpolator False assert_equal volume_label src[0]['seg_name'] out_name op.join tempdir 'temp-src.fif' write_source_spaces out_name src src_from_file read_source_spaces out_name _compare_source_spaces src src_from_file mode 'approx'
def partition lst f save_keys False d collections.OrderedDict for l in lst c f l s d.setdefault c [] s.append l if save_keys return delse return d.values
def getfilename package relativeTo None if relativeTo is None relativeTo os.getcwd path os.path.join relativeTo os.sep.join package.split '.' if os.path.exists path + '/__init__.py' return pathfilename path + '.py' if os.path.exists filename return filenamereturn None
def _get_codon_fold codon_table def find_fold_class codon forward_table base set ['A' 'T' 'C' 'G'] fold ''codon_base_lst [i for i in codon]for i b in enumerate codon_base_lst other_base base - set b aa []for j in other_base codon_base_lst[i] jtry aa.append forward_table[''.join codon_base_lst ] except KeyError aa.append 'stop' if aa.count forward_table[codon] 0 fold + '0'elif aa.count forward_table[codon] in 1 2 fold + '2'elif aa.count forward_table[codon] 3 fold + '4'else raise RuntimeError 'UnknownError cannotassignthepositiontoafold' codon_base_lst[i] breturn foldfold_table {}for codon in codon_table.forward_table if 'U' not in codon fold_table[codon] find_fold_class codon codon_table.forward_table fold_table['---'] '---'return fold_table
def requirements_to_mulled_targets requirements package_requirements [r for r in requirements if r.type 'package' ]targets [build_target r.name r.version for r in package_requirements]return targets
def _build_url url projects branches ret ''all_built {}all_not_building {}for project in projects built not_building build_branches project branches if not built update_imported_docs.delay project.versions.get slug LATEST .pk msg ' URLBuild Syncingversionsfor%s' % project.slug log.info msg all_built[project.slug] builtall_not_building[project.slug] not_buildingfor project_slug built in all_built.items if built msg ' URLBuild BuildStarted %s[%s]' % url ''.join built log_info project_slug msg msg ret + msgfor project_slug not_building in all_not_building.items if not_building msg ' URLBuild NotBuilding %s[%s]' % url ''.join not_building log_info project_slug msg msg ret + msgif not ret ret ' URLBuild Noknownbrancheswerepushedto.'return HttpResponse ret
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def get_themes root static_path os.path.join root 'static' templates_path os.path.join root 'templates' themes os.listdir os.path.join static_path 'themes' if '__common__' in themes themes.remove '__common__' return static_path templates_path themes
def modfacl acl_type acl_name '' perms '' *args **kwargs recursive kwargs.pop 'recursive' False _raise_on_no_files *args cmd 'setfacl'if recursive cmd + '-R'cmd + '-m'cmd '{0}{1} {2} {3}'.format cmd _acl_prefix acl_type acl_name perms for dentry in args cmd + '"{0}"'.format dentry __salt__['cmd.run'] cmd python_shell False return True
def elided_text text font None width 300 pos 'middle' from PyQt5.Qt import QFontMetrics QApplicationfm QApplication.fontMetrics if font is None else font if isinstance font QFontMetrics else QFontMetrics font delta 4ellipsis u'\u2026'def remove_middle x mid len x // 2 return x[ max 0 mid - delta // 2 ] + ellipsis + x[ mid + delta // 2 ] chomp {'middle' remove_middle 'left' lambda x ellipsis + x[delta ] 'right' lambda x x[ - delta ] + ellipsis }[pos]while len text > delta and fm.width text > width text chomp text return unicode text
def _to_qemu_format fmt return TO_QEMU_FORMAT_MAP[fmt]
def git_working_dir func @wraps func def set_git_working_dir self *args **kwargs cur_wd os.getcwd os.chdir self.repo.working_tree_dir try return func self *args **kwargs finally os.chdir cur_wd return set_git_working_dir
def getImportRadius elementNode if elementNode None return 0.36preferences skeinforge_craft.getCraftPreferences 'carve' importCoarseness getImportCoarseness elementNode preferences layerHeight skeinforge_craft.getCraftValue 'LayerHeight' preferences layerHeight getCascadeFloatWithoutSelf layerHeight elementNode 'layerHeight' edgeWidthOverHeight skeinforge_craft.getCraftValue 'EdgeWidthoverHeight' preferences edgeWidthOverHeight getCascadeFloatWithoutSelf edgeWidthOverHeight elementNode 'edgeWidthOverHeight' return getCascadeFloatWithoutSelf 0.5 * importCoarseness * layerHeight * edgeWidthOverHeight elementNode 'importRadius'
@login_required@require_http_methods ['GET' 'POST'] @mobile_template 'users/{mobile/}edit_settings.html' def edit_settings request template if request.method 'POST' form SettingsForm request.POST if form.is_valid form.save_for_user request.user messages.add_message request messages.INFO _ u'Yoursettingshavebeensaved.' return HttpResponseRedirect reverse 'users.edit_settings' return render request template {'form' form} values request.user.settings.values initial dict for v in values try initial[v['name']] literal_eval v['value'] except SyntaxError ValueError initial[v['name']] v['value']form SettingsForm initial initial return render request template {'form' form}
def _impose_f_order X if X.flags.c_contiguous return check_array X.T copy False order 'F' True else return check_array X copy False order 'F' False
def locale_info grains {}grains['locale_info'] {}if salt.utils.is_proxy return grainstry grains['locale_info']['defaultlanguage'] grains['locale_info']['defaultencoding'] locale.getdefaultlocale except Exception grains['locale_info']['defaultlanguage'] 'unknown'grains['locale_info']['defaultencoding'] 'unknown'grains['locale_info']['detectedencoding'] __salt_system_encoding__return grains
def handle_snapshot config_spec object_ref reloc_spec template vm_ if 'snapshot' not in vm_ return Noneallowed_types [FLATTEN_DISK_FULL_CLONE COPY_ALL_DISKS_FULL_CLONE CURRENT_STATE_LINKED_CLONE QUICK_LINKED_CLONE]clone_spec get_clonespec_for_valid_snapshot config_spec object_ref reloc_spec template vm_ if not clone_spec raise SaltCloudSystemExit 'Invaliddiskmovetypespecifiedsupportedtypesare{0}'.format ''.join allowed_types return clone_spec
def _arg bytes signed dvi _ return dvi._arg bytes signed
def _get_source_address course_id course_title truncate True course_title_no_quotes re.sub '"' '' course_title course_name re.sub '[^\\w.-]' '_' course_id.course from_addr_format u'"{course_title}"CourseStaff<{course_name}-{from_email}>'def format_address course_title_no_quotes '\nPartialfunctionforformattingthefrom_addr.Since\n`course_title_no_quotes`maybetruncatedtomakesurethereturned\nstringhasfewerthan320characters wedefinethisfunctiontomake\niteasytodeterminequicklywhatthemaxlengthisfor\n`course_title_no_quotes`.\n'return from_addr_format.format course_title course_title_no_quotes course_name course_name from_email configuration_helpers.get_value 'email_from_address' settings.BULK_EMAIL_DEFAULT_FROM_EMAIL from_addr format_address course_title_no_quotes __ encoded_from_addr forbid_multi_line_headers 'from' from_addr 'utf-8' escaped_encoded_from_addr escape encoded_from_addr if len escaped_encoded_from_addr > 320 and truncate from_addr format_address course_name return from_addr
def sample_dict d n 10 use_random True selected_keys random.sample list d min len d n if use_random else itertools.islice iterkeys d n return [ key d[key] for key in selected_keys]
def unescape_new_line escaped return ESCAPE_CHAR.join u'\n'.join u'\r'.join p.split ESCAPE_CHAR + u'r' .split ESCAPE_CHAR + u'n' for p in escaped.split ESCAPE_CHAR + ESCAPE_CHAR
@pytest.mark.skipif 'notHAS_BLEACH' def test_raw_html_write_clean import bleacht Table [['<script>x</script>'] ['<p>y</p>'] ['<em>y</em>']] names ['a' 'b' 'c'] out StringIO t.write out format 'ascii.html' htmldict {'raw_html_cols' t.colnames} expected '<tr>\n<td>&lt;script&gt;x&lt;/script&gt;</td>\n<td>&lt;p&gt;y&lt;/p&gt;</td>\n<td><em>y</em></td>\n</tr>'assert expected in out.getvalue out StringIO t.write out format 'ascii.html' htmldict {'raw_html_cols' t.colnames 'raw_html_clean_kwargs' {'tags' bleach.ALLOWED_TAGS + ['p'] }} expected '<tr>\n<td>&lt;script&gt;x&lt;/script&gt;</td>\n<td><p>y</p></td>\n<td><em>y</em></td>\n</tr>'assert expected in out.getvalue
def startIOHub global ioimport timepsychopy_mon_name 'testMonitor'exp_code 'events'sess_code 'S_{0}'.format long time.mktime time.localtime iohub_config {'psychopy_monitor_name' psychopy_mon_name 'mcu.iosync.MCU' dict serial_port 'auto' monitor_event_types ['AnalogInputEvent' 'DigitalInputEvent'] 'experiment_code' exp_code 'session_code' sess_code}return launchHubServer **iohub_config
def _add_sld_boilerplate symbolizer return '\n<StyledLayerDescriptorversion "1.0.0"xmlns "http //www.opengis.net/sld"xmlns ogc "http //www.opengis.net/ogc"\nxmlns xlink "http //www.w3.org/1999/xlink"xmlns xsi "http //www.w3.org/2001/XMLSchema-instance"\nxsi schemaLocation "http //www.opengis.net/sldhttp //schemas.opengis.net/sld/1.0.0/StyledLayerDescriptor.xsd">\n<NamedLayer>\n<Name>% name s</Name>\n<UserStyle>\n<Name>% name s</Name>\n<Title>% name s</Title>\n<FeatureTypeStyle>\n<Rule>\n' + symbolizer + '\n</Rule>\n</FeatureTypeStyle>\n</UserStyle>\n</NamedLayer>\n</StyledLayerDescriptor>\n'
def mine_get tgt fun tgt_type 'glob' opts None ret {}serial salt.payload.Serial opts checker CkMinions opts minions checker.check_minions tgt tgt_type cache salt.cache.Cache opts for minion in minions mdata cache.fetch 'minions/{0}'.format minion 'mine' if mdata is None continuefdata mdata.get fun if fdata ret[minion] fdatareturn ret
def set_permission perms permission 0for name in dir PERMS if name.startswith '_' continueif name in perms and perms[name] permission | getattr PERMS name return permission
def add_user name password None runas None clear_pw Falseif password is None clear_pw Truepassword ''.join random.SystemRandom .choice string.ascii_uppercase + string.digits for x in range 15 if runas is None and not salt.utils.is_windows runas salt.utils.get_user if salt.utils.is_windows python_shell Truecmd '"{0}"add_user"{1}""{2}"'.format __context__['rabbitmqctl'] name password else python_shell Falsecmd [__context__['rabbitmqctl'] 'add_user' name password]res __salt__['cmd.run_all'] cmd output_loglevel 'quiet' runas runas python_shell python_shell if clear_pw try clear_password name runas except Exception delete_user name runas raisemsg 'Added'return _format_response res msg
def parse_backend_uri backend_uri if backend_uri.find ' ' -1 raise InvalidCacheBackendError 'BackendURImuststartwithscheme //' scheme rest backend_uri.split ' ' 1 if not rest.startswith '//' raise InvalidCacheBackendError 'BackendURImuststartwithscheme //' host rest[2 ]qpos rest.find '?' if qpos ! -1 params dict parse_qsl rest[ qpos + 1 ] host rest[2 qpos]else params {}if host.endswith '/' host host[ -1 ]return scheme host params
def svm_save_model model_file_name model libsvm.svm_save_model model_file_name.encode model
def getSectionReference entry headers getFirstAncestorWithSectionHeader entry myHeader findNodeJustBefore entry headers return getSectionNumber myHeader
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _get_backup_name basename utctime datetime.datetime.utcnow utctime utctime.strftime '%Y%m%d_%H%M%S' return '{}-{}.json'.format basename utctime
@require_POSTdef join_group request url group get_object_or_404 Group url url profile_to_add request.user.userprofileif group.has_member profile_to_add messages.error request _ 'Youarealreadyinthisgroup.' elif group.has_pending_member profile_to_add messages.error request _ 'Yourrequesttojointhisgroupisstillpending.' elif group.accepting_new_members 'no' messages.error request _ 'Thisgroupisnotacceptingrequeststojoin.' else if group.accepting_new_members 'yes' status GroupMembership.MEMBERmessages.info request _ 'Youhavebeenaddedtothisgroup.' if group.terms status GroupMembership.PENDING_TERMSelif group.accepting_new_members 'by_request' status GroupMembership.PENDINGmessages.info request _ 'Yourmembershiprequesthasbeensenttothegroupcurator s .' group.add_member profile_to_add status status return redirect reverse 'groups show_group' args [group.url]
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def save_load jid load minions None serv _get_serv ret None serv.set jid json.dumps load _append_list serv 'jids' jid
def has_pair ip alias hosts _list_hosts return ip in hosts and alias in hosts[ip]
def mapall *args return list lazy_mapall *args
def list_sizes provider 'all' client _get_client sizes client.list_sizes provider return sizes
def backends return {'backends' user_backends_data g.user get_helper 'AUTHENTICATION_BACKENDS' get_helper 'STORAGE' do_import True }
def _centre x oshape start np.array x.shape - np.array oshape // 2 + 1 out x[[slice s s + n for s n in zip start oshape ]]return out
def set_carrier name _local.carrier name
def createDict data index return dict key values[index] for key values in data.iteritems
def _format_elemcreate etype script False *args **kw spec Noneopts if etype in 'image' 'vsapi' if etype 'image' iname args[0]imagespec _format_mapdict {None args[1 ]} [1]spec '%s%s' % iname imagespec else class_name part_id args[ 2]statemap _format_mapdict {None args[2 ]} [1]spec '%s%s%s' % class_name part_id statemap opts _format_optdict kw script elif etype 'from' spec args[0]if len args > 1 opts args[1] if script spec '{%s}' % spec opts ''.join map str opts return spec opts
def PatchStartNewThread thread_module thread threading_module threading thread_module.start_new_thread _MakeStartNewThread thread_module.start_new_thread reload threading_module
def utf8_encode value if isinstance value six.text_type return _utf8_encoder value [0]elif isinstance value six.binary_type return valueelse value_cls_name reflection.get_class_name value fully_qualified False raise TypeError 'valuemustbebasestring not%s' % value_cls_name
def p_typedef p setattr thrift_stack[ -1 ] p[3] p[2]
@utils.service_type 'monitor' def do_absolute_limits cs args limits cs.limits.get .absolutecolumns ['Name' 'Value']utils.print_list limits columns
def is_widget_required_attribute widget if DBS3_SET_REQUIRED_SET_DISABLED and not get_bootstrap_setting u'set_required' return Falseif not widget.is_required return Falseif isinstance widget AdminFileWidget HiddenInput FileInput CheckboxInput CheckboxSelectMultiple return Falsereturn True
def get_completed_courses student all_certs certificate_api.get_certificates_for_user student.username return [{'course_id' unicode cert['course_key'] 'mode' cert['type']} for cert in all_certs if certificate_api.is_passing_status cert['status'] ]
def letterbox image shape assert len image.shape 3 assert len shape 2 assert image.shape[0] < shape[0] assert image.shape[1] < shape[1] if image.shape[0] shape[0] and image.shape[1] shape[1] return image.copy rval np.zeros shape[0] shape[1] image.shape[2] dtype image.dtype rstart shape[0] - image.shape[0] / 2 cstart shape[1] - image.shape[1] / 2 rend rstart + image.shape[0] cend cstart + image.shape[1] rval[rstart rend cstart cend] imagereturn rval
def image_resize_and_sharpen image size preserve_aspect_ratio False factor 2.0 if image.mode ! 'RGBA' image image.convert 'RGBA' image.thumbnail size Image.ANTIALIAS if preserve_aspect_ratio size image.sizesharpener ImageEnhance.Sharpness image resized_image sharpener.enhance factor image Image.new 'RGBA' size 255 255 255 0 image.paste resized_image size[0] - resized_image.size[0] / 2 size[1] - resized_image.size[1] / 2 return image
def load_all_account_types for account_type in account_registry.keys _get_or_create_account_type account_type
def ensure_social_link website link if link '' or link is None return linkif link.find '/' ! -1 return linkelse return website + '/' + link
def unary_math_extern fn f32extern f64extern int_restype False f_restype types.int64 if int_restype else None def float_impl context builder sig args '\nImplement*fn*foratypes.Floatinput.\n'[val] argsmod builder.moduleinput_type sig.args[0]lty context.get_value_type input_type func_name {types.float32 f32extern types.float64 f64extern}[input_type]fnty Type.function lty [lty] fn cgutils.insert_pure_function builder.module fnty name func_name res builder.call fn val res context.cast builder res input_type sig.return_type return impl_ret_untracked context builder sig.return_type res lower fn types.Float float_impl unary_math_int_impl fn float_impl return float_impl
def _parse_allow allow seen_protos {}allow_dict []protocols allow.split ' ' for p in protocols pairs p.split ' ' if pairs[0].lower not in ['tcp' 'udp' 'icmp'] raise SaltCloudSystemExit 'Unsupportedprotocol{0}.Mustbetcp udp oricmp.'.format pairs[0] if len pairs 1 or pairs[0].lower 'icmp' seen_protos[pairs[0]] []elif pairs[0] not in seen_protos seen_protos[pairs[0]] [pairs[1]]else seen_protos[pairs[0]].append pairs[1] for k in seen_protos d {'IPProtocol' k}if len seen_protos[k] > 0 d['ports'] seen_protos[k]allow_dict.append d log.debug 'firewallallowedprotocols/ports {0}'.format allow_dict return allow_dict
def extract_from_query term filter regexp end_of_word_boundary True re_string '\\b%s \\s* %s ' % filter regexp if end_of_word_boundary re_string + '\\b'match re.search re_string term if match term term.replace match.group 0 '' .strip value match.group 1 else value Nonereturn term value
def _get_options raw_options apply_config if not raw_options return parse_args [u''] apply_config apply_config if isinstance raw_options dict options parse_args [u''] apply_config apply_config for name value in raw_options.items if not hasattr options name raise ValueError u"Nosuchoption'{}'".format name expected_type type getattr options name if not isinstance expected_type str unicode if isinstance value str unicode raise ValueError u"Option'{}'shouldnotbeastring".format name setattr options name value else options raw_optionsreturn options
def create_batch_id return str int time.time [ -6 ]
def _parse_json s def _obj_hook pairs 'convertjsonobjecttopythonobject'o JsonDict for k v in pairs.iteritems o[str k ] vreturn oreturn json.loads s object_hook _obj_hook
def unpack4 v assert len v 4 return struct.unpack '<I' v [0]
def markdown_unescape_field obj field_name if isinstance obj Model setattr obj field_name markdown_unescape getattr obj field_name elif isinstance obj dict obj[field_name] markdown_unescape obj[field_name] else raise TypeError u'Unexpectedtype%rpassedtomarkdown_unescape_field' % obj
def _in_process_find_conf_file conf_src_dir conf_file_name use_sample True dflt_src_dir os.path.normpath os.path.join os.path.abspath __file__ os.pardir os.pardir os.pardir 'etc' conf_src_dir dflt_src_dir if conf_src_dir is None else conf_src_dir conf_file_path os.path.join conf_src_dir conf_file_name if os.path.exists conf_file_path return conf_file_pathif use_sample conf_file_name + '-sample'conf_file_path os.path.join dflt_src_dir conf_file_name if os.path.exists conf_file_path return conf_file_pathmsg 'Failedtofindconfigfile%s' % conf_file_name raise InProcessException msg
def round_to_float number precision rounded Decimal str floor number + precision / 2 // precision * Decimal str precision return float rounded
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def _format_error_html msg return u'<pclass "error_msg">{msg}</p>'.format msg msg
def add_request_suffix string return string + REQUEST_SUFFIX
def stopListening global _listenerlogging._acquireLock try if _listener _listener.abort 1_listener Nonefinally logging._releaseLock
def read_env key value envkey key.replace '.' '_' .replace '-' '_' .upper return native_value os.getenv envkey value
def cgiHandler environ config './tilestache.cfg' debug False if debug import cgitbcgitb.enable path_info environ.get 'PATH_INFO' None query_string environ.get 'QUERY_STRING' None script_name environ.get 'SCRIPT_NAME' None status_code headers content requestHandler2 config path_info query_string script_name headers.setdefault 'Content-Length' str len content stdout.write 'Status %d\n' % status_code for k v in headers.items stdout.write '%s %s\n' % k v stdout.write '\n' stdout.write content
def test_category_save database category Category title 'TestCategory' category.save assert category.title 'TestCategory'
def _clade_to_bitstr clade tree_term_names clade_term_names set term.name for term in clade.find_clades terminal True return _BitString.from_bool name in clade_term_names for name in tree_term_names
def _validate_flavor_parameter flavor if flavor is not None if flavor 'sqlite' warnings.warn "the'flavor'parameterisdeprecatedandwillberemovedinafutureversion as'sqlite'istheonlysupportedoptionwhenSQLAlchemyisnotinstalled." FutureWarning stacklevel 2 else raise ValueError 'databaseflavor{flavor}isnotsupported'.format flavor flavor
def get_course_milestones_fulfillment_paths course_id user_id if not settings.FEATURES.get 'MILESTONES_APP' return Nonereturn milestones_api.get_course_milestones_fulfillment_paths course_id user_id
def chart_runner chart scales axes marks for i scale in enumerate scales nt.assert_dict_equal chart.scales[i].grammar scale for i axis in enumerate axes nt.assert_dict_equal chart.axes[i].grammar axis for i mark in enumerate marks nt.assert_dict_equal chart.marks[i].grammar mark
def cleanup _lib.RAND_cleanup
def get_docs_url path_name version None return urljoin DOCS_BASE get_rtd_version version version path_name
def grad *args **kwargs return theano.gradient.grad disconnected_inputs 'ignore' *args **kwargs
def config_file_provider_builder xml_parent data xml_files XML.SubElement xml_parent 'managedFiles' files data.get 'files' [] for file in files xml_file XML.SubElement xml_files 'org.jenkinsci.plugins.configfiles.buildwrapper.ManagedFile' mapping [ 'file-id' 'fileId' None 'target' 'targetLocation' '' 'variable' 'variable' '' ]convert_mapping_to_xml xml_file file mapping fail_required True
def convert_sv_char c if 65 < ord c - 64 < 90 return chr ord c - 64 else try return chr ord c - 128 except ValueError return c
def rgb2xyz rgb arr _prepare_colorarray rgb .copy mask arr > 0.04045 arr[mask] np.power arr[mask] + 0.055 / 1.055 2.4 arr[ ~ mask ] / 12.92return _convert xyz_from_rgb arr
def order_tables_from_databases appdir_str None order_tool OrderTablesFromDatabases appdir_str return order_tool.order_tables
def education_level return s3_rest_controller 'pr' 'education_level'
def row2poly row deg x k 0poly []leng len row while row[k] 0 k k + 1 for j in range deg + 1 if k + j < leng poly.append row[ k + j ] return Poly poly x
def get_jobs server _connect jobs server.get_jobs if jobs return jobsreturn {}
def lookupMailBox name timeout None return getResolver .lookupMailBox name timeout
def flavor_list request try return api.nova.flavor_list request except Exception exceptions.handle request _ 'Unabletoretrieveinstanceflavors.' return []
def Scan client table callback def _OnScan retry_cb count result for item in result.items if options.options.col_names item dict [ k v for k v in item.items if k in options.options.col_names ] pprint.pprint item if result.last_key retry_cb result.last_key count + len result.items else return callback 'scanned%ditems' % count + len result.items def _Scan last_key None count 0 client.Scan table.name partial _OnScan _Scan count None limit 50 excl_start_key last_key _Scan
def refresh hive hive_names timeout 0.5 for hostname in hive_names if hive[hostname] is not None hive[hostname].expect [pexpect.TIMEOUT pexpect.EOF] timeout timeout
@add_divider_highlight_group u'background divider' def uptime pl days_format u'{days d}d' hours_format u'{hours d}h' minutes_format u'{minutes d}m' seconds_format u'{seconds d}s' shorten_len 3 try seconds _get_uptime except NotImplementedError pl.warn u'Unabletogetuptime.Youshouldinstallpsutilmodule' return None minutes seconds divmod seconds 60 hours minutes divmod minutes 60 days hours divmod hours 24 time_formatted list filter None [ days_format.format days days if days and days_format else None hours_format.format hours hours if hours and hours_format else None minutes_format.format minutes minutes if minutes and minutes_format else None seconds_format.format seconds seconds if seconds and seconds_format else None ] [0 shorten_len]return u''.join time_formatted .strip
def makeBuildDir tmpDir tempfile.mkdtemp os.makedirs os.path.join tmpDir 'RPMS' 'noarch' os.makedirs os.path.join tmpDir 'SPECS' os.makedirs os.path.join tmpDir 'BUILD' os.makedirs os.path.join tmpDir 'SOURCES' os.makedirs os.path.join tmpDir 'SRPMS' log.msg format 'CreatedRPMbuildstructurein% path r' path tmpDir return tmpDir
def displayable_path path separator u';' if isinstance path list tuple return separator.join displayable_path p for p in path elif isinstance path unicode return pathelif not isinstance path str return unicode path try return path.decode _fsencoding 'ignore' except UnicodeError LookupError return path.decode 'utf8' 'ignore'
def dirty name target user None username None password None ignore_unversioned False ret {'name' name 'result' True 'comment' '' 'changes' {}}return _fail ret 'Thisfunctionisnotimplementedyet.'
def action_allowed_user user app action allowed any match_rules group.rules app action for group in user.groups.all return allowed
def superpack_name pyver numver return 'scipy-%s-win32-superpack-python%s.exe' % numver pyver
def compiler_version version_info subprocess.check_output ['solc' '--version'] match re.search '^Version [0-9a-z.-]+ /' version_info re.MULTILINE if match return match.group 1
def get_reg_code_validity registration_code request limiter reg_code_already_redeemed Falsecourse_registration Nonetry course_registration CourseRegistrationCode.objects.get code registration_code except CourseRegistrationCode.DoesNotExist reg_code_is_valid Falseelse if course_registration.is_valid reg_code_is_valid Trueelse reg_code_is_valid Falsereg_code_already_redeemed RegistrationCodeRedemption.is_registration_code_redeemed registration_code if not reg_code_is_valid AUDIT_LOG.info 'RedemptionofainvalidRegistrationCode%s' registration_code limiter.tick_bad_request_counter request raise Http404 return reg_code_is_valid reg_code_already_redeemed course_registration
def apply_to_window sequence window_size function step None seqlen len sequence if step is None step max window_size // 2 1 else step max step 1 results []pos 0while pos < seqlen - window_size + 1 start middle end pos pos + window_size + pos // 2 pos + window_size fragment sequence[start end]value function fragment results.append middle value pos + stepif pos ! seqlen - window_size pos seqlen - window_size start middle end pos pos + window_size + pos // 2 pos + window_size fragment sequence[start end]value function fragment results.append middle value return results
def responder url function zsock zcontext.socket zmq.REP zsock.bind url while True word zsock.recv zsock.send function word
def match_xfs_options dev needed_options tmp_mount_dir tempfile.mkdtemp cmd 'mount%s%s' % dev tmp_mount_dir utils.system_output cmd xfs_growfs os.path.join os.environ['AUTODIR'] 'tools' 'xfs_growfs' cmd '%s-n%s' % xfs_growfs dev try current_option utils.system_output cmd finally cmd 'umount%s' % dev utils.system_output cmd ignore_status True os.rmdir tmp_mount_dir cmd 'mkfs.xfs%s-N-f%s' % needed_options dev needed_out utils.system_output cmd needed_out re.sub 'internallog' 'internal' needed_out if current_option needed_out return Trueelse return False
def splder tck n 1 if isinstance tck BSpline return tck.derivative n else return _impl.splder tck n
def load_library lib name None lib_cls None try if lib_cls return lib_cls lib else return ctypes.CDLL lib except Exception if name lib_msg '%s %s ' % name lib else lib_msg liblib_msg + 'couldnotbeloaded'if sys.platform 'cygwin' lib_msg + 'incygwin'_LOGGER.error lib_msg exc_info True return None
def add_user name password None runas None clear_pw Falseif password is None clear_pw Truepassword ''.join random.SystemRandom .choice string.ascii_uppercase + string.digits for x in range 15 if runas is None and not salt.utils.is_windows runas salt.utils.get_user if salt.utils.is_windows python_shell Truecmd '"{0}"add_user"{1}""{2}"'.format __context__['rabbitmqctl'] name password else python_shell Falsecmd [__context__['rabbitmqctl'] 'add_user' name password]res __salt__['cmd.run_all'] cmd output_loglevel 'quiet' runas runas python_shell python_shell if clear_pw try clear_password name runas except Exception delete_user name runas raisemsg 'Added'return _format_response res msg
def set_rng new_rng global _rng_rng new_rng
def rebuild s return construct deconstruct s
def prepare_suites_from_test_cases case_class_list test_suites []for cls in case_class_list test_suites.append unittest.TestLoader .loadTestsFromTestCase cls return test_suites
def cp_key c ring return lbp_key lbp c[0] ring.zero Num c[2] lbp_key lbp c[3] ring.zero Num c[5]
def python_prereqs_installation for req_file in PYTHON_REQ_FILES pip_install_req_file req_file
def _strftime1900 d format if d.year < 1900 return strftime format 1900 + d.timetuple [1 ] .replace '1900' str d.year 1 return datetime.strftime d format
def delete_service name restart True out __mgmt name 'service' 'delete' if restart if out 'success' return __firewall_cmd '--reload' return out
def DocFileSuite *paths **kw suite unittest.TestSuite if kw.get 'module_relative' True kw['package'] _normalize_module kw.get 'package' for path in paths suite.addTest DocFileTest path **kw return suite
def convert_symbol mpl_symbol if isinstance mpl_symbol list symbol list for s in mpl_symbol symbol + [convert_symbol s ]return symbolelif mpl_symbol in SYMBOL_MAP return SYMBOL_MAP[mpl_symbol]else return 'dot'
def report tracking_id client_id requestable extra_info None extra_headers None return [_request data extra_headers for data extra_headers in payloads tracking_id client_id requestable extra_info extra_headers ]
def find_source_space_hemi src xave src['rr'][ 0].sum if xave < 0 hemi int FIFF.FIFFV_MNE_SURF_LEFT_HEMI else hemi int FIFF.FIFFV_MNE_SURF_RIGHT_HEMI return hemi
def _make_env opts os_opts env {}for k v in opts.items key u'ST_' + k.upper .replace u'-' u'_' env[key] vfor k v in os_opts.items key u'OS_' + k.upper .replace u'-' u'_' env[key] vreturn env
def decrypt_password private_key password unencoded base64.b64decode password cmd ['openssl' 'rsautl' '-decrypt' '-inkey' private_key]proc subprocess.Popen cmd stdin subprocess.PIPE stdout subprocess.PIPE stderr subprocess.PIPE out err proc.communicate unencoded proc.stdin.close if proc.returncode raise DecryptionFailure err return out
@checker '.rst' severity 0 def check_line_length fn lines for lno line in enumerate lines if len line > 81 if line.lstrip [0] not in '+|' and 'http //' not in line and not line.lstrip .startswith '..function' '..method' '..cfunction' yield lno + 1 'linetoolong'
def is_https_enabled return bool SSL_CERTIFICATE.get and SSL_PRIVATE_KEY.get
def _parse_settings_source opts iface_type enabled iface adapters salt.utils.odict.OrderedDict adapters[iface] salt.utils.odict.OrderedDict adapters[iface]['type'] iface_typeadapters[iface]['data'] salt.utils.odict.OrderedDict iface_data adapters[iface]['data']iface_data['sources'] [opts['source']]return adapters
def _hmac_sha256 key msg return hmac.new key msg hashlib.sha256 .digest
def get_sorts request attr_info sort_keys list_args request 'sort_key' sort_dirs list_args request 'sort_dir' if len sort_keys ! len sort_dirs msg _ 'Thenumberofsort_keysandsort_dirsmustbesame' raise exc.HTTPBadRequest explanation msg valid_dirs [constants.SORT_DIRECTION_ASC constants.SORT_DIRECTION_DESC]absent_keys [x for x in sort_keys if x not in attr_info ]if absent_keys msg _ '%sisinvalidattributeforsort_keys' % absent_keys raise exc.HTTPBadRequest explanation msg invalid_dirs [x for x in sort_dirs if x not in valid_dirs ]if invalid_dirs msg _ "% invalid_dirs sisinvalidvalueforsort_dirs validvalueis'% asc s'and'% desc s'" % {'invalid_dirs' invalid_dirs 'asc' constants.SORT_DIRECTION_ASC 'desc' constants.SORT_DIRECTION_DESC} raise exc.HTTPBadRequest explanation msg return zip sort_keys [ x constants.SORT_DIRECTION_ASC for x in sort_dirs]
def _order_cluster_tree Z q deque tree to_tree Z q.append tree nodes []while q node q.popleft if not node.is_leaf bisect.insort_left nodes node q.append node.get_right q.append node.get_left return nodes
def plt_closeall n 10 for i in range n plt.close
def _normalize_args args if isinstance args six.string_types return shlex.split args if isinstance args tuple list return [str arg for arg in args]else return [str args ]
@deprecated u'2.1' def unmasked_index_ranges mask compressed True mask mask.reshape mask.size m np.concatenate 1 mask 1 indices np.arange len mask + 1 mdif m[1 ] - m[ -1 ] i0 np.compress mdif -1 indices i1 np.compress mdif 1 indices assert len i0 len i1 if len i1 0 return Noneif not compressed return np.concatenate i0[ np.newaxis] i1[ np.newaxis] axis 1 seglengths i1 - i0 breakpoints np.cumsum seglengths ic0 np.concatenate 0 breakpoints[ -1 ] ic1 breakpointsreturn np.concatenate ic0[ np.newaxis] ic1[ np.newaxis] axis 1
def summary_option return s3_rest_controller
def _get_session server if server in _sessions return _sessions[server]config _get_spacewalk_configuration server if not config raise Exception "Noconfigfor'{0}'foundonmaster".format server session _get_client_and_key config['api_url'] config['username'] config['password'] atexit.register _disconnect_session session client session['client']key session['key']_sessions[server] client key return client key
def setup_conf opts [cfg.StrOpt 'dhcp_driver' default 'quantum.agent.linux.dhcp.Dnsmasq' help _ 'ThedriverusedtomanagetheDHCPserver.' cfg.BoolOpt 'force' default False help _ 'Deletethenamespacebyremovingalldevices.' ]conf cfg.CONFconf.register_opts opts agent_config.register_root_helper conf conf.register_opts dhcp.OPTS return conf
def Ping **kwargs return rule port 8 proto 'icmp' **kwargs
def RawArray typecode_or_type size_or_initializer type_ typecode_to_type.get typecode_or_type typecode_or_type if isinstance size_or_initializer int long type_ type_ * size_or_initializer obj _new_value type_ ctypes.memset ctypes.addressof obj 0 ctypes.sizeof obj return objelse type_ type_ * len size_or_initializer result _new_value type_ result.__init__ *size_or_initializer return result
def _env_root repo saltenv if saltenv 'base' trunk os.path.join repo['repo'] repo['trunk'] if os.path.isdir trunk return trunkelse return Nonebranches os.path.join repo['repo'] repo['branches'] if os.path.isdir branches and saltenv in os.listdir branches return os.path.join branches saltenv tags os.path.join repo['repo'] repo['tags'] if os.path.isdir tags and saltenv in os.listdir tags return os.path.join tags saltenv return None
def _logHistoryItem action showid season episode quality resource provider version -1 logDate datetime.datetime.today .strftime History.date_format resource ss resource main_db_con db.DBConnection main_db_con.action 'INSERTINTOhistory action date showid season episode quality resource provider version VALUES ? ? ? ? ? ? ? ? ? ' [action logDate showid season episode quality resource provider version]
def trailing_whitespace physical_line physical_line physical_line.rstrip '\n' physical_line physical_line.rstrip '\r' physical_line physical_line.rstrip '\x0c' stripped physical_line.rstrip if physical_line ! stripped return len stripped 'W291trailingwhitespace'
def _rightmost_descendants node try rightmost_leaf max node.treepositions except AttributeError return []return [node[rightmost_leaf[ i]] for i in range 1 len rightmost_leaf + 1 ]
def _get_aa_regex codon_table stop '*' unknown 'X' from Bio.Data.CodonTable import CodonTableif not isinstance codon_table CodonTable raise TypeError 'InputtableisnotainstanceofBio.Data.CodonTableobject' aa2codon {}for codon aa in codon_table.forward_table.items aa2codon.setdefault aa [] .append codon for aa codons in aa2codon.items aa2codon[aa] _codons2re codons aa2codon[stop] _codons2re codon_table.stop_codons aa2codon[unknown] '...'return aa2codon
def _api_retry_all name output kwargs return report output keyword 'status' data retry_all_jobs
def sbool s if isinstance s str return s.lower in ['true' '1' 't' 'y' 'yes' 'yeah' 'yup' 'certainly' 'uh-huh'] else return bool s
def http_date timestamp None if timestamp is None timestamp time.time s email.utils.formatdate timestamp localtime False usegmt True return s
def deleteLoggedSnatch release size provider release prepareFailedName release failed_db_con db.DBConnection 'failed.db' failed_db_con.action 'DELETEFROMhistoryWHERErelease ?ANDsize ?ANDprovider ?' [release size provider]
def get16ByteUUID uuid return hashlib.md5 uuid .hexdigest [ 16]
def endsWith str suffix return str[ - len suffix ] suffix
def _read_old_pack fid tag shape rlims offset float np.fromstring fid.read 4 dtype '>f4' scale float np.fromstring fid.read 4 dtype '>f4' data np.fromstring fid.read tag.size - 8 dtype '>i2' data data * scale data + offsetreturn data
def tamper payload **kwargs retVal ''if payload retVal '%s%ssp_password' % payload '--' if not any _ if _ in payload else None for _ in '#' '--' else '' return retVal
def FindFilesIn directory pattern return glob.glob os.path.join directory pattern
def _bootstrap_fedora name **kwargs dst _make_container_root name if not kwargs.get 'version' False if __grains__['os'].lower 'fedora' version __grains__['osrelease']else version '21'else version '21'cmd 'yum-y--releasever {0}--nogpg--installroot {1}--disablerepo "*"--enablerepo fedorainstallsystemdpasswdyumfedora-releasevim-minimal'.format version dst ret __salt__['cmd.run_all'] cmd python_shell False if ret['retcode'] ! 0 _build_failed dst name return ret
def versions_information return salt.version.versions_information
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def enable_notifications user UserPreference.objects.get_or_create user user key NOTIFICATION_PREF_KEY defaults {'value' UsernameCipher.encrypt user.username }
def set_symbols_handler file_extension symbols_handler global SYMBOLS_HANDLERSYMBOLS_HANDLER[file_extension] symbols_handler
def in6_isvalid address try socket.inet_pton socket.AF_INET6 address return Trueexcept return False
def file_list *packages errors []ret []cmd ['pacman' '-Ql']if len packages > 0 and os.path.exists packages[0] packages list packages cmd.extend '-r' packages.pop 0 cmd.extend packages out __salt__['cmd.run'] cmd output_loglevel 'trace' python_shell False for line in salt.utils.itertools.split out '\n' if line.startswith 'error' errors.append line else comps line.split ret.append ''.join comps[1 ] return {'errors' errors 'files' ret}
def dependencies snippet path '' if isinstance snippet Function return snippet.dependencies path elif isinstance snippet collections.Mapping def mkpath key return '.'.join [path six.text_type key ] deps dependencies value mkpath key for key value in snippet.items return itertools.chain.from_iterable deps elif not isinstance snippet six.string_types and isinstance snippet collections.Iterable def mkpath idx return ''.join [path '[%d]' % idx ] deps dependencies value mkpath i for i value in enumerate snippet return itertools.chain.from_iterable deps else return []
def setgid gid os.setgid parse_gid gid
@command 'set|showconfig' def showconfig width util.getxy .widthwidth - 30s '%s%-17s%s %s\n'out '%s%-17s%s%s%s\n' % c.ul 'Key' 'Value' '' * width c.w for setting in config val config[setting]if not util.is_known_player config.PLAYER.get and val.require_known_player continueif g.detectable_size and setting 'MAX_RESULTS' continueif g.detectable_size and setting 'CONSOLE_WIDTH' continueout + s % c.g setting.lower c.w val.display g.content outg.message 'Enter%sset<key><value>%stochange\n' % c.g c.w g.message + 'Enter%ssetalldefault%storesetall' % c.g c.w
def isProcedureDone gcodeText procedure if gcodeText '' return FalseextruderInitializationIndex gcodeText.find ' </extruderInitialization> ' if extruderInitializationIndex -1 metadataBeginIndex gcodeText.find '<metadata>' metadataEndIndex gcodeText.find '</metadata>' if metadataBeginIndex ! -1 and metadataEndIndex ! -1 attributeString "procedureName '%s'" % procedure return gcodeText.find attributeString metadataBeginIndex metadataEndIndex ! -1 return Falsereturn gcodeText.find getTagBracketedProcedure procedure 0 extruderInitializationIndex ! -1
def acquit fmri return _fmadm_action_fmri 'acquit' fmri
def log_likelihood emp_cov precision p precision.shape[0]log_likelihood_ - np.sum emp_cov * precision + fast_logdet precision log_likelihood_ - p * np.log 2 * np.pi log_likelihood_ / 2.0return log_likelihood_
def associate_user backend user uid social_user None *args **kwargs if social_user or not user return Nonetry social UserSocialAuth.create_social_auth user uid backend.name except IntegrityError return social_auth_user backend uid user social_user social_user *args **kwargs else return {'social_user' social 'user' social.user 'new_association' True}
def butter2d_hp size cutoff n 3 return 1.0 - butter2d_lp size cutoff n
def get_releases_in_collection collection limit None offset None params {}if limit params['limit'] limitif offset params['offset'] offsetreturn _do_mb_query 'collection' '%s/releases' % collection [] params
def get_group_name_id group if re.match '\\d+' str group group_info grp.getgrgid group else group_info grp.getgrnam group return group_info[0] group_info[2]
def is_valid target if nick_re.match target return Trueelse return False
def stop_gradient variables return theano.gradient.disconnected_grad variables
def token_offsets tokens end_offset 0previous_end_row 0previous_end_column 0for t in tokens token_type t[0]token_string t[1] start_row start_column t[2] end_row end_column t[3]end_offset + start_columnif previous_end_row start_row end_offset - previous_end_columnstart_offset end_offsetend_offset + len token_string yield token_type token_string start_offset end_offset previous_end_row end_rowprevious_end_column end_column
def sm_flavor_update context sm_flavor_id values return IMPL.sm_flavor_update context values
def _get_conversion_multiplier big_unit_code small_unit_code if big_unit_code 14 return 1c big_unit_codefactor 1while c < small_unit_code try c mult _factors[c]except KeyError return Nonefactor * multif c small_unit_code return factorelse return None
def FromImport package_name name_leafs for leaf in name_leafs leaf.remove children [Leaf token.NAME 'from' Leaf token.NAME package_name prefix '' Leaf token.NAME 'import' prefix '' Node syms.import_as_names name_leafs ]imp Node syms.import_from children return imp
@register u'vi-editing-mode' def vi_editing_mode event event.cli.editing_mode EditingMode.VI
@login_required@enforce_shopping_cart_enableddef remove_item request item_id request.GET.get 'id' or request.POST.get 'id' or '-1' items OrderItem.objects.filter id item_id status 'cart' .select_subclasses if not len items log.exception u'CannotremovecartOrderItemid %s.DoesNotExistoritemisalreadypurchased' item_id else item items[0]if item.user request.user Order.remove_cart_item_from_order item request.user item.order.update_order_type return HttpResponse 'OK'
def get_data name if name in editors return editors[name].get_raw_data return current_container .raw_data name
def get_sql_initial_data apps return style.ERROR "Thisactionhasbeenrenamed.Try'./manage.pysqlcustom%s'." % ''.join apps and apps or ['app1' 'app2']
def make_tag_decorator known_tags def tag *tags '\nTagatestmethodwiththegiventags.\nCanbeusedinconjunctionwiththe--tagscommand-lineargument\nforruntests.py.\n'for t in tags if t not in known_tags raise ValueError 'unknowntag %r' % t def decorate func if not callable func or isinstance func type or not func.__name__.startswith 'test_' raise TypeError '@tag ... shouldbeusedontestmethods' try s func.tagsexcept AttributeError s func.tags set s.update tags return funcreturn decoratereturn tag
def set_trace import pdbimport sysstdout sys.stdoutsys.stdout sys.__stdout__pdb.Pdb .set_trace sys._getframe .f_back
def get_application return tornado.web.Application [ '/?' MainHandler dict backup_recovery_service BackupService ]
def global_max col_vals index col_vals_without_None [x for x in col_vals if x is not None ] max_col min_col zip *col_vals_without_None return max max_col min min_col
def testEnabledDataStoreAutoSessionCode import timefrom pprint import pprintpsychopy_mon_name 'testMonitor'exp_code 'gap_endo_que'sess_code 'S_{0}'.format long time.mktime time.localtime print 'CurrentSessionCodewillbe ' sess_code io launchHubServer psychopy_monitor_name psychopy_mon_name experiment_code exp_code session_code sess_code display io.devices.displayprint 'DisplayPsychopyMonitorName ' display.getPsychopyMonitorName print 'DisplayDefaultEyeDistance ' display.getDefaultEyeDistance print 'DisplayPhysicalDimensions ' display.getPhysicalDimensions print 'ExperimentMetadata ' pprint io.getExperimentMetaData print '\nSessionMetadata ' pprint io.getSessionMetaData io.quit
def _machine_bytes machine_hash hashlib.md5 if PY3 machine_hash.update socket.gethostname .encode else machine_hash.update socket.gethostname return machine_hash.digest [0 3]
def unregister disp host resp disp.SendAndWaitForResponse Iq 'set' NS_REGISTER to host payload [Node 'remove' ] if isResultNode resp return 1
def remove_queue_name_prefix name prefix _get_queue_name_prefix if not name.startswith prefix raise ValueError u'Queuename"{}"isnotprefixed.'.format name return name[len prefix ]
def _mk_tree basedir tempfile.mkdtemp return basedir
def plaintext html keep [] replace blocks linebreaks 2 indentation False if isinstance html Element html html.contentif not keep.__contains__ 'script' html strip_javascript html if not keep.__contains__ 'style' html strip_inline_css html if not keep.__contains__ 'form' html strip_forms html if not keep.__contains__ 'comment' and not keep.__contains__ '!--' html strip_comments html html html.replace '\r' '\n' html strip_tags html exclude keep replace replace html decode_entities html html collapse_spaces html indentation html collapse_tabs html indentation html collapse_linebreaks html linebreaks html html.strip return html
def isrecursive object return _safe_repr object {} None 0 [2]
def urlsafe_base64_encode s return base64.urlsafe_b64encode s .rstrip '\n '
def get_language_bidi lang get_language if lang is None return Falseelse base_lang get_language .split '-' [0]return base_lang in settings.LANGUAGES_BIDI
def header_expand headers collector []if isinstance headers dict headers list headers.items elif isinstance headers basestring return headerselif isinstance headers str return headers.encode 'latin-1' elif headers is None return headersfor i value params in enumerate headers _params []for p_k p_v in list params.items _params.append '%s %s' % p_k p_v collector.append value collector.append ';' if len params collector.append ';'.join _params if not len headers i + 1 collector.append ' ' if collector[ -1 ] in ' ' ';' del collector[ -1 ]return ''.join collector
def explode_rdn rdn notypes 0 flags 0 if not rdn return []rdn_decomp str2dn rdn flags [0]if notypes return [ avalue or '' for atype avalue dummy in rdn_decomp]else return [' '.join atype escape_dn_chars avalue or '' for atype avalue dummy in rdn_decomp]
def num_to_bytes num bval ''bval + bytes chr 255 & num >> 24 bval + bytes chr 255 & num >> 16 bval + bytes chr 255 & num >> 8 bval + bytes chr 255 & num >> 0 return bval
def migrate_local_facts facts migrated_facts copy.deepcopy facts migrated_facts migrate_docker_facts migrated_facts migrated_facts migrate_common_facts migrated_facts migrated_facts migrate_node_facts migrated_facts migrated_facts migrate_hosted_facts migrated_facts migrated_facts migrate_admission_plugin_facts migrated_facts return migrated_facts
def _set_attribute_func function attribute value orig_func functionwhile isinstance orig_func partial orig_func orig_func.funcsetattr orig_func attribute value
def MGF1 mgfSeed maskLen hash T b '' for counter in xrange ceil_div maskLen hash.digest_size c long_to_bytes counter 4 hobj hash.new hobj.update mgfSeed + c T T + hobj.digest assert len T > maskLen return T[ maskLen]
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def format_response action response return { '%sResponse' % action { '%sResult' % action response}}
def _scipy_univariate_kde data bw gridsize cut clip try kde stats.gaussian_kde data bw_method bw except TypeError kde stats.gaussian_kde data if bw ! 'scott' msg 'Ignoringbandwidthchoice pleaseupgradescipytouseadifferentbandwidth.'warnings.warn msg UserWarning if isinstance bw string_types bw 'scotts' if bw 'scott' else bw bw getattr kde '%s_factor' % bw * np.std data grid _kde_support data bw gridsize cut clip y kde grid return grid y
def zpk2ss z p k return tf2ss *zpk2tf z p k
def _retry_on_unavailable exc return exc_to_code exc StatusCode.UNAVAILABLE
def test_make_imbalance_multiclass y_ np.zeros 1000 y_[100 500] 1y_[500 ] 2 X_ y_ make_imbalance X y_ ratio 0.1 min_c_ 0 counter Counter y_ assert_equal counter[0] 90 assert_equal counter[1] 400 assert_equal counter[2] 500 assert_true np.all [ X_i in X for X_i in X_]
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def CropObservations env if env.spec.tags.get 'flashgames' False spec runtime_spec 'flashgames' .server_registry[env.spec.id]return _CropObservations env x 18 y 84 height spec['height'] width spec['width'] elif env.spec.tags.get 'atari' False and env.spec.tags.get 'vnc' False return _CropObservations env height 194 width 160 else return env
def set_stock_basics dat ts.get_stock_basics engine create_engine ct._ENGINE_ dat.to_sql 'stock_basics' engine if_exists 'replace'
def get_environ environ for key in 'REMOTE_ADDR' 'SERVER_NAME' 'SERVER_PORT' if key in environ yield key environ[key]
def _NamesNotIn names mapping return [name for name in names if name not in mapping ]
def CheckFlowCanBeStartedOnClient flow_name flow_cls flow.GRRFlow.GetPlugin flow_name if not flow_cls.ACL_ENFORCED or flow_cls.category return Trueelse raise access_control.UnauthorizedAccess "Flow%scan'tbestartedonaclientbynon-suidusers." % flow_name
def preprocess_input x dim_ordering 'default' if dim_ordering 'default' dim_ordering K.image_dim_ordering assert dim_ordering in {'tf' 'th'} if dim_ordering 'th' x x[ -1 ]x[ 0 ] - 103.939x[ 1 ] - 116.779x[ 2 ] - 123.68else x x[ -1 ]x[ 0] - 103.939x[ 1] - 116.779x[ 2] - 123.68return x
def test_result jobs bg.BackgroundJobManager j jobs.new sleeper j.join nt.assert_equal j.result['interval'] t_short
def find_clickable_id_with_wait context id_str **kwargs return _find_clickable_elem_with_wait context By.ID id_str **kwargs
def convert_ByteStringProperty model prop kwargs return get_TextField kwargs
def issue_line issue template '#{number}{tags}{title}'tags issue_tags issue params {'title' issue['title'].capitalize .rstrip '.' 'number' issue['number'] 'tags' ''.join '[{}]'.format tag for tag in tags + '' if tags else '' }return template.format **params
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def simple_class_factory model attrs return model
def rheber shazeline random.choice [name for name value in globals .items if type value is type rheber ]
@management.before_requestdef check_fresh_login if not login_fresh return current_app.login_manager.needs_refresh
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def set_printoptions precision None threshold None edgeitems None linewidth None profile None if profile is not None if profile 'default' PRINT_OPTS.precision 4PRINT_OPTS.threshold 1000PRINT_OPTS.edgeitems 3PRINT_OPTS.linewidth 80elif profile 'short' PRINT_OPTS.precision 2PRINT_OPTS.threshold 1000PRINT_OPTS.edgeitems 2PRINT_OPTS.linewidth 80elif profile 'full' PRINT_OPTS.precision 4PRINT_OPTS.threshold float 'inf' PRINT_OPTS.edgeitems 3PRINT_OPTS.linewidth 80if precision is not None PRINT_OPTS.precision precisionif threshold is not None PRINT_OPTS.threshold thresholdif edgeitems is not None PRINT_OPTS.edgeitems edgeitemsif linewidth is not None PRINT_OPTS.linewidth linewidth
def serialize_for_reading element return etree.tostring element encoding u'unicode' pretty_print True
def isabs s s splitdrive s [1]return len s > 0 and s[ 1] in _get_bothseps s
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def _check_ruby ret ruby user None match_version Truematch_micro_version Falsemicro_version_regex re.compile '- [0-9]{4}\\.[0-9]{2}|p[0-9]+ $' if micro_version_regex.search ruby match_micro_version Trueif re.search '^[a-z]+$' ruby match_version Falseruby re.sub '^ruby-' '' ruby for impl version default in __salt__['rvm.list'] runas user if impl ! 'ruby' version '{impl}-{version}'.format impl impl version version if not match_micro_version version micro_version_regex.sub '' version if not match_version version re.sub '-.*' '' version if version ruby ret['result'] Trueret['comment'] 'Requestedrubyexists.'ret['default'] defaultbreakreturn ret
def test_get_inst_data raw read_raw_fif fname_raw raw.crop tmax 1.0 assert_equal _get_inst_data raw raw._data raw.pick_channels raw.ch_names[ 2] epochs _segment_raw raw 0.5 assert_equal _get_inst_data epochs epochs._data evoked epochs.average assert_equal _get_inst_data evoked evoked.data evoked.crop tmax 0.1 picks list range 2 freqs np.array [50.0 55.0] n_cycles 3tfr tfr_morlet evoked freqs n_cycles return_itc False picks picks assert_equal _get_inst_data tfr tfr.data assert_raises TypeError _get_inst_data 'foo'
def test_freeze_with_local_option script result script.pip_install_local 'initools 0.2' result script.pip 'freeze' expect_stderr True expected textwrap.dedent 'INITools 0.2\nwsgiref ...\n<BLANKLINE>' result script.pip 'freeze' '--local' expect_stderr True expected textwrap.dedent 'INITools 0.2\n<BLANKLINE>' _check_output result.stdout expected
def bitswap s out []for c in s out.append unbits bits_str c [ -1 ] return ''.join out
@access_log_level logging.WARN def kill_task_attempt request attemptid ret request.jt.kill_task_attempt request.jt.thriftattemptid_from_string attemptid return render_json {}
def set_tcp_md5sig s addr key impls {'FreeBSD' _set_tcp_md5sig_bsd 'Linux' _set_tcp_md5sig_linux 'NetBSD' _set_tcp_md5sig_bsd}system platform.system try impl impls[system]except KeyError raise NotImplementedError 'TCP-MD5unsupportedonthisplatform' impl s addr key
def _needs_update cloud module router network internal_subnet_ids if router['admin_state_up'] ! module.params['admin_state_up'] return Trueif router['external_gateway_info'] if router['external_gateway_info'].get 'enable_snat' True ! module.params['enable_snat'] return Trueif network if not router['external_gateway_info'] return Trueelif router['external_gateway_info']['network_id'] ! network['id'] return Trueif module.params['external_fixed_ips'] for new_iface in module.params['external_fixed_ips'] subnet cloud.get_subnet new_iface['subnet'] exists Falsefor existing_iface in router['external_gateway_info']['external_fixed_ips'] if existing_iface['subnet_id'] subnet['id'] if 'ip' in new_iface if existing_iface['ip_address'] new_iface['ip'] exists Truebreakelse exists Truebreakif not exists return Trueif module.params['interfaces'] existing_subnet_ids []for port in cloud.list_router_interfaces router 'internal' if 'fixed_ips' in port for fixed_ip in port['fixed_ips'] existing_subnet_ids.append fixed_ip['subnet_id'] if set internal_subnet_ids ! set existing_subnet_ids return Truereturn False
def getTreeWalker treeType implementation None **kwargs treeType treeType.lower if treeType not in treeWalkerCache if treeType u'dom' from . import domtreeWalkerCache[treeType] dom.TreeWalkerelif treeType u'genshi' from . import genshitreeWalkerCache[treeType] genshi.TreeWalkerelif treeType u'lxml' from . import etree_lxmltreeWalkerCache[treeType] etree_lxml.TreeWalkerelif treeType u'etree' from . import etreeif implementation is None implementation default_etreereturn etree.getETreeModule implementation **kwargs .TreeWalkerreturn treeWalkerCache.get treeType
def task weight 1 def decorator_func func func.locust_task_weight weightreturn func'\nCheckiftaskwasusedwithoutparentheses notcalled likethis \n\n@task\ndefmy_task \npass\n'if callable weight func weightweight 1return decorator_func func else return decorator_func
def contrastive x0 x1 y margin 1 return Contrastive margin x0 x1 y
def is_compat major_ver 1 import openpyxlver LooseVersion openpyxl.__version__ if major_ver 1 return LooseVersion start_ver < ver < LooseVersion stop_ver elif major_ver 2 return LooseVersion stop_ver < ver else raise ValueError 'cannottestforopenpyxlcompatibilitywithver{0}'.format major_ver
def lang_drop cursor lang cascade cursor.execute 'SAVEPOINTansible_pgsql_lang_drop' try if cascade cursor.execute 'DROPLANGUAGE"%s"CASCADE' % lang else cursor.execute 'DROPLANGUAGE"%s"' % lang except cursor.execute 'ROLLBACKTOSAVEPOINTansible_pgsql_lang_drop' cursor.execute 'RELEASESAVEPOINTansible_pgsql_lang_drop' return Falsecursor.execute 'RELEASESAVEPOINTansible_pgsql_lang_drop' return True
def StripWhitespace stream last_type Nonehas_space Falseignore_group frozenset Comparison Punctuation for token_type value in stream if last_type if token_type in Whitespace has_space Truecontinueelif token_type in Whitespace Whitespace.Newline ignore_group continueif has_space if not ignore_group.intersection last_type token_type yield Whitespace '' has_space False yield token_type value last_type token_type
def irecv shape dtype source tag return MPIRecv source tag shape dtype
def environmentfilter f f.environmentfilter Truereturn f
def get_history_items return [readline.get_history_item i for i in xrange 1 readline.get_current_history_length + 1 ]
def _in_memory_up_to_date cache_length return _module_values[u'certs'] and _module_values[u'last_update'] and _module_values[u'last_update'] > time.time - cache_length * 60 * 60
def encode_node node_id links None score 1 node {}if links is not None node['links'] sorted links.items node['score'] scorereturn JSONProtocol.write node_id node + '\n'
def _rebuild_function code_reduced globals name cell_values if cell_values cells tuple _dummy_closure v .__closure__[0] for v in cell_values else cells code _rebuild_code *code_reduced modname globals['__name__']try _rebuild_module modname except ImportError del globals['__name__']return FunctionType code globals name cells
def fetch url 'https //techblog.willshouse.com/2012/01/03/most-common-user-agents/'page requests.get url page html.fromstring page.text path '//*[@id "post-2229"]/div[2]/table/tbody'return page.xpath path [0]
def get_config_db_value key return settings.settings.get_value 'AUTOTEST_WEB' key
def generate_signature data rsa_key import base64try from tlslite.utils import keyfactoryexcept ImportError from gdata.tlslite.utils import keyfactoryprivate_key keyfactory.parsePrivateKey rsa_key signed private_key.hashAndSign data if hasattr base64 'b64encode' return base64.b64encode signed else return base64.encodestring signed .replace '\n' ''
def list_stacks env None _init_rosstack env env return _rosstack.list
def make_static_urls_absolute request html def replace __ prefix quote rest '\nFunctiontoactuallydoasinglerelative->absoluteurlreplacement\n'processed request.build_absolute_uri prefix + rest return quote + processed + quote return process_static_urls html replace
def test_replay_dump_template_name monkeypatch mocker user_config_data user_config_file monkeypatch.chdir 'tests/fake-repo-tmpl' mock_replay_dump mocker.patch 'cookiecutter.main.dump' mocker.patch 'cookiecutter.main.generate_files' cookiecutter '.' no_input True replay False config_file user_config_file mock_replay_dump.assert_called_once_with user_config_data['replay_dir'] 'fake-repo-tmpl' mocker.ANY
def map_indices_py arr return dict [ x i for i x in enumerate arr ]
def getMinimumByVector3Paths paths minimum Vector3 9.876543219876543e+17 9.876543219876543e+17 9.876543219876543e+17 for path in paths for point in path minimum.minimize point return minimum
def sort_root_accounts roots def compare_roots a b if a.report_type ! b.report_type and a.report_type u'BalanceSheet' return -1 if a.root_type ! b.root_type and a.root_type u'Asset' return -1 if a.root_type u'Liability' and b.root_type u'Equity' return -1 if a.root_type u'Income' and b.root_type u'Expense' return -1 return 1roots.sort compare_roots
def do_nothing return
def builtin_format_id fmt return BUILTIN_FORMATS_REVERSE.get fmt
def tsem a limits None inclusive True True axis 0 ddof 1 a ma.asarray a .ravel if limits is None n float a.count return a.std axis axis ddof ddof / ma.sqrt n am trima a.ravel limits inclusive sd np.sqrt am.var axis axis ddof ddof return sd / np.sqrt am.count
def gradients loss variables return tf.gradients loss variables colocate_gradients_with_ops True
def get_dH2 lab1 lab2 lab1 np.asarray lab1 lab2 np.asarray lab2 a1 b1 np.rollaxis lab1 -1 [1 3] a2 b2 np.rollaxis lab2 -1 [1 3]C1 np.hypot a1 b1 C2 np.hypot a2 b2 term C1 * C2 - a1 * a2 + b1 * b2 return 2 * term
def only_skips tests_run reasons return has_results tests_run Equals tests_run skipped AfterPreprocessing lambda xs list unicode x[1] for x in xs Equals reasons
def bulk client actions stats_only False **kwargs success failed 0 0 errors []for ok item in streaming_bulk client actions **kwargs if not ok if not stats_only errors.append item failed + 1else success + 1return success failed if stats_only else errors
def teardown shutil.rmtree TMP_TEST_DIR sys.path old_syspath
def get_sentiment_label sentiment if sentiment < 0 return -1 elif sentiment > 0 return 1else return 0
def sync_proxymodules saltenv 'base' return salt.utils.extmods.sync __opts__ 'proxy' saltenv saltenv [0]
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def extract_options field_list option_list []for field in field_list if len field[0].astext .split ! 1 raise BadOptionError 'extensionoptionfieldnamemaynotcontainmultiplewords' name str field[0].astext .lower body field[1]if len body 0 data Noneelif len body > 1 or not isinstance body[0] nodes.paragraph or len body[0] ! 1 or not isinstance body[0][0] nodes.Text raise BadOptionDataError 'extensionoptionfieldbodymaycontain\nasingleparagraphonly option"%s" ' % name else data body[0][0].astext option_list.append name data return option_list
def make_arg_reduction func argfunc is_nan_func False chunk partial arg_chunk func argfunc combine partial arg_combine func argfunc if is_nan_func agg partial nanarg_agg func argfunc else agg partial arg_agg func argfunc @wraps argfunc def _ x axis None split_every None return arg_reduction x chunk combine agg axis split_every return _
def align_targets predictions targets if getattr predictions 'broadcastable' None False True and getattr targets 'ndim' None 1 targets as_theano_expression targets .dimshuffle 0 'x' return predictions targets
def initialize db.configure_db
def directional_variance X w return sum directional_variance_i x_i w for x_i in X
def getAroundsFromPath path radius thresholdRatio 0.9 radius abs radius points getPointsFromPath path radius thresholdRatio return getAroundsFromPathPoints points radius thresholdRatio 0.9
def agent_checks consul_url None ret {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retfunction 'agent/checks'ret _query consul_url consul_url function function method 'GET' return ret
def nvlist2 thelist names None for _ _ value in nvlist thelist names for each in nvlist value yield each
def test_filter net_filter valid Falsetry scapy.arch.attach_filter None net_filter except Scapy_Exception passexcept valid Truereturn valid
def gf_rshift f n K if not n return f [] else return f[ - n ] f[ - n ]
def replaceUrls sheetOrStyle replacer ignoreImportRules False if not ignoreImportRules and not isinstance sheetOrStyle css.CSSStyleDeclaration for importrule in r for r in sheetOrStyle if r.type r.IMPORT_RULE importrule.href replacer importrule.href def styleDeclarations base 'recursivegeneratortofindallCSSStyleDeclarations'if hasattr base 'cssRules' for rule in base.cssRules for s in styleDeclarations rule yield s elif hasattr base 'style' yield base.style elif isinstance sheetOrStyle css.CSSStyleDeclaration yield base for style in styleDeclarations sheetOrStyle for p in style.getProperties all True for v in p.propertyValue if v.type v.URI v.uri replacer v.uri
def lc value if not value return ''return value.lower .strip '.'
def information_content synset global IC_MAXif not IC IC[NOUN] {}IC[VERB] {}for s in open IC_CORPUS .readlines [1 ] s s.split id w pos int s[0][ -1 ] float s[1] s[0][ -1 ] 'n' and NOUN or VERB if len s 3 and s[2] 'ROOT' IC[pos][0] IC[pos].get 0 0 + w if w ! 0 IC[pos][id] wif w > IC_MAX IC_MAX wreturn IC.get synset.pos {} .get synset.id 0.0 / IC_MAX
def set_permissions obj_name principal permissions access_mode 'grant' applies_to 'this_folder_subfolders_files' obj_type 'file' reset_perms False protected None if reset_perms dacl Dacl obj_type obj_type else dacl Dacl obj_name obj_type dacl.rm_ace principal access_mode dacl.add_ace principal access_mode permissions applies_to dacl.order_acl dacl.save obj_name protected return True
@auth.s3_requires_membership 1 def errors from gluon.admin import apathfrom gluon.fileutils import listdirfor item in request.vars if item[ 7] 'delete_' os.unlink apath '%s/errors/%s' % appname item[7 ] r request func lambda p os.stat apath '%s/errors/%s' % appname p r request .st_mtime tickets sorted listdir apath '%s/errors/' % appname r request '^\\w.*' key func reverse True return dict app appname tickets tickets
def imod a b a % breturn a
def make_binary_operator_eval oper f g return lambda inputs params tuple oper x y for x y in zip f inputs params g inputs params
def col name None dtype None if dtype is None dtype config.floatXtype CudaNdarrayType dtype dtype broadcastable False True return type name
def get_c_type name if isinstance name asdl.Id name name.valueif name in asdl.builtin_types return nameelse return '%s_ty' % name
def _create_unverified_context protocol PROTOCOL_SSLv23 cert_reqs None check_hostname False purpose Purpose.SERVER_AUTH certfile None keyfile None cafile None capath None cadata None if not isinstance purpose _ASN1Object raise TypeError purpose context SSLContext protocol context.options | OP_NO_SSLv2context.options | OP_NO_SSLv3if cert_reqs is not None context.verify_mode cert_reqscontext.check_hostname check_hostnameif keyfile and not certfile raise ValueError 'certfilemustbespecified' if certfile or keyfile context.load_cert_chain certfile keyfile if cafile or capath or cadata context.load_verify_locations cafile capath cadata elif context.verify_mode ! CERT_NONE context.load_default_certs purpose return context
def Corr xs ys xs np.asarray xs ys np.asarray ys meanx varx MeanVar xs meany vary MeanVar ys corr Cov xs ys meanx meany / math.sqrt varx * vary return corr
def _get_gid name if getgrnam is None or name is None return Nonetry result getgrnam name except KeyError result Noneif result is not None return result[2]return None
def Function fname klassname '_%s_Function' % fname c globals [klassname] return c
def get_scheme_names return tuple sorted _SCHEMES.sections
def directives cmd '{0}-L'.format _detect_os ret {}out __salt__['cmd.run'] cmd out out.replace '\n DCTB ' ' DCTB ' for line in out.splitlines if not line continuecomps line.split ' DCTB ' desc '\n'.join comps[1 ] ret[comps[0]] descreturn ret
def xml2json_from_elementtree el preserve_whitespaces False res {}if el.tag[0] '{' ns name el.tag.rsplit '}' 1 res['tag'] nameres['namespace'] ns[1 ]else res['tag'] el.tagres['attrs'] {}for k v in el.items res['attrs'][k] vkids []if el.text and preserve_whitespaces or el.text.strip ! '' kids.append el.text for kid in el kids.append xml2json_from_elementtree kid preserve_whitespaces if kid.tail and preserve_whitespaces or kid.tail.strip ! '' kids.append kid.tail res['children'] kidsreturn res
def reverse_dict d result {}for key in d for val in d[key] result[val] result.get val tuple + key return result
def _pretty_exemplars exemplars lu outstr u''outstr + u'exemplarsentencesfor{0.name}in{0.frame.name} \n\n'.format lu for i sent in enumerate exemplars outstr + u'[{0}]{1}\n'.format i sent.text outstr + u'\n'return outstr
def metric_to_Christoffel_1st expr matrix twoform_to_matrix expr if not matrix.is_symmetric raise ValueError 'Thetwo-formrepresentingthemetricisnotsymmetric.' coord_sys expr.atoms CoordSystem .pop deriv_matrices [matrix.applyfunc lambda a d a for d in coord_sys.base_vectors ]indices list range coord_sys.dim christoffel [[[ deriv_matrices[k][ i j ] + deriv_matrices[j][ i k ] - deriv_matrices[i][ j k ] / 2 for k in indices] for j in indices] for i in indices]return ImmutableDenseNDimArray christoffel
def get_headers_from_request req headers getattr req 'META' {} if headers headers {'-'.join [part.capitalize for part in k.split '_' ] .replace 'Http-' '' v for k v in headers.items }remote_addr headers.get 'X-Forwarded-For' or headers.get 'Remote-Addr' headers['Remote-Addr'] remote_addr.split ' ' [0].strip if remote_addr else None else headers getattr req 'headers' {} headers {k v for k v in headers.items }headers['Remote-Addr'] req.remote_addrreturn headers
def darken color percent return adjust color 2 - percent
def check_owner user project permission if project is None return Falseif not hasattr user 'acl_permissions_owner' user.acl_permissions_owner {}if project.pk not in user.acl_permissions_owner user.acl_permissions_owner[project.pk] project.owners.filter id user.id .exists if not user.acl_permissions_owner[project.pk] return Falsegroup Group.objects.get name 'Owners' app perm permission.split '.' return group.permissions.filter content_type__app_label app codename perm .exists
def for_CF_orders name 'order' return for_orders ['C' 'F'] name
def _unpack_tarfile filename extract_dir try tarobj tarfile.open filename except tarfile.TarError raise ReadError '%sisnotacompressedoruncompressedtarfile' % filename try tarobj.extractall extract_dir finally tarobj.close
def _snapshot_metadata_update context snapshot_id metadata delete pass
def _validate_args args unpassable_types _get_unpassable_types args if unpassable_types msg "argumentsoftype'%s'cannotbepassedtoremoteprofilers"msg % ' '.join t.__name__ for t in unpassable_types raise TypeError msg
def _get_search_paths preferred_path None suffix None search_paths [os.path.join '/etc' 'openstack_deploy' ]if preferred_path is not None search_paths.insert 0 os.path.expanduser preferred_path if suffix search_paths [os.path.join p suffix for p in search_paths]return search_paths
def mongo_uses_error_check store if hasattr store 'mongo_wire_version' return store.mongo_wire_version < 1 if hasattr store 'modulestores' return any [mongo_uses_error_check substore for substore in store.modulestores] return False
def test_horizontal_mask_line vgrad _ np.mgrid[ 1 11j 1 11j]vgrad[5 ] 1mask np.ones_like vgrad mask[5 ] 0expected np.zeros_like vgrad expected[1 -1 1 -1 ] 0.2expected[4 7 1 -1 ] 0for grad_func in filters.prewitt_h filters.sobel_h filters.scharr_h result grad_func vgrad mask yield assert_close result expected
def get_results_raw_url build import relog get_vbench_log 'https //api.travis-ci.org/builds/%s' % build if not log returnl [x.strip for x in log.split '\n' if re.match '.vbench-gist-raw_url' x ]if l s l[0]m re.search ' https //[^\\s]+ ' s if m return m.group 0
def config_items **kwargs return kwargs
def timeuntil value arg None from django.utils.timesince import timesincefrom datetime import datetimeif not value return ''if arg return timesince arg value return timesince datetime.now value
def _parser_dispatch flavor valid_parsers list _valid_parsers.keys if flavor not in valid_parsers raise ValueError '%risnotavalidflavor validflavorsare%s' % flavor valid_parsers if flavor in 'bs4' 'html5lib' if not _HAS_HTML5LIB raise ImportError 'html5libnotfound pleaseinstallit' if not _HAS_BS4 raise ImportError 'BeautifulSoup4 bs4 notfound pleaseinstallit' import bs4if bs4.__version__ LooseVersion '4.2.0' raise ValueError "You'reusingaversionofBeautifulSoup4 4.2.0 thathasbeenknowntocauseproblemsoncertainoperatingsystemssuchasDebian.PleaseinstallaversionofBeautifulSoup4! 4.2.0 bothearlierandlaterreleaseswillwork." elif not _HAS_LXML raise ImportError 'lxmlnotfound pleaseinstallit' return _valid_parsers[flavor]
def remove_copying_files for filename in ['COPYING'] os.remove os.path.join PROJECT_DIRECTORY filename
def ring return _nodetool 'ring'
def sqlalchemy_options options prefix 'sqlalchemy_' sa_keys [key for key in options.keys if key.startswith prefix ]sa_options {}for key in sa_keys sa_key key[11 ]sa_options[sa_key] options.pop key sa_options coalesce_options sa_options SQLALCHEMY_OPTION_TYPES return sa_options
def is_64bit return sizeof c_ulong ! sizeof c_void_p
def do_capitalize s return soft_unicode s .capitalize
def _load_mixed_class category component_class XBlock.load_class category select settings.XBLOCK_SELECT_FUNCTION mixologist Mixologist settings.XBLOCK_MIXINS return mixologist.mix component_class
def render s context None if context is None context {}t get_env .from_string s return t.render context
def __get_network conn vm_ network config.get_cloud_config_value 'network' vm_ __opts__ default 'default' search_global False return conn.ex_get_network network
def ShutdownDB if hasattr DBClient '_instance' DBClient.Instance .Shutdown
def _read_int64 f return np.int64 struct.unpack '>q' f.read 8 [0]
def _accessible_courses_summary_list request def course_filter course_summary '\nFilteroutunusableandinaccessiblecourses\n'if course_summary.location.course 'templates' return Falsereturn has_studio_read_access request.user course_summary.id courses_summary filter course_filter modulestore .get_course_summaries in_process_course_actions get_in_process_course_actions request return courses_summary in_process_course_actions
def shelter_registration s3.crud_strings.cr_shelter_registration Storage label_create T 'RegisterPerson' title_display T 'RegistrationDetails' title_list T 'RegisteredPeople' title_update T 'EditRegistration' label_list_button T 'ListRegistrations' msg_record_created T 'Registrationadded' msg_record_modified T 'Registrationupdated' msg_record_deleted T 'Registrationentrydeleted' msg_list_empty T 'Nopeoplecurrentlyregisteredinthisshelter' output s3_rest_controller return output
def test_score tpot_obj TPOTClassifier try tpot_obj.score testing_features testing_classes assert Falseexcept ValueError pass
def _CopyFieldToProtocolBuffer field pb pb.set_name field.name.encode 'utf-8' field_value_pb pb.mutable_value if field.language field_value_pb.set_language field.language.encode 'utf-8' if field.value is not None field._CopyValueToProtocolBuffer field_value_pb return pb
def list_records after None before None ret {}fmdump _check_fmdump cmd '{cmd}{after}{before}'.format cmd fmdump after '-t{0}'.format after if after else '' before '-T{0}'.format before if before else '' res __salt__['cmd.run_all'] cmd retcode res['retcode']result {}if retcode ! 0 result['Error'] 'errorexecutingfmdump'else result _parse_fmdump res['stdout'] return result
def get_gentoo_mirrors return get_var 'GENTOO_MIRRORS'
def by_url backend None loader None url Noneif backend and u' //' in backend url backend scheme _ _ url.partition u' //' if u'+' in scheme backend url url.split u'+' 1 else backend schemereturn by_name backend loader url
def p_variable p if len p 2 p[0] p[1] None None elif len p 5 p[0] p[1] p[3] None else p[0] p[1] p[3] p[5]
def suggest_type full_text text_before_cursor if full_text.startswith '\\i' return Path try stmt SqlStatement full_text text_before_cursor except TypeError AttributeError return []if stmt.parsed tok1 stmt.parsed.token_first if tok1 and tok1.value '\\' text stmt.text_before_cursor + stmt.word_before_cursor return suggest_special text return suggest_based_on_last_token stmt.last_token stmt
def _get_default_session if DEFAULT_SESSION is None setup_default_session return DEFAULT_SESSION
def collect_addon_css node visited None css []for addon_config in settings.ADDONS_AVAILABLE_DICT.values css.extend addon_config.include_css.get 'files' [] return css
def _flatten_params params def get_string value if isinstance value unicode return unicode value .encode 'utf-8' else return str value param_list []for key value in params.iteritems key get_string key if isinstance value basestring param_list.append key get_string value else try iterator iter value except TypeError param_list.append key str value else param_list.extend key get_string v for v in iterator return param_list
def ncut_cost cut D W cut np.array cut cut_cost _ncut_cy.cut_cost cut W assoc_a D.data[cut].sum assoc_b D.data[ ~ cut ].sum return cut_cost / assoc_a + cut_cost / assoc_b
def build_move_descriptions for m in Move.objects.all f_moves open 'data/moves.csv' 'rb' f_descrips open 'data/move_effects.csv' 'rb' for row in csv.reader f_moves delimiter ' ' if str row[1] m.name for drow in csv.reader f_descrips delimiter ' ' if str row[10] str drow[0] s str drow[3] .replace '$effect_chance' str row[11] s s.replace '[' '' s s.replace ']' '' m.description sm.save print 'addeddescriptionto%s' % m.name
@frappe.whitelist def save_report data frappe.local.form_dictif frappe.db.exists u'Report' data[u'name'] d frappe.get_doc u'Report' data[u'name'] else d frappe.new_doc u'Report' d.report_name data[u'name']d.ref_doctype data[u'doctype']d.report_type u'ReportBuilder'd.json data[u'json']frappe.get_doc d .save frappe.msgprint _ u'{0}issaved' .format d.name return d.name
def _select_free_device existing local_devices frozenset existing sorted_devices sorted existing IN_USE_DEVICES devices sorted_devices .write for suffix in 'fghijklmonpqrstuvwxyz' next_local_device 'xvd' + suffix next_local_sd_device 'sd' + suffix file_name u'/dev/sd' + unicode suffix possible_devices [next_local_device next_local_sd_device]if not local_devices.intersection possible_devices return file_nameNO_AVAILABLE_DEVICE devices sorted_devices .write raise NoAvailableDevice
def _params url return parse_qs urlparse url .query
@sopel.module.commands u'console' def interactive_shell bot trigger global consoleif not trigger.admin bot.say u'Onlyadminscanstarttheinteractiveconsole' returnif u'iconsole_running' in bot.memory and bot.memory[u'iconsole_running'] bot.say u'Consolealreadyrunning' returnif not sys.__stdout__.isatty bot.say u'Attyisrequiredtostarttheconsole' returnif bot._daemon bot.say u"Can'tstartconsolewhenrunningasadaemon" returnold_stdout sys.stdoutold_stderr sys.stderrsys.stdout sys.__stdout__sys.stderr sys.__stderr__banner1 u'Sopelinteractiveshell embeddedIPython 'banner2 u'`bot`and`trigger`areavailable.Toexit typeexit'exitmsg u'Interactiveshellclosed'console InteractiveShellEmbed banner1 banner1 banner2 banner2 exit_msg exitmsg bot.memory[u'iconsole_running'] Truebot.say u'consolestarted' console bot.memory[u'iconsole_running'] Falsesys.stdout old_stdoutsys.stderr old_stderr
def read_string_table xml_source root fromstring text xml_source nodes safe_iterator root '{%s}si' % SHEET_MAIN_NS strings get_string node for node in nodes return IndexedList strings
def reindent source indent_size reindenter Reindenter source return reindenter.run indent_size
def load_manifest package_name bootstrap_version '0.7' if package_name in _bootstrapped returnsys.path _generate_python_path package_name _rospack + sys.path
def getImportCoarseness elementNode preferences None if elementNode None return 1.0if preferences None preferences skeinforge_craft.getCraftPreferences 'carve' importCoarseness skeinforge_craft.getCraftValue 'ImportCoarseness' preferences return getCascadeFloatWithoutSelf importCoarseness elementNode 'importCoarseness'
def _task_info_update task_id values global DATAtry task_info DATA['task_info'][task_id]except KeyError LOG.debug 'Notaskinfofoundwithtaskid%s' task_id raise exception.TaskNotFound task_id task_id task_info.update values DATA['task_info'][task_id] task_inforeturn task_info
def test_give_classifier_wrong_obj ratio 'auto'classifier 2bc BalanceCascade ratio ratio random_state RND_SEED return_indices True estimator classifier assert_raises ValueError bc.fit_sample X Y
def httranslate text return Markup _ text
def insert_pdb editorWidget line index editorWidget.getCursorPosition indentation get_indentation editorWidget.text line editorWidget.insertAt '%simportpdb;pdb.set_trace \n' % indentation line 0
@with_setup prepare_stdout def test_output_with_success_colorful runner Runner join abspath dirname __file__ 'output_features' 'runner_features' verbosity 3 no_color False runner.run assert_stdout_lines '\n\x1b[1;37mFeature Dumbfeature\x1b[1;30m#tests/functional/output_features/runner_features/first.feature 1\x1b[0m\n\x1b[1;37mInordertotestsuccess\x1b[1;30m#tests/functional/output_features/runner_features/first.feature 2\x1b[0m\n\x1b[1;37mAsaprogrammer\x1b[1;30m#tests/functional/output_features/runner_features/first.feature 3\x1b[0m\n\x1b[1;37mIwanttoseethattheoutputisgreen\x1b[1;30m#tests/functional/output_features/runner_features/first.feature 4\x1b[0m\n\n\x1b[1;37mScenario Donothing\x1b[1;30m#tests/functional/output_features/runner_features/first.feature 6\x1b[0m\n\x1b[1;30mGivenIdonothing\x1b[1;30m#tests/functional/output_features/runner_features/dumb_steps.py 6\x1b[0m\n\x1b[A\x1b[1;32mGivenIdonothing\x1b[1;30m#tests/functional/output_features/runner_features/dumb_steps.py 6\x1b[0m\n\n\x1b[1;37m1feature \x1b[1;32m1passed\x1b[1;37m \x1b[0m\n\x1b[1;37m1scenario \x1b[1;32m1passed\x1b[1;37m \x1b[0m\n\x1b[1;37m1step \x1b[1;32m1passed\x1b[1;37m \x1b[0m\n'
def search_items bus attributes service_obj bus_get_object bus SS_PATH service_iface dbus.Interface service_obj SERVICE_IFACE locked unlocked service_iface.SearchItems attributes signature 'a{ss}' for item_path in locked + unlocked yield Item bus item_path
def get_column_letter col_idx if not 1 < col_idx < 18278 msg 'Columnindexoutofbounds %s' % col_idx raise ColumnStringIndexException msg ordinals []temp col_idxwhile temp quotient remainder divmod temp 26 if remainder 0 quotient - 1remainder 26ordinals.append remainder + 64 temp quotientordinals.reverse return ''.join [chr ordinal for ordinal in ordinals]
def get_default_datatype expr if expr.is_integer return default_datatypes['int']elif isinstance expr MatrixBase for element in expr if not element.is_integer return default_datatypes['float']return default_datatypes['int']else return default_datatypes['float']
def _openstack_auth_from_config auth_plugin 'password' **config if auth_plugin 'rackspace' plugin_class RackspaceAuthelse plugin_class get_plugin_class auth_plugin plugin_options plugin_class.get_options plugin_kwargs {}for option in plugin_options if option.dest in config plugin_kwargs[option.dest] config[option.dest]return plugin_class **plugin_kwargs
def fix_env if sabnzbd.DARWIN env os.environ.copy if 'PYTHONPATH' in env del env['PYTHONPATH']if 'PYTHONHOME' in env del env['PYTHONHOME']return envelse return None
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def gettemp basename exec_dir os.path.dirname sys.executable file_onedir os.path.join exec_dir '..' '..' basename file_onefile os.path.join exec_dir '..' basename if os.path.exists file_onedir return file_onedirelse return file_onefile
def write_bytes data urlpath name_function None compression None encoding None **kwargs mode 'wb' if encoding is None else 'wt' fs names myopen get_fs_paths_myopen urlpath compression mode name_function name_function num len data encoding encoding **kwargs return [delayed write_block_to_file pure False d myopen f mode 'wb' for d f in zip data names ]
def _get_splunk_search_props search props search.contentprops['app'] search.access.appprops['sharing'] search.access.sharingreturn props
def job_exists name None if not name raise SaltInvocationError 'Requiredparameter`name`ismissing.' server _connect if server.job_exists name return Trueelse return False
def grid margin spacing *widgets layout QtWidgets.QGridLayout layout.setSpacing spacing set_margin layout margin for row in widgets item row[0]if isinstance item QtWidgets.QWidget layout.addWidget *row elif isinstance item QtWidgets.QLayoutItem layout.addItem *row return layout
def get_icon name default None resample False icon_path get_image_path name default None if icon_path is not None icon QIcon icon_path elif isinstance default QIcon icon defaultelif default is None try icon get_std_icon name[ -4 ] except AttributeError icon QIcon get_image_path name default else icon QIcon get_image_path name default if resample icon0 QIcon for size in 16 24 32 48 96 128 256 512 icon0.addPixmap icon.pixmap size size return icon0else return icon
def test_install_exit_status_code_when_blank_requirements_file script script.scratch_path.join 'blank.txt' .write '\n' script.pip 'install' '-r' 'blank.txt'
def get_exploration_summary_by_id exploration_id exp_summary_model exp_models.ExpSummaryModel.get exploration_id if exp_summary_model exp_summary get_exploration_summary_from_model exp_summary_model return exp_summaryelse return None
def parse_dwarf parser DWARFParser for line in open sys.argv[1] 'r' .readlines parser.feed_line line parser.print_output
def xml_mapping_parser path pass
def use_app backend_name None call_reuse True global default_appif default_app is not None names default_app.backend_name.lower .replace ' ' '' .strip ' ' names [name for name in names.split '' if name]if backend_name and backend_name.lower not in names raise RuntimeError 'Canonlyselectabackendonce alreadyusing%s.' % names else if call_reuse default_app.reuse return default_appdefault_app Application backend_name return default_app
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
@click.command 'auto-update' def setup_auto_update from bench.utils import setup_auto_updatesetup_auto_update
def gabor image frequency theta 0 bandwidth 1 sigma_x None sigma_y None n_stds 3 offset 0 mode 'reflect' cval 0 assert_nD image 2 g gabor_kernel frequency theta bandwidth sigma_x sigma_y n_stds offset filtered_real ndi.convolve image np.real g mode mode cval cval filtered_imag ndi.convolve image np.imag g mode mode cval cval return filtered_real filtered_imag
def id_to_svd B idx proj if _is_real B U V S backend.idd_id2svd B idx + 1 proj else U V S backend.idz_id2svd B idx + 1 proj return U S V
def is_period array return isinstance array ABCPeriodIndex or is_period_arraylike array
def chebyu n monic False base jacobi n 0.5 0.5 monic monic if monic return basefactor sqrt pi / 2.0 * _gam n + 2 / _gam n + 1.5 base._scale factor return base
def setup_tv host mac name customize hass add_devices from pylgtv import WebOsClientfrom pylgtv import PyLGTVPairExceptionfrom websockets.exceptions import ConnectionClosedclient WebOsClient host if not client.is_registered if host in _CONFIGURING try client.register except PyLGTVPairException _LOGGER.warning 'ConnectedtoLGwebOSTV%sbutnotpaired' host returnexcept OSError ConnectionClosed _LOGGER.error 'Unabletoconnecttohost%s' host returnelse _LOGGER.warning 'LGwebOSTV%sneedstobepaired' host request_configuration host mac name customize hass add_devices returnif client.is_registered and host in _CONFIGURING request_id _CONFIGURING.pop host configurator get_component 'configurator' configurator.request_done request_id add_devices [LgWebOSDevice host mac name customize ] True
def _dotsum x y if sparse.issparse x return x.multiply y .sum else return np.dot x.ravel y.ravel
def __ipv4_quad value return salt.utils.validate.net.ipv4_addr value value 'dottedIPv4address'
def _to_loc ll if isinstance ll int float or len ll > 0 return llelse return 0.0
def _HCCM2 hessian_inv scale if scale.ndim 1 scale scale[ None]xxi hessian_invH np.dot np.dot xxi scale xxi.T return H
def s3_get_last_record_id tablename session current.sessionif RCVARS in session and tablename in session[RCVARS] return session[RCVARS][tablename]else return None
def python_3000_has_key logical_line noqa pos logical_line.find '.has_key ' if pos > -1 and not noqa yield pos "W601.has_key isdeprecated use'in'"
def createFillForSurroundings radius shouldExtraLoopsBeAdded surroundingLoops for surroundingLoop in surroundingLoops createExtraFillLoops radius shouldExtraLoopsBeAdded surroundingLoop
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def step2_form_factory mixin_cls entry_form_class attrs None if attrs is None attrs {}class_name 'WizardStep2Form'meta_class type entry_form_class FormClass meta_class class_name mixin_cls entry_form_class attrs return FormClass
def het_breuschpagan resid exog_het x np.asarray exog_het y np.asarray resid ** 2 nobs nvars x.shaperesols OLS y x .fit fval resols.fvaluefpval resols.f_pvaluelm nobs * resols.rsquared return lm stats.chi2.sf lm nvars - 1 fval fpval
def get_locale_from_lang lang if not lang or lang 'dbg' lang 'en'return Locale translation.to_locale lang
def _make_laplacian_sparse edges weights pixel_nb edges.max + 1 diag np.arange pixel_nb i_indices np.hstack edges[0] edges[1] j_indices np.hstack edges[1] edges[0] data np.hstack - weights - weights lap sparse.coo_matrix data i_indices j_indices shape pixel_nb pixel_nb connect - np.ravel lap.sum axis 1 lap sparse.coo_matrix np.hstack data connect np.hstack i_indices diag np.hstack j_indices diag shape pixel_nb pixel_nb return lap.tocsr
def enable_server server try config.get_config 'servers' server .enable.set 1 except logging.warning T 'Tryingtosetstatusofnon-existingserver%s' server returnconfig.save_config Downloader.do.update_server server server
def _check_remove_last_super user_obj if not user_obj.is_superuser returnall_active_su User.objects.filter is_superuser__exact True is_active__exact True num_active_su all_active_su.count if num_active_su < 1 raise PopupException _ 'Noactivesuperuserconfigured.' if num_active_su 1 raise PopupException _ 'Youcannotremovethelastactivesuperuserfromtheconfiguration.' error_code 401
def spidercls_for_request spider_loader request default_spidercls None log_none False log_multiple False snames spider_loader.find_by_request request if len snames 1 return spider_loader.load snames[0] if len snames > 1 and log_multiple logger.error 'Morethanonespidercanhandle % request s-% snames s' {'request' request 'snames' ' '.join snames } if len snames 0 and log_none logger.error 'Unabletofindspiderthathandles % request s' {'request' request} return default_spidercls
@given "I'vestartedtheintro" def step_impl context go_to_manage_page context start_intro context modal context.modal find_css_class_with_wait context MODAL_CLASS wait_time 30 context.skip_button modal.find_element_by_class_name SKIP_BUTTON_CLASS context.next_button modal.find_element_by_class_name NEXT_BUTTON_CLASS context.back_button modal.find_element_by_class_name BACK_BUTTON_CLASS
def latlng arg if is_string arg return argnormalized normalize_lat_lng arg return '%s %s' % format_float normalized[0] format_float normalized[1]
def get_thread_analytics_multi exploration_ids return feedback_jobs_continuous.FeedbackAnalyticsAggregator.get_thread_analytics_multi exploration_ids
def simple_traceback limit stack_trace traceback.extract_stack limit limit [ -2 ]return '\n'.join '-'.join os.path.basename filename function_name str line_number for filename line_number function_name text in stack_trace
def _write_instance_repr out visited name pyop_attrdict address out.write '<' out.write name if isinstance pyop_attrdict PyDictObjectPtr out.write ' ' first Truefor pyop_arg pyop_val in pyop_attrdict.items if not first out.write ' ' first Falseout.write pyop_arg.proxyval visited out.write ' ' pyop_val.write_repr out visited out.write ' ' out.write 'atremote0x%x>' % address
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
def apply_rollback datastore name return _get_client .apply_rollback datastore name
def pinv_extended X rcond 1e-15 X np.asarray X X X.conjugate u s vt np.linalg.svd X 0 s_orig np.copy s m u.shape[0]n vt.shape[1]cutoff rcond * np.maximum.reduce s for i in range min n m if s[i] > cutoff s[i] 1.0 / s[i] else s[i] 0.0res np.dot np.transpose vt np.multiply s[ np.core.newaxis] np.transpose u return res s_orig
def adjust_split_point split_point log sp split_pointwhile True parent sp.getparent if parent is None or barename parent.tag in {u'body' u'html'} or parent.text and parent.text.strip or parent.index sp > 0 breaksp parentif sp is not split_point log.debug u'Adjustedsplitpointtoancestor' return sp
def split_filter_value_for_quotes value validate_quotes value tmp re.compile '\n" #iffoundadouble-quote\n[^\\"\\\\]*#takecharacterseithernon-quotesorbackslashes\n ? \\\\.#takebackslashesandcharacterafterit\n[^\\"\\\\]* *#takecharacterseithernon-quotesorbackslashes\n #beforedouble-quote\n" ?#adouble-quotewithcommamaybe\n| [^ ]+ ?#ifnotfounddouble-quotetakeanynon-comma\n#characterswithcommamaybe\n| #ifwehaveonlycommatakeemptystring\n' re.VERBOSE return [ val[0] or val[1] for val in re.findall tmp value ]
def assert_is_subclass subcls cls msg '' assert issubclass subcls cls '%sisnotasubclassof%s\n%s' % _safe_cls_name subcls _safe_cls_name cls msg
def getClientSpec specList p4CmdList 'client-o' if len specList ! 1 die 'Outputfrom"client-o"is%dlines expecting1' % len specList entry specList[0]client_name entry['Client']view_keys [k for k in entry.keys if k.startswith 'View' ]view View client_name for view_num in range len view_keys k 'View%d' % view_num if k not in view_keys die 'Expectedviewkey%smissing' % k view.append entry[k] return view
def CancelBatchJob client batch_job max_poll_attempts MAX_POLL_ATTEMPTS batch_job_service client.GetService 'BatchJobService' 'v201605' batch_job['status'] 'CANCELING'operation {'operator' 'SET' 'operand' batch_job}batch_job_service.mutate [operation] poll_attempt 0while poll_attempt in range max_poll_attempts and batch_job['status'] ! 'CANCELED' sleep_interval 30 * 2 ** poll_attempt + random.randint 0 10000 / 1000 print 'BatchJobnotfinishedcanceling sleepingfor%sseconds.' % sleep_interval time.sleep sleep_interval batch_job GetBatchJob client batch_job['id'] poll_attempt + 1if batch_job['status'] 'CANCELED' print 'BatchJobwithID"%d"hasbeensuccessfullycanceled.' % batch_job['id'] else print 'BatchJobwithID"%d"failedtocancelafterpolling%dtimes.' % batch_job['id'] max_poll_attempts
def remove_template s n_open n_close 0 0 starts ends [] [] in_template Falseprev_c Nonefor i c in enumerate iter s if not in_template if c '{' and c prev_c starts.append i - 1 in_template Truen_open 1if in_template if c '{' n_open + 1elif c '}' n_close + 1if n_open n_close ends.append i in_template False n_open n_close 0 0 prev_c cs ''.join [s[ end + 1 start] for start end in zip starts + [None] [ -1 ] + ends ] return s
def literal_eval node_or_string _safe_names {'None' None 'True' True 'False' False}if isinstance node_or_string basestring node_or_string parse node_or_string mode 'eval' if isinstance node_or_string Expression node_or_string node_or_string.bodydef _convert node if isinstance node Str return node.selif isinstance node Num return node.nelif isinstance node Tuple return tuple map _convert node.elts elif isinstance node List return list map _convert node.elts elif isinstance node Dict return dict _convert k _convert v for k v in zip node.keys node.values elif isinstance node Name if node.id in _safe_names return _safe_names[node.id]raise ValueError 'malformedstring' return _convert node_or_string
def list_joysticks print 'Availablejoysticks ' print for jid in range pygame.joystick.get_count j pygame.joystick.Joystick jid print ' {} {}'.format jid j.get_name
def recursive_copy source dest for root _ files in os.walk source path_from_source root.replace source '' .lstrip '/' target_directory os.path.join dest path_from_source if not os.path.exists target_directory os.makedirs target_directory for name in files file_path_from_source os.path.join source path_from_source name target_path os.path.join target_directory name shutil.copyfile file_path_from_source target_path
def choose_plugin prepared question opts [ plugin_ep.description_with_name + '[Misconfigured]' if plugin_ep.misconfigured else '' for plugin_ep in prepared]while True disp z_util interfaces.IDisplay code index disp.menu question opts help_label 'MoreInfo' force_interactive True if code display_util.OK plugin_ep prepared[index]if plugin_ep.misconfigured z_util interfaces.IDisplay .notification 'Theselectedpluginencounteredanerrorwhileparsingyourserverconfigurationandcannotbeused.Theerrorwas \n\n{0}'.format plugin_ep.prepare pause False else return plugin_epelif code display_util.HELP if prepared[index].misconfigured msg 'ReportedError %s' % prepared[index].prepare else msg prepared[index].init .more_info z_util interfaces.IDisplay .notification msg force_interactive True else return None
def squeeze a axis None return a.squeeze axis
@np.deprecate message 'splineisdeprecatedinscipy0.19.0 useBsplineclassinstead.' def spline xk yk xnew order 3 kind 'smoothest' conds None return spleval splmake xk yk order order kind kind conds conds xnew
def TokenFromUrl url if url.find '?' > -1 query_params url.split '?' [1]else query_params urlfor pair in query_params.split '&' if pair.startswith 'token ' return pair[6 ]return None
def _get_host_utilization context host ram_mb disk_gb instances instance_get_all_by_host context host vms len instances free_ram_mb ram_mb - FLAGS.reserved_host_memory_mb free_disk_gb disk_gb - FLAGS.reserved_host_disk_mb * 1024 work 0for instance in instances free_ram_mb - instance.memory_mbfree_disk_gb - instance.root_gbfree_disk_gb - instance.ephemeral_gbif instance.vm_state in [vm_states.BUILDING vm_states.REBUILDING vm_states.MIGRATING vm_states.RESIZING] work + 1return dict free_ram_mb free_ram_mb free_disk_gb free_disk_gb current_workload work running_vms vms
def test_high_order_autoencoder_init corruptor BinomialCorruptor corruption_level 0.5 model HigherOrderContractiveAutoencoder corruptor corruptor num_corruptions 2 nvis 5 nhid 7 act_enc 'sigmoid' act_dec 'sigmoid' X tensor.matrix data np.random.randn 10 5 .astype config.floatX ff theano.function [X] model.higher_order_penalty X assert type ff data np.ndarray
def run _task
@anonymous_csrf@mobile_template 'questions/{mobile/}marketplace_refund.html' def marketplace_refund request template error_message Noneif request.method 'GET' form MarketplaceRefundForm request.user else form MarketplaceRefundForm request.user request.POST if form.is_valid try form.submit_ticket return HttpResponseRedirect reverse 'questions.marketplace_aaq_success' except ZendeskError error_message ZENDESK_ERROR_MESSAGEreturn render request template {'form' form 'error_message' error_message}
def get_schema_for_action_parameters action_db from st2common.util.action_db import get_runnertype_by_namerunner_type get_runnertype_by_name action_db.runner_type['name'] parameters_schema {}deep_update parameters_schema runner_type.runner_parameters deep_update parameters_schema action_db.parameters runner_parameter_names runner_type.runner_parameters.keys for name schema in six.iteritems action_db.parameters if name not in runner_parameter_names continuefor attribute value in six.iteritems schema runner_param_value runner_type.runner_parameters[name].get attribute validate_runner_parameter_attribute_override action_ref action_db.ref param_name name attr_name attribute runner_param_attr_value runner_param_value action_param_attr_value value schema get_schema_for_resource_parameters parameters_schema parameters_schema if parameters_schema schema['title'] action_db.nameif action_db.description schema['description'] action_db.descriptionreturn schema
def decipher_bifid6 msg key msg key _ _prep msg.upper key.upper None bifid6 key padded_key key bifid6 return decipher_bifid msg '' key
@then u'weseedatabaseconnected' def step_see_db_connected context _expect_exact context u'Youarenowconnectedtodatabase' timeout 2
def _iter_id iterable for item in iterable yield id item item
def test_no_dot_at_all q Line .render_pyquery assert q '.text-overlaytext' .text 'Nodata'
def colorscale_to_colors colorscale color_list []for item in colorscale color_list.append item[1] return color_list
def add_prerequisite_course course_key prerequisite_course_key if not is_prerequisite_courses_enabled return Nonemilestone_name _ 'Course{course_id}requires{prerequisite_course_id}' .format course_id unicode course_key prerequisite_course_id unicode prerequisite_course_key milestone milestones_api.add_milestone {'name' milestone_name 'namespace' unicode prerequisite_course_key 'description' _ 'Systemdefinedmilestone' } milestones_api.add_course_milestone course_key 'requires' milestone milestones_api.add_course_milestone prerequisite_course_key 'fulfills' milestone
def machine_get_by_hostname hostname try machine Machine.objects.get hostname hostname return machineexcept Machine.DoesNotExist return None
@register.filterdef comment_filter comment_text filter_func settings.COMMENT_FILTERif not filter_func def filter_func s return linebreaksbr urlize s autoescape True autoescape True elif not callable filter_func filter_func import_dotted_path filter_func return filter_func comment_text
def get_ninja_project_file path extension '.nja'return get_ninja_file path extension only_first True
def string2lines astring tab_width 8 convert_whitespace 0 whitespace re.compile '[\x0b\x0c]' if convert_whitespace astring whitespace.sub '' astring return [s.expandtabs tab_width .rstrip for s in astring.splitlines ]
def sliceable dim pad 0 dim0 np.prod dim[ -1 ] + pad return dim0 dim[ -1 ]
def setup app app.add_role 'rfc' rfclink return
def filter_traceback entry raw_filename entry.frame.code.raw.co_filenameis_generated '<' in raw_filename and '>' in raw_filename if is_generated return Falsep py.path.local entry.path return p ! cutdir1 and not p.relto cutdir2 and not p.relto cutdir3
def _normalize_entity value if ndb is not None and isinstance value ndb.Model return Noneif getattr value '_populate_internal_entity' None return value._populate_internal_entity return value
def getTime return monotonicClock.getTime
def mon_create **kwargs return ceph_cfg.mon_create **kwargs
def get_saved_policy table 'filter' chain None conf_file None family 'ipv4' if not chain return 'Error Chainneedstobespecified'rules _parse_conf conf_file family family try return rules[table][chain]['policy']except KeyError return None
def getPythonDirectoryNames directoryName pythonDirectoryNames []directory os.listdir directoryName for fileName in directory subdirectoryName os.path.join directoryName fileName if os.path.isdir subdirectoryName if os.path.isfile os.path.join subdirectoryName '__init__.py' pythonDirectoryNames.append subdirectoryName return pythonDirectoryNames
def simple_plot x np.linspace - np.pi np.pi 256 endpoint True y_cos y_sin np.cos x np.sin x plt.figure figsize 8 6 dpi 80 plt.title 'plottitle' plt.grid True plt.xlabel 'xlabel' plt.xlim -4.0 4.0 plt.xticks np.linspace -4 4 9 endpoint True plt.ylabel 'ylabel' plt.ylim -1.0 1.0 plt.yticks np.linspace -1 1 9 endpoint True plt.plot x y_cos 'b--' linewidth 2.0 label 'cos' plt.plot x y_sin 'g-' linewidth 2.0 label 'sin' plt.legend loc 'upperleft' shadow True plt.show return
def _average_weight G path weight None path_length len path - 1 if path_length < 0 return 0if weight is None return 1 / path_length total_weight sum G.edge[i][j][weight] for i j in pairwise path return total_weight / path_length
def rsa_crt_dmp1 private_exponent p return private_exponent % p - 1
def addGeometryList elementNode faces for face in faces faceElement xml_simple_reader.ElementNode face.addToAttributes faceElement.attributes faceElement.localName 'face'faceElement.parentNode elementNodeelementNode.childNodes.append faceElement
def get_log_content logfile f open logfile content f.read f.close os.remove logfile return content
def ParseArguments argv opts args getopt.getopt argv[1 ] 'h' ['debug' 'help' 'url ' 'filename ' 'cookie ' 'batch_size ' 'kind '] url Nonefilename Nonecookie ''batch_size 10kind Noneencoding Nonefor option value in opts if option '--debug' logging.getLogger .setLevel logging.DEBUG if option in '-h' '--help' PrintUsageExit 0 if option '--url' url valueif option '--filename' filename valueif option '--cookie' cookie valueif option '--batch_size' batch_size int value if batch_size < 0 print >>sys.stderr 'batch_sizemustbe1orlarger'PrintUsageExit 1 if option '--kind' kind valuereturn url filename cookie batch_size kind
def get_field java_object field_name command proto.FIELD_COMMAND_NAME + proto.FIELD_GET_SUBCOMMAND_NAME + java_object._target_id + u'\n' + field_name + u'\n' + proto.END_COMMAND_PART answer java_object._gateway_client.send_command command if answer proto.NO_MEMBER_COMMAND or is_error answer [0] raise Py4JError u'nofield{0}inobject{1}'.format field_name java_object._target_id else return get_return_value answer java_object._gateway_client java_object._target_id field_name
@event u'manager.db_cleanup' def db_cleanup manager session existing_tasks list manager.tasks + [None] session.query SimpleKeyValue .filter ~ SimpleKeyValue.task.in_ existing_tasks .delete synchronize_session False
def leftGroup ignored avatar q avatar.quit q.addCallback quitServer return q
def _copy_interfaces_info interfaces ret {}for interface in interfaces _interface_attrs_cpy set for attr in ATTRS attr_dict Hashabledict attr_dict[attr] repr interfaces[interface][attr] _interface_attrs_cpy.add attr_dict ret[interface] _interface_attrs_cpyreturn ret
def serialize_num val if isinstance val bool return str int val return str val
def delete_serving_url blob_key rpc None rpc delete_serving_url_async blob_key rpc rpc.get_result
def _logistic_loss_and_grad w X y alpha sample_weight None n_samples n_features X.shapegrad np.empty_like w w c yz _intercept_dot w X y if sample_weight is None sample_weight np.ones n_samples out - np.sum sample_weight * log_logistic yz + 0.5 * alpha * np.dot w w z expit yz z0 sample_weight * z - 1 * y grad[ n_features] safe_sparse_dot X.T z0 + alpha * w if grad.shape[0] > n_features grad[ -1 ] z0.sum return out grad
def get_ids_bcs_added_field header mapping_data barcode_type 'golay_12' added_demultiplex_field None sample_id_ix header.index 'SampleID' bc_ix header.index 'BarcodeSequence' if added_demultiplex_field added_demultiplex_ix header.index added_demultiplex_field ids_bcs_added_field {}for line in mapping_data if barcode_type 0 curr_bc ''else curr_bc line[bc_ix]if added_demultiplex_field curr_added_field line[added_demultiplex_ix]else curr_added_field ''ids_bcs_added_field[ upper curr_bc curr_added_field ] line[sample_id_ix]return ids_bcs_added_field
def replace_file file_name data base_dir os.path.dirname os.path.abspath file_name tmp_file tempfile.NamedTemporaryFile 'w+' dir base_dir delete False tmp_file.write data tmp_file.close os.chmod tmp_file.name 420 os.rename tmp_file.name file_name
@add_handler 'help' def qute_help url try utils.read_file 'html/doc/index.html' except OSError html jinja.render 'error.html' title 'Errorwhileloadingdocumentation' url url.toDisplayString error "Thismostlikelymeansthedocumentationwasnotgeneratedproperly.Ifyouarerunningqutebrowserfromthegitrepository pleaserunscripts/asciidoc2html.py.Ifyou'rerunningareleasedversionthisisabug pleaseuse reporttoreportit." icon '' return 'text/html' html urlpath url.path if not urlpath or urlpath '/' urlpath 'index.html'else urlpath urlpath.lstrip '/' if not docutils.docs_up_to_date urlpath message.error 'Yourdocumentationisoutdated!Pleasere-runscripts/asciidoc2html.py.' path 'html/doc/{}'.format urlpath if urlpath.endswith '.png' return 'image/png' utils.read_file path binary True else data utils.read_file path return 'text/html' data
def _TestBuildArchive tester user_cookie user_id device_id tester.GetIdsFromCookie user_cookie request_dict {'email' 'user1@emailscrubbed.com'}actual_dict tester.SendRequest 'build_archive' user_cookie request_dict tester._CompareResponseDicts 'build_archive' user_id request_dict {} actual_dict return actual_dict
def simplegeneric func registry {}def wrapper *args **kw ob args[0]try cls ob.__class__except AttributeError cls type ob try mro cls.__mro__except AttributeError try class cls cls object passmro cls.__mro__[1 ]except TypeError mro object for t in mro if t in registry return registry[t] *args **kw else return func *args **kw try wrapper.__name__ func.__name__except TypeError AttributeError passdef register typ func None if func is None return lambda f register typ f registry[typ] funcreturn funcwrapper.__dict__ func.__dict__wrapper.__doc__ func.__doc__wrapper.register registerreturn wrapper
def synchronousIsValidUser user return user in ['Alice' 'Angus' 'Agnes']
def extend image size virt_size get_disk_size image if virt_size > size returnutils.execute 'qemu-img' 'resize' image size resize2fs image
def is_relationship model fieldname mapper sqlalchemy_inspect model return fieldname in mapper.relationships
def split_pootle_path pootle_path slash_count pootle_path.count u'/' parts pootle_path.split u'/' 3 [1 ]language_code Noneproject_code Nonectx ''if slash_count ! 0 and pootle_path ! '/projects/' if slash_count 2 language_code parts[0]elif pootle_path.startswith '/projects/' project_code parts[1]ctx parts[2]elif slash_count ! 1 language_code parts[0]project_code parts[1]ctx parts[2] dir_path filename os.path.split ctx if dir_path dir_path u'/'.join [dir_path ''] return language_code project_code dir_path filename
def get_configuration options agent_config options[u'agent-config']configuration yaml.safe_load agent_config.getContent validate_configuration configuration configuration configuration['control-service'].setdefault 'port' 4524 path agent_config.parent configuration['ca-certificate'] Certificate.loadPEM path.child 'cluster.crt' .getContent configuration['node-credential'] NodeCredential.from_path path 'node' return configuration
def generate_bins_generic values binner closed lenidx len values lenbin len binner if lenidx < 0 or lenbin < 0 raise ValueError 'Invalidlengthforvaluesorforbinner' if values[0] < binner[0] raise ValueError 'Valuesfallsbeforefirstbin' if values[ lenidx - 1 ] > binner[ lenbin - 1 ] raise ValueError 'Valuesfallsafterlastbin' bins np.empty lenbin - 1 dtype np.int64 j 0bc 0for i in range 0 lenbin - 1 r_bin binner[ i + 1 ]while j < lenidx and values[j] < r_bin or closed 'right' and values[j] r_bin j + 1bins[bc] jbc + 1return bins
def upper_consonant_y w a []p Nonefor ch in w if ch 'y' and p is None or p in VOWELS a.append 'Y' else a.append ch p chreturn ''.join a
def buildmod *modules missing [module for module in modules if not os.path.exists module ]if missing return 'Error Thefile {0} doesnotexist.'.format ' '.join missing cmd ['znc-buildmod']cmd.extend modules out __salt__['cmd.run'] cmd python_shell False .splitlines return out[ -1 ]
def non_structured_query table query None **kwargs client _get_client client.table tableif query is None query_parts []for key value in kwargs.items query_parts.append '{0} {1}'.format key value query '^'.join query_parts query str query response client.get query return response
def is_hybi00 headers return 'Sec-WebSocket-Key1' in headers and 'Sec-WebSocket-Key2' in headers
def fix_frame_records_filenames records fixed_records []for frame filename line_no func_name lines index in records filename py3compat.cast_unicode_py2 filename 'utf-8' if not filename.endswith '.pyx' '.pxd' '.pxi' better_fn frame.f_globals.get '__file__' None if isinstance better_fn str filename better_fnfixed_records.append frame filename line_no func_name lines index return fixed_records
def fullrank X r None if r is None r np_matrix_rank X V D U L.svd X full_matrices 0 order np.argsort D order order[ -1 ]value []for i in range r value.append V[ order[i]] return np.asarray np.transpose value .astype np.float64
def add_translations translation translations_folder os.path.join current_app.root_path 'translations' source_file os.path.join translations_folder 'messages.pot' subprocess.call ['pybabel' 'extract' '-F' 'babel.cfg' '-k' 'lazy_gettext' '-o' source_file '.'] subprocess.call ['pybabel' 'init' '-i' source_file '-d' translations_folder '-l' translation]
def add_path path config None log.debug 'Addpath%s' % path if not path return []added []parent os.path.dirname path if parent and os.path.exists os.path.join path '__init__.py' added.extend add_path parent config elif not path in sys.path log.debug 'insert%sintosys.path' path sys.path.insert 0 path added.append path if config and config.srcDirs for dirname in config.srcDirs dirpath os.path.join path dirname if os.path.isdir dirpath sys.path.insert 0 dirpath added.append dirpath return added
@core_helper@maintain.deprecated 'h.nav_named_linkisdeprecatedpleaseuseh.nav_link\nNOTE youwillneedtopasstheroute_nameasanamedparameter' def nav_named_link text named_route **kwargs return nav_link text named_route named_route **kwargs
def get_logging_manager manage_stdout_and_stderr False redirect_fds False if redirect_fds manager FdRedirectionLoggingManager else manager LoggingManager if manage_stdout_and_stderr manager.manage_stdout manager.manage_stderr return manager
def rm_alias alias if not get_target alias return Truelines __parse_aliases out []for line_alias line_target line_comment in lines if line_alias ! alias out.append line_alias line_target line_comment __write_aliases_file out return True
def AZ s None if not s return uppercaset type s is str if t s [s]rv [check_and_join i.upper .split uppercase filter True for i in s]if t return rv[0]return rv
def libvlc_audio_get_track_count p_mi f _Cfunctions.get 'libvlc_audio_get_track_count' None or _Cfunction 'libvlc_audio_get_track_count' 1 None ctypes.c_int MediaPlayer return f p_mi
def clean_path_filename url filename url.get_file_name path url.get_path_without_file .encode DEFAULT_ENCODING if filename res path[1 ]res + clean_filename filename else res clean_path url.get_path .encode DEFAULT_ENCODING [1 ]return res
def is_done pkt if pkt[0] '43' return Truereturn False
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def volume_metadata_get context volume_id return IMPL.volume_metadata_get context volume_id
def maybe_iso8601 dt if not dt returnif isinstance dt datetime return dtreturn parse_iso8601 dt
def _list_iter host None path None tgt host or '*' client salt.client.get_local_client __opts__['conf_file'] for container_info in client.cmd_iter tgt 'lxc.list' kwarg {'path' path} if not container_info continueif not isinstance container_info dict continuechunk {}id_ next six.iterkeys container_info if host and host ! id_ continueif not isinstance container_info[id_] dict continueif 'ret' not in container_info[id_] continueif not isinstance container_info[id_]['ret'] dict continuechunk[id_] container_info[id_]['ret'] yield chunk
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
def geo_apps namespace True runtests False from django.db import connectionfrom django.contrib.gis.geos import GEOS_PREPAREfrom django.contrib.gis.gdal import HAS_GDALapps ['geoapp' 'relatedapp']if not connection.ops.mysql apps.append 'distapp' if connection.ops.postgis and connection.ops.geography apps.append 'geogapp' if HAS_GDAL if connection.ops.postgis and GEOS_PREPARE apps.append 'geo3d' apps.append 'layermap' if runtests return [ 'django.contrib.gis.tests' app for app in apps]elif namespace return [ 'django.contrib.gis.tests.%s' % app for app in apps]else return apps
def _is_enrollment_code_an_update course user redemption_code enrollment_mode is_active CourseEnrollment.enrollment_mode_for_user user course.id return not is_active or enrollment_mode ! redemption_code.mode_slug
def _format_date dt return '%s %02d%s%04d%02d %02d %02dGMT' % ['Mon' 'Tue' 'Wed' 'Thu' 'Fri' 'Sat' 'Sun'][dt.weekday ] dt.day ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec'][ dt.month - 1 ] dt.year dt.hour dt.minute dt.second
def onCellAppDeath addr WARNING_MSG 'onCellAppDeath %s' % str addr
def load_palette file_href bytes urlopen file_href .read count t_index unpack '!HH' bytes[768 768 + 4 ] t_index t_index < 255 and t_index or None palette []for offset in range 0 count if offset t_index rgb 255 153 0 else rgb unpack '!BBB' bytes[ offset * 3 offset + 1 * 3 ] palette.append rgb bits int ceil log len palette / log 2 return palette bits t_index
def strip_lines text output text.replace '\r\n' '' output output.replace '\r' '' output output.replace '\n' '' return output.strip
def clear_memo_cache source d_pth os.path.join settings.MEMO_DIR domain_to_filename source.domain if os.path.exists d_pth os.remove d_pth else print 'memofilefor' source.domain 'hasalreadybeendeleted!'
def group_feed_reader group mode 'div' counter '5' url 'http //groups.google.com/group/%s/feed/rss_v2_0_topics.xml?num %s' % group counter from gluon.contrib import feedparserg feedparser.parse url if mode 'div' html XML TAG.BLOCKQUOTE UL *[LI A entry['title'] + '-' + entry['author'][entry['author'].rfind ' ' ] _href entry['link'] _target '_blank' for entry in g['entries']] _class 'boxInfo' _style 'padding-bottom 5px;' else html XML UL *[LI A entry['title'] + '-' + entry['author'][entry['author'].rfind ' ' ] _href entry['link'] _target '_blank' for entry in g['entries']] return html
def _sorted_resource_labels labels head [label for label in TOP_RESOURCE_LABELS if label in labels ]tail sorted label for label in labels if label not in TOP_RESOURCE_LABELS return head + tail
def mkfs os_type fs_label target run_as_root True specified_fs None mkfs_command _MKFS_COMMAND.get os_type _DEFAULT_MKFS_COMMAND or '' % {'fs_label' fs_label 'target' target} if mkfs_command utils.execute run_as_root run_as_root *mkfs_command.split else if not specified_fs specified_fs CONF.default_ephemeral_formatif not specified_fs specified_fs _DEFAULT_FS_BY_OSTYPE.get os_type _DEFAULT_FILE_SYSTEM utils.mkfs specified_fs target fs_label run_as_root run_as_root
def make_chunk_iter stream separator limit None buffer_size 10 * 1024 stream make_limited_stream stream limit _read stream.read_split re.compile ' %s ' % re.escape separator .splitbuffer []while 1 new_data _read buffer_size if not new_data breakchunks _split new_data new_buf []for item in chain buffer chunks if item separator yield ''.join new_buf new_buf []else new_buf.append item buffer new_bufif buffer yield ''.join buffer
def chunks n *args keypoints []for i in xrange 0 len args[0] n keypoints.append i i + n random.shuffle keypoints for a b in keypoints yield [arg[a b] for arg in args]
def formatUIDListLines msgs getUidl for i m in enumerate msgs if m is not None uid getUidl i yield '%d%s\r\n' % i + 1 uid
def raw_interface_configs cmd ['netsh' 'interface' 'ip' 'show' 'config']return __salt__['cmd.run'] cmd python_shell False
def get_selinux_context path out __salt__['cmd.run'] ['ls' '-Z' path] python_shell False try ret re.search '\\w+ \\w+ \\w+ \\w+' out .group 0 except AttributeError ret 'Noselinuxcontextinformationisavailablefor{0}'.format path return ret
def _GetCallingModule return _GetCallingModuleObjectAndName [1]
def build output worklist force False output_path abspath output source_paths []for f files in worklist source_paths.extend map abspath files update_needed Falseif not os.path.exists output_path if not settings.ASSETS_AUTO_CREATE and not force raise MergeError "'%s'needstobecreated butASSETS_AUTO_CREATEisdisabled" % output else update_needed Trueelif not force update_needed get_updater output_path source_paths if update_needed or force output output_pathtry try for filters files in worklist output merge map abspath files output filters output_path close False finally if hasattr output 'close' output.close except if os.path.exists output_path os.remove output_path raise
def compute_node_update context compute_id values auto_adjust True return IMPL.compute_node_update context compute_id values auto_adjust
def _points_to_dig points n_idx_points use_hpi idx_idents list range 1 4 + list range 1 n_idx_points + 1 - 3 dig []for idx in range points.shape[0] point_info dict zip FIFF_INFO_DIG_FIELDS FIFF_INFO_DIG_DEFAULTS point_info['r'] points[idx]if idx < 3 point_info['kind'] FIFF.FIFFV_POINT_CARDINALpoint_info['ident'] idx_idents[idx]if 2 < idx < n_idx_points and use_hpi point_info['kind'] FIFF.FIFFV_POINT_HPIpoint_info['ident'] idx_idents[idx]elif idx > 4 point_info['kind'] FIFF.FIFFV_POINT_EXTRApoint_info['ident'] idx + 1 - len idx_idents if 2 < idx < n_idx_points and not use_hpi passelse dig + [point_info]return dig
def module_parent_packages full_modname prefix ''parents []for pkg in full_modname.split '.' [0 -1 ] prefix + '.' + pkg if prefix else pkg parents.append prefix return parents
def pip version MIN_PIP_VERSION pip_cmd 'pip' python_cmd 'python' setuptools python_cmd python_cmd if not is_pip_installed version python_cmd python_cmd pip_cmd pip_cmd install_pip python_cmd python_cmd
@register_specialize@gof.local_optimizer [T.mul] def local_mul_to_sqr node if node.op T.mul if len node.inputs 2 if node.inputs[0] is node.inputs[1] return [T.sqr node.inputs[0] ]
@pytest.mark.parametrize 'text expected' [ 'foo|bar' 'foo|ar' 'foobar|' 'foobar|' '|foobar' '|oobar' 'f<oo>bar' 'f|bar' ] def test_rl_delete_char text expected lineedit bridge lineedit.set_aug_text text bridge.rl_delete_char assert lineedit.aug_text expected
def normalize_path_for_engine path drive tail splitdrive path if drive path u'/' + drive.lower .rstrip u' ' + tail return path.replace u'\\' u'/'
def add_git_host_key module url accept_hostkey True create_dir True if is_ssh_url url fqdn get_fqdn url if fqdn known_host check_hostkey module fqdn if not known_host if accept_hostkey rc out err add_host_key module fqdn create_dir create_dir if rc ! 0 module.fail_json msg 'failedtoadd%shostkey %s' % fqdn out + err else module.fail_json msg '%shasanunknownhostkey.Setaccept_hostkeytoTrueormanuallyaddthehostkeypriortorunningthegitmodule' % fqdn
def _covar_mstep_spherical *args cv _covar_mstep_diag *args return np.tile cv.mean axis 1 [ np.newaxis] 1 cv.shape[1]
def virtual_interface_create provider names **kwargs client _get_client return client.extra_action provider provider names names action 'virtual_interface_create' **kwargs
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def save_main_static_files static_generator global _MAIN_STATIC_FILESif static_generator.settings['DEFAULT_LANG'] _MAIN_LANG _MAIN_STATIC_FILES static_generator.staticfiles
def EndsWithPython path return path and PYTHON_BINARY_REGEX.search path is not None
def convert in_file in_format out_file out_format in_kwargs None out_kwargs None if in_kwargs is None in_kwargs {}if out_kwargs is None out_kwargs {}qresults parse in_file in_format **in_kwargs return write qresults out_file out_format **out_kwargs
def _ofc id return 'ofc-%s' % id
def _preprocess_file file_name raw_content utils.get_file_content file_name force_lf_endings True comments [c for c in _RE_COMMENT.finditer raw_content ]content list raw_content for m in comments for i in range m.start m.end content[i] ''content ''.join content return raw_content content
def _isdummy X X np.asarray X if X.ndim > 1 ind np.zeros X.shape[1] .astype bool max np.max X axis 0 1 min np.min X axis 0 0 remainder np.all X % 1.0 0 axis 0 ind min & max & remainder if X.ndim 1 ind np.asarray [ind] return np.where ind [0]
def count_bcd_digits bcd count 0while bcd > 0 count + 1bcd >> 4return count
def _get_safe_url url parts urlsplit url if parts.username is None return urlelse frags list parts if parts.port frags[1] '{0}@{1} {2}'.format parts.username parts.hostname parts.port else frags[1] '{0}@{1}'.format parts.username parts.hostname return urlunsplit frags
def _address_family address if address.startswith '[' and address.endswith ']' return socket.AF_INET6for af in socket.AF_INET socket.AF_INET6 try socket.inet_pton af address return afexcept ValueError AttributeError socket.error continuereturn socket.AF_UNSPEC
def gis_marker_retrieve filename path None if not path path current.db.gis_marker.image.uploadfolderif '/' in filename _path filename filename.split '/' image open os.path.join path _path filename 'rb' else image open os.path.join path filename 'rb' return filename image
@register.inclusion_tag u'admin/includes/dropdown_menu.html' takes_context True def admin_dropdown_menu context template_vars context.flatten user context[u'request'].userif user.is_staff template_vars[u'dropdown_menu_app_list'] admin_app_list context[u'request'] if user.is_superuser sites Site.objects.all else try sites user.sitepermissions.sites.all except ObjectDoesNotExist sites Site.objects.none template_vars[u'dropdown_menu_sites'] list sites template_vars[u'dropdown_menu_selected_site_id'] current_site_id template_vars[u'settings'] context[u'settings']template_vars[u'request'] context[u'request']return template_vars
def make_django_command name django_command None help None if django_command is None django_command name@click.command name name help help add_help_option False context_settings dict ignore_unknown_options True @click.argument 'management_args' nargs -1 type click.UNPROCESSED @click.pass_contextdef inner ctx management_args from sentry.runner.commands.django import djangoctx.params['management_args'] django_command + management_args ctx.forward django return inner
def ostypecode x s ''for i in range 4 x c divmod x 256 s chr c + s return s
def contract_creation_exceptions return {sa.Column ['.'.join [table 'project_id'] for table in get_tables ] sa.Index get_tables }
def make_script_file directory effects builder ScriptBuilder effects fd filename tempfile.mkstemp dir directory text True os.write fd builder.script os.close fd os.chmod filename 365 return os.path.basename filename
def urlquote_plus url safe u'' return force_text quote_plus force_str url force_str safe
def get_product_search_handler_class if settings.OSCAR_PRODUCT_SEARCH_HANDLER is not None return import_string settings.OSCAR_PRODUCT_SEARCH_HANDLER if is_solr_supported return get_class 'catalogue.search_handlers' 'ProductSearchHandler' elif is_elasticsearch_supported return get_class 'catalogue.search_handlers' 'ESProductSearchHandler' else return get_class 'catalogue.search_handlers' 'SimpleProductSearchHandler'
def _sizes dev dev _devbase dev block_sizes 'hw_sector_size' 'minimum_io_size' 'physical_block_size' 'logical_block_size' discard_sizes 'discard_max_bytes' 'discard_max_hw_bytes' sysfs __salt__['sysfs.read'] 'size' 'queue/hw_sector_size' '../queue/hw_sector_size' 'queue/discard_max_bytes' '../queue/discard_max_bytes' root _syspath dev discard sysfs.get 'queue/discard_max_bytes' sysfs.get '../queue/discard_max_bytes' None block sysfs.get 'queue/hw_sector_size' sysfs.get '../queue/hw_sector_size' None return 512 * sysfs['size'] block discard
def list_fonts directory extensions pattern u';'.join [ u'*.%s;*.%s' % ext ext.upper for ext in extensions] return cbook.listFiles directory pattern
def wrapper ruby_string wrapper_prefix runas None *binaries cmd ['wrapper' ruby_string wrapper_prefix]cmd.extend binaries return _rvm cmd runas runas
def axis name None cols None values None units None ax {}cNameOrder ['name' 'units' 'title']if name is not None ax['name'] nameif values is not None ax['values'] valuesif units is not None ax['units'] unitsif cols is not None ax['cols'] []for c in cols if type c ! list and type c ! tuple c [c]col {}for i in range 0 len c col[cNameOrder[i]] c[i]ax['cols'].append col return ax
def sector def prep r s3db.gis_location_filter r return Trues3.prep prepreturn s3_rest_controller
def parse_set_imp_union source info version info.flags & _ALL_VERSIONS or DEFAULT_VERSION items [parse_set_member source info ]while True saved_pos source.posif source.match ']' source.pos saved_posbreakif version VERSION1 and any source.match op for op in SET_OPS source.pos saved_posbreakitems.append parse_set_member source info if len items 1 return items[0]return SetUnion info items
def _NewIndexFromIndexSpecPb index_spec_pb source _SOURCE_PB_TO_SOURCES_MAP.get index_spec_pb.source index Noneif index_spec_pb.has_namespace index Index name index_spec_pb.name namespace index_spec_pb.namespace source source else index Index name index_spec_pb.name source source return index
def failed seg return seg._marked is False and seg._uploaded is False
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def sanitize_output output if output is None return ''else return output.rstrip '\r\n'
@with_settings foo ['foo'] bar {'bar' 'bar'} baz 'baz' qux set 'qux' def test_require_complex_non_empty_values require 'foo' 'bar' 'baz' 'qux'
def change_root new_root pathname if os.name 'posix' if not os.path.isabs pathname return os.path.join new_root pathname else return os.path.join new_root pathname[1 ] elif os.name 'nt' drive path os.path.splitdrive pathname if path[0] '\\' path path[1 ]return os.path.join new_root path else raise DistutilsPlatformError "nothingknownaboutplatform'%s'" % os.name
def prepare_request_dict request_dict endpoint_url context None user_agent None r request_dictif user_agent is not None headers r['headers']headers['User-Agent'] user_agenturl _urljoin endpoint_url r['url_path'] if r['query_string'] encoded_query_string percent_encode_sequence r['query_string'] if '?' not in url url + '?%s' % encoded_query_string else url + '&%s' % encoded_query_string r['url'] urlr['context'] contextif context is None r['context'] {}
def build_application server log.info 'buildingwebapplication' api ModbusApiWebApp server register Bottle register_api_routes api register register_web_routes api register return register
def _mountpoint_to_number mountpoint if mountpoint.startswith '/dev/' mountpoint mountpoint[5 ]if re.match '^[hs]d[a-p]$' mountpoint return ord mountpoint[2 3] - ord 'a' elif re.match '^x?vd[a-p]$' mountpoint return ord mountpoint[ -1 ] - ord 'a' elif re.match '^[0-9]+$' mountpoint return int mountpoint 10 else LOG.warning _LW 'Mountpointcannotbetranslated %s' mountpoint return -1
@intercept_errors UserAPIInternalError ignore_errors [UserAPIRequestError] def activate_account activation_key try registration Registration.objects.get activation_key activation_key except Registration.DoesNotExist raise UserNotAuthorizedelse registration.activate
def resource_uuid value try uuid.UUID value return valueexcept ValueError if len value < 64 if six.PY2 and isinstance value six.text_type value value.encode 'utf-8' return uuid.uuid5 RESOURCE_ID_NAMESPACE value .hexraise ValueError _ 'Lengthoftransformableresourceid>64 whichismaxallowedcharacters'
def _multi_dot_three A B C cost1 A.shape[0] * A.shape[1] * B.shape[1] + A.shape[0] * B.shape[1] * C.shape[1] cost2 B.shape[0] * B.shape[1] * C.shape[1] + A.shape[0] * A.shape[1] * C.shape[1] if cost1 < cost2 return _dot _dot A B C else return _dot A _dot B C
def find_recursion etype value records if not is_recursion_error etype value records return len records 0 records [r[1 4] for r in records]inner_frames records[ - len records // 4 ]frames_repeated set inner_frames last_seen_at {}longest_repeat 0i len records for frame in reversed records i - 1if frame not in frames_repeated last_unique ibreakif frame in last_seen_at distance last_seen_at[frame] - i longest_repeat max longest_repeat distance last_seen_at[frame] ielse last_unique 0return last_unique longest_repeat
def stereo2mono x if x.ndim 1 return xelif x.ndim 2 return x[ 1] / 2 + x[ 0] / 2 else return -1
def create_from_sequence bits if len bits 1 name bits[0]try root Category.objects.get depth 1 name name except Category.DoesNotExist root Category.add_root name name except Category.MultipleObjectsReturned raise ValueError 'Therearemorethanonecategorieswithname%satdepth 1' % name return [root]else parents create_from_sequence bits[ -1 ] parent name parents[ -1 ] bits[ -1 ] try child parent.get_children .get name name except Category.DoesNotExist child parent.add_child name name except Category.MultipleObjectsReturned raise ValueError 'Therearemorethanonecategorieswithname%swhicharechildrenof%s' % name parent parents.append child return parents
def ADOSC barDs count fastperiod - 2 ** 31 slowperiod - 2 ** 31 return call_talib_with_hlcv barDs count talib.ADOSC fastperiod slowperiod
def chain_dot *arrs return reduce lambda x y np.dot y x arrs[ -1 ]
def get_groups_for_container inventory container_name groups {k for k v in inventory.items if 'hosts' in v and container_name in v['hosts'] }return groups
def obfuscate_language text level 0.0 language 'default' global _LANGUAGE_HANDLERif not _LANGUAGE_HANDLER try _LANGUAGE_HANDLER LanguageHandler.objects.get db_key 'language_handler' except LanguageHandler.DoesNotExist if not _LANGUAGE_HANDLER from evennia import create_script_LANGUAGE_HANDLER create_script LanguageHandler return _LANGUAGE_HANDLER.translate text level level language language
def make_app config None config config or {} app CoolMagicApplication config from werkzeug.utils import SharedDataMiddlewareapp SharedDataMiddleware app {'/public' path.join path.dirname __file__ 'public' } app local_manager.make_middleware app return app
def _convert_key_to_str key if isinstance key six.text_type return str key return key
def check_hl_group_name hl_group context_mark context echoerr return _highlight_group_spec.match hl_group context_mark context_mark context context echoerr echoerr [1]
def Connection server queue config_path host port protocol server.split ' ' if not protocol in 'st' raise Exception 'Unknownprotocol %s' % protocol c TcpConnection server queue config_path c.start return c
def _get_flash_params esp args detect_flash_size esp args flash_mode {'qio' 0 'qout' 1 'dio' 2 'dout' 3}[args.flash_mode]flash_size_freq esp.parse_flash_size_arg args.flash_size flash_size_freq + {'40m' 0 '26m' 1 '20m' 2 '80m' 15}[args.flash_freq]return struct.pack 'BB' flash_mode flash_size_freq
def qos_specs_create context values return IMPL.qos_specs_create context values
@pytest.mark.skipif "hasattr sys 'pypy_version_info' " def test_install_from_wheel_with_headers script data package data.packages.join 'headers.dist-0.1-py2.py3-none-any.whl' result script.pip 'install' package '--no-index' expect_error False dist_info_folder script.site_packages / 'headers.dist-0.1.dist-info' assert dist_info_folder in result.files_created dist_info_folder result.files_created result.stdout
def shell_sort collection gaps [701 301 132 57 23 10 4 1]for gap in gaps i gapwhile i < len collection temp collection[i]j iwhile j > gap and collection[ j - gap ] > temp collection[j] collection[ j - gap ]j - gapcollection[j] tempi + 1return collection
def GetGeneratePath assert not is_readonly 'Whydoyouwantthegenpathforareadonlystore?'try os.makedirs win32com.__gen_path__ except os.error passtry fname os.path.join win32com.__gen_path__ '__init__.py' os.stat fname except os.error f open fname 'w' f.write '#Generatedfile-thisdirectorymaybedeletedtoresettheCOMcache...\n' f.write 'importwin32com\n' f.write 'if__path__[ -1]! win32com.__gen_path__ __path__.append win32com.__gen_path__ \n' f.close return win32com.__gen_path__
def get_acl_groups **filter_data acl_groups models.AclGroup.list_objects filter_data for acl_group in acl_groups acl_group_obj models.AclGroup.objects.get id acl_group['id'] acl_group['users'] [user.login for user in acl_group_obj.users.all ]acl_group['hosts'] [host.hostname for host in acl_group_obj.hosts.all ]return rpc_utils.prepare_for_serialization acl_groups
def fake_service_orm **updates db_service fake_db_service **updates service models.Service **db_service return service
def test_log_sum_exp_2 x np.array [ -100.0 100.0] x sharedX x stable log_sum_exp x .eval assert np.allclose stable 100.0
def add_lookup namespace directory package None prepend False templates LOOKUP.get namespace if not templates LOOKUP[namespace] templates DynamicTemplateLookup module_directory settings.MAKO_MODULE_DIR output_encoding 'utf-8' input_encoding 'utf-8' default_filters ['decode.utf8'] encoding_errors 'replace' if package directory pkg_resources.resource_filename package directory templates.add_directory directory prepend prepend
def mocked_get_recording_by_id id_ includes [] release_status [] release_type [] releases {ImportMusicBrainzIdTest.ID_RECORDING_0 'VALID_RECORDING_0' 'TAGARTIST' ImportMusicBrainzIdTest.ID_RECORDING_1 'VALID_RECORDING_1' 'DISTANT_MATCH' }return {'recording' {'title' releases[id_][0] 'id' id_ 'length' 59 'artist-credit' [{'artist' {'name' releases[id_][1] 'id' 'some-id'}}]}}
def libvlc_audio_get_volume p_mi f _Cfunctions.get 'libvlc_audio_get_volume' None or _Cfunction 'libvlc_audio_get_volume' 1 None ctypes.c_int MediaPlayer return f p_mi
def execute_until_empty taskqueue queue 'default' handlers_map None task_run_counts collections.defaultdict lambda 0 while taskqueue.GetTasks queue new_counts execute_all_tasks taskqueue queue handlers_map for handler_cls in new_counts task_run_counts[handler_cls] + new_counts[handler_cls]return task_run_counts
def sum_combine s_t from sympy.concrete.summations import Sumused [False] * len s_t for method in range 2 for i s_term1 in enumerate s_t if not used[i] for j s_term2 in enumerate s_t if not used[j] and i ! j temp sum_add s_term1 s_term2 method if isinstance temp Sum or isinstance temp Mul s_t[i] temps_term1 s_t[i]used[j] Trueresult S.Zerofor i s_term in enumerate s_t if not used[i] result Add result s_term return result
def post_upgrade name if name not in _tracker['post_upgrade'] return Falsereturn _tracker['post_upgrade'][name]
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def pca data ncomp None standardize True demean True normalize True gls False weights None method 'svd' pc PCA data ncomp ncomp standardize standardize demean demean normalize normalize gls gls weights weights method method return pc.factors pc.loadings pc.projection pc.rsquare pc.ic pc.eigenvals pc.eigenvecs
def minimize *rules **kwargs objective kwargs.get 'objective' identity def minrule expr return min [rule expr for rule in rules] key objective return minrule
def service_get_all_computes_by_hv_type context hv_type include_disabled False return IMPL.service_get_all_computes_by_hv_type context hv_type include_disabled include_disabled
def _arg_cache name return wf .cachefile u'{0}.argcache'.format name
def wait_for_notification page def _is_saving 'Whetherornotthenotificationiscurrentlyshowing.'return page.q css '.wrapper-notification-mini.is-shown' .presentdef _is_saving_done 'Whetherornotthenotificationisfinishedshowing.'return page.q css '.wrapper-notification-mini.is-hiding' .presentEmptyPromise _is_saving 'Notificationshouldhavebeenshown.' try_interval 0.1 timeout 60 .fulfill EmptyPromise _is_saving_done 'Notificationshouldhavebeenhidden.' try_interval 0.1 timeout 60 .fulfill
def get_programs_by_run programs enrollments programs_by_run {}course_ids [unicode e.course_id for e in enrollments]for program in programs for course_code in program['course_codes'] for run in course_code['run_modes'] run_id run['course_key']if run_id in course_ids program_list programs_by_run.setdefault run_id list if program not in program_list program_list.append program for program_list in programs_by_run.itervalues program_list.sort key lambda p p['name'] return programs_by_run course_ids
def encipher_hill msg key symbols None pad 'Q' assert key.is_squareassert len pad 1 msg pad A _prep msg pad symbols map {c i for i c in enumerate A }P [map[c] for c in msg]N len A k key.colsn len P m r divmod n k if r P P + [map[pad]] * k - r m + 1rv ''.join [A[ c % N ] for j in range m for c in list key * Matrix k 1 [P[i] for i in range k * j k * j + 1 ] ] return rv
def check_password_strength password password unicode password n math.log len set password num re.search '[0-9]' password is not None and re.match '^[0-9]*$' password is None caps password ! password.upper and password ! password.lower extra re.match '^[a-zA-Z0-9]*$' password is None score len password * n + caps + num + extra / 20 password_strength {0 'Weak' 1 'Medium' 2 'Strong' 3 'VeryStrong'}return password_strength[min 3 int score ]
def get_yaml_path builtin_name runtime '' if _handler_dir is None set_builtins_dir DEFAULT_DIR available_builtins set _available_builtins if runtime 'python27' available_builtins available_builtins - BUILTINS_NOT_AVAIABLE_IN_PYTHON27 if builtin_name not in available_builtins raise InvalidBuiltinName '%sisnotthenameofavalidbuiltin.\nAvailablehandlersare %s' % builtin_name ' '.join sorted available_builtins return _get_yaml_path builtin_name runtime
def localsite request local_site_name getattr request u'_local_site_name' None return {u'local_site_name' local_site_name u'perms' AllPermsWrapper request.user local_site_name }
def test_completion_option_for_command script res env setup_completion script 'pipsearch--' '2' assert '--help' in res.stdout 'autocompletefunctioncouldnotcomplete``--``'
def p_dimlist p if len p 4 p[0] p[1]p[0].append p[3] else p[0] [p[1]]
def convert_StringListProperty model prop kwargs return StringListPropertyField **kwargs
def diffsets_with_comments review current_pair if not review returndiffsets DiffSet.objects.filter files__comments__review review diffsets diffsets.filter files__comments__interfilediff__isnull True diffsets diffsets.distinct for diffset in diffsets yield {u'diffset' diffset u'is_current' current_pair[0] diffset and current_pair[1] is None }
def _U_func_numpy x1 y1 x2 y2 if x1 x2 and y1 y2 return 0.0r_2 x2 - x1 ** 2 + y2 - y1 ** 2 return r_2 * np.log r_2
def constructor_float loader node value loader.construct_scalar node return float value
def get_os_sslcertfile l get_os_sslcertfile_searchpath if l None return Nonefor f in l assert type f type '' if os.path.exists f and os.path.isfile f or os.path.islink f return freturn None
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def localUp images filters targets numModulesX paddingStart moduleStride numImgColors numGroups 1 numImages images.shape[0]numFilters filters.shape[0]assert targets.shape numImages numFilters * numModulesX * numModulesX '%s%d%d-%d-%d' % targets.shape.__str__ numImages numFilters numModulesX numModulesX _ConvNet.localUp images.p_mat filters.p_mat targets.p_mat numModulesX - paddingStart moduleStride numImgColors numGroups
def libvlc_media_player_get_media p_mi f _Cfunctions.get 'libvlc_media_player_get_media' None or _Cfunction 'libvlc_media_player_get_media' 1 class_result Media ctypes.c_void_p MediaPlayer return f p_mi
def add_lazy_relation cls field relation operation if relation RECURSIVE_RELATIONSHIP_CONSTANT app_label cls._meta.app_labelmodel_name cls.__name__else try app_label model_name relation.split '.' except ValueError app_label cls._meta.app_labelmodel_name relationexcept AttributeError app_label relation._meta.app_labelmodel_name relation._meta.object_namemodel get_model app_label model_name seed_cache False only_installed False if model operation field model cls else key app_label model_name value cls field operation pending_lookups.setdefault key [] .append value
def _preformat_objects modules objects output {}if objects for module in modules output[module.name] {'module' module 'label' _ module.title 'count' 0 'objects' {}}for key in objects if objects[key]['module'] module if hasattr objects[key]['objects'] 'count' output[module.name]['count'] + objects[key]['objects'].count objects[key]['label'] _ objects[key]['label'] output[module.name]['objects'][key] objects[key]return output
def install_middlewares app settings if settings.get 'newrelic_config' ini_file settings['newrelic_config']env settings['newrelic_env']newrelic.agent.initialize ini_file env app newrelic.agent.WSGIApplicationWrapper app if asbool settings.get 'profiler_enabled' profile_dir settings['profiler_dir']app ProfilerMiddleware app profile_dir profile_dir restrictions '*kinto.core*' return app
def latin_to_vcg st for char in st if char not in string.ascii_letters try num ord char if num > 192 st st.replace char '\\fi%d' % ord char except passreturn st
def sanitize_param value valid_characters valid_chars character_map mapped_chars invalid_character 'X' if isinstance value string_types return sanitize_text value valid_characters valid_characters character_map character_map invalid_character invalid_character elif isinstance value list return [sanitize_text x valid_characters valid_characters character_map character_map invalid_character invalid_character for x in value]else raise Exception 'Unknownparametertype %s ' % type value
def get_built_statics_path r2_path get_r2_path return os.path.join r2_path 'build' 'public'
def cbPickMailbox result proto mboxes mbox mboxes[ int result or '1' - 1 ]return proto.examine mbox .addCallback cbExamineMbox proto
def _time_to_micros time seconds time.hour * 60 * 60 + time.minute * 60 + time.second return 1000000 * seconds + time.microsecond
def test_rewriting html "<ahref 'foo'>bar</a><ahref 'http //alpha.com'>baz</a>"assert_true '<ahref "/proxy/abc.com/80/sub/foo">bar</a>' in _rewrite_links UrlLibFileWrapper html 'http //abc.com/sub/' msg 'Relativelinks' assert_true '<ahref "/proxy/alpha.com/80/">baz</a>' in _rewrite_links UrlLibFileWrapper html 'http //abc.com/sub/' msg 'Absolutelinks' html "<ahref 'http //alpha.com 1234/bar'>bar</a><ahref 'http //alpha.com -1/baz'>baz</a>"assert_true '<ahref "/proxy/alpha.com/1234/bar">bar</a><a>baz</a>' in _rewrite_links UrlLibFileWrapper html 'http //abc.com/sub/' msg 'URLwithinvalidport' html '\n<imgsrc "/static/hadoop-logo.jpg"/><br>\n'rewritten _rewrite_links UrlLibFileWrapper html 'http //abc.com/sub/' assert_true '<imgsrc "/proxy/abc.com/80/static/hadoop-logo.jpg">' in rewritten msg 'Rewriteimages'
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def fake_site_name name default None if name 'SITE_NAME' return 'openedx.localhost'else return default
def setDefaultPrivacyList disp listname None return setActivePrivacyList disp listname 'default'
def getSequenceIndexPlusOneFromText fileText craftSequence getReadCraftSequence for craftSequenceIndex in xrange len craftSequence - 1 -1 -1 procedure craftSequence[craftSequenceIndex]if gcodec.isProcedureDone fileText procedure return craftSequenceIndex + 1 return 0
def _check_available name _status _systemctl_status name sd_version salt.utils.systemd.version __context__ if sd_version is not None and sd_version > 231 return 0 < _status['retcode'] < 4 out _status['stdout'].lower if 'couldnotbefound' in out return Falsefor line in salt.utils.itertools.split out '\n' match re.match '\\s+loaded \\s+ \\S+ ' line if match ret match.group 1 ! 'not-found' breakelse raise CommandExecutionError "Failedtogetinformationonunit'%s'" % name return ret
def remove_latex_commands s chars []FOUND_SLASH Falsefor c in s if c '{' if FOUND_SLASH FOUND_SLASH Falseelif c '}' passelif c '\\' FOUND_SLASH Trueelif not FOUND_SLASH chars.append c elif c.isspace FOUND_SLASH Falsereturn ''.join chars
def _get_cohort_representation cohort course group_id partition_id cohorts.get_group_info_for_cohort cohort assignment_type cohorts.get_assignment_type cohort return {'name' cohort.name 'id' cohort.id 'user_count' cohort.users.count 'assignment_type' assignment_type 'user_partition_id' partition_id 'group_id' group_id}
def get_full_pci_id pci_id cmd "lspci-D|awk'/%s/{print$1}'" % pci_id status full_id commands.getstatusoutput cmd if status ! 0 return Nonereturn full_id
def flatten expr new new cls expr.__class__args []for arg in expr.args if arg.__class__ cls args.extend arg.args else args.append arg return new expr.__class__ *args
def ChiSquared name k return rv name ChiSquaredDistribution k
def get_app_submodules submodule_name for name module in get_app_modules if module_has_submodule module submodule_name yield name import_module u'%s.%s' % name submodule_name
def rate rate if rate if isinstance rate basestring ops _ modifier rate.partition '/' return RATE_MODIFIER_MAP[ modifier or 's' ] int ops or 0 return rate or 0 return 0
def regions language x a language.lower [] for tag language region iso639 iso3166 in LANGUAGE_REGION.items if iso639 x a.append iso3166 return sorted a key lambda tag tag.lower ! x and tag or ''
def _next_datetime_with_utc_hour table_name utc_hour today datetime.date.today start_date_time datetime.datetime year today.year month today.month day today.day hour utc_hour minute _get_deterministic_value_for_table_name table_name 60 second _get_deterministic_value_for_table_name table_name 60 if start_date_time < datetime.datetime.utcnow one_day datetime.timedelta days 1 start_date_time + one_dayreturn start_date_time
def assert_allclose actual desired rtol 1e-07 atol 0 err_msg '' verbose True numpy.testing.assert_allclose cupy.asnumpy actual cupy.asnumpy desired rtol rtol atol atol err_msg err_msg verbose verbose
@receiver REGISTER_USER def email_marketing_register_user sender user None profile None **kwargs email_config EmailMarketingConfiguration.current if not email_config.enabled returnif user.is_anonymous returnupdate_user.delay _create_sailthru_user_vars user user.profile user.email site _get_current_site new_user True
def get_std_icon name size None if not name.startswith 'SP_' name 'SP_' + name icon QWidget .style .standardIcon getattr QStyle name if size is None return iconelse return QIcon icon.pixmap size size
def _get_indices input_items wanted_items try iter input_items except raise ValueError 'Theinput_itemstosearchmustbeiterable.' try len wanted_items except wanted_items [wanted_items]if isinstance wanted_items basestring wanted_items [wanted_items]return [input_items.index item for item in wanted_items if item in input_items ]
def _sinch x x2 x * x if abs x < 0.0135 return 1 + x2 / 6.0 * 1 + x2 / 20.0 * 1 + x2 / 42.0 else return np.sinh x / x
def donate import webbrowserwebbrowser.open u'https //donate.wikimedia.org/w/index.php?title Special FundraiserLandingPage' new 2
def get_state_rules_stats exploration_id state_name exploration exp_services.get_exploration_by_id exploration_id state exploration.states[state_name]rule_keys []for group in state.interaction.answer_groups for rule in group.rule_specs rule_keys.append _OLD_SUBMIT_HANDLER_NAME rule.stringify_classified_rule if state.interaction.default_outcome rule_keys.append _OLD_SUBMIT_HANDLER_NAME exp_domain.DEFAULT_RULESPEC_STR answer_logs stats_domain.StateRuleAnswerLog.get_multi exploration_id [{'state_name' state_name 'rule_str' rule_key[1]} for rule_key in rule_keys] results {}for ind answer_log in enumerate answer_logs results['.'.join rule_keys[ind] ] {'answers' answer_log.get_top_answers 5 'rule_hits' answer_log.total_answer_count}return results
def get url conn urlopen url resp conn.read conn.close return resp
def unpack_handshake pay paylen len pay offset 0payarr []while offset < paylen h pay[offset offset + 4 ] t l24 struct.unpack '>B3s' h l struct.unpack '>I' '\x00' + l24 [0]payarr.append t l pay[ offset + 4 offset + 4 + l ] offset offset + l + 4 return payarr
def write_record_pair read1 read2 fileobj _rec_pair u'@%s\n%s\n+\n%s\n' * 2 _rec_pair_no_qual u'>%s\n%s\n' * 2 if hasattr read1 u'quality' assert hasattr read2 u'quality' recstr _rec_pair % read1.name read1.sequence read1.quality read2.name read2.sequence read2.quality else recstr _rec_pair_no_qual % read1.name read1.sequence read2.name read2.sequence try fileobj.write bytes recstr u'ascii' except TypeError fileobj.write recstr
def _naive_eval x t c k if x t[k] i kelse i np.searchsorted t x - 1 assert t[i] < x < t[ i + 1 ] assert i > k and i < len t - k return sum c[ i - j ] * _naive_B x k i - j t for j in range 0 k + 1
def w2p_pack filename path compiled False filenames None filename abspath filename path abspath path tarname filename + '.tar' if compiled tar_compiled tarname path '^[\\w\\.\\-]+$' exclude_content_from ['cache' 'sessions' 'errors'] else tar tarname path '^[\\w\\.\\-]+$' filenames filenames exclude_content_from ['cache' 'sessions' 'errors'] w2pfp gzopen filename 'wb' tarfp open tarname 'rb' w2pfp.write tarfp.read w2pfp.close tarfp.close os.unlink tarname
def select_query query_type 'list_nodes_select' client _get_client info client.select_query query_type return info
def condense_semicolons css return re.sub ';;+' ';' css
def scala_fat_library name srcs [] deps [] resources [] source_encoding None warnings None exclusions [] **kwargs target ScalaFatLibrary name srcs deps resources source_encoding warnings exclusions kwargs blade.blade.register_target target
@after.each_scenariodef screenshot_on_error scenario if scenario.failed try output_dir '{}/log'.format settings.TEST_ROOT image_name '{}/{}.png'.format output_dir scenario.name.replace '' '_' world.browser.driver.save_screenshot image_name except WebDriverException LOGGER.error 'Couldnotcaptureascreenshot'
def _uidXform line index uid line.split None 1 return int index - 1 uid
def ExpandXcodeVariables string expansions matches _xcode_variable_re.findall string if matches None return stringmatches.reverse for match in matches to_replace variable matchif not variable in expansions continuereplacement expansions[variable]string re.sub re.escape to_replace replacement string return string
def update_server_info repo repo._put_named_file os.path.join 'info' 'refs' ''.join generate_info_refs repo repo._put_named_file os.path.join 'objects' 'info' 'packs' ''.join generate_objects_info_packs repo
def is_writable path if os.path.isfile path return bool os.stat path .st_mode & stat.S_IWUSR else return True
def permission_blacked_out course role_names permission_name return not course.forum_posts_allowed and role_names {FORUM_ROLE_STUDENT} and any [permission_name.startswith prefix for prefix in ['edit' 'update' 'create']]
def reorder_suite suite classes reverse False class_count len classes suite_class type suite bins [OrderedSet for i in range class_count + 1 ]partition_suite_by_type suite classes bins reverse reverse reordered_suite suite_class for i in range class_count + 1 reordered_suite.addTests bins[i] return reordered_suite
def _urlfetch_to_gcs_stub url payload method headers request response follow_redirects False deadline None validate_certificate None headers_map dict header.key .lower header.value for header in headers result dispatch method headers_map url payload response.set_statuscode result.status_code response.set_content result.content[ urlfetch_stub.MAX_RESPONSE_SIZE] for k v in result.headers.iteritems if k.lower 'content-length' and method ! 'HEAD' v len response.content header_proto response.add_header header_proto.set_key k header_proto.set_value str v if len result.content > urlfetch_stub.MAX_RESPONSE_SIZE response.set_contentwastruncated True
def for_dtypes_combination types names 'dtype' full None if full is None full int os.environ.get 'CUPY_TEST_FULL_COMBINATION' '0' ! 0 if full combination parameterized.product {name types for name in names} else ts []for _ in range len names t list types random.shuffle t ts.append t combination [dict zip names typs for typs in zip *ts ]def decorator impl @functools.wraps impl def test_func self *args **kw for dtypes in combination kw_copy kw.copy kw_copy.update dtypes try impl self *args **kw_copy except Exception print dtypes raisereturn test_funcreturn decorator
def getPointsFromPath path radius thresholdRatio 0.9 if len path < 1 return []if len path < 2 return pathradius abs radius points []addHalfPath path points radius thresholdRatio addHalfPath path[ -1 ] points radius thresholdRatio return points
def _build_locale_table filename_or_file from xml.dom.minidom import parsedom parse filename_or_file reps dom.getElementsByTagName 'representation' locs map lambda r r.childNodes[0].data reps locale_map {}for loc in locs lang _ reg loc.partition '_' lang_map locale_map.setdefault lang {'regs' [] 'default' reg} lang_map['regs'].append reg locale_map['en']['default'] 'US'locale_map['es']['default'] 'LA'locale_map['zh']['default'] 'CN'locale_map['fr']['default'] 'FR'locale_map['pt']['default'] 'PT'return locale_map
@open_file 1 mode 'wb' def write_pajek G path encoding 'UTF-8' for line in generate_pajek G line + '\n'path.write line.encode encoding
def _display_library library_key_string request library_key CourseKey.from_string library_key_string if not isinstance library_key LibraryLocator log.exception 'Non-librarykeypassedtocontentlibrariesAPI.' raise Http404if not has_studio_read_access request.user library_key log.exception u'User%striedtoaccesslibrary%swithoutpermission' request.user.username unicode library_key raise PermissionDenied library modulestore .get_library library_key if library is None log.exception u'Library%snotfound' unicode library_key raise Http404response_format 'html'if request.GET.get 'format' 'html' 'json' or 'application/json' in request.META.get 'HTTP_ACCEPT' 'text/html' response_format 'json'return library_blocks_view library request.user response_format
def read_bool fid return _unpack_simple fid '>?' np.bool
def get_sample_cats pmf category return {k pmf[k][category] for k in pmf if pmf[k][category] ! '' }
def validate_ternary setting value option_parser config_parser None config_section None if isinstance value bool or value is None return valuetry return option_parser.booleans[value.strip .lower ]except KeyError return value
def production env.hosts ['cabot.arachnys.com']
def get_pxe_mac_path mac return os.path.join CONF.baremetal.tftp_root 'pxelinux.cfg' '01-' + mac.replace ' ' '-' .lower
def prepare_rows_as_nested_dicts query nested_dict_column_names all_dicts []for row in query.select_related row_dict row.get_object_dict for column in nested_dict_column_names if row_dict[column] is not None row_dict[column] getattr row column .get_object_dict all_dicts.append row_dict return prepare_for_serialization all_dicts
def floating_ip_destroy context address return IMPL.floating_ip_destroy context address
def register_adapter mod func if not hasattr func '__call__' raise TypeError 'funcmustbecallable' imports.when_imported mod func
def qos_specs_delete context qos_specs_id return IMPL.qos_specs_delete context qos_specs_id
def force_implementation modname global implementationfor name spec in [ e[0] e for e in _modules] if name modname implementation _JsonImplementation spec returnraise ImportError 'Nomodulenamed %s' % modname
def delay_denial func func.delay_denial True@functools.wraps func def wrapped *a **kw return func *a **kw return wrapped
def remove_arg args arg has_param False for idx found_arg in enumerate args if found_arg arg if has_param slice_idx idx + 2 else slice_idx idx + 1 args args[ idx] + args[slice_idx ] breakreturn args
def randlist n amp ds {}rng []for i in range 10000 while 1 b randint 50000 if b not in ds rng.append b ds[b] 1breakreturn rng
def get_bound_method_class m return m.im_class if sys.version < '3' else m.__self__.__class__
def separate_stains rgb conv_matrix rgb dtype.img_as_float rgb force_copy True rgb + 2stains np.dot np.reshape - np.log rgb -1 3 conv_matrix return np.reshape stains rgb.shape
def test_ncr_sk_estimator check_estimator NeighbourhoodCleaningRule
def quote c assert isinstance c bytes and len c 1 c ord c return ESCAPE + bytes HEX[ c // 16 ] HEX[ c % 16 ]
def load_mrjob_conf conf_path None conf_path _expanded_mrjob_conf_path conf_path return _conf_object_at_path conf_path
def send_email_after_import email result if '__error' in result send_email email action EVENT_IMPORT_FAIL subject MAILS[EVENT_IMPORT_FAIL]['subject'] html MAILS[EVENT_IMPORT_FAIL]['message'].format error_text result['result']['message'] else send_email email action EVENT_IMPORTED subject MAILS[EVENT_IMPORTED]['subject'].format event_name result['name'] html MAILS[EVENT_IMPORTED]['message'].format event_url request.url_root.strip '/' + '/events/%d' % result['id']
@render_to 'distributed/learn.html' def learn request context {'channel' CHANNEL 'pdfjs' settings.PDFJS}return context
def create_document_editor_group group group_created Group.objects.get_or_create name 'editor' if group_created actions 'add' 'change' 'delete' 'view' 'restore' perms [Permission.objects.get codename '%s_document' % action for action in actions]group.permissions permsgroup.save return group
def _check_for_invalid_keys fname kwargs compat_args diff set kwargs - set compat_args if diff bad_arg list diff [0]raise TypeError "{fname} gotanunexpectedkeywordargument'{arg}'".format fname fname arg bad_arg
def s3_set_default_filter selector value tablename None s3 current.response.s3filter_defaults s3for level in 'filter_defaults' tablename if level not in filter_defaults filter_defaults[level] {}filter_defaults filter_defaults[level]filter_defaults[selector] value
def getCheckpointParentDir experimentDir baseDir os.path.join experimentDir 'savedmodels' baseDir os.path.abspath baseDir return baseDir
def _file_reader fh while True chunk fh.read DOWNLOAD_CHUNK_SIZE if chunk '' fh.close break yield chunk
def InitAndRun run_callback shutdown_callback None scan_ops False server_logging True main.InitAndRun run_callback partial _StartWWW run_callback scan_ops shutdown_callback shutdown_callback server_logging server_logging
def _get_indices_Add expr inds list map get_indices expr.args inds syms list zip *inds non_scalars [x for x in inds if x ! set ]if not non_scalars return set {} if not all [ x non_scalars[0] for x in non_scalars[1 ]] raise IndexConformanceException 'Indicesarenotconsistent %s' % expr if not reduce lambda x y x ! y or y syms symmetries syms[0]else symmetries {}return non_scalars[0] symmetries
def expand_dictionary record separator '.' result {}for key value in record.items current resultpath key.split separator for part in path[ -1 ] if part not in current current[part] {}current current[part]current[path[ -1 ]] valuereturn result
def run _task
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def test_cases suite for suite_or_case in suite._tests if isinstance suite_or_case unittest.TestCase yield suite_or_case else for case in test_cases suite_or_case yield case
def update_counter page node_info None db None from osf.models import PageCounterreturn PageCounter.update_counter page node_info
@magic_arguments 'frobnicate' @argument '-f' '--foo' help 'anargument' def magic_foo5 self args return parse_argstring magic_foo5 args
def exception_from_message code message headers None kwargs {'code' code 'message' message 'headers' headers}if headers and 'retry_after' in headers kwargs['retry_after'] headers['retry_after']cls _code_map.get code BaseHTTPError return cls **kwargs
def inverse_matrix matrix return numpy.linalg.inv matrix
@not_implemented_for 'undirected' def attracting_component_subgraphs G copy True for ac in attracting_components G if copy yield G.subgraph ac .copy else yield G.subgraph ac
def _insert_links data_dict limit offset data_dict['_links'] {}try urlstring toolkit.request.environ['CKAN_CURRENT_URL']except KeyError TypeError returnparsed list urlparse.urlparse urlstring query urllib2.unquote parsed[4] arguments dict urlparse.parse_qsl query arguments_start dict arguments arguments_prev dict arguments arguments_next dict arguments if 'offset' in arguments_start arguments_start.pop 'offset' arguments_next['offset'] int offset + int limit arguments_prev['offset'] int offset - int limit parsed_start parsed[ ]parsed_prev parsed[ ]parsed_next parsed[ ]parsed_start[4] urllib.urlencode arguments_start parsed_next[4] urllib.urlencode arguments_next parsed_prev[4] urllib.urlencode arguments_prev data_dict['_links']['start'] urlparse.urlunparse parsed_start data_dict['_links']['next'] urlparse.urlunparse parsed_next if int offset - int limit > 0 data_dict['_links']['prev'] urlparse.urlunparse parsed_prev
def isPointAddedAroundClosest pixelTable layerExtrusionWidth paths removedEndpointPoint width closestDistanceSquared 1e+18closestPathIndex Nonefor pathIndex in xrange len paths path paths[pathIndex]for pointIndex in xrange len path point path[pointIndex]distanceSquared abs point - removedEndpointPoint if distanceSquared < closestDistanceSquared closestDistanceSquared distanceSquaredclosestPathIndex pathIndexif closestPathIndex None returnif closestDistanceSquared < 0.8 * layerExtrusionWidth * layerExtrusionWidth returnclosestPath paths[closestPathIndex]closestPointIndex getWithLeastLength closestPath removedEndpointPoint if isAddedPointOnPathFree closestPath pixelTable removedEndpointPoint closestPointIndex width addPointOnPath closestPath closestPathIndex pixelTable removedEndpointPoint closestPointIndex width return Truereturn isSidePointAdded pixelTable closestPath closestPathIndex closestPointIndex layerExtrusionWidth removedEndpointPoint width
@ssl_requireddef aaq_step5 request product_key category_key return aaq request product_key product_key category_key category_key showform True step 3
def _get_sorted_time_zone_list time_zone_list return sorted [_get_time_zone_dictionary time_zone for time_zone in time_zone_list] key lambda tz_dict tz_dict['description']
def GetMD5Hashes fname force False new_encoding Truetable {}if force or not flag_file os.path.split fname [0] QCHECK_FILE try f open fname 'rb' except return table new_encoding new_encoding Falsetry header f.read 8 while header name hash ParseFilePacket f header new_encoding | is_utf8 name if name table[name] hashheader f.read 8 except struct.error IndexError logging.info 'Cannotusecorruptpar2fileforQuickCheck "%s"' fname table {}except logging.debug 'QuickCheckparsercrashedinfile%s' fname logging.info 'Traceback ' exc_info True table {}f.close return table new_encoding
def set_date_or_time css date_or_time world.css_fill css date_or_time e world.css_find css .firste._element.send_keys Keys.ENTER
def move_item_xy item x y animate True duration None move_item item QPointF x y animate duration
def dp value return dpi2px value 'dp'
def parse_args parser argparse.ArgumentParser parser.add_argument '--profile-tool' metavar 'TOOL' action 'store' choices ['kcachegrind' 'snakeviz' 'gprof2dot' 'none'] default 'snakeviz' help 'Thetooltousetoviewtheprofilingdata' parser.add_argument '--profile-file' metavar 'FILE' action 'store' help 'Thefilenametousewith--profile-tool none' return parser.parse_known_args
def _butter_analog_poles n poles []for k in range - n + 1 n 2 poles.append - mpmath.exp 1j * mpmath.pi * k / 2 * n return poles
def get_private_key_size private_key passphrase None return _get_private_key_obj private_key passphrase .size * 8
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def high data test None queue False **kwargs conflict _check_queue queue kwargs if conflict is not None return conflictopts _get_opts kwargs.get 'localconfig' opts['test'] _get_test_value test **kwargs pillar kwargs.get 'pillar' pillar_enc kwargs.get 'pillar_enc' if pillar_enc is None and pillar is not None and not isinstance pillar dict raise SaltInvocationError 'Pillardatamustbeformattedasadictionary unlesspillar_encisspecified.' try st_ salt.state.State opts pillar pillar_enc pillar_enc proxy __proxy__ context __context__ except NameError st_ salt.state.State opts pillar pillar_enc pillar_enc ret st_.call_high data _set_retcode ret return ret
def key_pair_create context values return IMPL.key_pair_create context values
def topic_rule_absent name ruleName region None key None keyid None profile None ret {'name' ruleName 'result' True 'comment' '' 'changes' {}}r __salt__['boto_iot.topic_rule_exists'] ruleName region region key key keyid keyid profile profile if 'error' in r ret['result'] Falseret['comment'] 'Failedtodeleterule {0}.'.format r['error']['message'] return retif r and not r['exists'] ret['comment'] 'Rule{0}doesnotexist.'.format ruleName return retif __opts__['test'] ret['comment'] 'Rule{0}issettoberemoved.'.format ruleName ret['result'] Nonereturn retr __salt__['boto_iot.delete_topic_rule'] ruleName region region key key keyid keyid profile profile if not r['deleted'] ret['result'] Falseret['comment'] 'Failedtodeleterule {0}.'.format r['error']['message'] return retret['changes']['old'] {'rule' ruleName}ret['changes']['new'] {'rule' None}ret['comment'] 'Rule{0}deleted.'.format ruleName return ret
def get_field_on_block block field_name default_value None try if block.fields[field_name].is_set_on block return getattr block field_name except KeyError passreturn default_value
@image_comparison baseline_images [u'EventCollection_plot__switch_orientation'] def test__EventCollection__switch_orientation splt coll props generate_EventCollection_plot new_orientation u'vertical'coll.switch_orientation assert_equal new_orientation coll.get_orientation assert_equal False coll.is_horizontal new_positions coll.get_positions check_segments coll new_positions props[u'linelength'] props[u'lineoffset'] new_orientation splt.set_title u'EventCollection switch_orientation' splt.set_ylim -1 22 splt.set_xlim 0 2
def _get_innerhtml html_node html_string _get_outerhtml html_node html_string re.sub '^<[^<>]*?>' '' html_string count 1 return re.sub '<[^<>]*?>$' '' html_string count 1
def safe_open path mode 'w' chmod None buffering None open_args if chmod is None else chmod fdopen_args if buffering is None else buffering return os.fdopen os.open path os.O_CREAT | os.O_EXCL | os.O_RDWR *open_args mode *fdopen_args
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def xor_pair data avoid '\x00\n' if isinstance data int long data packing.pack data alphabet list chr n for n in range 256 if chr n not in avoid res1 ''res2 ''for c1 in data if context.randomize random.shuffle alphabet for c2 in alphabet c3 chr ord c1 ^ ord c2 if c3 in alphabet res1 + c2res2 + c3breakelse return Nonereturn res1 res2
def have_pyrex pyrex_impls 'Cython.Distutils.build_ext' 'Pyrex.Distutils.build_ext' for pyrex_impl in pyrex_impls try __import__ pyrex_impl fromlist ['build_ext'] .build_extreturn Trueexcept Exception passreturn False
def min_resize x size interpolation cv2.INTER_LINEAR w h map float x.shape[ 2] if min [w h] ! size if w < h x cv2.resize x int round h / w * size int size interpolation interpolation else x cv2.resize x int size int round w / h * size interpolation interpolation return x
def transposelist arrays axes extradims 0 if len axes ! ndimlist arrays raise ValueError 'Lengthofaxesshouldequaldepthofnestedarrays' if extradims < 0 raise ValueError '`newdims`shouldbepositive' if len axes > len set axes raise ValueError '`axes`shouldbeunique' ndim max axes + 1 shape shapelist arrays newshape [ shape[axes.index i ] if i in axes else 1 for i in range ndim + extradims ]result list core.flatten arrays return reshapelist newshape result
def list_records after None before None ret {}fmdump _check_fmdump cmd '{cmd}{after}{before}'.format cmd fmdump after '-t{0}'.format after if after else '' before '-T{0}'.format before if before else '' res __salt__['cmd.run_all'] cmd retcode res['retcode']result {}if retcode ! 0 result['Error'] 'errorexecutingfmdump'else result _parse_fmdump res['stdout'] return result
def get_template_attribute template_name attribute return getattr current_app.jinja_env.get_template template_name .module attribute
def create_html api_key attrs gif get_gif api_key attrs['gif_id'] if 'alt' not in attrs.keys attrs['alt'] 'source {}'.format gif['data']['source'] html_out '<ahref "{}">'.format gif['data']['url'] html_out + '<imgsrc "{}"alt "{}">'.format gif['data']['images']['original']['url'] attrs['alt'] html_out + '</a>'return html_out
def disabled name ret {'name' name 'result' True 'comment' '' 'changes' {}}is_enabled __salt__['apache.check_conf_enabled'] name if is_enabled if __opts__['test'] msg 'Apacheconf{0}issettobedisabled.'.format name ret['comment'] msgret['changes']['old'] nameret['changes']['new'] Noneret['result'] Nonereturn retstatus __salt__['apache.a2disconf'] name ['Status']if isinstance status string_types and 'disabled' in status ret['result'] Trueret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodisable{0}Apacheconf'.format name if isinstance status string_types ret['comment'] ret['comment'] + ' {0} '.format status return retelse ret['comment'] '{0}alreadydisabled.'.format name return ret
@nox.parametrize 'sample' ALL_SAMPLE_DIRECTORIES def session_lint session sample session.install 'flake8' 'flake8-import-order' local_names _determine_local_import_names sample args FLAKE8_COMMON_ARGS + ['--application-import-names' ' '.join local_names '.'] session.chdir sample session.run 'flake8' *args
def set_cert_generation_enabled course_key is_enabled CertificateGenerationCourseSetting.set_enabled_for_course course_key is_enabled cert_event_type 'enabled' if is_enabled else 'disabled' event_name '.'.join ['edx' 'certificate' 'generation' cert_event_type] tracker.emit event_name {'course_id' unicode course_key } if is_enabled log.info u"Enabledself-generatedcertificatesforcourse'%s'." unicode course_key else log.info u"Disabledself-generatedcertificatesforcourse'%s'." unicode course_key
@skip 'multiple_execute' @retry_on_failuredef test_makefile_refcount def echoer port s socket.socket s.bind 'localhost' port s.listen 5 s2 ignore s.accept s2.send s2.recv 10 port 50008thread.start_new_thread echoer port time.sleep 0 s socket.socket s.connect 'localhost' port f1 s.makefile 'r' f2 s.makefile 'w' s.close test_msg 'abc\n'f2.write test_msg f2.flush str f1.readline Assert str test_msg
def test_local_legacy_flag script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' result script.pip 'list' '--local' '--format legacy' assert 'simple 1.0 ' in result.stdout
def test_zero assert satask Q.zero x | Q.zero y Q.zero x * y is True assert satask Q.zero x * y Q.zero x | Q.zero y is True assert satask Implies Q.zero x Q.zero x * y is True assert satask Q.zero x | Q.zero y Q.nonzero x * y is False assert satask Q.zero x Q.zero x ** 2 is True
def read_uic4tag fh byteorder dtype plane_count assert dtype '1I' and byteorder '<' result {}while True tagid struct.unpack '<H' fh.read 2 [0]if tagid 0 break name value read_uic_tag fh tagid plane_count offset False result[name] valuereturn result
def _get_sr_comments sr_id q Comment._query Comment.c.sr_id sr_id sort desc '_date' return make_results q
def getAngleDifferenceByComplex subtractFromComplex subtractComplex subtractComplexMirror complex subtractComplex.real - subtractComplex.imag differenceComplex subtractComplexMirror * subtractFromComplex return math.atan2 differenceComplex.imag differenceComplex.real
def password_response password times_called None silent True fake Fake 'getpass' callable True if isinstance password StringTypes passwords [password]else passwords list password echo lambda x y y.write x + '\n' if x ! '' else '' fake fake.returns passwords.pop 0 if not silent fake fake.calls echo for pw in passwords fake fake.next_call .returns pw if not silent fake fake.calls echo if times_called fake fake.times_called times_called return patched_context getpass 'getpass' fake
def missing_docutils_page request return render_to_response 'admin_doc/missing_docutils.html'
def tweak_code func codestring None consts None co func.__code__tp type co if codestring is None codestring co.co_codeif consts is None consts co.co_constsif sys.version_info > 3 new_code tp co.co_argcount co.co_kwonlyargcount co.co_nlocals co.co_stacksize co.co_flags codestring consts co.co_names co.co_varnames co.co_filename co.co_name co.co_firstlineno co.co_lnotab else new_code tp co.co_argcount co.co_nlocals co.co_stacksize co.co_flags codestring consts co.co_names co.co_varnames co.co_filename co.co_name co.co_firstlineno co.co_lnotab func.__code__ new_code
def fix_reg_approved_log_params targets logger.info 'Migratingregistration_approvedlogs.' count 0for log in targets log.params['registration'] RegistrationApproval.load log.params['registration_approval_id'] ._get_registration ._idlogger.info 'Updatingparams[registration]oflog{}.params[node] {} params[registration] {}'.format log._id log.params['node'] log.params['registration'] log.original_node log.save count + 1logger.info '{}logsmigrated'.format count
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def _test form EvForm 'evennia.utils.evform_test' form.map cells {'AA' '|gTomtheBouncer' 2 '|yGriatch' 3 'Asturdyfellow' 4 12 5 10 6 5 7 18 8 10 9 3} tableA EvTable 'HP' 'MV' 'MP' table [['**'] ['*****'] ['***']] border 'incols' tableB EvTable 'Skill' 'Value' 'Exp' table [['Shooting' 'Herbalism' 'Smithing'] [12 14 9] ['550/1200' '990/1400' '205/900']] border 'incols' form.map tables {'A' tableA 'B' tableB} return unicode form
def set_values data if data.set_value for args in data.set_value doc frappe.get_doc args[0] args[1] or args[0] doc.set args[2] args[3] doc.save
def _get_domain *vms **kwargs ret list lookup_vms list conn __get_conn all_vms list_domains if not all_vms raise CommandExecutionError 'Novirtualmachinesfound.' if vms for vm in vms if vm not in all_vms raise CommandExecutionError 'TheVM"{name}"isnotpresent'.format name vm else lookup_vms.append vm else lookup_vms list all_vms for vm in lookup_vms ret.append conn.lookupByName vm return len ret 1 and not kwargs.get 'iterable' and ret[0] or ret
def readWriteNavigationHelp documentDirectoryPath transferredFileNameIndex transferredFileNames fileName os.path.basename transferredFileNames[transferredFileNameIndex] print 'readWriteNavigationHelp' + fileName filePath os.path.join documentDirectoryPath fileName fileText archive.getFileText filePath fileText getNavigationHypertext fileText transferredFileNameIndex transferredFileNames archive.writeFileText filePath fileText
def find_tex_file filename format None cmd ['kpsewhich']if format is not None cmd + [ '--format ' + format ]cmd + [filename]matplotlib.verbose.report 'find_tex_file %s %s' % filename cmd 'debug' pipe subprocess.Popen cmd stdout subprocess.PIPE result pipe.communicate [0].rstrip matplotlib.verbose.report 'find_tex_fileresult %s' % result 'debug' return result
def id_srando _id.id_srando
def encode_company_abbr name company company_abbr frappe.db.get_value u'Company' company u'abbr' parts name.rsplit u'-' 1 if parts[ -1 ].lower ! company_abbr.lower parts.append company_abbr return u'-'.join [parts[0] company_abbr]
def _GetGuidOfProject proj_path spec default_config _GetDefaultConfiguration spec guid default_config.get 'msvs_guid' if guid if VALID_MSVS_GUID_CHARS.match guid is None raise ValueError 'InvalidMSVSguid "%s".Mustmatchregex "%s".' % guid VALID_MSVS_GUID_CHARS.pattern guid '{%s}' % guid guid guid or MSVSNew.MakeGuid proj_path return guid
@csrf_protect@never_cachedef login request template_name 'registration/login.html' redirect_field_name REDIRECT_FIELD_NAME authentication_form AuthenticationForm redirect_to request.REQUEST.get redirect_field_name '' if request.method 'POST' form authentication_form data request.POST if form.is_valid if not redirect_to or '' in redirect_to redirect_to settings.LOGIN_REDIRECT_URLelif '//' in redirect_to and re.match '[^\\?]*//' redirect_to redirect_to settings.LOGIN_REDIRECT_URLauth_login request form.get_user if request.session.test_cookie_worked request.session.delete_test_cookie return HttpResponseRedirect redirect_to else form authentication_form request request.session.set_test_cookie current_site get_current_site request return render_to_response template_name {'form' form redirect_field_name redirect_to 'site' current_site 'site_name' current_site.name} context_instance RequestContext request
def authorize api_handle user resource arg1 None arg2 None return True
def _get_change_list state_name property_name new_value return [{'cmd' 'edit_state_property' 'state_name' state_name 'property_name' property_name 'new_value' new_value}]
def is_abstract_model model return hasattr model '_meta' and hasattr model._meta 'abstract' and model._meta.abstract
def validate_embargo_end_date end_date_string node end_date parse_date end_date_string ignoretz True .replace tzinfo pytz.utc today timezone.now if end_date - today < settings.DRAFT_REGISTRATION_APPROVAL_PERIOD raise HTTPError http.BAD_REQUEST data {'message_short' 'Invalidembargoenddate' 'message_long' 'Embargoenddateforthissubmissionmustbeatleast{0}daysinthefuture.'.format settings.DRAFT_REGISTRATION_APPROVAL_PERIOD } elif not node._is_embargo_date_valid end_date max_end_date today + settings.DRAFT_REGISTRATION_APPROVAL_PERIOD raise HTTPError http.BAD_REQUEST data {'message_short' 'Invalidembargoenddate' 'message_long' 'Embargoenddatemustonorbefore{0}.'.format max_end_date.isoformat }
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def test_find_module_2 nt.assert_is_none mp.find_module 'xmod' []
def get_pickle_protocol try protocol_str os.environ['PYLEARN2_PICKLE_PROTOCOL']except KeyError protocol_str '0'if protocol_str 'pickle.HIGHEST_PROTOCOL' return pickle.HIGHEST_PROTOCOLreturn int protocol_str
def _bestDriver devNames devIDs preferredDrivers prefs.general['audioDriver']outputID NoneaudioDriver NoneosEncoding sys.getfilesystemencoding for prefDriver in preferredDrivers logging.info 'Lookingfor{}'.format prefDriver if prefDriver.lower 'directsound' prefDriver u'PrimarySound'for devN devString in enumerate devNames logging.info 'Examiningfor{}'.format devString try ds devString.decode osEncoding .encode 'utf-8' .lower if prefDriver.encode 'utf-8' .lower in ds audioDriver devString.decode osEncoding .encode 'utf-8' outputID devIDs[devN]logging.info 'Success {}'.format devString return audioDriver outputID except UnicodeDecodeError UnicodeEncodeError logging.info 'Failed {}'.format devString logging.warn 'findbestsounddriver-couldnotinterpretunicodeindrivername' else return None None
def xonsh_superhelp x lineno None col None return xonsh_call '__xonsh_superhelp__' [x] lineno lineno col col
def bohachevsky individual return sum x ** 2 + 2 * x1 ** 2 - 0.3 * cos 3 * pi * x - 0.4 * cos 4 * pi * x1 + 0.7 for x x1 in zip individual[ -1 ] individual[1 ]
@lru_cache 1 def _containers_from_deployment deployment results []for node in deployment.nodes.itervalues for application in node.applications.values results.append container_configuration_response application node.uuid return results
def StartMain main argv None global FLAGSFLAGS PARSER.parse_args args argv try main [sys.argv[0]] except Exception if FLAGS.debug pdb.post_mortem raise
def _pick_format album fmt None if fmt return fmtif album return config['list_format_album'].get unicode else return config['list_format_item'].get unicode
def _rows_from_json rows schema return [_row_from_json row schema for row in rows]
def encrypt_master_key master_key public_key key RSA.importKey public_key cipher PKCS1_OAEP.new key return cipher.encrypt master_key
def pants_release return u'Pants{version}https //pypi.python.org/pypi/pantsbuild.pants/{version}'.format version pants_version
def serialize_stream stream obj check_qdatastream stream stream << obj check_qdatastream stream
def plot_normal_mix pis mus sigmas ax label '' comp True x np.linspace -10.5 10.5 250 final np.zeros_like x for i weight_mix mu_mix sigma_mix in enumerate zip pis mus sigmas temp stats.norm.pdf x mu_mix sigma_mix * weight_mix final final + temp if comp ax.plot x temp label 'Normal' + str i ax.plot x final label 'MixtureofNormals' + label ax.legend fontsize 13
def standard_icon standard_pixmap style QApplication.instance .style return style.standardIcon standard_pixmap
def test_cp14632 def helper_func class C def __eq__ self *args **kwargs return Truea C Assert C 3 x _weakref.proxy a y _weakref.proxy a AreEqual x y keep_alive a return x y x y helper_func gc.collect Assert not x 3 AssertError ReferenceError lambda x y
def test_editable_install_from_local_directory_with_no_setup_py script data result script.pip 'install' '-e' data.root expect_error True assert not result.files_created assert "isnotinstallable.File'setup.py'notfound." in result.stderr
def DEFINE parser name default help flag_values FLAGS serializer None **args DEFINE_flag Flag parser serializer name default help **args flag_values
def extract_read_info data fname seq qual get_read_data data seqstring qualstring format_as_fasta data['name'] seq qual xmlstring create_xml_for_unpaired_read data fname return seqstring qualstring xmlstring
def _pull_assemble_error_status status ret logs comment 'Anerroroccurredpullingyourimage'out ''try out '\n' + ret for err_log in logs if isinstance err_log dict if 'errorDetail' in err_log if 'code' in err_log['errorDetail'] msg '\n{0}\n{1} {2}'.format err_log['error'] err_log['errorDetail']['code'] err_log['errorDetail']['message'] else msg '\n{0}\n{1}'.format err_log['error'] err_log['errorDetail']['message'] comment + msgexcept Exception out traceback.format_exc _invalid status out out comment comment return status
def javascript_catalog request domain 'djangojs' packages None locale to_locale get_language if request.GET and 'language' in request.GET if check_for_language request.GET['language'] locale to_locale request.GET['language'] if packages is None packages ['django.conf']if isinstance packages six.string_types packages packages.split '+' catalog plural get_javascript_catalog locale domain packages return render_javascript_catalog catalog plural
@with_setup prepare_stdout def test_output_snippets_with_groups_within_single_quotes_colorless runner Runner feature_name 'single-quoted-snippet' verbosity 3 no_color True runner.run assert_stdout_lines u"\nFeature single-quotedsnippetproposal#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 1\n\nScenario Proposematchedgroups#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 2\nGivenIhave'stuffhere'and'more@#$%\u02c6&bizarsutffh3r3'#tests/functional/output_features/single-quoted-snippet/single-quoted-snippet.feature 3 undefined \n\n1feature 0passed \n1scenario 0passed \n1step 1undefined 0passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u'GivenIhave\\' [^\\']* \\'and\\' [^\\']* \\'' \ndefgiven_i_have_group1_and_group2 step group1 group2 \nassertFalse 'Thisstepmustbeimplemented'\n"
def freeze G G.add_node frozenG.add_nodes_from frozenG.remove_node frozenG.remove_nodes_from frozenG.add_edge frozenG.add_edges_from frozenG.remove_edge frozenG.remove_edges_from frozenG.clear frozenG.frozen Truereturn G
def save_auth_tokens token_dict user None if user is None user users.get_current_user if user is None return Nonememcache.set 'gdata_pickled_tokens %s' % user pickle.dumps token_dict user_tokens TokenCollection.all .filter 'user ' user .get if user_tokens user_tokens.pickled_tokens pickle.dumps token_dict return user_tokens.put else user_tokens TokenCollection user user pickled_tokens pickle.dumps token_dict return user_tokens.put
def get_template_dirs from django.conf import settingsdirs set if 'django.template.loaders.filesystem.load_template_source' in settings.TEMPLATE_LOADERS or 'django.template.loaders.filesystem.Loader' in settings.TEMPLATE_LOADERS dirs.update map unicode settings.TEMPLATE_DIRS if 'django.template.loaders.app_directories.load_template_source' in settings.TEMPLATE_LOADERS or 'django.template.loaders.app_directories.Loader' in settings.TEMPLATE_LOADERS from django.template.loaders.app_directories import app_template_dirsdirs.update app_template_dirs return dirs
def job_show context data_dict return {'success' False}
def needsquoting c quotetabs header if c in ' DCTB ' return quotetabsif c '_' return headerreturn c ESCAPE or not '' < c < '~'
def reverseNameFromIPAddress address try socket.inet_pton socket.AF_INET address except socket.error return reverseNameFromIPv6Address address else return reverseNameFromIPv4Address address
def build_user_agent global USER_AGENTif USER_AGENT return USER_AGENTua_tuple 'Mozilla/5.0' ' %s;U;%s;en-us ' % platform.system platform.architecture [0] 'Python/%s' % platform.python_version ' KHTML likeGecko ' 'speedtest-cli/%s' % __version__ USER_AGENT ''.join ua_tuple printer USER_AGENT debug True return USER_AGENT
def remove_volume_type_access context volume_type_id project_id if volume_type_id is None msg _ 'volume_type_idcannotbeNone' raise exception.InvalidVolumeType reason msg elevated context if context.is_admin else context.elevated if is_public_volume_type elevated volume_type_id msg _ 'Typeaccessmodificationisnotapplicabletopublicvolumetype.' raise exception.InvalidVolumeType reason msg db.volume_type_access_remove elevated volume_type_id project_id notify_about_volume_type_access_usage context volume_type_id project_id 'access.remove'
def datetime_to_seconds date return date.second + 60 * date.minute + 3600 * date.hour
def build_dist_from_args ctx dist args bs Bootstrap.get_bootstrap args.bootstrap ctx build_order python_modules bs get_recipe_order_and_bootstrap ctx dist.recipes bs ctx.recipe_build_order build_orderctx.python_modules python_modulesif python_modules and hasattr sys 'real_prefix' error 'virtualenvisneededtoinstallpure-Pythonmodules but' error 'virtualenvdoesnotsupportnesting andyouarerunning' error 'python-for-androidinone.Pleaserunp4aoutsideofa' error 'virtualenvinstead.' exit 1 info 'Theselectedbootstrapis{}'.format bs.name info_main '#Creatingdistwith{}bootstrap'.format bs.name bs.distribution distinfo_notify 'Distwillhavename{}andrecipes {} '.format dist.name ' '.join dist.recipes ctx.dist_name bs.distribution.namectx.prepare_bootstrap bs ctx.prepare_dist ctx.dist_name build_recipes build_order python_modules ctx ctx.bootstrap.run_distribute info_main '#Yourdistributionwascreatedsuccessfully exiting.' info 'Distcanbefoundat fornow {}'.format join ctx.dist_dir ctx.dist_name
def get_chunk samples labels chunkSize if len samples ! len labels raise Exception 'Lengthofsamplesandlabelsmustequal' stepStart 0i 0while stepStart < len samples stepEnd stepStart + chunkSize if stepEnd < len samples yield i samples[stepStart stepEnd] labels[stepStart stepEnd] i + 1stepStart stepEnd
def aggregate_get context aggregate_id return IMPL.aggregate_get context aggregate_id
def _get_umf_family A family {'di' 'di' 'Di' 'zi' 'dl' 'dl' 'Dl' 'zl'}dt A.dtype.char + A.indices.dtype.char return family[dt]
def generate_signed_link user viewname args None kwargs None if hasattr user 'is_authenticated' if not user.is_authenticated raise RuntimeError 'Needanauthenticatedusertosignalink.' user_id user.idelse user_id userpath reverse viewname args args kwargs kwargs item '%s|%s|%s' % options.get 'system.url-prefix' path base36_encode user_id signature ' '.join get_signer .sign item .rsplit ' ' 2 [1 ] return '%s?_ %s %s' % absolute_uri path base36_encode user_id signature
def jackknife_stats data statistic conf_lvl 0.95 from scipy.special import erfinvn data.shape[0]assert n > 0 u'datamustcontainatleastonemeasurement'resamples jackknife_resampling data stat_data statistic data jack_stat np.apply_along_axis statistic 1 resamples mean_jack_stat np.mean jack_stat axis 0 bias n - 1 * mean_jack_stat - stat_data std_err np.sqrt n - 1 * np.mean jack_stat - mean_jack_stat * jack_stat - mean_jack_stat axis 0 estimate stat_data - bias assert conf_lvl > 0 and conf_lvl < 1 u'confidencelevelmustbein 0 1 .'z_score np.sqrt 2.0 * erfinv conf_lvl conf_interval estimate + z_score * np.array - std_err std_err return estimate bias std_err conf_interval
def get_system_time now win32api.GetLocalTime meridian 'AM'hours int now[4] if hours 12 meridian 'PM'elif hours 0 hours 12elif hours > 12 hours hours - 12 meridian 'PM'return '{0 02d} {1 02d} {2 02d}{3}'.format hours now[5] now[6] meridian
def _get_privacy_fields privacy_level data {}for field in UserProfilePrivacyModel._meta.fields data[field.name] privacy_leveldata['privacy_tshirt'] PRIVILEGEDreturn data
def cleanHeaders headers method body host port if headers is None headers []found Falsefor k v in headers if k.lower 'host' found Truebreakif not found if port 80 headers.append 'Host' host else headers.append 'Host' '%s %s' % host port if method in methods_with_bodies found Falsefor k v in headers if k.lower 'content-type' found Truebreakif not found headers.append 'Content-Type' 'application/x-www-form-urlencoded' headers.append 'Content-Length' str len body or '' return headers
def is_weekly_release version parsed_version parse_version version return parsed_version.weekly_release is not None and parsed_version.commit_count is None and parsed_version.pre_release is None and parsed_version.dirty is None
def fetch_lfw_people data_home None funneled True resize 0.5 min_faces_per_person 0 color False slice_ slice 70 195 slice 78 172 download_if_missing True lfw_home data_folder_path check_fetch_lfw data_home data_home funneled funneled download_if_missing download_if_missing logger.info 'LoadingLFWpeoplefacesfrom%s' lfw_home m Memory cachedir lfw_home compress 6 verbose 0 load_func m.cache _fetch_lfw_people faces target target_names load_func data_folder_path resize resize min_faces_per_person min_faces_per_person color color slice_ slice_ return Bunch data faces.reshape len faces -1 images faces target target target_names target_names DESCR 'LFWfacesdataset'
def generate s limit 20 return _gen parse s limit
def validate_stringlist s if type s is str return [v.strip for v in s.split ' ' ]else assert type s in [list tuple] return [str v for v in s]
def proxyForInterface iface originalAttribute 'original' def __init__ self original setattr self originalAttribute original contents {'__init__' __init__}for name in iface contents[name] _ProxyDescriptor name originalAttribute proxy type ' Proxyfor%s ' % reflect.qual iface object contents declarations.classImplements proxy iface return proxy
def AccountListFeedFromString xml_string feed atom.CreateClassFromXMLString AccountListFeed xml_string for entry in feed.entry for pro in entry.property entry.__dict__[pro.name.replace 'ga ' '' ] profor td in entry.tableId td.__dict__['value'] td.textreturn feed
def update_unread_queries inbox_rels insert True mutator None if not mutator m CachedQueryMutator else m mutatorinbox_rels tup inbox_rels for inbox_rel in inbox_rels thing inbox_rel._thing2user inbox_rel._thing1if isinstance thing Comment if inbox_rel._name 'inbox' query get_unread_comments user._id elif inbox_rel._name 'selfreply' query get_unread_selfreply user._id elif inbox_rel._name 'mention' query get_unread_comment_mentions user._id elif isinstance thing Message query get_unread_messages user._id else raise ValueError "can'thandle%s" % thing.__class__.__name__ if insert m.insert query [inbox_rel] else m.delete query [inbox_rel] if not mutator m.send
def sync_runners saltenv 'base' return salt.utils.extmods.sync __opts__ 'runners' saltenv saltenv [0]
def sgf_iter_states sgf_string include_end True collection sgf.parse sgf_string game collection[0]gs _sgf_init_gamestate game.root if game.rest is not None for node in game.rest props node.propertiesif 'W' in props move _parse_sgf_move props['W'][0] player go.WHITEelif 'B' in props move _parse_sgf_move props['B'][0] player go.BLACK yield gs move player gs.do_move move player if include_end yield gs None None
def getappattr path from celery import current_appreturn current_app._rgetattr path
def addresses_from_address_families address_families return Addresses tuple a for af in address_families for a in af.addressables.keys
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def get_nested_value d key if '.' not in key if key not in d return Nonereturn d[key] base_key sub_key key.split '.' 1 if base_key not in d return Nonesub_dict d[base_key]return get_nested_value sub_dict sub_key
def plugin_loaded name if name in _PLUGINS return Truereturn False
def mode x counts Counter x max_count max counts.values return [x_i for x_i count in counts.iteritems if count max_count ]
def _truncate_digest_for_dsa dsa_cdata digest backend order_bits backend._lib.BN_num_bits dsa_cdata.q return _truncate_digest digest order_bits
def valid_path value value.encode 'ascii' if not value and value[0] '/' return Falseif not Definitions.PATH_RE.match value return Falsereturn True
def get_date_formats warnings.warn "'django.utils.translation.get_date_formats'isdeprecated.Pleaseupdateyourcodetousethenewi18nawareformatting." DeprecationWarning from django.conf import settingsdate_format ugettext 'DATE_FORMAT' datetime_format ugettext 'DATETIME_FORMAT' time_format ugettext 'TIME_FORMAT' if date_format 'DATE_FORMAT' date_format settings.DATE_FORMATif datetime_format 'DATETIME_FORMAT' datetime_format settings.DATETIME_FORMATif time_format 'TIME_FORMAT' time_format settings.TIME_FORMATreturn date_format datetime_format time_format
def corruptDLL createAssembly 'CORRUPT' 'CORRUPT' -1 file open 'fooCORRUPT.dll' 'rb' joe file.readlines file.close joe.insert len joe / 2 'Fileisnowcorrupted...\n' file open 'fooCORRUPT.dll' 'wb' file.writelines joe file.close
def load_json_sent flist_json subset_pct subset_fnum int np.ceil subset_pct / 100.0 * len flist_json all_sent []for f in flist_json[ subset_fnum] data load_json f num_sent len data['text'] if num_sent < 0 continuenum_sent len data['text'] sent [data['text'][i]['sentence'] for i in range num_sent ]all_sent + sentreturn all_sent
@_FFI.callback u'UTF8Buffer ExternContext* Id ' def extern_id_to_str context_handle id_ c _FFI.from_handle context_handle return c.utf8_buf str c.from_id id_
def default try conn get_connection if conn.session log.warning 'configuringnewdefaultconnectionforcqlenginewhenonewasalreadyset' except passconn register_connection 'default' hosts None default True conn.setup log.debug 'cqlengineconnectioninitializedwithdefaultsessiontolocalhost'
@environmentfilterdef do_attr environment obj name try name str name except UnicodeError passelse try value getattr obj name except AttributeError passelse if environment.sandboxed and not environment.is_safe_attribute obj name value return environment.unsafe_undefined obj name return valuereturn environment.undefined obj obj name name
def read_registers task addr_space return list read_int_list task.thread.sp0 - 21 * address_size task.thread.sp0 addr_space
def clause reldict relsym items relsym reldict['subjsym'] reldict['objsym'] return '%s %r %r ' % items
def stack tup axis 0 return concatenate [cupy.expand_dims x axis for x in tup] axis
@depends HAS_PYVMOMI def get_host_datetime host username password protocol None port None host_names None service_instance salt.utils.vmware.get_service_instance host host username username password password protocol protocol port port host_names _check_hosts service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name date_time_manager _get_date_time_mgr host_ref date_time date_time_manager.QueryDateTime ret.update {host_name date_time} return ret
def case_sensitive_collator global _case_sensitive_collatorif _case_sensitive_collator is None _case_sensitive_collator collator .clone _case_sensitive_collator.numeric sort_collator .numeric_case_sensitive_collator.upper_first Truereturn _case_sensitive_collator
def BuildObjects default_class stream loader yaml.loader.SafeLoader builder ObjectBuilder default_class handler yaml_builder.BuilderHandler builder listener yaml_listener.EventListener handler listener.Parse stream loader return handler.GetResults
def proportions_chisquare count nobs value None nobs np.atleast_1d nobs table expected n_rows _table_proportion count nobs if value is not None expected np.column_stack nobs * value nobs * 1 - value ddof n_rows - 1 else ddof n_rows chi2stat pval stats.chisquare table.ravel expected.ravel ddof ddof return chi2stat pval table expected
def _template_func setup func def inner _it _timer _func func setup _t0 _timer for _i in _it _func _t1 _timer return _t1 - _t0 return inner
def without_document_lock f @wraps f def wrapper *args **kw return f *args **kw wrapper.nolock Truereturn wrapper
def rewrite_file_imports item vendored_libs text item.read_text text re.sub 'pkg_resources.extern' 'pip._vendor' text for lib in vendored_libs text re.sub ' \\n\\s* import%s' % lib '\\1frompip._vendorimport%s' % lib text text re.sub ' \\n\\s* from%s' % lib '\\1frompip._vendor.%s' % lib text item.write_text text
def unsubscribe request watch_id try watch Watch.objects.get pk watch_id secret request.GET.get 's' if secret ! watch.secret raise Watch.DoesNotExistexcept Watch.DoesNotExist return render request 'motidings/unsubscribe_error.html' if request.method 'POST' watch.delete return render request 'motidings/unsubscribe_success.html' return render request 'motidings/unsub.html' {'watch' watch}
def parseString string parser None if parser is None from xml.dom import expatbuilderreturn expatbuilder.parseString string else from xml.dom import pulldomreturn _do_pulldom_parse pulldom.parseString string {'parser' parser}
def repl_absolute m base_path link m.group 0 try scheme netloc path params query fragment is_url is_absolute parse_url m.group 'path' [1 -1 ] if not is_absolute and not is_url path url2pathname path temp os.path.normpath os.path.join base_path path if os.path.exists temp path pathname2url temp.replace '\\' '/' link '%s"%s"' % m.group 'name' urlunparse scheme netloc path params query fragment except Exception passreturn link
def compose *funcs **kfuncs return reduce lambda f g lambda *args **kaargs f g *args **kaargs funcs
def get_sass_directories system theme_dir None if system not in SYSTEMS raise ValueError "'system'mustbeoneof {allowed_values} ".format allowed_values ' '.join SYSTEMS.keys system SYSTEMS[system]applicable_directories list if theme_dir applicable_directories.extend get_theme_sass_dirs system theme_dir else applicable_directories.extend get_system_sass_dirs system return applicable_directories
def resolve_ipv4 name flags 0 waiter Waiter core.dns_resolve_ipv4 name flags waiter.switch_args result _type ttl addrs waiter.get if result ! core.DNS_ERR_NONE raise DNSError result return ttl addrs
def _refresh_quota_usages quota_usage until_refresh in_use if quota_usage.in_use ! in_use LOG.info _LI 'quota_usagesoutofsync updating.project_id % project_id s user_id % user_id s resource % res s trackedusage % tracked_use s actualusage % in_use s' {'project_id' quota_usage.project_id 'user_id' quota_usage.user_id 'res' quota_usage.resource 'tracked_use' quota_usage.in_use 'in_use' in_use} else LOG.debug 'QuotaUsagehasnotchanged refreshisunnecessaryfor %s' dict quota_usage quota_usage.in_use in_usequota_usage.until_refresh until_refresh or None
@not_implemented_for 'undirected' def strongly_connected_component_subgraphs G copy True for comp in strongly_connected_components G if copy yield G.subgraph comp .copy else yield G.subgraph comp
def _get_wheel_version package_source return get_installable_version package_source.version or version
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def person return s3_rest_controller 'pr' 'person'
def config_to_yaml config assert 'init_config' in config "No'init_config'sectionfound"assert 'instances' in config "No'instances'sectionfound"valid_instances Trueif config['instances'] is None or not isinstance config['instances'] list valid_instances Falseelse yaml_output yaml.safe_dump config default_flow_style False if not valid_instances raise Exception 'Youneedtohaveatleastoneinstancedefinedinyourconfig.' return yaml_output
def cache_master saltenv 'base' return _client .cache_master saltenv
def void_output func argtypes errcheck True if argtypes func.argtypes argtypesif errcheck func.restype c_intfunc.errcheck check_errcodeelse func.restype Nonereturn func
def _identity_matcher target def match node return node is target return match
def test_hsl_to_rgb_part_18 assert hsl_to_rgb 300 100 0 0 0 0 assert hsl_to_rgb 300 100 10 51 0 51 assert hsl_to_rgb 300 100 20 102 0 102 assert hsl_to_rgb 300 100 30 153 0 153 assert hsl_to_rgb 300 100 40 204 0 204 assert hsl_to_rgb 300 100 50 255 0 255 assert hsl_to_rgb 300 100 60 255 51 255 assert hsl_to_rgb 300 100 70 255 102 255 assert hsl_to_rgb 300 100 80 255 153 255 assert hsl_to_rgb 300 100 90 255 204 255 assert hsl_to_rgb 300 100 100 255 255 255
def create_snappy_message payloads key None message_set KafkaProtocol._encode_message_set [create_message payload pl_key for payload pl_key in payloads] snapped snappy_encode message_set codec ATTRIBUTE_CODEC_MASK & CODEC_SNAPPY return kafka.structs.Message 0 0 | codec key snapped
def _totuple x if isinstance x str out x elif isinstance x int float out str x elif x is None out None else out tuple x return out
def get_registered_auth_backends warn u'reviewboard.accounts.backends.get_registered_auth_backends isdeprecated.Iterateoverreviewboard.accounts.backends.auth_backendsinstead.' DeprecationWarning for backend in auth_backends yield backend
def op_as_string i op leaf_formatter default_leaf_formatter node_formatter default_node_formatter strs as_string i op.inputs leaf_formatter node_formatter return node_formatter op strs
def _H n return struct.pack '>H' n
def add_organization_course organization_data course_id if not organizations_enabled return Nonefrom organizations import api as organizations_apireturn organizations_api.add_organization_course organization_data organization_data course_key course_id
def make_signed_jwt signer payload header {'typ' 'JWT' 'alg' 'RS256'}segments [_urlsafe_b64encode _json_encode header _urlsafe_b64encode _json_encode payload ]signing_input '.'.join segments signature signer.sign signing_input segments.append _urlsafe_b64encode signature logger.debug str segments return '.'.join segments
def libvlc_audio_output_device_enum mp f _Cfunctions.get 'libvlc_audio_output_device_enum' None or _Cfunction 'libvlc_audio_output_device_enum' 1 None ctypes.POINTER AudioOutputDevice MediaPlayer return f mp
def save_carousel shop carousel_pk configuration.set shop SAMPLE_CAROUSEL_KEY carousel_pk
@frappe.whitelist def get_standard_reply template_name doc if isinstance doc basestring doc json.loads doc standard_reply frappe.get_doc u'StandardReply' template_name return {u'subject' frappe.render_template standard_reply.subject doc u'message' frappe.render_template standard_reply.response doc }
def enable_debug fo from libcloud.common.base import Connectionfrom libcloud.utils.loggingconnection import LoggingConnectionLoggingConnection.log foConnection.conn_class LoggingConnection
def get_all_tensor_parents tensor parents_list []parents_list.append tensor if tensor.op for t in tensor.op.inputs parents_list + get_tensor_parents t return list set parents_list
def actor request content_type_id object_id ctype get_object_or_404 ContentType pk content_type_id instance get_object_or_404 ctype.model_class pk object_id return render_to_response 'actstream/actor.html' {'action_list' models.actor_stream instance 'actor' instance 'ctype' ctype} context_instance RequestContext request
def __before_delete collection _sa_initiator None executor collection._sa_adapterif executor executor.fire_pre_remove_event _sa_initiator
def get_gateway host port cache replace False from fabric.state import env outputsock Noneproxy_command ssh_config .get 'proxycommand' None if env.gateway gateway normalize_to_string env.gateway if replace or gateway not in cache if output.debug print 'Creatingnewgatewayconnectionto%r' % gateway cache[gateway] connect * normalize gateway + cache False sock direct_tcpip dict.__getitem__ cache gateway host port elif proxy_command sock ssh.ProxyCommand proxy_command return sock
def get_captcha_challenge http_body captcha_base_url 'http //www.google.com/accounts/' contains_captcha_challenge Falsecaptcha_parameters {}for response_line in http_body.splitlines if response_line.startswith 'Error CaptchaRequired' contains_captcha_challenge Trueelif response_line.startswith 'CaptchaToken ' captcha_parameters['token'] response_line[13 ]elif response_line.startswith 'CaptchaUrl ' captcha_parameters['url'] '%s%s' % captcha_base_url response_line[11 ] if contains_captcha_challenge return captcha_parameterselse return None
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def rollback name ret {'name' name 'changes' {} 'result' True 'comment' ''}ret['changes'] __salt__['junos.rollback'] return ret
def connect_to_queues region None public True return _create_client ep_name 'queues' region region public public
@block_user_agents@require_GET@allow_CORS_GET@process_document_pathdef children request document_slug document_locale expand 'expand' in request.GET max_depth 5depth int request.GET.get 'depth' max_depth if depth > max_depth depth max_depthresult []try doc Document.objects.get locale document_locale slug document_slug result _make_doc_structure doc 0 expand depth if result is None result {'error' 'Documenthasmoved.'}except Document.DoesNotExist result {'error' 'Documentdoesnotexist.'}return JsonResponse result
def _has_access_xmodule user action xmodule course_key return has_access user action xmodule.descriptor course_key
def get_parent_child_from_xpath name if '/' in name pname label name.rsplit '/' 1 else pname Nonelabel namereturn pname label
@log_call@utils.no_4byte_paramsdef metadef_tag_update context namespace_name id values global DATAnamespace metadef_namespace_get context namespace_name _check_namespace_visibility context namespace namespace_name tag metadef_tag_get_by_id context namespace_name id if tag['name'] ! values['name'] for db_tag in DATA['metadef_tags'] if db_tag['name'] values['name'] and db_tag['namespace_id'] namespace['id'] LOG.debug 'Invalidupdate.Itwouldresultinaduplicatemetadatadefinitiontagwithsamename % name sinnamespace % namespace_name s.' {'name' tag['name'] 'namespace_name' namespace_name} raise exception.MetadefDuplicateTag name tag['name'] namespace_name namespace_name DATA['metadef_tags'].remove tag tag.update values tag['updated_at'] timeutils.utcnow DATA['metadef_tags'].append tag return tag
def maybe_shutdown if should_stop is not None and should_stop is not False raise WorkerShutdown should_stop elif should_terminate is not None and should_terminate is not False raise WorkerTerminate should_terminate
@not_implemented_for 'directed' def clustering G nodes None weight None if weight is not None td_iter _weighted_triangles_and_degree_iter G nodes weight clusterc {v 0 if t 0 else t / d * d - 1 for v d t in td_iter}else td_iter _triangles_and_degree_iter G nodes clusterc {v 0 if t 0 else t / d * d - 1 for v d t _ in td_iter}if nodes in G return clusterc[nodes]return clusterc
def memoized_instancemethod fn def oneshot self *args **kw result fn self *args **kw memo lambda *a **kw result memo.__name__ fn.__name__memo.__doc__ fn.__doc__self.__dict__[fn.__name__] memoreturn resultreturn update_wrapper oneshot fn
def deprecatedWorkerClassProperty scope prop compat_name None new_name None if new_name is None scope_keys list scope.keys scope_values list scope.values attribute_name scope_keys[scope_values.index prop ]else attribute_name new_namecompat_name _compat_name attribute_name compat_name compat_name if attribute_name advice_msg "use'{0}'instead".format attribute_name else advice_msg "don'tuseit"def get self reportDeprecatedWorkerNameUsage "'{old}'propertyisdeprecated {advice}.".format old compat_name advice advice_msg return getattr self attribute_name assert compat_name not in scope scope[compat_name] property get
def generate_unique_password generated_passwords password_length 12 password generate_random_string password_length while password in generated_passwords password generate_random_string password_length generated_passwords.append password return password
def psql_csv_run sql_command error_handler None csv_query 'COPY {query} TOSTDOUTWITHCSVHEADER;'.format query sql_command new_env os.environ.copy new_env.setdefault 'PGOPTIONS' '' new_env['PGOPTIONS'] + '--statement-timeout 0'psql_proc popen_nonblock [PSQL_BIN '-d' 'postgres' '--no-password' '--no-psqlrc' '-c' csv_query] stdout PIPE env new_env stdout psql_proc.communicate [0].decode 'utf-8' if psql_proc.returncode ! 0 if error_handler is not None error_handler psql_proc else assert error_handler is None raise UserException 'couldnotcsv-executeaquerysuccessfullyviapsql' 'Querywas"{query}".'.format sql_command 'Youmayhavetosetsomelibpqenvironmentvariablesifyouaresuretheserverisrunning.' assert psql_proc.returncode 0 return csv.reader iter stdout.strip .split '\n'
def rsa_crt_iqmp p q return _modinv q p
def define_task name tick_script task_type 'stream' database None retention_policy 'default' if version < '0.13' cmd 'kapacitordefine-name{0}'.format name else cmd 'kapacitordefine{0}'.format name if tick_script.startswith 'salt //' tick_script __salt__['cp.cache_file'] tick_script __env__ cmd + '-tick{0}'.format tick_script if task_type cmd + '-type{0}'.format task_type if database and retention_policy cmd + '-dbrp{0}.{1}'.format database retention_policy return _run_cmd cmd
def has_shareable_memory a return _get_backing_memmap a is not None
def shortenIDs doc unprotectedElements None num 0identifiedElements findElementsWithId doc.documentElement if unprotectedElements is None unprotectedElements identifiedElementsreferencedIDs findReferencedElements doc.documentElement idList [ referencedIDs[rid][0] rid for rid in referencedIDs if rid in unprotectedElements ]idList.sort reverse True idList [rid for count rid in idList]curIdNum 1for rid in idList curId intToID curIdNum if curId ! rid while curId in identifiedElements curIdNum + 1curId intToID curIdNum num + renameID doc rid curId identifiedElements referencedIDs curIdNum + 1return num
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def load_tables words []utable numpy.load path_to_tables + 'utable.npy' btable numpy.load path_to_tables + 'btable.npy' f open path_to_tables + 'dictionary.txt' 'rb' for line in f words.append line.decode 'utf-8' .strip f.close utable OrderedDict zip words utable btable OrderedDict zip words btable return utable btable
def upgradeWithIQResponseTracker xs def callback iq '\nHandleiqresponsebyfiringassociateddeferred.\n'if getattr iq 'handled' False returntry d xs.iqDeferreds[iq['id']]except KeyError passelse del xs.iqDeferreds[iq['id']]iq.handled Trueif iq['type'] 'error' d.errback error.exceptionFromStanza iq else d.callback iq def disconnected _ "\nMakesuredeferredsdonotlingeronafterdisconnect.\n\nThiserrbacksalldeferredsofiq'sforwhichnoresponsehasbeen\nreceivedwithaL{ConnectionLost}failure.Otherwise thedeferreds\nwillneverbefired.\n"iqDeferreds xs.iqDeferredsxs.iqDeferreds {}for d in iqDeferreds.itervalues d.errback ConnectionLost xs.iqDeferreds {}xs.iqDefaultTimeout getattr xs 'iqDefaultTimeout' None xs.addObserver xmlstream.STREAM_END_EVENT disconnected xs.addObserver '/iq[@type "result"]' callback xs.addObserver '/iq[@type "error"]' callback directlyProvides xs ijabber.IIQResponseTracker
def test_ctor_keyword_args_newslot x BinderTest.KeywordDerived SomeProperty 'abc' AreEqual x.SomeProperty 'abc' x BinderTest.KeywordDerived SomeField 'abc' AreEqual x.SomeField 'abc'
def preload song delay 2 override False args song delay override t threading.Thread target _preload args args t.daemon Truet.start
def detach_virtual_disk_spec client_factory device destroy_disk False virtual_device_config client_factory.create 'ns0 VirtualDeviceConfigSpec' virtual_device_config.operation 'remove'if destroy_disk virtual_device_config.fileOperation 'destroy'virtual_device_config.device devicereturn virtual_device_config
def __format_items items column_names dataset []for item_dict in items row []for fieldname in column_names if fieldname 'name' html_element 'name'elif fieldname in ['system' 'repo' 'distro' 'profile' 'image' 'mgmtclass' 'package' 'file'] html_element 'editlink'elif fieldname in field_ui_info.USES_CHECKBOX html_element 'checkbox'else html_element 'text'row.append [fieldname item_dict[fieldname] html_element] dataset.append row return dataset
@api_experimental.route '/dags/<string dag_id>/tasks/<string task_id>' methods ['GET'] @requires_authenticationdef task_info dag_id task_id from airflow.www.views import dagbagif dag_id not in dagbag.dags response jsonify error 'Dag{}notfound'.format dag_id response.status_code 404return responsedag dagbag.dags[dag_id]if not dag.has_task task_id response jsonify error 'Task{}notfoundindag{}'.format task_id dag_id response.status_code 404return responsetask dag.get_task task_id fields {k str v for k v in vars task .items if not k.startswith '_' }return jsonify fields
def assign_user_to_page page user grant_on ACCESS_PAGE_AND_DESCENDANTS can_add False can_change False can_delete False can_change_advanced_settings False can_publish False can_change_permissions False can_move_page False can_recover_page True can_view False grant_all False global_permission False grant_all grant_all and not global_permission data {'can_add' can_add or grant_all 'can_change' can_change or grant_all 'can_delete' can_delete or grant_all 'can_change_advanced_settings' can_change_advanced_settings or grant_all 'can_publish' can_publish or grant_all 'can_change_permissions' can_change_permissions or grant_all 'can_move_page' can_move_page or grant_all 'can_view' can_view or grant_all }page_permission PagePermission page page user user grant_on grant_on **data page_permission.save if global_permission page_permission GlobalPagePermission user user can_recover_page can_recover_page **data page_permission.save page_permission.sites.add Site.objects.get_current return page_permission
def _encode_header key pdict if not pdict return keyout [key]for k v in sorted pdict.items if v is None out.append k else out.append '%s %s' % k v return ';'.join out
def mail_page_user_change user created False password '' if created subject _ 'CMS-youruseraccountwascreated.' else subject _ 'CMS-youruseraccountwaschanged.' send_mail subject 'admin/cms/mail/page_user_change.txt' [user.email] {'user' user 'password' password or '*' * 8 'created' created} 'admin/cms/mail/page_user_change.html'
def has_use atom use return has_flag 'use' atom use
def pullnodeIDs in_network name_key u'dn_name' import networkx as nximport numpy as npfrom nipype.interfaces.base import isdefinedif not isdefined in_network raise ValueErrorreturn Nonetry ntwk nx.read_graphml in_network except ntwk nx.read_gpickle in_network nodedata ntwk.nodeids []integer_nodelist []for node in list nodedata.keys integer_nodelist.append int node for node in np.sort integer_nodelist try nodeid nodedata[node][name_key]except KeyError nodeid nodedata[str node ][name_key]ids.append nodeid return ids
def get_image vm_ vm_image config.get_cloud_config_value 'image' vm_ __opts__ .encode 'ascii' 'salt-cloud-force-ascii' images avail_images for key value in images.iteritems if vm_image and vm_image in images[key]['id'] images[key]['name'] return images[key]raise SaltCloudNotFound "Thespecifiedimage '{0}' couldnotbefound.".format vm_image
def _activities_from_user_query user_id import ckan.model as modelq model.Session.query model.Activity q q.filter model.Activity.user_id user_id return q
def set_location node lineno col_offset def _fix node lineno col_offset if 'lineno' in node._attributes node.lineno linenoif 'col_offset' in node._attributes node.col_offset col_offsetfor child in ast.iter_child_nodes node _fix child lineno col_offset _fix node lineno col_offset return node
def get_installed_state m packages cmd get_cmd m 'search' cmd.extend ['--match-exact' '--details' '--installed-only'] cmd.extend packages return parse_zypper_xml m cmd fail_not_found False [0]
def trans ele standard False try node globals .get ele[u'type'] if not node raise NotImplementedError u'%sisnotsupported!' % ele[u'type'] if standard node node.__dict__[u'standard'] if u'standard' in node.__dict__ else node return node **ele except raise
def _af_parity pi n len pi a [0] * n c 0for j in range n if a[j] 0 c + 1a[j] 1i jwhile pi[i] ! j i pi[i]a[i] 1return n - c % 2
@receiver pre_delete sender Microsite def on_microsite_deleted sender instance **kwargs _make_archive_copy instance
def handle_threading_error scans_completed threading_error active_threads threading.active_count def nice_thread_repr alive_threads repr_alive [repr x for x in alive_threads]repr_alive.sort return pprint.pformat repr_alive pprint_threads nice_thread_repr threading.enumerate msg 'A"%s"threadingerrorwasfound.\nThecurrentprocesshasatotalof%sactivethreadsandhascompleted%sscans.Thecompletelistofthreadsfollows \n\n%s'raise Exception msg % threading_error active_threads scans_completed pprint_threads
def get_assignments_for_problem problem_descriptor user_id course_key locations []current_descriptor problem_descriptorwhile current_descriptor locations.append current_descriptor.location current_descriptor current_descriptor.get_parent assignments GradedAssignment.objects.filter user user_id course_key course_key usage_key__in locations return assignments
def writeRegisterRequestValue data packet unpack '>H' data[10 ] return packet[0]
def bracelets n k return necklaces n k free True
def _pairwise_similarity a b similarity a_rows a_cols b_rows b_cols _check_rows_and_columns a b n_a a_rows.shape[0]n_b b_rows.shape[0]result np.array list list similarity a_rows[i] a_cols[i] b_rows[j] b_cols[j] for j in range n_b for i in range n_a return result
def isclose a b rtol 1e-05 atol 1e-08 equal_nan False diff abs a - b tolerance atol + rtol * abs b close_prelim le diff tolerance a_nan isnan a b_nan isnan b nans bitwise_or a_nan b_nan a_inf isinf a b_inf isinf b infs bitwise_or a_inf b_inf nans_or_infs bitwise_or nans infs close bitwise_and close_prelim bitwise_not nans_or_infs both_infs bitwise_and a_inf b_inf inf_signs_eq eq a_inf * sgn a b_inf * sgn b inf_eq bitwise_and both_infs inf_signs_eq close_with_infs bitwise_or close inf_eq if equal_nan both_nans bitwise_and a_nan b_nan return bitwise_or close_with_infs both_nans else return close_with_infs
def check_astroyear year field config None pos None if year is not None and re.match u'^[JB]?[0-9]+ [.][0-9]* ?$' year is None warn_or_raise W07 W07 field year config pos return Falsereturn True
def get_password vm_ return config.get_cloud_config_value 'password' vm_ __opts__ default config.get_cloud_config_value 'passwd' vm_ __opts__ search_global False search_global False
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def get_js_dependencies group if settings.PIPELINE_ENABLED return [settings.PIPELINE_JS[group]['output_filename']]else return settings.PIPELINE_JS[group]['source_filenames']
def _split_version_id full_version_id server_and_version full_version_id.split '.' [0]result server_and_version.split ' ' if len result 2 return result[0] result[1] else return None result[0]
def add_to_distribution dist try dist.add_qt_bindings except AttributeError raise ImportError 'Thisscriptrequiresguidata1.5+' for _modname in 'spyder' 'spyderplugins' dist.add_module_data_files _modname '' '.png' '.svg' '.html' '.png' '.txt' '.js' '.inv' '.ico' '.css' '.doctree' '.qm' '.py' copy_to_root False
def num_obs_y Y Y np.asarray Y order 'c' is_valid_y Y throw True name 'Y' k Y.shape[0]if k 0 raise ValueError 'Thenumberofobservationscannotbedeterminedonanemptydistancematrix.' d int np.ceil np.sqrt k * 2 if d * d - 1 / 2 ! k raise ValueError 'Invalidcondenseddistancematrixpassed.Mustbesomekwherek nchoose2 forsomen> 2.' return d
def test_ros_fit_sample_half ratio 0.5ros RandomOverSampler ratio ratio random_state RND_SEED X_resampled y_resampled ros.fit_sample X Y X_gt np.array [[0.04352327 -0.20515826 ] [0.20792588 1.49407907] [0.22950086 0.33367433] [0.15490546 0.3130677] [0.09125309 -0.85409574 ] [0.12372842 0.6536186] [0.094035 -2.55298982 ] [0.92923648 0.76103773] [0.47104475 0.44386323] [0.13347175 0.12167502]] y_gt np.array [1 1 1 1 1 1 1 0 0 0] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def skipIfDBFeature feature return _deferredSkip lambda getattr connection.features feature 'Databasehasfeature%s' % feature
def _check_resources name expr resources if expr is None returnbound expr._resources if not bound and resources is None raise ValueError 'noresourcesprovidedtocompute%s' % name if bound and resources raise ValueError 'explicitandimplicitresourcesprovidedtocompute%s' % name
def create_locks l SHLock wrapper DebugRWLockWrapper if tweaks.get u'newdb_debug_locking' False else RWLockWrapper return wrapper l wrapper l is_shared False
def test_pytest_runner pyi_builder pyi_builder.test_source "\nimportpytest\nimportsys\nsys.exit pytest.main ['--help'] \n"
def fuzzy_bool x if x is None return Noneif x in True False return bool x
def medcouple y axis 0 if axis is None return _medcouple_1d y.ravel return np.apply_along_axis _medcouple_1d axis y
def comment_quote s comment str s comment _comment_quote_re.sub '-&gt;' comment return comment
def build_consumer_oauth_request backend token url redirect_uri '/' oauth_verifier None extra_params None method HTTP_METHOD params {'oauth_callback' redirect_uri}if extra_params params.update extra_params if oauth_verifier params['oauth_verifier'] oauth_verifierconsumer OAuthConsumer *backend.get_key_and_secret request OAuthRequest.from_consumer_and_token consumer token token http_method method http_url url parameters params request.sign_request SignatureMethod_HMAC_SHA1 consumer token return request
def create_default_settings from flaskbb.fixtures.settings import fixturecreate_settings_from_fixture fixture
def get_notifications_for_other config notification_count return get_notifications_for u'for_other' config notification_count
def diff before after assert after.eid before.eid plays []after_plays list after.drives.plays before_plays list before.drives.plays for play in after_plays if play not in before_plays plays.append play _players OrderedDict after_players list after.max_player_stats before_players list before.max_player_stats for aplayer in after_players has_before Falsefor bplayer in before_players if aplayer.playerid bplayer.playerid has_before Truepdiff aplayer - bplayer if pdiff is not None _players[aplayer.playerid] pdiffif not has_before _players[aplayer.playerid] aplayerplayers nflgame.seq.GenPlayerStats _players return GameDiff before before after after plays plays players players
def clean s lines [l.rstrip for l in s.split '\n' ]return '\n'.join lines
def model_fields model db_session None only None exclude None field_args None converter None if not hasattr model u'_sa_class_manager' raise TypeError u'modelmustbeasqlalchemymappedmodel' mapper model._sa_class_manager.mapperconverter converter or ModelConverter field_args field_args or {} properties p.key p for p in mapper.iterate_properties if only properties x for x in properties if x[0] in only elif exclude properties x for x in properties if x[0] not in exclude field_dict {}for name prop in properties field converter.convert model mapper prop field_args.get name db_session if field is not None field_dict[name] fieldreturn field_dict
@repo_mgr_cli.command 'show' @click.pass_contextdef show ctx client get_client **ctx.obj['client_args'] show_repos client
def _ConcatenateErrorMessages prefix status if status.error_detail return prefix + ' ' + status.error_detail return prefix
def validate_instantiation **kwargs if kwargs and kwargs.get 'netapp_mode' 'proxy' returnLOG.warning _LW 'ItisnottherecommendedwaytousedriversbyNetApp.PleaseuseNetAppDrivertoachievethefunctionality.'
def utf8encode value return unicodeencode value 'utf-8'
def runner name **kwargs jid kwargs.pop '__orchestration_jid__' None saltenv kwargs.pop '__env__' 'base' full_return kwargs.pop 'full_return' False kwargs salt.utils.clean_kwargs **kwargs if 'master_job_cache' not in __opts__ master_config os.path.join os.path.dirname __opts__['conf_file'] 'master' master_opts salt.config.master_config master_config rclient salt.runner.RunnerClient master_opts else rclient salt.runner.RunnerClient __opts__ if name in rclient.functions aspec salt.utils.args.get_function_argspec rclient.functions[name] if 'saltenv' in aspec.args kwargs['saltenv'] saltenvif jid salt.utils.event.fire_args __opts__ jid {'type' 'runner' 'name' name 'args' kwargs} prefix 'run' return rclient.cmd name kwarg kwargs print_event False full_return full_return
@FileSystem.in_directory current_directory 'django' 'brocolis' def test_harvest_with_debug_mode_disabled status out run_scenario 'leaves' 'disabled' assert_equals status 0 out
def split_function payload return payload[ - append_size ] payload
def _translate_message message return {'id' message['id'] 'project_id' message['project_id'] 'request_id' message['request_id'] 'resource_type' message['resource_type'] 'resource_uuid' message.get 'resource_uuid' 'event_id' message['event_id'] 'message_level' message['message_level'] 'created_at' message['created_at'] 'expires_at' message.get 'expires_at' }
def categorical_logpmf x logits x x.astype np.int32 p np.exp logits / np.sum np.exp logits 0 return np.log p [x]
def get_enabled jail None ret []service _cmd jail prf _get_jail_path jail if jail else '' for svc in __salt__['cmd.run'] '{0}-e'.format service .splitlines ret.append os.path.basename svc for svc in get_all jail if svc in ret continueif not os.path.exists '{0}/etc/rc.conf.d/{1}'.format prf svc continueif enabled svc jail jail ret.append svc return sorted ret
def inv_item_total_volume row try inv_item getattr row 'inv_inv_item' except AttributeError inv_item rowtry quantity inv_item.quantityexcept AttributeError return 0.0try supply_item getattr row 'supply_item' volume supply_item.volumeexcept AttributeError itable current.s3db.inv_inv_itemstable current.s3db.supply_itemquery itable.id inv_item.id & itable.item_id stable.id supply_item current.db query .select stable.volume limitby 0 1 .first if not supply_item returnelse volume supply_item.volumeif volume is None return current.messages['NONE']else return quantity * volume
def problems r **attr try group_id r.record.group_idexcept raise HTTP 400 else redirect URL f 'group' args [group_id 'problem']
def start_and_enable service start service enable service
def delete_queue name region opts None user None queues list_queues region opts user url_map _parse_queue_list queues logger logging.getLogger __name__ logger.debug 'map' + six.text_type url_map if name in url_map delete {'queue-url' url_map[name]}rtn _run_aws 'delete-queue' region region opts opts user user **delete success Trueerr ''out '{0}deleted'.format name else out ''err 'Deletefailed'success Falseret {'retcode' 0 if success else 1 'stdout' out 'stderr' err}return ret
def gravatar_url email size 80 return 'http //www.gravatar.com/avatar/%s?d identicon&s %d' % md5 email.strip .lower .encode 'utf-8' .hexdigest size
@task@cmdopts [ 'python_version ' 'p' 'Pythonversiontobuildtheinstalleragainst' ] def bdist_wininst_simple call_task 'clean' env os.environ.copy for k v in SITECFG['nosse'].items env[k] v_bdist_wininst options.bdist_wininst_simple.python_version env
def get_permalink_url self return '/'.join self.settings['SITEURL'] self.get_permalink_path
def scatter tensor devices chunk_sizes None dim 0 if chunk_sizes is None chunks tensor.chunk len devices dim else assert sum chunk_sizes tensor.size dim "givenchunksizesdon'tsumuptothetensor'ssize sum chunk_sizes {} butexpected{} ".format sum chunk_sizes tensor.size dim assert min chunk_sizes > 0 'gotanegativechunk_size'chunks [tensor.narrow dim start - size size for start size in zip _accumulate chunk_sizes chunk_sizes ]return tuple chunk.cuda gpu_id async chunk.is_contiguous for gpu_id chunk in zip devices chunks
def inv_recv_crud_strings T current.Tif current.deployment_settings.get_inv_shipment_name 'order' ADD_RECV T 'AddOrder' current.response.s3.crud_strings['inv_recv'] Storage label_create ADD_RECV title_display T 'OrderDetails' title_list T 'Orders' title_update T 'EditOrder' label_list_button T 'ListOrders' label_delete_button T 'DeleteOrder' msg_record_created T 'OrderCreated' msg_record_modified T 'Orderupdated' msg_record_deleted T 'Ordercanceled' msg_list_empty T 'NoOrdersregistered' else ADD_RECV T 'ReceiveNewShipment' current.response.s3.crud_strings['inv_recv'] Storage label_create ADD_RECV title_display T 'ReceivedShipmentDetails' title_list T 'Received/IncomingShipments' title_update T 'ShipmenttoReceive' label_list_button T 'ListReceived/IncomingShipments' label_delete_button T 'DeleteReceivedShipment' msg_record_created T 'ShipmentCreated' msg_record_modified T 'ReceivedShipmentupdated' msg_record_deleted T 'ReceivedShipmentcanceled' msg_list_empty T 'NoReceivedShipments' return
def packOpen_direct_tcpip destination source connHost connPort destination origHost origPort sourceif isinstance connHost unicode connHost connHost.encode 'utf-8' if isinstance origHost unicode origHost origHost.encode 'utf-8' conn common.NS connHost + struct.pack '>L' connPort orig common.NS origHost + struct.pack '>L' origPort return conn + orig
def clean_proc proc wait_for_kill 10 if not proc returntry waited 0while proc.is_alive proc.terminate waited + 1time.sleep 0.1 if proc.is_alive and waited > wait_for_kill log.error 'Processdidnotdiewithterminate {0}'.format proc.pid os.kill proc.pid signal.SIGKILL except AssertionError AttributeError pass
def locales names family distrib_family if family 'debian' command 'dpkg-reconfigure--frontend noninteractivelocales'config_file '/etc/locale.gen'_locales_generic names config_file config_file command command elif family in ['arch' 'gentoo'] _locales_generic names config_file '/etc/locale.gen' command 'locale-gen' elif distrib_family 'redhat' _locales_redhat names else raise UnsupportedFamily supported ['debian' 'arch' 'gentoo' 'redhat']
def unread_count_for user return InboxMessage.objects.filter to user read False .count
def get_extended_due_date node if isinstance node dict get node.getelse get partial getattr node due_date get 'due' None if not due_date return due_dateextended get 'extended_due' None if not extended or extended < due_date return due_datereturn extended
def addAttributeWord evaluatorWords word if len word < 2 evaluatorWords.append word returnif word[0] ! '.' evaluatorWords.append word returndotIndex word.find '.' 1 if dotIndex < 0 evaluatorWords.append word returnevaluatorWords.append word[ dotIndex] addAttributeWord evaluatorWords word[dotIndex ]
def tagify suffix '' prefix '' base SALT parts [base TAGS.get prefix prefix ]if hasattr suffix 'append' parts.extend suffix else parts.append suffix return TAGPARTER.join [part for part in parts if part]
def zmq_version return '%i.%i.%i' % zmq_version_info
@nodes_or_number [0 1] def complete_bipartite_graph n1 n2 create_using None if create_using is None G nx.Graph else if create_using.is_directed raise nx.NetworkXError 'DirectedGraphnotsupported' G create_usingG.clear n1 top n1 n2 bottom n2if isinstance n2 int bottom [ n1 + i for i in bottom]G.add_nodes_from top bipartite 0 G.add_nodes_from bottom bipartite 1 G.add_edges_from u v for u in top for v in bottom G.graph['name'] 'complete_bipartite_graph %s %s ' % n1 n2 return G
def get_resolver_for_permission_type permission_type resource_type PermissionType.get_resource_type permission_type permission_type resolver_instance get_resolver_for_resource_type resource_type resource_type return resolver_instance
def _process_content_range content_range _ _ range_spec content_range.partition '' byte_range _ _ range_spec.partition '/' start _ end byte_range.partition '-' return int end - int start + 1
def momentcondquant distfn params mom2 quantile None shape None if len params 2 loc scale paramselif len params 3 shape loc scale paramselse pass pq xq quantilecdfdiff distfn.cdf xq *params - pq return cdfdiff
def make_analysator f def text_analyse text try rv f text except Exception return 0.0if not rv return 0.0try return min 1.0 max 0.0 float rv except ValueError TypeError return 0.0text_analyse.__doc__ f.__doc__return staticmethod text_analyse
def subject_template template context subject loader.get_template template .render Context context return u''.join subject.splitlines .strip
def removeUnreferencedIDs referencedIDs identifiedElements global numIDsRemovedkeepTags ['font']num 0for id in identifiedElements.keys node identifiedElements[id]if referencedIDs.has_key id False and not node.nodeName in keepTags node.removeAttribute 'id' numIDsRemoved + 1num + 1return num
def mac addr valid re.compile '\n ^ [0-9A-F]{1 2}[-] {5} [0-9A-F]{1 2} $\n|^ [0-9A-F]{1 2}[ ] {5} [0-9A-F]{1 2} $\n|^ [0-9A-F]{1 2}[.] {5} [0-9A-F]{1 2} $ \n' re.VERBOSE | re.IGNORECASE return valid.match addr is not None
def mse actual predicted return np.mean se actual predicted
def push cwd remote None ref None opts '' user None password None identity None ignore_retcode False saltenv 'base' **kwargs kwargs salt.utils.clean_kwargs **kwargs if kwargs salt.utils.invalid_kwargs kwargs cwd _expand_path cwd user command ['git' 'push']command.extend _format_opts opts if not isinstance remote six.string_types remote str remote if not isinstance ref six.string_types ref str ref command.extend [remote ref] return _git_run command cwd cwd user user password password identity identity ignore_retcode ignore_retcode saltenv saltenv ['stdout']
def getRadiusComplex radius xmlElement radius getComplexByPrefixes ['demisize' 'radius'] radius xmlElement return getComplexByMultiplierPrefixes 2.0 ['diameter' 'size'] radius xmlElement
def ts_dlldy y df return - df + 1 / df / 1 + y ** 2 / df * y
def to_rgb c return to_rgba c [ 3]
def get_doctype_info module doctype_info frappe.db.sql u'select"doctype"astype name description \n DCTB DCTB ifnull document_type "" asdocument_type customascustom \n DCTB DCTB issingleasissingle\n DCTB DCTB from`tabDocType`wheremodule %sandistable 0\n DCTB DCTB orderbycustomasc document_typedesc nameasc' module as_dict True for d in doctype_info d.description _ d.description or u'' return doctype_info
def order_workflow_steps steps position_data_available Truefor step in steps if not step.position or 'left' not in step.position or 'top' not in step.position position_data_available Falseif position_data_available steps.sort key lambda _ math.sqrt _.position['left'] ** 2 + _.position['top'] ** 2 try edges edgelist_for_workflow_steps steps node_order topsort edges return [steps[i] for i in node_order]except CycleError return None
def create_invitation **kwargs project kwargs.pop 'project' ProjectFactory project.points.add PointsFactory.create project project value None defaults {'project' project 'role' RoleFactory.create project project 'email' 'invited-user@email.com' 'token' 'tokenvalue' 'invited_by_id' project.owner.id}defaults.update kwargs return MembershipFactory.create **defaults
def linscale d lim return d - d.min * lim[1] - lim[0] + lim[0]
def get_numeric_subclasses cls numpy.number ignore None if ignore is None ignore []rval []dtype numpy.dtype cls dtype_num dtype.numif dtype_num not in ignore numpy.array 0 dtype dtype rval.append cls ignore.append dtype_num for sub in cls.__subclasses__ rval + [c for c in get_numeric_subclasses sub ignore ignore ]return rval
def parse_content_range content_range found re.search _content_range_pattern content_range if not found raise ValueError 'malformedContent-Range%r' % content_range return tuple int x for x in found.groups
def getDateTime value None if value is None return datetime.datetime.today if isinstance value datetime.datetime return valueif isinstance value datetime.date return datetime.datetime.fromordinal value.toordinal if isinstance value int float return datetime.datetime.fromtimestamp value if isinstance value str raise NotImplementedError "Stringsaren'tcurrentlyimplemented" if hasattr value '__getitem__' return datetime.datetime *tuple value [ 6] return datetime.datetime.fromtimestamp value.ticks
def _edge_generator_from_csr csr_matrix nrows csr_matrix.shape[0]values csr_matrix.dataindptr csr_matrix.indptrcol_indices csr_matrix.indicesfor i in range nrows for j in range indptr[i] indptr[ i + 1 ] yield i col_indices[j] values[j]
def argspec module '' return salt.utils.argspec_report __salt__ module
def _check_steps a b if a.step ! 1 raise ValueError 'a.stepmustbeequalto1 got %s' % a.step if b.step ! 1 raise ValueError 'b.stepmustbeequalto1 got %s' % b.step
def set_mem_rlimit max_mem None import resourceif max_mem is None mem_info get_mem_info max_mem int mem_info['memtotal'] * 0.7 cur_limit resource.getrlimit resource.RLIMIT_AS if cur_limit[0] > 0 max_mem min max_mem cur_limit[0] resource.setrlimit resource.RLIMIT_AS max_mem cur_limit[1]
def preprocess_for_train image output_height output_width padding _PADDING tf.image_summary 'image' tf.expand_dims image 0 image tf.to_float image if padding > 0 image tf.pad image [[padding padding] [padding padding] [0 0]] distorted_image tf.random_crop image [output_height output_width 3] distorted_image tf.image.random_flip_left_right distorted_image tf.image_summary 'distorted_image' tf.expand_dims distorted_image 0 distorted_image tf.image.random_brightness distorted_image max_delta 63 distorted_image tf.image.random_contrast distorted_image lower 0.2 upper 1.8 return tf.image.per_image_whitening distorted_image
def get_all_messages_from_js_files app_name None messages []for app in [app_name] if app_name else frappe.get_installed_apps if os.path.exists frappe.get_app_path app u'public' for basepath folders files in os.walk frappe.get_app_path app u'public' if u'frappe/public/js/lib' in basepath continuefor fname in files if fname.endswith u'.js' or fname.endswith u'.html' messages.extend get_messages_from_file os.path.join basepath fname return messages
def _verify_subnet_association route_table_desc subnet_id if route_table_desc if 'associations' in route_table_desc for association in route_table_desc['associations'] if association['subnet_id'] subnet_id return Truereturn False
def isNullValue value return isinstance value basestring and value.upper NULL
def get_prefetcher instance attr prefetcher Noneattr_found Falseis_fetched Falserel_obj_descriptor getattr instance.__class__ attr None if rel_obj_descriptor is None try rel_obj getattr instance attr attr_found Trueexcept AttributeError passelse attr_found Trueif rel_obj_descriptor if hasattr rel_obj_descriptor 'get_prefetch_query_set' prefetcher rel_obj_descriptorif rel_obj_descriptor.is_cached instance is_fetched Trueelse rel_obj getattr instance attr if hasattr rel_obj 'get_prefetch_query_set' prefetcher rel_objreturn prefetcher rel_obj_descriptor attr_found is_fetched
def tool_tag_manager app if hasattr app.config 'get_bool' and app.config.get_bool 'enable_tool_tags' False return PersistentToolTagManager app else return NullToolTagManager
def _zero_pad array amount axes 1 2 if amount 0 return arraynew_shape []slices []for i s in enumerate array.shape if i in axes new_shape.append s + 2 * amount slices.append slice amount - amount else new_shape.append s slices.append slice None new_shape tuple new_shape slices tuple slices new_array numpy.zeros new_shape dtype array.dtype new_array[slices] arrayreturn new_array
def generate_hash txt None length None import hashlib timefrom .utils import random_stringdigest hashlib.sha224 txt or u'' + repr time.time + repr random_string 8 .hexdigest if length digest digest[ length]return digest
def _BackendPremultiplication color alpha color[3]rgb color[0 3]multiplied [ x * alpha + 1 >> 8 for x in rgb]if alpha alpha_inverse 16777215 / alpha unmultiplied [ x * alpha_inverse >> 16 for x in multiplied]else unmultiplied [0] * 3 return tuple unmultiplied + [alpha]
def test_creation_args raises ValueError lambda zeros 3 -1 raises TypeError lambda zeros 1 2 3 4 assert zeros long 3 zeros 3 assert zeros Integer 3 zeros 3 assert zeros 3.0 zeros 3 assert eye long 3 eye 3 assert eye Integer 3 eye 3 assert eye 3.0 eye 3 assert ones long 3 Integer 4 ones 3 4 raises TypeError lambda Matrix 5 raises TypeError lambda Matrix 1 2
def beip_zeros nt if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'ntmustbepositiveintegerscalar.' return specfun.klvnzo nt 6
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def _expanded_mrjob_conf_path conf_path None if conf_path is False return Noneelif conf_path is None return find_mrjob_conf else return expand_path conf_path
def get_filename_from_cd cd if not cd return '' '' fname re.findall 'filename .+ ' cd if len fname 0 return '' '' fn fname[0].rsplit '.' 1 return fn[0] '' if len fn 1 else '.' + fn[1]
def getWindowAnalyzeFileGivenText fileName gcodeText repository None if gcodeText '' return Noneif repository None repository settings.getReadRepository SkeinlayerRepository skeinWindow getWindowGivenTextRepository fileName gcodeText repository skeinWindow.updateDeiconify return skeinWindow
def validate_username_not_url username if username.startswith 'http //' or username.startswith 'https //' raise ValidationError _ 'Thisfieldrequiresanidentifier notaURL.' return username
def py__iter__types evaluator types node None return unite py__iter__ evaluator types node
def getReactorTypes return getPlugins IReactorInstaller
def test_mode question question.mode usertypes.PromptMode.yesnoassert question.mode usertypes.PromptMode.yesno
def urlquote_plus url safe u'' return force_text quote_plus force_str url force_str safe
def inside resource1 resource2 while resource1 is not None if resource1 is resource2 return Trueresource1 resource1.__parent__return False
@frappe.whitelist def get_evaluation_criterias course return frappe.get_list u'CourseEvaluationCriteria' fields [u'evaluation_criteria' u'weightage'] filters {u'parent' course} order_by u'idx'
def close *args if len args 0 figManager _pylab_helpers.Gcf.get_active if figManager is None returnelse _pylab_helpers.Gcf.destroy figManager.num elif len args 1 arg args[0]if arg u'all' _pylab_helpers.Gcf.destroy_all elif isinstance arg six.integer_types _pylab_helpers.Gcf.destroy arg elif hasattr arg u'int' _pylab_helpers.Gcf.destroy arg.int elif is_string_like arg allLabels get_figlabels if arg in allLabels num get_fignums [allLabels.index arg ]_pylab_helpers.Gcf.destroy num elif isinstance arg Figure _pylab_helpers.Gcf.destroy_fig arg else raise TypeError u'Unrecognizedargumenttype%stoclose' % type arg else raise TypeError u'closetakes0or1arguments'
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
def simple_multi_optimizer num_dims 2 def get_coordinate i return tf.get_variable 'x_{}'.format i shape [] dtype tf.float32 initializer tf.ones_initializer def build coordinates [get_coordinate i for i in xrange num_dims ]x tf.concat 0 [tf.expand_dims c 0 for c in coordinates] return tf.reduce_sum tf.square x name 'x_squared' return build
def get_traceback exc_type exc_value exc_tb sys.exc_info trace_list traceback.format_exception exc_type exc_value exc_tb body u''.join cstr t for t in trace_list return body
def _parallel_decision_function estimators estimators_features X return sum estimator.decision_function X[ features] for estimator features in zip estimators estimators_features
def diskusage path total_size 0seen set if os.path.isfile path stat_structure os.stat path ret stat_structure.st_sizereturn retfor dirpath dirnames filenames in os.walk path for f in filenames fp os.path.join dirpath f try stat_structure os.stat fp except OSError continueif stat_structure.st_ino in seen continueseen.add stat_structure.st_ino total_size + stat_structure.st_sizeret total_sizereturn ret
def get_transaction_cursor_near_timestamp namespace_id timestamp db_session dt datetime.utcfromtimestamp timestamp latest_timestamp db_session.query Transaction.created_at .order_by desc Transaction.created_at .filter Transaction.created_at < dt Transaction.namespace_id namespace_id .limit 1 .subquery latest_transaction db_session.query Transaction .filter Transaction.created_at latest_timestamp Transaction.namespace_id namespace_id .order_by desc Transaction.id .first if latest_transaction is None return '0'return latest_transaction.public_id
def unified_strdate date_str day_first True if date_str is None return Noneupload_date Nonedate_str date_str.replace u' ' u'' date_str re.sub u' ?i \\s* ? AM|PM ? \\s+[A-Z]+ ?' u'' date_str _ date_str extract_timezone date_str for expression in date_formats day_first try upload_date datetime.datetime.strptime date_str expression .strftime u'%Y%m%d' except ValueError passif upload_date is None timetuple email.utils.parsedate_tz date_str if timetuple try upload_date datetime.datetime *timetuple[ 6] .strftime u'%Y%m%d' except ValueError passif upload_date is not None return compat_str upload_date
def recursive_dict_removal inventory purge_list for key value in inventory.iteritems if isinstance value dict for child_key child_value in value.iteritems if isinstance child_value dict for item in purge_list if item in child_value del child_value[item]elif isinstance child_value list recursive_list_removal child_value purge_list elif isinstance value list recursive_list_removal value purge_list
def at_install flag def decorator obj obj.at_install flagreturn objreturn decorator
def bankcard_type card_number def matches card_number lengths prefixes if len card_number not in lengths return Falsefor prefix in prefixes if card_number.startswith prefix return Truereturn Falsefor card_type lengths prefixes in CARD_TYPES if matches card_number lengths prefixes return card_type
def export_course_to_tarfile course_key filename tmp_dir mkdtemp try course_dir export_course_to_directory course_key tmp_dir compress_directory course_dir filename finally shutil.rmtree tmp_dir ignore_errors True
@login_required@require_http_methods ['GET'] def account_settings request return render_to_response 'student_account/account_settings.html' account_settings_context request
def config return __proxy__['napalm.call'] 'get_probes_config' **{}
def _event_on_init state args kwargs instrumenting_mapper state.manager.info.get _INSTRUMENTOR if instrumenting_mapper if Mapper._new_mappers configure_mappers if instrumenting_mapper._set_polymorphic_identity instrumenting_mapper._set_polymorphic_identity state
def fullData master builders []for b in master.config.builders steps []for step in b.factory.steps steps.append getName step builders.append steps return {'builders' builders}
def sigmoidPrime x tmp sigmoid x return tmp * 1 - tmp
def _is_dev2_environment return os.environ.get 'SERVER_SOFTWARE' '' 'Development/2.0'
def unicode_safe_truncate s max_length if not isinstance s unicode s str s .decode 'utf-8' 'ignore' return s.rstrip [ max_length]
def generate_cookie cookie random.randrange 1 100000000.0 return cookie
def declarative_base bind None metadata None mapper None cls object name 'Base' constructor _declarative_constructor class_registry None metaclass DeclarativeMeta lcl_metadata metadata or MetaData if bind lcl_metadata.bind bindif class_registry is None class_registry weakref.WeakValueDictionary bases not isinstance cls tuple and cls or cls class_dict dict _decl_class_registry class_registry metadata lcl_metadata if isinstance cls type class_dict['__doc__'] cls.__doc__if constructor class_dict['__init__'] constructorif mapper class_dict['__mapper_cls__'] mapperreturn metaclass name bases class_dict
def multigaussian x mean stddev tmp -0.5 * x - mean / stddev ** 2 return np.exp tmp / np.sqrt 2.0 * np.pi * stddev
def print_versions import platform as ptfrom .. import __version__message '\nBokehversion %s\nPythonversion %s-%s\nPlatform %s\n' % __version__ pt.python_version pt.python_implementation pt.platform print message
def list_blobs call None kwargs None global storconnif not storconn storconn get_conn StorageManagementClient if kwargs is None kwargs {}if 'container' not in kwargs raise SaltCloudSystemExit 'Acontainermustbespecified' storageaccount azure.storage.CloudStorageAccount config.get_cloud_config_value 'storage_account' get_configured_provider __opts__ search_global False config.get_cloud_config_value 'storage_key' get_configured_provider __opts__ search_global False storageservice storageaccount.create_block_blob_service ret {}for blob in storageservice.list_blobs kwargs['container'] .items ret[blob.name] object_to_dict blob return ret
def _gen_candidate_chars characters chars []for chars_spec in characters chars.append to_text getattr string to_native chars_spec chars_spec errors 'strict' chars u''.join chars .replace u'"' u'' .replace u"'" u'' return chars
@loader_option def immediateload loadopt attr loader loadopt.set_relationship_strategy attr {'lazy' 'immediate'} return loader
def import_module name required True try __import__ name globals locals [] except ImportError if not required and module_not_found return Noneraisereturn sys.modules[name]
@inspect_command def memsample state **kwargs from celery.utils.debug import sample_memreturn sample_mem
@transaction.non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def get_course_survey_results request course_id course_key SlashSeparatedCourseKey.from_deprecated_string course_id try lms.djangoapps.instructor_task.api.submit_course_survey_report request course_key status_response _ 'Thesurveyreportisbeingcreated.Toviewthestatusofthereport seePendingTasksbelow.' except AlreadyRunningError status_response _ 'Thesurveyreportiscurrentlybeingcreated.Toviewthestatusofthereport seePendingTasksbelow.Youwillbeabletodownloadthereportwhenitiscomplete.' return JsonResponse {'status' status_response}
def quadratic batch_size 128 num_dims 10 stddev 0.01 dtype tf.float32 def build 'Buildslossgraph.'x tf.get_variable 'x' shape [batch_size num_dims] dtype dtype initializer tf.random_normal_initializer stddev stddev w tf.get_variable 'w' shape [batch_size num_dims num_dims] dtype dtype initializer tf.random_uniform_initializer trainable False y tf.get_variable 'y' shape [batch_size num_dims] dtype dtype initializer tf.random_uniform_initializer trainable False product tf.squeeze tf.batch_matmul w tf.expand_dims x -1 return tf.reduce_mean tf.reduce_sum product - y ** 2 1 return build
def getOutput gcodeText repository None if gcodeText '' return ''if repository is None repository GcodeTimeSegmentRepository settings.getReadRepository repository return GcodeTimeSegmentSkein .getCraftedGcode gcodeText repository
def get_long_be s return ord s[0] << 24 | ord s[1] << 16 | ord s[2] << 8 | ord s[3]
def libvlc_title_descriptions_release p_titles i_count f _Cfunctions.get 'libvlc_title_descriptions_release' None or _Cfunction 'libvlc_title_descriptions_release' 1 1 None None ctypes.POINTER TitleDescription ctypes.c_uint return f p_titles i_count
def nametofont name return Font name name exists True
def test_add_slider_to_section tempdir _TempDir from matplotlib import pyplot as pltreport Report info_fname raw_fname subject 'sample' subjects_dir subjects_dir section 'slider_section'figs list figs.append plt.figure plt.plot [1 2 3] plt.close 'all' figs.append plt.figure plt.plot [3 2 1] plt.close 'all' report.add_slider_to_section figs section section report.save op.join tempdir 'report.html' open_browser False assert_raises NotImplementedError report.add_slider_to_section [figs figs] assert_raises ValueError report.add_slider_to_section figs ['wug'] assert_raises TypeError report.add_slider_to_section figs 'wug'
def export_response request filename fields data output request.GET.get 'format' 'json' if output not in 'json' 'csv' output 'json'if output 'csv' response HttpResponse content_type 'text/csv;charset utf-8' response['Content-Disposition'] 'attachment;filename %s' % filename writer csv.DictWriter response fields writer.writeheader if six.PY2 for row in data for item in row if isinstance row[item] six.text_type row[item] row[item].encode 'utf-8' writer.writerow row else for row in data writer.writerow row return responsereturn JsonResponse data data safe False json_dumps_params {'indent' 2}
def monthrange year month if not 1 < month < 12 raise IllegalMonthError month day1 weekday year month 1 ndays mdays[month] + month February and isleap year return day1 ndays
def get_session_from_cookie cookie_val session_id itsdangerous.Signer settings.SECRET_KEY .unsign cookie_val return Session.load session_id
@disabled 'ResourceFileisnotavailableanymore' def test_ip_hosting_resource_file rf_list [IronPython.Hosting.ResourceFile 'name0' 'file0' IronPython.Hosting.ResourceFile 'name1' 'file1' False ]rf_list[0].PublicResource Falsefor i in xrange len rf_list AreEqual rf_list[i].Name 'name' + str i rf_list[i].Name 'name'AreEqual rf_list[i].Name 'name' AreEqual rf_list[i].File 'file' + str i rf_list[i].File 'file'AreEqual rf_list[i].File 'file' AreEqual rf_list[i].PublicResource False rf_list[i].PublicResource TrueAreEqual rf_list[i].PublicResource True
def de_bruijn charset n maxlen k len charset a [0] * k * n sequence []def db t p if len sequence maxlen returnif t > n if n % p 0 for j in range 1 p + 1 sequence.append charset[a[j]] if len sequence maxlen returnelse a[t] a[ t - p ]db t + 1 p for j in range a[ t - p ] + 1 k a[t] jdb t + 1 t db 1 1 return ''.join sequence
def _property_tuples entity_pb return six.iteritems entity_pb.properties
def targets tgt tgt_type 'glob' **kwargs roster_order __opts__.get 'roster_order' 'public' 'private' 'local' cached_data __runner__['cache.grains'] tgt tgt tgt_type tgt_type ret {}for server grains in cached_data.items ret[server] __opts__.get 'roster_defaults' {} .copy ret[server].update {'host' extract_ipv4 roster_order grains.get 'ipv4' [] } return ret
def is_supported value check_all False filters None iterate True assert filters is not None if not is_editable_type value return Falseelif not isinstance value filters return Falseelif iterate if isinstance value list tuple set for val in value if not is_supported val filters filters iterate check_all return Falseif not check_all breakelif isinstance value dict for key val in list value.items if not is_supported key filters filters iterate check_all or not is_supported val filters filters iterate check_all return Falseif not check_all breakreturn True
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def _regex_from_encoded_pattern s if s.startswith '/' and s.rfind '/' ! 0 idx s.rfind '/' pattern flags_str s[1 idx] s[ idx + 1 ] flag_from_char {'i' re.IGNORECASE 'l' re.LOCALE 's' re.DOTALL 'm' re.MULTILINE 'u' re.UNICODE}flags 0for char in flags_str try flags | flag_from_char[char]except KeyError raise ValueError "unsupportedregexflag '%s'in'%s' mustbeoneof'%s' " % char s ''.join list flag_from_char.keys return re.compile s[1 idx] flags else return re.compile re.escape s
def _getRandomNumber random bits if bits % 8 raise ValueError 'bits %d mustbeamultipleof8' % bits bytes random bits / 8 result Util.number.bytes_to_long bytes return result
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
@register_canonicalize@register_stabilize@gof.local_optimizer [T.Flatten] def local_flatten_lift node if isinstance node.op T.Flatten and node.inputs[0].owner and isinstance node.inputs[0].owner.op T.Elemwise and len node.inputs[0].owner.inputs 1 f node.op node.inputs[0].owner.inputs[0] copy_stack_trace node.outputs f e node.inputs[0].owner.op f copy_stack_trace node.outputs + [node.inputs[0]] e return [e]
def rec_getattr obj attr default None try return reduce getattr attr.split '.' obj except AttributeError return default
def FakeUname return 'Linux' '' '' '' ''
def getPointsFromLoops loops radius thresholdRatio 0.9 points []for loop in loops points + getPointsFromLoop loop radius thresholdRatio return points
def truncate_rev_primers fasta_f output_fp reverse_primers truncate_option 'truncate_only' primer_mismatches 2 log_data {'sample_id_not_found' 0 'reverse_primer_not_found' 0 'total_seqs' 0 'seqs_written' 0}for label seq in parse_fasta fasta_f curr_label label.split '_' [0]log_data['total_seqs'] + 1try curr_rev_primer reverse_primers[curr_label]except KeyError log_data['sample_id_not_found'] + 1output_fp.write '>%s\n%s\n' % label seq log_data['seqs_written'] + 1continuemm_tests {}for rev_primer in curr_rev_primer rev_primer_mm rev_primer_index local_align_primer_seq rev_primer seq mm_tests[rev_primer_mm] rev_primer_indexrev_primer_mm min mm_tests.keys rev_primer_index mm_tests[rev_primer_mm]if rev_primer_mm > primer_mismatches if truncate_option 'truncate_remove' log_data['reverse_primer_not_found'] + 1else log_data['reverse_primer_not_found'] + 1log_data['seqs_written'] + 1output_fp.write '>%s\n%s\n' % label seq elif rev_primer_index > 0 log_data['seqs_written'] + 1output_fp.write '>%s\n%s\n' % label seq[0 rev_primer_index] return log_data
@validatordef truthy value return value and not isinstance value six.string_types or value.strip
def help_show context data_dict function_name logic.get_or_bust data_dict 'name' _check_access 'help_show' context data_dict try function logic.get_action function_name except KeyError raise NotFound 'Actionfunctionnotfound' return function.__doc__
def _raise_connection_failure address error host port addressif port is not None msg '%s %d %s' % host port error else msg '%s %s' % host error if isinstance error socket.timeout raise NetworkTimeout msg elif isinstance error SSLError and 'timedout' in str error raise NetworkTimeout msg else raise AutoReconnect msg
def task_log_stop task_id _tasks.pop thread.get_ident None
def angle_axis matrix m np.asanyarray matrix if m.shape[ -2 ] ! 3 3 raise ValueError 'matrixisnot3x3' axis np.zeros m.shape[ -1 ] axis[... 0] m[... 2 1] - m[... 1 2] axis[... 1] m[... 0 2] - m[... 2 0] axis[... 2] m[... 1 0] - m[... 0 1] r np.sqrt axis * axis .sum -1 keepdims True angle np.arctan2 r[... 0] m[... 0 0] + m[... 1 1] + m[... 2 2] - 1.0 return Angle angle u.radian - axis / r
def ShowInteractiveWindow if edit is None CreateInteractiveWindow elif edit.NeedRecreateWindow edit.RecreateWindow else parent edit.currentView.GetParentFrame if parent win32ui.GetMainFrame edit.currentView.SetFocus else edit.currentView.GetParentFrame .AutoRestore win32ui.GetMainFrame .MDIActivate edit.currentView.GetParentFrame
def get_console_mode fd 1 mode DWORD hcon STDHANDLES[fd]GetConsoleMode hcon byref mode return mode.value
def randintw w size 1 from numpy.random import randomp np.cumsum w / np.sum w rvs p.searchsorted random np.prod size .reshape size return rvs
def brentq f a b args xtol _xtol rtol _rtol maxiter _iter full_output False disp True if not isinstance args tuple args args if xtol < 0 raise ValueError 'xtoltoosmall %g< 0 ' % xtol if rtol < _rtol raise ValueError 'rtoltoosmall %g<%g ' % rtol _rtol r _zeros._brentq f a b xtol rtol maxiter args full_output disp return results_c full_output r
def use_ansi_escape_colorbold_composites color_codes {}for color_name color_escape in colors.items color_code color_escape.replace u'\x1b[' u'' .replace u'm' u'' color_codes[color_name] color_codefor alias in aliases parts [color_codes[c] for c in aliases[alias].split ' ' ]composite_escape u'\x1b[{0}m'.format u';'.join parts escapes[alias] composite_escapearg_alias alias + '_arg' arg_seq aliases.get arg_alias aliases[alias] + ' bold' parts [color_codes[c] for c in arg_seq.split ' ' ]composite_escape u'\x1b[{0}m'.format u';'.join parts escapes[arg_alias] composite_escape
def lp2lp b a wo 1.0 a b map atleast_1d a b try wo float wo except TypeError wo float wo[0] d len a n len b M max d n pwo pow wo numpy.arange M - 1 -1 -1 start1 max n - d 0 start2 max d - n 0 b b * pwo[start1] / pwo[start2 ] a a * pwo[start1] / pwo[start1 ] return normalize b a
def wrap_loader_context function context if 'loader_context' in get_func_args function return partial function loader_context context else return function
def to_source node indent_with '' * 4 generator SourceGenerator indent_with generator.visit node return ''.join generator.result
def subset_mapping_data mdata samples_of_interest return mdata[in1d mdata[ 0] samples_of_interest ]
def wiener_index G weight None is_directed G.is_directed if is_directed and not is_strongly_connected G or not is_directed and not is_connected G return float 'inf' total sum chaini p.values for v p in spl G weight weight return total if is_directed else total / 2
def _ClearTemplateCache module_dict sys.modules template_module module_dict.get 'google.appengine.ext.webapp.template' if template_module is not None template_module.template_cache.clear
def test_error_during_readouterr testdir testdir.makepyfile pytest_xyz "\nfrom_pytest.captureimportFDCapture\ndefbad_snap self \nraiseException 'boom' \nassertFDCapture.snap\nFDCapture.snap bad_snap\n" result testdir.runpytest_subprocess '-p' 'pytest_xyz' '--version' syspathinsert True result.stderr.fnmatch_lines ['*inbad_snap' "raiseException 'boom' " 'Exception boom']
def lstrips text remove return _strips 'l' text remove
def _serialize_command command_modified return _serialize_item command_modified
def descendants pid this_pid pidallpids all_pids ppids {}def _parent pid if pid not in ppids ppids[pid] parent pid return ppids[pid]def _children ppid return [pid for pid in allpids if _parent pid ppid ]def _loop ppid return {pid _loop pid for pid in _children ppid }return _loop pid
def strip_unknown_categories x if isinstance x pd.Series pd.DataFrame x x.copy if isinstance x pd.DataFrame cat_mask x.dtypes 'category' if cat_mask.any cats cat_mask[cat_mask].indexfor c in cats if not has_known_categories x[c] x[c].cat.set_categories [] inplace True elif isinstance x pd.Series if is_categorical_dtype x.dtype and not has_known_categories x x.cat.set_categories [] inplace True if isinstance x.index pd.CategoricalIndex and not has_known_categories x.index x.index x.index.set_categories [] elif isinstance x pd.CategoricalIndex and not has_known_categories x x x.set_categories [] return x
def list_nodes_full call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodes_fullfunctionmustbecalledwith-for--function.' return get_resources_vms includeConfig True
def load_formatter_class scoped_class_name if ' ' not in scoped_class_name message 'REQUIRE "module class" butwas "%s"' % scoped_class_name raise ValueError message module_name class_name parse_scoped_name scoped_class_name formatter_module load_module module_name formatter_class getattr formatter_module class_name None if formatter_class is None raise ImportError 'CLASSNOTFOUND %s' % scoped_class_name return formatter_class
def _convert_agg_to_wx_bitmap agg bbox if bbox is None return wxc.BitmapFromBuffer int agg.width int agg.height agg.buffer_rgba else return _WX28_clipped_agg_as_bitmap agg bbox
def oauth2decorator_from_clientsecrets filename scope message None return OAuth2DecoratorFromClientSecrets filename scope message
@_np.deprecate message 'scipy.constants.K2Cisdeprecatedinscipy0.18.0.Usescipy.constants.convert_temperatureinstead.Notethatthenewfunctionhasadifferentsignature.' def K2C K return _np.asanyarray K - zero_Celsius
def clippedObj obj maxElementSize 64 if hasattr obj '_asdict' obj obj._asdict if isinstance obj dict objOut dict for key val in obj.iteritems objOut[key] clippedObj val elif hasattr obj '__iter__' objOut []for val in obj objOut.append clippedObj val else objOut str obj if len objOut > maxElementSize objOut objOut[0 maxElementSize] + '...' return objOut
def import_library_from_xml *args **kwargs manager LibraryImportManager *args **kwargs return list manager.run_imports
def MatchScorerAmbigs match mismatch matches None matches matches or {'A' {'A' None} 'G' {'G' None} 'C' {'C' None} 'T' {'T' None} '-' {'-' None}} for ambig chars in DNASequence.iupac_degeneracies .iteritems try matches[ambig].update {}.fromkeys chars except KeyError matches[ambig] {}.fromkeys chars for char in chars try matches[char].update {ambig None} except KeyError matches[char] {ambig None}def scorer x y if x not in matches or y not in matches raise ValueError 'Unknowncharacter %sor%s' % x y if y in matches[x] return matchelse return mismatchreturn scorer
def pstdev data mu None var pvariance data mu try return var.sqrt except AttributeError return math.sqrt var
def ec2_credentials_create user_id None name None tenant_id None tenant None profile None **connection_args kstone auth profile **connection_args if name user_id user_get name name profile profile **connection_args [name]['id']if not user_id return {'Error' 'CouldnotresolveUserID'}if tenant tenant_id tenant_get name tenant profile profile **connection_args [tenant]['id']if not tenant_id return {'Error' 'CouldnotresolveTenantID'}newec2 kstone.ec2.create user_id tenant_id return {'access' newec2.access 'secret' newec2.secret 'tenant_id' newec2.tenant_id 'user_id' newec2.user_id}
def start_project_transfer project user reason signer signing.TimestampSigner token signer.sign user.id project.transfer_token tokenproject.save template mail_builder.transfer_startcontext {'project' project 'receiver' user 'token' token 'reason' reason}email template user context email.send
@csrf_exemptdef checkout_cancel _request context {'payment_support_email' configuration_helpers.get_value 'payment_support_email' settings.PAYMENT_SUPPORT_EMAIL }return render_to_response 'commerce/checkout_cancel.html' context
def combinations l result []for x in range len l - 1 ls l[ x + 1 ]for y in ls result.append l[x] y return result
def to_manager sdf columns index axes [_ensure_index columns _ensure_index index ]return create_block_manager_from_arrays [sdf[c] for c in columns] columns axes
def matthews_correlation y_true y_pred y_pred_pos K.round K.clip y_pred 0 1 y_pred_neg 1 - y_pred_pos y_pos K.round K.clip y_true 0 1 y_neg 1 - y_pos tp K.sum y_pos * y_pred_pos tn K.sum y_neg * y_pred_neg fp K.sum y_neg * y_pred_pos fn K.sum y_pos * y_pred_neg numerator tp * tn - fp * fn denominator K.sqrt tp + fp * tp + fn * tn + fp * tn + fn return numerator / denominator + K.epsilon
def one_one_in_books book_id_val_map db field *args if book_id_val_map sequence sqlite_datetime v k for k v in book_id_val_map.iteritems db.executemany u'UPDATEbooksSET%s ?WHEREid ?' % field.metadata[u'column'] sequence field.table.book_col_map.update book_id_val_map return set book_id_val_map
def many_to_one input_dict return dict key val for keys val in input_dict.items for key in keys
def _skew a try res stats.skew a except ValueError res np.nanreturn res
def is_future stmt if not isinstance stmt ast.From return 0if stmt.modname '__future__' return 1else return 0
def auth_add user auth ret {}auths auth.split ' ' known_auths auth_list .keys valid_auths [r for r in auths if r in known_auths ]log.debug 'rbac.auth_add-auths {0} known_auths {1} valid_auths {2}'.format auths known_auths valid_auths if len valid_auths > 0 res __salt__['cmd.run_all'] 'usermod-A"{auths}"{login}'.format login user auths ' '.join set auth_get user False + valid_auths if res['retcode'] > 0 ret['Error'] {'retcode' res['retcode'] 'message' res['stderr'] if 'stderr' in res else res['stdout'] }return retactive_auths auth_get user False for a in auths if a not in valid_auths ret[a] 'Unknown'elif a in active_auths ret[a] 'Added'else ret[a] 'Failed'return ret
def localize_input value default None if isinstance value decimal.Decimal float int long return number_format value elif isinstance value datetime.datetime value datetime_safe.new_datetime value format smart_str default or get_format 'DATETIME_INPUT_FORMATS' [0] return value.strftime format elif isinstance value datetime.date value datetime_safe.new_date value format smart_str default or get_format 'DATE_INPUT_FORMATS' [0] return value.strftime format elif isinstance value datetime.time format smart_str default or get_format 'TIME_INPUT_FORMATS' [0] return value.strftime format return value
def initialize_modgraph excludes user_hook_dirs None logger.info 'Initializingmoduledependencygraph...' debug os.environ.get 'MODULEGRAPH_DEBUG' 0 try debug int debug except ValueError debug 0graph PyiModuleGraph HOMEPATH excludes excludes implies get_implies debug debug user_hook_dirs user_hook_dirs if not is_py2 logger.info 'Analyzingbase_library.zip...' required_mods []for m in PY3_BASE_MODULES if is_package m required_mods + collect_submodules m else required_mods.append m for m in required_mods graph.import_hook m return graph
def make_YAxis yaxis_title yaxis graph_objs.YAxis title yaxis_title showticklabels True autorange True ticklen 4 showline True zeroline False showgrid False mirror False return yaxis
def test_scenarios_with_special_characters feature Feature.from_string FEATURE19 assert that feature.scenarios[0].tags .deep_equals ['runme1'] assert that feature.scenarios[1].tags .deep_equals ['runme2']
def to_signum signum if isinstance signum int return signumm re.match ' \\w+ \\+ \\d+ ?' signum if m name m.group 1 .upper if not name.startswith 'SIG' name 'SIG' + name offset int m.group 3 if m.group 3 else 0 try return getattr signal name + offset except KeyError passraise ValueError 'signalinvalid {}'.format signum
def get_last_change name ret _get_account_policy_data_value name 'passwordLastSetTime' unix_timestamp salt.utils.mac_utils.parse_return ret date_text _convert_to_datetime unix_timestamp return date_text
def inf_range start 0 step 1 while True yield start start + step
def inventory out __salt__['cmd.run_all'] 'xfsrestore-I' _verify_run out return _xfs_inventory_output out['stdout']
def cull dsk keys if not isinstance keys list set keys [keys]out_keys []seen set dependencies dict work list set flatten keys while work new_work []out_keys + workdeps [ k get_dependencies dsk k as_list True for k in work]dependencies.update deps for _ deplist in deps for d in deplist if d not in seen seen.add d new_work.append d work new_workout {k dsk[k] for k in out_keys}return out dependencies
def working_function return True
def input_select_objects prompt objs rep choice input_options u'y' u'n' u's' False u'%s? Yes/no/select ' % prompt print if choice u'y' return objselif choice u's' out []for obj in objs rep obj if input_yn u'%s? yes/no ' % prompt True out.append obj print return outelse return []
def CreateParser query input_string antlr3.ANTLRStringStream query lexer QueryLexerWithErrors input_string tokens antlr3.CommonTokenStream lexer parser QueryParserWithErrors tokens return parser
def parse_address address allow_ranges False port Nonefor matching in ['bracketed_hostport' 'hostport'] m patterns[matching].match address if m address port m.groups port int port continuehost Nonefor matching in ['ipv4' 'ipv6' 'hostname'] m patterns[matching].match address if m host addresscontinueif not host raise AnsibleError 'Notavalidnetworkhostname %s' % address if not allow_ranges and '[' in host raise AnsibleParserError 'Detectedrangeinhostbutwasaskedtoignoreranges' return host port
def git_version process subprocess.Popen [u'git' u'--version'] stdout subprocess.PIPE stdout stderr process.communicate assert process.returncode 0 u'Failedtodeterminegitversion.'matches re.search u'\\s \\d+ ? \\.\\d+ * [\\s\\.]' stdout return Revision.lenient matches.group 1
def get_flowgram_distances id flowgram flowgrams fc ids outdir error_profile DENOISER_DATA_DIR + 'FLX_error_profile.dat' check_flowgram_ali_exe fh tmpfile init_flowgram_file prefix outdir append_to_flowgram_file id flowgram fh k 0names []for f in flowgrams if f.Name in ids fc.add f append_to_flowgram_file f.Name f fh trim False k + 1names.append f.Name fh.close scores_fh popen '%s-relscore_pairid%s%s' % get_flowgram_ali_exe error_profile tmpfile 'r' scores [map float s.split for s in scores_fh if s ! '\n' ]if k ! len scores raise RuntimeError 'Somethingbadhashappened!Ireceivedless' + 'alignmentscoresthanthereareflowgrams.Mostlikelythis' + 'meansthatthealignmentprogramisnotsetuporcorrupted.' + 'Pleaserunthetestscriptstofigureoutthecauseoftheerror.' remove tmpfile return scores names fc
def create_batch_tables cluster session logging.info 'Tryingtocreatebatches' create_table '\nCREATETABLEIFNOTEXISTSbatches \napptext \ntransactionint \nnamespacetext \npathblob \nold_valueblob \nnew_valueblob \nexclude_indicestext \nPRIMARYKEY app transaction namespace path \n \n'statement SimpleStatement create_table retry_policy NO_RETRIES try session.execute statement except cassandra.OperationTimedOut logging.warning 'Encounteredanoperationtimeoutwhilecreatingbatchestable.Waiting1minuteforschematosettle.' time.sleep 60 raiselogging.info 'Tryingtocreatebatch_status' create_table '\nCREATETABLEIFNOTEXISTSbatch_status \napptext \ntransactionint \nappliedboolean \nPRIMARYKEY app transaction \n \n'statement SimpleStatement create_table retry_policy NO_RETRIES try session.execute statement except cassandra.OperationTimedOut logging.warning 'Encounteredanoperationtimeoutwhilecreatingbatch_statustable.Waiting1minuteforschematosettle.' time.sleep 60 raise
def aggregate_flow_tests registry xml_parent data agg_flow XML.SubElement xml_parent 'org.zeroturnaround.jenkins.flowbuildtestaggregator.FlowTestAggregator' XML.SubElement agg_flow 'showTestResultTrend' .text str data.get 'show-test-results-trend' True .lower
def random_distribution size vocabulary_size b np.random.uniform 0.0 1.0 size [1 size] return b / np.sum b 1 [ None]
def get_language_from_path path supported None strict False if supported is None from django.conf import settingssupported SortedDict settings.LANGUAGES regex_match language_code_prefix_re.match path if not regex_match return Nonelang_code regex_match.group 1 try return get_supported_language_variant lang_code supported strict strict except LookupError return None
def multi_source_dijkstra_path_length G sources cutoff None weight 'weight' if not sources raise ValueError 'sourcesmustnotbeempty' weight _weight_function G weight dist _dijkstra_multisource G sources weight cutoff cutoff return iter dist.items
def padone x front 0 back 0 axis 0 fillvalue 0 shape np.array x.shape shape[axis] + front + back shapearr np.array x.shape out np.empty shape out.fill fillvalue startind np.zeros x.ndim startind[axis] frontendind startind + shapearr myslice [slice startind[k] endind[k] for k in range len endind ]out[tuple myslice ] xreturn out
def CDLCLOSINGMARUBOZU barDs count return call_talib_with_ohlc barDs count talib.CDLCLOSINGMARUBOZU
def p_funcdef p p[0] ast.Function None p[2] tuple p[3] 0 None p[5]
@receiver user_pre_delete def user_commit_pending sender instance **kwargs all_changes Change.objects.last_changes instance .filter user instance user_translation_ids all_changes.values_list 'translation' flat True .distinct for translation in Translation.objects.filter pk__in user_translation_ids try last_author translation.change_set.content [0].authorexcept IndexError continueif last_author instance translation.commit_pending None
def execusercustomize try import usercustomizeexcept ImportError passexcept Exception if sys.flags.verbose sys.excepthook *sys.exc_info else print >>sys.stderr "'importusercustomize'failed;use-vfortraceback"
def egg_info_matches egg_info search_name link _egg_info_re re.compile ' [a-z0-9_.]+ - [a-z0-9_.!+-]+ ' re.I match _egg_info_re.search egg_info if not match logger.debug 'Couldnotparseversionfromlink %s' link return Noneif search_name is None full_match match.group 0 return full_match[full_match.index '-' ]name match.group 0 .lower name name.replace '_' '-' look_for search_name.lower + '-' if name.startswith look_for return match.group 0 [len look_for ]else return None
def add_representer data_type representer Dumper Dumper Dumper.add_representer data_type representer
def pretty_tree_from_tree tree indent_width 2 INDENT '' * indent_width def _prettify elem indent_level 0 if elem elem.text '\n' + INDENT * indent_level + 1 for child in elem _prettify child indent_level + 1 elem[ -1 ].tail '\n' + INDENT * indent_level elem.tail '\n' + INDENT * indent_level else elem.text Noneelem.tail '\n' + INDENT * indent_level _prettify tree return tree
def _process_return_data retData if retData.status_code 200 if retData.json return retDataelse log.debug 'nodatareturnedfrominfoblox' return Noneelse msg 'Unsuccessfulerrorcode{0}returned'.format retData.status_code raise CommandExecutionError msg return None
def get_clips url _url html _html url clips html.find 'div' {'id' 'newvideos_results'} .findAll 'tr' {'class' None} return [_get_clip clip for clip in clips]
def set_is_polling polling host None core_name None ret _get_return_dict if _is_master and _get_none_or_value host is None err ['solr.set_is_pollingcanonlybecalledby"slave"minions']return ret.update {'success' False 'errors' err} cmd 'enablepoll' if polling else 'disapblepoll' if _get_none_or_value core_name is None and _check_for_cores success Truefor name in __opts__['solr.cores'] resp set_is_polling cmd host host core_name name if not resp['success'] success Falsedata {name {'data' resp['data']}}ret _update_return_dict ret success data resp['errors'] resp['warnings'] return retelse resp _replication_request cmd host host core_name core_name return resp
def getSaveFile parent title dir_description key ext fname None config_key dir_description + 'Directory' base aqt.mw.pm.profile.get config_key aqt.mw.pm.base path os.path.join base fname file QFileDialog.getSaveFileName parent title path '{0} *{1} '.format key ext options QFileDialog.DontConfirmOverwrite [0]if file if not file.lower .endswith ext file + extdir os.path.dirname file aqt.mw.pm.profile[config_key] dirif os.path.exists file if not askUser _ 'Thisfileexists.Areyousureyouwanttooverwriteit?' parent return Nonereturn file
def has_change_db_cmd query try first_token query.split [0]if first_token.lower in u'use' u'\\c' u'\\connect' return Trueexcept Exception return Falsereturn False
def get_cluster_init_process_names runner nodes return gather_deferreds list get_node_init_process_name runner node for node in nodes
def certificate_get_all_by_project context project_id return IMPL.certificate_get_all_by_project context project_id
def try_serialize_handler handler if isinstance handler types.InstanceType or isinstance handler object and not inspect.isfunction handler and not inspect.ismethod handler and hasattr handler '__call__' return pickle.dumps handler return None
def _is_used_in_graph var return not var.clients [ 'output' 1 ] or var.clients []
def get_zk_locations_string zk_location_ips return ' ' + str zk.DEFAULT_PORT + ' ' .join zk_location_ips + ' ' + str zk.DEFAULT_PORT
def block_device_mapping_destroy_by_instance_and_device context instance_uuid device_name return IMPL.block_device_mapping_destroy_by_instance_and_device context instance_uuid device_name
def acl_changed module cmd if get_platform .lower 'freebsd' return Truecmd cmd[ ]cmd.insert 1 '--test' lines run_acl module cmd for line in lines if not line.endswith '* *' return Truereturn False
def register_swift_info name 'swift' admin False **kwargs if name 'admin' or name 'disallowed_sections' raise ValueError "'{0}'isreservedname.".format name if admin dict_to_use _swift_admin_infoelse dict_to_use _swift_infoif name not in dict_to_use if '.' in name raise ValueError 'Cannotuse"."inaswift_infokey %s' % name dict_to_use[name] {}for key val in kwargs.items if '.' in key raise ValueError 'Cannotuse"."inaswift_infokey %s' % key dict_to_use[name][key] val
def extra_context_request_processor page request request._feincms_extra_context.update {u'in_appcontent_subpage' False u'extra_path' u'/'} url page.get_absolute_url if request.path ! url request._feincms_extra_context.update {u'in_appcontent_subpage' True u'extra_path' re.sub u'^' + re.escape url.rstrip u'/' u'' request.path }
def install_editor template wait False def call_editor self filename line 0 if line is None line 0cmd template.format filename pipes.quote filename line line print '>' cmd if sys.platform.startswith 'win' cmd shlex.split cmd proc subprocess.Popen cmd shell True if wait and proc.wait ! 0 raise TryNext if wait py3compat.input 'PressEnterwhendoneediting ' get_ipython .set_hook 'editor' call_editor get_ipython .editor template
def _image_property_delete_all context image_id delete_time None session None props_updated_count _image_child_entry_delete_all models.ImageProperty image_id delete_time session return props_updated_count
def sort_unique alist alist.sort out list for i in alist if i not in out out.append i return out
def _read_julian fid tag shape rlims return jd2jcal int np.fromstring fid.read 4 dtype '>i4'
def _zero_fill_array context builder ary cgutils.memset builder ary.data builder.mul ary.itemsize ary.nitems 0
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _hashtable_algo f values return_dtype None dtype values.dtypeif is_float_dtype dtype return f htable.Float64HashTable _ensure_float64 elif is_signed_integer_dtype dtype return f htable.Int64HashTable _ensure_int64 elif is_unsigned_integer_dtype dtype return f htable.UInt64HashTable _ensure_uint64 elif is_datetime64_dtype dtype return_dtype return_dtype or 'M8[ns]' return f htable.Int64HashTable _ensure_int64 .view return_dtype elif is_timedelta64_dtype dtype return_dtype return_dtype or 'm8[ns]' return f htable.Int64HashTable _ensure_int64 .view return_dtype if lib.infer_dtype values in ['string'] return f htable.StringHashTable _ensure_object return f htable.PyObjectHashTable _ensure_object
def is_release return VERSION[6]
def web_daemon path '.' address None port None from dulwich.web import make_wsgi_chain make_server WSGIRequestHandlerLogger WSGIServerLoggerbackend FileSystemBackend path app make_wsgi_chain backend server make_server address port app handler_class WSGIRequestHandlerLogger server_class WSGIServerLogger server.serve_forever
def is_closed hass entity_id None entity_id entity_id or ENTITY_ID_ALL_COVERS return hass.states.is_state entity_id STATE_CLOSED
def binhex inp out finfo getfileinfo inp ofp BinHex finfo out ifp io.open inp 'rb' while True d ifp.read 128000 if not d breakofp.write d ofp.close_data ifp.close ifp openrsrc inp 'rb' while True d ifp.read 128000 if not d breakofp.write_rsrc d ofp.close ifp.close
def test_sample_wrong_X sm SMOTEENN random_state RND_SEED sm.fit X Y assert_raises RuntimeError sm.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def _IsPresent item if item[0].label _FieldDescriptor.LABEL_REPEATED return bool item[1] elif item[0].cpp_type _FieldDescriptor.CPPTYPE_MESSAGE return item[1]._is_present_in_parentelse return True
def get_job_ids **filter_data query models.TestView.query_objects filter_data job_ids set for test_view in query.values 'job_tag' .distinct first_tag_component test_view['job_tag'].split '-' [0]try job_id int first_tag_component job_ids.add job_id except ValueError passreturn list job_ids
def isPackageDirectory dirname for ext in zip *imp.get_suffixes [0] initFile '__init__' + ext if os.path.exists os.path.join dirname initFile return initFilereturn False
def filter_build_dirs address_mapper build_files dirnames set dirname f.stat.path for f in build_files.dependencies ignored_dirnames address_mapper.build_ignore_patterns.match_files u'{}/'.format dirname for dirname in dirnames ignored_dirnames set d.rstrip u'/' for d in ignored_dirnames return BuildDirs tuple Dir d for d in dirnames if d not in ignored_dirnames
def cov_hc3 results h np.diag np.dot results.model.exog np.dot results.normalized_cov_params results.model.exog.T het_scale results.resid / 1 - h ** 2 cov_hc3_ _HCCM results het_scale return cov_hc3_
def _check_group_features info parsed call_refs {}additional_groups []for call reverse fuzzy in info.group_calls key call.group reverse fuzzy ref call_refs.get key if ref is None if call.group 0 rev bool info.flags & REVERSE fuz isinstance parsed Fuzzy if rev fuz ! reverse fuzzy additional_groups.append CallRef len call_refs parsed reverse fuzzy else def_info info.defined_groups[call.group]group def_info[0]if def_info[1 ] ! reverse fuzzy additional_groups.append group reverse fuzzy ref len call_refs call_refs[key] refcall.call_ref refinfo.call_refs call_refsinfo.additional_groups additional_groups
def submit_calculate_problem_responses_csv request course_key problem_location task_type 'problem_responses_csv'task_class calculate_problem_responses_csvtask_input {'problem_location' problem_location}task_key ''return submit_task request task_type task_class course_key task_input task_key
def CDLONNECK barDs count return call_talib_with_ohlc barDs count talib.CDLONNECK
def build_request uri '/' path _ querystring uri.partition '?' return WSGIRequest {'CONTENT_TYPE' 'text/html;charset utf-8' 'PATH_INFO' path 'QUERY_STRING' querystring 'REMOTE_ADDR' '127.0.0.1' 'REQUEST_METHOD' 'GET' 'SCRIPT_NAME' '' 'SERVER_NAME' 'testserver' 'SERVER_PORT' '80' 'SERVER_PROTOCOL' 'HTTP/1.1' 'wsgi.version' 1 0 'wsgi.url_scheme' 'http' 'wsgi.input' FakePayload '' 'wsgi.errors' six.StringIO 'wsgi.multiprocess' True 'wsgi.multithread' False 'wsgi.run_once' False}
def parse_day_period_rules tree day_periods {}for ruleset in tree.findall './/dayPeriodRuleSet' ruleset_type ruleset.attrib.get 'type' for rules in ruleset.findall 'dayPeriodRules' locales rules.attrib['locales'].split for rule in rules.findall 'dayPeriodRule' type rule.attrib['type']if type in 'am' 'pm' continuerule _compact_dict dict key _time_to_seconds_past_midnight rule.attrib.get key for key in 'after' 'at' 'before' 'from' 'to' for locale in locales dest_list day_periods.setdefault locale {} .setdefault ruleset_type {} .setdefault type [] dest_list.append rule return day_periods
def unique_slug queryset slug_field slug i 0while True if i > 0 if i > 1 slug slug.rsplit u'-' 1 [0]slug u'%s-%s' % slug i try queryset.get **{slug_field slug} except ObjectDoesNotExist breaki + 1return slug
def shortest_path digr s nodes_explored set [s] nodes_unexplored DFS digr s nodes_unexplored.remove s dist {s 0}node_heap []for n in nodes_unexplored min compute_min_dist digr n nodes_explored dist heapq.heappush node_heap min n while len node_heap > 0 min_dist nearest_node heapq.heappop node_heap dist[nearest_node] min_distnodes_explored.add nearest_node nodes_unexplored.remove nearest_node for v in digr.neighbors nearest_node if v in nodes_unexplored for i in range len node_heap if node_heap[i][1] v node_heap[i] compute_min_dist digr v nodes_explored dist v heapq.heapify node_heap return dist
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
@command 'dlurl\\s .*[-_a-zA-Z0-9]{11}.* ' def dl_url url g.browse_mode 'normal'yt_url url if len g.model 1 download 'download' '1' if g.command_line sys.exit
def changes_from_tree names lookup_entry object_store tree want_unchanged False other_names set names if tree is not None for name mode sha in object_store.iter_tree_contents tree try other_sha other_mode lookup_entry name except KeyError yield name None mode None sha None else other_names.remove name if want_unchanged or other_sha ! sha or other_mode ! mode yield name name mode other_mode sha other_sha for name in other_names try other_sha other_mode lookup_entry name except KeyError passelse yield None name None other_mode None other_sha
@support_nddatadef block_reduce data block_size func np.sum from skimage.measure import block_reducedata np.asanyarray data block_size np.atleast_1d block_size if data.ndim > 1 and len block_size 1 block_size np.repeat block_size data.ndim if len block_size ! data.ndim raise ValueError u'`block_size`mustbeascalarorhavethesamelengthas`data.shape`' block_size np.array [int i for i in block_size] size_resampled np.array data.shape // block_size size_init size_resampled * block_size for i in range data.ndim if data.shape[i] ! size_init[i] data data.swapaxes 0 i data data[ size_init[i]]data data.swapaxes 0 i return block_reduce data tuple block_size func func
def document_nav_links obj return combine_funcs obj parent_document_link topic_parent_document_link topic_sibling_documents_link topic_children_documents_link
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def cuirfft inp norm None is_odd False if is_odd not in True False raise ValueError 'Invalidvalue%sforid_odd mustbeTrueorFalse' % is_odd s inp.shape[1 -1 ]if is_odd s T.set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 + 1 else s T.set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 cond_norm _unitary norm scaling 1if cond_norm is None scaling s.prod .astype 'float32' elif cond_norm 'ortho' scaling T.sqrt s.prod .astype 'float32' return cuirfft_op inp s / scaling
def strip_stopwords sentence words sentence.split sentence []for word in words if word.lower not in stopwords sentence.append word return ''.join sentence
def add_enabled_equivalencies equivalencies context _UnitContext get_current_unit_registry get_current_unit_registry .add_enabled_equivalencies equivalencies return context
def test_pl_dash o nikola.utils.slugify u'za\u017c\xf3\u0142\u0107-g\u0119\u015bl\u0105-ja\u017a\u0144' lang u'pl' assert o u'zazolc-gesla-jazn'
def save_load jid load minions None serv _get_serv ret None serv.set jid json.dumps load _append_list serv 'jids' jid
def get_exploration_components_from_zip zip_file_contents memfile StringIO.StringIO memfile.write zip_file_contents zf zipfile.ZipFile memfile 'r' yaml_content Noneassets_list []for filepath in zf.namelist if filepath.startswith 'assets/' assets_list.append '/'.join filepath.split '/' [1 ] zf.read filepath elif yaml_content is not None raise Exception 'Morethanonenon-assetfilespecifiedforzipfile' elif not filepath.endswith '.yaml' raise Exception 'Foundinvalidnon-assetfile%s.Thereshouldonlybeasinglefilenotinassets/ anditshouldhavea.yamlsuffix.' % filepath else yaml_content zf.read filepath if yaml_content is None raise Exception 'Noyamlfilespecifiedinzipfilecontents' return yaml_content assets_list
def test_index_page c make_logged_in_client c.get '/beeswax'
def _strip_key key_string key_string.strip key_string.replace '\n' '' key_string.replace '\r\n' '' return key_string
def tanhm A A _asarray_square A return _maybe_real A solve coshm A sinhm A
def b1_mapping char return u'' if stringprep.in_table_b1 char else None
def hprModelAnal x fs w N H t minSineDur nH minf0 maxf0 f0et harmDevSlope hfreq hmag hphase HM.harmonicModelAnal x fs w N H t nH minf0 maxf0 f0et harmDevSlope minSineDur Ns 512xr UF.sineSubtraction x Ns H hfreq hmag hphase fs return hfreq hmag hphase xr
def _GetHWInfos client_list batch_size 10000 token None hw_infos {}logging.info '%dclientstoprocess.' len client_list c 0for batch in utils.Grouper client_list batch_size logging.info 'Processingbatch %d-%d' c c + batch_size c + len batch client_objs aff4.FACTORY.MultiOpen batch age aff4.ALL_TIMES token token for client in client_objs hwi client.GetValuesForAttribute client.Schema.HARDWARE_INFO hw_infos[client.urn] set [ '%s' % x.serial_number for x in hwi] return hw_infos
def token_lists_match l r if len l ! len r print "lengthsdon'tmatch" print len l print len r return Falsefor l_elem r_elem in zip l r assert isinstance l_elem str float int type l_elem assert isinstance r_elem str float int type r_elem if l_elem ! r_elem print '"' + l_elem + '"doesn\'tmatch"' + r_elem + '"' return Falsereturn True
@login_required@mobile_template 'users/{mobile/}pw_change_complete.html' def password_change_complete request template return render request template
def rst_xline width char ' ' return char * width
def rad_fn x pos None n int x / np.pi * 2.0 + 0.25 if n 0 return str x elif n 1 return u'$\\pi/2$'elif n 2 return u'$\\pi$'elif n % 2 0 return u'$%s\\pi$' % n / 2 else return u'$%s\\pi/2$' % n
def update_user_bio user_id user_bio user_settings get_user_settings user_id strict True user_settings.user_bio user_bio_save_user_settings user_settings
def _run_command cmd logging.info ''.join cmd pipe subprocess.PIPEproc subprocess.Popen cmd stdin pipe stdout pipe stderr pipe close_fds True out err proc.communicate if proc.returncode is not os.EX_OK raise XenstoreError cmd proc.returncode err out return proc.returncode out
def getLittleEndianUnsignedLongGivenFile file return unpack '<L' file.read 4 [0]
def groups_for_user environ username UserModel auth.get_user_model db.reset_queries try try user UserModel._default_manager.get_by_natural_key username except UserModel.DoesNotExist return []if not user.is_active return []return [force_bytes group.name for group in user.groups.all ]finally db.close_connection
def cloudformation registry xml_parent data region_dict helpers.cloudformation_region_dict stacks helpers.cloudformation_init xml_parent data 'CloudFormationPostBuildNotifier' for stack in data.get 'create-stacks' [] helpers.cloudformation_stack xml_parent stack 'PostBuildStackBean' stacks region_dict delete_stacks helpers.cloudformation_init xml_parent data 'CloudFormationNotifier' for delete_stack in data.get 'delete-stacks' [] helpers.cloudformation_stack xml_parent delete_stack 'SimpleStackBean' delete_stacks region_dict
def _linear_banded_jac t y a ml mu _band_count a bjac []for k in range mu 0 -1 bjac.append np.r_[ [0] * k np.diag a k ] bjac.append np.diag a for k in range -1 - ml - 1 -1 bjac.append np.r_[ np.diag a k [0] * - k ] return bjac
def collatz start start int start begin time.time steps []while start ! 1 steps.append start if start > 1 if start % 2 0 start start / 2 else start start * 3 + 1 return steps time.time - begin
def _responds result_type data None msg '' return {'result' result_type_map[result_type] 'message' msg 'data' {} if not data else data }
def get_store_from_scheme context scheme loc None if scheme not in location.SCHEME_TO_CLS_MAP raise exception.UnknownScheme scheme scheme scheme_info location.SCHEME_TO_CLS_MAP[scheme]store scheme_info['store_class'] context loc return store
def get_table_names_from_sql context sql def _get_table_names_from_plan plan table_names []if plan.get 'RelationName' table_names.append plan['RelationName'] if 'Plans' in plan for child_plan in plan['Plans'] table_name _get_table_names_from_plan child_plan if table_name table_names.extend table_name return table_namesresult context['connection'].execute 'EXPLAIN FORMATJSON {0}'.format sql.encode 'utf-8' .fetchone table_names []try query_plan json.loads result['QUERYPLAN'] plan query_plan[0]['Plan']table_names.extend _get_table_names_from_plan plan except ValueError log.error 'Couldnotparsequeryplan' return table_names
@retry 2 delay 0.5 backoff 1.1 def safe_deepcopy instance return copy.deepcopy instance
def login_required func @wraps func def decorated_view *args **kwargs if not users.get_current_user return redirect users.create_login_url request.url return func *args **kwargs return decorated_view
def _get_storage_api retry_params account_id None api _StorageApi _StorageApi.full_control_scope service_account_id account_id retry_params retry_params if common.local_run and not common.get_access_token api.api_url common.local_api_url if common.get_access_token api.token common.get_access_token return api
def job_from_request from digits.webapp import schedulerjob_id get_request_arg 'job_id' if job_id is None raise werkzeug.exceptions.BadRequest 'job_idisarequiredfield' job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' else return job
def object_build_class node member localname basenames [base.__name__ for base in member.__bases__]return _base_class_object_build node member basenames localname localname
def flatten_iterator x for elem in x if not isinstance elem str and hasattr elem '__iter__' for y in flatten_iterator elem yield y else yield elem
def callbackmethod callback return callback
def update_status msg **redis_kwargs pid getpid red StrictRedis **redis_kwargs key 'pid-%d-statuses' % pid msg '%.6f%s' % time msg red.lpush key msg red.expire key 60 * 60 red.ltrim key 0 _keep
def getSelectedPluginModuleFromPath filePath plugins for plugin in plugins if plugin.value return gcodec.getModuleFromPath plugin.name filePath return None
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _uniquely_named_symbol xname *exprs prefix '%s'x prefix % xname syms set .union *[e.free_symbols for e in exprs] while any x str s for s in syms prefix '_' + prefix x prefix % xname return _symbol x
def residue_reduce_derivation H DE z i Dummy 'i' return S sum RootSum a[0].as_poly z Lambda i i * derivation a[1] DE .as_expr .subs z i / a[1].as_expr .subs z i for a in H
def transfer var target if target 'cpu' return as_tensor_variable var else for trans in transfer._others res trans var target if res is not None return resraise ValueError "Can'ttransfertotarget%s" % target
def set_default_zone zone return __firewall_cmd '--set-default-zone {0}'.format zone
def resolve_model model_path module_path model_name model_path.rsplit '.' 1 module importlib.import_module module_path model getattr module model_name return model
def _FindServerInMapping mapping hashed server_list list mapping.servers val _BisectHashList server_list 0 len server_list - 1 hashed .indexreturn val
def p_struct_declarator_list_2 t pass
def all_filters return HostFilterHandler .get_all_classes
def test_install_quiet script data to_install data.packages.join 'FSPkg' result script.pip 'install' '-q' to_install expect_error False assert result.stdout '' assert result.stderr ''
def disable states ret {'res' True 'msg' ''}if isinstance states six.string_types states states.split ' ' msg []_disabled __salt__['grains.get'] 'state_runs_disabled' if not isinstance _disabled list _disabled []_changed Falsefor _state in states if _state in _disabled msg.append 'Info {0}statealreadydisabled.'.format _state else msg.append 'Info {0}statedisabled.'.format _state _disabled.append _state _changed Trueif _changed __salt__['grains.setval'] 'state_runs_disabled' _disabled ret['msg'] '\n'.join msg __salt__['saltutil.refresh_modules'] return ret
def getone regex_string limit 20 return _randone parse regex_string limit
def stopListening global _listenerlogging._acquireLock try if _listener _listener.abort 1_listener Nonefinally logging._releaseLock
def rename name kwargs call None if call ! 'action' raise SaltCloudSystemExit 'Therenameactionmustbecalledwith-aor--action.' log.info 'Renaming{0}to{1}'.format name kwargs['newname'] set_tags name {'Name' kwargs['newname']} call 'action' salt.utils.cloud.rename_key __opts__['pki_dir'] name kwargs['newname']
def internalerror context.status '500InternalServerError'context.headers [ 'Content-Type' 'text/html' ]context.output 'internalservererror'
def touch_empty_backreferences app what name obj options lines examples_path os.path.join app.srcdir app.config.sphinx_gallery_conf['mod_example_dir'] '%s.examples' % name if not os.path.exists examples_path open examples_path 'w' .close
def parse_bootloader rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--append' dest 'append' action 'store' parser.add_argument '--driveorder' dest 'driveorder' action 'store' parser.add_argument '--location' dest 'location' action 'store' parser.add_argument '--password' dest 'password' action 'store' parser.add_argument '--md5pass' dest 'md5pass' action 'store' parser.add_argument '--upgrade' dest 'upgrade' action 'store_true' parser.add_argument '--timeout' dest 'timeout' action 'store' parser.add_argument '--boot-drive' dest 'bootdrive' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
@validatordef truthy value return value and not isinstance value six.string_types or value.strip
def get url conn urlopen url resp conn.read conn.close return resp
def betweenness_centrality_subset G sources targets normalized False weight None b dict.fromkeys G 0.0 for s in sources if weight is None S P sigma shortest_path G s else S P sigma dijkstra G s weight b _accumulate_subset b S P sigma s targets b _rescale b len G normalized normalized directed G.is_directed return b
def to_cnf first second if isinstance first AndExpression r_first to_cnf first.first second r_second to_cnf first.second second return r_first & r_second elif isinstance second AndExpression r_first to_cnf first second.first r_second to_cnf first second.second return r_first & r_second else return first | second
def all_filters return HostFilterHandler .get_all_classes
def logstash registry xml_parent data logstash XML.SubElement xml_parent 'jenkins.plugins.logstash.LogstashNotifier' logstash.set 'plugin' 'logstash' mapping [ 'max-lines' 'maxLines' 1000 'fail-build' 'failBuild' False ]helpers.convert_mapping_to_xml logstash data mapping fail_required True
def jarque_bera x x np.asarray x n float x.size if n 0 raise ValueError 'Atleastoneobservationisrequired.' mu x.mean diffx x - mu skewness 1 / n * np.sum diffx ** 3 / 1 / n * np.sum diffx ** 2 ** 3 / 2.0 kurtosis 1 / n * np.sum diffx ** 4 / 1 / n * np.sum diffx ** 2 ** 2 jb_value n / 6 * skewness ** 2 + kurtosis - 3 ** 2 / 4 p 1 - distributions.chi2.cdf jb_value 2 return jb_value p
def generate_bounding_box bottom_left top_right west lat_1 bottom_left.get_coords east lat_2 top_right.get_coords min_lat max_lat min lat_1 lat_2 max lat_1 lat_2 return min_lat west max_lat east
def R p q if p in consonants or q in consonants return R_creturn R_v
def _is_proxy_running proxyname cmd 'psax|grep"salt-proxy--proxyid {0}"|grep-vgrep'.format salt.ext.six.moves.shlex_quote proxyname cmdout __salt__['cmd.run_all'] cmd timeout 5 python_shell True if not cmdout['stdout'] return Falseelse return True
def aes_cipher_from_key key return AES.new key AES.MODE_CBC generate_aes_iv key
def findHandler self while self if self.name in 'media' 'tags' breakself self.parentelse return Nonefor atom in self if atom['tag'].value 'hdlr' return atom['hdlr']return None
def qapplication translate True test_time 3 if running_in_mac_app SpyderApplication MacApplicationelse SpyderApplication QApplicationapp SpyderApplication.instance if app is None app SpyderApplication ['Spyder'] app.setApplicationName 'Spyder' if translate install_translator app test_ci os.environ.get 'TEST_CI_WIDGETS' None if test_ci is not None timer_shutdown QTimer app timer_shutdown.timeout.connect app.quit timer_shutdown.start test_time * 1000 return app
def fallback_trans x t _ x if t x l get_lang set_lang g.lang graceful_fail True t _ x if l and l[0] ! g.lang set_lang l[0] return t
def get_dynamic_property vim mobj type property_name obj_content get_object_properties vim None mobj type [property_name] property_value Noneif obj_content dynamic_property obj_content[0].propSetif dynamic_property property_value dynamic_property[0].valreturn property_value
def create_quiver x y u v scale 0.1 arrow_scale 0.3 angle math.pi / 9 **kwargs utils.validate_equal_length x y u v utils.validate_positive_scalars arrow_scale arrow_scale scale scale barb_x barb_y _Quiver x y u v scale arrow_scale angle .get_barbs arrow_x arrow_y _Quiver x y u v scale arrow_scale angle .get_quiver_arrows quiver graph_objs.Scatter x barb_x + arrow_x y barb_y + arrow_y mode 'lines' **kwargs data [quiver]layout graph_objs.Layout hovermode 'closest' return graph_objs.Figure data data layout layout
def setup app app.add_role 'rfc' rfclink return
def int64_feature values if not isinstance values tuple list values [values]return tf.train.Feature int64_list tf.train.Int64List value values
def libvlc_audio_get_channel p_mi f _Cfunctions.get 'libvlc_audio_get_channel' None or _Cfunction 'libvlc_audio_get_channel' 1 None ctypes.c_int MediaPlayer return f p_mi
def get_requirement_from_url url link Link url egg_info link.egg_fragmentif not egg_info egg_info splitext link.filename [0]return package_to_requirement egg_info
def barycenter_weights X Z reg 0.001 X check_array X dtype FLOAT_DTYPES Z check_array Z dtype FLOAT_DTYPES allow_nd True n_samples n_neighbors X.shape[0] Z.shape[1] B np.empty n_samples n_neighbors dtype X.dtype v np.ones n_neighbors dtype X.dtype for i A in enumerate Z.transpose 0 2 1 C A.T - X[i] G np.dot C C.T trace np.trace G if trace > 0 R reg * trace else R regG.flat[ Z.shape[1] + 1 ] + Rw solve G v sym_pos True B[i ] w / np.sum w return B
def _ToWebSafeString per_result internal_cursor return str per_result + ' ' + internal_cursor
def location_to_url location strict True if location is None return Nonesplit_path Hdfs.urlsplit location if strict and not split_path[1] or not split_path[2] return Nonepath locationif split_path[0] 'hdfs' path split_path[2]return reverse 'filebrowser.views.view' kwargs dict path path
def article_course_wiki_root_slug article try urlpath article.urlpath_set.get except ObjectDoesNotExist return Noneancestors urlpath.cached_ancestorscourse_wiki_root_urlpath Noneif len ancestors 0 course_wiki_root_urlpath Noneelif len ancestors 1 course_wiki_root_urlpath urlpathelse course_wiki_root_urlpath ancestors[1]if course_wiki_root_urlpath is not None return course_wiki_root_urlpath.slugreturn None
def binary_log_loss y_true y_prob y_prob np.clip y_prob 1e-10 1 - 1e-10 return - np.sum y_true * np.log y_prob + 1 - y_true * np.log 1 - y_prob / y_prob.shape[0]
def interrupt_main if _main raise KeyboardInterruptelse global _interrupt_interrupt True
def get_scheduler_events event scheduler_events frappe.cache .get_value u'scheduler_events' if not scheduler_events scheduler_events frappe.get_hooks u'scheduler_events' integration_events get_integration_service_events for key handlers in integration_events.items scheduler_events.setdefault key [] .extend handlers frappe.cache .set_value u'scheduler_events' scheduler_events return scheduler_events.get event or []
def _make_ctf_name directory extra raise_error True fname op.join directory op.basename directory [ -3 ] + '.' + extra if not op.isfile fname if raise_error raise IOError 'Standardfile%snotfound' % fname else return Nonereturn fname
def remove_sshkey host known_hosts None if known_hosts is None if 'HOME' in os.environ known_hosts '{0}/.ssh/known_hosts'.format os.environ['HOME'] else try known_hosts '{0}/.ssh/known_hosts'.format pwd.getpwuid os.getuid .pwd_dir except Exception passif known_hosts is not None log.debug 'Removingsshkeyfor{0}fromknownhostsfile{1}'.format host known_hosts else log.debug 'Removingsshkeyfor{0}fromknownhostsfile'.format host cmd 'ssh-keygen-R{0}'.format host subprocess.call cmd shell True
def setup_lockfile_method_mocks testcase scenario class_name def mock_read_pid return scenario['pidfile_pid']def mock_is_locked return scenario['locking_pid'] is not None def mock_i_am_locking return scenario['locking_pid'] scenario['pid'] def mock_acquire timeout None if scenario['locking_pid'] is not None raise lockfile.AlreadyLocked scenario['locking_pid'] scenario['pid']def mock_release if scenario['locking_pid'] is None raise lockfile.NotLocked if scenario['locking_pid'] ! scenario['pid'] raise lockfile.NotMyLock scenario['locking_pid'] Nonedef mock_break_lock scenario['locking_pid'] Nonefor func_name in ['read_pid' 'is_locked' 'i_am_locking' 'acquire' 'release' 'break_lock'] mock_func vars [ 'mock_% func_name s' % vars ]lockfile_func_name '% class_name s.% func_name s' % vars mock_lockfile_func scaffold.Mock lockfile_func_name returns_func mock_func tracker testcase.mock_tracker try scaffold.mock lockfile_func_name mock_obj mock_lockfile_func tracker testcase.mock_tracker except NameError pass
def ior a b a | breturn a
def does_chmod_work dir_to_test if not os.path.isdir dir_to_test return Truef1 tempfile.NamedTemporaryFile dir dir_to_test try f1_stat os.stat f1.name os.chmod f1.name f1_stat.st_mode | stat.S_IRUSR chmod_works Truelogging.debug 'Detectedthatchmodsworkin%r' % dir_to_test except OSError chmod_works Falselogging.debug 'DetectedthatchmodsdoNOTworkin%r' % dir_to_test return chmod_works
def runTests vm tests None pre '' post '' prompt Prompt uninstallNtpd False if uninstallNtpd removeNtpd vm vm.expect prompt if Branch checkOutBranch vm branch Branch vm.expect prompt if not tests tests []if pre log '*Runningcommand' pre vm.sendline pre vm.expect prompt testfns testDict if tests log '*Runningtests' for test in tests if test not in testfns raise Exception 'Unknowntest ' + test log '*Runningtest' test fn testfns[test]fn vm vm.expect prompt if post log '*Runningpost-testcommand' post vm.sendline post vm.expect prompt
def pvdisplay pvname '' real False ret {}cmd ['pvdisplay' '-c']if pvname cmd.append pvname cmd_ret __salt__['cmd.run_all'] cmd python_shell False if cmd_ret['retcode'] ! 0 return {}out cmd_ret['stdout'].splitlines for line in out if 'isanewphysicalvolume' not in line comps line.strip .split ' ' if real device os.path.realpath comps[0] else device comps[0]ret[device] {'PhysicalVolumeDevice' comps[0] 'VolumeGroupName' comps[1] 'PhysicalVolumeSize kB ' comps[2] 'InternalPhysicalVolumeNumber' comps[3] 'PhysicalVolumeStatus' comps[4] 'PhysicalVolume not Allocatable' comps[5] 'CurrentLogicalVolumesHere' comps[6] 'PhysicalExtentSize kB ' comps[7] 'TotalPhysicalExtents' comps[8] 'FreePhysicalExtents' comps[9] 'AllocatedPhysicalExtents' comps[10]}if real ret[device]['RealPhysicalVolumeDevice'] devicereturn ret
def _get_backing_memmap a b getattr a 'base' None if b is None return Noneelif isinstance b mmap return aelse return _get_backing_memmap b
def write_pack_objects f objects delta_window_size None deltify False if deltify pack_contents deltify_pack_objects objects delta_window_size else pack_contents o.type_num o.sha .digest None o.as_raw_string for o path in objects return write_pack_data f len objects pack_contents
def _convert_stringval value value unicode value try value int value except ValueError TypeError passreturn value
def index_groups request group_form forms.GroupCreateForm request.POST or None if group_form.is_valid group group_form.save group.curators.add request.user.userprofile group.add_member request.user.userprofile GroupMembership.MEMBER return redirect reverse 'groups group_edit' args [group.url] query Group.get_non_functional_areas template 'groups/index_groups.html'context {'group_form' group_form}return _list_groups request template query context
def pred_error f_pred prepare_data data iterator verbose False valid_err 0for _ valid_index in iterator x mask y prepare_data [data[0][t] for t in valid_index] numpy.array data[1] [valid_index] maxlen None preds f_pred x mask targets numpy.array data[1] [valid_index]valid_err + preds targets .sum valid_err 1.0 - numpy_floatX valid_err / len data[0] return valid_err
def getGcodeTextWithoutRedundantMcode gcodeText lines archive.getTextLines gcodeText lines getLinesWithoutRedundancy 'M104' lines lines getLinesWithoutRedundancy 'M108' lines output cStringIO.StringIO gcodec.addLinesToCString output lines return output.getvalue
def sanitize_results_data results_dirpath raise NotImplementedError
def assert_server_running server if server.poll is not None raise RuntimeError 'Serverdiedunexpectedly!Check%s' % LOG_FILE
def authenticated_build registry xml_parent data security XML.SubElement xml_parent 'hudson.security.AuthorizationMatrixProperty' XML.SubElement security 'permission' .text 'hudson.model.Item.Build authenticated'
def in6_getifaddr ret []i dnet.intf for int in i ifname int['name']v6 []if int.has_key 'alias_addrs' v6 int['alias_addrs']for a in v6 if a.type ! dnet.ADDR_TYPE_IP6 continuexx str a .split '/' [0]addr scapy.utils6.in6_ptop xx scope scapy.utils6.in6_getscope addr ret.append xx scope ifname return ret
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def admin_context request if django.VERSION < 1 8 0 return admin.site.each_context return admin.site.each_context request
def _generate_java_binary target_name onejar_path jvm_flags run_args onejar_name os.path.basename onejar_path full_path os.path.abspath onejar_path target_file open target_name 'w' target_file.write '#!/bin/sh\n#Autogeneratedwrappershellscriptbyblade\n\njar `dirname"$0"`/"%s"\nif[!-f"$jar"];then\njar "%s"\nfi\n\nexecjava%s-jar"$jar"%s$@\n' % onejar_name full_path jvm_flags run_args os.chmod target_name 493 target_file.close return None
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def test_datasets for dname in 'sample' 'somato' 'spm_face' 'testing' 'bst_raw' 'bst_auditory' 'bst_resting' 'visual_92_categories' if dname.startswith 'bst' dataset getattr datasets.brainstorm dname else dataset getattr datasets dname if dataset.data_path download False ! '' assert_true isinstance dataset.get_version string_types else assert_true dataset.get_version is None tempdir _TempDir os.environ['_MNE_FAKE_HOME_DIR'] tempdirtry assert_equal datasets.utils._get_path None 'foo' 'bar' op.join tempdir 'mne_data' finally del os.environ['_MNE_FAKE_HOME_DIR']
def broadcasted_add a b raise NotImplementedError 'TODO implementthisfunction.'
def _get_subnet_explicit_route_table subnet_id vpc_id conn None region None key None keyid None profile None if not conn conn _get_conn region region key key keyid keyid profile profile if conn vpc_route_tables conn.get_all_route_tables filters {'vpc_id' vpc_id} for vpc_route_table in vpc_route_tables for rt_association in vpc_route_table.associations if rt_association.subnet_id subnet_id and not rt_association.main return rt_association.idreturn None
def getos return {'os' __pillar__.get 'proxy' {} .get 'driver' '' }
def pwConvert pw encode True if pw u'' return pwif encode if Preferences.getUser u'UseMasterPassword' epw pwEncrypt pw [0]else epw pwEncode pw return epwelse if Preferences.getUser u'UseMasterPassword' plain ok pwDecrypt pw else plain ok pwDecode pw True return plain if ok else pw
def mock_software_secure_post url headers None data None **kwargs data_dict json.loads data EXPECTED_KEYS ['EdX-ID' 'ExpectedName' 'PhotoID' 'PhotoIDKey' 'SendResponseTo' 'UserPhoto' 'UserPhotoKey']for key in EXPECTED_KEYS assert_true data_dict.get key "'{}'mustbepresentandnotblankinJSONsubmittedtoSoftwareSecure".format key data_dict['PhotoIDKey'].decode 'base64' data_dict['UserPhotoKey'].decode 'base64' response requests.Response response.status_code 200return response
def accept_dict match include_rejected False include_denied False skey get_key __opts__ return skey.accept match_dict match include_rejected include_rejected include_denied include_denied
def get_fund_info code request ct.SINA_FUND_INFO_URL % ct.P_TYPE['http'] ct.DOMAINS['ssf'] code text urlopen request timeout 10 .read text text.decode 'gbk' org_js json.loads text status_code int org_js['result']['status']['code'] if status_code ! 0 status str org_js['result']['status']['msg'] raise ValueError status data org_js['result']['data']fund_df pd.DataFrame data columns ct.FUND_INFO_COLS index [0] fund_df fund_df.set_index 'symbol' return fund_df
def invoice_resend_email request order_id try order Order.objects.get_for_user order_id request except Order.DoesNotExist raise Http404if request.method u'POST' checkout.send_order_email request order msg _ u'TheorderemailfororderID%shasbeenre-sent' % order_id info request msg redirect_to next_url request if redirect_to is None if request.user.is_staff redirect_to reverse u'admin shop_order_change' args [order_id] else redirect_to reverse u'shop_order_history' return redirect redirect_to
def is_number dtype return is_float dtype or 'int' in dtype.name or 'long' in dtype.name or 'short' in dtype.name
def rename name kwargs call None if call ! 'action' raise SaltCloudSystemExit 'Therenameactionmustbecalledwith-aor--action.' log.info 'Renaming{0}to{1}'.format name kwargs['newname'] set_tags name {'Name' kwargs['newname']} call 'action' salt.utils.cloud.rename_key __opts__['pki_dir'] name kwargs['newname']
def get_purchase_endpoint return get_processor_config .get 'PURCHASE_ENDPOINT' ''
def list_settings keys from importlib import import_modulefrom evennia.utils import evtableevsettings import_module SETTINGS_DOTPATH if len keys 1 and keys[0].upper 'ALL' table evtable.EvTable confs [key for key in sorted evsettings.__dict__ if key.isupper ]for i in range 0 len confs 4 table.add_row *confs[i i + 4 ] else table evtable.EvTable width 131 keys [key.upper for key in keys]confs dict key var for key var in evsettings.__dict__.items if key in keys for key val in confs.items table.add_row key str val print table
def exception msg *args error msg exc_info 1 *args
def test2 buildPackage '/Users/dinu/Desktop/reportlab' Title 'reportlab' Version '1.10' Description "ReportLab'sOpenSourcePDFtoolkit." DefaultLocation '/Applications/ReportLab' Relocatable 'YES'
def GetRecommendedIndexProperties properties prefix postfix propertiesresult []for sub_list in itertools.chain prefix postfix if isinstance sub_list frozenset set for prop in sorted sub_list result.append prop ASCENDING else for prop dir in sub_list result.append prop dir if dir is not None else ASCENDING return tuple result
def stations stations_strings []append stations_strings.appendtable s3db.climate_placeetable s3db.climate_place_elevationitable s3db.climate_place_station_idntable s3db.climate_place_station_namequery table.id etable.id & table.id itable.id & table.id ntable.id rows db query .select table.id table.longitude table.latitude etable.elevation_metres itable.station_id ntable.name for place_row in rows append ''.join ' ' str place_row.climate_place.id ' {' '"longitude" ' str place_row.climate_place.longitude ' "latitude" ' str place_row.climate_place.latitude '}' return '[%s]' % ' '.join stations_strings
def benchmark scale 1 overallResult {}byteCount 1024bufferedDeferred _benchmarkBuffered byteCount * scale def didBuffered bufferedResult overallResult[u'buffered'] bufferedResultunbufferedDeferred _benchmarkUnbuffered byteCount * scale def didUnbuffered unbufferedResult overallResult[u'unbuffered'] unbufferedResultreturn overallResultunbufferedDeferred.addCallback didUnbuffered return unbufferedDeferredbufferedDeferred.addCallback didBuffered return bufferedDeferred
def is_protected_type obj return isinstance obj _PROTECTED_TYPES
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def shapelist a if type a is list return tuple [len a ] + list shapelist a[0] else return
def get_fc_wwpns hbas get_fc_hbas wwpns []if hbas for hba in hbas if hba['port_state'] 'Online' wwpn hba['port_name'].replace '0x' '' wwpns.append wwpn return wwpns
@shared_constructordef generic_constructor value name None strict False allow_downcast None return SharedVariable type generic value value name name strict strict allow_downcast allow_downcast
def incident_type return s3_rest_controller
def monitor_one_import_per_line logical_line pos logical_line.find ' ' parts logical_line.split if pos > -1 and parts[0] 'import' or parts[0] 'from' and parts[2] 'import' and not is_import_exception parts[1] yield pos 'ENERGYN301 oneimportperline'
def xml_item item xml xml_root_open item xml + xml_add_links item xml + xml_dict item xml + xml_root_close return xml
def splitUp pred res re_splitComparison.match pred if not res raise ValueError 'badpackagerestrictionsyntax %r' % pred comp verStr res.groups return comp distutils.version.StrictVersion verStr
def mock_ret cdata if cdata['args'] name cdata['args'][0]else name cdata['kwargs']['name']return {'name' name 'comment' 'Notcalled mocked' 'changes' {} 'result' True}
def a2s arr return ''.join chr b for b in arr
def _parse_time time_isoformat return datetime.strptime time_isoformat.split '+' [0] '%Y-%m-%dT%H %M %S.%f' .replace tzinfo UTC
def redirect_to request url permanent True **kwargs if url is not None klass permanent and HttpResponsePermanentRedirect or HttpResponseRedirect return klass url % kwargs else return HttpResponseGone
def package pkg_name repos None yes None options None if not is_installed pkg_name install pkg_name repos yes options
def gen_item fmt obj mode chars fmt.split '#' x []for c in chars x.append randrange_fmt mode c obj return x[0] if len x 1 else tuple x
def _setup_traditional_switches logger config add_devices_callback traditional config.get CONF_TRADITIONAL switches []if traditional for _ entity_info in traditional.items if entity_info[scsgate.CONF_SCS_ID] in scsgate.SCSGATE.devices continuename entity_info[CONF_NAME]scs_id entity_info[scsgate.CONF_SCS_ID]logger.info 'Adding%sscsgate.traditional_switch' name switch SCSGateSwitch name name scs_id scs_id logger logger switches.append switch add_devices_callback switches scsgate.SCSGATE.add_devices_to_register switches
def get_mapped_batch dataset design_batch if design_batch.ndim ! 2 design_batch dataset.get_design_matrix design_batch mapped_batch_design dataset.mapback_for_viewer design_batch mapped_batch dataset.get_topological_view mapped_batch_design return mapped_batch
def make_temp_fname fname None suffix os.path.split fname [ -1 ] fd temp_prefix tempfile.mkstemp prefix 'tmp' suffix suffix return temp_prefix
def test_rocket data.rocket
def safepath p return p.replace '/' os.sep
def member_create request **kwargs body {'member' {'pool_id' kwargs['pool_id'] 'address' kwargs['address'] 'protocol_port' kwargs['protocol_port'] 'weight' kwargs['weight'] 'admin_state_up' kwargs['admin_state_up']}}member quantumclient request .create_member body .get 'member' return Member member
def clean_ascii_chars txt charlist None if not txt return ''global _ascii_patif _ascii_pat is None chars set xrange 32 chars.add 127 for x in 9 10 13 chars.remove x _ascii_pat re.compile u'|'.join map unichr chars if charlist is None pat _ascii_patelse pat re.compile u'|'.join map unichr charlist return pat.sub '' txt
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def archFor filepath name path.basename filepath if 'amd64' in name or 'x86_64' in name arch 'x86_64'elif 'i386' in name or '32' in name or 'x86' in name arch 'i386'elif '64' in name arch 'x86_64'else log "Error can'tdiscernCPUforname" name exit 1 return arch
def _rgb_to_rgba A rgba np.zeros A.shape[0] A.shape[1] 4 dtype A.dtype rgba[ 3] Aif rgba.dtype np.uint8 rgba[ 3] 255else rgba[ 3] 1.0return rgba
def _ConvertToUnicode some_string if some_string is None return Noneif isinstance some_string unicode return some_stringreturn unicode some_string 'utf-8'
def unfrackpath path follow True if follow final_path os.path.normpath os.path.realpath os.path.expanduser os.path.expandvars to_bytes path errors 'surrogate_or_strict' else final_path os.path.normpath os.path.abspath os.path.expanduser os.path.expandvars to_bytes path errors 'surrogate_or_strict' return to_text final_path errors 'surrogate_or_strict'
def _get_request_value request value_name default '' if request is not None and hasattr request 'GET' and value_name in request.GET return request.GET[value_name]elif request is not None and hasattr request 'POST' and value_name in request.POST return request.POST[value_name]else return default
def is_legal_name name if name is None return Falseif name '' return Truem NAME_LEGAL_CHARS_P.match name return m is not None and m.group 0 name and not '//' in name
def get_collection_summary_by_id collection_id collection_summary_model collection_models.CollectionSummaryModel.get collection_id if collection_summary_model collection_summary get_collection_summary_from_model collection_summary_model return collection_summaryelse return None
def filter_jchars c if is_asian c return ''return c
def clear_logical_volume path vol_size logical_volume_size path bs 1024 * 1024 direct_flags 'oflag direct' sync_flags remaining_bytes vol_sizewhile remaining_bytes zero_blocks remaining_bytes / bs seek_blocks vol_size - remaining_bytes / bs zero_cmd 'dd' 'bs %s' % bs 'if /dev/zero' 'of %s' % path 'seek %s' % seek_blocks 'count %s' % zero_blocks zero_cmd + direct_flagszero_cmd + sync_flagsif zero_blocks utils.execute run_as_root True *zero_cmd remaining_bytes % bsbs / 1024direct_flags sync_flags 'conv fdatasync'
def date value arg None from django.utils.dateformat import formatif not value return ''if arg is None arg settings.DATE_FORMATreturn format value arg
def MapKeyToServer mapping key hsh int hashlib.sha1 key .hexdigest [ 16] 16 return _FindServerInMapping mapping hsh
def _ratio_enum anchor ratios w h x_ctr y_ctr _whctrs anchor size w * h size_ratios size / ratios ws np.round np.sqrt size_ratios hs np.round ws * ratios anchors _mkanchors ws hs x_ctr y_ctr return anchors
def groups attrs None where None return _osquery_cmd table 'groups' attrs attrs where where
def manual_updates_required request updates template_name u'admin/manual_updates_required.html' return render_to_response template_name RequestContext request {u'updates' [render_to_string update_template_name RequestContext request extra_context for update_template_name extra_context in updates]}
def _obtain_lock id try os.symlink '/dev/null' _lock_file id return Trueexcept return False
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _CreateRegisterRequest device_dict None auth_info_dict None synchronous True version message.MAX_SUPPORTED_MESSAGE_VERSION request_dict {'headers' {'version' version}}util.SetIfNotNone request_dict 'device' device_dict util.SetIfNotNone request_dict 'auth_info' auth_info_dict if synchronous request_dict['headers']['synchronous'] Truereturn request_dict
def update_router router name None admin_state_up None profile None **kwargs conn _auth profile return conn.update_router router name admin_state_up **kwargs
def _get_all_test_class_names_in_jar jar test_class_names []zip_file zipfile.ZipFile jar 'r' name_list zip_file.namelist for name in name_list basename os.path.basename name if basename.endswith 'Test.class' and len basename > len 'Test.class' and not '$' in basename class_name name.replace '/' '.' [ -6 ]test_class_names.append class_name zip_file.close return test_class_names
def wrap_value x wrapper _wrappers.get type x if wrapper is None return xelse return wrapper x
def nameVariations name fromPtdf 0 name1 name2 name3 u''if fromPtdf or re_nameIndex.search name namedict analyze_name name canonical 1 name1 namedict['name']if fromPtdf if namedict.has_key 'imdbIndex' name3 nameelse name3 build_name namedict canonical 1 else name1 canonicalName name name3 u''name2 normalizeName name1 if name1 name2 name2 u''_aux_logger.debug 'namevariations 1 [%s]2 [%s]3 [%s]' name1 name2 name3 return name1 name2 name3
def vmotion_configured name enabled device 'vmk0' ret {'name' name 'result' False 'changes' {} 'comment' ''}esxi_cmd 'esxi.cmd'host __pillar__['proxy']['host']current_vmotion_enabled __salt__[esxi_cmd] 'get_vmotion_enabled' .get host current_vmotion_enabled current_vmotion_enabled.get 'VMotionEnabled' if enabled ! current_vmotion_enabled if not __opts__['test'] if enabled is True response __salt__[esxi_cmd] 'vmotion_enable' device device .get host error response.get 'Error' if error ret['comment'] 'Error {0}'.format error return retelse response __salt__[esxi_cmd] 'vmotion_disable' .get host error response.get 'Error' if error ret['comment'] 'Error {0}'.format error return retret['changes'].update {'enabled' {'old' current_vmotion_enabled 'new' enabled}} ret['result'] Trueif ret['changes'] {} ret['comment'] 'VMotionconfigurationisalreadyinthedesiredstate.'return retif __opts__['test'] ret['result'] Noneret['comment'] 'VMotionconfigurationwillchange.'return ret
def get_config_h_filename if _PYTHON_BUILD if os.name 'nt' inc_dir os.path.join _PROJECT_BASE 'PC' else inc_dir _PROJECT_BASEelse inc_dir get_path 'platinclude' return os.path.join inc_dir 'pyconfig.h'
def _check_scaling_inputs data picks_list scalings rescale_dict_ dict mag 1000000000000000.0 grad 10000000000000.0 eeg 1000000.0 scalings_ Noneif isinstance scalings string_types and scalings 'norm' scalings_ 1.0 / _compute_row_norms data elif isinstance scalings dict rescale_dict_.update scalings scalings_ rescale_dict_elif isinstance scalings np.ndarray scalings_ scalingselif scalings is None passelse raise NotImplementedError "Noway!That'snotarescalingoption %s" % scalings return scalings_
def GetSmallestThumbnail media_thumbnail_list r {}for thumb in media_thumbnail_list r[ int thumb.width * int thumb.height ] thumbkeys r.keys keys.sort return r[keys[0]]
def _normalize_server_settings **settings ret dict settings salt.utils.clean_kwargs **settings for setting in settings if isinstance settings[setting] dict _LOG.debug 'Fixingvalue %s' settings[setting] value_from_key next six.iterkeys settings[setting] ret[setting] '{{{0}}}'.format value_from_key else ret[setting] settings[setting]return ret
def parse_type attrtype uattribute attrtype.lower .strip if uattribute[0] '{' return 'nominal'elif uattribute[ len 'real' ] 'real' return 'numeric'elif uattribute[ len 'integer' ] 'integer' return 'numeric'elif uattribute[ len 'numeric' ] 'numeric' return 'numeric'elif uattribute[ len 'string' ] 'string' return 'string'elif uattribute[ len 'relational' ] 'relational' return 'relational'elif uattribute[ len 'date' ] 'date' return 'date'else raise ParseArffError 'unknownattribute%s' % uattribute
def can_edit user translation permission if translation.subproject.locked return Falseif user.is_authenticated and not user.email return Falseif check_owner user translation.subproject.project permission return Trueif not has_group_perm user permission translation return Falseif translation.is_template and not has_group_perm user 'trans.save_template' translation return Falseif not has_group_perm user 'trans.override_suggestion' translation and translation.subproject.suggestion_voting and translation.subproject.suggestion_autoaccept > 0 return Falsereturn True
def unfollow_dataset context data_dict schema context.get 'schema' or ckan.logic.schema.default_follow_dataset_schema _unfollow context data_dict schema context['model'].UserFollowingDataset
def _roots_hermite_asy n iv _initial_nodes n nodes weights _newton n iv if n % 2 0 nodes hstack [ - nodes[ -1 ] nodes] weights hstack [weights[ -1 ] weights] else nodes hstack [ - nodes[ -1 0 -1 ] nodes] weights hstack [weights[ -1 0 -1 ] weights] weights * sqrt pi / sum weights return nodes weights
def register_rbssh envvar envvar envvar.encode u'utf-8' os.putenv envvar 'rbssh' os.environ[envvar] 'rbssh'
def proj_plane_pixel_scales wcs return np.sqrt wcs.pixel_scale_matrix ** 2 .sum axis 0 dtype np.float
def _execute4 *args **kargs cmd args[1 -3 ] if args[0] 'raidcom' else args result EXECUTE_TABLE4.get cmd CMD_SUCCEED return result
def filter_attribute_value_assertions ava attribute_restrictions None if not attribute_restrictions return avafor attr vals in ava.items _attr attr.lower try _rests attribute_restrictions[_attr]except KeyError del ava[attr]else if _rests is None continueif isinstance vals basestring vals [vals]rvals []for restr in _rests for val in vals if restr.match val rvals.append val if rvals ava[attr] list set rvals else del ava[attr]return ava
def fake_ugettext translations def _ugettext text return translations.get text text return _ugettext
def parse_head fileobj parser while 1 data fileobj.read CHUNK try parser.feed data except EndOfHeadError breakif len data ! CHUNK breakreturn parser.http_equiv
def prepare_grant_uri uri client_id response_type redirect_uri None scope None state None **kwargs params [ u'response_type' response_type u'client_id' client_id ]if redirect_uri params.append u'redirect_uri' redirect_uri if scope params.append u'scope' scope if state params.append u'state' state for k in kwargs params.append unicode k kwargs[k] return add_params_to_uri uri params
def setup_holiday_list year now_datetime .yearholiday_list frappe.get_doc {u'doctype' u'HolidayList' u'holiday_list_name' str year u'from_date' u'{0}-01-01'.format year u'to_date' u'{0}-12-31'.format year } holiday_list.insert holiday_list.weekly_off u'Saturday'holiday_list.get_weekly_off_dates holiday_list.weekly_off u'Sunday'holiday_list.get_weekly_off_dates holiday_list.save frappe.set_value u'Company' erpnext.get_default_company u'default_holiday_list' holiday_list.name
@view_config context httpexceptions.HTTPForbidden permission NO_PERMISSION_REQUIRED def authorization_required response request if Authenticated not in request.effective_principals error_msg 'Pleaseauthenticateyourselftousethisendpoint.'response http_error httpexceptions.HTTPUnauthorized errno ERRORS.MISSING_AUTH_TOKEN message error_msg response.headers.extend forget request return responseif response.content_type ! 'application/json' error_msg 'Thisusercannotaccessthisresource.'response http_error httpexceptions.HTTPForbidden errno ERRORS.FORBIDDEN message error_msg return reapply_cors request response
def _get_request_id global _CURRENT_REQUEST_ID_HASHglobal _REQUEST_TIMErequest_id_hash os.environ.get 'REQUEST_ID_HASH' '' if _CURRENT_REQUEST_ID_HASH ! request_id_hash _CURRENT_REQUEST_ID_HASH request_id_hash_REQUEST_TIME time.time return str int _FUTURE_TIME - _REQUEST_TIME * 1000000
def get_vm_resize_spec client_factory vcpus memory_mb extra_specs metadata None resize_spec client_factory.create 'ns0 VirtualMachineConfigSpec' resize_spec.numCPUs vcpusresize_spec.memoryMB memory_mbresize_spec.cpuAllocation _get_allocation_info client_factory extra_specs.cpu_limits 'ns0 ResourceAllocationInfo' if metadata resize_spec.annotation metadatareturn resize_spec
def is_python_3 return sys.version_info[0] 3
def sanitize_word s s re.sub '[^\\w-]+' '_' s s re.sub '__+' '_' s return s.strip '_'
def previous_friday dt if dt.weekday 5 return dt - timedelta 1 elif dt.weekday 6 return dt - timedelta 2 return dt
def to_tag_list journal tag_counts get_tags_count journal result u''if not tag_counts return u'[Notagsfoundinjournal.]'elif min tag_counts [0] 0 tag_counts filter lambda x x[0] > 1 tag_counts result + u'[Removedtagsthatappearonlyonce.]\n'result + u'\n'.join u'{0 20} {1}'.format tag n for n tag in sorted tag_counts reverse True return result
def _node_name node return node.name or '{}{}'.format node.manufacturer_name node.product_name
def prioritySortColumns columns _ lambda x x and 'id' in x.lower return sorted sorted columns key len lambda x y -1 if _ x and not _ y else 1 if not _ x and _ y else 0
def _is_finite_with_finite_vars f domain S.Complexes def assumptions s A s.assumptions0if A.get 'finite' None is None A['finite'] TrueA.setdefault 'complex' True A.setdefault 'real' domain.is_subset S.Reals return Areps {s Dummy **assumptions s for s in f.free_symbols}return f.xreplace reps .is_finite
def test_uninstall_editable_and_pip_install script data script.environ['SETUPTOOLS_SYS_PATH_TECHNIQUE'] 'raw'pkg_path data.packages.join 'FSPkg' script.pip 'install' '-e' '.' expect_stderr True cwd pkg_path script.pip 'install' '--ignore-installed' '.' expect_stderr True cwd pkg_path list_result script.pip 'list' '--format legacy' assert 'FSPkg 0.1.dev0 ' in list_result.stdout uninstall script.pip 'uninstall' 'FSPkg' '-y' assert not any filename.endswith '.egg-link' for filename in uninstall.files_deleted.keys uninstall2 script.pip 'uninstall' 'FSPkg' '-y' assert join script.site_packages 'FSPkg.egg-link' in uninstall2.files_deleted list uninstall2.files_deleted.keys list_result2 script.pip 'list' '--format legacy' assert 'FSPkg' not in list_result2.stdout
def education def prep r if r.method in 'create' 'create.popup' 'update' 'update.popup' person_id get_vars.get '~.person_id' None if person_id field s3db.pr_education.person_idfield.default person_idfield.readable field.writable Falsereturn Trues3.prep prepreturn s3_rest_controller 'pr' 'education'
def sha256_encode t s hashlib.sha256 t return s.hexdigest
def MINMAXINDEX ds count timeperiod - 2 ** 31 ret call_talib_with_ds ds count talib.MINMAXINDEX timeperiod if ret is None ret None None return ret
def isestimable C D C np.asarray C D np.asarray D if C.ndim 1 C C[None ]if C.shape[1] ! D.shape[1] raise ValueError 'Contrastshouldhave%dcolumns' % D.shape[1] new np.vstack [C D] if np_matrix_rank new ! np_matrix_rank D return Falsereturn True
def algorithm_list return ['metagenomeSeq_fitZIG' 'DESeq2_nbinom']
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _lowess_wt_standardize weights new_entries x_copy_i width weights[ ] new_entriesweights - x_copy_iweights / width
def parse_media_range range type subtype params parse_mime_type range try if not 0 < float params['q'] < 1 raise ValueErrorexcept KeyError ValueError params['q'] '1'return type subtype params
def p_enumerator_list_1 t pass
def choose_diverging_palette as_cmap False pal []if as_cmap cmap _init_mutable_colormap @interactdef choose_diverging_palette h_neg IntSlider min 0 max 359 value 220 h_pos IntSlider min 0 max 359 value 10 s IntSlider min 0 max 99 value 74 l IntSlider min 0 max 99 value 50 sep IntSlider min 1 max 50 value 10 n 2 16 center ['light' 'dark'] if as_cmap colors diverging_palette h_neg h_pos s l sep 256 center _update_lut cmap colors _show_cmap cmap else pal[ ] diverging_palette h_neg h_pos s l sep n center palplot pal if as_cmap return cmapreturn pal
def test_adjust_inv_sigmoid_cutoff_half image np.arange 0 255 4 np.uint8 .reshape 8 8 expected np.array [[253 253 252 252 251 251 250 249] [249 248 247 245 244 242 240 238] [235 232 229 225 220 215 210 204] [197 190 182 174 165 155 146 136] [126 116 106 96 87 78 70 62] [55 49 43 37 33 28 25 21] [18 16 14 12 10 8 7 6] [5 4 4 3 3 2 2 1]] dtype np.uint8 result exposure.adjust_sigmoid image 0.5 10 True assert_array_equal result expected
def _check_preload inst if inst.preload is False raise RuntimeError 'ModifyingdataofInstanceisonlysupportedwhenpreloadingisused.Usepreload True orstring intheconstructor.'
def invisible_input prompt '>>>' import getpassentry getpass.getpass prompt if entry is None raise KeyboardInterruptreturn entry
def create_init_file folderName if not os.path.isdir folderName raise NinjaIOException u'Thedestinationfolderdoesnotexist' name os.path.join folderName u'__init__.py' if file_exists name raise NinjaFileExistsException name f open name u'w' f.flush f.close
@check_simple_wiki_locale@mobile_template 'products/{mobile/}documents.html' def document_listing request template product_slug topic_slug subtopic_slug None product get_object_or_404 Product slug product_slug topic get_object_or_404 Topic slug topic_slug product product parent__isnull True doc_kw {'locale' request.LANGUAGE_CODE 'products' [product]}if subtopic_slug is not None subtopic get_object_or_404 Topic slug subtopic_slug product product parent topic doc_kw['topics'] [subtopic]else subtopic Nonedoc_kw['topics'] [topic] documents fallback_documents documents_for **doc_kw user_agent request.META.get 'HTTP_USER_AGENT' '' browser get_browser user_agent show_fx_download product.slug 'thunderbird' and browser ! 'Firefox' return render request template {'product' product 'topic' topic 'subtopic' subtopic 'topics' topics_for product product parent None 'subtopics' topics_for product product parent topic 'documents' documents 'fallback_documents' fallback_documents 'search_params' {'product' product_slug} 'show_fx_download' show_fx_download}
def _toInt val replace for before after in replace val val.replace before after try return int val except TypeError ValueError return None
def ManifestFromDOM domtree manifest Manifest manifest.load_dom domtree return manifest
def service_get_by_args context host binary return IMPL.service_get_by_args context host binary
def create_sunspec_sync_client host modbus ModbusTcpClient host modbus.connect client SunspecClient modbus client.initialize return client
def service_type stype def inner f f.service_type stypereturn freturn inner
def check_permission user project permission return has_group_perm user permission project project or check_owner user project permission or user.has_perm permission
@add_mask_if_nonedef crossfadein clip duration newclip clip.copy newclip.mask clip.mask.fx fadein duration return newclip
def can_fs_encode filename if os.path.supports_unicode_filenames return Truetry filename.encode sys.getfilesystemencoding except UnicodeEncodeError return Falsereturn True
def _get_finder import_path Finder import_by_path import_path if not issubclass Finder BaseFinder raise ImproperlyConfigured 'Finder"%s"isnotasubclassof"%s"' % Finder BaseFinder return Finder
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def reraise_uncaught func @functools.wraps func def wrapper *args **kwds try return func *args **kwds except AttributeError exc_info sys.exc_info reraise UncaughtAttributeError exc_info[1] exc_info[2] return wrapper
def tmax a upperlimit None axis 0 inclusive True nan_policy 'propagate' a axis _chk_asarray a axis am _mask_to_limits a None upperlimit False inclusive contains_nan nan_policy _contains_nan am nan_policy if contains_nan and nan_policy 'omit' am ma.masked_invalid am res ma.maximum.reduce am axis .dataif res.ndim 0 return res[ ]return res
def _windows_cpudata grains {}if 'NUMBER_OF_PROCESSORS' in os.environ try grains['num_cpus'] int os.environ['NUMBER_OF_PROCESSORS'] except ValueError grains['num_cpus'] 1grains['cpu_model'] __salt__['reg.read_value'] 'HKEY_LOCAL_MACHINE' 'HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0' 'ProcessorNameString' .get 'vdata' return grains
@register.inclusion_tag u'admin/includes/recent_comments.html' takes_context True def recent_comments context latest context[u'settings'].COMMENTS_NUM_LATESTcomments ThreadedComment.objects.all .select_related u'user' context[u'comments'] comments.order_by u'-id' [ latest]return context
def provide_worker_fake_entries group return _WORKER_FAKE_ENTRIES.get group []
def unionTest comment place parameter value prefix suffix if conf.direct returnkb.technique PAYLOAD.TECHNIQUE.UNION validPayload vector _unionTestByCharBruteforce comment place parameter value prefix suffix if validPayload validPayload agent.removePayloadDelimiters validPayload return validPayload vector
def run_ssh reactor username host command **kwargs ssh_command ['ssh'] + SSH_OPTIONS + ['-l' username host ''.join map shell_quote command ] return run reactor ssh_command **kwargs
def clues_too_many text text text.lower for clue in 'exceed' 'connections' 'toomany' 'threads' 'limit' if clue in text return Truereturn False
def fullsplit path result None if result is None result [] head tail os.path.split path if head '' return [tail] + result if head path return resultreturn fullsplit head [tail] + result
def rand_str size 9999999999 hash_type None if not hash_type hash_type __opts__.get 'hash_type' 'md5' return salt.utils.rand_str hash_type hash_type size size
def get_vlan_binding netid LOG.debug _ 'get_vlan_binding called' session db.get_session try binding session.query l2network_models.VlanBinding .filter_by network_id netid .one return bindingexcept exc.NoResultFound raise q_exc.NetworkNotFound net_id netid
def colorx clip factor return clip.fl_image lambda pic np.minimum 255 factor * pic .astype 'uint8'
def run _task
def validate_parameters params shape validator ParamValidator report validator.validate params shape if report.has_errors raise ParamValidationError report report.generate_report
def addToMenu master menu repository window analyzeFilePath archive.getSkeinforgePluginsPath 'analyze.py' pluginsDirectoryPath skeinforge_analyze.getPluginsDirectoryPath settings.addPluginsParentToMenu pluginsDirectoryPath menu analyzeFilePath skeinforge_analyze.getPluginFileNames
def unflatten_envelope packenv i iter packenv h {}try while True k i.next h[k] i.next except StopIteration return h
def test_set_params_2 tpot_obj TPOTClassifier generations 2 tpot_obj.set_params generations 3 assert tpot_obj.generations 3
def releaseCompleteNetToMs Cause_presence 0 Facility_presence 0 UserUser_presence 0 a TpPd pd 3 b MessageType mesType 42 packet a / b if Cause_presence is 1 c CauseHdr ieiC 8 eightBitC 0 packet packet / c if Facility_presence is 1 d FacilityHdr ieiF 28 eightBitF 0 packet packet / d if UserUser_presence is 1 e UserUserHdr ieiUU 126 eightBitUU 0 packet packet / e return packet
def Strip txt try return txt.strip except return None
@docstring.copy_dedent Figure.ginput def ginput *args **kwargs return gcf .ginput *args **kwargs
def status_leader consul_url None ret {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retfunction 'status/leader'ret _query consul_url consul_url function function return ret
def test_simulate_for_matrices_with_C_F_orders P_C np.array [[0.5 0.5] [0 1]] order 'C' P_F np.array [[0.5 0.5] [0 1]] order 'F' init 1ts_length 10sample_path np.ones ts_length dtype int computed_C_and_F MarkovChain np.array [[1.0]] .simulate ts_length init 0 assert_array_equal computed_C_and_F np.zeros ts_length dtype int computed_C MarkovChain P_C .simulate ts_length init computed_F MarkovChain P_F .simulate ts_length init init assert_array_equal computed_C sample_path assert_array_equal computed_F sample_path
def order_modified_iter cursor trim sentinel for rows in iter lambda cursor.fetchmany GET_ITERATOR_CHUNK_SIZE sentinel yield [r[ - trim ] for r in rows]
def ctrl_alt_del vm_ dom _get_domain vm_ return dom.sendKey 0 0 [29 56 111] 3 0 0
def run_with_reloader main_func extra_files None interval 1 import signalsignal.signal signal.SIGTERM lambda *args sys.exit 0 if os.environ.get 'WERKZEUG_RUN_MAIN' 'true' thread.start_new_thread main_func try reloader_loop extra_files interval except KeyboardInterrupt returntry sys.exit restart_with_reloader except KeyboardInterrupt pass
def _check_margeff_args at method if at not in ['overall' 'mean' 'median' 'zero' 'all'] raise ValueError '%snotavalidoptionfor`at`.' % at if method not in ['dydx' 'eyex' 'dyex' 'eydx'] raise ValueError 'methodisnotunderstood.Got%s' % method
def aaq_confirm request if request.user.is_authenticated email request.user.emailauth.logout request statsd.incr 'questions.user.logout' else email Nonerequest.session['in-aaq'] Falseconfirm_t 'questions/mobile/confirm_email.html' if request.MOBILE else 'questions/confirm_email.html' return render request confirm_t {'email' email}
def inf_to_nan func def wrap *a **kw v func *a **kw if not np.isfinite v return np.nanreturn vreturn wrap
def _copy2 src dst metadata None retry_params None common.validate_file_path src common.validate_file_path dst if metadata is None metadata {}copy_meta 'COPY'else copy_meta 'REPLACE'metadata.update {'x-goog-copy-source' src 'x-goog-metadata-directive' copy_meta} api storage_api._get_storage_api retry_params retry_params status resp_headers content api.put_object api_utils._quote_filename dst headers metadata errors.check_status status [200] src metadata resp_headers body content
def channel_session func @functools.wraps func def inner message *args **kwargs if hasattr message 'channel_session' try return func message *args **kwargs finally if message.channel_session.modified message.channel_session.save if not message.reply_channel raise ValueError 'Noreply_channelsenttoconsumer;@channel_session' + 'canonlybeusedonmessagescontainingit.' session session_for_reply_channel message.reply_channel.name if not session.exists session.session_key try session.save must_create True except CreateError raise ConsumeLater message.channel_session sessiontry return func message *args **kwargs finally if session.modified and not session.is_empty session.save return inner
def Replay *args for mock in args mock._Replay
def _check_surface_size surf sizes surf['rr'].max axis 0 - surf['rr'].min axis 0 if sizes < 0.05 .any raise RuntimeError 'Dimensionsofthesurface%sseemtoosmall %9.5fmm .Maybethetheunitofmeasureismetersinsteadofmm' % _surf_name[surf['id']] 1000 * sizes.min
def flavor_extra_specs_update_or_create context flavor_id extra_specs IMPL.flavor_extra_specs_update_or_create context flavor_id extra_specs
def get_tool_dependency_definition_metadata_from_tool_shed app tool_shed_url name owner tool_shed_url common_util.get_tool_shed_url_from_tool_shed_registry app tool_shed_url params dict name name owner owner pathspec ['repository' 'get_tool_dependency_definition_metadata']metadata util.url_get tool_shed_url password_mgr app.tool_shed_registry.url_auth tool_shed_url pathspec pathspec params params return metadata
def toPickle filename data f open filename 'w' cPickle.dump data f f.close
def libvlc_media_add_option p_md psz_options f _Cfunctions.get 'libvlc_media_add_option' None or _Cfunction 'libvlc_media_add_option' 1 1 None None Media ctypes.c_char_p return f p_md psz_options
def warp_occupancy info cc smem_config None ret {}try limits PHYSICAL_LIMITS[cc]except KeyError raise ValueError '%sisnotasupportedcomputecapability' % '.'.join str c for c in cc if smem_config is None smem_config limits['default_smem_config']warpsize limits['thread_per_warp']max_thread info.maxthreadsfor tpb in range warpsize max_thread + 1 warpsize result compute_warp_occupancy tpb tpb reg info.regs smem info.shared smem_config smem_config limits limits if result[0] ret[tpb] resultreturn ret
def _ConvertToListAndCheckType arg element_type arg_name ret _ConvertToList arg for element in ret if not isinstance element element_type raise TypeError '%sshouldbesingleelementorlistoftype%s' % arg_name element_type return ret
def path2html sourcepath colors None markup 'html' header None footer None linenumbers 0 form None stringIO StringIO.StringIO sourcestring open sourcepath .read Parser sourcestring colors title sourcepath out stringIO markup markup header header footer footer linenumbers linenumbers .format form stringIO.seek 0 return stringIO.read
def _getopt_flags options s []l []for o in options if o.prefix '-' s.append o.name if o.takes_argument s.append ' ' elif o.takes_argument l.append o.name + ' ' else l.append o.name return ''.join s l
def get_account nick last_account [row[1] for row in last_cache if nick.lower row[0] ]if not last_account returnelse last_account last_account[0]return last_account
def contains_point poly point n len poly c Falsei 0j n - 1 while i < n if poly[i][0] > point[0] ! poly[j][0] > point[0] and point[1] < poly[j][1] - poly[i][1] * point[0] - poly[i][0] / poly[j][0] - poly[i][0] + poly[i][1] c not c j ii + 1return c
@manager.command def create_tables from redash.models import dbdb.create_all stamp
def delete_file_from_filesystem doc only_thumbnail False if only_thumbnail delete_file doc.thumbnail_url else delete_file doc.file_url delete_file doc.thumbnail_url
def hwaddr value query '' alias 'hwaddr' query_func_extra_args {'' 'value' }query_func_map {'' _empty_hwaddr_query 'bare' _bare_query 'bool' _bool_hwaddr_query 'int' _int_hwaddr_query 'cisco' _cisco_query 'eui48' _win_query 'linux' _linux_query 'pgsql' _postgresql_query 'postgresql' _postgresql_query 'psql' _postgresql_query 'unix' _unix_query 'win' _win_query}try v netaddr.EUI value except if query and query ! 'bool' raise errors.AnsibleFilterError alias + ' notahardwareaddress %s' % value extras []for arg in query_func_extra_args.get query tuple extras.append locals [arg] try return query_func_map[query] v *extras except KeyError raise errors.AnsibleFilterError alias + ' unknownfiltertype %s' % query return False
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def seconds s return float s / SEC_PER_DAY
def move source destination use_sudo False func use_sudo and run_as_root or run func '/bin/mv{0}{1}'.format quote source quote destination
def _expected_cols expected_attrs if not expected_attrs return expected_attrssimple_cols [attr for attr in expected_attrs if attr in _INSTANCE_OPTIONAL_JOINED_FIELDS ]complex_cols [ 'extra.%s' % field for field in _INSTANCE_EXTRA_FIELDS if field in expected_attrs ]if complex_cols simple_cols.append 'extra' simple_cols [x for x in simple_cols if x not in _INSTANCE_EXTRA_FIELDS ]expected_cols simple_cols + complex_cols return sorted list set expected_cols key expected_cols.index
def dblquad func a b gfun hfun args epsabs 1.49e-08 epsrel 1.49e-08 def temp_ranges *args return [gfun args[0] hfun args[0] ]return nquad func [temp_ranges [a b]] args args
def get_unicode_modules modules []try import codecsmodules.append 'codecs' except ImportError logger.error "Cannotdetectmodules'codecs'." return modules
def transferCoincidences network fromElementName toElementName coincidenceHandle getLockedHandle runtimeElement network.getElement fromElementName expression 'self._cd._W' network.getElement toElementName .setParameter 'coincidencesAbove' coincidenceHandle
def mergecfmfiles srclist dst architecture 'fat' srclist list srclist for i in range len srclist srclist[i] Carbon.File.pathname srclist[i] dst Carbon.File.pathname dst dstfile open dst 'wb' rf Res.FSpOpenResFile dst 3 try dstcfrg CfrgResource for src in srclist srccfrg CfrgResource src for frag in srccfrg.fragments if frag.architecture 'pwpc' and architecture 'm68k' continueif frag.architecture 'm68k' and architecture 'pwpc' continuedstcfrg.append frag frag.copydata dstfile cfrgres Res.Resource dstcfrg.build Res.UseResFile rf cfrgres.AddResource 'cfrg' 0 '' finally dstfile.close rf Res.CloseResFile rf
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def flocker_dataset_agent_main service_factory DatasetServiceFactory agent_script AgentScript service_factory service_factory.get_service options DatasetAgentOptions pr cProfile.Profile clock signal.signal signal.SIGUSR1 partial enable_profiling pr signal.signal signal.SIGUSR2 partial disable_profiling pr 'dataset' return FlockerScriptRunner script agent_script options options .main
def fgraph_updated_vars fgraph expanded_inputs updated_vars {}potential_values list fgraph.outputs if len expanded_inputs ! len fgraph.inputs raise ValueError 'expanded_inputsmustmatchlen fgraph.inputs ' for e_input ivar in reversed list zip expanded_inputs fgraph.inputs if e_input.update is not None updated_vars[ivar] potential_values.pop return updated_vars
def libvlc_media_player_get_title p_mi f _Cfunctions.get 'libvlc_media_player_get_title' None or _Cfunction 'libvlc_media_player_get_title' 1 None ctypes.c_int MediaPlayer return f p_mi
def _TryOpenSslImport try _ _package_dir _ imp.find_module 'OpenSSL' if not os.path.isfile os.path.join _package_dir 'crypto.py' or os.path.isfile os.path.join _package_dir 'crypto.so' or os.path.isdir os.path.join _package_dir 'crypto' raise ImportError 'NomodulenamedOpenSSL.crypto' returnexcept ImportError import OpenSSL.crypto
def rApply d f remainingDicts [ d ]while len remainingDicts > 0 current prevKeys remainingDicts.pop for k v in current.iteritems keys prevKeys + k if isinstance v dict remainingDicts.insert 0 v keys else f v keys
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def get_or_bust data_dict keys if isinstance keys basestring keys [keys]import ckan.logic.schema as schemaschema schema.create_schema_for_required_keys keys data_dict errors _validate data_dict schema if errors raise ValidationError errors values [data_dict[key] for key in keys]if len values 1 return values[0]return tuple values
def read_null_list start end addr_space return null_list read_addr_range start end addr_space end - start
def grammar grammar_type None grammar_name None def grammar_creator validator name def setter self value if isinstance grammar_type type tuple _assert_is_type validator.__name__ value grammar_type validator value self.grammar[name] valuedef getter self return self.grammar.get name None def deleter self if name in self.grammar del self.grammar[name]return property getter setter deleter validator.__doc__ if isinstance grammar_type type tuple def grammar_dec validator if grammar_name return grammar_creator validator grammar_name else return grammar_creator validator validator.__name__ return grammar_decelif isinstance grammar_name str_types def grammar_dec validator return grammar_creator validator grammar_name return grammar_decelse return grammar_creator grammar_type grammar_type.__name__
def read_worksheet xml_source parent preset_title string_table style_table workbook_name None sheet_codename None if workbook_name and sheet_codename ws IterableWorksheet parent preset_title workbook_name sheet_codename xml_source else ws Worksheet parent preset_title fast_parse ws xml_source string_table style_table return ws
def kneighbors_graph X n_neighbors mode 'connectivity' metric 'minkowski' p 2 metric_params None include_self False n_jobs 1 if not isinstance X KNeighborsMixin X NearestNeighbors n_neighbors metric metric p p metric_params metric_params n_jobs n_jobs .fit X else _check_params X metric p metric_params query _query_include_self X include_self return X.kneighbors_graph X query n_neighbors n_neighbors mode mode
def replace_opts rep_doc opts for key val in list opts.items rep_doc rep_doc.replace key val return rep_doc
def ShortenParameterNames params out {}for name value in params.iteritems short_name LONG_NAMES.get name name if short_name in out raise KeyError 'Bothlongandshortversionofparameter%s %s found.Itisunclearwhichonetouse.' % name short_name out[short_name] valuereturn out
def resolve1 x while isinstance x PDFObjRef x x.resolve return x
def _decode_embedded_dict src output {}for key val in six.iteritems src if isinstance val dict val _decode_embedded_dict val elif isinstance val list val _decode_embedded_list val elif isinstance val bytes try val val.decode except UnicodeError passif isinstance key bytes try key key.decode except UnicodeError passoutput[key] valreturn output
def getMinimumByPathComplex path minimum complex 999999999.0 999999999.0 for point in path minimum getMinimum minimum point return minimum
def humanBitSize size divisor 1000if size < divisor return ngettext '%ubit' '%ubits' size % size units [u'Kbit' u'Mbit' u'Gbit' u'Tbit']size float size for unit in units size size / divisor if size < divisor return '%.1f%s' % size unit return u'%u%s' % size unit
def getDiagonalSwitchedTetragrid angleDegrees diagonals unitPolar euclidean.getWiddershinsUnitPolar math.radians angleDegrees diagonalSwitchedTetragrid getIdentityMatrixTetragrid for diagonal in diagonals diagonalSwitchedTetragrid[diagonal][diagonal] unitPolar.realdiagonalSwitchedTetragrid[diagonals[0]][diagonals[1]] - unitPolar.imag diagonalSwitchedTetragrid[diagonals[1]][diagonals[0]] unitPolar.imagreturn diagonalSwitchedTetragrid
def get_anonymized_user return HMAC key config.WEB_SECRET msg get_user .digest [ 9].encode 'base64' .rstrip
def is_package dir_name if '.' in dir_name return Falsetry if not nt.stat dir_name return Falseexcept return Falsetry if '__init__.py' not in nt.listdir nt.getcwd + '\\' + dir_name return Falseexcept return Falsereturn True
def set_no_proxy_settings to_add ['127.0.0.1' 'localhost' '169.254.169.254']no_proxy os.environ.get 'no_proxy' '' if not no_proxy.strip no_proxy []else no_proxy no_proxy.split ' ' for host in to_add if host not in no_proxy no_proxy.append host os.environ['no_proxy'] ' '.join no_proxy
def get_static_welcome_message return '\n<h3>SearchHelp</h3>\n<ul><li>Thedisplaybelowthelineisanexampleoftheoutputthebrowser\nshowsyouwhenyouenterasearchword.Thesearchwordwas<b>green</b>.</li>\n<li>Thesearchresultshowsfordifferentpartsofspeechthe<b>synsets</b>\ni.e.differentmeaningsfortheword.</li>\n<li>Allunderlinedtextsarehypertextlinks.Therearetwotypesoflinks \nwordlinksandothers.Clickingawordlinkcarriesoutasearchfortheword\nintheWordnetdatabase.</li>\n<li>Clickingalinkoftheothertypeopensadisplaysectionofdataattached\ntothatlink.Clickingthatlinkasecondtimeclosesthesectionagain.</li>\n<li>Clicking<u>S </u>opensasectionshowingtherelationsforthatsynset.</li>\n<li>Clickingonarelationnameopensasectionthatdisplaystheassociated\nsynsets.</li>\n<li>Typeasearchwordinthe<b>NextWord</b>fieldandstartthesearchbythe\n<b>Enter/Return</b>keyorclickthe<b>Search</b>button.</li>\n</ul>\n'
def tag_regex tagname return dict open ' ? <\\s*% t s\\s+[^<>]*?>|<\\s*% t s\\s*> ' % dict t tagname close '</\\s*% t s\\s*>' % dict t tagname
def add_one i return i + 1
def get_target_list module action_parameter None exec_output exec_action module 'list' action_parameter action_parameter if not exec_output return Nonetarget_list []if isinstance exec_output list for item in exec_output target_list.append item.split None 1 [0] return target_listreturn None
def sdm_ecart f return sdm_deg f - sdm_monomial_deg sdm_LM f
def for_dtypes dtypes name 'dtype' def decorator impl @functools.wraps impl def test_func self *args **kw for dtype in dtypes try kw[name] dtypeimpl self *args **kw except Exception print name 'is' dtype raisereturn test_funcreturn decorator
def id_from_fasta_label_line line id_field line.split [0]id id_field.strip '>' return id
def _encode_long name value dummy0 dummy1 try return '\x12' + name + _PACK_LONG value except struct.error raise OverflowError 'BSONcanonlyhandleupto8-byteints'
def ValidateSourceReference ref repo_revision ref.split '#' 1 revision_id repo_revision[ -1 ]if not re.match SOURCE_REVISION_RE_STRING revision_id raise validation.ValidationError 'Badrevisionidentifier %s' % revision_id if len repo_revision 2 uri repo_revision[0]if not re.match SOURCE_REPO_RE_STRING uri raise validation.ValidationError 'BadrepositoryURI %s' % uri
def libvlc_media_player_get_fps p_mi f _Cfunctions.get 'libvlc_media_player_get_fps' None or _Cfunction 'libvlc_media_player_get_fps' 1 None ctypes.c_float MediaPlayer return f p_mi
def test_locale_html testfield Mock this_lang translation.get_language testfield.locale this_langs helpers.locale_html testfield assert not s 'nospecialHTMLattributesforsitelanguage'testfield.locale 'de's helpers.locale_html testfield assert s 'lang "de"dir "ltr"' for lang in settings.RTL_LANGUAGES testfield.locale langs helpers.locale_html testfield assert s 'lang "%s"dir "rtl"' % testfield.locale
@open_file 0 mode 'rb' def read_gexf path node_type None relabel False version '1.1draft' reader GEXFReader node_type node_type version version if relabel G relabel_gexf_graph reader path else G reader path return G
def idz_reconint idx proj return _id.idz_reconint idx proj
def eye size dtype None name None return variable np.eye size dtype name
def tokenize readline from itertools import chain repeat encoding consumed detect_encoding readline rl_gen iter readline '' empty repeat '' return _tokenize chain consumed rl_gen empty .__next__ encoding
def map_library_datasets_to_lddas trans lib_datasets lib_dataset_ids [x.library_dataset_dataset_association_id for x in lib_datasets]lddas trans.sa_session.query trans.app.model.LibraryDatasetDatasetAssociation .filter trans.app.model.LibraryDatasetDatasetAssociation.id.in_ lib_dataset_ids .all ret_lddas {}for ldda in lddas ret_lddas[ldda.library_dataset_id] lddareturn ret_lddas
def _SignedVarintEncoder local_chr chrdef EncodeSignedVarint write value if value < 0 value + 1 << 64 bits value & 127 value >> 7while value write local_chr 128 | bits bits value & 127 value >> 7return write local_chr bits return EncodeSignedVarint
def _fetch_vhd_image context session instance image_id LOG.debug _ 'Askingxapitofetchvhdimage% image_id s' locals instance instance params {'image_id' image_id 'uuid_stack' _make_uuid_stack 'sr_path' get_sr_path session }if _image_uses_bittorrent context instance plugin_name 'bittorrent'callback Noneparams['torrent_base_url'] CONF.xenapi_torrent_base_urlparams['torrent_seed_duration'] CONF.xenapi_torrent_seed_durationparams['torrent_seed_chance'] CONF.xenapi_torrent_seed_chanceparams['torrent_max_last_accessed'] CONF.xenapi_torrent_max_last_accessedparams['torrent_listen_port_start'] CONF.xenapi_torrent_listen_port_startparams['torrent_listen_port_end'] CONF.xenapi_torrent_listen_port_endparams['torrent_download_stall_cutoff'] CONF.xenapi_torrent_download_stall_cutoffparams['torrent_max_seeder_processes_per_host'] CONF.xenapi_torrent_max_seeder_processes_per_hostelse plugin_name 'glance'glance_api_servers glance.get_api_servers def pick_glance params g_host g_port g_use_ssl glance_api_servers.next params['glance_host'] g_hostparams['glance_port'] g_portparams['glance_use_ssl'] g_use_sslparams['auth_token'] getattr context 'auth_token' None callback pick_glancevdis _fetch_using_dom0_plugin_with_retry context session image_id plugin_name params callback callback sr_ref safe_find_sr session _scan_sr session sr_ref root_vdi_uuid vdis['root']['uuid']set_vdi_name session root_vdi_uuid instance['name'] 'root' _check_vdi_size context session instance root_vdi_uuid return vdis
def is_select_query query return not RE_SELECT_QUERY.match query.upper
def filebrowser_view view return staff_member_required never_cache view
def blend_channels_screen bottom_chan top_chan return 1 - 1 - bottom_chan[ ] * 1 - top_chan[ ]
def get_config_by_name section name for config in section if config['name'] name return configreturn None
def pde_separate_mul eq fun sep return pde_separate eq fun sep strategy 'mul'
def reply journalist source num_replies assert num_replies > 1 replies []for _ in range num_replies source.interaction_count + 1fname '{}-{}-reply.gpg'.format source.interaction_count source.journalist_filename crypto_util.encrypt str os.urandom 1 [crypto_util.getkey source.filesystem_id config.JOURNALIST_KEY] store.path source.filesystem_id fname reply db.Reply journalist source fname replies.append reply db.db_session.add reply db.db_session.commit return replies
def remove_rich_rule zone rule permanent True cmd "--zone {0}--remove-rich-rule '{1}'".format zone rule if permanent cmd + '--permanent'return __firewall_cmd cmd
def my_queries request DEFAULT_PAGE_SIZE 30app_name get_app_name request prefix 'h-'querydict_history _copy_prefix prefix request.GET querydict_history[ prefix + 'user' ] request.userquerydict_history[ prefix + 'type' ] app_name hist_page hist_filter _list_query_history request.user querydict_history DEFAULT_PAGE_SIZE prefix prefix 'q-'querydict_query _copy_prefix prefix request.GET querydict_query[ prefix + 'user' ] request.userquerydict_query[ prefix + 'type' ] app_name query_page query_filter _list_designs request.user querydict_query DEFAULT_PAGE_SIZE prefix filter_params hist_filterfilter_params.update query_filter return render 'my_queries.mako' request {'request' request 'h_page' hist_page 'q_page' query_page 'filter_params' filter_params 'designs_json' json.dumps [query.id for query in query_page.object_list] }
def list_scrubber_opts return [ g copy.deepcopy o for g o in _scrubber_opts]
def DihedralGroup n if n 1 return PermutationGroup [Permutation [1 0] ] if n 2 return PermutationGroup [Permutation [1 0 3 2] Permutation [2 3 0 1] Permutation [3 2 1 0] ] a list range 1 n a.append 0 gen1 _af_new a a list range n a.reverse gen2 _af_new a G PermutationGroup [gen1 gen2] if n & n - 1 0 G._is_nilpotent Trueelse G._is_nilpotent FalseG._is_abelian FalseG._is_solvable TrueG._degree nG._is_transitive TrueG._order 2 * n return G
def check_paypal_id name d dict version settings.PAYPAL_API_VERSION buttoncode 'cleartext' buttontype 'donate' method 'BMCreateButton' l_buttonvar0 'business %s' % name d['user'] settings.PAYPAL_EMBEDDED_AUTH['USER']d['pwd'] settings.PAYPAL_EMBEDDED_AUTH['PASSWORD']d['signature'] settings.PAYPAL_EMBEDDED_AUTH['SIGNATURE']r requests.get settings.PAYPAL_API_URL params d timeout 10 response dict urlparse.parse_qsl r.text valid response['ACK'] 'Success' msg None if valid else response['L_LONGMESSAGE0'] return valid msg
def iter_traceback_frames tb while tb and hasattr tb 'tb_frame' f_locals getattr tb.tb_frame 'f_locals' {} if not _getitem_from_frame f_locals '__traceback_hide__' yield tb.tb_frame getattr tb 'tb_lineno' None tb tb.tb_next
def body request return HttpResponse request.body
def _approximate_mode class_counts n_draws rng continuous n_draws * class_counts / class_counts.sum floored np.floor continuous need_to_add int n_draws - floored.sum if need_to_add > 0 remainder continuous - floored values np.sort np.unique remainder [ -1 ]for value in values inds np.where remainder value add_now min len inds need_to_add inds choice inds size add_now replace False random_state rng floored[inds] + 1need_to_add - add_nowif need_to_add 0 breakreturn floored.astype np.int
def test_sobel_v_horizontal i j np.mgrid[ -5 6 -5 6]image i > 0 .astype float result filters.sobel_v image assert_allclose result 0
def _stop_on_read fd _triggered.clear fdref CFFileDescriptorCreate None fd False _c_input_callback None CFFileDescriptorEnableCallBacks fdref kCFFileDescriptorReadCallBack source CFFileDescriptorCreateRunLoopSource None fdref 0 loop CFRunLoopGetCurrent CFRunLoopAddSource loop source kCFRunLoopCommonModes CFRelease source
def _formatExample example substitutions yield u'**Example **{}'.format example.doc yield u'' yield u'Request' yield u'' yield u'..sourcecode http' yield u'' lines example.request % substitutions .splitlines lines.insert 1 u'Content-Type application/json' lines.insert 1 u'Host api.% DOMAIN s' % substitutions for line in lines yield u'' + line.rstrip yield u'' yield u'Response' yield u'' yield u'..sourcecode http' yield u'' lines example.response % substitutions .splitlines lines.insert 1 u'Content-Type application/json' for line in lines yield u'' + line.rstrip yield u''
def get_prop_filter_spec client_factory obj_spec prop_spec prop_filter_spec client_factory.create 'ns0 PropertyFilterSpec' prop_filter_spec.propSet prop_specprop_filter_spec.objectSet obj_specreturn prop_filter_spec
def create_tree_folders folderName if os.path.exists folderName raise NinjaIOException u'Thefolderalreadyexist' os.makedirs folderName
def trimone x front 0 back 0 axis 0 shape np.array x.shape shape[axis] - front + back shapearr np.array x.shape startind np.zeros x.ndim startind[axis] frontendind startind + shape myslice [slice startind[k] endind[k] for k in range len endind ]return x[tuple myslice ]
def BytesEncoder field_number is_repeated is_packed tag TagBytes field_number wire_format.WIRETYPE_LENGTH_DELIMITED local_EncodeVarint _EncodeVarintlocal_len lenassert not is_packed if is_repeated def EncodeRepeatedField write value for element in value write tag local_EncodeVarint write local_len element write element return EncodeRepeatedFieldelse def EncodeField write value write tag local_EncodeVarint write local_len value return write value return EncodeField
def drt_discourse_demo reading_command None dt DiscourseTester ['everydogchasesaboy' 'heruns'] reading_command dt.models print dt.sentences print dt.readings print dt.readings show_thread_readings True print dt.readings filter True show_thread_readings True
def _patchTextFileLogObserver patch logFiles []oldFileLogObserver logger.textFileLogObserverdef observer logFile *args **kwargs logFiles.append logFile return oldFileLogObserver logFile *args **kwargs patch logger 'textFileLogObserver' observer return logFiles
def _parseClientTLS reactor host port timeout '30' bindAddress None certificate None privateKey None trustRoots None endpoint None **kwargs if kwargs raise TypeError 'unrecognizedkeywordargumentspresent' list kwargs.keys host host if isinstance host unicode else host.decode 'utf-8' bindAddress bindAddress if isinstance bindAddress unicode or bindAddress is None else bindAddress.decode 'utf-8' port int port timeout int timeout return wrapClientTLS optionsForClientTLS host trustRoot _parseTrustRootPath trustRoots clientCertificate _privateCertFromPaths certificate privateKey clientFromString reactor endpoint if endpoint is not None else HostnameEndpoint reactor _idnaBytes host port timeout bindAddress
def set_power_state state utils.write_one_line '/sys/power/state' state
def rax_find_bootable_volume module rax_module server exit True cs rax_module.cloudserverscbs rax_module.cloud_blockstorageserver_id rax_module.utils.get_id server volumes cs.volumes.get_server_volumes server_id bootable_volumes []for volume in volumes vol cbs.get volume if module.boolean vol.bootable bootable_volumes.append vol if not bootable_volumes if exit module.fail_json msg 'Nobootablevolumescouldbefoundforserver%s' % server_id else return Falseelif len bootable_volumes > 1 if exit module.fail_json msg 'Multiplebootablevolumesfoundforserver%s' % server_id else return Falsereturn bootable_volumes[0]
def random_name size 6 chars string.ascii_uppercase + string.digits return 'test-' + ''.join random.choice chars for x in range size
def quantify iterable pred bool return sum imap pred iterable
def get_owner obj_name security_descriptor win32security.GetFileSecurity obj_name win32security.OWNER_SECURITY_INFORMATION owner_sid security_descriptor.GetSecurityDescriptorOwner return get_name win32security.ConvertSidToStringSid owner_sid
def pct_total_area image percentile 0.8 idx int image.size - 1 * percentile sorted_pixels np.sort image.flat return sorted_pixels[idx]
def median_from_dict total count pos total - 1 / 2 for k in sorted six.iterkeys count if pos < count[k] return kpos - count[k]
def make_flat_dict name selector None subselector None ns None if ns is None elemname nametagname Selector 0 else elemname '{%s}%s' % ns name tagname lambda obj do_raise False '{%s}%s' % ns obj[0] if selector is None selector nameroot TemplateElement elemname selector selector subselector subselector elem SubTemplateElement root tagname selector get_items elem.text 1return root
def cloudformation registry xml_parent data region_dict helpers.cloudformation_region_dict stacks helpers.cloudformation_init xml_parent data 'CloudFormationPostBuildNotifier' for stack in data.get 'create-stacks' [] helpers.cloudformation_stack xml_parent stack 'PostBuildStackBean' stacks region_dict delete_stacks helpers.cloudformation_init xml_parent data 'CloudFormationNotifier' for delete_stack in data.get 'delete-stacks' [] helpers.cloudformation_stack xml_parent delete_stack 'SimpleStackBean' delete_stacks region_dict
def get_gem_classified df fd.get_stock_basics df.reset_index level 0 inplace True df df[ct.FOR_CLASSIFY_B_COLS]df df.ix[ df.code.str[0] '3' ]df df.sort 'code' .reset_index drop True return df
def linereader f while 1 line f.readline if not line break yield line[ -1 ]
def parse_treasury_csv_column column column_re re.compile '^ ?P<prefix>RIFLGFC ?P<unit>[YM] ?P<periods>[0-9]{2} ?P<suffix>_N.B $' match column_re.match column if match is None raise ValueError "Couldn'tparseCSVcolumn%r." % column unit periods get_unit_and_periods match.groupdict return str int periods + 'year' if unit 'Y' else 'month'
def radio text u'' tooltip u'' checked None return _checkbox QtWidgets.QRadioButton text tooltip checked
def post_gist content description '' filename 'file' auth False post_data json.dumps {'description' description 'public' True 'files' {filename {'content' content}}} .encode 'utf-8' headers make_auth_header if auth else {} response requests.post 'https //api.github.com/gists' data post_data headers headers response.raise_for_status response_data json.loads response.text return response_data['html_url']
def import_no_clients_in_api_and_scenario_tests physical_line filename if 'tempest/api' in filename or 'tempest/scenario' in filename res PYTHON_CLIENT_RE.match physical_line if res return physical_line.find res.group 1 'T102 pythonclientsimportnotallowedintempest/api/*ortempest/scenario/*tests'
def page_not_found request template_name '404.html' t loader.get_template template_name return http.HttpResponseNotFound t.render RequestContext request {'request_path' request.path}
def _reshape_2D X if hasattr X u'shape' if len X.shape 1 if hasattr X[0] u'shape' X list X else X [X]elif len X.shape 2 nrows ncols X.shapeif nrows 1 X [X]elif ncols 1 X [X.ravel ]else X [X[ i] for i in xrange ncols ]else raise ValueError u'input`X`musthave2orfewerdimensions' if not hasattr X[0] u'__len__' X [X]else X [np.ravel x for x in X]return X
def test_load_mappings_warnings tempdir app status warning inv_file tempdir / 'inventory' inv_file.write_bytes inventory_v2 app.config.intersphinx_mapping {'https //docs.python.org/' inv_file 'py3k' 'https //docs.python.org/py3k/' inv_file 'repoze.workflow' 'http //docs.repoze.org/workflow/' inv_file 'django-taggit' 'http //django-taggit.readthedocs.org/en/latest/' inv_file 12345 'http //www.sphinx-doc.org/en/stable/' inv_file }app.config.intersphinx_cache_limit 0load_mappings app assert warning.getvalue .count '\n' 1
def get_enterprise_customer_logo_url request if not enterprise_enabled return Noneparameter get_enterprise_branding_filter_param request if not parameter return Noneprovider_id parameter.get 'provider_id' None ec_uuid parameter.get 'ec_uuid' None if provider_id branding_info enterprise_api.get_enterprise_branding_info_by_provider_id provider_id provider_id elif ec_uuid branding_info enterprise_api.get_enterprise_branding_info_by_ec_uuid ec_uuid ec_uuid logo_url Noneif branding_info and branding_info.logo logo_url branding_info.logo.urlreturn logo_url
def plot_occlusion net X target square_length 7 figsize 9 None return _plot_heat_map net X figsize lambda net X n occlusion_heatmap net X target[n] square_length
@ssl_required@require_POSTdef logout request auth.logout request statsd.incr 'user.logout' res HttpResponseRedirect get_next_url request or reverse 'home' res.delete_cookie settings.SESSION_EXISTS_COOKIE return res
def init_logging options log_file options['log_basename'] + '.log' log_dir options['log_dir']log_config {'version' 1 'disable_existing_loggers' True 'formatters' {'timestamped' {'format' '% asctime s% message s' 'datefmt' '%H %M %S'}} 'handlers' {'console' {'level' 'WARNING' 'class' 'logging.StreamHandler' 'formatter' 'timestamped'} 'file' {'level' 'DEBUG' 'class' 'logging.FileHandler' 'formatter' 'timestamped' 'filename' os.path.join log_dir log_file 'mode' 'w'}} 'loggers' {'' {'level' 'DEBUG' 'handlers' ['console' 'file']}}}logging.config.dictConfig log_config
def get_spot_config vm_ return config.get_cloud_config_value 'spot_config' vm_ __opts__ search_global False
def dehydrate_content_ratings content_ratings for body in content_ratings or {} content_ratings[body] dehydrate_content_rating content_ratings[body] return content_ratings
def get_updated_changeset_revisions app name owner changeset_revision repository tool_shed.util.repository_util.get_repository_by_name_and_owner app name owner repo hg_util.get_repo_for_repository app repository repository repo_path None create False upper_bound_changeset_revision get_next_downloadable_changeset_revision repository repo changeset_revision changeset_hashes []for changeset in hg_util.reversed_lower_upper_bounded_changelog repo changeset_revision upper_bound_changeset_revision if changeset ! upper_bound_changeset_revision changeset_hashes.append str repo.changectx changeset if changeset_hashes changeset_hashes_str ' '.join changeset_hashes return changeset_hashes_strreturn ''
def runLengthDecode stream decodedStream ''index 0try while index < len stream length ord stream[index] if length > 0 and length < 128 decodedStream + stream[ index + 1 index + length + 2 ]index + length + 2 elif length > 128 and length < 256 decodedStream + stream[ index + 1 ] * 257 - length index + 2else breakexcept return -1 'Errordecodingstring' return 0 decodedStream
def list2hexstr intlist intsize 4 result ''for value in intlist if isinstance value str result + valueelse result + int2hexstr value intsize return result
def onlyPy279OrNewer test @functools.wraps test def wrapper *args **kwargs msg '{name}requiresPython2.7.9+torun'.format name test.__name__ if sys.version_info < 2 7 9 raise SkipTest msg return test *args **kwargs return wrapper
def stripHTMLMedia s s reMedia.sub '\\1' s return stripHTML s
def _ResolveParent path base_path_components depth 0while path.startswith '../' depth + 1path path[3 ]if depth > len base_path_components return ''if depth len base_path_components return pathreturn '/'.join base_path_components[0 len base_path_components - depth ] + '/' + path
def _get_rcscript name jail None cmd '{0}-r'.format _cmd jail prf _get_jail_path jail if jail else '' for line in __salt__['cmd.run_stdout'] cmd python_shell False .splitlines if line.endswith '{0}{1}'.format os.path.sep name return os.path.join prf line.lstrip os.path.sep return None
def test_positive_integer_3 try positive_integer 'foobar' assert Falseexcept Exception pass
def filter_private_variable scope origin_node instance scope.get_parent_scope coming_from origin_nodewhile coming_from is not None and not isinstance coming_from tree.Class compiled.CompiledObject coming_from coming_from.get_parent_scope if isinstance instance compiled.CompiledObject return instance ! coming_from else return isinstance instance er.Instance and instance.base.base ! coming_from
def convert_Ti_to_FLX sff_fp output_fp use_sfftools False if use_sfftools _fail_on_gzipped_sff sff_fp check_sfffile _check_call ['sfffile' '-flx' '-o' output_fp sff_fp] stdout open devnull 'w' else header reads adjust_sff_cycles parse_binary_sff qiime_open sff_fp 'rb' True 100 write_binary_sff open output_fp 'w' header reads
def _api_resume_pp name output kwargs PostProcessor.do.paused Falsereturn report output
def load_stop_words stop_word_file stop_words []for line in open stop_word_file if line.strip [0 1] ! '#' for word in line.split stop_words.append word return stop_words
def check_feature_file features_dir feature_name return os.path.exists os.path.join features_dir feature_name + '.feature'
def set_clean using None if using is None using DEFAULT_DB_ALIASthread_ident thread.get_ident if thread_ident in dirty and using in dirty[thread_ident] dirty[thread_ident][using] Falseelse raise TransactionManagementError "Thiscodeisn'tundertransactionmanagement" clean_savepoints using using
def _nested_output obj nested.__opts__ __opts__ret nested.output obj .rstrip return ret
def do_topic_action topics user action reverse from flaskbb.utils.requirements import IsAtleastModeratorInForum CanDeleteTopicfrom flaskbb.user.models import Userfrom flaskbb.forum.models import Postif not Permission IsAtleastModeratorInForum forum topics[0].forum flash _ 'Youdonothavethepermissionstoexecutethisaction.' 'danger' return Falsemodified_topics 0if action ! 'delete' for topic in topics if getattr topic action and not reverse continuesetattr topic action not reverse modified_topics + 1topic.save elif action 'delete' for topic in topics if not Permission CanDeleteTopic flash _ 'Youdonothavethepermissionstodeletethistopic.' 'danger' return Falseinvolved_users User.query.filter Post.topic_id topic.id User.id Post.user_id .all modified_topics + 1topic.delete involved_users return modified_topics
def generate_desc from_commit to_commit changelog if from_commit.startswith to_commit desc 'Pushing{0}again'.format to_commit else bugs extract_bugs changelog.split '\n' if bugs bugs ['bug#{0}'.format bug for bug in bugs]desc 'Fixing {0}'.format ' '.join bugs else desc get_random_desc return desc
def dmp_eject f u K front False f h dmp_to_dict f u {} n K.ngensv u - K.ngens + 1 for monom c in f.items if front g_monom f_monom monom[ n] monom[n ] else g_monom f_monom monom[ - n ] monom[ - n ] if f_monom in h h[f_monom][g_monom] celse h[f_monom] {g_monom c}for monom c in h.items h[monom] K c return dmp_from_dict h v - 1 K
def _parse_exchange_token_response content resp {}content _helpers._from_bytes content try resp json.loads content except Exception resp _helpers.parse_unique_urlencoded content if resp and 'expires' in resp resp['expires_in'] resp.pop 'expires' return resp
def get_library_dirs from os.path import join dirname abspath pardirbase dirname __file__ parent abspath join base pardir return [join parent base ]
def ReadIntoObject buff index value_obj length 0 raw_data value_obj.GetRawData count 0for encoded_tag encoded_length encoded_field in SplitBuffer buff index index length length type_info_obj value_obj.type_infos_by_encoded_tag.get encoded_tag wire_format encoded_tag encoded_length encoded_field if type_info_obj is None raw_data[count] None wire_format None count + 1elif type_info_obj.__class__ is ProtoList value_obj.Get type_info_obj.name .wrapped_list.append None wire_format else raw_data[type_info_obj.name] None wire_format type_info_obj value_obj.SetRawData raw_data
@pytest.mark.parametrize u'model_class' u'mode' list itertools.product test_models_2D modes def test_pixel_sum_2D model_class mode if model_class Box2D and mode u'center' pytest.skip u'Nonintegratingmode.Skipintegraltest.' parameters models_2D[model_class]model create_model model_class parameters values discretize_model model models_2D[model_class][u'x_lim'] models_2D[model_class][u'y_lim'] mode mode assert_allclose values.sum models_2D[model_class][u'integral'] atol 0.0001
def openAllU3 returnDict dict for i in range deviceCount 3 d U3 firstFound False devNumber i + 1 returnDict[str d.serialNumber ] dreturn returnDict
def dashboard return s3_rest_controller 's3' 'dashboard'
def ascii str if type str ! type '' return map ascii str rv ''for c in str if c in ' DCTB ' '\n' '\r' or '' < c < chr 127 rv rv + c else rv rv + '\\' + 'x%02.2x' % ord c return rv
def p_external_declaration_1 t pass
def getMetricFromPath filePath data_dir os.path.normpath settings.LOCAL_DATA_DIR + os.sep metric_name filePath.replace data_dir '' metric_name metric_name.replace '.wsp' '' metric_name metric_name.replace '/' '.' return metric_name
def arbitrary_n module_name func_name args kwargs {} notification lambda x y y if module_name.startswith 'calibre_plugins' from calibre.customize.ui import find_pluginfind_pluginmodule importlib.import_module module_name func getattr module func_name kwargs['notification'] notificationreturn func *args **kwargs
def get_entry_size context set_type llty context.get_data_type types.SetEntry set_type return context.get_abi_sizeof llty
def _escapify qstring text ''for c in qstring if c in __escaped text + '\\' + c elif ord c > 32 and ord c < 127 text + celse text + '\\%03d' % ord c return text
def get_archive_tarball_name source_dir tarball_name compression if tarball_name is None tarball_name os.path.basename source_dir if not tarball_name.endswith '.tar' tarball_name '%s.tar' % tarball_name if compression and not tarball_name.endswith '.%s' % compression tarball_name '%s.%s' % tarball_name compression return tarball_name
def perm_is_defined_on perm obj return Permission.objects.filter codename perm content_type ContentType.objects.get_for_model obj .pk object_id obj.pk approved True .exists
def locale_display_name locale if not locale raise KeyErrorif locale.lower in languages v languages[locale.lower ]return v['English'] v['native'] else hyphen locale.rfind '-' if hyphen -1 raise KeyErrorelse return locale_display_name locale[ hyphen]
def dvr_case_status_filter_opts closed None table current.s3db.dvr_case_statusquery table.deleted ! True if closed is not None if closed query & table.is_closed True else query & table.is_closed False | table.is_closed None rows current.db query .select table.id table.name orderby 'workflow_position' if not rows return {}T current.Treturn OrderedDict row.id T row.name for row in rows
def get_error_message error try return error.args[0]except IndexError return ''
def get_field_with_path model name return_remote_proxy_attr True path []if isinstance name string_types current_model modelvalue Nonefor attribute in name.split '.' value getattr current_model attribute if is_association_proxy value relation_values value.attrif return_remote_proxy_attr value value.remote_attrelse relation_values [value]for relation_value in relation_values if is_relationship relation_value current_model relation_value.property.mapper.class_table current_model.__table__if need_join model table path.append relation_value attr valueelse attr nameif isinstance attr InstrumentedAttribute or is_association_proxy attr columns get_columns_for_field attr if len columns > 1 raise Exception 'Canonlyhandleonecolumnfor%s' % name column columns[0]if need_join model column.table path.append column.table return attr path
def mysql_to_dict data key ret {}headers ['']for line in data if not line continueif line.startswith '+' continuecomps line.split '|' for comp in range len comps comps[comp] comps[comp].strip if len headers > 1 index len headers - 1 row {}for field in range index if field < 1 continueelse row[headers[field]] str_to_num comps[field] ret[row[key]] rowelse headers compsreturn ret
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def _get_pks_model_and_ctype objects if isinstance objects QuerySet model objects.modelpks [force_text pk for pk in objects.values_list u'pk' flat True ]ctype get_content_type model else pks []for idx obj in enumerate objects if not idx model type obj ctype get_content_type model pks.append force_text obj.pk return pks model ctype
def decode encoding None default_encoding 'utf-8' body cherrypy.request.bodyif encoding is not None if not isinstance encoding list encoding [encoding]body.attempt_charsets encodingelif default_encoding if not isinstance default_encoding list default_encoding [default_encoding]body.attempt_charsets body.attempt_charsets + default_encoding
def search_code query sort None order None per_page None text_match False number -1 etag None return gh.search_code query sort order per_page text_match number etag
def _setup_constants alphabet NAMESPACE_CHARACTERS max_length MAX_NAMESPACE_LENGTH global NAMESPACE_CHARACTERSglobal MAX_NAMESPACE_LENGTHglobal MAX_NAMESPACEglobal _LEX_DISTANCENAMESPACE_CHARACTERS alphabetMAX_NAMESPACE_LENGTH max_lengthMAX_NAMESPACE NAMESPACE_CHARACTERS[ -1 ] * MAX_NAMESPACE_LENGTH _LEX_DISTANCE [1]for i in range 1 MAX_NAMESPACE_LENGTH _LEX_DISTANCE.append _LEX_DISTANCE[ i - 1 ] * len NAMESPACE_CHARACTERS + 1 del i
def vtk_version global _vtk_versionreturn _vtk_version
def get_module_path modname return osp.abspath osp.dirname sys.modules[modname].__file__
def _name_from_project_path path project template if isinstance template str template re.compile template match template.match path if not match raise ValueError 'path"%s"didnotmatchexpectedpattern"%s"' % path template.pattern if project is not None found_project match.group 'project' if found_project ! project raise ValueError 'Projectfromclient %s shouldagreewithprojectfromresource %s .' % project found_project return match.group 'name'
def dup_trial_division f factors K result []for factor in factors k 0while True q r dup_div f factor K if not r f k q k + 1 else breakresult.append factor k return _sort_factors result
def htmlparser_trace data parser AnnouncingParser parser.feed data
def verify_exists_urls existing_urls def decorator func @wraps func def wrapper *args **kwargs from django.core import validatorsoriginal_open validators.urllib2.OpenerDirector.opendef custom_open self req data None timeout None if req.get_full_url in existing_urls return Trueraise Exception try urllib2.OpenerDirector.open custom_openfunc *args **kwargs finally validators.urllib2.OpenerDirector.open original_openreturn wrapperreturn decorator
def verify_signatures params signed_fields_key 'signedFields' full_sig_key 'signedDataPublicSignature' signed_fields params.get signed_fields_key '' .split ' ' data u' '.join [u'{0} {1}'.format k params.get k '' for k in signed_fields] signed_fields_sig processor_hash params.get signed_fields_key '' data + u' signedFieldsPublicSignature ' + signed_fields_sig returned_sig params.get full_sig_key '' if processor_hash data ! returned_sig raise CCProcessorSignatureException
def _hashing_map binary_record proto file_service_pb.KeyValue proto.ParseFromString binary_record yield proto.key proto.value
def rdoc num_elements 1000 tag_names ['p' 'div' 'span' 'i' 'b' 'script' 'table']elements []for i in range num_elements choice random.randint 0 3 if choice 0 tag_name random.choice tag_names elements.append '<%s>' % tag_name elif choice 1 elements.append rsentence random.randint 1 4 elif choice 2 tag_name random.choice tag_names elements.append '</%s>' % tag_name return '<html>' + '\n'.join elements + '</html>'
@blueprint.route '/projects/<project>/meters/<meter>/volume/max' def compute_project_volume_max project meter check_authorized_project project return _get_statistics 'max' project project meter meter
def normalize_trace_output output output re.sub '\\[[0-9]+refs\\]' '' output try result [row.split ' DCTB ' for row in output.splitlines if row and not row.startswith '#' ]result.sort key lambda row int row[0] result [row[1] for row in result]return '\n'.join result except IndexError ValueError raise AssertionError 'tracerproducedunparseableoutput \n{}'.format output
def run_hive args check_return_code True cmd load_hive_cmd + args p subprocess.Popen cmd stdout subprocess.PIPE stderr subprocess.PIPE stdout stderr p.communicate if check_return_code and p.returncode ! 0 raise HiveCommandError 'Hivecommand {0}failedwitherrorcode {1}'.format ''.join cmd p.returncode stdout stderr return stdout
def RedisCache redis_conn None debug False with_lock False fail_gracefully False db None locker.acquire try instance_name 'redis_instance_' + current.request.application if not hasattr RedisCache instance_name setattr RedisCache instance_name RedisClient redis_conn redis_conn debug debug with_lock with_lock fail_gracefully fail_gracefully return getattr RedisCache instance_name finally locker.release
def getCubicPathByBeginEnd begin controlPoints elementNode end return svg_reader.getCubicPoints begin controlPoints end lineation.getNumberOfBezierPoints begin elementNode end
def groupsstats_1d y x labelsunique labelmeans np.array ndimage.mean x labels y index labelsunique labelvars np.array ndimage.var x labels y index labelsunique return labelmeans labelvars
def validate_string option value if isinstance value string_type return valueraise TypeError 'Wrongtypefor%s valuemustbeaninstanceof%s' % option string_type.__name__
def roberts_pos_diag image mask None assert_nD image 2 image img_as_float image result convolve image ROBERTS_PD_WEIGHTS return _mask_filter_result result mask
def get_github_auth_id username password note response requests.get u'https //api.github.com/authorizations' auth username password headers {u'User-Agent' u'edx-release'} if not response.ok message response.json [u'message']raise requests.exceptions.RequestException message for auth_token in response.json if auth_token[u'note'] u'edx-release' return auth_token[u'id']return None
def b0_indices in_bval max_b 10.0 import numpy as npbval np.loadtxt in_bval return np.argwhere bval < max_b .flatten .tolist
def _add_additional_response_fields request serialized_discussion_entities usernames discussion_entity_type include_profile_image if include_profile_image username_profile_dict _get_user_profile_dict request usernames ' '.join usernames for discussion_entity in serialized_discussion_entities discussion_entity['users'] _get_users discussion_entity_type discussion_entity username_profile_dict return serialized_discussion_entities
def forget func *xs return Forget func *xs
def _parse_date_mssql dateString m _mssql_date_re.match dateString if not m returnw3dtfdate '% year s-% month s-% day sT% hour s % minute s % second s% zonediff s' % {'year' m.group 1 'month' m.group 2 'day' m.group 3 'hour' m.group 4 'minute' m.group 5 'second' m.group 6 'zonediff' '+09 00'} if _debug sys.stderr.write 'MSSQLdateparsedas %s\n' % w3dtfdate return _parse_date_w3dtf w3dtfdate
def is_strictly_increasing f interval S.Reals symbol None f sympify f free_sym f.free_symbolsif symbol is None if len free_sym > 1 raise NotImplementedError 'is_strictly_increasinghasnotyetbeenimplementedforallmultivariateexpressions' elif len free_sym 0 return Falsesymbol free_sym.pop df f.diff symbol df_pos_interval solveset df > 0 symbol domain S.Reals return interval.is_subset df_pos_interval
def find_attribute_in_tag block offset attr_name end_block boundary next_tag_boundary block offset if boundary.is_start return None None end_offset boundary.offsetend_pos end_block.blockNumber end_offset current_block current_offset block offset found_attr Falsewhile True current_block boundary next_attr_boundary current_block current_offset if current_block is None or current_block.blockNumber boundary.offset > end_pos return None None current_offset boundary.offsetif found_attr if boundary.type is not ATTR_VALUE or boundary.data is not ATTR_START return None None return current_block current_offset else if boundary.type is ATTR_NAME and boundary.data.lower attr_name.lower found_attr Truecurrent_offset + 1
def pause_trace return replace_trace
def replace_new_vars expr id_to_new_var if expr.type lo.VARIABLE and expr.data in id_to_new_var return id_to_new_var[expr.data]else new_args []for arg in expr.args new_args.append replace_new_vars arg id_to_new_var return lo.LinOp expr.type expr.size new_args expr.data
def mask_to_positions maskstring return nonzero array map int maskstring [0]
def create_template_register return django.template.Library
def multisig_type wallet_type match re.match ' \\d+ of \\d+ ' wallet_type if match match [int x for x in match.group 1 2 ]return match
def chebyt n monic False if n < 0 raise ValueError 'nmustbenonnegative.' wfunc lambda x 1.0 / sqrt 1 - x * x if n 0 return orthopoly1d [] [] pi 1.0 wfunc -1 1 monic lambda x eval_chebyt n x n1 n x w mu roots_chebyt n1 mu True hn pi / 2 kn 2 ** n - 1 p orthopoly1d x w hn kn wfunc -1 1 monic lambda x eval_chebyt n x return p
def StudentT name nu return rv name StudentTDistribution nu
def make_collectstatic statuses []hue_exec os.path.join common.INSTALL_ROOT 'build' 'env' 'bin' 'hue' if os.path.exists hue_exec statuses.append runcmd [hue_exec 'collectstatic' '--noinput'] return not any statuses
def movavg x n w np.empty n dtype float w[ ] 1.0 / n return np.convolve x w mode u'valid'
def getNewMouseTool return ZoomOut
def index_to_month index return index // 12 + 1 index % 12 + 1
@compositedef related_deployments_strategy draw number_of_deployments node_uuid_pool draw node_uuid_pool_strategy deployments set while True deployments.add draw deployment_strategy node_uuid_pool node_uuid_pool if len deployments number_of_deployments return tuple deployments
def mangle_c ident argtys return PREFIX + mangle_identifier ident + mangle_args_c argtys
def getManipulatedGeometryOutput geometryOutput xmlElement scalePoints matrix.getConnectionVertexes geometryOutput 'scale.' xmlElement return geometryOutput
def convert_user_name_or_id_to_id user_name_or_id context session context['session']result session.query model.User .filter_by id user_name_or_id .first if not result result session.query model.User .filter_by name user_name_or_id .first if not result raise df.Invalid '%s %s' % _ 'Notfound' _ 'User' return result.id
def s3_include_debug_css request current.requestfolder request.folderappname request.applicationsettings current.deployment_settingstheme settings.get_theme location current.response.s3.theme_locationcss_cfg '%s/modules/templates/%s%s/css.cfg' % folder location theme try f open css_cfg 'r' except raise HTTP 500 'Themeconfigurationfilemissing modules/templates/%s%s/css.cfg' % location theme files f.readlines files files[ -1 ]include ''for file in files if file[0] ! '#' include '%s\n<linkhref "/%s/static/styles/%s"rel "stylesheet"type "text/css"/>' % include appname file[ -1 ] f.close return XML include
def _get_n_jobs n_jobs if n_jobs < 0 return max cpu_count + 1 + n_jobs 1 elif n_jobs 0 raise ValueError 'Parametern_jobs 0hasnomeaning.' else return n_jobs
def _portal_maintenance now time.time reason 'Idletimeoutexceeded disconnecting.'for session in [sess for sess in PORTAL_SESSIONS.values if now - sess.cmd_last > _IDLE_TIMEOUT ] session.disconnect reason reason PORTAL_SESSIONS.disconnect session
def wait_for_occupied_port host port if not host raise ValueError "Hostvaluesof''orNonearenotallowed." for trial in range 50 try check_port host port except IOError returnelse time.sleep 0.1 raise IOError 'Port%rnotboundon%r' % port host
def show_interfaces resolve_mac True return ifaces.show resolve_mac
def fromstring data beautifulsoup None makeelement None **bsargs return _parse data beautifulsoup makeelement **bsargs
@profiledef test body file OUTPUT_FILE .read url URL 'http //www.clarin.com.ar/' headers Headers headers['content-type'] 'text/html'response HTTPResponse 200 body headers url url charset 'utf-8' p HTMLParser response del p
def test_url_completion_delete_bookmark qtmodeltester config_stub web_history quickmarks bookmarks qtbot config_stub.data['completion'] {'timestamp-format' '%Y-%m-%d' 'web-history-max-items' 2}model urlmodel.UrlCompletionModel qtmodeltester.data_display_may_return_none Trueqtmodeltester.check model view _mock_view_index model 1 0 qtbot model.delete_cur_item view assert 'https //github.com' not in bookmarks.marks assert 'https //python.org' in bookmarks.marks assert 'http //qutebrowser.org' in bookmarks.marks
def endian_int pkt return int ''.join pkt 16
def count_braces line open_braces ['[' ' ' '{']close_braces [']' ' ' '}']closing_prefix_re re.compile ' .*?[^\\s\\]\\}\\ ]+.*? [\\]\\}\\ ] ? \\s*$' cnt 0stripline COMMENT_RE.sub '' line stripline QUOTE_RE.sub "''" stripline for char in stripline for brace in open_braces if char brace cnt + 1for brace in close_braces if char brace cnt - 1after Falseif cnt > 0 after Trueif cnt < 0 and closing_prefix_re.match stripline after Truereturn cnt after
def _difftrap function interval numtraps if numtraps < 0 raise ValueError 'numtrapsmustbe>0indifftrap .' elif numtraps 1 return 0.5 * function interval[0] + function interval[1] else numtosum numtraps / 2 h float interval[1] - interval[0] / numtosum lox interval[0] + 0.5 * h points lox + h * np.arange numtosum s np.sum function points axis 0 return s
def _get_name_of_init run utils.run output run 'readlink/proc/1/exe' .stdout.strip return os.path.basename output
def make_extension trigger None default_name None priority None invoke_before_training False finalizer None if trigger is None trigger Extension.triggerif priority is None priority Extension.prioritydef decorator ext ext.trigger triggerext.default_name default_name or ext.__name__ ext.priority priorityext.invoke_before_training invoke_before_trainingext.finalize finalizerreturn extreturn decorator
def block_device_mapping_destroy context bdm_id return IMPL.block_device_mapping_destroy context bdm_id
def describe_message message_definition message_descriptor MessageDescriptor message_descriptor.name message_definition.definition_name .split '.' [ -1 ]fields sorted message_definition.all_fields key lambda v v.number if fields message_descriptor.fields [describe_field field for field in fields]try nested_messages message_definition.__messages__except AttributeError passelse message_descriptors []for name in nested_messages value getattr message_definition name message_descriptors.append describe_message value message_descriptor.message_types message_descriptorstry nested_enums message_definition.__enums__except AttributeError passelse enum_descriptors []for name in nested_enums value getattr message_definition name enum_descriptors.append describe_enum value message_descriptor.enum_types enum_descriptorsreturn message_descriptor
def get_pylint_version if PYLINT_PATH is None returncwd osp.dirname PYLINT_PATH args ['--version']if os.name 'nt' cmd ''.join [PYLINT] + args process programs.run_shell_command cmd cwd cwd else process programs.run_program PYLINT args cwd cwd lines to_unicode_from_fs process.stdout.read .splitlines if lines regex ' {0}*|pylint-script.py [0-9\\.]* '.format PYLINT match re.match regex lines[0] if match is not None return match.groups [1]
def p_enumerator_2 t pass
def RelayStateHelper manager delay return internet.TimerService delay _checkState manager
def get_minibatches_idx n minibatch_size shuffle False idx_list numpy.arange n dtype 'int32' if shuffle numpy.random.shuffle idx_list minibatches []minibatch_start 0for i in range n // minibatch_size minibatches.append idx_list[minibatch_start minibatch_start + minibatch_size ] minibatch_start + minibatch_sizeif minibatch_start ! n minibatches.append idx_list[minibatch_start ] return zip range len minibatches minibatches
def exact_filter query model filters filter_dict {}if filters is None filters {}for key value in six.iteritems filters if isinstance value list tuple set frozenset column_attr getattr model key query query.filter column_attr.in_ value else filter_dict[key] valueif filter_dict query query.filter_by **filter_dict return query
def LocatePythonFile fileName bBrowseIfDir 1 if not os.path.isfile fileName baseName fileNamefor path in sys.path fileName os.path.abspath os.path.join path baseName if os.path.isdir fileName if bBrowseIfDir d win32ui.CreateFileDialog 1 '*.py' None 0 'PythonFiles *.py |*.py|Allfiles|*.*' d.SetOFNInitialDir fileName rc d.DoModal if rc win32con.IDOK fileName d.GetPathName breakelse return Noneelse fileName fileName + '.py' if os.path.isfile fileName breakelse return Nonereturn win32ui.FullPath fileName
def degree G nbunch None weight None return G.degree nbunch weight
def set_floatx floatx global _FLOATXif floatx not in {'float16' 'float32' 'float64'} raise ValueError 'Unknownfloatxtype ' + str floatx _FLOATX str floatx
def encode_table pieces table table table or {} length_index len pieces pieces.append None tablesize 0for key value in table.items tablesize + encode_short_string pieces key tablesize + encode_value pieces value pieces[length_index] struct.pack '>I' tablesize return tablesize + 4
def to_sql frame name con flavor None schema None if_exists 'fail' index True index_label None chunksize None dtype None if if_exists not in 'fail' 'replace' 'append' raise ValueError "'{0}'isnotvalidforif_exists".format if_exists pandas_sql pandasSQL_builder con schema schema flavor flavor if isinstance frame Series frame frame.to_frame elif not isinstance frame DataFrame raise NotImplementedError "'frame'argumentshouldbeeitheraSeriesoraDataFrame" pandas_sql.to_sql frame name if_exists if_exists index index index_label index_label schema schema chunksize chunksize dtype dtype
@apply_to_maskdef even_size clip w h clip.sizeif w % 2 0 and h % 2 0 return clipif w % 2 ! 0 and h % 2 ! 0 fl_image lambda a a[ -1 -1 ] elif w % 2 ! 0 fl_image lambda a a[ -1 ] else fl_image lambda a a[ -1 ] return clip.fl_image fl_image
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def safe_join base *paths base force_text base paths [force_text p for p in paths]final_path abspath join base *paths base_path abspath base if not normcase final_path .startswith normcase base_path + sep and normcase final_path ! normcase base_path and dirname normcase base_path ! normcase base_path raise SuspiciousFileOperation 'Thejoinedpath {} islocatedoutsideofthebasepathcomponent {} '.format final_path base_path return final_path
def feature_selection documents [] top None method CHISQUARED threshold 0.0 a []for d in documents if not isinstance d Document d Document d[0] type d[1] stopwords True a.append d m Model a weight None p m.posterior_probabilityc m.classesfor w f in m.feature_selection top method threshold weighted True yield f w max [ p f type type for type in c]
def get_combination_hash_from_variable_mapping parent variables mapping {}for variable_identifier value_identifier in variables.items variable _ ProductVariationVariable.objects.get_or_create product parent identifier force_text variable_identifier value _ ProductVariationVariableValue.objects.get_or_create variable variable identifier force_text value_identifier mapping[variable] valuereturn hash_combination mapping
def skip_for_dialect dialect def dec fn def wrap self *args **kwargs if self.db_engine.dialect.name dialect raise unittest.SkipTest "Notsupportedondialect'%s'" % dialect return fn self *args **kwargs return wrapreturn dec
def make_small_undirected_graph graph_description create_using None if create_using is not None and create_using.is_directed raise NetworkXError 'DirectedGraphnotsupported' return make_small_graph graph_description create_using
def _payment_accepted order_id auth_amount currency decision try order Order.objects.get id order_id except Order.DoesNotExist raise CCProcessorDataException _ 'Thepaymentprocessoracceptedanorderwhosenumberisnotinoursystem.' if decision 'ACCEPT' if auth_amount order.total_cost and currency.lower order.currency.lower return {'accepted' True 'amt_charged' auth_amount 'currency' currency 'order' order}else ex CCProcessorWrongAmountException _ u'Theamountchargedbytheprocessor{charged_amount}{charged_amount_currency}isdifferentthanthetotalcostoftheorder{total_cost}{total_cost_currency}.' .format charged_amount auth_amount charged_amount_currency currency total_cost order.total_cost total_cost_currency order.currency ex.order orderraise exelse return {'accepted' False 'amt_charged' 0 'currency' 'usd' 'order' order}
def imdisplay imarray screen None a pg.surfarray.make_surface imarray.swapaxes 0 1 if screen is None screen pg.display.set_mode imarray.shape[ 2][ -1 ] screen.blit a 0 0 pg.display.flip
def description_for_valid_number numobj lang script None region None number_region region_code_for_number numobj if region is None or region number_region mobile_token country_mobile_token numobj.country_code national_number national_significant_number numobj if mobile_token ! U_EMPTY_STRING and national_number.startswith mobile_token national_number national_number[len mobile_token ]region region_code_for_country_code numobj.country_code try copied_numobj parse national_number region except NumberParseException copied_numobj numobjarea_description _prefix_description_for_number GEOCODE_DATA GEOCODE_LONGEST_PREFIX copied_numobj lang script region else area_description _prefix_description_for_number GEOCODE_DATA GEOCODE_LONGEST_PREFIX numobj lang script region if area_description ! '' return area_descriptionelse return country_name_for_number numobj lang script region else return _region_display_name number_region lang script region
def parse_command line globals_dict locals_dict res full_command.parseString line if res if _print_commands print >>commands.OUT "twill executingcmd'%s'" % line.strip args process_args res.arguments.asList globals_dict locals_dict return res.command args return None None
def DumbDispatch IDispatch userName None createClass None UnicodeToString None clsctx pythoncom.CLSCTX_SERVER assert UnicodeToString is None 'thisisdeprecatedandwillgoaway' IDispatch userName _GetGoodDispatchAndUserName IDispatch userName clsctx if createClass is None createClass CDispatchreturn createClass IDispatch build.DispatchItem userName
def check_win_size size if not size.strip return dict valid True message 'Windowsizenotset default ' size size.lower reg '\\d{1 4}x\\d{1 4}'if not re.match reg size re.I msg 'Trysomethinglike720x480'return dict valid False message msg else return dict valid True value size
def report_nodes_not_run notrun if notrun logger.info u'***********************************' for info in notrun logger.error u'couldnotrunnode %s' % u'.'.join info[u'node']._hierarchy info[u'node']._id logger.info u'crashfile %s' % info[u'crashfile'] logger.debug u'Thefollowingdependentnodeswerenotrun' for subnode in info[u'dependents'] logger.debug subnode._id logger.info u'***********************************' raise RuntimeError u'Workflowdidnotexecutecleanly.Checklogfordetails'
def _serialize_rules rules result [ rule_name str rule for rule_name rule in rules.items ]return sorted result key lambda rule rule[0]
def _to_args x if not isinstance x list tuple np.ndarray x [x]return x
def _st x start_f windows n_samp x.shape[ -1 ]ST np.empty x.shape[ -1 ] + len windows n_samp dtype np.complex Fx fftpack.fft x XF np.concatenate [Fx Fx] axis -1 for i_f window in enumerate windows f start_f + i_f ST[... i_f ] fftpack.ifft XF[... f f + n_samp ] * window return ST
def getInradius defaultInradius elementNode defaultInradius getComplexByPrefixes elementNode ['demisize' 'inradius'] defaultInradius return getComplexByMultiplierPrefix elementNode 2.0 'size' defaultInradius
def ec2_id_to_id ec2_id try return int ec2_id.split '-' [ -1 ] 16 except ValueError raise exception.InvalidEc2Id ec2_id ec2_id
def _buildArgs f self None kwargs {} argTuples getArgumentDescriptions f argTuples argTuples[1 ]init TPRegion.__init__ourArgNames [t[0] for t in getArgumentDescriptions init ]ourArgNames + ['numberOfCols']for argTuple in argTuples[ ] if argTuple[0] in ourArgNames argTuples.remove argTuple if self for argTuple in argTuples argName argTuple[0]if argName in kwargs argValue kwargs.pop argName else if len argTuple 2 raise TypeError "Mustprovide'%s'" % argName argValue argTuple[2]setattr self argName argValue return argTuples
def _AddAccumulatedActionsToMSVS p spec actions_dict for primary_input in actions_dict inputs OrderedSet outputs OrderedSet descriptions []commands []for action in actions_dict[primary_input] inputs.update OrderedSet action['inputs'] outputs.update OrderedSet action['outputs'] descriptions.append action['description'] commands.append action['command'] description ' andalso'.join descriptions command '\r\n'.join commands _AddCustomBuildToolForMSVS p spec primary_input primary_input inputs inputs outputs outputs description description cmd command
def audit jail None chroot None root None return __salt__['cmd.run'] _pkg jail chroot root + ['audit' '-F'] output_loglevel 'trace' python_shell False
def all_bit_strings bits dtype 'uint8' return np.array [[int x for x in np.binary_repr i width bits ] for i in xrange 0 2 ** bits ] dtype dtype
def test_hsl_to_rgb_part_6 assert hsl_to_rgb 240 100 50 0 0 255 assert hsl_to_rgb 252 100 50 51 0 255 assert hsl_to_rgb 264 100 50 102 0 255 assert hsl_to_rgb 276 100 50 153 0 255 assert hsl_to_rgb 288 100 50 204 0 255 assert hsl_to_rgb 300 100 50 255 0 255 assert hsl_to_rgb 312 100 50 255 0 204 assert hsl_to_rgb 324 100 50 255 0 153 assert hsl_to_rgb 336 100 50 255 0 102 assert hsl_to_rgb 348 100 50 255 0 51 assert hsl_to_rgb 360 100 50 255 0 0
def applyFilter normalized_uri xrd_data flt None flt mkFilter flt et parseXRDS xrd_data endpoints []for service_element in iterServices et endpoints.extend flt.getServiceEndpoints normalized_uri service_element return endpoints
def _load_client_secrets filename client_type client_info clientsecrets.loadfile filename if client_type ! clientsecrets.TYPE_WEB raise ValueError 'Theflowspecifiedin{}isnotsupported onlytheWEBflowtypeissupported.'.format client_type return client_info['client_id'] client_info['client_secret']
def concat_indexed_dataframes dfs axis 0 join 'outer' meta methods.concat [df._meta for df in dfs] axis axis join join empties [strip_unknown_categories df._meta for df in dfs] dfs2 divisions parts align_partitions *dfs name 'concat-indexed-' + tokenize join *dfs parts2 [[ df if df is not None else empty for df empty in zip part empties ] for part in parts]dsk dict name i methods.concat part axis join for i part in enumerate parts2 for df in dfs2 dsk.update df.dask return new_dd_object dsk name meta divisions
def _is_sparse_variable x if not isinstance x gof.Variable raise NotImplementedError 'thisfunctionshouldonlybecalledon*variables* oftypesparse.SparseTypeortensor.TensorType forinstance not' x return isinstance x.type SparseType
def security_group_exists context project_id group_name return IMPL.security_group_exists context project_id group_name
def _req_environ_property environ_field def getter self return self.environ.get environ_field None def setter self value if isinstance value unicode self.environ[environ_field] value.encode 'utf-8' else self.environ[environ_field] valuereturn property getter setter doc 'Getandsetthe%spropertyintheWSGIenvironment' % environ_field
def _get_user_partition_groups course_key user_partitions user partition_groups {}for partition in user_partitions group partition.scheme.get_group_for_user course_key user partition if group is not None partition_groups[partition.id] groupreturn partition_groups
def is_valid_vpnv6_prefix prefix if not isinstance prefix str return Falsetokens prefix.split ' ' 2 if len tokens ! 3 return Falseif not is_valid_route_dist ' '.join [tokens[0] tokens[1]] return Falsereturn is_valid_ipv6_prefix tokens[2]
def get_year book return int book['date'].split [1]
def uninstall pkg user None env None cmd ['ghc-pkgunregister']cmd.append '"{0}"'.format pkg result __salt__['cmd.run_all'] ''.join cmd runas user env env if result['retcode'] ! 0 raise CommandExecutionError result['stderr'] return result
def palplot pal size 1 n len pal f ax plt.subplots 1 1 figsize n * size size ax.imshow np.arange n .reshape 1 n cmap mpl.colors.ListedColormap list pal interpolation 'nearest' aspect 'auto' ax.set_xticks np.arange n - 0.5 ax.set_yticks [ -0.5 0.5] ax.set_xticklabels [] ax.set_yticklabels []
def indexing_is_enabled return settings.FEATURES.get 'ENABLE_COURSEWARE_INDEX' False
def create_tip_index tree if hasattr tree '_tip_index' returnelse tree._tip_index {n.Name n for n in tree.tips }
def merge dict1 dict2 for key val2 in dict2.items if val2 is not None val1 dict1.get key if isinstance val2 dict if val1 is None val1 {}if isinstance val1 Alias val1 val1 val2 elif isinstance val1 tuple alias others val1others others.copy merge others val2 val1 alias others else val1 val1.copy merge val1 val2 else val1 val2dict1[key] val1
def make_simple_equity_info sids start_date end_date symbols None num_assets len sids if symbols is None symbols list ascii_uppercase[ num_assets] return pd.DataFrame {'symbol' list symbols 'start_date' pd.to_datetime [start_date] * num_assets 'end_date' pd.to_datetime [end_date] * num_assets 'exchange' 'TEST' 'exchange_full' 'TESTFULL'} index sids columns 'start_date' 'end_date' 'symbol' 'exchange' 'exchange_full'
def setup_master master None if master is None if Tkinter._support_default_root master Tkinter._default_root or Tkinter.Tk else raise RuntimeError 'NomasterspecifiedandTkinterisconfiguredtonotsupportdefaultroot' return master
def test_split_lines_3 lines list split_lines [ Token.A u'line1\nline2\n' ] assert lines [[ Token.A u'line1' ] [ Token.A u'line2' ] [ Token.A u'' ]] lines list split_lines [ Token.A u'\n' ] assert lines [[] [ Token.A u'' ]] lines list split_lines [ Token.A u'' ] assert lines [[ Token.A u'' ]]
def get_trash_interval return get_conf .get _CNF_TRASH_INTERVAL
def unify x y s None variables **kwargs decons lambda x deconstruct x variables s s or {} s dict decons k decons v for k v in s.items ds core.unify decons x decons y s is_associative is_associative is_commutative is_commutative **kwargs for d in ds yield dict construct k construct v for k v in d.items
def create_new_branch revision u'' settings None model main.MainModel model.update_status view CreateBranchDialog model settings settings parent qtutils.active_window if revision view.set_revision revision view.show return view
def generate_clone_url_for_repository_in_tool_shed user repository base_url url_for '/' qualified True .rstrip '/' if user protocol base base_url.split ' //' username '%s@' % user.username return '%s //%s%s/repos/%s/%s' % protocol username base repository.user.username repository.name else return '%s/repos/%s/%s' % base_url repository.user.username repository.name
def atciqd rc dc astrom pco erfa.s2c rc dc pnat erfa.ld 1.0 pco pco astrom[u'eh'] astrom[u'em'] 5e-08 ppr erfa.ab pnat astrom[u'v'] astrom[u'em'] astrom[u'bm1'] pi erfa.rxp astrom[u'bpn'] ppr ri di erfa.c2s pi return erfa.anp ri di
def swift_load_pack_index scon filename f scon.get_object filename try return load_pack_index_file filename f finally f.close
def accuracy features labels model preds predict model features return np.mean preds labels
@frappe.whitelist def cancel doctype name wrapper frappe.get_doc doctype name wrapper.cancel return wrapper.as_dict
def refresh_window procs disks_read disks_write curses.endwin templ '%-5s%-7s%11s%11s%s'win.erase disks_tot 'TotalDISKREAD %s|TotalDISKWRITE %s' % bytes2human disks_read bytes2human disks_write print_line disks_tot header templ % 'PID' 'USER' 'DISKREAD' 'DISKWRITE' 'COMMAND' print_line header highlight True for p in procs line templ % p.pid p._username[ 7] bytes2human p._read_per_sec bytes2human p._write_per_sec p._cmdline try print_line line except curses.error breakwin.refresh
def numericise_all input empty2zero False default_blank '' return [numericise s empty2zero default_blank for s in input]
def in6_getifaddr ret []i dnet.intf for int in i ifname int['name']v6 []if int.has_key 'alias_addrs' v6 int['alias_addrs']for a in v6 if a.type ! dnet.ADDR_TYPE_IP6 continuexx str a .split '/' [0]addr scapy.utils6.in6_ptop xx scope scapy.utils6.in6_getscope addr ret.append xx scope ifname return ret
def build_abstract info example None detailed_info {} abstract ''if info abstract + '<p>%s</p>' % info.replace '\n' '\\n' if example abstract + '<pre><code>%s</code></pre>' % example.replace '\n' '\\n' for key value in detailed_info.items abstract + '<spanclass "prog__sub">%s</span><p>%s</p>' % key value abstract '<sectionclass "prog__container">%s</section>' % abstract.replace '\n' '\\n' return abstract
def basic_auth_header username password return b 'Basic%s' % base64.b64encode to_bytes '%s %s' % username password errors 'surrogate_or_strict'
def _build_target action original_target plugin context target original_target.copy resource _a get_resource_and_action action hierarchy_info attributes.RESOURCE_HIERARCHY_MAP.get resource None if hierarchy_info and plugin parent_resource hierarchy_info['parent'][ -1 ]parent_id hierarchy_info['identified_by']f getattr plugin 'get_%s' % parent_resource data f context target[parent_id] fields ['tenant_id'] target[ '%s_tenant_id' % parent_resource ] data['tenant_id']return target
def is_mobile_number_portable_region region_code metadata PhoneMetadata.metadata_for_region region_code None if metadata is None return Falsereturn metadata.mobile_number_portable_region
def measurementReport a TpPd pd 6 b MessageType mesType 21 c MeasurementResults packet a / b / c return packet
def serialize_item collection item __grab_lock storage_module __get_storage_module collection.collection_type storage_module.serialize_item collection item __release_lock with_changes True
def plot_MCMC_results xdata ydata trace colors 'k' fig ax plt.subplots 1 2 figsize 10 4 plot_MCMC_trace ax[0] xdata ydata trace True colors colors plot_MCMC_model ax[1] xdata ydata trace
def is_channel string return string and string[0] in '#&+!'
def p_direct_abstract_declarator_1 t pass
def writeSettingsPrintMessage repository writeSettings repository print repository.title.lower .capitalize + 'havebeensaved.'
def write_local tex_root name obj cache_path _local_cache_path tex_root _write cache_path name obj _create_cache_timestamp cache_path
def statuses_resolve_uids twitter tl user_ids []for t in tl rt t.get 'retweeted_status' if rt and not rt['user'].get 'screen_name' user_ids.append rt['user']['id'] if not t['user'].get 'screen_name' user_ids.append t['user']['id'] names lookup twitter list set user_ids new_tl []for t in tl rt t.get 'retweeted_status' if rt and not rt['user'].get 'screen_name' name names[rt['user']['id']]t['retweeted_status']['user']['screen_name'] nameif not t['user'].get 'screen_name' name names[t['user']['id']]t['user']['screen_name'] namenew_tl.append t return new_tl
def find_objects input max_label 0 input numpy.asarray input if numpy.iscomplexobj input raise TypeError 'Complextypenotsupported' if max_label < 1 max_label input.max return _nd_image.find_objects input max_label
def get_ec2_client_for_test config return ec2_client region config['region'] zone config['zone'] access_key_id config['access_key_id'] secret_access_key config['secret_access_key']
def isLoopNumberEqual betweenX betweenXIndex loopNumber if betweenXIndex > len betweenX return Falsereturn betweenX[betweenXIndex].index loopNumber
def match_var regex cmd _traffic_line '-m' regex log.debug 'Running %s' cmd return _subprocess cmd
def add_user name password None runas None clear_pw Falseif password is None clear_pw Truepassword ''.join random.SystemRandom .choice string.ascii_uppercase + string.digits for x in range 15 if runas is None and not salt.utils.is_windows runas salt.utils.get_user if salt.utils.is_windows python_shell Truecmd '"{0}"add_user"{1}""{2}"'.format __context__['rabbitmqctl'] name password else python_shell Falsecmd [__context__['rabbitmqctl'] 'add_user' name password]res __salt__['cmd.run_all'] cmd output_loglevel 'quiet' runas runas python_shell python_shell if clear_pw try clear_password name runas except Exception delete_user name runas raisemsg 'Added'return _format_response res msg
def _ad_hoc_noise coils ch_type 'meg' v np.empty len coils if ch_type 'meg' axs np.array [_is_axial_coil coil for coil in coils] dtype bool v[axs] 4e-28v[np.logical_not axs ] 2.5e-25else v.fill 1e-12 cov dict diag True data v eig None eigvec None return cov
@jsonifydef delete_record self arg_dict cmd ['xenstore-rm' '/local/domain/% dom_id s/% path s' % arg_dict ] ret result _run_command cmd return result
def _sph_to_cart sph assert sph.ndim 2 and sph.shape[1] 3 sph np.atleast_2d sph out np.empty len sph 3 out[ 2] sph[ 0] * np.cos sph[ 2] xy sph[ 0] * np.sin sph[ 2] out[ 0] xy * np.cos sph[ 1] out[ 1] xy * np.sin sph[ 1] return out
def get_current_theme request None if _current_theme_class is not _not_set if _current_theme_class return _current_theme_class return Nonevalue cache.get THEME_CACHE_KEY if value return valueif request and hasattr request '_current_xtheme' return request._current_xthemetheme _get_current_theme if request request._current_xtheme themecache.set THEME_CACHE_KEY theme return theme
def middleware_class api None def decorator middleware_class apply_to_api hug.API api if api else hug.api.from_object middleware_class apply_to_api.http.add_middleware middleware_class return middleware_classreturn decorator
def _compute_p_max m_max sqrt_m_max np.sqrt m_max p_low int np.floor sqrt_m_max p_high int np.ceil sqrt_m_max + 1 return max p for p in range p_low p_high + 1 if p * p - 1 < m_max + 1
def _length obj album if album return sum i.length for i in obj.items else return obj.length
def add_glob_to_array _bondmems result []if isinstance _bondmems list for _entry in _bondmems if re.search '-' _entry _entry 'glob' + _entry result.append _entry return ''.join result return _bondmems
def get_user_from_request handler None request None *args **kwargs assert handler or request if not handler handler lambda request user *args **kwargs user def get_user_from_request_wrapper_fn request *args **kwargs user get_object_or_None FacilityUser id request.REQUEST['user'] if 'user' in request.REQUEST else None user user or request.session.get 'facility_user' return handler request user user *args **kwargs return get_user_from_request_wrapper_fn if not request else get_user_from_request_wrapper_fn request request *args **kwargs
def run_on_appengine gdata_service store_tokens True single_user_mode False deadline None gdata_service.http_client AppEngineHttpClient deadline deadline gdata_service.token_store AppEngineTokenStore gdata_service.auto_store_tokens store_tokensgdata_service.auto_set_current_token single_user_modereturn gdata_service
def filter sum_dict align_dict filter_attribute low_bound high_bound new_sum_dict FSSP.FSSPSumDict new_align_dict copy.deepcopy align_dict for prot_num in sum_dict attr_value getattr sum_dict[prot_num] filter_attribute if attr_value > low_bound and attr_value < high_bound new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict.abs_res_dict new_align_dict.abs pos_num .pos_align_dict {}for prot_num in prot_numbers new_align_dict.abs pos_num .pos_align_dict[prot_num] align_dict.abs pos_num .pos_align_dict[prot_num]return new_sum_dict new_align_dict
@commands u'gettimeformat' u'gettf' @example u'.gettf[nick]' def get_user_format bot trigger nick trigger.group 2 if not nick nick trigger.nicknick nick.strip format bot.db.get_nick_value nick u'time_format' if format bot.say u"%s'stimeformat %s." % nick format else bot.say u"%shasn'tsetacustomtimeformat" % nick
def mds_create **kwargs return ceph_cfg.mds_create **kwargs
def is_stale last_updated lifespan 14 if last_updated is None return Trueexpiration_date last_updated + datetime.timedelta days lifespan return datetime.datetime.now > expiration_date
def iri2uri uri if isinstance uri str scheme authority path query fragment urllib.parse.urlsplit uri authority authority.encode 'idna' .decode 'utf-8' uri urllib.parse.urlunsplit scheme authority path query fragment uri ''.join [encode c for c in uri] return uri
def get_all_elements node if isinstance node astroid.Tuple astroid.List for child in node.elts for e in get_all_elements child yield e else yield node
def complete_python_mode prefix line start end ctx if not prefix.startswith '@ ' or prefix.startswith '${' return set prefix_start prefix[ 2]python_matches complete_python prefix[2 ] line start + 2 end ctx if isinstance python_matches cabc.Sequence python_matches python_matches[0]return set prefix_start + i for i in python_matches
def key_checker expected_keys def check actual_dict raise_error True '\nFunctionthatcheckswhetherallkeysintheexpected_keysobjectisinthegivenactual_dictobject.\n'missing set expected_keys - set actual_dict.keys if not missing return Trueif raise_error raise InvalidTabsException "Expectedkeys'{0}'arenotpresentinthegivendict {1}".format expected_keys actual_dict else return Falsereturn check
def _GetUnqualifiedToTargetMapping all_targets to_find result {}if not to_find return {} [] to_find set to_find for target_name in all_targets.keys extracted gyp.common.ParseQualifiedTarget target_name if len extracted > 1 and extracted[1] in to_find to_find.remove extracted[1] result[extracted[1]] all_targets[target_name]if not to_find return result [] return result [x for x in to_find]
def test_render t Jinja2Template JINJA2.path t.configure None t.env.filters['dateformat'] dateformatsource File JINJA2.child 'index.html' .read_all html t.render source context actual PyQuery html assert actual '.navigationli' .length 30 assert actual 'div.article' .length 20 assert actual 'div.articleh2' .length 20 assert actual 'div.articleh2a' .length 20 assert actual 'div.articlep.meta' .length 20 assert actual 'div.articlediv.text' .length 20
def survey_getAllTranslationsForSeries series_id table current.s3db.survey_seriesrow current.db table.id series_id .select table.template_id limitby 0 1 .first template_id row.template_idreturn survey_getAllTranslationsForTemplate template_id
def global_registry entry_point_group '_default' global __GLOBAL_REGISTRYif __GLOBAL_REGISTRY.get entry_point_group is None log.debug "'global_registry '-runningwidgetdiscovery." if entry_point_group '_default' from ..config import widgets_entry_pointsentry_points_iter widgets_entry_points else entry_points_iter entry_point_groupreg WidgetRegistry disc discovery.WidgetDiscovery reg disc.run entry_points_iter log.info "'global_registry 'discoveryfinished." __GLOBAL_REGISTRY[entry_point_group] regreturn __GLOBAL_REGISTRY[entry_point_group]
def get_support_url request siteconfig SiteConfiguration.objects.get_current return siteconfig.get u'support_url' or get_default_support_url request
def _input_callback fdref flags info _triggered.set CFFileDescriptorInvalidate fdref CFRelease fdref NSApp _NSApp msg NSApp n 'stop ' NSApp _wake NSApp
def _RunningInThread thread return threading.currentThread .getName thread.getName
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def hamiltonian pos vel energy_fn return energy_fn pos + kinetic_energy vel
def list_sebool bdata __salt__['cmd.run'] 'semanageboolean-l' .splitlines ret {}for line in bdata[1 ] if not line.strip continuecomps line.split ret[comps[0]] {'State' comps[1][1 ] 'Default' comps[3][ -1 ] 'Description' ''.join comps[4 ] }return ret
def handoverFailure a TpPd pd 6 b MessageType mesType 40 c RrCause packet a / b / c return packet
def _GetModelTypeForEntityType python_type from google.appengine.ext import db_PYTHON_TYPE_TO_MODEL_TYPE {basestring db.StringProperty str db.StringProperty unicode db.StringProperty int db.IntegerProperty bool db.BooleanProperty float db.FloatProperty db.Text db.TextProperty}return _PYTHON_TYPE_TO_MODEL_TYPE.get python_type None
def make_eventrule date_rule time_rule cal half_days True date_rule.cal caltime_rule.cal calif half_days inner_rule date_rule & time_rule else nhd_rule NotHalfDay nhd_rule.cal calinner_rule date_rule & time_rule & nhd_rule return OncePerDay rule inner_rule
def safe_str_cmp a b if isinstance a text_type a a.encode 'utf-8' if isinstance b text_type b b.encode 'utf-8' if _builtin_safe_str_cmp is not None return _builtin_safe_str_cmp a b if len a ! len b return Falserv 0if PY2 for x y in izip a b rv | ord x ^ ord y else for x y in izip a b rv | x ^ y return rv 0
def get_cluster_id kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theget_cluster_idfunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None if name is None raise SaltCloudSystemExit 'Theget_cluster_idfunctionrequiresaname.' try ret list_clusters [name]['id']except KeyError raise SaltCloudSystemExit "Thecluster'{0}'couldnotbefound".format name return ret
def gcf figManager _pylab_helpers.Gcf.get_active if figManager is not None return figManager.canvas.figureelse return figure
def dmp_invert f g u K if not u return dup_invert f g K else raise MultivariatePolynomialError f g
def delete_softly context obj update_and_save context obj {'deleted_at' timeutils.utcnow }
def test_can_parse_feature_description feature Feature.from_string FEATURE2 assert_equals feature.description 'Inordertoavoidsillymistakes\nCashiersmustbeabletocalculateafraction' expected_scenario_names ['Regularnumbers']got_scenario_names [s.name for s in feature.scenarios]assert_equals expected_scenario_names got_scenario_names assert_equals len feature.scenarios[0].steps 4 step1 step2 step3 step4 feature.scenarios[0].stepsassert_equals step1.sentence '*Ihaveentered3intothecalculator' assert_equals step2.sentence '*Ihaveentered2intothecalculator' assert_equals step3.sentence '*Ipressdivide' assert_equals step4.sentence '*theresultshouldbe1.5onthescreen'
def shift_path_info environ path_info environ.get 'PATH_INFO' '' if not path_info return Nonepath_parts path_info.split '/' path_parts[1 -1 ] [p for p in path_parts[1 -1 ] if p and p ! '.' ]name path_parts[1]del path_parts[1]script_name environ.get 'SCRIPT_NAME' '' script_name posixpath.normpath script_name + '/' + name if script_name.endswith '/' script_name script_name[ -1 ]if not name and not script_name.endswith '/' script_name + '/'environ['SCRIPT_NAME'] script_nameenviron['PATH_INFO'] '/'.join path_parts if name '.' name Nonereturn name
def course_id_from_url url if not url return Nonematch COURSE_REGEX.match url if match is None return Nonecourse_id match.group 'course_id' if course_id is None return Nonetry return SlashSeparatedCourseKey.from_deprecated_string course_id except InvalidKeyError return None
def test_invalid_options_show_extra_information testdir testdir.makeini '\n[pytest]\naddopts --invalid-option\n' result testdir.runpytest result.stderr.fnmatch_lines ['*error unrecognizedarguments --invalid-option*' '*inifile %s*' % testdir.tmpdir.join 'tox.ini' '*rootdir %s*' % testdir.tmpdir ]
def counts x v idx np.digitize x v try return np.bincount idx minlength len v except bc np.bincount idx return np.r_[ bc np.zeros len v - len bc ]
def get_pixel x y return _sensehat.get_pixel x y
def visualize profiling_data converter CalltreeConverter profiling_data converter.visualize
@manager.commanddef test tests unittest.TestLoader .discover 'tests' unittest.TextTestRunner verbosity 2 .run tests
def wxToPIL wimg from PIL import Image w h wimg.GetSize d wimg.GetData pimg Image.new 'RGB' w h color 1 pimg.fromstring d return pimg
def register_check check codes None def _add_check check kind codes args if check in _checks[kind] _checks[kind][check][0].extend codes or [] else _checks[kind][check] codes or [''] args if inspect.isfunction check args _get_parameters check if args and args[0] in 'physical_line' 'logical_line' if codes is None codes ERRORCODE_REGEX.findall check.__doc__ or '' _add_check check args[0] codes args elif inspect.isclass check if _get_parameters check.__init__ [ 2] ['self' 'tree'] _add_check check 'tree' codes None
def _get_network_obj session network_objects network_name network_obj {}for obj_content in network_objects if not hasattr obj_content 'propSet' continueprop_dict vm_util.propset_dict obj_content.propSet network_refs prop_dict.get 'network' if network_refs network_refs network_refs.ManagedObjectReferencefor network in network_refs if network._type 'DistributedVirtualPortgroup' props session._call_method vutil 'get_object_property' network 'config' if network_name in props.name network_obj['type'] 'DistributedVirtualPortgroup'network_obj['dvpg'] props.keydvs_props session._call_method vutil 'get_object_property' props.distributedVirtualSwitch 'uuid' network_obj['dvsw'] dvs_propsreturn network_objelse props session._call_method vutil 'get_object_property' network 'summary.name' if props network_name network_obj['type'] 'Network'network_obj['name'] network_namereturn network_obj
def get_installed_packages return [x.key for x in filter lambda y where_am_i not in y.location pkg_resources.working_set ]
def generate_django_secretkey chars 'abcdefghijklmnopqrstuvwxyz0123456789!@#$%^&* -_ + 'return get_random_string 50 chars
def get_easy_ec2 config_file None cache False cfg get_config config_file cache return cfg.get_easy_ec2
def certificate_info_for_user user course_id grade user_is_whitelisted None if user_is_whitelisted is None user_is_whitelisted CertificateWhitelist.objects.filter user user course_id course_id whitelist True .exists certificate_is_delivered 'N'certificate_type 'N/A'eligible_for_certificate 'Y' if user_is_whitelisted or grade is not None and user.profile.allow_certificate else 'N' certificate_status certificate_status_for_student user course_id certificate_generated certificate_status['status'] CertificateStatuses.downloadable if certificate_generated certificate_is_delivered 'Y'certificate_type certificate_status['mode']return [eligible_for_certificate certificate_is_delivered certificate_type]
def _dup_right_decompose f s K n len f - 1 lc dup_LC f K f dup_to_raw_dict f g {s K.one}r n // s for i in range 1 s coeff K.zerofor j in range 0 i if not n + j - i in f continueif not s - j in g continue fc gc f[ n + j - i ] g[ s - j ] coeff + i - r * j * fc * gc g[ s - i ] K.quo coeff i * r * lc return dup_from_raw_dict g K
def setcbreak fd when TCSAFLUSH mode tcgetattr fd mode[LFLAG] mode[LFLAG] & ~ ECHO | ICANON mode[CC][VMIN] 1mode[CC][VTIME] 0tcsetattr fd when mode
def onCellAppData key value DEBUG_MSG 'onCellAppData %s' % key
def TreeRepr tree depth 0 def _NodeRepr node text str node.getType if node.getText text '%s %s' % text node.getText return textchildren ''if tree.children children '\n' + '\n'.join [TreeRepr child depth depth + 1 for child in tree.children if child] return depth * '' + _NodeRepr tree + children
def avail_platforms ret {}for platform in CMD_MAP ret[platform] Truefor cmd in CMD_MAP[platform] if not salt.utils.which cmd ret[platform] Falsereturn ret
def str2list data list_data []for line in data.split '\n' line line.strip if not line continuetry splitted line.split '' value splitted[1]except Exception continuelist_data.append value return list_data
def startapp app_name directory project_dir os.path.normpath os.path.join directory '..' project_name os.path.basename project_dir if app_name os.path.basename directory sys.stderr.write style.ERROR 'Error Youcannotcreateanappwiththesamename %r asyourproject.\n' % app_name sys.exit 1 _start_helper 'app' app_name directory project_name
def _save_and_block_module name orig_modules saved Truetry orig_modules[name] sys.modules[name]except KeyError saved Falsesys.modules[name] Nonereturn saved
def fake_execute_default_reply_handler *ignore_args **ignore_kwargs return '' ''
def install_repl_displayhook global _IP_REGISTEREDglobal _INSTALL_FIG_OBSERVERclass _NotIPython Exception passtry if u'IPython' in sys.modules from IPython import get_ipythonip get_ipython if ip is None raise _NotIPython if _IP_REGISTERED returndef post_execute if matplotlib.is_interactive draw_all try ip.events.register u'post_execute' post_execute except AttributeError ip.register_post_execute post_execute _IP_REGISTERED post_execute_INSTALL_FIG_OBSERVER Falsefrom IPython.core.pylabtools import backend2guiipython_gui_name backend2gui.get get_backend if ipython_gui_name ip.enable_gui ipython_gui_name else _INSTALL_FIG_OBSERVER Trueexcept ImportError _NotIPython _INSTALL_FIG_OBSERVER True
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def avail_sizes response list_common_lookups kwargs {'lookup' 'server.ram'} ret {}for item in response['list'] name item['name']ret[name] itemreturn ret
def checkKeys srvState assert srvState.hmacKey is not None and srvState.aesKey is not None and srvState.keyCreation is not None if int time.time - srvState.keyCreation > const.KEY_ROTATION_TIME log.info 'Rotatingserverkeymaterialforsessiontickets.' srvState.oldAesKey srvState.aesKeysrvState.oldHmacKey srvState.hmacKeysrvState.aesKey mycrypto.strongRandom const.TICKET_AES_KEY_LENGTH srvState.hmacKey mycrypto.strongRandom const.TICKET_HMAC_KEY_LENGTH srvState.keyCreation int time.time srvState.writeState
def resetlocale category LC_ALL _setlocale category _build_localename getdefaultlocale
def _tree_namespace_handler k v cherrypy.tree.graft v v.script_name cherrypy.engine.log 'Mounted %son%s' % v v.script_name or '/'
def test_cnn_fit_single_class cnn CondensedNearestNeighbour random_state RND_SEED y_single_class np.zeros X.shape[0] assert_warns UserWarning cnn.fit X y_single_class
def prepare_realm_pattern source return ' ?<![^\\s\'"\\ <] ?P<name>' + source + ' ?!\\w '
def concrete_head expr n 10 if not expr._resources raise ValueError 'Expressiondoesnotcontaindataresources' if not iscollection expr.dshape return compute expr head expr.head n + 1 if not iscollection expr.dshape return odo head object elif isrecord expr.dshape.measure return odo head DataFrame df odo head DataFrame df.columns [expr._name]return df
def get_data_disk_size vm_ swap linode_id disk_size get_linode kwargs {'linode_id' linode_id} ['TOTALHD']root_disk_size config.get_cloud_config_value 'disk_size' vm_ __opts__ default disk_size - swap return disk_size - root_disk_size - swap
def strip_format msg flags if u'python-format' in flags regex PYTHON_PRINTF_MATCHelif u'python-brace-format' in flags regex PYTHON_BRACE_MATCHelif u'php-format' in flags regex PHP_PRINTF_MATCHelif u'c-format' in flags regex C_PRINTF_MATCHelif u'rst-text' in flags regex RST_MATCHelse return msgstripped regex.sub u'' msg return stripped
def dbref_to_obj inp objclass raise_errors True dbid dbref inp if not dbid return inptry if dbid < 0 return Noneexcept ValueError return Nonetry return objclass.objects.get id dbid except Exception if raise_errors raisereturn inp
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u''.join choice chars for x in range length
def cvxopt2dense value return np.array value
def update_commerce_config enabled False checkout_page '/test_basket/' receipt_page '/checkout/receipt/' CommerceConfiguration.objects.create checkout_on_ecommerce_service enabled receipt_page receipt_page single_course_checkout_page checkout_page
def dmercer number start 2 sieve []for n in xrange start number + 1 is_prime Truefor p in sieve if n % p 0 is_prime Falsebreakif p * p > n breakif is_prime sieve.append n return sieve
def _get_uid name if getpwnam is None or name is None return Nonetry result getpwnam name except KeyError result Noneif result is not None return result[2]return None
def split_add_ops text n 0text text.replace '++' '##' .replace '--' '@@' spotted Falselast 0while n < len text e text[n]if e '+' or e '-' if spotted yield text[last n].replace '##' '++' .replace '@@' '--' yield e last n + 1 spotted Falseelif e '/' or e '*' or e '%' spotted Falseelif e ! '' spotted Truen + 1 yield text[last n].replace '##' '++' .replace '@@' '--'
def xsrf_secret_key secret memcache.get XSRF_MEMCACHE_ID namespace OAUTH2CLIENT_NAMESPACE if not secret model SiteXsrfSecretKey.get_or_insert key_name 'site' if not model.secret model.secret _generate_new_xsrf_secret_key model.put secret model.secretmemcache.add XSRF_MEMCACHE_ID secret namespace OAUTH2CLIENT_NAMESPACE return str secret
def host_add_labels id labels labels models.Label.smart_get_bulk labels host models.Host.smart_get id platforms [label.name for label in labels if label.platform]if len platforms > 1 raise model_logic.ValidationError {'labels' 'Addingmorethanoneplatformlabel %s' % ' '.join platforms } if len platforms 1 models.Host.check_no_platform [host] host.labels.add *labels
def load_comparable_cert *names return jose.ComparableX509 load_cert *names
def create_default_groups from flaskbb.fixtures.groups import fixtureresult []for key value in fixture.items group Group name key for k v in value.items setattr group k v group.save result.append group return result
@requires_duration@add_mask_if_nonedef crossfadeout clip duration newclip clip.copy newclip.mask clip.mask.fx fadeout duration return newclip
def seconds_to_str value if value < 60 return '%sseconds' % value elif value < 3600 return '%sminutes' % value / 60 else return '%shoursand%sminutes' % value / 3600 value % 3600 / 60
def is_copy_only_path path context try for dont_render in context[u'cookiecutter'][u'_copy_without_render'] if fnmatch.fnmatch path dont_render return Trueexcept KeyError return Falsereturn False
def chelsea return load 'chelsea.png'
def _breakHDB2 HDB2 ACK HDB2 & 2 / pow 2 1 NAK HDB2 & 1 return ACK NAK
def remove_useless_attributes field db False indexes False keywords USELESS_KEYWORDS[ ]if db keywords + USELESS_DB_KEYWORDS[ ]if indexes keywords + INDEX_KEYWORDS[ ]if field for name in keywords if name in field[2] del field[2][name]return field
def assert_almost_equal first second places 7 msg None values True if round second - first places ! 0 extra 'within%rplaces' % places _report_inequality_failure first second msg values '! ' extra
def taxonomy_process_prefs taxonomy_levels color_prefs None prefs {}for j col in enumerate taxonomy_levels key str col col str col prefs[key] {}prefs[key]['column'] colif color_prefs for p in color_prefs if 'column' in color_prefs[p] and str color_prefs[p]['column'] col if 'colors' in color_prefs[p] prefs[key]['colors'] color_prefs[p]['colors'].copy else prefs[key]['colors'] {}match Truebreakelse match Falseif not match prefs[key] {}prefs[key]['column'] colprefs[key]['colors'] {}return prefs
def test_endian_independence for endian in [u'<' u'>'] for ntype in [u'i' u'f'] for byte in [u'4' u'8'] x np.array [1 2 3] dtype endian + ntype + byte u.m.to u.cm x
@requires_segment_infodef readonly_indicator pl segment_info text u'RO' return text if int vim_getbufoption segment_info u'readonly' else None
def splitFields fields delimiter ' ' fields fields.replace '%s' % delimiter delimiter commas [ -1 len fields ]commas.extend zeroDepthSearch fields ' ' commas sorted commas return [fields[ x + 1 y] for x y in zip commas commas[1 ] ]
@register u'self-insert' def self_insert event event.current_buffer.insert_text event.data * event.arg
def fill_gaps_generator time_points query *columns iterator PeekableIterator query for t in time_points row iterator.peek if row and row.date t yield t tuple getattr row c for c in columns iterator.next else yield t tuple 0 for c in columns
def publish long_description make_long_description if long_description ! read RST_DESCRIPTION_PATH print 'Descriptionfilenotup-to-date %s\nRunthefollowingcommandandcommitthechanges--\n\npythonsetup.py%s\n' % RST_DESCRIPTION_PATH PREP_COMMAND sys.exit print 'Descriptionup-to-date %s' % RST_DESCRIPTION_PATH answer raw_input 'AreyousureyouwanttopublishtoPyPI yes/no ?' if answer ! 'yes' exit 'Aborted nothingpublished' os.system 'pythonsetup.pysdistupload'
def proxy_object obj if type obj in list tuple return ArrayCollection obj if isinstance obj dict return ObjectProxy obj return obj
def generate_events_list generator if not localized_events generator.context['events_list'] sorted events reverse True key lambda ev ev.dtstart ev.dtend else generator.context['events_list'] {k sorted v reverse True key lambda ev ev.dtstart ev.dtend for k v in localized_events.items }
def ob_is_tty ob fileno get_fileno ob is_tty Falseif fileno is_tty os.isatty fileno return is_tty
def slave_utilization registry xml_parent data utilization XML.SubElement xml_parent 'com.suryagaddipati.jenkins.SlaveUtilizationProperty' percent int data.get 'slave-percentage' 0 XML.SubElement utilization 'needsExclusiveAccessToNode' .text 'true' if percent else 'false' XML.SubElement utilization 'slaveUtilizationPercentage' .text str percent XML.SubElement utilization 'singleInstancePerSlave' .text str data.get 'single-instance-per-slave' False .lower
def _osborne e d def f rv if not isinstance rv HyperbolicFunction return rva rv.args[0]a a * d if not a.is_Add else Add._from_args [ i * d for i in a.args] if rv.func is sinh return I * sin a elif rv.func is cosh return cos a elif rv.func is tanh return I * tan a elif rv.func is coth return cot a / I else raise NotImplementedError 'unhandled%s' % rv.func return bottom_up e f
def ex_varassign name expr if not isinstance expr ast.expr expr ex_literal expr return ast.Assign [ex_lvalue name ] expr
def uri_to_iri uri charset 'utf-8' errors 'replace' if isinstance uri tuple uri url_unparse uri uri url_parse to_unicode uri charset path url_unquote uri.path charset errors '%/;?' query url_unquote uri.query charset errors '%;/? @& + $#' fragment url_unquote uri.fragment charset errors '%;/? @& + $#' return url_unparse uri.scheme uri.decode_netloc path query fragment
def computeCompressionRate meta if not meta.has 'file_size' or not meta.get 'compr_size' 0 returnfile_size meta.get 'file_size' if not file_size returnmeta.compr_rate float file_size / meta.get 'compr_size'
def enable_css_animations page page.browser.execute_script "\nvarstyles document.getElementById 'no-transitions' \nhead document.head||document.getElementsByTagName 'head' [0];\n\nhead.removeChild styles \n"
def url_params_from_lookup_dict lookups params {}if lookups and hasattr lookups 'items' items []for k v in lookups.items if callable v v v if isinstance v tuple list v ' '.join str x for x in v elif isinstance v bool v '0' '1' [v]else v str v items.append k v params.update dict items return params
@ensure_csrf_cookie@xframe_options_denydef signup request csrf_token csrf request ['csrf_token']if request.user.is_authenticated return redirect '/course/' if settings.FEATURES.get 'AUTH_USE_CERTIFICATES_IMMEDIATE_SIGNUP' return redirect_with_get 'login' request.GET False return render_to_response 'register.html' {'csrf' csrf_token}
def get_all_permission_grants_for_user user_db resource_uid None resource_types None permission_types None role_names UserRoleAssignment.query user user_db.name .only 'role' .scalar 'role' permission_grant_ids Role.query name__in role_names .scalar 'permission_grants' permission_grant_ids sum permission_grant_ids [] permission_grants_filters {}permission_grants_filters['id__in'] permission_grant_idsif resource_uid permission_grants_filters['resource_uid'] resource_uidif resource_types permission_grants_filters['resource_type__in'] resource_typesif permission_types permission_grants_filters['permission_types__in'] permission_typespermission_grant_dbs PermissionGrant.query **permission_grants_filters return permission_grant_dbs
def DateFromTicks ticks return date *localtime ticks [ 3]
def read_from_vmstat key vmstat open '/proc/vmstat' vmstat_info vmstat.read vmstat.close return int re.findall '%s\\s+ \\d+ ' % key vmstat_info [0]
def html_escape t html_escape_table {'&' '&amp;' '"' '&quot;' "'" '&#039;' '>' '&gt;' '<' '&lt;'}return ''.join html_escape_table.get c c for c in t
def _lowess_bisquare t t * tt[ ] np.negative t t + 1t * t
def is_gzipped response ctype response.headers.get 'Content-Type' '' cenc response.headers.get 'Content-Encoding' '' .lower return _is_gzipped ctype or _is_octetstream ctype and cenc in 'gzip' 'x-gzip'
def _get_meaning value_pb is_list False meaning Noneif is_list if len value_pb.array_value.values 0 return Noneall_meanings [_get_meaning sub_value_pb for sub_value_pb in value_pb.array_value.values]unique_meanings set all_meanings if len unique_meanings 1 meaning unique_meanings.pop else meaning all_meaningselif value_pb.meaning meaning value_pb.meaningreturn meaning
def _setAcceptableProtocols context acceptableProtocols def protoSelectCallback conn protocols '\nNPNclient-sideandALPNserver-sidecallbackusedtoselect\nthenextprotocol.Prefersprotocolsfoundearlierin\nC{_acceptableProtocols}.\n\n@paramconn Thecontextwhichissetup.\n@typeconn L{OpenSSL.SSL.Connection}\n\n@paramconn Protocolsadvertisedbytheotherside.\n@typeconn L{list}ofL{bytes}\n'overlap set protocols & set acceptableProtocols for p in acceptableProtocols if p in overlap return pelse return ''if not acceptableProtocols returnsupported protocolNegotiationMechanisms if supported & ProtocolNegotiationSupport.NPN def npnAdvertiseCallback conn return acceptableProtocolscontext.set_npn_advertise_callback npnAdvertiseCallback context.set_npn_select_callback protoSelectCallback if supported & ProtocolNegotiationSupport.ALPN context.set_alpn_select_callback protoSelectCallback context.set_alpn_protos acceptableProtocols
def mill it label '' hide None expected_size None every 1 def _mill_char _i if _i > count return ''else return MILL_CHARS[ _i // every % len MILL_CHARS ]def _show _i if not hide if _i % every 0 or _i count STREAM.write MILL_TEMPLATE % label _mill_char _i _i count STREAM.flush count len it if expected_size is None else expected_size if count _show 0 for i item in enumerate it yield item _show i + 1 if not hide STREAM.write '\n' STREAM.flush
def _tpl val match _tpl_pattern.match val if match return match.groups [0]return None
def parse_storage_policies conf policies []for section in conf.sections if not section.startswith 'storage-policy ' continuepolicy_index section.split ' ' 1 [1]config_options dict conf.items section policy_type config_options.pop 'policy_type' DEFAULT_POLICY_TYPE policy_cls BaseStoragePolicy.policy_type_to_policy_cls[policy_type]policy policy_cls.from_config policy_index config_options policies.append policy return StoragePolicyCollection policies
def truncate_before value srch before_index value.find srch if before_index > 0 return value[ before_index]else return value
def addHorizontallyBoundedPoint begin center end horizontalBegin horizontalEnd path if center.real > horizontalEnd and center.real < horizontalBegin path.append center returnif end ! None if center.real > horizontalBegin and end.real < horizontalBegin centerMinusEnd center - end along center.real - horizontalBegin / centerMinusEnd.real path.append center - along * centerMinusEnd returnif begin ! None if center.real < horizontalEnd and begin.real > horizontalEnd centerMinusBegin center - begin along center.real - horizontalEnd / centerMinusBegin.real path.append center - along * centerMinusBegin
def geom_output func argtypes offset None func.argtypes argtypesif not offset func.restype c_void_pfunc.errcheck check_geomelse func.restype c_intdef geomerrcheck result func cargs return check_geom_offset result func cargs offset func.errcheck geomerrcheckreturn func
def standardize_name name return name.replace '/' '_' if name else 'no_name.json'
def list_ip_configurations call None kwargs None global netconnif not netconn netconn get_conn NetworkManagementClient if kwargs is None kwargs {}if 'group' not in kwargs if 'resource_group' in kwargs kwargs['group'] kwargs['resource_group']else raise SaltCloudSystemExit 'Aresource_groupmustbespecifiedas"group"or"resource_group"' ip_conf {}for ip_ in kwargs.get 'ip_configurations' [] ip_data object_to_dict ip_ ip_conf[ip_data['name']] ip_datatry pub_ip netconn.public_ip_addresses.get kwargs['resource_group'] ip_data['name'] .ip_addressip_conf[ip_data['name']]['public_ip_address'] pub_ipexcept CloudError passreturn ip_conf
def encrypt data iv Random.new .read AES.block_size cipher _create_cipher iv return iv + cipher.encrypt data
def is_strictly_decreasing f interval S.Reals symbol None f sympify f free_sym f.free_symbolsif symbol is None if len free_sym > 1 raise NotImplementedError 'is_strictly_decreasinghasnotyetbeenimplementedforallmultivariateexpressions' elif len free_sym 0 return Falsesymbol free_sym.pop df f.diff symbol df_neg_interval solveset df < 0 symbol domain S.Reals return interval.is_subset df_neg_interval
def count_nonzero x return int _count_nonzero x
def get_sid principal try sid salt.utils.win_functions.get_sid_from_name principal except CommandExecutionError sid principaltry sid win32security.ConvertStringSidToSid sid except pywintypes.error raise CommandExecutionError 'Invaliduser/grouporsid {0}'.format principal except TypeError raise CommandExecutionErrorreturn sid
def _get_repr_cls value if value in REPRESENTATION_CLASSES value REPRESENTATION_CLASSES[value]try assert issubclass value BaseRepresentation except TypeError AssertionError raise ValueError u'Representationis{0!r}butmustbeaBaseRepresentationclassoroneofthestringaliases{1}'.format value list REPRESENTATION_CLASSES return value
def nmapspec2ports string result set for ports in string.split ' ' if '-' in ports ports map int ports.split '-' 1 result result.union xrange ports[0] ports[1] + 1 else result.add int ports return result
def _find_cached_images session sr_ref cached_images {}for vdi_ref vdi_rec in _get_all_vdis_in_sr session sr_ref try image_id vdi_rec['other_config']['image-id']except KeyError continuecached_images[image_id] vdi_refreturn cached_images
def make_rowcol string rowlens [ len x + 1 for x in string.split '\n' ]rowpos []acc 0for i in rowlens acc + irowpos.append acc def rowcol pos last 0for i k in enumerate rowpos 0 if pos < k return i pos - last last kreturn -1 -1 return rowcol
def withClass classname namespace '' classattr '%s class' % namespace if namespace else 'class' return withAttribute **{classattr classname}
def barthann M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym n np.arange 0 M fac np.abs n / M - 1.0 - 0.5 w 0.62 - 0.48 * fac + 0.38 * np.cos 2 * np.pi * fac return _truncate w needs_trunc
def test_SAMPIntegratedClient SAMPIntegratedClient
def test_scalar_column c table.Column 1.5 assert repr c '1.5' assert str c '1.5'
def ghissue_role name rawtext text lineno inliner options {} content [] try issue_num int text if issue_num < 0 raise ValueErrorexcept ValueError msg inliner.reporter.error 'GitHubissuenumbermustbeanumbergreaterthanorequalto1;"%s"isinvalid.' % text line lineno prb inliner.problematic rawtext rawtext msg return [prb] [msg] app inliner.document.settings.env.appif 'pull' in name.lower category 'pull'elif 'issue' in name.lower category 'issues'else msg inliner.reporter.error 'GitHubrolesinclude"ghpull"and"ghissue" "%s"isinvalid.' % name line lineno prb inliner.problematic rawtext rawtext msg return [prb] [msg] node make_link_node rawtext app category str issue_num options return [node] []
def One dtype None return Constant 1.0 dtype dtype
def write_html_file out_table outpath page_out PAGE_HTML % 'TaxaSummaries' out_table out open outpath 'w+' out.write page_out out.close
def convert_to_unicode s encoding_list if isinstance s bytearray s bytes s if isinstance s six.text_type return u'utf-8' s elif isinstance s six.string_types try enc u'utf-8'return enc six.text_type s enc except UnicodeError for e in encoding_list try return e six.text_type s e except UnicodeError LookupError passtry enc u'utf-8'return enc six.text_type s enc errors u'replace' except UnicodeError raise Exception _ u"Diffcontentcouldn'tbeconvertedtounicodeusingthefollowingencodings %s" % [u'utf-8'] + encoding_list else raise TypeError u'Valuetoconvertisunexpectedtype%s' type s
def _time_to_datetime value assert isinstance value datetime.time return datetime.datetime 1970 1 1 value.hour value.minute value.second value.microsecond
def member_status ret {'membership' {} 'summary' {'Valid' 0 'Leaving' 0 'Exiting' 0 'Joining' 0 'Down' 0}}out __execute_cmd 'riak-admin' 'member-status' ['stdout'].splitlines for line in out if line.startswith ' ' '-' 'Status' continueif '/' in line for item in line.split '/' key val item.split ' ' ret['summary'][key.strip ] val.strip if len line.split 4 status ring pending node line.split ret['membership'][node] {'Status' status 'Ring' ring 'Pending' pending}return ret
def transparent_image_overlay pos overlay_img img alpha roi slice pos[1] pos[1] + overlay_img.shape[0] slice pos[0] pos[0] + overlay_img.shape[1] try cv2.addWeighted overlay_img alpha img[roi] 1.0 - alpha 0 img[roi] except logger.debug 'transparent_image_overlaywasoutsideoftheworldimageandwasnotdrawn' pass
def _int64_feature value if not isinstance value list value [value]return tf.train.Feature int64_list tf.train.Int64List value value
def volume_info path out err utils.execute 'lvs' '-o' 'vg_all lv_all' '--separator' '|' path run_as_root True info [line.split '|' for line in out.splitlines ]if len info ! 2 raise RuntimeError _ 'Path%smustbeLVMlogicalvolume' % path return dict zip *info
def _value parameter class DummyLuigiTask luigi.Task param parameterreturn DummyLuigiTask .param
def _authenticate consumer_key consumer_secret token_data {'client_id' consumer_key 'client_secret' consumer_secret 'grant_type' 'client_credentials' 'scope' 'SMS'}token_resource 'https //api.telstra.com/v1/oauth/token'token_response requests.get token_resource params token_data timeout 10 .json if 'error' in token_response return Falsereturn token_response
def setup_input port pull_mode import RPi.GPIO as GPIOGPIO.setup port GPIO.IN GPIO.PUD_DOWN if pull_mode 'DOWN' else GPIO.PUD_UP
def get_html_subsection name return '<h2>{}</h2>'.format name
def nct_kurt_bug from numpy.testing import assert_almost_equalmvsk_10_1 1.08372 1.325546 0.39993 1.2499424941142943 assert_almost_equal stats.nct.stats 10 1 moments 'mvsk' mvsk_10_1 decimal 6 c1 np.array [1.08372] c2 np.array [0.075546 1.25] c3 np.array [0.0297802 0.580566] c4 np.array [0.0425458 1.17491 6.25] nc 1mc1 c1.item mc2 c2 * nc ** np.array [2 0] .sum mc3 c3 * nc ** np.array [3 1] .sum mc4 c4 np.array [0.0425458 1.17491 6.25] mvsk_nc mc2mvsk mc1 mc2 mc3 mc4
def test_cli_name test_apps from cliapp.app import testappassert testapp.cli.name testapp.name
def _validate_path path if not path raise ValueError 'Pathisempty' if not isinstance path basestring raise TypeError 'Pathshouldbeastringbutis%s %s .' % path.__class__ path
def validate_authorizer_ttl ttl_value ttl_value int positive_integer ttl_value if ttl_value > 3600 raise ValueError 'TheAuthorizerResultTtlInSecondsshouldbe< 3600' return ttl_value
def _parse_pem_key raw_key_input offset raw_key_input.find '-----BEGIN' if offset ! -1 return raw_key_input[offset ]
def FragmentCond pkt fragTypeTable [41016 41017]return pkt.version 1 and pkt.HPtype in fragTypeTable
def multi_source_dijkstra G sources target None cutoff None weight 'weight' if not sources raise ValueError 'sourcesmustnotbeempty' if target in sources return {target 0} {target [target]} weight _weight_function G weight paths {source [source] for source in sources}dist _dijkstra_multisource G sources weight paths paths cutoff cutoff target target return dist paths
def strip_headers post if '\n\n' in post headers body post.split '\n\n' 1 return body.lower else return post.lower
def _StructPackEncoder wire_type format value_size struct.calcsize format def SpecificEncoder field_number is_repeated is_packed local_struct_pack struct.packif is_packed tag_bytes TagBytes field_number wire_format.WIRETYPE_LENGTH_DELIMITED local_EncodeVarint _EncodeVarintdef EncodePackedField write value write tag_bytes local_EncodeVarint write len value * value_size for element in value write local_struct_pack format element return EncodePackedFieldelif is_repeated tag_bytes TagBytes field_number wire_type def EncodeRepeatedField write value for element in value write tag_bytes write local_struct_pack format element return EncodeRepeatedFieldelse tag_bytes TagBytes field_number wire_type def EncodeField write value write tag_bytes return write local_struct_pack format value return EncodeFieldreturn SpecificEncoder
def _start_relationships workflow parent child_el if 'to' not in child_el.attrib raise RuntimeError _ "Node%shasalinkthatismissing'to'attribute." % parent.name workflow.start parentto child_el.attrib['to']try child Node.objects.get workflow workflow name to except Node.DoesNotExist raise RuntimeError _ 'Node%shasnotbeendefined.' % to try obj Link.objects.filter parent parent .get name 'to' obj.child childexcept Link.DoesNotExist obj Link.objects.create name 'to' parent parent child child obj.save
def format_help_list hdict_cmds hdict_db string ''if hdict_cmds and any hdict_cmds.values string + '\n' + _SEP + '\n{CCommandhelpentries{n\n' + _SEP for category in sorted hdict_cmds.keys string + '\n{w%s{n \n' % str category .title string + '{G' + fill ' '.join sorted hdict_cmds[category] + '{n' if hdict_db and any hdict_db.values string + '\n\n' + _SEP + '\n\r{COtherhelpentries{n\n' + _SEP for category in sorted hdict_db.keys string + '\n\r{w%s{n \n' % str category .title string + '{G' + fill ' '.join sorted [str topic for topic in hdict_db[category]] + '{n' return string
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def repeat_elements x rep axis x_shape x.get_shape .as_list try splits tf.split value x num_or_size_splits x_shape[axis] axis axis except TypeError splits tf.split value x num_split x_shape[axis] split_dim axis x_rep [s for s in splits for i in range rep ]return concatenate x_rep axis
def show_migration_changes apps for app in apps print app.app_label migrations [migration for migration in app]reduce diff_migrations migrations
def _load_response response try data json.loads response.text except ValueError data response.textret {'code' response.status_code 'content' data}return ret
def line2d_dist l p a b c l x0 y0 preturn abs a * x0 + b * y0 + c / np.sqrt a ** 2 + b ** 2
def udivisors n generator False n as_int abs n if isprime n return [1 n]if n 1 return [1]if n 0 return []rv _udivisors n if not generator return sorted rv return rv
def zoneout h x ratio 0.5 train True if train return Zoneout ratio h x return x
def get_project_root settings_mod __import__ settings.SETTINGS_MODULE {} {} [''] return os.path.dirname os.path.abspath settings_mod.__file__
def IsPackageDir path packageName knownFileName import osif knownFileName is None knownFileName '.'return FileExists os.path.join os.path.join path packageName knownFileName
def test_editable_install script result script.pip 'install' '-e' 'INITools 0.2' expect_error True assert 'INITools 0.2shouldeitherbeapathtoalocalprojectoraVCSurl' in result.stderr assert not result.files_created assert not result.files_updated
def is_py3 import sysreturn sys.version_info[0] 3
def nunpack s default 0 l len s if not l return defaultelif l 1 return ord s elif l 2 return struct.unpack '>H' s [0]elif l 3 return struct.unpack '>L' '\x00' + s [0]elif l 4 return struct.unpack '>L' s [0]else return TypeError 'invalidlength %d' % l
def make_profile_middleware app global_conf log_filename 'profile.log.tmp' limit 40 limit int limit return ProfileMiddleware app log_filename log_filename limit limit
def close_db_connections func *args **kwargs def _close_db_connections *args **kwargs ret Nonetry ret func *args **kwargs finally from django.db import connectionsfor conn in connections.all conn.close return retreturn _close_db_connections
def multinomial random_state size None n 1 pvals [0.5 0.5] ndim None dtype 'int64' n tensor.as_tensor_variable n pvals tensor.as_tensor_variable pvals tmp pvals.T[0].T ndim size bcast _infer_ndim_bcast ndim size n tmp bcast bcast + pvals.type.broadcastable[ -1 ] op RandomFunction multinomial_helper tensor.TensorType dtype dtype broadcastable bcast ndim_added 1 return op random_state size n pvals
@not_implemented_for 'directed' def biconnected_component_subgraphs G copy True for comp_nodes in biconnected_components G if copy yield G.subgraph comp_nodes .copy else yield G.subgraph comp_nodes
def cleanup _lib.RAND_cleanup
def pick_info info sel copy True info._check_consistency if copy info deepcopy info if sel is None return infoelif len sel 0 raise ValueError 'Nochannelsmatchtheselection.' info['chs'] [info['chs'][k] for k in sel]info._update_redundant info['bads'] [ch for ch in info['bads'] if ch in info['ch_names'] ]comps deepcopy info['comps'] for c in comps row_idx [k for k n in enumerate c['data']['row_names'] if n in info['ch_names'] ]row_names [c['data']['row_names'][i] for i in row_idx]rowcals c['rowcals'][row_idx]c['rowcals'] rowcalsc['data']['nrow'] len row_names c['data']['row_names'] row_namesc['data']['data'] c['data']['data'][row_idx]info['comps'] compsinfo._check_consistency return info
def load_theme_plugins if not pkg_resources return []theme_paths []for plugin in pkg_resources.iter_entry_points 'sphinx_themes' func_or_path plugin.load try path func_or_path except Exception path func_or_pathif isinstance path string_types theme_paths.append path else raise ThemeError 'Plugin%rdoesnotresponsecorrectly.' % plugin.module_name return theme_paths
def get url conn urlopen url resp conn.read conn.close return resp
def gce_connect module provider None if not HAS_LIBCLOUD_BASE module.fail_json msg 'libcloudmustbeinstalledtousethismodule' provider provider or Provider.GCE return gcp_connect module provider get_driver USER_AGENT_PRODUCT USER_AGENT_VERSION
def walkModules importPackages False return theSystemPath.walkModules importPackages importPackages
@pytest.mark.parametrize 'i item' enumerate ITEMS def test_urls objects i item assert objects.history.itemAt i .url item.url
def signal_job jid sig if HAS_PSUTIL is False log.warning 'saltutil.signaljobcalled butpsutilisnotinstalled.InstallpsutiltoensuremorereliableandaccuratePIDmanagement.' for data in running if data['jid'] jid try if HAS_PSUTIL for proc in salt.utils.psutil_compat.Process pid data['pid'] .children recursive True proc.send_signal sig os.kill int data['pid'] sig if HAS_PSUTIL is False and 'child_pids' in data for pid in data['child_pids'] os.kill int pid sig return 'Signal{0}senttojob{1}atpid{2}'.format int sig jid data['pid'] except OSError path os.path.join __opts__['cachedir'] 'proc' str jid if os.path.isfile path os.remove path return 'Job{0}wasnotrunningandjobdatahasbeencleanedup'.format jid return ''
def get_distribution_path venv distribution _verify_safe_py_code distribution bin_path _verify_virtualenv venv ret __salt__['cmd.exec_code_all'] bin_path "importpkg_resources;print pkg_resources.get_distribution '{0}' .location ".format distribution if ret['retcode'] ! 0 raise CommandExecutionError '{stdout}\n{stderr}'.format **ret return ret['stdout']
def diff_index_filenames ref out git.diff_index ref name_only True z True [STDOUT]return _parse_diff_filenames out
@add_to_dict _after_create_functions def after_VIF_create vif_ref vif_rec vm_ref vif_rec['VM']vm_rec _db_content['VM'][vm_ref]vm_rec['VIFs'].append vif_ref
def fcontext_policy_applied name recursive False ret {'name' name 'result' False 'changes' {} 'comment' ''}changes_text __salt__['selinux.fcontext_policy_is_applied'] name recursive if changes_text '' ret.update {'result' True 'comment' 'SElinuxpoliciesarealreadyappliedforfilespec"{0}"'.format name } return retif __opts__['test'] ret.update {'result' None} else apply_ret __salt__['selinux.fcontext_apply_policy'] name recursive if apply_ret['retcode'] ! 0 ret.update {'comment' apply_ret} else ret.update {'result' True} ret.update {'changes' apply_ret.get 'changes' } return ret
def test_command_completion qtmodeltester monkeypatch stubs config_stub key_config_stub _patch_cmdutils monkeypatch stubs 'qutebrowser.completion.models.miscmodels.cmdutils' config_stub.data['aliases'] {'rock' 'roll'}key_config_stub.set_bindings_for 'normal' {'s' 'stop' 'rr' 'roll' 'ro' 'rock'} model miscmodels.CommandCompletionModel qtmodeltester.data_display_may_return_none Trueqtmodeltester.check model _check_completions model {'Commands' [ 'stop' 'stopqutebrowser' 's' 'drop' 'dropalluserdata' '' 'roll' 'nevergonnagiveyouup' 'rr' 'rock' "Aliasfor'roll'" 'ro' ]}
def assign obj **kwargs obj.__dict__.update kwargs
def _get_basic_info ca_name cert ca_dir None if ca_dir is None ca_dir '{0}/{1}'.format _cert_base_path ca_name index_file '{0}/index.txt'.format ca_dir expire_date _four_digit_year_to_two_digit datetime.strptime cert.get_notAfter four_digit_year_fmt serial_number format cert.get_serial_number 'X' subject '/'subject + '/'.join ['{0} {1}'.format x y for x y in cert.get_subject .get_components ] subject + '\n'return index_file expire_date serial_number subject
def get_node conn name nodes conn.list_nodes for node in nodes if node.name name __utils__['cloud.cache_node'] salt.utils.simple_types_filter node.__dict__ __active_provider_name__ __opts__ return node
def script_from_examples s output []for piece in DocTestParser .parse s if isinstance piece Example output.append piece.source[ -1 ] want piece.wantif want output.append '#Expected ' output + [ '##' + l for l in want.split '\n' [ -1 ]]else output + [_comment_line l for l in piece.split '\n' [ -1 ]]while output and output[ -1 ] '#' output.pop while output and output[0] '#' output.pop 0 return '\n'.join output
def print_tree node print tree node
def test_classifier_single_class X [[1 2] [3 4]]y [1 1]assert_raise_message ValueError 'Thissolverneedssamplesofatleast2classesinthedata' LogisticRegression solver 'sag' .fit X y
def test_x_minus_y_not_same_as_x_lt_y x I + 2 y I + 3 raises TypeError lambda x < y assert x - y < 0 ineq Lt x y evaluate False raises TypeError lambda ineq.doit assert ineq.lhs - ineq.rhs < 0 t Symbol 't' imaginary True x 2 + t y 3 + t ineq Lt x y evaluate False raises TypeError lambda ineq.doit assert ineq.lhs - ineq.rhs < 0 x I + 2 y 2 * I + 3 raises TypeError lambda x < y raises TypeError lambda x - y < 0
def bag_range n npartitions size n // npartitions name 'range-%d-npartitions-%d' % n npartitions ijs list enumerate take npartitions range 0 n size dsk dict name i reify range j min j + size n for i j in ijs if n % npartitions ! 0 i j ijs[ -1 ]dsk[ name i ] reify range j n return Bag dsk name npartitions
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def raise_404_if_not_version req min_version max_version None want_version req.environ[MICROVERSION_ENVIRON]if not want_version.matches min_version max_version raise webob.exc.HTTPNotFound
def _tokenize description empty _matchingString u'' description colon _matchingString u' ' description equals _matchingString u' ' description backslash _matchingString u'\\' description current emptyops colon + equals nextOps {colon colon + equals equals colon}iterdesc iter iterbytes description for n in iterdesc if n in iterbytes ops yield _STRING current yield _OP n current emptyops nextOps[n]elif n backslash current + next iterdesc else current + n yield _STRING current
def _present w_prime_star w w_backtrack index -1 flag 0for arr in w_backtrack index + 1if np.all w_prime_star arr[0] and np.all w arr[1] flag + 1breakif not flag return -1 return index
def AssignSubtypes tree subtype_assigner _SubtypeAssigner subtype_assigner.Visit tree
def get_aliases_base_paths aliases_base_paths cfg.CONF.content.aliases_base_paths or '' if aliases_base_paths.endswith ' ' aliases_base_paths aliases_base_paths[ -1 ]result []aliases_base_paths aliases_base_paths.split ' ' result aliases_base_pathsresult [path for path in result if path]result list OrderedSet result return result
def unparse input_dict output None encoding 'utf-8' full_document True short_empty_elements False **kwargs if full_document and len input_dict ! 1 raise ValueError 'Documentmusthaveexactlyoneroot.' must_return Falseif output is None output StringIO must_return Trueif short_empty_elements content_handler XMLGenerator output encoding True else content_handler XMLGenerator output encoding if full_document content_handler.startDocument for key value in input_dict.items _emit key value content_handler full_document full_document **kwargs if full_document content_handler.endDocument if must_return value output.getvalue try value value.decode encoding except AttributeError passreturn value
def iter_good_values for ctype values in sorted GOOD_VALUES.items for value in values yield ctype value
def collect_docs_for_readmes files_to_docs readmes_to_docs defaultdict list for file docs in files_to_docs.iteritems readme get_readme_path file readmes_to_docs[readme].extend docs readmes_to_docs[readme] list set readmes_to_docs[readme] return readmes_to_docs
def return_url_handler request logger1.info '>>returnurlhandlerstart' if notify_verify request.GET tn request.GET.get 'out_trade_no' trade_no request.GET.get 'trade_no' logger1.info 'Changethestatusofbill%s' % tn bill Bill.objects.get pk tn trade_status request.GET.get 'trade_status' logger1.info 'thestatuschangedto%s' % trade_status bill.trade_status trade_statusupgrade_bill bill 30 * 6 + 7 url send_goods_confirm_by_platform trade_no req urllib.urlopen url logger1.info 'sendgoodsconfirmation.%s' % url return HttpResponseRedirect reverse 'payment_success' return HttpResponseRedirect reverse 'payment_error'
def namespace namespace None Register._default_namespace namespace or ''
def create_embedded_plot model update_time params pickle.loads model.params extra_text 'Lastupdated %s' % update_time if model.graph_type 'metrics' plot_info MetricsPlot query_dict params['queries'] plot_type params['plot'] inverted_series params['invert'] normalize_to None drilldown_callback '' figure areas_unused _create_metrics_plot_helper plot_info extra_text elif model.graph_type 'qual' plot_info QualificationHistogram query params['query'] filter_string params['filter_string'] interval params['interval'] drilldown_callback '' figure areas_unused _create_qual_histogram_helper plot_info extra_text else raise ValueError 'Invalidgraph_type%s' % model.graph_type image bounding_box_unused _create_png figure return image
def install_error_handlers root_urlconf_module getattr settings u'ROOT_URLCONF' None if not root_urlconf_module returntry root_urlconf import_module root_urlconf_module except ImportError returnfor error_status in 400 403 404 500 handler_attr HANDLER_ATTR_FMT % error_status if hasattr root_urlconf handler_attr _URLCONF_ERROR_HANDLERS[handler_attr] getattr root_urlconf handler_attr setattr root_urlconf handler_attr make_error_view error_status
def markdown text mode '' context '' raw False return gh.markdown text mode context raw
def reject_dict match include_accepted False include_denied False skey get_key __opts__ return skey.reject match_dict match include_accepted include_accepted include_denied include_denied
def get_trial_environment cluster package_source return {'FLOCKER_ACCEPTANCE_CONTROL_NODE' cluster.control_node.address 'FLOCKER_ACCEPTANCE_NUM_AGENT_NODES' str len cluster.agent_nodes 'FLOCKER_ACCEPTANCE_VOLUME_BACKEND' cluster.dataset_backend.name 'FLOCKER_ACCEPTANCE_API_CERTIFICATES_PATH' cluster.certificates_path.path 'FLOCKER_ACCEPTANCE_HOSTNAME_TO_PUBLIC_ADDRESS' json.dumps {node.private_address node.address for node in cluster.agent_nodes if node.private_address is not None } 'FLOCKER_ACCEPTANCE_DEFAULT_VOLUME_SIZE' bytes cluster.default_volume_size 'FLOCKER_ACCEPTANCE_TEST_VOLUME_BACKEND_CONFIG' cluster.dataset_backend_config_file.path 'FLOCKER_ACCEPTANCE_DISTRIBUTION' cluster.control_node.distribution 'FLOCKER_ACCEPTANCE_PACKAGE_BRANCH' package_source.branch or '' 'FLOCKER_ACCEPTANCE_PACKAGE_VERSION' package_source.version or '' 'FLOCKER_ACCEPTANCE_PACKAGE_BUILD_SERVER' package_source.build_server}
def _random_password length DEFAULT_LENGTH chars C.DEFAULT_PASSWORD_CHARS assert isinstance chars text_type '%s %s isnotatext_type' % chars type chars random_generator random.SystemRandom password []while len password < length new_char random_generator.choice chars password.append new_char return u''.join password
def test_write_twoline_normal out StringIO ascii.write dat out Writer ascii.FixedWidthTwoLine assert_equal_splitlines out.getvalue 'Col1Col2Col3Col4\n---------------------\n1.2"hello"1a\n2.4\'sworlds22\n'
def neg_expr operator return lo.LinOp lo.NEG operator.size [operator] None
def update_generators for generator in _GENERATOR_DB.keys install_templates_translations generator add_variables_to_context generator interlink_static_files generator interlink_removed_content generator interlink_translated_content generator
def check_bool result func cargs if bool result return Trueelse return False
def fail_on_eslint arg if 'eslint' in arg paver.easy.sh 'exit1' else return
def _gl_transform estimators X method n_sample n_iter X.shape[0] X.shape[ -1 ] for ii est in enumerate estimators X_stack X.transpose np.r_[ 0 X.ndim - 1 range 1 X.ndim - 1 ] X_stack X_stack.reshape np.r_[ n_sample * n_iter X_stack.shape[2 ] ] transform getattr est method _y_pred transform X_stack if _y_pred.ndim 2 _y_pred np.reshape _y_pred [n_sample n_iter _y_pred.shape[1]] else shape np.r_[ n_sample n_iter _y_pred.shape[1 ] ].astype int _y_pred np.reshape _y_pred shape if ii 0 y_pred _gl_init_pred _y_pred X len estimators y_pred[ ii ...] _y_predreturn y_pred
def previous_key tuple_of_tuples key for i t in enumerate tuple_of_tuples if t[0] key try return tuple_of_tuples[ i - 1 ][0]except IndexError return None
def is_pseudographical sequence s list sequence if not nx.utils.is_list_of_ints s return Falsereturn sum s % 2 0 and min s > 0
def test_mnist_pi train load_train_file os.path.join pylearn2.__path__[0] 'scripts/papers/maxout/mnist_pi.yaml' init_value control.load_datacontrol.load_data [False]train.dataset MNIST which_set 'train' start 0 stop 100 train.algorithm._set_monitoring_dataset train.dataset control.load_data init_valuetrain.algorithm.termination_criterion EpochCounter max_epochs 1 train.extensions.pop 0 train.save_freq 0train.main_loop
def _parse_check rule if rule '!' return FalseCheck elif rule '@' return TrueCheck try kind match rule.split ' ' 1 except Exception LOG.exception _ 'Failedtounderstandrule%s' % rule return FalseCheck if kind in _checks return _checks[kind] kind match elif None in _checks return _checks[None] kind match else LOG.error _ 'Nohandlerformatchesofkind%s' % kind return FalseCheck
def sortByValue d items d.items backitems [[v[1] v[0]] for v in items]backitems.sort backitems.reverse return [backitems[i][1] for i in range 0 len backitems ]
def logs name return _client_wrapper 'logs' name
def task_id_in ids body message return body[u'id'] in ids
def rfind s *args return _apply s.rfind args
def residue_depth residue surface atom_list residue.get_unpacked_list length len atom_list d 0for atom in atom_list coord atom.get_coord d d + min_dist coord surface return d / length
def multiply_by_two number return float number * 2
def add_lazy_relation cls field relation operation if relation RECURSIVE_RELATIONSHIP_CONSTANT app_label cls._meta.app_labelmodel_name cls.__name__else try app_label model_name relation.split '.' except ValueError app_label cls._meta.app_labelmodel_name relationexcept AttributeError app_label relation._meta.app_labelmodel_name relation._meta.object_namemodel get_model app_label model_name seed_cache False only_installed False if model operation field model cls else key app_label model_name value cls field operation pending_lookups.setdefault key [] .append value
def time_xlsxwriter start_time clock workbook xlsxwriter.Workbook 'xlsxwriter.xlsx' worksheet workbook.add_worksheet for row in range row_max // 2 for col in range col_max worksheet.write_string row * 2 col 'Row %dCol %d' % row col for col in range col_max worksheet.write_number row * 2 + 1 col row + col workbook.close elapsed clock - start_time print_elapsed_time 'xlsxwriter' elapsed
def create_large_tree value_of_nodes [1 2 3 4 5 6 7 8 9 10 'a' 'b' 'c' 'd' 'e']tree ''depth 0count 0while depth < 4 if depth 0 tree [value_of_nodes[0] [] []]depth + 1count + 1elif depth 1 for i in [1 2] tree[i] [value_of_nodes[count] [] []]count + 1depth + 1elif depth 2 for i j in itertools.product [1 2] repeat depth tree[i][j] [value_of_nodes[count] [] []]count + 1depth + 1elif depth 3 for i j k in itertools.product [1 2] repeat depth tree[i][j][k] [value_of_nodes[count] [] []]count + 1depth + 1return tree
def flattenValue value for i in iter value if isListLike i for j in flattenValue i yield j else yield i
def _get_or_create_user_list_for_site sailthru_client site None default_list_name None if site and site.get 'id' ! settings.SITE_ID list_name site.get 'domain' '' .replace '.' '_' + '_user_list' else list_name default_list_namesailthru_list _get_or_create_user_list sailthru_client list_name return list_name if sailthru_list else default_list_name
def tenant_delete tenant_id None name None profile None **connection_args kstone auth profile **connection_args if name for tenant in getattr kstone _TENANTS None .list if tenant.name name tenant_id tenant.idbreakif not tenant_id return {'Error' 'Unabletoresolvetenantid'}getattr kstone _TENANTS None .delete tenant_id ret 'TenantID{0}deleted'.format tenant_id if name ret + ' {0} '.format name return ret
def dictfetchmany cursor number return cursor.dictfetchmany number
def access_key k if QKeySequence.keyBindings k return u' DCTB ' + QKeySequence k .toString QKeySequence.NativeText return u''
def cache_clean path None runas None env None env env or {} if runas uid salt.utils.get_uid runas if uid env.update {'SUDO_UID' '{0}'.format uid 'SUDO_USER' ''} cmd ['npm' 'cache' 'clean']if path cmd.append path cmd ''.join cmd result __salt__['cmd.run_all'] cmd cwd None runas runas env env python_shell True ignore_retcode True if result['retcode'] ! 0 log.error result['stderr'] return Falsereturn True
def libvlc_vlm_get_media_instance_seekable p_instance psz_name i_instance f _Cfunctions.get 'libvlc_vlm_get_media_instance_seekable' None or _Cfunction 'libvlc_vlm_get_media_instance_seekable' 1 1 1 None ctypes.c_int Instance ctypes.c_char_p ctypes.c_int return f p_instance psz_name i_instance
def _AddTool tool _msvs_validators[tool.msvs_name] {}_msbuild_validators[tool.msbuild_name] {}_msvs_to_msbuild_converters[tool.msvs_name] {}_msbuild_name_of_tool[tool.msvs_name] tool.msbuild_name
def arglist_to_dict arglist return dict x.split ' ' 1 for x in arglist
def _get_next_vmid return int query 'get' 'cluster/nextid'
def linkify_bounce_url_callback attrs new False attrs['href'] get_outgoing_url attrs['href'] return attrs
def bind_table_action action_name _actions_locator by.By.CSS_SELECTOR 'div.table_actions>button div.table_actions>a' def decorator method @functools.wraps method def wrapper table actions table._get_elements *_actions_locator action_element Nonefor action in actions target_action_id '%s__action_%s' % table.name action_name if action.get_attribute 'id' target_action_id action_element actionbreakif action_element is None msg "Couldnotbindmethod'%s'toactioncontrol'%s'" % method.__name__ action_name raise ValueError msg return method table action_element return wrapperreturn decorator
def _iri_utf8_errors_handler exc bytes_as_ints bytes_to_list exc.object[exc.start exc.end] replacements [ u'%%%02x' % num for num in bytes_as_ints]return u''.join replacements exc.end
def read_index_dict f ret {}for x in read_index f ret[x[0]] IndexEntry *x[1 ] return ret
@pytest.mark.parametrize 'fast_writer' [True False] def test_write_comments fast_writer data ascii.read '#c1\n#c2 DCTB \na b c\n#c3\n1 2 3' out StringIO ascii.write data out format 'basic' fast_writer fast_writer expected ['#c1' '#c2' '#c3' 'abc' '123']assert out.getvalue .splitlines expected out StringIO ascii.write data out format 'commented_header' fast_writer fast_writer expected ['#abc' '#c1' '#c2' '#c3' '123']assert out.getvalue .splitlines expected out StringIO ascii.write data out format 'basic' comment False fast_writer fast_writer expected ['abc' '123']assert out.getvalue .splitlines expected
def index_template_get name hosts None profile None es _get_instance hosts profile try ret es.indices.get_template name name return retexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def metadef_resource_type_get context resource_type_name session None session session or get_session return metadef_resource_type_api.get context resource_type_name session
def handle_activity user post original_author_id None if original_author_id is not None and user.id ! original_author_id returnif getattr post 'context' 'course' TEAM_DISCUSSION_CONTEXT CourseTeamMembership.update_last_activity user post.commentable_id
def logger_init log logging.getLogger 'pyinotify' console_handler logging.StreamHandler console_handler.setFormatter logging.Formatter '[% asctime s% name s% levelname s]% message s' log.addHandler console_handler log.setLevel 20 return log
def sprot_search_ful text make_wild None swissprot 1 trembl None cgi 'http //www.expasy.ch/cgi-bin/sprot-search-ful' variables {'SEARCH' text}if make_wild variables['makeWild'] 'on'if swissprot variables['S'] 'on'if trembl variables['T'] 'on'options _urlencode variables fullcgi '%s?%s' % cgi options handle _urlopen fullcgi return handle
def load_key pubkey try return load_pem_public_key pubkey.encode default_backend except ValueError pubkey pubkey.replace 'BEGINRSA' 'BEGIN' .replace 'ENDRSA' 'END' return load_pem_public_key pubkey.encode default_backend
def xonsh_help x lineno None col None return xonsh_call '__xonsh_help__' [x] lineno lineno col col
def get_volume_summary_all context return IMPL.get_volume_summary_all context
def alias_root v if v.owner is None return vvmap getattr v.owner.op 'view_map' {} dmap getattr v.owner.op 'destroy_map' {} outpos v.owner.outputs.index v v_views vmap.get outpos [] + dmap.get outpos [] if len v_views > 1 raise NotImplementedError str v + 'isaview/destroyedversionofmorethenoneinputs.Currently weonlysupportthecasewhereanoutputisavieworadestroyedversionofoneinput.' elif v_views return alias_root v.owner.inputs[v_views[0]] else return v
def logSubtitle showid season episode status subtitleResult resource subtitleResult.language.opensubtitlesprovider subtitleResult.provider_name status quality Quality.splitCompositeStatus status action Quality.compositeStatus SUBTITLED quality _logHistoryItem action showid season episode quality resource provider
def show_refs objs max_depth 3 extra_ignore filter None too_many 10 highlight None filename None extra_info None refcounts False shortnames True output None _show_graph objs max_depth max_depth extra_ignore extra_ignore filter filter too_many too_many highlight highlight edge_func gc.get_referents swap_source_target True filename filename extra_info extra_info refcounts refcounts shortnames shortnames output output
def health_checks consul_url None service None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif not service raise SaltInvocationError 'Requiredargument"service"ismissing.' if 'dc' in kwargs query_params['dc'] kwargs['dc']function 'health/checks/{0}'.format service ret _query consul_url consul_url function function query_params query_params return ret
def encode_integer integer prefix_bits max_number 2 ** prefix_bits - 1 if integer < max_number return bytearray [integer] else elements [max_number]integer integer - max_number while integer > 128 elements.append integer % 128 + 128 integer integer // 128 elements.append integer return bytearray elements
def _vindex_transpose block axis axes [axis] + list range axis + list range axis + 1 block.ndim return block.transpose axes
@require_GETdef contributors_detail request readout_slug product _get_product request return _kb_detail request readout_slug CONTRIBUTOR_READOUTS 'dashboards.contributors' _ 'KnowledgeBaseDashboard' locale settings.WIKI_DEFAULT_LANGUAGE product product
def moveIntfNoRetry intf dstNode printError False intf str intf cmd 'iplinkset%snetns%s' % intf dstNode.pid cmdOutput quietRun cmd if cmdOutput if printError error '***Error moveIntf ' + intf + 'notsuccessfullymovedto' + dstNode.name + ' \n' cmdOutput return Falsereturn True
def oo_combine_key_value data joiner ' ' if not isinstance data list raise errors.AnsibleFilterError '|failedexpectsfirstparamisalist' rval []for item in data rval.append '%s%s%s' % item['key'] joiner item['value'] return rval
def last_check cache cache_file if cache return os.path.getmtime cache_file return time.time
def _reduced_kernel_size_for_small_input input_tensor kernel_size shape input_tensor.get_shape .as_list if shape[1] is None or shape[2] is None kernel_size_out kernel_sizeelse kernel_size_out [min shape[1] kernel_size[0] min shape[2] kernel_size[1] ]return kernel_size_out
def hi_given samples i W_list b_list beta 1.0 apply_sigmoid True depth len samples hi_mean 0.0if i < depth - 1 wip1 W_list[ i + 1 ]hi_mean + T.dot samples[ i + 1 ] wip1.T * beta if i > 0 wi W_list[i]hi_mean + T.dot samples[ i - 1 ] wi * beta hi_mean + b_list[i] * beta if apply_sigmoid return T.nnet.sigmoid hi_mean else return hi_mean
@frappe.whitelist def set_order new_order user None if isinstance new_order basestring new_order json.loads new_order for i module_name in enumerate new_order if module_name not in u'Explore' if user icon get_user_copy module_name user else name frappe.db.get_value u'DesktopIcon' {u'standard' 1 u'module_name' module_name} if name icon frappe.get_doc u'DesktopIcon' name else name add_user_icon module_name standard 1 icon frappe.get_doc u'DesktopIcon' name icon.db_set u'idx' i clear_desktop_icons_cache
def getLocalDictionary attributesKey elementNode xmlProcessor elementNode.getXMLProcessor if len xmlProcessor.functions < 1 return Nonereturn xmlProcessor.functions[ -1 ].localDictionary
def test_finder_detects_latest_find_links data req InstallRequirement.from_line 'simple' None finder PackageFinder [data.find_links] [] session PipSession link finder.find_requirement req False assert link.url.endswith 'simple-3.0.tar.gz'
def disassociate_all context specs_id try get_qos_specs context specs_id db.qos_specs_disassociate_all context specs_id except db_exc.DBError LOG.exception _LE 'DBerror ' LOG.warning _LW 'Failedtodisassociateqosspecs%s.' specs_id raise exception.QoSSpecsDisassociateFailed specs_id specs_id type_id None
def build_submit_description executable output error user_log query_params all_query_params DEFAULT_QUERY_CLASSAD.copy all_query_params.update query_params submit_description []for key value in all_query_params.items submit_description.append '%s %s' % key value submit_description.append 'executable ' + executable submit_description.append 'output ' + output submit_description.append 'error ' + error submit_description.append 'log ' + user_log submit_description.append 'queue' return '\n'.join submit_description
def startLogging file *a **kw if isinstance file LoggingFile returnflo FileLogObserver file startLoggingWithObserver flo.emit *a **kw return flo
def core_observations_across_sample_ids table sample_ids None fraction_for_core 1.0 try result list filter_table_to_core table sample_ids fraction_for_core .ids axis 'observation' except TableException result []return result
def get_subject_and_message subject_template message_template param_dict subject render_to_string subject_template param_dict message render_to_string message_template param_dict return subject message
def list_l3_agent_hosting_routers router profile None conn _auth profile return conn.list_l3_agent_hosting_routers router
def format_bytes_to_human size precision 2 size int size fmt '%%1.%df%%s' % precision for unit in ['B' 'KB' 'MB' 'GB' 'TB'] if size < 1024.0 return fmt % size unit size / 1024.0
def read_address space start length None if not length length linux_process_info.address_sizefmt '<I' if length 4 else '<Q' return struct.unpack fmt space.read start length [0]
def _remove_dnsmasq_accept_rules dev table iptables_manager.ipv4['filter']for port in [67 53] for proto in ['udp' 'tcp'] args {'dev' dev 'port' port 'proto' proto}table.remove_rule 'INPUT' '-i% dev s-p% proto s-m% proto s--dport% port s-jACCEPT' % args iptables_manager.apply
def load_network_dict try cache_db_con db.DBConnection 'cache.db' cur_network_list cache_db_con.select 'SELECT*FROMnetwork_timezones;' if not cur_network_list update_network_dict cur_network_list cache_db_con.select 'SELECT*FROMnetwork_timezones;' network_dict.clear network_dict.update dict cur_network_list except Exception pass
def convert_group_name_or_id_to_id group_name_or_id context session context['session']result session.query model.Group .filter_by id group_name_or_id .first if not result result session.query model.Group .filter_by name group_name_or_id .first if not result raise df.Invalid '%s %s' % _ 'Notfound' _ 'Group' return result.id
def annotate_validation_results results if isinstance results dict validation resultselse from .utils import ValidationComparatorvalidation ValidationComparator results[1] .compare_results results[0] validation.setdefault 'signing_summary' {'trivial' 0 'low' 0 'medium' 0 'high' 0} validation['passed_auto_validation'] addon_can_be_signed validation if not settings.SIGNING_SERVER validation skip_signing_warning validation return validation
@task ignore_result True def remove_empty_groups from mozillians.groups.models import Group Skillfor model in [Group Skill] model.objects.annotate mcount Count 'members' .filter mcount 0 .delete
def smartsplit code strings []pos 0while pos < len code if code[pos] '"' word ''pos + 1while pos < len code if code[pos] '"' breakif code[pos] '\\' word + '\\'pos + 1word + code[pos]pos + 1strings.append '"%s"' % word pos + 1return strings
def _missing_raise raise ClusterError 'Oneoftheclustersisempty.Re-runkmeanwithadifferentinitialization.'
def delete_task name location '\\' if name not in list_tasks location return '{0}notfoundin{1}'.format name location pythoncom.CoInitialize task_service win32com.client.Dispatch 'Schedule.Service' task_service.Connect task_folder task_service.GetFolder location task_folder.DeleteTask name 0 if name not in list_tasks location return Trueelse return False
def plotting_pos nobs a return np.arange 1.0 nobs + 1 - a / nobs - 2 * a + 1
def evidence_url user_id course_key return site_prefix + reverse 'certificates html_view' kwargs {'user_id' user_id 'course_id' unicode course_key } + '?evidence_visit 1'
def convert_x_domain mpl_plot_bounds mpl_max_x_bounds mpl_x_dom [mpl_plot_bounds[0] mpl_plot_bounds[0] + mpl_plot_bounds[2] ]plotting_width mpl_max_x_bounds[1] - mpl_max_x_bounds[0] x0 mpl_x_dom[0] - mpl_max_x_bounds[0] / plotting_width x1 mpl_x_dom[1] - mpl_max_x_bounds[0] / plotting_width return [x0 x1]
def _read_complex_float fid tag shape rlims if shape is not None shape shape[0] shape[1] * 2 d _fromstring_rows fid tag.size dtype '>f4' shape shape rlims rlims d d[ 2] + 1j * d[1 2] return d
def _validate_args args unpassable_types _get_unpassable_types args if unpassable_types msg "argumentsoftype'%s'cannotbepassedtoremoteprofilers"msg % ' '.join t.__name__ for t in unpassable_types raise TypeError msg
def google_has_height style if 'height' in style return Truereturn False
def multipath_flush device if not os.path.exists device return '{0}doesnotexist'.format device cmd 'multipath-f{0}'.format device return __salt__['cmd.run'] cmd .splitlines
def get_configured_provider return config.is_provider_configured __opts__ __active_provider_name__ or __virtualname__ 'user' 'password' 'url'
def valid_course_modules course_module_list master_course_key course_chapters get_course_chapters master_course_key if course_chapters is None return Falsereturn set course_module_list .intersection set course_chapters set course_module_list
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_repository_owner_from_clone_url repository_clone_url tmp_url common_util.remove_protocol_and_user_from_clone_url repository_clone_url return get_repository_owner tmp_url
def escape s if s is None return ''assert isinstance s basestring 'expected%sbutgot%s;value %s' % basestring type s s s s.replace '\\' '\\\\' s s.replace '\n' '\\n' s s.replace ' DCTB ' '\\t' s s.replace ' ' ' DCTB ' return s
def namespace namespace None Register._default_namespace namespace or ''
def _device_pointer_attr devmem attr odata error driver.cuPointerGetAttribute byref odata attr device_ctypes_pointer devmem driver.check_error error 'Failedtoquerypointerattribute'
def storeCallResults obj verbose False results []oldcall obj.__class__.__call__def newcall *args **kwargs result oldcall *args **kwargs results.append result if verbose print result return resultobj.__class__.__call__ newcallreturn results
def get_user_credentials user credential_configuration CredentialsApiConfig.current user_query {u'status' u'awarded' u'username' user.username}use_cache credential_configuration.is_cache_enabled and not user.is_staff cache_key credential_configuration.CACHE_KEY + u'.' + user.username if use_cache else None credentials get_edx_api_data credential_configuration user u'credentials' querystring user_query cache_key cache_key return credentials
def makeRequests callable args_list callback None exc_callback None requests []for item in args_list if isinstance item tuple requests.append WorkRequest callable item[0] item[1] callback callback exc_callback exc_callback else requests.append WorkRequest callable [item] None callback callback exc_callback exc_callback return requests
def emotional_jenkins registry xml_parent data XML.SubElement xml_parent 'org.jenkinsci.plugins.emotional__jenkins.EmotionalJenkinsPublisher'
def _create_unique_device_link backup_id volume_path volume_id bckup_mode if _image_mode bckup_mode hardlink_path utils.make_dev_path '%s-%s' % CONF.backup_tsm_volume_prefix backup_id else dir volname os.path.split volume_path hardlink_path '%s/%s-%s' % dir CONF.backup_tsm_volume_prefix backup_id _make_link volume_path hardlink_path volume_id return hardlink_path
def test_only_major_dots_every line Line show_only_major_dots True x_labels_major_every 3 line.add 'test' range 12 line.x_labels map str range 12 q line.render_pyquery assert len q '.dots' 4
def test_nm2__wrong_nn_obj ratio 'auto'nn 'rnd'nm2 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS return_indices True n_neighbors nn assert_raises ValueError nm2.fit_sample X Y
def TerminateInstance region instance_id ec2 _Connect region ec2.terminate_instances [instance_id]
def test_FixedLocator_set_params fixed mticker.FixedLocator range 0 24 nbins 5 fixed.set_params nbins 7 assert fixed.nbins 7
def _get_flaky_annotation case method case._get_test_method return getattr method _FLAKY_ATTRIBUTE None
def PatchOsEnviron os_module os os_module.environ RequestLocalEnviron current_request
def escapedComment data if isinstance data unicode data data.encode 'utf-8' data data.replace '--' '--' .replace '>' '&gt;' if data and data[ -1 ] '-' data + ''return data
def _get_veths net_data if isinstance net_data dict net_data list net_data.items nics salt.utils.odict.OrderedDict current_nic salt.utils.odict.OrderedDict no_names Truefor item in net_data if item and isinstance item dict item list item.items [0]elif isinstance item six.string_types sitem item.strip if sitem.startswith '#' or not sitem continueelif ' ' in item item tuple [a.strip for a in item.split ' ' 1 ] if item[0] 'lxc.network.type' current_nic salt.utils.odict.OrderedDict if item[0] 'lxc.network.name' no_names Falsenics[item[1].strip ] current_niccurrent_nic[item[0].strip ] item[1].strip if no_names and current_nic nics[DEFAULT_NIC] current_nicreturn nics
def parse_sphinx_searchindex searchindex if hasattr searchindex 'decode' searchindex searchindex.decode 'UTF-8' query 'objects 'pos searchindex.find query if pos < 0 raise ValueError '"objects "notfoundinsearchindex' sel _select_block searchindex[pos ] '{' '}' objects _parse_dict_recursive sel query 'filenames 'pos searchindex.find query if pos < 0 raise ValueError '"filenames "notfoundinsearchindex' filenames searchindex[ pos + len query + 1 ]filenames filenames[ filenames.find ']' ]filenames [f.strip '"' for f in filenames.split ' ' ]return filenames objects
def open_error_resource need 'Estr' 1 filename 'errors.rsrc' modname __name__
def group_from_value groups v sum 0for g p in groups sum sum + p if sum > v return greturn g
def unescape_encoded_uri_component escaped_string return urllib.unquote escaped_string .decode 'utf-8'
def _double_prefix deque new_len max len deque[0] * 2 len deque[0] + len deque[1] _merge_prefix deque new_len
def get_internal_endpoint path '' return get_endpoint settings.EDXNOTES_INTERNAL_API path
def get_plugin_by_name name issued_by u'???' if name not in plugins raise DependencyError issued_by issued_by missing name message u'Unknownplugin%s' % name return plugins[name]
@docstring.copy_dedent Figure.ginput def ginput *args **kwargs return gcf .ginput *args **kwargs
def get_resource_docname resource is_list if inspect.isclass resource class_name resource.__name__else class_name resource.__class__.__name__class_name class_name.replace 'Resource' '' docname uncamelcase class_name '-' if is_list and resource.name ! resource.name_plural docname '%s-list' % docname return docname
def tree2conlltags t tags []for child in t try category child.label prefix u'B-'for contents in child if isinstance contents Tree raise ValueError u'TreeistoodeeplynestedtobeprintedinCoNLLformat' tags.append contents[0] contents[1] prefix + category prefix u'I-'except AttributeError tags.append child[0] child[1] u'O' return tags
def tropo from tropo import Tropo Sessiontry s Session request.body.read t Tropo try row_id s.parameters['row_id']table s3db.msg_tropo_scratchquery table.row_id row_id row db query .select .first t.call to row.recipient network row.network t.say row.message outbox s3db.msg_outboxdb outbox.id row.row_id .update status 2 db query .delete return t.RenderJson except try message s.initialTextuuid s.idrecipient s.to['id']try fromaddress s.fromaddress['id']except fromaddress ''reply msg.parse_message message t.say [reply] return t.RenderJson except raise HTTP 501 except pass
def vrrp_transmit app monitor_name data transmit_request vrrp_event.EventVRRPTransmitRequest data app.send_event monitor_name transmit_request
def rs_cos_sin p x prec if rs_is_puiseux p x return rs_puiseux rs_cos_sin p x prec t rs_tan p / 2 x prec t2 rs_square t x prec p1 rs_series_inversion 1 + t2 x prec return rs_mul p1 1 - t2 x prec rs_mul p1 2 * t x prec
def kei_zeros nt if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'ntmustbepositiveintegerscalar.' return specfun.klvnzo nt 4
def normalize_key_for_search library_key return library_key.replace version_guid None branch None
def lsb_release_info return _distro.lsb_release_info
def security_group_rule_destroy context security_group_rule_id return IMPL.security_group_rule_destroy context security_group_rule_id
def test_redirect Client .get '/' redirect shortcuts.redirect 'home' assert redirect['Location'] '/en-US/firefox/'
def basic_sent_chop data raw True new_data []curr_sent []sent_mark [' ' '.' '?' '!']if raw for word in data if word in sent_mark curr_sent.append word new_data.append curr_sent curr_sent []else curr_sent.append word else for word tag in data if word in sent_mark curr_sent.append word tag new_data.append curr_sent curr_sent []else curr_sent.append word tag return new_data
def read_from_persistent_store return 'apersistentvalue'
def _get_repo_info alias repos_cfg None try meta dict repos_cfg or _get_configured_repos .items alias meta['alias'] aliasfor key val in six.iteritems meta if val in ['0' '1'] meta[key] int meta[key] 1 elif val 'NONE' meta[key] Nonereturn metaexcept ValueError configparser.NoSectionError return {}
def remove_compiled_application folder try shutil.rmtree pjoin folder 'compiled' path pjoin folder 'controllers' for file in listdir path '.*\\.pyc$' drop False os.unlink file except OSError pass
def in_ a b msg None assert a in b msg or '%rnotin%r' % a b
def realpath filename if isabs filename bits ['/'] + filename.split '/' [1 ] else bits [''] + filename.split '/' for i in range 2 len bits + 1 component join *bits[0 i] if islink component resolved _resolve_link component if resolved is None return abspath join * [component] + bits[i ] else newpath join * [resolved] + bits[i ] return realpath newpath return abspath filename
def convert_to_printable s if is_printable s return sreturn ''.join convert_char c for c in s
def _full_archive_path config_obj cli_config lineagename if config_obj and 'archive_dir' in config_obj return config_obj['archive_dir']else return os.path.join cli_config.default_archive_dir lineagename
def xyz2lab xyz illuminant 'D65' observer '2' arr _prepare_colorarray xyz xyz_ref_white get_xyz_coords illuminant observer arr arr / xyz_ref_white mask arr > 0.008856 arr[mask] np.power arr[mask] 1.0 / 3.0 arr[ ~ mask ] 7.787 * arr[ ~ mask ] + 16.0 / 116.0 x y z arr[... 0] arr[... 1] arr[... 2] L 116.0 * y - 16.0 a 500.0 * x - y b 200.0 * y - z return np.concatenate [x[... np.newaxis] for x in [L a b]] axis -1
def display_rgb rgb title None import matplotlib.pyplot as pltplt.imshow rgb interpolation u'nearest' origin u'lower' if title plt.title title plt.show return plt
def _convert_etree_element_to_topic entry_element topic Topic invalid_topic Truetopic_element entry_element.find './atom content/sb TopicDescription' _etree_sb_feed_namespaces if topic_element is not None mappings [ 'DefaultMessageTimeToLive' 'default_message_time_to_live' None 'MaxSizeInMegabytes' 'max_size_in_megabytes' int 'RequiresDuplicateDetection' 'requires_duplicate_detection' _parse_bool 'DuplicateDetectionHistoryTimeWindow' 'duplicate_detection_history_time_window' None 'EnableBatchedOperations' 'enable_batched_operations' _parse_bool 'SizeInBytes' 'size_in_bytes' int ]for map in mappings if _read_etree_element topic_element map[0] topic map[1] map[2] invalid_topic Falseif invalid_topic raise AzureServiceBusResourceNotFound _ERROR_TOPIC_NOT_FOUND for name value in _ETreeXmlToObject.get_entry_properties_from_element entry_element True .items setattr topic name value return topic
def generate_shell_test_data target source env target str target[0] testdata open target 'w' for i in range 0 len source 2 print >>testdata os.path.abspath str source[i] source[ i + 1 ]testdata.close return None
def submit_albums collection_id release_ids for i in range 0 len release_ids SUBMISSION_CHUNK_SIZE chunk release_ids[i i + SUBMISSION_CHUNK_SIZE ]mb_call musicbrainzngs.add_releases_to_collection collection_id chunk
def format_qiime_parameters params header '#QIIMEparameters' qiime_params [header]for script options in sorted params.items for option value in sorted options.items specific_option ' '.join [script option] if value is None value 'True'full_line ' DCTB '.join [specific_option str value ] qiime_params.append full_line return qiime_params
def layer_config if settings.get_security_map and not s3_has_role MAP_ADMIN auth.permission.fail layer get_vars.get 'layer' None if layer csv_stylesheet 'layer_%s.xsl' % layer else csv_stylesheet Noneoutput s3_rest_controller csv_stylesheet csv_stylesheet return output
def _maximal_independent_set G result set remaining set G while remaining G G.subgraph remaining v min remaining key G.degree result.add v remaining - set G[v] | {v} return result
def get_groups_with_perms obj attach_perms False ctype get_content_type obj if not attach_perms group_model get_group_obj_perms_model obj group_rel_name group_model.group.field.related_query_name if group_model.objects.is_generic group_filters { u'%s__content_type' % group_rel_name ctype u'%s__object_pk' % group_rel_name obj.pk}else group_filters { u'%s__content_object' % group_rel_name obj}groups Group.objects.filter **group_filters .distinct return groupselse groups {}for group in get_groups_with_perms obj if group not in groups groups[group] sorted get_group_perms group obj return groups
def opt_factory name default_value desc _type help '' tabid '' option_klasses {BOOL BoolOption INT IntegerOption POSITIVE_INT PositiveIntegerOption FLOAT FloatOption STRING StringOption URL URLOption URL_LIST URLListOption IPPORT IPPortOption LIST ListOption REGEX RegexOption COMBO ComboOption INPUT_FILE InputFileOption OUTPUT_FILE OutputFileOption PORT PortOption IP IPOption}return option_klasses[_type] name default_value desc _help help tabid tabid
def GetAvailableReportPlugins return sorted REGISTRY.GetRegisteredPlugins .itervalues key lambda cls cls.__name__
def create_task **kwargs owner kwargs.pop 'owner' None if not owner owner UserFactory.create project kwargs.pop 'project' None if project is None project ProjectFactory.create owner owner defaults {'project' project 'owner' owner 'status' TaskStatusFactory.create project project 'milestone' MilestoneFactory.create project project 'user_story' UserStoryFactory.create project project owner owner }defaults.update kwargs return TaskFactory.create **defaults
def _convert_if_int value try value int str value except ValueError passreturn value
def _model2dataframe model_endog model_exog model_type OLS **kwargs model_result model_type model_endog model_exog **kwargs .fit statistics pd.Series {'r2' model_result.rsquared 'adj_r2' model_result.rsquared_adj} result_df pd.DataFrame {'params' model_result.params 'pvals' model_result.pvalues 'std' model_result.bse 'statistics' statistics} fisher_df pd.DataFrame {'params' {'_f_test' model_result.fvalue} 'pvals' {'_f_test' model_result.f_pvalue}} res_series pd.concat [result_df fisher_df] .unstack return res_series.dropna
def test_precision f PlainTextFormatter nt.assert_equal f pi repr pi f.float_precision 0if numpy po numpy.get_printoptions nt.assert_equal po['precision'] 0 nt.assert_equal f pi '3' f.float_precision 2if numpy po numpy.get_printoptions nt.assert_equal po['precision'] 2 nt.assert_equal f pi '3.14' f.float_precision '%g'if numpy po numpy.get_printoptions nt.assert_equal po['precision'] 2 nt.assert_equal f pi '3.14159' f.float_precision '%e'nt.assert_equal f pi '3.141593e+00' f.float_precision ''if numpy po numpy.get_printoptions nt.assert_equal po['precision'] 8 nt.assert_equal f pi repr pi
def detect_changes_shippable args git Git args result ShippableChanges args git if result.is_pr job_type 'pullrequest'elif result.is_tag job_type 'tag'else job_type 'mergecommit'display.info 'Processing%sforbranch%scommit%s' % job_type result.branch result.commit return result.paths
@validate_labeldef hp_pchoice label p_options p options list zip *p_options n_options len options ch scope.hyperopt_param label scope.categorical p upper n_options return scope.switch ch *options
def _run_proxy_processes proxies ret []for prox_ in proxies proxy prox_.keys [0]result {}if not __salt__['salt_proxy.is_running'] proxy ['result'] __salt__['salt_proxy.configure_proxy'] proxy start True result[proxy] 'Proxy{0}wasstarted'.format proxy else msg 'Proxy{0}isalreadyrunning'.format proxy result[proxy] msglog.debug msg ret.append result return ret
def parse_subpattern source info flags_on flags_off saved_flags info.flagsinfo.flags info.flags | flags_on & ~ flags_off source.ignore_space bool info.flags & VERBOSE try subpattern _parse_pattern source info source.expect ' ' finally info.flags saved_flagssource.ignore_space bool info.flags & VERBOSE return subpattern
def validate_arguments func args kwargs drop_extra True parser _parse_signature func args kwargs missing extra extra_positional parser args kwargs [ 5]if missing raise ArgumentValidationError tuple missing elif extra or extra_positional and not drop_extra raise ArgumentValidationError None extra extra_positional return tuple args kwargs
def rand_infiniband_guid_address guid []for i in range 8 guid.append '%02x' % random.randint 0 255 return ' '.join guid
def checkSessionType assoc_type session_type if session_type not in getSessionTypes assoc_type raise ValueError 'Sessiontype%rnotvalidforassocationtype%r' % session_type assoc_type
def mon_quorum **kwargs return ceph_cfg.mon_quorum **kwargs
def default_remote config None if config is None config gitcfg.current return config.get u'branch.%s.remote' % current_branch
def attrprint d delimiter ' ' return delimiter.join '"%s" "%s"' % item for item in sorted d.items
def _populate_security_checks if not _security_checks _security_checks[u'executable_check'] ExecutableCodeCheck_security_checks[u'hosts_check'] AllowedHostsCheck
def setup_logging options None level logging.DEBUG if options is not None and options.debug else logging.WARNING console logging.StreamHandler console.setLevel level formatter logging.Formatter u'% name s % levelname -8s% message s' console.setFormatter formatter logging.getLogger u'parquet' .setLevel level logging.getLogger u'parquet' .addHandler console
def unicode_sorter input key1 input.lower key1 key1.replace u'\xe4' u'a' key1 key1.replace u'\xf6' u'o' key1 key1.replace u'\xfc' u'u' key1 key1.replace u'\xdf' u'ss' return key1
def _segment_pattern indexname return re.compile ' _%s_[0-9]+ \\..*' % indexname
def image_colorize original randomize True color 255 255 255 original Image.open StringIO.StringIO original image Image.new 'RGB' original.size if randomize color randrange 32 224 24 randrange 32 224 24 randrange 32 224 24 image.paste color box 0 0 + original.size image.paste original mask original buffer StringIO.StringIO image.save buffer 'PNG' return buffer.getvalue
def getVector3FromXMLElement xmlElement vector3 Vector3 getEvaluatedFloatDefault 0.0 'x' xmlElement getEvaluatedFloatDefault 0.0 'y' xmlElement getEvaluatedFloatDefault 0.0 'z' xmlElement return getCumulativeVector3 '' vector3 xmlElement
def _safe_quote val SAFE_QUOTE_CHARS '/.?& 'try ret urllib.parse.quote val safe SAFE_QUOTE_CHARS except KeyError ret urllib.parse.quote val.encode 'utf-8' safe SAFE_QUOTE_CHARS return ret
def get_namespace_choices return NAMESPACE_CHOICES
def prepend_to_setting setting_name value values getattr settings setting_name value type values value setattr settings setting_name value + values
def get_application_model try app_label model_name oauth2_settings.APPLICATION_MODEL.split u'.' except ValueError e u"APPLICATION_MODELmustbeoftheform'app_label.model_name'"raise ImproperlyConfigured e app_model apps.get_model app_label model_name if app_model is None e u'APPLICATION_MODELreferstomodel{0}thathasnotbeeninstalled'raise ImproperlyConfigured e.format oauth2_settings.APPLICATION_MODEL return app_model
def _cherry_pick_call func *args **dargs p_args p_dargs _cherry_pick_args func args dargs return func *p_args **p_dargs
def booted context None contextkey 'salt.utils.systemd.booted'if isinstance context dict if contextkey in context return context[contextkey]elif context is not None raise SaltInvocationError 'contextmustbeadictionaryifpassed' try ret bool os.stat '/run/systemd/system' except OSError ret Falsetry context[contextkey] retexcept TypeError passreturn ret
def establish_connection ip username '' password '' remote_conn_pre paramiko.SSHClient remote_conn_pre.set_missing_host_key_policy paramiko.AutoAddPolicy remote_conn_pre.connect ip username username password password look_for_keys False allow_agent False remote_conn remote_conn_pre.invoke_shell output remote_conn.recv 65535 return remote_conn_pre remote_conn output
def make_query_from_filter sample_filter require_meter True return make_query sample_filter.user sample_filter.project sample_filter.meter sample_filter.resource sample_filter.source sample_filter.start sample_filter.end require_meter
def parse_config_file path final True return options.parse_config_file path final final
def strip_dev device_name return _dev.sub '' device_name if device_name else device_name
def test_iht_init ratio 'auto'iht InstanceHardnessThreshold ESTIMATOR ratio ratio random_state RND_SEED assert_equal iht.ratio ratio assert_equal iht.random_state RND_SEED
def get_random_color alpha 1.0 from random import randomif alpha 'random' return [random random random random ]else return [random random random alpha]
def make_sample_data items frappe.get_all u'Item' {u'is_sales_item' 1} customers frappe.get_all u'Customer' warehouses frappe.get_all u'Warehouse' if items and customers for i in range 3 customer random.choice customers .namemake_opportunity items customer make_quote items customer make_projects if items and warehouses make_material_request frappe.get_all u'Item' frappe.db.commit
def on_content_type handlers default None error 'Therequestedcontenttypedoesnotmatchanyofthoseallowed' def output_type data request response handler handlers.get request.content_type.split ';' [0] default if not handler raise falcon.HTTPNotAcceptable error response.content_type handler.content_typereturn handler data request request response response output_type.__doc__ 'Supportsanyofthefollowingformats {0}'.format ' '.join function.__doc__ for function in handlers.values output_type.content_type ' '.join handlers.keys return output_type
def deprecated version replacement None def deprecationDecorator function '\nDecoratorthatmarksC{function}asdeprecated.\n'warningString getDeprecationWarningString function version None replacement @wraps function def deprecatedFunction *args **kwargs warn warningString DeprecationWarning stacklevel 2 return function *args **kwargs _appendToDocstring deprecatedFunction _getDeprecationDocstring version replacement deprecatedFunction.deprecatedVersion versionreturn deprecatedFunctionreturn deprecationDecorator
def cloudnetwork vm_ return config.get_cloud_config_value 'cloudnetwork' vm_ __opts__ default False search_global False
def run_hive_script script if not os.path.isfile script raise RuntimeError 'Hivescript {0}doesnotexist.'.format script return run_hive ['-f' script]
def chown path owner execute 'chown' owner path run_as_root True
def two_step_backprop mlp raise NotImplementedError 'TODO implementthisfunction.'
def oo_haproxy_backend_masters hosts port servers []for idx host_info in enumerate hosts server dict name 'master%s' % idx server_ip host_info['openshift']['common']['ip']server['address'] '%s %s' % server_ip port server['opts'] 'check'servers.append server return servers
def MessageEncoder field_number is_repeated is_packed tag TagBytes field_number wire_format.WIRETYPE_LENGTH_DELIMITED local_EncodeVarint _EncodeVarintassert not is_packed if is_repeated def EncodeRepeatedField write value for element in value write tag local_EncodeVarint write element.ByteSize element._InternalSerialize write return EncodeRepeatedFieldelse def EncodeField write value write tag local_EncodeVarint write value.ByteSize return value._InternalSerialize write return EncodeField
def _csrtodok csr smat {} A JA IA shape csrfor i in range len IA - 1 indices slice IA[i] IA[ i + 1 ] for l m in zip A[indices] JA[indices] smat[ i m ] lreturn SparseMatrix * shape + [smat]
def cosine_transform f x k **hints return CosineTransform f x k .doit **hints
def _check_files_limits files for fileinput_id in files.keys inputfiles files.getlist fileinput_id if len inputfiles > settings.MAX_FILEUPLOADS_PER_INPUT msg 'Submissionaborted!Maximum%dfilesmaybesubmittedatonce' % settings.MAX_FILEUPLOADS_PER_INPUT return msgfor inputfile in inputfiles if inputfile.size > settings.STUDENT_FILEUPLOAD_MAX_SIZE msg 'Submissionaborted!Yourfile"%s"istoolarge maxsize %dMB ' % inputfile.name settings.STUDENT_FILEUPLOAD_MAX_SIZE / 1000 ** 2 return msgreturn None
def dict_dir obj ns {}for key in dir2 obj try ns[key] getattr obj key except AttributeError passreturn ns
def _fix_up_private_attr clsname spec out OrderedDict for k v in spec.items if k.startswith '__' and not k.endswith '__' k '_' + clsname + k out[k] vreturn out
def test_grouped_item_access T1 for masked in False True t1 Table T1 masked masked tg t1.group_by 'a' tgs tg[ 'a' 'c' 'd' ]assert np.all tgs.groups.keys tg.groups.keys assert np.all tgs.groups.indices tg.groups.indices tgsa tgs.groups.aggregate np.sum assert tgsa.pformat ['acd' '----------' '00.04' '16.018' '222.06'] tgs tg[ 'c' 'd' ]assert np.all tgs.groups.keys tg.groups.keys assert np.all tgs.groups.indices tg.groups.indices tgsa tgs.groups.aggregate np.sum assert tgsa.pformat ['cd' '-------' '0.04' '6.018' '22.06']
def libdoc_cli arguments LibDoc .execute_cli arguments
def _unhandled_mock_read filename raise CommandExecutionError 'Unhandledmockreadfor{0}'.format filename
def get_trail_by_arn cloudtrail_client trail_arn trails cloudtrail_client.describe_trails ['trailList']for trail in trails if trail.get 'TrailARN' None trail_arn return trailraise ValueError 'Atrailcouldnotbefoundfor%s' % trail_arn
def getNode template context Context name 'subject' for node in template if isinstance node BlockNode and node.name name return node.render context elif isinstance node ExtendsNode return getNode node.nodelist context name raise Exception "Node'%s'couldnotbefoundintemplate." % name
def inspect_response response spider Shell spider.crawler .start response response
def solve_rational_inequalities eqs result S.EmptySetfor _eqs in eqs if not _eqs continueglobal_intervals [Interval S.NegativeInfinity S.Infinity ]for numer denom rel in _eqs numer_intervals solve_poly_inequality numer * denom rel denom_intervals solve_poly_inequality denom ' ' intervals []for numer_interval in numer_intervals for global_interval in global_intervals interval numer_interval.intersect global_interval if interval is not S.EmptySet intervals.append interval global_intervals intervalsintervals []for global_interval in global_intervals for denom_interval in denom_intervals global_interval - denom_intervalif global_interval is not S.EmptySet intervals.append global_interval global_intervals intervalsif not global_intervals breakfor interval in global_intervals result result.union interval return result
def pluck ind seqs default no_default if default no_default get getter ind return map get seqs elif isinstance ind list return tuple _get item seq default for item in ind for seq in seqs return _get ind seq default for seq in seqs
def generateClassificationData size nClasses 3 if nClasses 3 means [ -1 0 2 4 3 1 ]else means [ -2 0 2 1 6 0 ]cov [diag [1 1] diag [0.5 1.2] diag [1.5 0.7] ]dataset ClassificationDataSet 2 1 nb_classes nClasses for _ in range size for c in range 3 input multivariate_normal means[c] cov[c] dataset.addSample input [ c % nClasses ] dataset.assignClasses return dataset
def CheckEntity request_trusted request_app_id entity CheckReference request_trusted request_app_id entity.key False for prop in entity.property_list CheckProperty request_trusted request_app_id prop for prop in entity.raw_property_list CheckProperty request_trusted request_app_id prop indexed False
def define_file file_descriptor module None if module is None module new.module file_descriptor.package for enum_descriptor in file_descriptor.enum_types or [] enum_class define_enum enum_descriptor module.__name__ setattr module enum_descriptor.name enum_class for message_descriptor in file_descriptor.message_types or [] message_class define_message message_descriptor module.__name__ setattr module message_descriptor.name message_class for service_descriptor in file_descriptor.service_types or [] service_class define_service service_descriptor module setattr module service_descriptor.name service_class return module
@cacheitdef _remove_multiple_delta expr from sympy.solvers import solveif expr.is_Add return expr.func *list map _remove_multiple_delta expr.args if not expr.is_Mul return expreqs []newargs []for arg in expr.args if isinstance arg KroneckerDelta eqs.append arg.args[0] - arg.args[1] else newargs.append arg if not eqs return exprsolns solve eqs dict True if len solns 0 return S.Zeroelif len solns 1 for key in solns[0].keys newargs.append KroneckerDelta key solns[0][key] expr2 expr.func *newargs if expr ! expr2 return _remove_multiple_delta expr2 return expr
def from_flags flags ednsflags value flags & 15 | ednsflags >> 20 & 4080 if value < 0 or value > 4095 raise ValueError 'rcodemustbe> 0and< 4095' return value
def chgrp path group func_name '{0}.chgrp'.format __virtualname__ if __opts__.get 'fun' '' func_name log.info 'Thefunction{0}shouldnotbeusedonWindowssystems;seefunctiondocsfordetails.'.format func_name log.debug 'win_file.py{0}Doingnothingfor{1}'.format func_name path return None
def unfreeze name quiet False path None data _do_names name 'unfreeze' path path if data and not quiet __jid_event__.fire_event {'data' data 'outputter' 'lxc_resume'} 'progress' return data
def out_of_date original derived return not os.path.exists derived or os.path.exists original and os.stat derived .st_mtime < os.stat original .st_mtime
def is_server_error status return 500 < status < 599
def get_gcc_shared_library_arg if sys.platform 'darwin' return '-dynamiclib'else return '-shared'
def latest_package_name distro 'trusty' latest_minor_version latest_release_version [ 3]return 'python-ckan_{version}-{distro}_amd64.deb'.format version latest_minor_version distro distro
def _explain_exception start -1 stop None prefix '>' etype value tb sys.exc_info string traceback.format_list traceback.extract_tb tb [start stop] string ''.join string .split '\n' + traceback.format_exception_only etype value string ' \n' + prefix + '\n' + prefix .join string return string
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def message_warning text title None informative_text None details None buttons None default_button None exc_info False parent None if not text import randomtext_candidates ['Deathcouldcomeatanymoment.' 'Murphylurksabout.Remembertosavefrequently.']text random.choice text_candidates if title is not None title 'Warning'return message QMessageBox.Warning text title informative_text details buttons default_button exc_info parent
def translate_syntax_error error source None error.source sourceerror.translated Trueexc_info error.__class__ error None filename error.filenameif filename is None filename '<unknown>'return fake_exc_info exc_info filename error.lineno
def security_group_rule_get_by_security_group context security_group_id return IMPL.security_group_rule_get_by_security_group context security_group_id
def whitespace_around_keywords logical_line for match in KEYWORD_REGEX.finditer logical_line before after match.groups if ' DCTB ' in before yield match.start 1 'E274tabbeforekeyword' elif len before > 1 yield match.start 1 'E272multiplespacesbeforekeyword' if ' DCTB ' in after yield match.start 2 'E273tabafterkeyword' elif len after > 1 yield match.start 2 'E271multiplespacesafterkeyword'
def classify_saves saves period_start def retain_oldest_in_region region prev Nonefor save in region if prev yield False prev prev saveif prev yield True prev matches rest partition lambda s s[0] > period_start['all'] saves for save in matches yield True save tm_ranges period_start['dailies'] lambda s localtime s[0] .tm_yday period_start['monthlies'] lambda s localtime s[0] .tm_mon period_start['yearlies'] lambda s localtime s[0] .tm_year for pstart time_region_id in tm_ranges matches rest partition lambda s s[0] > pstart rest for region_id region_saves in groupby matches time_region_id for action in retain_oldest_in_region region_saves yield action for save in rest yield False save
def cos mat target None if not target target materr_code _cudamat.apply_cos mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def remove_group_type_access context group_type_id project_id if group_type_id is None msg _ 'group_type_idcannotbeNone' raise exception.InvalidGroupType reason msg elevated context if context.is_admin else context.elevated if is_public_group_type elevated group_type_id msg _ 'Typeaccessmodificationisnotapplicabletopublicgrouptype.' raise exception.InvalidGroupType reason msg return db.group_type_access_remove elevated group_type_id project_id
def rndstr size 16 alphabet '' rng random.SystemRandom if not alphabet alphabet string.letters[0 52] + string.digits return str .join rng.choice alphabet for _ in range size
def gompertz x A u d v y0 y A * np.exp - np.exp u * np.e / A * d - x + 1 + y0 return y
def startLoggingWithObserver observer setStdout 1 theLogPublisher._startLogging observer setStdout msg 'Logopened.'
def _normpath p initial_dotslash p.startswith os.curdir + os.sep initial_dotslash | xp.ON_WINDOWS and p.startswith os.curdir + os.altsep p p.rstrip trailing_slash p.endswith os.sep trailing_slash | xp.ON_WINDOWS and p.endswith os.altsep p os.path.normpath p if initial_dotslash and p ! '.' p os.path.join os.curdir p if trailing_slash p os.path.join p '' if xp.ON_WINDOWS and builtins.__xonsh_env__.get 'FORCE_POSIX_PATHS' p p.replace os.sep os.altsep return p
def get_mock_hadoop_output output_dir get_mock_dir 'output' dirnames sorted os.listdir output_dir if dirnames return os.path.join output_dir dirnames[0] else return None
def disable_signal module signal return patch.object module signal new Signal
@pytest.mark.skipif 'notHAS_YAML' def test_round_trip_empty_table t Table dtype [bool 'i' 'f'] names ['a' 'b' 'c'] out StringIO t.write out format 'ascii.ecsv' t2 Table.read out.getvalue format 'ascii.ecsv' assert t.dtype t2.dtype assert len t2 0
def _get_django_admin bin_env if not bin_env if salt.utils.which 'django-admin.py' return 'django-admin.py'elif salt.utils.which 'django-admin' return 'django-admin'else raise salt.exceptions.CommandExecutionError 'django-adminordjango-admin.pynotfoundonPATH' if os.path.exists os.path.join bin_env 'bin' 'django-admin.py' return os.path.join bin_env 'bin' 'django-admin.py' return bin_env
def autostrip cls fields [ key value for key value in cls.base_fields.iteritems if isinstance value forms.CharField ]for field_name field_object in fields def get_clean_func original_clean return lambda value original_clean value and value.strip clean_func get_clean_func getattr field_object 'clean' setattr field_object 'clean' clean_func return cls
@register.filter is_safe True def gfm value html markdown value extensions ['mdx_gfm'] return mark_safe html
def contains_partial haystack needle if not isinstance haystack Element haystack parse_html haystack if not isinstance needle Element needle parse_html needle if needle.name haystack.name and set needle.attributes .issubset haystack.attributes return Truereturn any contains_partial child needle for child in haystack.children if isinstance child Element
def setup_and_run from ninja_ide import corefrom ninja_ide import ninja_resourcesfrom multiprocessing import freeze_supportfreeze_support core.run_ninja
def html_params **kwargs params []for k v in sorted iteritems kwargs if k in u'class_' u'class__' u'for_' k k[ -1 ]if v is True params.append k else params.append u'%s "%s"' % text_type k escape text_type v quote True return u''.join params
def wait_for_interface_status client server port_id status body client.show_interface server port_id ['interfaceAttachment']interface_status body['port_state']start int time.time while interface_status ! status time.sleep client.build_interval body client.show_interface server port_id ['interfaceAttachment']interface_status body['port_state']timed_out int time.time - start > client.build_timeout if interface_status ! status and timed_out message 'Interface%sfailedtoreach%sstatus current%s withintherequiredtime %ss .' % port_id status interface_status client.build_timeout raise lib_exc.TimeoutException message return body
@dispatch Expr MongoQuery def post_compute e q scope None scope {'$project' toolz.merge {'_id' 0} dict col 1 for col in e.fields }q q.append scope if not e.dshape.shape result get_result q.coll.aggregate list q.query [0]if isscalar e.dshape.measure return result[e._name]else return get e.fields result dicts get_result q.coll.aggregate list q.query if isscalar e.dshape.measure return list pluck e.fields[0] dicts default None else return list pluck e.fields dicts default None
def _get_disk_of_partition devpath st None diskpath re.sub ' ? ?< \\d p ?\\d+$' '' devpath if diskpath ! devpath try st_disk os.stat diskpath if stat.S_ISBLK st_disk.st_mode return diskpath st_disk except OSError passif st is None st os.stat devpath return devpath st
def list_cache_subnet_groups region None key None keyid None profile None return [g['CacheSubnetGroupName'] for g in describe_cache_subnet_groups None region key keyid profile ]
def dispatch_aliases app current_appaliases_map app.config.get 'ALIASES_MAP' if aliases_map and request.path in aliases_map alias aliases_map[request.path]status alias.get 'status' 200 if alias['alias_type'] 'endpoint' endpoint alias['to']if alias.get 'action' 'redirect' return redirect url_for endpoint **request.args else return app.process_response app.make_response app.view_functions[endpoint] elif alias['alias_type'] 'long_slug' long_slug alias['to']if alias.get 'action' 'redirect' return redirect long_slug else endpoint route_from long_slug [0]return app.process_response app.make_response app.view_functions[endpoint] elif alias['alias_type'] 'url' return redirect alias['to'] elif alias['alias_type'] 'string' return render_template_string alias['to'] status elif alias['alias_type'] 'template' return render_template alias['to'] status
def policy task_instance pass
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
@treeio_login_requireddef ajax_ticket_lookup request response_format 'html' tickets []if request.GET and 'term' in request.GET tickets Ticket.objects.filter name__icontains request.GET['term'] [ 10]return render_to_response 'services/ajax_ticket_lookup' {'tickets' tickets} context_instance RequestContext request response_format response_format
def _multi_send method context topic msg timeout None envelope False _msg_id None conf CONFLOG.debug _ '% msg s' % {'msg' ''.join map pformat topic msg } queues _get_matchmaker .queues topic LOG.debug _ 'Sendingmessage s to %s' queues if len queues 0 LOG.warn _ 'Nomatchmakerresults.Notcasting.' raise rpc_common.Timeout _ 'Nomatchfrommatchmaker.' for queue in queues _topic ip_addr queue_addr 'tcp //%s %s' % ip_addr conf.rpc_zmq_port if method.__name__ '_cast' eventlet.spawn_n method _addr context _topic msg timeout envelope _msg_id returnreturn method _addr context _topic msg timeout envelope
def column_indices text string_indices range len text for index in find_combining_chars text string_indices[index] Nonereturn [i for i in string_indices if i is not None ]
def gettext message return do_translate message u'gettext'
def _write_raw_buffer fid buf cals fmt if buf.shape[0] ! len cals raise ValueError 'bufferandcalibrationsizesdonotmatch' if fmt not in ['short' 'int' 'single' 'double'] raise ValueError 'fmtmustbe"short" "single" or"double"' if np.isrealobj buf if fmt 'short' write_function write_dau_pack16elif fmt 'int' write_function write_intelif fmt 'single' write_function write_floatelse write_function write_doubleelif fmt 'single' write_function write_complex64elif fmt 'double' write_function write_complex128else raise ValueError 'only"single"and"double"supportedforwritingcomplexdata' buf buf / np.ravel cals [ None] write_function fid FIFF.FIFF_DATA_BUFFER buf
def col_retrieve fid uid url build_url RESOURCE id fid route 'col' params make_params uid uid return request 'get' url params params
def frange *args if all is_integer arg for arg in args return list range *args start stop step _get_start_stop_step args digits max _digits start _digits stop _digits step factor pow 10 digits return [ x / float factor for x in range roundup start * factor roundup stop * factor roundup step * factor ]
def notification_factory code subcode notification BGPNotification code subcode if not notification.reason raise ValueError 'Invalidcode/sub-code.' return notification
@receiver post_save sender UserProfile def user_profile_post_save_callback sender **kwargs user_profile kwargs['instance']emit_field_changed_events user_profile user_profile.user sender._meta.db_table excluded_fields ['meta']
@handle_response_format@treeio_login_required@_process_mass_opportunity_formdef opportunity_index_assigned request response_format 'html' query Q status__hidden False assigned request.user.profile if request.GET if 'status' in request.GET and request.GET['status'] query _get_filter_query request.GET else query query & _get_filter_query request.GET statuses Object.filter_by_request request SaleStatus.objects mode 'r' opportunities Object.filter_by_request request Opportunity.objects.filter query mode 'r' filters OpportunityFilterForm request.user.profile '' request.GET massform OpportunityMassActionForm request.user.profile return render_to_response 'sales/opportunity_index_assigned' {'opportunities' opportunities 'filters' filters 'massform' massform 'statuses' statuses} context_instance RequestContext request response_format response_format
def convert_otu_table_relative otu_table sample_ids otu_ids otu_counts consensus otu_tableotu_counts asarray otu_counts float otu_counts otu_counts / otu_counts.sum otu_counts where isnan otu_counts 0.0 otu_counts return sample_ids otu_ids otu_counts consensus
def test_prefit clf SGDClassifier alpha 0.1 n_iter 10 shuffle True random_state 0 model SelectFromModel clf model.fit data y X_transform model.transform data clf.fit data y model SelectFromModel clf prefit True assert_array_equal model.transform data X_transform model SelectFromModel clf prefit False model.fit data y assert_array_equal model.transform data X_transform model SelectFromModel clf prefit True assert_raises ValueError model.fit data y
def dup_rem f g K return dup_div f g K [1]
def rename_variables fstruct vars None used_vars new_vars None fs_class u'default' if fs_class u'default' fs_class _default_fs_class fstruct if new_vars is None new_vars {}if vars is None vars find_variables fstruct fs_class else vars set vars used_vars find_variables fstruct fs_class .union used_vars return _rename_variables copy.deepcopy fstruct vars used_vars new_vars fs_class set
def other_types_on_host host_state instance_type_id host_instances host_state.instances.values host_types set [inst.instance_type_id for inst in host_instances] inst_set set [instance_type_id] return bool host_types - inst_set
def _getWriters reactor if IReactorFDSet.providedBy reactor return reactor.getWriters elif 'IOCP' in reactor.__class__.__name__ return reactor.handleselse raise Exception 'Cannotfindwriterson%r' % reactor
def isdatadescriptor object return hasattr object '__set__' and hasattr object '__get__'
def at_webserver_root_creation web_root return web_root
def getClockShowDate **kwargs _gsession _GSettings user kwargs.get 'user' schema 'org.gnome.desktop.interface' key 'clock-show-date' return _gsession._get
@frappe.whitelist def load_messages language frappe.clear_cache set_default_language get_language_code language m get_dict u'page' u'setup-wizard' for path in frappe.get_hooks u'setup_wizard_requires' js_file_path os.path.abspath frappe.get_site_path u'..' *path.strip u'/' .split u'/' m.update get_dict u'jsfile' js_file_path m.update get_dict u'boot' send_translations m return frappe.local.lang
def VerifyPassword user cleartext_pwd expected GetPassword user hashed _HashPassword cleartext_pwd expected['version'] expected.get 'salt' if hashed ! expected['hashed'] raise OTPException 'Enteredusername/passwordinvalid'
def console_get_all_by_instance context instance_uuid return IMPL.console_get_all_by_instance context instance_uuid
def _validate_labels labels l len labels total 0i -1 j 0for label in labels ll len label total + ll + 1 if ll > 63 raise LabelTooLongif i < 0 and label '' i jj + 1if total > 255 raise NameTooLongif i > 0 and i ! l - 1 raise EmptyLabel
def setsemod module state if state.lower 'enabled' cmd 'semodule-e{0}'.format module elif state.lower 'disabled' cmd 'semodule-d{0}'.format module return not __salt__['cmd.retcode'] cmd
def instance_tag_add context instance_uuid tag return IMPL.instance_tag_add context instance_uuid tag
def test_wikipedia_is_dominating_set G nx.cycle_graph 4 G.add_edges_from [ 0 4 1 4 2 5 ] assert_true nx.is_dominating_set G set [4 3 5] assert_true nx.is_dominating_set G set [0 2] assert_true nx.is_dominating_set G set [1 2]
@register.filter name 'user_location' def parse_location user path ''try membership user.membershipexcept Membership.DoesNotExist return ''if membership.city path + '%s' % membership.city if membership.region if membership.city path + ' 'path + '%s' % membership.region if membership.country if membership.region path + ''elif membership.city path + ' 'path + '%s' % membership.country return path
def launch url wait False locate False from ._termui_impl import open_urlreturn open_url url wait wait locate locate
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def _onenormest_product operator_seq t 2 itmax 5 compute_v False compute_w False structure None return scipy.sparse.linalg.onenormest ProductOperator structure structure *operator_seq
def build_filter_properties scheduler_hints forced_host forced_node instance_type filter_properties dict scheduler_hints scheduler_hints filter_properties['instance_type'] instance_typeif forced_host filter_properties['force_hosts'] [forced_host]if forced_node filter_properties['force_nodes'] [forced_node]return filter_properties
def add_openid_simple_registration request response data sreg_data {}sreg_request sreg.SRegRequest.fromOpenIDRequest request sreg_fields sreg_request.allRequestedFields if sreg_fields for field in sreg_fields if field 'email' and 'email' in data sreg_data['email'] data['email']elif field 'fullname' and 'fullname' in data sreg_data['fullname'] data['fullname']elif field 'nickname' and 'nickname' in data sreg_data['nickname'] data['nickname']sreg_response sreg.SRegResponse.extractResponse sreg_request sreg_data sreg_response.toMessage response.fields
def yiq2rgb yiq return _convert rgb_from_yiq yiq
@register.inclusion_tag 'bootstrap/progress_bar.html' def bs_progress_bar *args **kwargs bars []contexts kwargs.get 'contexts' ['' 'success' 'info' 'warning' 'danger'] for ndx arg in enumerate args bars.append dict percent arg context kwargs.get 'context' contexts[ ndx % len contexts ] return {'bars' bars 'text' kwargs.pop 'text' False 'striped' kwargs.pop 'striped' False 'animated' kwargs.pop 'animated' False 'min_val' kwargs.pop 'min_val' 0 'max_val' kwargs.pop 'max_val' 100 }
@app.route '/links/<int n>/<int offset>' def link_page n offset n min max 1 n 200 link "<ahref '{0}'>{1}</a>"html ['<html><head><title>Links</title></head><body>']for i in xrange n if i offset html.append '{0}'.format i else html.append link.format url_for 'link_page' n n offset i i html.append '</body></html>' return ''.join html
def showUnicodeWarning showWarning _ 'SelectedfilewasnotinUTF-8format.Pleaseseetheimportingsectionofthemanual.'
def adjust_sigmoid image cutoff 0.5 gain 10 inv False _assert_non_negative image dtype image.dtype.typescale float dtype_limits image True [1] - dtype_limits image True [0] if inv out 1 - 1 / 1 + np.exp gain * cutoff - image / scale * scale return dtype out out 1 / 1 + np.exp gain * cutoff - image / scale * scale return dtype out
def runHook hook *args hook _hooks.get hook None if hook for func in hook func *args
def isCarbonTk assert _tk_type is not None return _tk_type 'carbon'
def get_bound_method_weakref target on_delete if hasattr target '__get__' return BoundMethodWeakref target target on_delete on_delete else return BoundNonDescriptorMethodWeakref target target on_delete on_delete
def remove_empty_line content r re.compile '^\\s+$' re.M | re.S s r.sub '' content r re.compile '\\n+' re.M | re.S s r.sub '\n' s return s
def _get_xblock_parent xblock category None parent xblock.get_parent if parent and category if parent.category category return parentelse return _get_xblock_parent parent category return parent
def _logn n x out None if out is None return np.log x / np.log n else np.log x out out np.true_divide out np.log n out out return out
def _AppendFiltersForMSBuild parent_filter_name sources rule_dependencies extension_to_rule_name filter_group source_group for source in sources if isinstance source MSVSProject.Filter if not parent_filter_name filter_name source.nameelse filter_name '%s\\%s' % parent_filter_name source.name filter_group.append ['Filter' {'Include' filter_name} ['UniqueIdentifier' MSVSNew.MakeGuid source.name ]] _AppendFiltersForMSBuild filter_name source.contents rule_dependencies extension_to_rule_name filter_group source_group else _ element _MapFileToMsBuildSourceType source rule_dependencies extension_to_rule_name source_entry [element {'Include' source}]if parent_filter_name source_entry.append ['Filter' parent_filter_name] source_group.append source_entry
def InternalError message None if message return _InternalError message elif ctx.get 'app_stack' return ctx.app_stack[ -1 ].internalerror else return _InternalError
def expires name return _expires name .isoformat
def run_setup_py cmd pypath None path None data_stream 0 env None if env is None env dict for envname in os.environ env[envname] os.environ[envname]if pypath is not None env['PYTHONPATH'] pypathif path is not None env['PATH'] pathif not env.get 'PATH' '' env['PATH'] _which_dirs 'tar' .union _which_dirs 'gzip' env['PATH'] os.pathsep.join env['PATH'] cmd [sys.executable 'setup.py'] + list cmd try proc _Popen cmd stdout _PIPE stderr _PIPE shell sys.platform 'win32' env env data proc.communicate [data_stream]except OSError return 1 '' if hasattr data 'decode' data data.decode data unicodedata.normalize 'NFC' data return proc.returncode data
def _get_deterministic_value_for_table_name table_name max_value return hash table_name % max_value
def carmichael_of_factorized f_list if len f_list < 1 return 1result carmichael_of_ppower f_list[0] for i in range 1 len f_list result lcm result carmichael_of_ppower f_list[i] return result
def unix_time_from_uuid1 uuid_arg return uuid_arg.time - 122192928000000000 / 10000000.0
def attach_closed_milestones queryset as_field 'closed_milestones_attr' model queryset.modelsql '\nSELECTCOUNT milestones_milestone.id \nFROMmilestones_milestone\nWHEREmilestones_milestone.project_id {tbl}.idAND\nmilestones_milestone.closed True\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def render_table header_row data table [header_row] + data max_lens [max len compat_str v for v in col for col in zip *table ]format_str u''.join u'%-' + compat_str ml + 1 + u's' for ml in max_lens[ -1 ] + u'%s' return u'\n'.join format_str % tuple row for row in table
def canonicalize app pagename templatename context doctree if not app.config.canonical_root returncontext['canonical'] _build_url app.config.canonical_root app.config.canonical_branch pagename
def _format_master service conn_type private unpriv chroot wakeup maxproc command if private 'y' private '-'if unpriv 'y' unpriv '-'if chroot 'y' chroot '-'if wakeup 'n' wakeup '-'maxproc str maxproc if maxproc '100' maxproc '-'conf_line '{0 9s}{1 5s}{2 7s}{3 7s}{4 7s}{5 7s}{6 7s}{7}'.format service conn_type private unpriv chroot wakeup maxproc command return conf_line
def mw_t x y continuity True two_sided True u pval mannwhitneyu x y continuity if two_sided return u 2.0 * pval else return u pval
def servicegroup_exists sg_name sg_type None **connection_args sg _servicegroup_get sg_name **connection_args if sg is None return Falseif sg_type is not None and sg_type.upper ! sg.get_servicetype return Falsereturn True
def show_compilers from distutils.fancy_getopt import FancyGetoptcompilers []for compiler in compiler_class.keys compilers.append 'compiler ' + compiler None compiler_class[compiler][2] compilers.sort pretty_printer FancyGetopt compilers pretty_printer.print_help 'Listofavailablecompilers '
def _get_package_info module package env None if env opt_dirs [ '%s/bin' % env ]else opt_dirs []python_bin module.get_bin_path 'python' False opt_dirs if python_bin is None formatted_dep Noneelse rc out err module.run_command [python_bin '-c' _SPECIAL_PACKAGE_CHECKERS[package]] if rc formatted_dep Noneelse formatted_dep '%s %s' % package out.strip return formatted_dep
def sequence_case data left right return_merged_clips data seq data['bases']if left > right new_seq seq.lower else new_seq ''.join seq[ left - 1 ].lower seq[ left - 1 right] seq[right ].lower return new_seq
def store_response resp response_dict if response_dict is not None response_dict['status'] resp.statusresponse_dict['reason'] resp.reasonresponse_dict['headers'] resp_header_dict resp
def disk_partitions all False result [dict partition._asdict for partition in psutil.disk_partitions all ]return result
def test_nm3_fit_sample_auto ratio 'auto'nm3 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS X_resampled y_resampled nm3.fit_sample X Y X_gt np.array [[0.91464286 1.61369212] [ -0.80809175 -1.09917302 ] [ -0.20497017 -0.26630228 ] [1.17737838 -0.2002118 ] [ -0.60413357 0.24628718] [0.03142011 0.12323596] [1.15157493 -1.2981518 ] [ -0.54619583 1.73009918] [0.99272351 -0.11631728 ]] y_gt np.array [0 0 0 1 1 1 2 2 2] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def has_comments_in_diffsets_excluding review diffset_pair if not review return False current_diffset interdiff diffset_pairq DiffSet.objects.filter files__comments__review review q q.filter files__comments__interfilediff__isnull True .distinct if not interdiff q q.exclude pk current_diffset.id if q.count > 0 return Trueq DiffSet.objects.filter files__comments__review review q q.filter files__comments__interfilediff__isnull False if interdiff q q.exclude pk current_diffset.id files__comments__interfilediff__diffset interdiff return q.count > 0
def compare_arrays left right return left is right or left.shape right.shape and left right .all
def user_data_dir appname None appauthor None version None roaming False if system 'win32' if appauthor is None appauthor appnameconst roaming and 'CSIDL_APPDATA' or 'CSIDL_LOCAL_APPDATA' path os.path.normpath _get_win_folder const if appname if appauthor is not False path os.path.join path appauthor appname else path os.path.join path appname elif system 'darwin' path os.path.expanduser '~/Library/ApplicationSupport/' if appname path os.path.join path appname else path os.getenv 'XDG_DATA_HOME' os.path.expanduser '~/.local/share' if appname path os.path.join path appname if appname and version path os.path.join path version return path
def _set_tz values tz preserve_UTC False coerce False if tz is not None name getattr values 'name' None values values.ravel tz tslib.get_timezone _ensure_decoded tz values DatetimeIndex values name name if values.tz is None values values.tz_localize 'UTC' .tz_convert tz if preserve_UTC if tz 'UTC' values list values elif coerce values np.asarray values dtype 'M8[ns]' return values
def EntityKind key if key.path .element_list return key.path .element_list [ -1 ].type else return ''
def format_jid_instance jid job ret format_job_instance job ret.update {'StartTime' jid_to_time jid } return ret
def call_action action_name context None **kwargs if context is None context {}context.setdefault 'user' '127.0.0.1' context.setdefault 'ignore_auth' True return logic.get_action action_name context context data_dict kwargs
def compareMarkPos a b linecmp cmp a[0] b[0] if linecmp return linecmpreturn cmp a[1] b[1]
def interval_decode s time 0sign 1s s.strip if s.startswith '-' s s[1 ]sign -1 elif s.startswith '+' s s[1 ]for match in allMatches s _timeRE char match.group 0 [ -1 ].lower if char not in timeValues continuetime + int match.group 0 [ -1 ] * timeValues[char] return time
def _get_none_or_value value if value is None return Noneelif not value return valueelif isinstance value six.string_types if value.lower 'none' return Nonereturn valueelse return None
def get_limit_choices_to_from_path model path fields get_fields_from_path model path fields remove_trailing_data_field fields limit_choices_to fields and hasattr fields[ -1 ] u'rel' and getattr fields[ -1 ].rel u'limit_choices_to' None if not limit_choices_to return models.Q elif isinstance limit_choices_to models.Q return limit_choices_toelse return models.Q **limit_choices_to
def get_sentence start_with_lorem False return _GENERATOR.generate_sentence start_with_lorem [ -1 ]
def is_ascii_encoding encoding try return codecs.lookup encoding .name 'ascii' except LookupError return False
def addTZCleanup testCase tzIn environ.get 'TZ' None @testCase.addCleanupdef resetTZ setTZ tzIn
def string_contains_surrogates ustring for c in map ord ustring if c > 65535 return Trueif 55296 < c < 57343 return Truereturn False
def quota_destroy context project_id resource return IMPL.quota_destroy context project_id resource
def setup app app.add_role 'rfc' rfclink return
def walksymlinks top topdown True onerror None for dirpath dirnames filenames in os.walk top topdown onerror if topdown yield dirpath dirnames filenames symlinks filter lambda dirname os.path.islink os.path.join dirpath dirname dirnames for s in symlinks for x in walksymlinks os.path.join dirpath s topdown onerror yield x if not topdown yield dirpath dirnames filenames
def rfc2822_format val if isinstance val six.string_types return valelif isinstance val datetime.datetime datetime.date val time.mktime val.timetuple if isinstance val numbers.Number return email.utils.formatdate val else return val
def say_hello name None if name is None name u'Stranger'return u'Hithere %s!' % name
def ParseFlags resp mo Flags.match resp if not mo return return tuple mo.group 'flags' .split
def check_repo_or_die path None guess_repo path top repo pst stat_if_exists top + '/objects/pack' if pst and stat.S_ISDIR pst.st_mode returnif not pst top_st stat_if_exists top if not top_st log 'error repository%rdoesnotexist see"buphelpinit" \n' % top sys.exit 15 log 'error %risnotarepository\n' % top sys.exit 14
def issues_on owner repository milestone None state None assignee None mentioned None labels None sort None direction None since None number -1 etag None if owner and repository return gh.issues_on owner repository milestone state assignee mentioned labels sort direction since number etag return iter []
def object_hook ob _len len _keys _keys _first_three_chars np.s_[ 3] _converters _converters if _len ob ! 1 return decode ob key _keys ob [0]if key[_first_three_chars] ! '__!' return obreturn _converters[key] ob[key]
def user_to_uid user if user is None user salt.utils.get_user try if isinstance user int return userreturn pwd.getpwnam user .pw_uidexcept KeyError return ''
def log_statsd_event name event_name 'events.%s' % name statsd.incr event_name
def ensure_directory_containing path ensure_directory os.path.dirname path
def _node default '' try import socketexcept ImportError return defaulttry return socket.gethostname except socket.error return default
def load_include_path paths for path in paths if not os.path.isdir path continueif path not in sys.path sys.path.insert 1 path for f in os.listdir path fpath os.path.join path f if os.path.isdir fpath load_include_path [fpath]
def convert_to_id_fields data table field_name for item in data[table] item[ field_name + '_id' ] item[field_name]del item[field_name]
def test_derived_cols_from_lists_kw test_data ds ChartDataSource.from_data y test_data.array_data assert ds['y'] ['a' 'b']
def test_solve_discrete_lyapunov_complex A np.array [[ 0.5 + 0.3j 0.1 + 0.1j ] [1 0]] B np.eye 2 X qme.solve_discrete_lyapunov A B assert_allclose np.dot np.dot A X A.conj .transpose - X - B atol 1e-15
def zerofree_randstring l tmp map lambda x struct.pack 'B' random.randrange 1 256 1 [''] * l return ''.join tmp
def set_vif_host_backend_direct_config conf devname mode 'passthrough' conf.net_type 'direct'conf.source_mode modeconf.source_dev devnameconf.model 'virtio'
def test_LinearLocator_set_params loc mticker.LinearLocator numticks 2 loc.set_params numticks 8 presets { 0 1 []} assert loc.numticks 8 assert loc.presets { 0 1 []}
@with_setup state.setup state.teardown def test_subunit_output_unicode state.expect [Includes {'status' 'success'} Includes {'status' 'fail' 'details' Includes {'traceback' ContentContains 'given_my_daemi_that_blows_a_exception' } } ]runner Runner feature_name 'unicode_traceback' enable_subunit True runner.run
def TR3 rv from sympy.simplify.simplify import signsimpdef f rv if not isinstance rv TrigonometricFunction return rvrv rv.func signsimp rv.args[0] if rv.args[0] - S.Pi / 4 .is_positive is S.Pi / 2 - rv.args[0] .is_positive is True fmap {cos sin sin cos tan cot cot tan sec csc csc sec}rv fmap[rv.func] S.Pi / 2 - rv.args[0] return rvreturn bottom_up rv f
def consistencygroup_get context consistencygroup_id return IMPL.consistencygroup_get context consistencygroup_id
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def _subdivide_interval_by_date start end if start.date end.date date_to_secs {start.date _to_secs end - start }else date_to_secs {}date_to_secs[start.date ] _to_secs datetime start.year start.month start.day + timedelta days 1 - start date_to_secs[end.date ] _to_secs end - datetime end.year end.month end.day cur_date start.date + timedelta days 1 while cur_date < end.date date_to_secs[cur_date] _to_secs timedelta days 1 cur_date + timedelta days 1 date_to_secs dict d secs for d secs in date_to_secs.items if secs return date_to_secs
def getTetragridTimesOther firstTetragrid otherTetragrid if firstTetragrid None return otherTetragridif otherTetragrid None return firstTetragridtetragridTimesOther []for row in xrange 4 matrixRow firstTetragrid[row]tetragridTimesOtherRow []tetragridTimesOther.append tetragridTimesOtherRow for column in xrange 4 dotProduct 0for elementIndex in xrange 4 dotProduct + matrixRow[elementIndex] * otherTetragrid[elementIndex][column] tetragridTimesOtherRow.append dotProduct return tetragridTimesOther
def get_zone zone_id profile conn _get_driver profile profile return conn.get_zone zone_id
def create_file_watcher pl watcher_type u'auto' expire_time 10 if watcher_type u'stat' pl.debug u'Usingrequestedstat-basedwatcher' prefix u'watcher' return StatFileWatcher if watcher_type u'inotify' pl.debug u'Usingrequestedinotifywatcher' prefix u'watcher' return INotifyFileWatcher expire_time expire_time elif watcher_type u'uv' pl.debug u'Usingrequesteduvwatcher' prefix u'watcher' return UvFileWatcher if sys.platform.startswith u'linux' try pl.debug u'Tryingtouseinotifywatcher' prefix u'watcher' return INotifyFileWatcher expire_time expire_time except INotifyError pl.info u'Failedtocreateinotifywatcher' prefix u'watcher' try pl.debug u'Usinglibuv-basedwatcher' return UvFileWatcher except UvNotFound pl.debug u'Failedtoimportpyuv' pl.debug u'Usingstat-basedwatcher' return StatFileWatcher
def setup_module_map _cache cache if conf.db_name local.app_modules _cache.get_value u'app_modules' local.module_app _cache.get_value u'module_app' if not local.app_modules and local.module_app local.module_app local.app_modules {} {} for app in get_all_apps True if app u'webnotes' app u'frappe'local.app_modules.setdefault app [] for module in get_module_list app module scrub module local.module_app[module] applocal.app_modules[app].append module if conf.db_name _cache.set_value u'app_modules' local.app_modules _cache.set_value u'module_app' local.module_app
def list_max_show_all changelist try from django.contrib.admin.views.main import MAX_SHOW_ALL_ALLOWEDreturn MAX_SHOW_ALL_ALLOWEDexcept ImportError return changelist.list_max_show_all
def make_array_flat_cls flatiterty return _make_flattening_iter_cls flatiterty 'flat'
def group_models_by_index backend models indices {}models_by_index collections.OrderedDict for model in models index backend.get_index_for_model model if index indices.setdefault index.name index models_by_index.setdefault index.name [] models_by_index[index.name].append model return collections.OrderedDict [ indices[index_name] index_models for index_name index_models in models_by_index.items ]
def _nbytes_full fmt nlines return fmt.repeat * fmt.width + 1 * nlines - 1
def compare_scores earned1 possible1 earned2 possible2 percentage1 float earned1 / float possible1 percentage2 float earned2 / float possible2 is_higher percentage2 > percentage1 return is_higher percentage1 percentage2
def fibs n result [0 1]for i in range n - 2 result.append result[ -2 ] + result[ -1 ] return result
def get_sorted_fields doctype custom_fields fields_dict frappe.get_meta doctype .get u'fields' standard_fields_count frappe.db.sql u'selectcount name from`tabDocField`\n DCTB DCTB whereparent %s' doctype [0][0]newlist []pending [d.fieldname for d in fields_dict]maxloops len custom_fields + 20 while pending and maxloops > 0 maxloops - 1for fieldname in pending[ ] if fieldname in custom_fields and len newlist > standard_fields_count for n in newlist if n custom_fields.get fieldname newlist.insert newlist.index n + 1 fieldname pending.remove fieldname breakelse newlist.append fieldname pending.remove fieldname if pending newlist + pendingreturn newlist
def shamelessly_promote click.echo u'Need' + click.style u'help' fg u'green' bold True + u'?Founda' + click.style u'bug' fg u'green' bold True + u'?Letus' + click.style u'know' fg u'green' bold True + u'! D' click.echo u'Filebugreportson' + click.style u'GitHub' bold True + u'here ' + click.style u'https //github.com/Miserlou/Zappa' fg u'cyan' bold True click.echo u'Andjoinour' + click.style u'Slack' bold True + u'channelhere ' + click.style u'https //slack.zappa.io' fg u'cyan' bold True click.echo u'Love! ' click.echo u'~Team' + click.style u'Zappa' bold True + u'!'
def maybe_promise value if isinstance value promise return value.evaluate return value
def getWithoutBracketsEqualTab line line line.replace ' ' '' line line.replace ' <' '' line line.replace '>' '' return line.replace ' DCTB ' ''
def s_render return blocks.CURRENT.render
def _fetch_ret_config ret if not ret return Noneif 'ret_config' not in ret return ''return str ret['ret_config']
def c_step X n_support remaining_iterations 30 initial_estimates None verbose False cov_computation_method empirical_covariance random_state None X np.asarray X random_state check_random_state random_state return _c_step X n_support remaining_iterations remaining_iterations initial_estimates initial_estimates verbose verbose cov_computation_method cov_computation_method random_state random_state
@aborts@with_settings foo {} def test_require_key_exists_empty_dict require 'foo'
def request_user_has_role request role if not cfg.CONF.auth.enable return Trueuser_db get_user_db_from_request request request return user_has_role user_db user_db role role
def _get_upgradable dist_upgrade True **kwargs cmd ['apt-get' '--just-print']if dist_upgrade cmd.append 'dist-upgrade' else cmd.append 'upgrade' fromrepo _get_repo **kwargs if fromrepo cmd.extend ['-o' 'APT Default-Release {0}'.format fromrepo ] call __salt__['cmd.run_all'] cmd python_shell False output_loglevel 'trace' if call['retcode'] ! 0 msg 'Failedtogetupgrades'for key in 'stderr' 'stdout' if call[key] msg + ' ' + call[key] breakraise CommandExecutionError msg else out call['stdout']rexp re.compile ' ?m ^Conf [^]+ \\ [^]+ ' keys ['name' 'version']_get lambda l k l[keys.index k ] upgrades rexp.findall out ret {}for line in upgrades name _get line 'name' version_num _get line 'version' ret[name] version_numreturn ret
def cautious_slugify value value force_text value value unicodedata.normalize u'NFKD' value value SLUGIFY_RE.sub u'' value value value.encode u'ascii' u'backslashreplace' .decode u'ascii' return slugify value
def decode_from_querystring s **kw if not isinstance s unicode raise TypeError u'unicoderequired' try return urlsafe_b64decode s.encode u'ascii' .replace '~' ' ' .decode u'utf8' except if u'default' in kw return kw[u'default']raise Response 400 u'invalidinput'
def summarize_address_range first last if not isinstance first _BaseAddress and isinstance last _BaseAddress raise TypeError 'firstandlastmustbeIPaddresses notnetworks' if first.version ! last.version raise TypeError '%sand%sarenotofthesameversion' % first last if first > last raise ValueError 'lastIPaddressmustbegreaterthanfirst' if first.version 4 ip IPv4Networkelif first.version 6 ip IPv6Networkelse raise ValueError 'unknownIPversion' ip_bits first._max_prefixlenfirst_int first._iplast_int last._ipwhile first_int < last_int nbits min _count_righthand_zero_bits first_int ip_bits _int_bit_length last_int - first_int + 1 - 1 net ip '%s/%d' % first ip_bits - nbits yield net first_int + 1 << nbits if first_int - 1 ip._ALL_ONES breakfirst first.__class__ first_int
def add_zone_slave service master_device_id service.data.get 'master' slaves_ids service.data.get 'slaves' slaves [device for device in DEVICES if device.entity_id in slaves_ids ]master next [device for device in DEVICES if device.entity_id master_device_id ].__iter__ None if master is None _LOGGER.warning 'Unabletofindmasterwithentity_id ' + str master_device_id elif not slaves _LOGGER.warning 'Unabletofindslavestoadd' else _LOGGER.info 'Addingslavestozonewithmaster' + str master.device.config.name master.device.add_zone_slave [slave.device for slave in slaves]
def cohere x y NFFT 256 Fs 2 detrend detrend_none window window_hanning noverlap 0 pad_to None sides 'default' scale_by_freq None if len x < 2 * NFFT raise ValueError _coh_error Pxx f psd x NFFT Fs detrend window noverlap pad_to sides scale_by_freq Pyy f psd y NFFT Fs detrend window noverlap pad_to sides scale_by_freq Pxy f csd x y NFFT Fs detrend window noverlap pad_to sides scale_by_freq Cxy np.divide np.absolute Pxy ** 2 Pxx * Pyy Cxy.shape len f return Cxy f
def CheckForCopyright filename lines error for line in range 1 min len lines 11 if re.search 'Copyright' lines[line] re.I breakelse error filename 0 'legal/copyright' 5 'Nocopyrightmessagefound.Youshouldhavealine "Copyright[year]<CopyrightOwner>"'
def filter_results original_file_dict modified_file_dict original_results modified_results renamed_files ensure_files_present original_file_dict modified_file_dict diffs_dict {}for file in original_file_dict diffs_dict[file] Diff.from_string_arrays original_file_dict[file] modified_file_dict[renamed_files.get file file ] orig_result_diff_dict_dict remove_result_ranges_diffs original_results original_file_dict mod_result_diff_dict_dict remove_result_ranges_diffs modified_results modified_file_dict unique_results []for m_r in reversed modified_results unique Truefor o_r in original_results if basics_match o_r m_r if source_ranges_match original_file_dict diffs_dict orig_result_diff_dict_dict[o_r] mod_result_diff_dict_dict[m_r] renamed_files unique Falsebreakif unique unique_results.append m_r return unique_results
def connect servers None framed_transport False timeout None retry_time 60 recycle None round_robin None max_retries 3 if servers is None servers [DEFAULT_SERVER]return ThreadLocalConnection servers framed_transport timeout retry_time recycle max_retries max_retries
def _KindKeyToString key key_path key.to_path if len key_path 2 and key_path[0] '__kind__' and isinstance key_path[1] basestring return key_path[1]raise BadRequestError 'invalidKeyfor__kind__table'
def gamma_corr clip gamma def fl im corrected 255 * 1.0 * im / 255 ** gamma return corrected.astype 'uint8' return clip.fl_image fl
def ParseFilePacket f header nothing None None if header ! 'PAR2\x00PKT' return nothinglen struct.unpack '<Q' f.read 8 [0]if int len / 4 * 4 ! len or len < 20 return nothingmd5sum f.read 16 data f.read len - 32 md5 new_md5 md5.update data if md5sum ! md5.digest return nothingfor offset in range 0 len 8 if data[offset offset + 16 ] 'PAR2.0\x00FileDesc' hash data[ offset + 32 offset + 48 ]filename data[ offset + 72 ].strip '\x00' return filename hash return nothing
def standard_b64decode s return b64decode s
def template_stack name None profile None h_client _auth profile if not name return {'result' False 'comment' 'ParameternamemissingorNone'}try get_template h_client.stacks.template name except exc.HTTPNotFound return {'result' False 'comment' 'Nostackwith{0}'.format name }except exc.BadRequest return {'result' False 'comment' 'Badrequestfotstack{0}'.format name }if 'heat_template_version' in get_template template yaml.dump get_template Dumper YamlDumper else template jsonutils.dumps get_template indent 2 ensure_ascii False checksum __salt__['hashutil.digest'] template ret {'template' template 'result' True 'checksum' checksum}return ret
def get_change_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'change_page' check_global check_global use_cache use_cache return page_ids
def bisect_right item item_list is_torrent lo 0hi len item_list while lo < hi mid lo + hi // 2 if item['relevance_score'] item_list[mid]['relevance_score'] and is_torrent if len split_into_keywords item['name'] < len split_into_keywords item_list[mid]['name'] hi midelse lo mid + 1 elif item['relevance_score'] > item_list[mid]['relevance_score'] hi midelse lo mid + 1 return lo
def _py_convert_agg_to_wx_image agg bbox image wx.EmptyImage int agg.width int agg.height image.SetData agg.tostring_rgb if bbox is None return imageelse return wx.ImageFromBitmap _clipped_image_as_bitmap image bbox
def hsv2rgb hsv arr _prepare_colorarray hsv hi np.floor arr[ 0] * 6 f arr[ 0] * 6 - hi p arr[ 2] * 1 - arr[ 1] q arr[ 2] * 1 - f * arr[ 1] t arr[ 2] * 1 - 1 - f * arr[ 1] v arr[ 2]hi np.dstack [hi hi hi] .astype np.uint8 % 6 out np.choose hi [np.dstack v t p np.dstack q v p np.dstack p v t np.dstack p q v np.dstack t p v np.dstack v p q ] return out
def _get_markdown_renderer class PygmentsHighlighter mistune.Renderer def block_code self code lang None if not lang return '\n<pre><code>%s</code></pre>\n' % mistune.escape code lexer get_lexer_by_name lang stripall True formatter HtmlFormatter classprefix 'highlight' return highlight code lexer formatter return mistune.Markdown renderer PygmentsHighlighter
def _transfer_data src dest length chunk_size chunks int math.ceil length / chunk_size remaining_length lengthLOG.debug '% chunks schunksof% bytes sbytestobetransferred.' {'chunks' chunks 'bytes' chunk_size} for chunk in range 0 chunks before time.time data tpool.execute src.read min chunk_size remaining_length if data '' breaktpool.execute dest.write data remaining_length - len data delta time.time - before rate chunk_size / delta / units.Ki LOG.debug 'Transferredchunk% chunk sof% chunks s % rate dK/s .' {'chunk' chunk + 1 'chunks' chunks 'rate' rate} eventlet.sleep 0 tpool.execute dest.flush
def _is_firewall_required vif if vif.is_neutron_filtering_enabled return Falseif CONF.firewall_driver ! 'nova.virt.firewall.NoopFirewallDriver' return Truereturn False
def get_previous_metadata_changeset_revision repository repo before_changeset_revision downloadable True changeset_revisions [revision[1] for revision in get_metadata_revisions repository repo ]if len changeset_revisions 1 changeset_revision changeset_revisions[0]if changeset_revision before_changeset_revision return hg_util.INITIAL_CHANGELOG_HASHreturn changeset_revisionprevious_changeset_revision Nonefor changeset_revision in changeset_revisions if changeset_revision before_changeset_revision if previous_changeset_revision return previous_changeset_revisionelse return hg_util.INITIAL_CHANGELOG_HASHelse previous_changeset_revision changeset_revision
def set_prerequisite_courses course_key prerequisite_course_keys if not is_prerequisite_courses_enabled return Nonecourse_milestones milestones_api.get_course_milestones course_key course_key relationship 'requires' if course_milestones for milestone in course_milestones remove_prerequisite_course course_key milestone if prerequisite_course_keys for prerequisite_course_key_string in prerequisite_course_keys prerequisite_course_key CourseKey.from_string prerequisite_course_key_string add_prerequisite_course course_key prerequisite_course_key
def size_label byte_count decimal 0 is_long False is_bytes True if is_bytes return _get_label SIZE_UNITS_BYTES byte_count decimal is_long else return _get_label SIZE_UNITS_BITS byte_count decimal is_long
def chhome name home persist False pre_info info name if not pre_info raise CommandExecutionError "User'{0}'doesnotexist".format name if home pre_info['home'] return Truecmd ['pw' 'usermod' name '-d' home]if persist cmd.append '-m' __salt__['cmd.run'] cmd python_shell False return info name .get 'home' home
def _task_names mapping tasks collections _sift_tasks mapping for collection in collections module mapping[collection]if hasattr module 'default' tasks.append collection join lambda x '.'.join collection x tasks.extend map join _task_names module return tasks
def _get_method_result module_ module_instance method_name method_arg None log.debug 'Tryingtocall%son%s' method_name module_ try method_obj getattr module_ method_name except AttributeError try method_obj getattr module_instance method_name except AttributeError raise InvalidArgumentError 'The{0}moduledoesnothaveanypropertyormethodnamed{1}'.format module_ method_name if isinstance method_obj property return method_obj.fget module_instance elif isinstance method_obj types.MethodType types.FunctionType if not method_arg raise InvalidArgumentError '{0}isamethodofthe{1}module.Anargumentdictisrequired.'.format method_name module_ try return getattr module_instance method_name method_arg['parameter'] except KeyError raise InvalidArgumentError 'Theargumentdictsuppliedhasnokeynamed"parameter" {0}'.format method_arg except AttributeError raise InvalidArgumentError 'The{0}moduledoesnothaveanypropertyormethodnamed{1}'.format module_ method_name else return method_objreturn None
def test_unicode_attribute s1 u '#-*-coding utf-8-*-\nclassPerson \nname "e"\n\nPerson .name.' completions1 Script s1 .completions assert 'strip' in [c.name for c in completions1] s2 u '#-*-coding utf-8-*-\nclassPerson \nname "\xc3\xa9"\n\nPerson .name.' completions2 Script s2 .completions assert 'strip' in [c.name for c in completions2]
def getnode global _nodeif _node is not None return _nodeimport sysif sys.platform 'win32' getters [_windll_getnode _netbios_getnode _ipconfig_getnode]else getters [_unixdll_getnode _ifconfig_getnode _arp_getnode _lanscan_getnode _netstat_getnode]for getter in getters + [_random_getnode] try _node getter except continueif _node is not None return _node
def UniformSum name n return rv name UniformSumDistribution n
def _get_host_ssds host_reference return _get_host_disks host_reference .get 'SSDs'
def esp8266_function_only func return check_supported_function func lambda o o.CHIP_NAME 'ESP8266'
@lower_cast MyDummyType types.Number def mydummy_to_number context builder fromty toty val return context.get_constant toty 42
def _smw_solver s A AtA BI di qmat AtA / s m BI.shape[0]qmat[0 m 0 m] + BIix np.arange m A.shape[1] qmat[ ix ix ] + diif sparse.issparse A qi sparse.linalg.inv qmat qmati A.dot qi.T .Telse qmati np.linalg.solve qmat A.T def solver rhs if sparse.issparse A ql qmati.dot rhs ql A.dot ql else ql np.dot qmati rhs ql np.dot A ql rslt rhs / s - ql / s ** 2 if sparse.issparse rslt rslt np.asarray rslt.todense return rsltreturn solver
def check_header_chars header warnings allowed_chars_header '_' + digits + letters for curr_elem in range len header for curr_char in header[curr_elem] if curr_char not in allowed_chars_header warnings.append 'Foundinvalidcharacterin%s' % header[curr_elem] + 'headerfield. DCTB %d %d' % 0 curr_elem breakreturn warnings
@deprecateddef script_resolve_name script_name name if not name return roslib.names.get_ros_namespace if roslib.names.is_global name return nameelif roslib.names.is_private name return ns_join roslib.names.make_caller_id script_name name[1 ] return roslib.names.get_ros_namespace + name
@never_cachedef complete request template u'shop/complete.html' extra_context None try order Order.objects.from_request request except Order.DoesNotExist raise Http404items order.items.all skus [item.sku for item in items]variations ProductVariation.objects.filter sku__in skus names {}for variation in variations.select_related u'product' names[variation.sku] variation.product.titlefor i item in enumerate items setattr items[i] u'name' names[item.sku] context {u'order' order u'items' items u'has_pdf' HAS_PDF u'steps' checkout.CHECKOUT_STEPS}context.update extra_context or {} return TemplateResponse request template context
def get_token_status token operation return_data False s TimedJSONWebSignatureSerializer current_app.config['SECRET_KEY'] user data None None expired invalid False False try data s.loads token except SignatureExpired expired Trueexcept BadSignature TypeError ValueError invalid Trueif data is not None if operation data.get 'op' None user User.query.filter_by id data.get 'id' .first else invalid Trueif return_data return expired invalid user data return expired invalid user
def _compare_bem_solutions sol_a sol_b _compare_bem_surfaces sol_a['surfs'] sol_b['surfs'] names ['bem_method' 'field_mult' 'gamma' 'is_sphere' 'nsol' 'sigma' 'source_mult' 'solution']assert_equal set sol_a.keys set sol_b.keys assert_equal set names + ['surfs'] set sol_b.keys for key in names assert_allclose sol_a[key] sol_b[key] rtol 0.001 atol 1e-05 err_msg 'Mismatch %s' % key
def _has_staff_access_to_descriptor user descriptor course_key return _has_staff_access_to_location user descriptor.location course_key
@utils.arg 'backup' metavar '<backup>' help 'IDofthebackuptorestore.' @utils.arg '--monitor-id' metavar '<monitor-id>' help 'OptionalIDofthemonitortorestoreto.' default None @utils.service_type 'monitor' def do_backup_restore cs args cs.restores.restore args.backup args.monitor_id
def test_wheel_exit_status_code_when_no_requirements script script.pip 'install' 'wheel' result script.pip 'wheel' expect_error True assert 'Youmustgiveatleastonerequirementtowheel' in result.stderr assert result.returncode ERROR
def has_include_file include_dirs filename if sys.platform 'win32' include_dirs + os.environ.get 'INCLUDE' '.' .split ';' for dir in include_dirs if os.path.exists os.path.join dir filename return Truereturn False
def run_command_with_code cmd redirect_output True check_exit_code True if redirect_output stdout subprocess.PIPEelse stdout Noneproc subprocess.Popen cmd cwd ROOT stdout stdout output proc.communicate [0]if check_exit_code and proc.returncode ! 0 die 'Command"%s"failed.\n%s' ''.join cmd output return output proc.returncode
def dfs_present path cmd_return _hadoop_cmd 'dfs' 'stat' path if 'Nosuchfileordirectory' in cmd_return return Falseelse return True
def parse_string io_or_string return XmlPropertyListParser .parse io_or_string
def basic_tokenizer sentence words []for space_separated_fragment in sentence.strip .split words.extend _WORD_SPLIT.split space_separated_fragment return [w for w in words if w]
def is_public_stream stream_name realm stream get_stream stream_name realm if stream is None return Falsereturn stream.is_public
def vare x1 x2 ddof 0 axis 0 x1 np.asanyarray x1 x2 np.asanyarray x2 return np.var x1 - x2 ddof ddof axis axis
def followers request content_type_id object_id ctype get_object_or_404 ContentType pk content_type_id instance get_object_or_404 ctype.model_class pk object_id return render_to_response 'actstream/followers.html' {'followers' models.followers instance 'actor' instance} context_instance RequestContext request
def af_for_address text try junk dns.ipv4.inet_aton text return AF_INETexcept try junk dns.ipv6.inet_aton text return AF_INET6except raise ValueError
def disable states ret {'res' True 'msg' ''}if isinstance states six.string_types states states.split ' ' msg []_disabled __salt__['grains.get'] 'state_runs_disabled' if not isinstance _disabled list _disabled []_changed Falsefor _state in states if _state in _disabled msg.append 'Info {0}statealreadydisabled.'.format _state else msg.append 'Info {0}statedisabled.'.format _state _disabled.append _state _changed Trueif _changed __salt__['grains.setval'] 'state_runs_disabled' _disabled ret['msg'] '\n'.join msg __salt__['saltutil.refresh_modules'] return ret
def _pad_h h up h_padlen len h + - len h % up h_full np.zeros h_padlen h.dtype h_full[ len h ] hh_full h_full.reshape -1 up .T[ -1 ].ravel return h_full
def get_game_dir_path for i in range 10 gpath os.getcwd if 'server' in os.listdir gpath if os.path.isfile os.path.join 'server' 'conf' 'settings.py' return gpathelse os.chdir os.pardir raise RuntimeError 'server/conf/settings.pynotfound Muststartfrominsidegamedir.'
def json_in content_type [ntou 'application/json' ntou 'text/javascript' ] force True debug False processor json_processor request cherrypy.serving.requestif isinstance content_type basestring content_type [content_type]if force if debug cherrypy.log 'Removingbodyprocessors%s' % repr request.body.processors.keys 'TOOLS.JSON_IN' request.body.processors.clear request.body.default_proc cherrypy.HTTPError 415 'Expectedanentityofcontenttype%s' % ' '.join content_type for ct in content_type if debug cherrypy.log 'Addingbodyprocessorfor%s' % ct 'TOOLS.JSON_IN' request.body.processors[ct] processor
def _muly p x y p1 poly_from_expr p x [0]n degree p1 a [ c * x ** i * y ** n - i for i c in p1.terms ]return Add *a
def convert_to_tgt_list_and_itor_tgt_map zone_mapping target_wwns []itor_tgt_map {}for san_name in zone_mapping one_map zone_mapping[san_name]for target in one_map['target_port_wwn_list'] if target not in target_wwns target_wwns.append target for initiator in one_map['initiator_port_wwn_list'] itor_tgt_map[initiator] one_map['target_port_wwn_list']LOG.debug 'target_wwns % tgt_wwns s\ninit_targ_map % itor_tgt_map s' {'tgt_wwns' target_wwns 'itor_tgt_map' itor_tgt_map} return target_wwns itor_tgt_map
def register_tests test_class method_name test_func exclude None formats [f for f in serializers.get_serializer_formats if not isinstance serializers.get_serializer f serializers.BadSerializer and f ! 'geojson' and exclude is None or f not in exclude ]for format_ in formats setattr test_class method_name % format_ curry test_func format_
def unwrapped_ball data return 10.0 / 5.0 + sum d - 3 ** 2 for d in data
def get_user_sites_queryset user qs Site.objects.all if not get_cms_setting 'PERMISSION' or user.is_superuser return qsglobal_ids GlobalPagePermission.objects.with_user user .filter Q can_add True | Q can_change True .values_list 'id' flat True query Q if global_ids query Q globalpagepermission__id__in global_ids if not qs.filter query .exists return qsquery | Q Q djangocms_pages__pagepermission__user user | Q djangocms_pages__pagepermission__group__user user & Q Q djangocms_pages__pagepermission__can_add True | Q djangocms_pages__pagepermission__can_change True return qs.filter query .distinct
def _activities_from_everything_followed_by_user_query user_id limit q1 _activites_from_users_followed_by_user_query user_id limit q2 _activities_from_datasets_followed_by_user_query user_id limit q3 _activities_from_groups_followed_by_user_query user_id limit return _activities_union_all q1 q2 q3
def bytes num_bytes if not isinstance num_bytes _integer_types raise TypeError 'num_bytesmustbeaninteger' if num_bytes < 0 raise ValueError 'num_bytesmustnotbenegative' result_buffer _ffi.new 'char[]' num_bytes result_code _lib.RAND_bytes result_buffer num_bytes if result_code -1 _raise_current_error return _ffi.buffer result_buffer [ ]
def is_null_slice obj return isinstance obj slice and obj.start is None and obj.stop is None and obj.step is None
def _GetBlobMetadata blob_key size content_type open_key _GetGoogleStorageFileMetadata blob_key if size is None size content_type open_key _GetBlobstoreMetadata blob_key return size content_type open_key
def test_float_range_2 try float_range '2.0' assert Falseexcept Exception pass
def add_token_to_response response csrf_token None if csrf_token response.set_cookie 'csrf_token' csrf_token expires CSRF_TIMEOUT httponly False
def _function_called_str function_name args kwargs template_str '{0} {1} {2} 'args_str repr args [1 -1 ]kwargs_str ' '.join '%s %s' % k v for k v in kwargs.items return template_str.format function_name args_str kwargs_str
def get_bc_lens ids_bcs_added_field bc_index 0bc_lens [len curr_bc[bc_index] for curr_bc in ids_bcs_added_field.keys ]bc_lens list set bc_lens bc_lens.sort reverse True return bc_lens
def constrain n min max if n < min return minif n > max return maxreturn n
def _format_elemcreate etype script False *args **kw spec Noneopts if etype in 'image' 'vsapi' if etype 'image' iname args[0]imagespec _format_mapdict {None args[1 ]} [1]spec '%s%s' % iname imagespec else class_name part_id args[ 2]statemap _format_mapdict {None args[2 ]} [1]spec '%s%s%s' % class_name part_id statemap opts _format_optdict kw script elif etype 'from' spec args[0]if len args > 1 opts args[1] if script spec '{%s}' % spec opts ''.join map str opts return spec opts
def fetch_tree client path index items consul_fetch client path ret {}has_children re.compile '/$' log.debug 'Fetcheditems %r' format items if items is None return retfor item in reversed items key re.sub '^' + path + '/?' '' item['Key'] if key ! '' log.debug 'key/path-%s %s' path key log.debug 'has_children?%r' format has_children.search key if has_children.search key is None ret pillar_format ret key.split '/' item['Value'] log.debug 'Fetchingsubkeysforkey %r' format item return ret
def randomSource return struct.unpack 'H' randbytes.secureRandom 2 fallback True [0]
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def assert_str_equal reference_str test_str format_str u'String{str1}and{str2}donotmatch \n{differences}' if reference_str ! test_str diff difflib.unified_diff reference_str.splitlines 1 test_str.splitlines 1 u'Reference' u'Testresult' u'' u'' 0 raise ValueError format_str.format str1 reference_str str2 test_str differences u''.join diff
def create_tmp_test code prefix 'tmp' delete True **kwargs py tempfile.NamedTemporaryFile prefix prefix delete delete code code.format **kwargs if IS_PY3 code code.encode 'UTF-8' py.write code py.flush st os.stat py.name os.chmod py.name st.st_mode | stat.S_IEXEC return py
def filter_settings_spec settings_spec *exclude **replace settings list settings_spec for i in range 2 len settings 3 newopts []for opt_spec in settings[i] opt_name [opt_string[2 ].replace '-' '_' for opt_string in opt_spec[1] if opt_string.startswith '--' ][0]if opt_name in exclude continueif opt_name in replace.keys newopts.append replace[opt_name] else newopts.append opt_spec settings[i] tuple newopts return tuple settings
def isplit string sep ' DCTB \n\x0b\x0c\r' a []for ch in string if ch not in sep a.append ch continueif a yield ''.join a a []if a yield ''.join a
def parse_limited_quantifier source saved_pos source.posmin_count parse_count source if source.match ' ' max_count parse_count source min_count int min_count or 0 max_count int max_count if max_count else None else if not min_count source.pos saved_posreturn Nonemin_count max_count int min_count if not source.match '}' source.pos saved_posreturn Noneif is_above_limit min_count or is_above_limit max_count raise error 'repeatcounttoobig' source.string saved_pos if max_count is not None and min_count > max_count raise error 'minrepeatgreaterthanmaxrepeat' source.string saved_pos return min_count max_count
def stop_and_disable service stop service disable service
def legacy_mapping block_device_mapping legacy_block_device_mapping []for bdm in block_device_mapping try legacy_block_device BlockDeviceDict bdm .legacy except exception.InvalidBDMForLegacy continuelegacy_block_device_mapping.append legacy_block_device for i dev in enumerate dev for dev in legacy_block_device_mapping if dev['virtual_name'] and is_ephemeral dev['virtual_name'] dev['virtual_name'] dev['virtual_name'][ -1 ] + str i return legacy_block_device_mapping
def getOverhangAngle elementNode return getCascadeFloatWithoutSelf 45.0 elementNode 'overhangAngle'
def combined_levels dimensions default_only False groups []for dim in dimensions if default_only levels dim.hierarchy .levelselse levels dim.levelsgroup [ str dim str level for level in levels]groups.append group return tuple itertools.product *groups
def _extract_submatrices M block_indices block_size axis assert block_indices.ndim 1 assert axis in [0 1] r c M.shapeif axis 0 sh [block_indices.shape[0] block_size c]elif axis 1 sh [block_indices.shape[0] r block_size]dt M.dtypeM_res np.empty sh dtype dt if axis 0 for ir in range block_size M_res[ ir ] M[ block_indices * block_size + ir ]elif axis 1 for ic in range block_size M_res[ ic] M[ block_indices * block_size + ic ]return M_res
@snippetdef topic_exists client to_delete TOPIC_NAME 'topic_exists-%d' % _millis topic client.topic TOPIC_NAME to_delete.append topic assert not topic.exists topic.create assert topic.exists
def call_split_lines x lineno None col None return ast.Call func ast.Attribute value x attr 'splitlines' ctx ast.Load lineno lineno col_offset col args [] keywords [] starargs None kwargs None lineno lineno col_offset col
def unlock_account name return __salt__['user.update'] name unlock_account True
def delete_temp_backups older_than 24 file_list os.listdir get_backup_path for this_file in file_list this_file_path os.path.join get_backup_path this_file if is_file_old this_file_path older_than os.remove this_file_path
def document_get index id doc_type '_all' hosts None profile None es _get_instance hosts profile try ret es.get index index id id doc_type doc_type return retexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def get_all_controllers try result utils.run 'lssubsys' ignore_status False controllers_str result.stdout.strip controller_list []for controller in controllers_str.splitlines controller_sub_list controller.split ' ' controller_list + controller_sub_listexcept error.CmdError controller_list ['cpuacct' 'cpu' 'memory' 'cpuset' 'devices' 'freezer' 'blkio' 'netcls']return controller_list
def GetELBInstanceHealth region instance_id node_types None balancers GetLoadBalancers region node_types node_types if not balancers return Nonefor b in balancers for state in b.get_instance_health if state.instance_id instance_id return state.statereturn None
def Dagum name p a b return rv name DagumDistribution p a b
def get_permission_for_course_about return configuration_helpers.get_value 'COURSE_ABOUT_VISIBILITY_PERMISSION' settings.COURSE_ABOUT_VISIBILITY_PERMISSION
def is_computable_float v tmp float v if not logical_or isnan tmp isinf tmp return tmpelse return False
@utils.cached 7 def ignored_regions source return [ match.start match.end for match in _str.finditer source ]
def getAllPhotometers from . import minolta prfrom . import crsphotometers [pr.PR650 pr.PR655 minolta.LS100]if hasattr crs 'ColorCAL' photometers.append crs.ColorCAL return photometers
def recursive_unlink f if os.path.isdir f for s in os.listdir f recursive_unlink os.path.join f s os.rmdir f elif os.path.isfile f os.unlink f
def equateCylindricalDotZ point returnValue point.z returnValue
def create_node args node query method 'droplets' args args http_method 'post' return node
@pytest.fixture autouse True def urlutils_config_stub config_stub monkeypatch config_stub.data {'general' {'auto-search' True} 'searchengines' {'test' 'http //www.qutebrowser.org/?q {}' 'test-with-dash' 'http //www.example.org/?q {}' 'DEFAULT' 'http //www.example.com/?q {}'}}monkeypatch.setattr 'qutebrowser.utils.urlutils.config' config_stub return config_stub
def get_tags_count journal tags [tag for entry in journal.entries for tag in set entry.tags ]tag_counts set [ tags.count tag tag for tag in tags] return tag_counts
def make_batches size batch_size nb_batch int np.ceil size / float batch_size return [ i * batch_size min size i + 1 * batch_size for i in range 0 nb_batch ]
def _find_start score_matrix align_globally nrows ncols len score_matrix len score_matrix[0] if align_globally starts [ score_matrix[ -1 ][ -1 ] nrows - 1 ncols - 1 ]else starts []for row in range nrows for col in range ncols score score_matrix[row][col]starts.append score row col return starts
def check_sffinfo if not which 'sffinfo' raise ApplicationNotFoundError _MISSING_APP_MESSAGE % 'sffinfo'
def lambdarepr expr **settings return LambdaPrinter settings .doprint expr
def bezier_subdivide cp t c00 c01 c02 c03 cpc10 c00 * 1 - t + c01 * t c11 c01 * 1 - t + c02 * t c12 c02 * 1 - t + c03 * t c20 c10 * 1 - t + c11 * t c21 c11 * 1 - t + c12 * t c30 c20 * 1 - t + c21 * t first [c00 c10 c20 c30]second [c30 c21 c12 c03]return first second
def modify_acl_group id **data group models.AclGroup.smart_get id group.check_for_acl_violation_acl_group group.update_object data group.add_current_user_if_empty
def never_cache view_func def _wrapped_view_func request *args **kwargs response view_func request *args **kwargs add_never_cache_headers response return responsereturn _wrapped_view_func
def _get_arrays arrays {}for node path in utils.node_generator GRAPH_REFERENCE if any [ key in path for key in GRAPH_REFERENCE['defs']['metaKeys']] continueif node.get 'role' ! 'object' continueif 'items' not in node continueobject_name path[ -1 ]if object_name not in arrays items node['items']if isinstance items dict item_names list items.keys else item_names [object_name[ -1 ]]arrays[object_name] {'meta_paths' [path] 'items' item_names}return arrays
def equalize image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._equalize image selem out out mask mask shift_x shift_x shift_y shift_y
def get_course_enrollment_details course_id include_expired False cache_key u'enrollment.course.details.{course_id}.{include_expired}'.format course_id course_id include_expired include_expired cached_enrollment_data Nonetry cached_enrollment_data cache.get cache_key except Exception log.exception u'Erroroccurredwhileretrievingcourseenrollmentdetailsfromthecache' if cached_enrollment_data log.info u'Getenrollmentdataforcourse%s cached ' course_id return cached_enrollment_datacourse_enrollment_details _data_api .get_course_enrollment_info course_id include_expired try cache_time_out getattr settings 'ENROLLMENT_COURSE_DETAILS_CACHE_TIMEOUT' 60 cache.set cache_key course_enrollment_details cache_time_out except Exception log.exception u'Erroroccurredwhilecachingcourseenrollmentdetailsforcourse%s' course_id raise errors.CourseEnrollmentError u'Anunexpectederroroccurredwhileretrievingcourseenrollmentdetails.' log.info u'Getenrollmentdataforcourse%s' course_id return course_enrollment_details
def _HPERM_OP a t a << 18 ^ a & 3435921408 return a ^ t ^ t >> 18 & 16383
def is_valid_definition params language return not exclude_bracket params.get 'enabled' BH_ENABLED params.get 'language_filter' BH_LANG_FILTER params.get 'language_list' BH_LANG_LIST language and params.get 'open' None is not None and params.get 'close' None is not None
def reg name ret {'name' name 'changes' {} 'comment' '' 'result' True}now time.time if 'status' not in __reg__ __reg__['status'] {}__reg__['status']['val'] {}for event in __events__ if fnmatch.fnmatch event['tag'] 'salt/beacon/*/status/*' idata {'recv_time' now}for key in event['data']['data'] if key in 'id' 'recv_time' continueidata[key] event['data'][key]__reg__['status']['val'][event['data']['data']['id']] idataret['changes'][event['data']['data']['id']] Truereturn ret
def hook_response response 'Updatetriggered' status 'success' return JsonResponse data {'status' status 'message' response}
def _get_dynamic_tabs course user dynamic_tabs list for tab_type in CourseTabPluginManager.get_tab_types if getattr tab_type 'is_dynamic' False tab tab_type dict if tab.is_enabled course user user dynamic_tabs.append tab dynamic_tabs.sort key lambda dynamic_tab dynamic_tab.name return dynamic_tabs
def getIntersectionOfXIntersectionIndexes totalSolidSurfaceThickness xIntersectionIndexList xIntersectionList []solidTable {}solid FalsexIntersectionIndexList.sort for xIntersectionIndex in xIntersectionIndexList toggleHashtable solidTable xIntersectionIndex.index '' oldSolid solidsolid len solidTable > totalSolidSurfaceThickness if oldSolid ! solid xIntersectionList.append xIntersectionIndex.x return xIntersectionList
def set_recv_attr status recvtable s3db.inv_recvship_status s3db.inv_ship_statusrecvtable.sender_id.readable recvtable.sender_id.writable Falserecvtable.grn_status.readable recvtable.grn_status.writable Falserecvtable.cert_status.readable recvtable.cert_status.writable Falserecvtable.eta.readable Falserecvtable.req_ref.writable Trueif status ship_status['IN_PROCESS'] recvtable.send_ref.writable Truerecvtable.recv_ref.readable Falserecvtable.sender_id.readable Falseelse for field in recvtable.fields recvtable[field].writable Falseif status ship_status['SENT'] recvtable.date.writable Truerecvtable.recipient_id.readable recvtable.recipient_id.writable Truerecvtable.comments.writable True
def validate_port_or_colon_separated_port_range port_range if port_range.count ' ' > 1 raise ValidationError _ 'Onecolonallowedinportrange' ports port_range.split ' ' for port in ports validate_port_range port
@register_canonicalize@gof.local_optimizer [T.Reshape] def local_reshape_to_dimshuffle node op node.opif not isinstance op Reshape return Falseinput node.inputs[0]output node.outputs[0]output_shape node.inputs[1]dimshuffle_new_order []new_output_shape []index 0for i in xrange output.ndim dim extract_constant output_shape[i] only_process_constants False elemwise False if dim 1 dimshuffle_new_order.append 'x' else dimshuffle_new_order.append index new_output_shape.append dim index index + 1 if index ! output.ndim inner op.__class__ len new_output_shape input new_output_shape copy_stack_trace output inner new_node [DimShuffle inner.type.broadcastable dimshuffle_new_order inner ]copy_stack_trace output new_node return new_node
def _listOpenFDs return detector._listOpenFDs
def urlopen url data None proxies None global _urlopenerif proxies is not None opener urllib.request.FancyURLopener proxies proxies elif not _urlopener opener FancyURLopener _urlopener openerelse opener _urlopenerif data is None return opener.open url else return opener.open url data
def checkCRC data check return computeCRC data check
def test_iter_evoked raw events picks _get_data epochs Epochs raw events[ 5] event_id tmin tmax picks picks for ii ev in enumerate epochs.iter_evoked x ev.datay epochs.get_data [ii ]assert_array_equal x y
def _clean_to_gce_name identifier return unicode identifier.lower .replace u'+' u'-' .replace u'/' u'-'
def get_sorted_filediffs filediffs key None def cmp_filediffs x y if x[0] ! y[0] return cmp x[0] y[0] x_file x_ext os.path.splitext x[1] y_file y_ext os.path.splitext y[1] if x_file y_file return cmp y_ext x_ext else return cmp x_file y_file def make_key filediff if key filediff key filediff filename filediff.dest_filei filename.rfind u'/' if i -1 return u'' filename else return filename[ i] filename[ i + 1 ] return sorted filediffs cmp cmp_filediffs key make_key
def if_firewall_available distribution commands if is_centos_or_rhel distribution firewall_command 'firewall-cmd'elif is_ubuntu distribution firewall_command 'ufw'else raise DistributionNotSupported distribution distribution return run_from_args ['which' firewall_command] .on success lambda result commands error catch_exit_code 1
def base36 value result ''while value value i divmod value 36 result BASE36_ALPHABET[i] + result return result
def worker_get_all context until None db_filters None **filters return IMPL.worker_get_all context until until db_filters db_filters **filters
def get_filename_with_new_ext original_file_path new_ext output_directory return path.join output_directory path.splitext path.split original_file_path [1] [0] + new_ext
def attach_is_voter_to_queryset queryset user as_field 'is_voter' model queryset.modeltype apps.get_model 'contenttypes' 'ContentType' .objects.get_for_model model if user is None or user.is_anonymous sql 'SELECTfalse'else sql 'SELECTCASEWHEN SELECTcount * \nFROMvotes_vote\nWHEREvotes_vote.content_type_id {type_id}\nANDvotes_vote.object_id {tbl}.id\nANDvotes_vote.user_id {user_id} >0\nTHENTRUE\nELSEFALSE\nEND'sql sql.format type_id type.id tbl model._meta.db_table user_id user.id qs queryset.extra select {as_field sql} return qs
def proto1_to_proto2 message body try args kwargs body.get u'args' body.get u'kwargs' {} kwargs.itemsexcept KeyError raise InvalidTaskError u'Messagedoesnothaveargs/kwargs' except AttributeError raise InvalidTaskError u'Taskkeywordargumentsmustbeamapping' body.update argsrepr saferepr args kwargsrepr saferepr kwargs headers message.headers try body[u'group'] body[u'taskset']except KeyError passembed {u'callbacks' body.get u'callbacks' u'errbacks' body.get u'errbacks' u'chord' body.get u'chord' u'chain' None}return args kwargs embed body True body.get u'utc' True
def generate_frontpage_pngs only_if_needed True for fn_png fn_py in FRONTPAGE_PNGS.items pn_png os.path.join FRONTPAGE_PNG_PATH fn_png pn_py os.path.join FRONTPAGE_PY_PATH fn_py mtime_py os.path.getmtime pn_py mtime_png os.path.getmtime pn_png if os.path.exists pn_png else mtime_py - 1 if only_if_needed and mtime_py < mtime_png continuesubprocess.check_call ['python' pn_py] os.rename fn_png pn_png
def _api_fullstatus name output kwargs status build_status skip_dashboard kwargs.get 'skip_dashboard' output output return report output keyword 'status' data remove_callable status
def get_changed_fields_dict instance model_class try old_model model_class.objects.get pk instance.pk except model_class.DoesNotExist return {}else field_names [f.name for f in model_class._meta.get_fields if not f.is_relation ]changed_fields {field_name getattr old_model field_name for field_name in field_names if getattr old_model field_name ! getattr instance field_name }return changed_fields
def join_bytes_or_unicode prefix suffix if type prefix type suffix return join prefix suffix if isinstance prefix text_type return join prefix suffix.decode getfilesystemencoding else return join prefix suffix.encode getfilesystemencoding
def enable_source name return _change_source_state name 'enable'
def survey_getAllQuestionsForSeries series_id table current.s3db.survey_seriesrow current.db table.id series_id .select table.template_id limitby 0 1 .first template_id row.template_idquestions survey_getAllQuestionsForTemplate template_id return questions
def assert_request_user_is_admin request is_admin request_user_is_admin request request if not is_admin user_db get_user_db_from_request request request raise AccessDeniedError message 'Administratoraccessrequired' user_db user_db
def hide_tick_labels_from_box_subplots fig boxplot_xaxes []for trace in fig['data'] if trace['type'] 'box' boxplot_xaxes.append 'xaxis{}'.format trace['xaxis'][1 ] for xaxis in boxplot_xaxes fig['layout'][xaxis]['showticklabels'] False
def read_all filter_ [] dir_ rospkg.get_test_results_dir root_result Result 'ros' 0 0 0 if not os.path.exists dir_ return root_resultfor d in os.listdir dir_ if filter_ and not d in filter_ continuesubdir os.path.join dir_ d if os.path.isdir subdir for filename in os.listdir subdir if filename.endswith '.xml' filename os.path.join subdir filename result read filename os.path.basename subdir root_result.accumulate result return root_result
def _bayes_thresh details var dvar np.mean details * details eps np.finfo details.dtype .epsthresh var / np.sqrt max dvar - var eps return thresh
def vector_norm data axis None out None data numpy.array data dtype numpy.float64 copy True if out is None if data.ndim 1 return math.sqrt numpy.dot data data data * dataout numpy.atleast_1d numpy.sum data axis axis numpy.sqrt out out return outelse data * datanumpy.sum data axis axis out out numpy.sqrt out out
@_docstring 'area' def search_areas query '' limit None offset None strict False **fields return _do_mb_search 'area' query fields limit offset strict
def test_call_accepts_func_pos_params_kw_types @accepts int_2 int int_1 int int_3 int def foo int_1 int_2 int_3 passt time.time for i in range 0 10000 foo 5 6 7 return time.time - t
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def test_role_serialization roles [blocks.roles.INPUT blocks.roles.OUTPUT blocks.roles.COST blocks.roles.PARAMETER blocks.roles.AUXILIARY blocks.roles.WEIGHT blocks.roles.BIAS blocks.roles.FILTER]for role in roles deserialized cPickle.loads cPickle.dumps role assert deserialized role
def check_extras dist attr value try for k v in value.items if ' ' in k k m k.split ' ' 1 if pkg_resources.invalid_marker m raise DistutilsSetupError 'Invalidenvironmentmarker ' + m list pkg_resources.parse_requirements v except TypeError ValueError AttributeError raise DistutilsSetupError "'extras_require'mustbeadictionarywhosevaluesarestringsorlistsofstringscontainingvalidproject/versionrequirementspecifiers."
def _get_ctf_head_to_head_t idx_points fp idx_points.astype '>f8' dp np.sum fp[2] * fp[0] - fp[1] tmp1 tmp2 sum_squared fp[2] sum_squared fp[0] - fp[1] dcos - dp / np.sqrt tmp1 * tmp2 dsin np.sqrt 1.0 - dcos * dcos dt dp / np.sqrt tmp2 t np.array [[dcos - dsin 0.0 dt] [dsin dcos 0.0 0.0] [0.0 0.0 1.0 0.0] [0.0 0.0 0.0 1.0]] return Transform 'ctf_head' 'head' t
def _make_interpolation_matrix pos_from pos_to alpha 1e-05 pos_from pos_from.copy pos_to pos_to.copy _normalize_vectors pos_from _normalize_vectors pos_to cosang_from pos_from.dot pos_from.T cosang_to_from pos_to.dot pos_from.T G_from _calc_g cosang_from G_to_from _calc_g cosang_to_from if alpha is not None G_from.flat[ len G_from + 1 ] + alphan_channels G_from.shape[0]C np.r_[ np.c_[ G_from np.ones n_channels 1 ] np.c_[ np.ones 1 n_channels 0 ] ]C_inv linalg.pinv C interpolation np.c_[ G_to_from np.ones G_to_from.shape[0] 1 ].dot C_inv[ -1 ] return interpolation
def _fake_run_horcmstart2 *args return 0 if not run_horcmstart_returns_error2 else 3
def _get_play obj if hasattr obj '_play' return obj._playif getattr obj '_parent' return _get_play obj._parent
def makePrintable data charset quote None to_unicode False smart True if data if not isinstance data unicode data unicode data 'ISO-8859-1' charset 'ASCII'data regex_control_code.sub lambda regs controlchars[ord regs.group 1 ] data if quote if quote in '"\'' data data.replace quote '\\' + quote data ''.join quote data quote elif quote data ' empty 'data data.encode charset 'backslashreplace' if smart data re.sub '\\\\x0 [0-7] ? [^0-7]|$ ' '\\\\\\1' data if to_unicode data unicode data charset return data
def create_lead email_id from email.utils import parseaddrfrom frappe.model.naming import get_default_naming_series real_name email_id parseaddr email_id if frappe.db.get_value u'Lead' {u'email_id' email_id} returnlead frappe.get_doc {u'doctype' u'Lead' u'email_id' email_id u'lead_name' real_name or email_id u'status' u'Lead' u'naming_series' get_default_naming_series u'Lead' u'company' frappe.db.get_default u'Company' u'source' u'Email'} lead.insert
def center_on_screen widget desk desktop rect desk.screenGeometry QtGui.QCursor .pos cy rect.height // 2 cx rect.width // 2 widget.move cx - widget.width // 2 cy - widget.height // 2
def url_path_join *pieces initial pieces[0].startswith '/' final pieces[ -1 ].endswith '/' stripped [s.strip '/' for s in pieces]result '/'.join s for s in stripped if s if initial result '/' + result if final result + '/'if result '//' result '/'return result
@step u'{word w}stepfails' def step_fails context word assert False 'EXPECT Failingstep'
def symptom_invalid_password_regular_expression try if CONF.security_compliance.password_regex re.match CONF.security_compliance.password_regex 'password' return Falseexcept re.error return True
def tup_to_vs tup return '.'.join tup
def assert_has_line_matching output expression match re.search '^%s$' % expression output flags re.MULTILINE assert match is not None "Nolinematchingexpression'%s'wasfoundinoutputfile." % expression
def test_sorted_bases assert u.m * u.Jy .bases u.Jy * u.m .bases
def parse_uid uid if UIDFieldMixin.UID_SEPARATOR not in uid raise ValueError 'Invaliduid %s' % uid parsed uid.split UIDFieldMixin.UID_SEPARATOR if len parsed < 2 raise ValueError 'Invalidormalformeduid %s' % uid resource_type parsed[0]uid_remainder parsed[1 ]return resource_type uid_remainder
def powersum n p b 10 dlist digitsrep n b sum 0for k in dlist sum + k ** p return sum
def munge_name name if isinstance name unicode name substitute_ascii_equivalents name name re.sub '[. /]' '-' name name re.sub '[^a-zA-Z0-9-_]' '' name .lower name _munge_to_length name model.PACKAGE_NAME_MIN_LENGTH model.PACKAGE_NAME_MAX_LENGTH return name
def register_input_converter converter prepend False global INPUT_CONVERTERif prepend INPUT_CONVERTER.insert 0 converter else INPUT_CONVERTER.append converter
def create_bias_initializer bias_shape stddev 1 / math.sqrt np.prod bias_shape return tf.truncated_normal_initializer stddev stddev
def addAcceleratorCommand acceleratorBinding commandFunction master menu text acceleratorText acceleratorBinding[1 -1 ]lastIndexOfMinus acceleratorText.rfind '-' if lastIndexOfMinus > -1 acceleratorText acceleratorText[ lastIndexOfMinus + 1 ] + acceleratorText[ lastIndexOfMinus + 1 ].capitalize acceleratorText acceleratorText.replace 'KeyPress-' '' acceleratorText acceleratorText.replace '-' '+' acceleratorText acceleratorText.replace 'Control' 'Ctrl' acceleratorBinding acceleratorBinding.replace 'KeyPress' '' menu.add_command accelerator acceleratorText label text underline 0 command commandFunction master.bind acceleratorBinding commandFunction
def _image_locations_delete_all context image_id delete_time None session None session session or get_session location_refs session.query models.ImageLocation .filter_by image_id image_id .filter_by deleted False .all for loc_id in [loc_ref.id for loc_ref in location_refs] image_location_delete context image_id loc_id 'deleted' delete_time delete_time session session
def startTLS transport contextFactory normal bypass if normal client transport._tlsClientDefaultelse client not transport._tlsClientDefault producer streaming None None if transport.producer is not None producer streaming transport.producer transport.streamingProducer transport.unregisterProducer tlsFactory TLSMemoryBIOFactory contextFactory client None tlsProtocol TLSMemoryBIOProtocol tlsFactory transport.protocol False transport.protocol tlsProtocoltransport.getHandle tlsProtocol.getHandletransport.getPeerCertificate tlsProtocol.getPeerCertificatedirectlyProvides transport ISSLTransport transport.TLS Truetransport.protocol.makeConnection _BypassTLS bypass transport if producer transport.registerProducer producer streaming
def fmt_ex ex return traceback.format_exception_only ex.__class__ ex [ -1 ].strip
def _inverse_tester norm_instance vals assert_array_almost_equal norm_instance.inverse norm_instance vals vals
def attach_notify_policies queryset as_field 'notify_policies_attr' model queryset.modelsql '\nSELECTjson_agg row_to_json notifications_notifypolicy \nFROMnotifications_notifypolicy\nWHEREnotifications_notifypolicy.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def defuse_xml_libs from defusedxml import defuse_stdlibdefuse_stdlib import lxmlimport lxml.etreefrom . import etree as safe_etreelxml.etree safe_etree
def wait_for_page_change browser source_url None page_source None wait_time 0.1 max_retries 50 for i in range max_retries if source_url is not None and browser.current_url ! source_url breakelif page_source is not None and browser.page_source ! page_source breakelse time.sleep wait_time return browser.current_url ! source_url
def install_dependencies npm 'npm' run '% npm sinstall' % locals
def test_forum_delete forum forum.delete forum Forum.query.filter_by id forum.id .first assert forum is None
def fake_wait_for_ip check_for_ip_fn interval None timeout None interval_multiplier None assert isinstance interval int assert isinstance timeout int assert isinstance interval_multiplier int return check_for_ip_fn
def survey_getAllQuestionsForComplete complete_id table current.s3db.survey_completerow current.db table.id complete_id .select table.series_id limitby 0 1 .first series_id row.series_idquestions survey_getAllQuestionsForSeries series_id return questions series_id
def override_pylons_about_with_core_template return render_template u'home/about.html'
def _backupFile filePath assert os.path.exists filePath stampNum 0 prefix suffix os.path.splitext filePath while True backupPath '%s.%d%s' % prefix stampNum suffix stampNum + 1if not os.path.exists backupPath breakshutil.copyfile filePath backupPath return backupPath
def getPythonDirectoryNamesRecursively directoryName '' recursivePythonDirectoryNames []if directoryName '' directoryName os.getcwd if os.path.isfile os.path.join directoryName '__init__.py' recursivePythonDirectoryNames.append directoryName pythonDirectoryNames getPythonDirectoryNames directoryName for pythonDirectoryName in pythonDirectoryNames recursivePythonDirectoryNames + getPythonDirectoryNamesRecursively pythonDirectoryName else return []return recursivePythonDirectoryNames
def _subdivide_interval_by_hour start end start_hour start.replace minute 0 second 0 microsecond 0 end_hour end.replace minute 0 second 0 microsecond 0 if start_hour end_hour hour_to_secs {start_hour _to_secs end - start }else hour_to_secs {}hour_to_secs[start_hour] _to_secs start_hour + timedelta hours 1 - start hour_to_secs[end_hour] _to_secs end - end_hour cur_hour start_hour + timedelta hours 1 while cur_hour < end_hour hour_to_secs[cur_hour] _to_secs timedelta hours 1 cur_hour + timedelta hours 1 hour_to_secs dict h secs for h secs in hour_to_secs.items if secs return hour_to_secs
def getNewRepository return FillRepository
@simple_decoratordef valid_prefs_required view_func def _check_valid_prefs request *args **kwargs if request.user.is_authenticated Profile.objects.get_or_create user request.user return view_func request *args **kwargs return _check_valid_prefs
@pipeline.mutator_stagedef import_asis session task if task.skip returnlog.info displayable_path task.paths task.set_choice action.ASIS
def fetch_stream_from_url url config data None handlers None return_code return_message response open_url url config data data handlers handlers if return_code and return_code http_client_.OK return responseelse raise URLFetchError return_message
def _scale_enum anchor scales w h x_ctr y_ctr _whctrs anchor ws w * scales hs h * scales anchors _mkanchors ws hs x_ctr y_ctr return anchors
def get_build_platform try from sysconfig import get_platformexcept ImportError from distutils.util import get_platformplat get_platform if sys.platform 'darwin' and not plat.startswith 'macosx-' try version _macosx_vers machine os.uname [4].replace '' '_' return 'macosx-%d.%d-%s' % int version[0] int version[1] _macosx_arch machine except ValueError passreturn plat
def _parsems value if u'.' not in value return int value 0 else i f value.split u'.' return int i int f.ljust 6 u'0' [ 6]
def destroy_cached_images session sr_ref all_cached False dry_run False cached_images _find_cached_images session sr_ref destroyed set def destroy_cached_vdi vdi_uuid vdi_ref LOG.debug "DestroyingcachedVDI'% vdi_uuid s'" if not dry_run destroy_vdi session vdi_ref destroyed.add vdi_uuid for vdi_ref in cached_images.values vdi_uuid session.call_xenapi 'VDI.get_uuid' vdi_ref if all_cached destroy_cached_vdi vdi_uuid vdi_ref continuechain list _walk_vdi_chain session vdi_uuid if len chain > 2 continueelif len chain 2 root_vdi_rec chain[ -1 ]children _child_vhds session sr_ref [root_vdi_rec['uuid']] if len children > 1 continuedestroy_cached_vdi vdi_uuid vdi_ref return destroyed
def test_dirops curpath os.getcwdstartdir os.getcwd ipdir os.path.realpath _ip.ipython_dir try _ip.magic 'cd"%s"' % ipdir nt.assert_equal curpath ipdir _ip.magic 'cd-' nt.assert_equal curpath startdir _ip.magic 'pushd"%s"' % ipdir nt.assert_equal curpath ipdir _ip.magic 'popd' nt.assert_equal curpath startdir finally os.chdir startdir
def validate_publicname username if len username < 3 return 'Publicnamemustbeatleast3charactersinlength'if len username > 255 return 'Publicnamecannotbemorethan255charactersinlength'if not VALID_PUBLICNAME_RE.match username return "Publicnamemustcontainonlylower-caseletters numbersand'-'"return ''
def extract request response None ids []cookie_name settings.OSCAR_RECENTLY_VIEWED_COOKIE_NAMEif cookie_name in request.COOKIES try ids json.loads request.COOKIES[cookie_name] except ValueError if response response.delete_cookie cookie_name else if not isinstance ids list ids []return ids
def unpack expr if len expr.args 1 return expr.args[0]else return expr
def mrv_max1 f g exps x u b f.union g exps return mrv_max3 f g.do_subs exps g f.do_subs exps u b x
def customer_gateway_exists customer_gateway_id None customer_gateway_name None region None key None keyid None profile None return resource_exists 'customer_gateway' name customer_gateway_name resource_id customer_gateway_id region region key key keyid keyid profile profile
def write_fasta_line demultiplexed_seqs_f fasta_seq label_line keep_barcode bc_len if keep_barcode final_seq fasta_seqelse final_seq fasta_seq[bc_len ]demultiplexed_seqs_f.write '>%s\n' % label_line demultiplexed_seqs_f.write '%s\n' % final_seq
def get_desktop if 'KDE_FULL_SESSION' in os.environ or 'KDE_MULTIHEAD' in os.environ return 'KDE'elif 'GNOME_DESKTOP_SESSION_ID' in os.environ or 'GNOME_KEYRING_SOCKET' in os.environ return 'GNOME'elif 'MATE_DESKTOP_SESSION_ID' in os.environ or 'MATE_KEYRING_SOCKET' in os.environ return 'MATE'elif sys.platform 'darwin' return 'MacOSX'elif hasattr os 'startfile' return 'Windows'elif _is_xfce return 'XFCE'if _is_x11 return 'X11'else return None
def _run_quiet cmd cwd None stdin None runas None shell DEFAULT_SHELL python_shell False env None template None umask None timeout None reset_system_locale True saltenv 'base' pillarenv None pillar_override None return _run cmd runas runas cwd cwd stdin stdin stderr subprocess.STDOUT output_loglevel 'quiet' log_callback None shell shell python_shell python_shell env env template template umask umask timeout timeout reset_system_locale reset_system_locale saltenv saltenv pillarenv pillarenv pillar_override pillar_override ['stdout']
def get_or_empty_db_cart cart_queryset Cart.objects.all def get_cart view @wraps view def func request *args **kwargs cart get_cart_from_request request cart_queryset return view request cart *args **kwargs return funcreturn get_cart
def scan_interfaces interfaces []for service in GetIOServicesByType 'IOSerialBSDClient' device get_string_property service 'IOCalloutDevice' if device usb_device GetParentDeviceByType service 'IOUSBInterface' if usb_device name get_string_property usb_device 'USBInterfaceName' or None locationID get_int_property usb_device 'locationID' kCFNumberSInt32Type or '' i SuitableSerialInterface i.id locationIDi.name nameinterfaces.append i return interfaces
def p_item_string p p[0] p[1][1 -1 ] None
def _resolve_user_group_names opts name_id_opts {'uid' 'user.info' 'gid' 'group.info'}for ind opt in enumerate opts if opt.split ' ' [0] in name_id_opts _givenid opt.split ' ' [1]_param opt.split ' ' [0]_id _givenidif not re.match '[0-9]+$' _givenid _info __salt__[name_id_opts[_param]] _givenid if _info and _param in _info _id _info[_param]opts[ind] _param + ' ' + str _id return opts
def get_autoscaler gce name zone try return gce.ex_get_autoscaler name zone except ResourceNotFoundError return None
def ignore_sigint func @wraps func def wrapped *args **kwargs curr_thread threading.currentThread single_thread threading.activeCount 1 and curr_thread.getName 'MainThread' class SigintHandler object def __init__ self self.sigint_received Falsedef __call__ self signum frame warnings.warn 'KeyboardInterruptignoreduntil{}iscomplete!'.format func.__name__ AstropyUserWarning self.sigint_received Truesigint_handler SigintHandler if single_thread old_handler signal.signal signal.SIGINT sigint_handler try func *args **kwargs finally if single_thread if old_handler is not None signal.signal signal.SIGINT old_handler else signal.signal signal.SIGINT signal.SIG_DFL if sigint_handler.sigint_received raise KeyboardInterruptreturn wrapped
def _get_user_certificate request user course_key course preview_mode None user_certificate Noneif preview_mode if has_access request.user 'instructor' course or has_access request.user 'staff' course user_certificate GeneratedCertificate mode preview_mode verify_uuid unicode uuid4 .hex modified_date datetime.now .date else try user_certificate GeneratedCertificate.eligible_certificates.get user user course_id course_key status CertificateStatuses.downloadable except GeneratedCertificate.DoesNotExist passreturn user_certificate
def register linter linter.register_checker ExceptionsChecker linter
def assertIsNotNone expr msg '' return assertIsNot expr None msg
def constants_pyx all_lines []assign_lines []for name in all_names if name 'NULL' assign_lines.append "globals ['NULL'] ZMQ_NULL" else assign_lines.append '{0} ZMQ_{0}'.format name all_lines.append '"{0}" '.format name return dict ASSIGNMENTS '\n'.join assign_lines ALL '\n'.join all_lines
def model_query context model *args **kwargs session kwargs.get 'session' or get_session read_deleted kwargs.get 'read_deleted' or context.read_deleted project_only kwargs.get 'project_only' query session.query model *args if read_deleted 'no' query query.filter_by deleted False elif read_deleted 'yes' passelif read_deleted 'only' query query.filter_by deleted True elif read_deleted 'int_no' query query.filter_by deleted 0 else raise Exception _ "Unrecognizedread_deletedvalue'%s'" % read_deleted if project_only and is_user_context context if model models.VolumeAttachment query query.filter models.Volume.project_id context.project_id else query query.filter_by project_id context.project_id return query
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def Nakagami name mu omega return rv name NakagamiDistribution mu omega
def filebytes fileobj buffersize 1024 buff fileobj.read buffersize while buff for byte in buff yield byte buff fileobj.read buffersize
def Event type _fields None **fields event dict _fields or {} type type **fields if 'timestamp' not in event event['timestamp'] time.time return event
def RemoveDirectory rebalance loc data_store.DB.Location if not os.path.exists loc return Falseif not os.path.isdir loc return Falsetempdir _GetTransactionDirectory loc rebalance.id try if tempdir.startswith loc shutil.rmtree tempdir except OSError pass
def change_USE_TRAKT use_trakt use_trakt checkbox_to_value use_trakt if sickbeard.USE_TRAKT use_trakt returnsickbeard.USE_TRAKT use_traktif sickbeard.USE_TRAKT if not sickbeard.traktCheckerScheduler.enable logger.log u'StartingTRAKTCHECKERthread' logger.INFO sickbeard.traktCheckerScheduler.silent Falsesickbeard.traktCheckerScheduler.enable Trueelse logger.log u'UnabletostartTRAKTCHECKERthread.Alreadyrunning' logger.INFO else sickbeard.traktCheckerScheduler.enable Falsesickbeard.traktCheckerScheduler.silent Truelogger.log u'StoppingTRAKTCHECKERthread' logger.INFO
def getGcodeWithoutDuplication duplicateWord gcodeText lines archive.getTextLines gcodeText oldWrittenLine Noneoutput cStringIO.StringIO for line in lines firstWord getFirstWordFromLine line if firstWord duplicateWord if line ! oldWrittenLine output.write line + '\n' oldWrittenLine lineelif len line > 0 output.write line + '\n' return output.getvalue
def authopenid request if hasattr request 'openid' openid request.openidelse openid Noneif hasattr request 'openids' openids request.openidselse openids []if hasattr request 'associated_openids' associated_openids request.associated_openidselse associated_openids []return {'openid' openid 'openids' openids 'associated_openids' associated_openids 'signin_with_openid' openid is not None 'has_openids' len associated_openids > 0 }
def get_locales prefix None normalize True locale_getter _default_locale_getter try raw_locales locale_getter except return Nonetry raw_locales raw_locales.split '\n' out_locales []for x in raw_locales if PY3 out_locales.append str x encoding pd.options.display.encoding else out_locales.append str x except TypeError passif prefix is None return _valid_locales out_locales normalize found re.compile '%s.*' % prefix .findall '\n'.join out_locales return _valid_locales found normalize
def countBits value assert 0 < value count 1bits 1while 1 << bits < value count + bitsvalue >> bitsbits << 1while 2 < value if bits ! 1 bits >> 1else bits - 1while 1 << bits < value count + bitsvalue >> bitsreturn count
def s3_encode_iso_datetime dt if isinstance dt datetime.datetime datetime.time dx dt.replace microsecond 0 else dx dtreturn dx.isoformat
def authenticate username password service 'login' @CONV_FUNCdef my_conv n_messages messages p_response app_data 'Simpleconversationfunctionthatrespondstoany\npromptwheretheechoisoffwiththesuppliedpassword'addr CALLOC n_messages sizeof PamResponse p_response[0] cast addr POINTER PamResponse for i in range n_messages if messages[i].contents.msg_style PAM_PROMPT_ECHO_OFF pw_copy STRDUP str password p_response.contents[i].resp cast pw_copy c_char_p p_response.contents[i].resp_retcode 0return 0handle PamHandle conv PamConv my_conv 0 retval PAM_START service username pointer conv pointer handle if retval ! 0 return Falseretval PAM_AUTHENTICATE handle 0 return retval 0
@decorators.which 'dig' def dig host cmd 'dig{0}'.format salt.utils.network.sanitize_host host return __salt__['cmd.run'] cmd
def add_selenium_arguments parser parser.add_argument '--selenium-browser' default 'auto' help BROWSER_DESCRIPTION parser.add_argument '--selenium-headless' default False action 'store_true' help HEADLESS_DESCRIPTION parser.add_argument '--selenium-remote' default False action 'store_true' help REMOTE_DESCRIPTION parser.add_argument '--selenium-remote-host' default '127.0.0.1' help REMOTE_HOST_DESCRIPTION parser.add_argument '--selenium-remote-port' default '4444' help REMOTE_PORT_DESCRIPTION parser.add_argument '--galaxy_url' default 'http //127.0.0.1 8080/' help GALAXY_URL_DESCRIPTION return parser
def p_logical_and_expression_2 t pass
def RubikGroup n from sympy.combinatorics.generators import rubikif n < 1 raise ValueError 'Invalidcube.nhastobegreaterthan1' return PermutationGroup rubik n
def detachRequest GmmCause_presence 0 a TpPd pd 3 b MessageType mesType 5 c DetachTypeAndForceToStandby packet a / b / c if GmmCause_presence is 1 e GmmCause ieiGC 37 packet packet / e return packet
def configure_zfs node variants return sequence [run_remotely username 'root' address node.address commands task_upgrade_kernel distribution node.distribution node.reboot run_remotely username 'root' address node.address commands sequence [task_install_zfs distribution node.distribution variants variants task_create_flocker_pool_file ] Effect Func lambda configure_ssh node.address 22 ]
def setup_management_exists _type _id deployment_id db current.dbttable current.s3db.scheduler_taskargs '["%s" "%s" "%s"]' % _type _id deployment_id query ttable.function_name 'setup_management' & ttable.args args & ttable.status.belongs ['RUNNING' 'QUEUED' 'ASSIGNED'] exists db query .select ttable.id limitby 0 1 .first if exists return Truereturn False
def _get_picks raw return pick_types raw.info meg True eeg False stim False ecg False eog False exclude 'bads'
def volume_create name size 100 snapshot None voltype None **kwargs conn get_conn create_kwargs {'name' name 'size' size 'snapshot' snapshot 'voltype' voltype}create_kwargs['availability_zone'] kwargs.get 'availability_zone' None return conn.volume_create **create_kwargs
def git_commit_id path ref cmd git_cmd_base path + ['show' ref] try output run_subprocess cmd stderr None universal_newlines True [0]except CalledProcessError raise NameError "Unknowngitreference'%s'" % ref commit output.split '\n' [0]assert commit[ 7] 'commit' return commit[7 ]
def is_resource_enabled resource return use_resources is None or resource in use_resources
def eventAsJSON event if bytes is str kw dict default objectSaveHook encoding 'charmap' skipkeys True else def default unencodable '\nSerializeanobjectnototherwiseserializablebyL{dumps}.\n\n@paramunencodable Anunencodableobject.\n@return C{unencodable} serialized\n'if isinstance unencodable bytes return unencodable.decode 'charmap' return objectSaveHook unencodable kw dict default default skipkeys True flattenEvent event result dumps event **kw if not isinstance result unicode return unicode result 'utf-8' 'replace' return result
def test_iht_wrong_estimator ratio 0.7est 'rnd'iht InstanceHardnessThreshold estimator est ratio ratio random_state RND_SEED assert_raises NotImplementedError iht.fit_sample X Y
def isWiddershins polygonComplex return getAreaLoop polygonComplex > 0.0
def node_format s name **extra shortname host nodesplit name return host_format s host shortname or NODENAME_DEFAULT p name **extra
def test_mergextend assert mergextend ['a' 'b'] ['c' 'd'] ['a' 'b'] assert mergextend [] ['c' 'd'] [] assert mergextend ['a' 'b'] [] ['a' 'b'] assert mergextend [_ellipsis] ['c' 'd'] ['c' 'd'] assert mergextend [_ellipsis 'b'] ['c' 'd'] ['c' 'd' 'b'] assert mergextend ['a' _ellipsis] ['c' 'd'] ['a' 'c' 'd'] assert mergextend ['a' _ellipsis 'b'] ['c' 'd'] ['a' 'c' 'd' 'b'] if sys.version_info[0] > 3 assert eval "mergextend ['a' ... 'b'] ['c' 'd'] " ['a' 'c' 'd' 'b']
def helper_here html u"<!DOCTYPEhtml>\n<html>\n<head>\n<title>HellofromFlask</title>\n</head>\n<body>HelloWorld helperhere {{h.render_markdown '*hi*' }}</body>\n</html>"return render_template_string html
def RegisterCLSIDsFromDict dict mapCLSIDToClass.update dict
def copy2subjdir cls in_file folder None basename None subject_id None if not isdefined in_file return in_fileif isdefined cls.inputs.subjects_dir subjects_dir cls.inputs.subjects_direlse subjects_dir os.getcwd if not subject_id if isdefined cls.inputs.subject_id subject_id cls.inputs.subject_idelse subject_id u'subject_id'if basename None basename os.path.basename in_file if folder ! None out_dir os.path.join subjects_dir subject_id folder else out_dir os.path.join subjects_dir subject_id if not os.path.isdir out_dir os.makedirs out_dir out_file os.path.join out_dir basename if not os.path.isfile out_file shutil.copy in_file out_file return out_file
def _add_reference reference statement type_ value _expand_one_key_dictionary reference opt Option type_ param SimpleParameter value opt.add_parameter param statement.add_child opt
def test_inherited_getattribute class x object def __getattribute__ self name if name 'abc' return 42return object.__getattribute__ self name class y x passAreEqual y .abc 42
def _SharedSuffix pattern1 pattern2 return _SharedPrefix pattern1[ -1 ] pattern2[ -1 ] [ -1 ]
def _session_tests session sample session.install '-r' 'testing/requirements.txt' session.install GCP_REPO_TOOLS_REQ session.chdir sample if os.path.exists os.path.join sample 'requirements.txt' session.install '-r' 'requirements.txt' session.run 'pytest' * PYTEST_COMMON_ARGS + session.posargs
def hdata try _id request.args[0]except raise HTTP 400 table s3db.gis_hierarchyquery table.deleted False & table.location_id _id row db query .select table.L1 table.L2 table.L3 table.L4 table.L5 limitby 0 1 .first if not row return 'varn'hdict {}for l in ['L1' 'L2' 'L3' 'L4' 'L5'] if row[l] hdict[int l[1 ] ] row[l]script 'n %s\n' % json.dumps hdict separators SEPARATORS response.headers['Content-Type'] 'application/json'return script
def _inv22_vectorized M assert M.ndim 3 assert M.shape[ -2 ] 2 2 M_inv np.empty_like M delta_inv np.reciprocal M[ 0 0] * M[ 1 1] - M[ 0 1] * M[ 1 0] M_inv[ 0 0] M[ 1 1] * delta_inv M_inv[ 0 1] - M[ 0 1] * delta_inv M_inv[ 1 0] - M[ 1 0] * delta_inv M_inv[ 1 1] M[ 0 0] * delta_inv return M_inv
def random_rotation x rg row_axis 1 col_axis 2 channel_axis 0 fill_mode 'nearest' cval 0.0 theta np.pi / 180 * np.random.uniform - rg rg rotation_matrix np.array [[np.cos theta - np.sin theta 0] [np.sin theta np.cos theta 0] [0 0 1]] h w x.shape[row_axis] x.shape[col_axis] transform_matrix transform_matrix_offset_center rotation_matrix h w x apply_transform x transform_matrix channel_axis fill_mode cval return x
def get_href element rel links element.findall 'link' for link in links if link.attrib['rel'] rel href link.attrib['href']needle '/api/'url_path urlparse.urlparse href .pathindex url_path.find needle result url_path[ index + len needle - 1 ]return result
def _create_quota_usage_if_missing user_usages resource until_refresh project_id user_id session new_usage Noneif resource not in user_usages user_id_to_use user_idif resource in PER_PROJECT_QUOTAS user_id_to_use Nonenew_usage _quota_usage_create project_id user_id_to_use resource 0 0 until_refresh or None session user_usages[resource] new_usagereturn new_usage is not None
def rsub self rhs if isinstance rhs variable.Variable return Sub rhs self _check_constant_type rhs return SubFromConstant rhs self
def _do_download version download_base to_dir download_delay egg os.path.join to_dir 'setuptools-%s-py%d.%d.egg' % version sys.version_info[0] sys.version_info[1] if not os.path.exists egg archive download_setuptools version download_base to_dir download_delay _build_egg egg archive to_dir sys.path.insert 0 egg if 'pkg_resources' in sys.modules _unload_pkg_resources import setuptoolssetuptools.bootstrap_install_from egg
def get_ca_bundle opts None if hasattr get_ca_bundle '__return_value__' return get_ca_bundle.__return_value__if opts is None opts {}opts_bundle opts.get 'ca_bundle' None if opts_bundle is not None and os.path.exists opts_bundle return opts_bundlefile_roots opts.get 'file_roots' {'base' [syspaths.SRV_ROOT_DIR]} for salt_root in file_roots.get 'base' [] for path in 'cacert.pem' 'ca-bundle.crt' cert_path os.path.join salt_root path if os.path.exists cert_path return cert_pathlocations '/etc/ssl/certs/ca-certificates.crt' '/etc/pki/tls/certs/ca-bundle.crt' '/etc/pki/tls/certs/ca-bundle.trust.crt' '/etc/ssl/certs/ca-bundle.crt' '/var/lib/ca-certificates/ca-bundle.pem' '/etc/ssl/cert.pem' for path in locations if os.path.exists path return pathif salt.utils.is_windows and HAS_CERTIFI return certifi.where return None
def _get_chunks shape ncpu chunks []nchunks_per_dim int ceil ncpu ** 1.0 / len shape used_chunks 1for i in shape if used_chunks < ncpu regular_chunk i // nchunks_per_dim remainder_chunk regular_chunk + i % nchunks_per_dim if regular_chunk 0 chunk_lens remainder_chunk else chunk_lens regular_chunk * nchunks_per_dim - 1 + remainder_chunk else chunk_lens i chunks.append chunk_lens used_chunks * nchunks_per_dimreturn tuple chunks
def ndarray_from_pil pil dtype 'uint8' rval np.asarray pil if dtype ! rval.dtype rval np.cast[dtype] rval if str dtype .startswith 'float' rval / 255.0if len rval.shape 2 rval rval.reshape rval.shape[0] rval.shape[1] 1 return rval
def _get_color_percentage a_c1 a_c2 a_c3 b_c1 b_c2 b_c3 percent if not 0 < percent < 100 raise ValueError 'percentneedstobebetween0and100!' out_c1 round a_c1 + b_c1 - a_c1 * percent / 100 out_c2 round a_c2 + b_c2 - a_c2 * percent / 100 out_c3 round a_c3 + b_c3 - a_c3 * percent / 100 return out_c1 out_c2 out_c3
def NgramAnalyzer minsize maxsize None return NgramTokenizer minsize maxsize maxsize | LowercaseFilter
def test_huber_and_sgd_same_results X y make_regression_with_outliers n_samples 10 n_features 2 huber HuberRegressor fit_intercept False alpha 0.0 max_iter 100 epsilon 1.35 huber.fit X y X_scale X / huber.scale_ y_scale y / huber.scale_ huber.fit X_scale y_scale assert_almost_equal huber.scale_ 1.0 3 sgdreg SGDRegressor alpha 0.0 loss 'huber' shuffle True random_state 0 n_iter 10000 fit_intercept False epsilon 1.35 sgdreg.fit X_scale y_scale assert_array_almost_equal huber.coef_ sgdreg.coef_ 1
def getTeardropPathByEndStart end radius start xmlElement inclination getInclination end start return getTeardropPath inclination radius xmlElement
def file_validator optdict name value return optik_ext.check_file None name value
def get_order_from_tree ids tree_text tree parse_newick tree_text PhyloNode ordered_ids []for tip in tree.iterTips if tip.Name in ids ordered_ids.append tip.Name return names_to_indices ids ordered_ids
def _solve_simple f x DE g k from sympy.solvers import rsolveRE hyper_re DE g k init {}for i in range len Add.make_args RE if i f f.diff x init[g k .subs k i ] f.limit x 0 / factorial i sol rsolve RE g k init if sol return sol S.Zero S.Zero
def get_credit_provider_info request provider_id credit_provider CreditProvider.get_credit_provider provider_id provider_id credit_provider_data {}if credit_provider credit_provider_data {'provider_id' credit_provider.provider_id 'display_name' credit_provider.display_name 'provider_url' credit_provider.provider_url 'provider_status_url' credit_provider.provider_status_url 'provider_description' credit_provider.provider_description 'enable_integration' credit_provider.enable_integration 'fulfillment_instructions' credit_provider.fulfillment_instructions 'thumbnail_url' credit_provider.thumbnail_url}return JsonResponse credit_provider_data
def get_ips linode_id None if linode_id ips _query 'linode' 'ip.list' args {'LinodeID' linode_id} else ips _query 'linode' 'ip.list' ips ips['DATA']ret {}for item in ips node_id str item['LINODEID'] if item['ISPUBLIC'] 1 key 'public_ips'else key 'private_ips'if ret.get node_id is None ret.update {node_id {'public_ips' [] 'private_ips' []}} ret[node_id][key].append item['IPADDRESS'] if linode_id _all_ips {'public_ips' [] 'private_ips' []}matching_id ret.get str linode_id if matching_id _all_ips['private_ips'] matching_id['private_ips']_all_ips['public_ips'] matching_id['public_ips']ret _all_ipsreturn ret
def set_lcd_filter filt library get_handle error FT_Library_SetLcdFilter library filt if error raise FT_Exception error
def delta_seconds before after delta after - before return datetime.timedelta.total_seconds delta
def ensure_minimal_setup package_manager if package_manager in 'dnf' 'yum' return run_network_interacting_from_args ['su' 'root' '-c' [package_manager '-y' 'install' 'sudo']] elif package_manager 'apt' return sequence [run_network_interacting_from_args ['su' 'root' '-c' ['apt-get' 'update']] run_network_interacting_from_args ['su' 'root' '-c' ['apt-get' '-y' 'install' 'sudo']] ] else raise UnsupportedDistribution
def _validate_labels labels l len labels total 0i -1 j 0for label in labels ll len label total + ll + 1 if ll > 63 raise LabelTooLongif i < 0 and label '' i jj + 1if total > 255 raise NameTooLongif i > 0 and i ! l - 1 raise EmptyLabel
def _resp_charset_property def getter self if ';charset ' in self.headers['content-type'] return self.headers['content-type'].split ';charset ' [1]def setter self value if 'content-type' in self.headers self.headers['content-type'] self.headers['content-type'].split ';' [0]if value self.headers['content-type'] + ';charset ' + value return property getter setter doc 'Retrieveandsettheresponsecharset'
def fixup_internal_links config soups reverse_directory {}for d s in config[u'sources'].items reverse_directory[s] dfor name soup in soups.items old_src_dir os.path.dirname config[u'sources'][name] for tag in soup.find_all True if not u'href' in tag.attrs continueold_rel_path tag[u'href'].split u'#' [0]old_dst os.path.normpath os.path.join old_src_dir old_rel_path if not old_dst in reverse_directory continuenew_dst reverse_directory[old_dst] + u'.html' new_rel_path rel_href name new_dst tag[u'href'] tag[u'href'].replace old_rel_path new_rel_path 1
def _open_pem_file cli_arg_path pem_path if cli.set_by_cli cli_arg_path return util.safe_open pem_path chmod 420 mode 'wb' os.path.abspath pem_path else uniq util.unique_file pem_path 420 'wb' return uniq[0] os.path.abspath uniq[1]
def addLoopLoopsIntersections loop loopsLoopsIntersections otherLoops for pointIndex in xrange len loop pointBegin loop[pointIndex]pointEnd loop[ pointIndex + 1 % len loop ]addLineLoopsIntersections loopsLoopsIntersections otherLoops pointBegin pointEnd
def screensaver cmd 'open/System/Library/Frameworks/ScreenSaver.framework/Versions/A/Resources/ScreenSaverEngine.app'call __salt__['cmd.run_all'] cmd output_loglevel 'debug' python_shell False _check_cmd call return True
def populate_option_groups_with_options assignments indexed_options for opt_group opt_dest_list in assignments.items new_options []for option_dest in assignments[opt_group] for option in indexed_options[option_dest] new_options.append option opt_group.add_options new_options opt_group.option_list sorted opt_group.option_list key lambda item item.get_opt_string
def unescape_doctest text if not contains_doctest text return textcode ''for line in text.split '\n' m re.match '^\\s* >>>|\\.\\.\\. .* $' line if m code + m.group 2 + '\n' elif line.strip code + '#' + line.strip + '\n' else code + '\n'return code
def weAreFrozen return hasattr sys 'frozen'
def split_resource_url resource_url protocol path_ resource_url.split u' ' 1 if protocol u'nltk' passelif protocol u'file' if path_.startswith u'/' path_ u'/' + path_.lstrip u'/' else path_ re.sub u'^/{0 2}' u'' path_ return protocol path_
def idd_sfrm l n w x return _id.idd_sfrm l n w x
def create_digest_traverser cloudtrail_client s3_client_provider trail_arn trail_source_region None on_invalid None on_gap None on_missing None bucket None prefix None assert_cloudtrail_arn_is_valid trail_arn account_id get_account_id_from_arn trail_arn if bucket is None trail_info get_trail_by_arn cloudtrail_client trail_arn LOG.debug 'Loadedtrailinfo %s' trail_info bucket trail_info['S3BucketName']prefix trail_info.get 'S3KeyPrefix' None trail_region trail_arn.split ' ' [3]trail_name trail_arn.split '/' [ -1 ]digest_provider DigestProvider account_id account_id trail_name trail_name s3_client_provider s3_client_provider trail_source_region trail_source_region trail_home_region trail_region return DigestTraverser digest_provider digest_provider starting_bucket bucket starting_prefix prefix on_invalid on_invalid on_gap on_gap on_missing on_missing public_key_provider PublicKeyProvider cloudtrail_client
def assert_contains haystack needle if needle not in haystack raise AssertionError 'item%rnotfoundincollection%r' % needle haystack
def matchSetContribution match_set target_set index contribution 0.0for t in target_set match - float 'inf' id -1 for i m in enumerate match_set v matchStrength m t if v > match match vid iif id index contribution + matchreturn contribution / len target_set
def test_events_are_condensed api_client message ts int time.time + 22 cursor get_cursor api_client ts message_id api_client.get_data '/messages/' [0]['id']message_path '/messages/{}'.format message_id api_client.put_data message_path {'unread' True} api_client.put_data message_path {'unread' False} api_client.put_data message_path {'unread' True} sync_data api_client.get_data '/delta?cursor {}'.format cursor deltas sync_data['deltas']message_deltas [d for d in deltas if d['object'] 'message' ]assert len message_deltas 1 delta message_deltas[0]assert delta['object'] 'message' and delta['event'] 'modify' assert delta['attributes']['unread'] is True
def _compute_mne_loc coil_loc loc np.zeros 12 if np.linalg.norm coil_loc['inner_coil'] 0 and np.linalg.norm coil_loc['outer_coil'] 0 return locloc[0 3] coil_loc['inner_coil'] / 39.370078 z_axis coil_loc['outer_coil'] - coil_loc['inner_coil'] R rotation3d_align_z_axis z_axis loc[3 13] R.T.reshape 9 return loc
def truncate_second dt measure d datetime dt.year dt.month dt.day tzinfo dt.tzinfo seconds total_seconds dt - d // measure * measure return dt.utcfromtimestamp seconds + utctotimestamp d
def wsgi_xmlrpc environ start_response if environ['REQUEST_METHOD'] 'POST' and environ['PATH_INFO'].startswith '/xmlrpc/' length int environ['CONTENT_LENGTH'] data environ['wsgi.input'].read length string_faultcode Trueif environ['PATH_INFO'].startswith '/xmlrpc/2/' service environ['PATH_INFO'][len '/xmlrpc/2/' ]string_faultcode Falseelse service environ['PATH_INFO'][len '/xmlrpc/' ] params method xmlrpclib.loads data return xmlrpc_return start_response service method params string_faultcode
def initTargetEnv if conf.multipleTargets if conf.hashDB conf.hashDB.close if conf.cj resetCookieJar conf.cj conf.paramDict {}conf.parameters {}conf.hashDBFile None_setKnowledgeBaseAttributes False _restoreMergedOptions _setDBMS if conf.data class _ unicode passkb.postUrlEncode Truefor key value in conf.httpHeaders if key.upper HTTP_HEADER.CONTENT_TYPE.upper kb.postUrlEncode 'urlencoded' in value breakif kb.postUrlEncode original conf.dataconf.data _ urldecode conf.data setattr conf.data UNENCODED_ORIGINAL_VALUE original kb.postSpaceToPlus '+' in original
def new_grep text None parent None widget Grep parent parent if text widget.search_for text return widget
def getTransformElementNode coords transformName transformElementNode coords.getFirstChildByLocalName transformName if len transformElementNode.attributes < 16 if 'bf ref' in transformElementNode.attributes idReference transformElementNode.attributes['bf ref']return coords.getDocumentElement .getSubChildWithID idReference return transformElementNode
def alpha_composite im1 im2 im1.load im2.load return im1._new core.alpha_composite im1.im im2.im
def test_finder_deplink req InstallRequirement.from_line 'gmpy 1.15' None finder PackageFinder [] [] process_dependency_links True session PipSession finder.add_dependency_links ['https //pypi.python.org/packages/source/g/gmpy/gmpy-1.15.zip'] link finder.find_requirement req False assert link.url.startswith 'https //pypi' link
def getNewRepository return FillRepository
def is_course_cohorted course_key return get_course_cohort_settings course_key .is_cohorted
def make_table oldtable None values None if oldtable is None table {'init' 0 0 'init_A/T' 0 0 'init_G/C' 0 0 'init_oneG/C' 0 0 'init_allA/T' 0 0 'init_5T/A' 0 0 'sym' 0 0 'AA/TT' 0 0 'AT/TA' 0 0 'TA/AT' 0 0 'CA/GT' 0 0 'GT/CA' 0 0 'CT/GA' 0 0 'GA/CT' 0 0 'CG/GC' 0 0 'GC/CG' 0 0 'GG/CC' 0 0 }else table oldtable.copy if values table.update values return table
def put_response_to_local_cache url _our_resp without_content False if parse.method ! 'GET' or _our_resp.status_code ! 200 returndbgprint 'PuttingCache ' url 'without_content ' without_content if without_content our_resp copy.copy _our_resp our_resp.response Noneobj_size 0else our_resp _our_respobj_size len parse.remote_response.content last_modified parse.remote_response.headers.get 'Last-Modified' None cache.put_obj url our_resp expires get_expire_from_mime parse.mime obj_size obj_size last_modified last_modified info_dict {'without_content' without_content 'last_modified' last_modified}
def get_diff_mat dim axis val_arr []row_arr []col_arr []for i in range dim val_arr.append 1.0 row_arr.append i col_arr.append i if i > 0 val_arr.append -1.0 row_arr.append i col_arr.append i - 1 mat sp.coo_matrix val_arr row_arr col_arr dim dim .tocsc if axis 0 return matelse return mat.T
def test_alnum arr for element in arr if not element.isalnum return Falsereturn True
def test_subdomain_detect for bn in SUBDOMAIN_OK assert _is_mostly_subdomain_compatible bn is True for bn in SUBDOMAIN_BOGUS assert _is_mostly_subdomain_compatible bn is False
def in_special_context node global p0 p1 p2 pats_builtif not pats_built p0 patcomp.compile_pattern p0 p1 patcomp.compile_pattern p1 p2 patcomp.compile_pattern p2 pats_built Truepatterns [p0 p1 p2]for pattern parent in zip patterns attr_chain node 'parent' results {}if pattern.match parent results and results['node'] is node return Truereturn False
def ALL_REGIONS_WITH_CONTENT_RATINGS return [x for x in ALL_REGIONS if x.ratingsbody]
def arity rel if len rel 0 return 0return len list rel [0]
def royal_road2 individual order total 0norder orderwhile norder < order ** 2 total + royal_road1 norder individual [0]norder * 2return total
def members_option arg if arg is None return ALLreturn [x.strip for x in arg.split ' ' ]
def is_known_charset charset try codecs.lookup charset except LookupError return Falsereturn True
def set_feature dev feature recipient None bmRequestType wIndex _parse_recipient recipient util.CTRL_OUT dev.ctrl_transfer bmRequestType bmRequestType bRequest 3 wIndex wIndex wValue feature
def pportD6 state global dataRegif state 0 dataReg dataReg & ~ 64 else dataReg dataReg | 64 port.DlPortWritePortUchar baseAddress dataReg
def list_fonts directory extensions pattern u';'.join [ u'*.%s;*.%s' % ext ext.upper for ext in extensions] return cbook.listFiles directory pattern
def test_forum_save category moderator_user forum Forum title 'TestForum' category_id category.id forum.moderators [moderator_user]forum.save assert forum.title 'TestForum' assert forum.moderators [moderator_user]
def get_taxa_coords tax_counts sample_coords tax_counts apply_along_axis lambda x x / float sum x 0 tax_counts tax_ratios apply_along_axis lambda x x / float sum x 1 tax_counts return dot tax_ratios sample_coords
def get_args parser cli.build_arg_parser parser.add_argument '-v' '--vm_uuid' required False action 'store' help 'Virtualmachineuuid' parser.add_argument '-r' '--vm_user' required False action 'store' help 'virtualmachineusername' parser.add_argument '-w' '--vm_pwd' required False action 'store' help 'virtualmachinepassword' parser.add_argument '-l' '--path_inside_vm' required False action 'store' help 'PathinsideVMforupload' parser.add_argument '-f' '--upload_file' required False action 'store' help 'Pathofthefiletobeuploadedfromhost' args parser.parse_args cli.prompt_for_password args return args
def wrapmodule module if _defaultproxy ! None module.socket.socket socksocketelse raise GeneralProxyError 4 'noproxyspecified'
def convert_to_bytes string factors {'K' 1024 'M' 1024 * 1024 'G' 1024 * 1024 * 1024 'T' 1024 * 1024 * 1024 * 1024 'P' 1024 * 1024 * 1024 * 1024 * 1024 'E' 1024 * 1024 * 1024 * 1024 * 1024 * 1024 }for f fm in factors.items if string.endswith f number float string[ -1 ] number number * fm return long number return long string
@ajax_required@require_http_methods ['POST' 'DELETE'] def manage_suggestion request uid sugg_id **kwargs_ if request.method 'DELETE' return reject_suggestion request uid sugg_id elif request.method 'POST' return accept_suggestion request uid sugg_id
def setup_button hass config add_entities client address timeout config.get CONF_TIMEOUT ignored_click_types config.get CONF_IGNORED_CLICK_TYPES button FlicButton hass client address timeout ignored_click_types _LOGGER.info 'Connectedtobutton %s ' address add_entities [button]
def whitelist allow_guest False xss_safe False def innerfn fn global whitelisted guest_methods xss_safe_methodswhitelisted.append fn if allow_guest guest_methods.append fn if xss_safe xss_safe_methods.append fn return fnreturn innerfn
def processXMLElement xmlElement xmlElement.parent.object.vertexes.append evaluate.getVector3FromXMLElement xmlElement
def _fast_count_smallints arr if len arr 0 return np.empty 0 2 dtype arr.dtype else counts np.bincount arr.astype np.int_ nz counts.nonzero [0]return np.c_[ nz counts[nz] ]
def puppyplot grown_up False from .external.six.moves.urllib.request import urlopenfrom IPython.display import HTMLtry from bs4 import BeautifulSoupurl 'http //www.dailypuppy.com'if grown_up url + '/dogs'html_doc urlopen url soup BeautifulSoup html_doc puppy soup.find 'div' {'class' 'daily_puppy'} return HTML str puppy.img except ImportError html '<imgsrc "http //cdn-www.dailypuppy.com/dog-images/decker-the-nova-scotia-duck-tolling-retriever_72926_2013-11-04_w450.jpg"style "width 450px;"/>'return HTML html
def non_neighbors graph node nbors set neighbors graph node | {node} return nnode for nnode in graph if nnode not in nbors
def test_pprint_nomod output pretty.pretty NoModule nt.assert_equal output 'NoModule'
def answer output s3_rest_controller return output
def sample prediction size vocabulary_size p np.zeros shape [1 size] dtype np.float p[ 0 sample_distribution prediction[0] ] 1.0return p
def _subject_from_forward forward return forward['src'][0].get 'subject_his_id' None
def set_user_info_cookie response request cookie_settings _get_cookie_settings request user_info_cookie_is_secure request.is_secure user_info get_user_info_cookie_data request response.set_cookie settings.EDXMKTG_USER_INFO_COOKIE_NAME.encode u'utf-8' json.dumps user_info secure user_info_cookie_is_secure **cookie_settings
def from_pci_stats pci_stats pools []if isinstance pci_stats six.string_types try pci_stats jsonutils.loads pci_stats except ValueError TypeError pci_stats Noneif pci_stats if 'nova_object.namespace' in pci_stats return objects.PciDevicePoolList.obj_from_primitive pci_stats elif isinstance pci_stats list pools [objects.PciDevicePool.from_dict stat for stat in pci_stats]else pools [objects.PciDevicePool.from_dict pci_stats ]return objects.PciDevicePoolList objects pools
def dfs_postorder b seen order []seen[b] bfor c in b.get_children if seen.has_key c continueorder order + dfs_postorder c seen order.append b return order
@treeio_login_required@module_admin_required def page_view request page_id response_format 'html' page get_object_or_404 Page pk page_id return render_to_response 'core/administration/page_view' {'page' page} context_instance RequestContext request response_format response_format
def test_extract_array_return_pos large_test_array np.arange 5 for i in np.arange -1 6 extracted new_pos extract_array large_test_array 3 i mode u'partial' return_position True assert new_pos 1 for i expected in zip [1.49 1.51 3] [1.49 0.51 1] extracted new_pos extract_array large_test_array 2 i mode u'strict' return_position True assert new_pos expected for i expected in zip np.arange -1 6 -1 0 1 1 1 1 1 extracted new_pos extract_array large_test_array 3 i mode u'trim' return_position True assert new_pos expected
def negate_tips_to_keep tips_to_keep tree tips_to_keep set tips_to_keep tmp_tips set [tip.Name for tip in tree.tips ] tips set [t.strip "'" .strip '"' for t in tmp_tips] return tips - tips_to_keep
def _genericHTTPChannelProtocolFactory self return _GenericHTTPChannelProtocol HTTPChannel
def test_feature_max_length_on_step_sentence feature Feature.from_string FEATURE4 assert_equals feature.max_length 55
def shlex_quotes value lex shlex.shlex value lex.quotes '"'lex.whitespace_split Truelex.commenters ''return list lex
def max_heapify seq i n l 2 * i + 1 r 2 * i + 2 if l < n and seq[l] > seq[i] largest lelse largest iif r < n and seq[r] > seq[largest] largest rif largest ! i seq[i] seq[largest] seq[largest] seq[i] max_heapify seq largest n
def clean_url_prefixes if hasattr _local 'prefix' delattr _local 'prefix'
def t_cleaning_features gb_parser GenBank.FeatureParser feature_cleaner utils.FeatureValueCleaner handle open os.path.join 'GenBank' 'arab1.gb' iterator GenBank.Iterator handle gb_parser first_record next iterator translation_feature first_record.features[1]test_trans translation_feature.qualifiers['translation'][0]assert '' not in test_trans 'Didnotcleanspacesoutofthetranslation'assert '\n' not in test_trans 'Didnotcleannewlinesoutofthetranslation'handle.close
def cmp_version ver1 ver2 return cmp [int v for v in ver1.split '.' ] [int v for v in ver2.split '.' ]
def is_win32 return sys.platform u'win32' or sys.platform u'cygwin'
def dup_mul_term f c i K if not c or not f return []else return [ cf * c for cf in f] + [K.zero] * i
def _hammingDistance s1 s2 return sum abs s1 - s2
def unpatch module attribute_name was_patched Falseattribute getattr module attribute_name if hasattr attribute __BACKUP_ATTRIBUTE_NAME attribute_old getattr attribute __BACKUP_ATTRIBUTE_NAME setattr module attribute_name attribute_old was_patched Truereturn was_patched
def test_sizeof_fmt assert_equal sizeof_fmt 0 '0bytes' assert_equal sizeof_fmt 1 '1byte' assert_equal sizeof_fmt 1000 '1000bytes'
def assert_categorical_equal left right check_dtype True obj 'Categorical' check_category_order True assertIsInstance left pd.Categorical '[Categorical]' assertIsInstance right pd.Categorical '[Categorical]' if check_category_order assert_index_equal left.categories right.categories obj '{0}.categories'.format obj assert_numpy_array_equal left.codes right.codes check_dtype check_dtype obj '{0}.codes'.format obj else assert_index_equal left.categories.sort_values right.categories.sort_values obj '{0}.categories'.format obj assert_index_equal left.categories.take left.codes right.categories.take right.codes obj '{0}.values'.format obj assert_attr_equal 'ordered' left right obj obj
def ConnectAndDisconnectChildModules old_module_dict new_module_dict old_keys set old_module_dict.keys new_keys set new_module_dict.keys for deleted_module_name in old_keys - new_keys if old_module_dict[deleted_module_name] is None continuesegments deleted_module_name.rsplit '.' 1 if len segments 2 parent_module new_module_dict.get segments[0] if parent_module and hasattr parent_module segments[1] delattr parent_module segments[1] for added_module_name in new_keys - old_keys if new_module_dict[added_module_name] is None continuesegments added_module_name.rsplit '.' 1 if len segments 2 parent_module old_module_dict.get segments[0] child_module new_module_dict[added_module_name]if parent_module and getattr parent_module segments[1] None is not child_module setattr parent_module segments[1] child_module
def get_module_data_path modname relpath None attr_name 'DATAPATH' datapath getattr sys.modules[modname] attr_name '' if datapath return datapathelse datapath get_module_path modname parentdir osp.join datapath osp.pardir if osp.isfile parentdir datapath osp.abspath osp.join osp.join parentdir osp.pardir modname if relpath is not None datapath osp.abspath osp.join datapath relpath return datapath
def parse_accept value result []for match in part_re.finditer ' ' + value name match.group 1 if name 'q' continuequality match.group 2 or '' if not quality quality 1else try quality max min float quality 1 0 except ValueError quality 1result.append name quality return result
def fixed_hessian point vars None model None model modelcontext model if vars is None vars model.cont_varsvars inputvars vars point Point point model model bij DictToArrayBijection ArrayOrdering vars point dlogp bij.mapf model.fastdlogp vars rval np.ones bij.map point .size / 10 return rval
def cache_on_disk t cache.disk 'time' lambda time.ctime time_expire 5 return dict time t link A 'clicktoreload' _href URL r request
def should_validate filename for extension in INCLUDE_TYPES if filename.endswith extension return Truereturn False
def hmac_sha256 k m key OpenSSL.malloc k len k d OpenSSL.malloc m len m md OpenSSL.malloc 0 32 i OpenSSL.pointer OpenSSL.c_int 0 OpenSSL.HMAC OpenSSL.EVP_sha256 key len k d len m md i return md.raw
def none_to_zero x if x is None return 0return x
def set_time_info layer attribute end_attribute presentation precision_value precision_step enabled True layer gs_catalog.get_layer layer.name if layer is None raise ValueError 'nosuchlayer %s' % layer.name resource layer.resourceresolution Noneif precision_value and precision_step resolution '%s%s' % precision_value precision_step info DimensionInfo 'time' enabled presentation resolution 'ISO8601' None attribute attribute end_attribute end_attribute metadata dict resource.metadata or {} metadata['time'] inforesource.metadata metadatags_catalog.save resource
def send_email_invitation email event_name link message_settings MessageSettings.query.filter_by action INVITE_PAPERS .first if not message_settings or message_settings.mail_status 1 send_email to email action INVITE_PAPERS subject MAILS[INVITE_PAPERS]['subject'].format event_name event_name html MAILS[INVITE_PAPERS]['message'].format email str email event_name str event_name link link
def attachComplete a TpPd pd 3 b MessageType mesType 3 packet a / b return packet
def dataset_followee_count context data_dict return _followee_count context data_dict context['model'].UserFollowingDataset
def onDBMgrShutDown INFO_MSG 'onDBMgrShutDown '
def short_time_label seconds if seconds < 0 raise ValueError "Inputneedstobeanon-negativeinteger got'%i'" % seconds time_comp {}for amount _ label in TIME_UNITS count int seconds / amount seconds % amounttime_comp[label.strip ] countlabel '%02i %02i' % time_comp['minute'] time_comp['second'] if time_comp['day'] label '%i-%02i %s' % time_comp['day'] time_comp['hour'] label elif time_comp['hour'] label '%02i %s' % time_comp['hour'] label return label
def get_group_symbol locale LC_NUMERIC return Locale.parse locale .number_symbols.get 'group' u' '
def get_module app modname verbose failfast module_name '%s.%s' % app modname app_mod import_module app try imp.find_module modname app_mod.__path__ if hasattr app_mod '__path__' else None except ImportError if failfast raiseelif verbose print u'Couldnotfind%rfrom%r' % modname app traceback.print_exc return Nonemodule import_module module_name if verbose print u'Loaded%rfrom%r' % modname app return module
def test_prove arguments for goal assumptions in arguments g Expression.fromstring goal alist [Expression.fromstring a for a in assumptions]p Prover9Command g assumptions alist .prove for a in alist print '%s' % a print '|-%s %s\n' % g p
def seedit seed 0 import randomimport numpyrandom.seed seed numpy.random.seed seed
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def getImportRadius elementNode if elementNode None return 0.36preferences skeinforge_craft.getCraftPreferences 'carve' importCoarseness getImportCoarseness elementNode preferences layerHeight skeinforge_craft.getCraftValue 'LayerHeight' preferences layerHeight getCascadeFloatWithoutSelf layerHeight elementNode 'layerHeight' edgeWidthOverHeight skeinforge_craft.getCraftValue 'EdgeWidthoverHeight' preferences edgeWidthOverHeight getCascadeFloatWithoutSelf edgeWidthOverHeight elementNode 'edgeWidthOverHeight' return getCascadeFloatWithoutSelf 0.5 * importCoarseness * layerHeight * edgeWidthOverHeight elementNode 'importRadius'
def plugin_loaded name if name in _PLUGINS return Truereturn False
def x_forwarded_ip request ip_address_list request.META.get 'HTTP_X_FORWARDED_FOR' if ip_address_list ip_address_list ip_address_list.split ' ' return ip_address_list[0]
def runSome tests []names ['testMasterContextSetup' 'testMasterRoadStats' 'testMasterLaneStats' 'testMasterStatsWrongMissingTag' 'testMasterStatsUnknownRemote' 'testMasterStatsNoRequest' 'testMinionContextSetup' 'testMinionRoadStats' 'testMinionLaneStats' 'testMinionStatsWrongMissingTag' 'testMinionStatsUnknownRemote' 'testMinionStatsNoRequest']tests.extend map StatsEventerTestCase names suite unittest.TestSuite tests unittest.TextTestRunner verbosity 2 .run suite
def selected_items list_widget items item_count len items selected []for widget_item in list_widget.selectedItems row list_widget.row widget_item if row < item_count selected.append items[row] return selected
def GeneratePassphrase length 20 valid_chars 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'valid_chars + '0123456789 -_&$#'return ''.join random.choice valid_chars for i in range length
def real_project_name project_name if project_name u'{{project_name}}' return u'project_name'return project_name
def getNormal a b c p np.roll normalize b - a 1 n - np.roll normalize c - a 1 p[1] * -1 n[1] * -1 return normalize p + n * 0.5
def separate x axis 0 shape list x.shape del shape[axis]ys split_axis.split_axis x x.shape[axis] axis force_tuple True return tuple reshape.reshape y shape for y in ys
def recipient_represent id default_label '' output ''table s3db.pr_pentitype db table.pe_id id .select table.instance_type limitby 0 1 .first if not pe return outputinstance_type pe.instance_typetable db.get instance_type None if not table return outputif instance_type 'pr_person' person db table.pe_id id .select table.first_name table.middle_name table.last_name limitby 0 1 .first if person output s3_fullname person elif instance_type 'pr_group' group db table.pe_id id .select table.name limitby 0 1 .first if group output group.namereturn output
def parse_authorization_header value if not value returnvalue wsgi_to_bytes value try auth_type auth_info value.split None 1 auth_type auth_type.lower except ValueError returnif auth_type 'basic' try username password base64.b64decode auth_info .split ' ' 1 except Exception returnreturn Authorization 'basic' {'username' bytes_to_wsgi username 'password' bytes_to_wsgi password } elif auth_type 'digest' auth_map parse_dict_header auth_info for key in 'username' 'realm' 'nonce' 'uri' 'response' if key not in auth_map returnif 'qop' in auth_map if not auth_map.get 'nc' or not auth_map.get 'cnonce' returnreturn Authorization 'digest' auth_map
def _fixup_cell_info cell_info keys if 'transport_url' not in cell_info returntransport_url cell_info.pop 'transport_url' try transport_url rpc.get_transport_url transport_url except messaging.InvalidTransportURL for key in keys cell_info.setdefault key None returnif not transport_url.hosts returntransport_host transport_url.hosts[0]transport_field_map {'rpc_host' 'hostname' 'rpc_port' 'port'}for key in keys if key in cell_info continuetransport_field transport_field_map.get key key cell_info[key] getattr transport_host transport_field
def expose url '/' methods 'GET' def wrap f if not hasattr f '_urls' f._urls []f._urls.append url methods return freturn wrap
def skip reason def decorator test_item if isinstance test_item type and issubclass test_item TestCase test_item.__unittest_skip__ Truetest_item.__unittest_skip_why__ reasonreturn test_item@functools_copy.wraps test_item def skip_wrapper *args **kwargs raise SkipTest reason return skip_wrapperreturn decorator
def _js_slot *args def _decorator method @functools.wraps method def new_method self *args **kwargs try return method self *args **kwargs except e str sys.exc_info [0] log.network.exception 'PACevaluationerror' return self._error_con.callAsConstructor [e] return pyqtSlot result QJSValue *args new_method return _decorator
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def _process_plotsummary x xauthor x.get 'author' xplot x.get 'plot' u'' .strip if xauthor xplot + u' %s' % xauthor return xplot
def AnyEntryFromString xml_string tree ElementTree.fromstring xml_string category tree.find '{%s}category' % atom.ATOM_NAMESPACE if category is None return atom._CreateClassFromElementTree GPhotosBaseEntry tree namespace kind category.get 'term' .split '#' if namespace ! PHOTOS_NAMESPACE return atom._CreateClassFromElementTree GPhotosBaseEntry tree feed_class getattr gdata.photos '%sEntry' % kind.title return atom._CreateClassFromElementTree feed_class tree
def get_rev_primer_seqs mapping_fp hds mapping_data run_description errors warnings process_id_map mapping_fp has_barcodes False disable_primer_check True if errors for curr_err in errors if curr_err.startswith 'DuplicateSampleID' raise ValueError 'Errorswerefoundwithmappingfile ' + 'pleaserunvalidate_mapping_file.pyto' + 'identifyproblems.' id_map {}for curr_data in mapping_data id_map[curr_data[0]] {}for header in range len hds for curr_data in mapping_data id_map[curr_data[0]][hds[header]] curr_data[header]reverse_primers {}for curr_id in id_map.keys try reverse_primers[curr_id] [str DNA curr_rev_primer .rc for curr_rev_primer in id_map[curr_id]['ReversePrimer'].split ' ' ]except KeyError raise KeyError 'Reverseprimernotfoundinmappingfile ' + "pleaseincludea'ReversePrimer'column." for curr_err in errors if curr_err.startswith 'InvalidDNAsequencedetected' raise ValueError 'Problemsfoundwithreverseprimers please' + 'checkmappingfilewithvalidate_mapping_file.py' return reverse_primers
def getUntilFirstBracket text dotIndex text.find ' ' if dotIndex < 0 return textreturn text[ dotIndex]
def p_declaration_specifiers_3 t pass
def drop_caches utils.run 'sync' verbose False utils.run 'echo3>/proc/sys/vm/drop_caches' ignore_status True verbose False
def _set_logfile_close_signal_handler logfile def _on_signal_close_logfile_before_exit unused_signal_no unused_frame logfile.close os.exit 1 signal.signal signal.SIGTERM _on_signal_close_logfile_before_exit
def _combined_regex regexes flags re.IGNORECASE use_re2 False max_mem None joined_regexes '|'.join r for r in regexes if r if not joined_regexes return Noneif use_re2 import re2return re2.compile joined_regexes flags flags max_mem max_mem return re.compile joined_regexes flags flags
def _get_thread_callback thread_data def callback request _uri headers '\nSimulatethethreadcreationorupdateendpointbyreturningtheprovided\ndataalongwiththedatafromresponse_overridesanddummyvaluesforany\nadditionalrequiredfields.\n'response_data make_minimal_cs_thread thread_data for key val_list in request.parsed_body.items val val_list[0]if key in ['anonymous' 'anonymous_to_peers' 'closed' 'pinned'] response_data[key] val 'True' else response_data[key] valreturn 200 headers json.dumps response_data return callback
def dep_attrs snippet resource_name if isinstance snippet Function return snippet.dep_attrs resource_name elif isinstance snippet collections.Mapping attrs dep_attrs value resource_name for value in snippet.items return itertools.chain.from_iterable attrs elif not isinstance snippet six.string_types and isinstance snippet collections.Iterable attrs dep_attrs value resource_name for value in snippet return itertools.chain.from_iterable attrs return []
def decode_chunked_transfer chunked_body body h t '' '' chunked_body while t h t t.split '\r\n' 1 if h '0' breaksize int h 16 body + t[ size]t t[ size + 2 ]return body
def get_key key host None port None db None password None server _connect host port db password return server.get key
def CompileQuery schema bound_query_str if isinstance bound_query_str tuple query_str param_dict bound_query_strelse query_str bound_query_strparam_dict Nonequery _query_cache.Get schema query_str lambda Query schema query_str return query param_dict
def iddr_rid m n matvect k idx proj _id.iddr_rid m n matvect k proj proj[ k * n - k ].reshape k n - k order 'F' return idx proj
def _list_descriptors return [desc for desc in [desc for _ desc in XModuleDescriptor.load_classes ]]
def real_path_to_hdfs_uri real_path environ hdfs_root get_mock_hdfs_root environ environ if not real_path.startswith hdfs_root raise ValueError 'path%sisnotin%s' % real_path hdfs_root hdfs_uri real_path[len hdfs_root ]if not hdfs_uri.startswith '/' hdfs_uri '/' + hdfs_uri return hdfs_uri
def _mbcs_to_unicode_wrap obj vtype if vtype u'REG_BINARY' return objif isinstance obj list return [_mbcs_to_unicode x for x in obj]elif isinstance obj int return objelse return _mbcs_to_unicode obj
def path_to_songname path return os.path.splitext os.path.basename path [0]
def scan_cix content filename md5sum None mtime None lang 'Python' codeintel scan_et content filename md5sum mtime lang tree et.ElementTree codeintel stream StringIO tree.write stream 'utf-8' raw_cix stream.getvalue cix raw_cix.replace '\n' '&#xA;' return cix
def _setHTTPHost if conf.host debugMsg 'settingtheHTTPHostheader'logger.debug debugMsg conf.httpHeaders.append HTTP_HEADER.HOST conf.host
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
def eval_univariate f var idx point x bij DictToVarBijection var idx point return list map bij.mapf f x
def getNewRepository return FillRepository
def get_filters_from_dict data attr_info skips None skips skips or [] res {}for key values in data.items if key in skips or hasattr model_base.BASEV2 key continuevalues [v for v in values if v]key_attr_info attr_info.get key {} if 'convert_list_to' in key_attr_info values key_attr_info['convert_list_to'] values elif 'convert_to' in key_attr_info convert_to key_attr_info['convert_to']values [convert_to v for v in values]if values res[key] valuesreturn res
def collect_glib_etc_files *path glib_config_dirs get_glib_sysconf_dirs if glib_config_dirs is None return []destdir os.path.join 'etc' *path[ -1 ] collected []for config_dir in glib_config_dirs p os.path.join config_dir *path collected + collect_system_data_files p destdir destdir include_py_files False return collected
def is_scalar_or_string val return is_string_like val or not iterable val
def rref_solve matlist variable constant K new_matlist copy.deepcopy matlist augmented augment new_matlist constant K solution rref augmented K return col solution -1
def runrefreshrepo module auto_import_keys False shortname None if auto_import_keys cmd _get_cmd '--gpg-auto-import-keys' 'refresh' '--force' else cmd _get_cmd 'refresh' '--force' if shortname is not None cmd.extend ['-r' shortname] rc stdout stderr module.run_command cmd check_rc True return rc stdout stderr
def communicate command None if command is not None logger.info 'DEBUG sendingcommand%s' % command pipe_in.write command result []while True data pipe_out.read if data is None breakresult.append data logger.info 'DEBUG result%s' % repr result return ''.join result
def stringfilter func def _dec *args **kwargs if args args list args args[0] force_text args[0] if isinstance args[0] SafeData and getattr _dec._decorated_function 'is_safe' False return mark_safe func *args **kwargs return func *args **kwargs _dec._decorated_function getattr func '_decorated_function' func return wraps func _dec
def get_sandbox_path virtualenv_path sandbox_path []parent_path os.environ.get 'PATH' '' if not virtualenv_path return parent_pathparent_path parent_path.split ' ' parent_path [path for path in parent_path if path]virtualenv_bin_path os.path.join virtualenv_path 'bin/' sandbox_path.append virtualenv_bin_path sandbox_path.extend parent_path sandbox_path ' '.join sandbox_path return sandbox_path
def _recurmatch path aug if path clean_path path.rstrip '/*' yield clean_path aug.get path for i in aug.match clean_path + '/*' i i.replace '!' '\\!' for _match in _recurmatch i aug yield _match
def askretrycancel title None message None **options s _show title message WARNING RETRYCANCEL **options return s RETRY
def autoassign self locals for key value in iteritems locals if key 'self' continuesetattr self key value
def list_upgrades refresh False root None **kwargs upgrades {}cmd ['pacman' '-S' '-p' '-u' '--print-format' '%n%v']if root is not None cmd.extend '-r' root if refresh cmd.append '-y' call __salt__['cmd.run_all'] cmd python_shell False output_loglevel 'trace' if call['retcode'] ! 0 comment ''if 'stderr' in call comment + call['stderr']if 'stdout' in call comment + call['stdout']if comment comment ' ' + comment raise CommandExecutionError 'Errorlistingupgrades' + comment else out call['stdout']for line in salt.utils.itertools.split out '\n' try pkgname pkgver line.split except ValueError continueif pkgname.lower 'downloading' and '.db' in pkgver.lower continueupgrades[pkgname] pkgverreturn upgrades
def foldl fn elems initializer None name None if initializer is None initializer elems[0]elems elems[1 ]fn2 lambda x acc fn acc x return theano.foldl fn2 elems initializer name name [0]
def correct_mapping_data mapping_data header char_replace '_' corrected_data deepcopy mapping_data valid_sample_id_chars letters + digits + '.' valid_data_field_chars letters + digits + '+-%./ ;_' sample_id_char_replace '.'sample_id_field 'SampleID'fields_to_skip ['BarcodeSequence' 'LinkerPrimerSequence' 'ReversePrimer']try sample_id_ix header.index sample_id_field except ValueError sample_id_ix -1 fields_to_skip_ixs []for curr_field in fields_to_skip try fields_to_skip_ixs.append header.index curr_field except ValueError continuefor curr_row in range len mapping_data for curr_col in range len mapping_data[curr_row] if curr_col in fields_to_skip_ixs continueelif sample_id_ix ! -1 and curr_col sample_id_ix curr_replacement sample_id_char_replacecurr_valid_chars valid_sample_id_charselse curr_replacement char_replacecurr_valid_chars valid_data_field_charscurr_corrected_field ''for curr_char in mapping_data[curr_row][curr_col].replace '\n' '' if curr_char not in curr_valid_chars curr_corrected_field + curr_replacementelse curr_corrected_field + curr_charcorrected_data[curr_row][curr_col] curr_corrected_fieldreturn corrected_data
def auto from .autopep8 import fix_fileclass Options object aggressive 2diff Falseexperimental Trueignore vim.eval 'g pymode_lint_ignore' in_place Trueindent_size int vim.eval '&tabstop' line_range Nonemax_line_length int vim.eval 'g pymode_options_max_line_length' pep8_passes 100recursive Falseselect vim.eval 'g pymode_lint_select' verbose 0fix_file vim.current.buffer.name Options
def refresh_db if 'eix.sync' in __salt__ return __salt__['eix.sync'] if 'makeconf.features_contains' in __salt__ and __salt__['makeconf.features_contains'] 'webrsync-gpg' cmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0 else if __salt__['cmd.retcode'] 'emerge--askn--quiet--sync' python_shell False 0 return Truecmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0
def fake_execute_set_repliers repliers global _fake_execute_repliers_fake_execute_repliers repliers
def iphexval ip a ip.split '.' hexval ''for val in a hexval ''.join [hexval hex int val [2 ].zfill 2 ] return hexval.upper
def _get_msvcrt_symbol symbol from ctypes import cdll cast c_void_pf getattr cdll.msvcrt symbol return cast f c_void_p .value
def serialize_device device device_data {}device_data['id'] device.iddevice_data['hostname'] device.hostnamedevice_data['tags'] device.tagsdevice_data['locked'] device.lockeddevice_data['ip_addresses'] [{'address' addr_data['address'] 'address_family' addr_data['address_family'] 'public' addr_data['public']} for addr_data in device.ip_addresses]for ipdata in device_data['ip_addresses'] if ipdata['public'] if ipdata['address_family'] 6 device_data['public_ipv6'] ipdata['address']elif ipdata['address_family'] 4 device_data['public_ipv4'] ipdata['address']elif not ipdata['public'] if ipdata['address_family'] 6 device_data['private_ipv6'] ipdata['address']elif ipdata['address_family'] 4 device_data['private_ipv4'] ipdata['address']return device_data
def _prepare_rerp_data raw events picks None decim 1 if picks is None picks pick_types raw.info meg True eeg True ref_meg True info pick_info raw.info picks decim int decim info['sfreq'] / decim data times raw[ ]data data[picks decim]if len set events[ 0] < len events[ 0] raise ValueError '`events`containsduplicatetimepoints.Makesureallentriesinthefirstcolumnof`events`areunique.' events events.copy events[ 0] - raw.first_sampevents[ 0] // decimif len set events[ 0] < len events[ 0] raise ValueError 'Afterdecimating `events`containsduplicatetimepoints.Thismeanssomeeventsaretoocloselyspacedfortherequesteddecimationfactor.Choosedifferentevents dropcloseevents orchooseadifferentdecimationfactor.' return data info events
def endpoint_direction address return address & _ENDPOINT_DIR_MASK
def check_evennia_dependencies from evennia.server.evennia_launcher import check_main_evennia_dependenciesnot_error check_main_evennia_dependencies errstring ''if 'south' in settings.INSTALLED_APPS errstring + "\nERROR 'south'foundinsettings.INSTALLED_APPS.\nSouthisnolongerused.Ifthiswasaddedmanually removeit."not_error Falseif settings.IRC_ENABLED try import twisted.wordstwisted.wordsexcept ImportError errstring + "\nERROR IRCisenabled buttwisted.wordsisnotinstalled.Pleaseinstallit.\nLinuxDebian/Ubuntuusersshouldinstallpackage'python-twisted-words' others\ncangetitfromhttp //twistedmatrix.com/trac/wiki/TwistedWords."not_error Falseerrstring errstring.strip if errstring mlen max len line for line in errstring.split '\n' logger.log_err '%s\n%s\n%s' % '-' * mlen errstring '-' * mlen return not_error
def _hex_to_rgba hexs hexs np.atleast_1d np.array hexs '|U9' out np.ones len hexs 4 np.float32 for hi h in enumerate hexs assert isinstance h string_types off 1 if h[0] '#' else 0 assert len h in 6 + off 8 + off e len h - off // 2 out[hi e] [ int h[i i + 2 ] 16 / 255.0 for i in range off len h 2 ]return out
def pipeline_id_from_name name region None key None keyid None profile None r {}result_pipelines list_pipelines if 'error' in result_pipelines return result_pipelinesfor pipeline in result_pipelines['result'] if pipeline['name'] name r['result'] pipeline['id']return rr['error'] 'Nopipelinefoundwithname {0}'.format name return r
def _butterfly_onpick event params params['need_draw'] Trueax event.artist.axesax_idx np.where [ ax is a for a in params['axes']] [0]if len ax_idx 0 returnelse ax_idx ax_idx[0]lidx np.where [ l is event.artist for l in params['lines'][ax_idx]] [0][0]ch_name params['ch_names'][params['idxs'][ax_idx][lidx]]text params['texts'][ax_idx]x event.artist.get_xdata [event.ind[0]]y event.artist.get_ydata [event.ind[0]]text.set_x x text.set_y y text.set_text ch_name text.set_color event.artist.get_color text.set_alpha 1.0 text.set_zorder len ax.lines text.set_path_effects params['path_effects']
def get_vlan_config_commands vlan vid reverse_value_map {'admin_state' {'down' 'shutdown' 'up' 'noshutdown'}}if vlan.get 'admin_state' vlan apply_value_map reverse_value_map vlan VLAN_ARGS {'name' 'name{0}' 'vlan_state' 'state{0}' 'admin_state' '{0}' 'mode' 'mode{0}' 'mapped_vni' 'vn-segment{0}'}commands []for param value in vlan.iteritems if param 'mapped_vni' and value 'default' command 'novn-segment'else command VLAN_ARGS.get param .format vlan.get param if command commands.append command commands.insert 0 'vlan' + vid commands.append 'exit' return commands
def general_random_intersection_graph n m p if len p ! m raise ValueError 'Probabilitylistpmusthavemelements.' G nx.empty_graph n + m mset range n n + m for u in range n for v q in zip mset p if random.random < q G.add_edge u v return nx.projected_graph G range n
def sall brule fns basic_fns op new children leaf map fns.get 'op' 'new' 'children' 'leaf' def all_rl expr if leaf expr yield expr else myop op expr argss product *map brule children expr for args in argss yield new myop *args return all_rl
def flatten_el el include_hrefs skip_tag False if not skip_tag if el.tag 'img' yield 'img' el.get 'src' start_tag el else yield start_tag el if el.tag in empty_tags and not el.text and not len el and not el.tail returnstart_words split_words el.text for word in start_words yield html_escape word for child in el for item in flatten_el child include_hrefs include_hrefs yield item if el.tag 'a' and el.get 'href' and include_hrefs yield 'href' el.get 'href' if not skip_tag yield end_tag el end_words split_words el.tail for word in end_words yield html_escape word
@pytest.mark.parametrize u'testframe' totest_frames def test_gcrs_altaz_moonish testframe moon GCRS MOONDIST_CART obstime testframe.obstime moonaa moon.transform_to testframe assert 1000 * u.km < np.abs moonaa.distance - moon.distance .to u.au < 7000 * u.km moon2 moonaa.transform_to moon assert_allclose moon.cartesian.xyz moon2.cartesian.xyz
def unfold_entities entity_list target_level if target_level not in entity_levels raise PDBException '%s Notanentitylevel.' % target_level if entity_list [] return []if isinstance entity_list Entity Atom entity_list [entity_list]level entity_list[0].get_level if not all entity.get_level level for entity in entity_list raise PDBException 'Entitylistisnothomogeneous.' target_index entity_levels.index target_level level_index entity_levels.index level if level_index target_index return entity_listif level_index > target_index for i in range target_index level_index entity_list itertools.chain.from_iterable entity_list else for i in range level_index target_index entity_list set entity.get_parent for entity in entity_list return list entity_list
def new_feed_id entry cache {} try s entry['title'] + entry['link'] except KeyError msg 'Requiredkeymissing %r'raise BogusEntry msg % entry hashval hash s sign 'A' if 0 < hashval else 'B' _id entry['state'].upper + 'F' + str hashval + sign .zfill 21 return _id
def lesk context_sentence ambiguous_word pos None synsets None context set context_sentence if synsets is None synsets wordnet.synsets ambiguous_word if pos synsets [ss for ss in synsets if str ss.pos pos ]if not synsets return None _ sense max len context.intersection ss.definition .split ss for ss in synsets return sense
def elgamal_private_key digit 10 seed None randrange _randrange seed p nextprime 2 ** digit return p primitive_root p randrange 2 p
def p_constant t pass
def calendar request calendar_slug template 'schedule/calendar.html' calendar get_object_or_404 Calendar slug calendar_slug return render_to_response template {'calendar' calendar} context_instance RequestContext request
def truncate_minute dt measure return asminute truncate_second dt measure * 60
def flagsplit s if s[0] ! ' ' or s[ -1 ] ! ' ' raise ValueError "Passeds'%s'isnotaflaglist" % s return imapsplit s[1 -1 ]
def resolve_output_type context inputs formal_output selected_input inputs[select_array_wrapper inputs ]args selected_input formal_output sig context.resolve_function_type '__array_wrap__' args {} if sig is None if selected_input.array_priority types.Array.array_priority return formal_outputraise errors.TypingError '__array_wrap__failedfor%s' % args return sig.return_type
def get_object_or_404 klass *args **kwargs queryset _get_queryset klass try return queryset.get *args **kwargs except queryset.model.DoesNotExist raise Http404 'No%smatchesthegivenquery.' % queryset.model._meta.object_name
def driver_initiator_data_get context initiator namespace return IMPL.driver_initiator_data_get context initiator namespace
def test_config _ip.magic 'config'
def _dict_to_stanza key stanza ret ''for skey in stanza if stanza[skey] is True stanza[skey] ''ret + '{0}{1}\n'.format skey stanza[skey] return '{0}{{\n{1}}}'.format key ret
def _unescape_node node unescaped []seq u''for i char in enumerate node if char u'\\' seq node[i i + 3 ]if seq not in JID_ESCAPE_SEQUENCES seq u''if seq if len seq 3 unescaped.append JID_UNESCAPE_TRANSFORMATIONS.get seq char seq seq[1 ]else unescaped.append char unescaped u''.join unescaped return unescaped
def rsh data points None data ma.array data copy False if points is None points dataelse points np.array points copy False ndmin 1 if data.ndim ! 1 raise AttributeError 'Theinputarrayshouldbe1Donly!' n data.count r idealfourths data axis None h 1.2 * r[ -1 ] - r[0] / n ** 1.0 / 5 nhi data[ None] < points[None ] + h .sum 0 nlo data[ None] < points[None ] - h .sum 0 return nhi - nlo / 2.0 * n * h
def mplskip cls @classmethoddef setUpClass cls try import matplotlib as mplmpl.use 'Agg' warn False except ImportError import noseraise nose.SkipTest 'matplotlibnotinstalled' cls.setUpClass setUpClassreturn cls
@register.filter is_safe False def unlocalize value return force_text value
def entropy image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._entropy image selem out out mask mask shift_x shift_x shift_y shift_y out_dtype np.double
def fullmodname path comparepath os.path.normcase path longest ''for dir in sys.path dir os.path.normcase dir if comparepath.startswith dir and comparepath[len dir ] os.sep if len dir > len longest longest dirif longest base path[ len longest + 1 ]else base path drive base os.path.splitdrive base base base.replace os.sep '.' if os.altsep base base.replace os.altsep '.' filename ext os.path.splitext base return filename.lstrip '.'
def capability_removed name image None restart False ret {'name' name 'result' True 'comment' '' 'changes' {}}old __salt__['dism.installed_capabilities'] if name not in old ret['comment'] 'Thecapability{0}isalreadyremoved'.format name return retif __opts__['test'] ret['changes']['capability'] '{0}willberemoved'.format name ret['result'] Nonereturn retstatus __salt__['dism.remove_capability'] name image restart if status['retcode'] not in [0 1641 3010] ret['comment'] 'Failedtoremove{0} {1}'.format name status['stdout'] ret['result'] Falsenew __salt__['dism.installed_capabilities'] changes salt.utils.compare_lists old new if changes ret['comment'] 'Removed{0}'.format name ret['changes'] statusret['changes']['capability'] changesreturn ret
def taggedsents_to_conll sentences for sentence in sentences for input_str in taggedsent_to_conll sentence yield input_str yield '\n\n'
def next_char input_iter for ch in input_iter if ch ! '\\' yield ch False continuech input_iter.next representative ESCAPE_MAPPINGS.get ch ch if representative is None continue yield representative True
def threaded_factory func use_add from sympy.core import sympifyfrom sympy.matrices import MatrixBase@wraps func def threaded_func expr *args **kwargs if isinstance expr MatrixBase return expr.applyfunc lambda f func f *args **kwargs elif iterable expr try return expr.__class__ [func f *args **kwargs for f in expr] except TypeError return exprelse expr sympify expr if use_add and expr.is_Add return expr.__class__ *[func f *args **kwargs for f in expr.args] elif expr.is_Relational return expr.__class__ func expr.lhs *args **kwargs func expr.rhs *args **kwargs else return func expr *args **kwargs return threaded_func
def a2idx j n None if type j is not int try j j.__index__ except AttributeError raise IndexError 'Invalidindexa[%r]' % j if n is not None if j < 0 j + nif not j > 0 and j < n raise IndexError 'Indexoutofrange a[%s]' % j return int j
def time_format value format_string tf TimeFormat value return tf.format format_string
def parse_commands module for cmd in module.params['commands'] if isinstance cmd basestring cmd dict command cmd output None elif 'command' not in cmd module.fail_json msg 'commandkeywordargumentisrequired' elif cmd.get 'output' not in [None 'text' 'json'] module.fail_json msg 'invalidoutputspecifiedforcommand' elif not set cmd.keys .issubset VALID_KEYS module.fail_json msg 'unknownkeywordspecified' yield cmd
def populate_entry_fields entry parser config entry[u'series_parser'] copy parser entry[u'series_name'] parser.nameif u'quality' in entry and entry[u'quality'] ! parser.quality log.verbose u'Founddifferentqualityfor%s.Was%s overridingwith%s.' % entry[u'title'] entry[u'quality'] parser.quality entry[u'quality'] parser.qualityentry[u'proper'] parser.properentry[u'proper_count'] parser.proper_countentry[u'release_group'] parser.groupif parser.id_type u'ep' entry[u'series_season'] parser.seasonentry[u'series_episode'] parser.episodeelif parser.id_type u'date' entry[u'series_date'] parser.identry[u'series_season'] parser.id.yearelse entry[u'series_season'] time.gmtime .tm_yearentry[u'series_episodes'] parser.episodesentry[u'series_id'] parser.pack_identifierentry[u'series_id_type'] parser.id_typeif config if u'path' in config log.debug u'setting%scustompathto%s' entry[u'title'] config.get u'path' config.setdefault u'set' {} .update path config[u'path'] if u'set' in config set plugin.get_plugin_by_name u'set' set.instance.modify entry config.get u'set'
def getSplitLineBeforeBracketSemicolon line bracketSemicolonIndex min line.find ';' line.find ' ' if bracketSemicolonIndex < 0 return line.split return line[ bracketSemicolonIndex].split
def render_price_property request item priceful property_name 'price' options PriceDisplayOptions.from_context {'request' request} if options.hide_prices return ''new_priceful convert_taxness request item priceful options.include_taxes price_value getattr new_priceful property_name return money price_value
def mongo_db registry xml_parent data mongodb XML.SubElement xml_parent 'org.jenkinsci.plugins.mongodb.MongoBuildWrapper' mongodb.set 'plugin' 'mongodb' mapping [ 'name' 'mongodbName' None 'port' 'port' '' 'data-directory' 'dbpath' '' 'startup-params' 'parameters' '' 'start-timeout' 'startTimeout' 0 ]convert_mapping_to_xml mongodb data mapping fail_required True
def get_all_distribution_names url None if url is None url DEFAULT_INDEXclient ServerProxy url timeout 3.0 return client.list_packages
def _legalize_stage path replacements length extension fragment path sanitize_path path replacements if not fragment path bytestring_path path path + extension.lower pre_truncate_path pathpath truncate_path path length return path path ! pre_truncate_path
def default try conn get_connection if conn.session log.warning 'configuringnewdefaultconnectionforcqlenginewhenonewasalreadyset' except passconn register_connection 'default' hosts None default True conn.setup log.debug 'cqlengineconnectioninitializedwithdefaultsessiontolocalhost'
def for_orders orders name 'order' def decorator impl @functools.wraps impl def test_func self *args **kw for order in orders try kw[name] orderimpl self *args **kw except Exception print name 'is' order raisereturn test_funcreturn decorator
def load_exception_handler path exc_info log.warning LOAD_FAILURE_ERROR % path exc_info exc_info
def delete_tile filename coord db _connect filename db.text_factory bytestile_row 2 ** coord.zoom - 1 - coord.row q 'DELETEFROMtilesWHEREzoom_level ?ANDtile_column ?ANDtile_row ?'db.execute q coord.zoom coord.column tile_row
def getTransformedFillOutline elementNode loop yAxisPointingUpward fillOutlineLoops Noneif getStyleValue 'none' elementNode 'fill' .lower 'none' fillOutlineLoops intercircle.getAroundsFromLoop loop getStrokeRadius elementNode else fillOutlineLoops [loop]return getChainMatrixSVGIfNecessary elementNode yAxisPointingUpward .getTransformedPaths fillOutlineLoops
def localize value use_l10n None if isinstance value str return valueelif isinstance value bool return mark_safe str value elif isinstance value decimal.Decimal float int return number_format value use_l10n use_l10n elif isinstance value datetime.datetime return date_format value 'DATETIME_FORMAT' use_l10n use_l10n elif isinstance value datetime.date return date_format value use_l10n use_l10n elif isinstance value datetime.time return time_format value 'TIME_FORMAT' use_l10n use_l10n return value
def test_concat tempdir _TempDir raw read_raw_fif test_fif_fname raw.crop 0 2.0 test_name op.join tempdir 'test_raw.fif' raw.save test_name _test_concat partial read_raw_fif test_name
def get_cache_with_key keyfunc cache_name None def decorator func @wraps func def func_with_caching *args **kwargs key keyfunc *args **kwargs val cache_get key cache_name cache_name if val is not None return val[0]raise NotFoundInCache return func_with_cachingreturn decorator
def get_common_replies locale settings.WIKI_DEFAULT_LANGUAGE replies []try default_doc Document.objects.get slug REPLIES_DOCUMENT_SLUG locale settings.WIKI_DEFAULT_LANGUAGE except Document.DoesNotExist return repliesif locale ! default_doc.locale translated_doc default_doc.translated_to locale if translated_doc and translated_doc.current_revision doc translated_docelse doc default_docelse doc default_docpq PyQuery doc.html try current_node pq 'h1' [0]except IndexError return repliescurrent_category Nonecurrent_response Nonewhile current_node is not None if current_node.tag 'h1' current_category {'title' current_node.text 'responses' []}replies.append current_category elif current_node.tag 'h2' current_response {'title' current_node.text 'response' ''}current_category['responses'].append current_response elif current_node.tag 'p' text current_node.text_content .strip if text and current_response current_response['response'] textcurrent_node current_node.getnext return replies
def adjoin space *lists **kwargs strlen kwargs.pop 'strlen' len justfunc kwargs.pop 'justfunc' justify out_lines []newLists []lengths [ max map strlen x + space for x in lists[ -1 ]]lengths.append max map len lists[ -1 ] maxLen max map len lists for i lst in enumerate lists nl justfunc lst lengths[i] mode 'left' nl.extend [ '' * lengths[i] ] * maxLen - len lst newLists.append nl toJoin zip *newLists for lines in toJoin out_lines.append _join_unicode lines return _join_unicode out_lines sep '\n'
def start_statsd path if django_statsd django_statsd.start path
def dmp_lift f u K if not K.is_Algebraic raise DomainError 'computationcanbedoneonlyinanalgebraicdomain' F monoms polys dmp_to_dict f u [] [] for monom coeff in F.items if not coeff.is_ground monoms.append monom perms variations [ -1 1] len monoms repetition True for perm in perms G dict F for sign monom in zip perm monoms if sign -1 G[monom] - G[monom] polys.append dmp_from_dict G u K return dmp_convert dmp_expand polys u K u K K.dom
def crossproduct ss row None level 0 if row is None row []if len ss > 1 return reduce operator.add [crossproduct ss[1 ] row + [i] level + 1 for i in ss[0]] else return [ row + [i] for i in ss[0]]
def register_group group _groups.append group return group
def _GetTimestamps time_offset 0 if options.options.use_utc else time.timezone cur_day datetime.datetime.now .replace hour 0 minute 0 second 0 microsecond 0 utc_cur_day LocalDatetimeToUTCDatetime cur_day if options.options.start_timestamp start_timestamp options.options.start_timestampelif options.options.start_date utc_dt ParseIso8601DatetimeToUTCDatetime options.options.start_date start_timestamp UTCDatetimeToTimestamp utc_dt + time_offset else start_timestamp UTCDatetimeToTimestamp utc_cur_day if options.options.end_timestamp end_timestamp options.options.end_timestampelif options.options.end_date utc_dt ParseIso8601DatetimeToUTCDatetime options.options.end_date end_timestamp UTCDatetimeToTimestamp utc_dt + time_offset else end_timestamp UTCDatetimeToTimestamp utc_cur_day + SECONDS_PER_DAY return start_timestamp end_timestamp
def isotime at None subsecond False if not at at timeutils.utcnow st at.strftime _ISO8601_TIME_FORMAT if not subsecond else _ISO8601_TIME_FORMAT_SUBSECOND tz at.tzinfo.tzname None if at.tzinfo else 'UTC' st + 'Z' if tz 'UTC' else tz return st
def _list_linodes full False nodes _query 'linode' 'list' ['DATA']ips get_ips ret {}for node in nodes this_node {}linode_id str node['LINODEID'] this_node['id'] linode_idthis_node['image'] node['DISTRIBUTIONVENDOR']this_node['name'] node['LABEL']this_node['size'] node['TOTALRAM']state int node['STATUS'] this_node['state'] _get_status_descr_by_id state for key val in six.iteritems ips if key linode_id this_node['private_ips'] val['private_ips']this_node['public_ips'] val['public_ips']if full this_node['extra'] noderet[node['LABEL']] this_nodereturn ret
def publish long_description make_long_description if long_description ! read RST_DESCRIPTION_PATH print 'Descriptionfilenotup-to-date %s\nRunthefollowingcommandandcommitthechanges--\n\npythonsetup.py%s\n' % RST_DESCRIPTION_PATH PREP_COMMAND sys.exit print 'Descriptionup-to-date %s' % RST_DESCRIPTION_PATH answer raw_input 'AreyousureyouwanttopublishtoPyPI yes/no ?' if answer ! 'yes' exit 'Aborted nothingpublished' os.system 'pythonsetup.pysdistupload'
def pycryptodome_filename dir_comps filename if dir_comps[0] ! 'Cryptodome' raise ValueError "Onlyavailableformodulesunder'Cryptodome'" dir_comps list dir_comps[1 ] + [filename] util_lib _ os.path.split os.path.abspath __file__ root_lib os.path.join util_lib '..' return os.path.join root_lib *dir_comps
def bilinear e1 e2 W V1 None V2 None b None flags [ V1 is None V2 is None b is None ]if any flags if not all flags raise ValueError 'Allcoefficientsandbiasforbilinear mustbeNone ifatleastoneofthemisNone.' return BilinearFunction e1 e2 W else return BilinearFunction e1 e2 W V1 V2 b
def test_ci_to_errsize cis [[0.5 0.5] [1.25 1.5]]heights [1 1.5]actual_errsize np.array [[0.5 1] [0.25 0]] test_errsize utils.ci_to_errsize cis heights npt.assert_array_equal actual_errsize test_errsize
def get_pull_request project num github_api 3 if github_api 2 url 'http //github.com/api/v2/json/pulls/{project}/{num}'.format project project num num elif github_api 3 url 'https //api.github.com/repos/{project}/pulls/{num}'.format project project num num response requests.get url response.raise_for_status if github_api 2 return json.loads response.text ['pull']return json.loads response.text
def iterator_content_items ids None channel 'khan' language 'en' **kwargs if ids items Item.select .where Item.id.in_ ids .dicts .iterator else items Item.select .dicts .iterator mapped_items itertools.imap unparse_model_data items updated_mapped_items update_content_availability mapped_items channel channel language language for path update in updated_mapped_items yield path update
def convert_va mpl_va if mpl_va in VA_MAP return VA_MAP[mpl_va]else return None
def with_special_errors func def wrapper *a **kw old_filters list getattr warnings 'filters' [] old_errprint sc.errprint 1 warnings.filterwarnings 'error' category sc.SpecialFunctionWarning try return func *a **kw finally sc.errprint old_errprint setattr warnings 'filters' old_filters wrapper.__name__ func.__name__wrapper.__doc__ func.__doc__return wrapper
def _check_file fname overwrite if op.isfile fname and not overwrite raise IOError 'File%sexists use--overwritetooverwriteit' % fname
def test_lagrange Chart datas chart Chart interpolate 'lagrange' chart make_data chart datas assert chart.render
@paralleldef logs sudo 'tail-f{logdir}*/var/log/nginx/*.log'.format logdir LOG_DIR
def writerec outrec handle fields GAF20FIELDS outstr ''for field in fields[ -1 ] if isinstance outrec[field] list for subfield in outrec[field] outstr + subfield + '|' outstr outstr[ -1 ] + ' DCTB ' else outstr + outrec[field] + ' DCTB ' outstr + outrec[fields[ -1 ]] + '\n' handle.write '%s' % outstr
def _create_start_end levels rads levels[0].copy for level in levels[1 ] rads rads * level rads * 2 * np.pi end rads.cumsum start shift_series end return start end
def tree_graph data attrs _attrs graph nx.DiGraph id_ attrs['id']children attrs['children']def add_children parent children_ for data in children_ child data[id_]graph.add_edge parent child grandchildren data.get children [] if grandchildren add_children child grandchildren nodedata dict make_str k v for k v in data.items if k ! id_ and k ! children graph.add_node child **nodedata root data[id_]children_ data.get children [] nodedata dict make_str k v for k v in data.items if k ! id_ and k ! children graph.add_node root **nodedata add_children root children_ return graph
def read_and_call_until uhandle method **keywds nlines 0while True line safe_readline uhandle if not _fails_conditions * line **keywds uhandle.saveline line breakmethod line nlines nlines + 1 return nlines
def _get_fake_enrollment student_id course_id for enrollment in _ENROLLMENTS if student_id enrollment['student'] and course_id enrollment['course']['course_id'] return enrollment
def floating_ip_deallocate context address return IMPL.floating_ip_deallocate context address
@ratelimit @requires_auth 'home' def home_endpoint response {}if config.INFO info {}info['server'] 'Eve'info['version'] eve.__version__if config.API_VERSION info['api_version'] config.API_VERSIONresponse[config.INFO] infoif config.HATEOAS links []for resource in config.DOMAIN.keys internal config.DOMAIN[resource]['internal_resource']if not resource.endswith config.VERSIONS if not bool internal links.append {'href' '%s' % config.URLS[resource] 'title' '%s' % config.DOMAIN[resource]['resource_title'] } if config.SCHEMA_ENDPOINT is not None links.append {'href' '%s' % config.SCHEMA_ENDPOINT 'title' '%s' % config.SCHEMA_ENDPOINT } response[config.LINKS] {'child' links}return send_response None response else return send_response None response
def find_indices condition res np.nonzero np.ravel condition return res
def unescape s assert isinstance s basestring s s.replace ' DCTB ' ' ' s s.replace '\\ ' ' ' s s.replace '\\n' '\n' s s.replace '\\\\' '\\' return s
def _pecan_generator_wrapper func *args **kwargs kwargs.setdefault 'content_type' 'application/json' kwargs.setdefault 'template' 'json' return _composed _protect_original_resources db_api.retry_db_errors func *args **kwargs
def _read_dig_point_struct fid tag shape rlims return dict kind int np.fromstring fid.read 4 dtype '>i4' ident int np.fromstring fid.read 4 dtype '>i4' r np.fromstring fid.read 12 dtype '>f4' coord_frame FIFF.FIFFV_COORD_UNKNOWN
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def regularized_lsq_with_qr m n R QTb perm diag copy_R True if copy_R R R.copy v QTb.copy givens_elimination R v diag[perm] abs_diag_R np.abs np.diag R threshold EPS * max m n * np.max abs_diag_R nns np.nonzero abs_diag_R > threshold R R[np.ix_ nns nns ]v v[nns]x np.zeros n x[perm[nns]] solve_triangular R v return x
def profile func stream None def wrapper *args **kwargs prof LineProfiler val prof func *args **kwargs show_results prof stream stream return valreturn wrapper
def returners opts functions whitelist None context None return LazyLoader _module_dirs opts 'returners' 'returner' opts tag 'returner' whitelist whitelist pack {'__salt__' functions '__context__' context}
def document_exists index id doc_type '_all' hosts None profile None es _get_instance hosts profile try if es.exists index index id id doc_type doc_type return Trueelse return Falseexcept elasticsearch.exceptions.NotFoundError return Noneexcept elasticsearch.exceptions.ConnectionError return Nonereturn None
def validate_bucket_name name label '[a-z0-9]+ ? [a-z0-9\\-]*[a-z0-9] ?'validate_name re.compile '^' + label + ' ? \\.' + label + ' *$' is_ip_address re.compile '^[0-9]+ ? \\.[0-9]+ {3}$' return len name > 3 and len name < 63 and bool validate_name.match name and not bool is_ip_address.match name
def csort objs key idxs dict obj i for i obj in enumerate objs return sorted objs key lambda obj key obj idxs[obj]
def test_feature_has_repr feature Feature.from_string FEATURE1 expect repr feature .to.equal '<Feature "Rentmovies">'
def ipython_only option if __IPYTHON__ return optionargname extract_option_object option .namedef d f @wraps f def _ *args **kwargs kwargs[argname] Nonereturn f *args **kwargs return _return d
def test_dict_aliasing ad _AliasDict {'bar' False 'biz' True 'baz' False} aliases {'foo' ['bar' 'biz' 'baz']} eq_ ad['bar'] False eq_ ad['biz'] True eq_ ad['baz'] False ad['foo'] Trueeq_ ad['bar'] True eq_ ad['biz'] True eq_ ad['baz'] True
def _strify_spec spec buff None indent '' if buff is None buff StringIO for c in spec.constants buff.write '%s%s%s %s\n' % indent c.type c.name c.val_text for type_ name in zip spec.types spec.names buff.write '%s%s%s\n' % indent type_ name base_type base_msg_type type_ if not base_type in BUILTIN_TYPES subspec get_registered base_type _strify_spec subspec buff indent + '' return buff.getvalue
def _psequence_model klass category u'set' if issubclass klass CheckedPSet else u'list' record {u'category' category u'type' sorted fqpn cls for cls in klass._checked_types }further_classes set klass._checked_types return record further_classes
def resize_images X height_factor width_factor dim_ordering if dim_ordering 'th' output repeat_elements X height_factor axis 2 output repeat_elements output width_factor axis 3 return outputelif dim_ordering 'tf' output repeat_elements X height_factor axis 1 output repeat_elements output width_factor axis 2 return outputelse raise ValueError 'Invaliddim_ordering ' dim_ordering
def is_token_subtype ttype other return ttype in other
@environmentfilterdef do_attr environment obj name try name str name except UnicodeError passelse try value getattr obj name except AttributeError passelse if environment.sandboxed and not environment.is_safe_attribute obj name value return environment.unsafe_undefined obj name return valuereturn environment.undefined obj obj name name
def _set_cleanup_test data data[2] True
def _ssh_ls ssh_bin address ec2_key_pair_file path keyfile None sudo False cmd_args ['find' '-L' path '-type' 'f']if sudo cmd_args ['sudo'] + cmd_args out to_string _check_output *_ssh_run_with_recursion ssh_bin address ec2_key_pair_file keyfile cmd_args if 'Nosuchfileordirectory' in out raise IOError 'Nosuchfileordirectory %s' % path return out.split '\n'
def validate_trigger_payload trigger_type_ref payload if not trigger_type_ref return Noneis_system_trigger trigger_type_ref in SYSTEM_TRIGGER_TYPES if is_system_trigger payload_schema SYSTEM_TRIGGER_TYPES[trigger_type_ref]['payload_schema']else trigger_type_db triggers.get_trigger_type_db trigger_type_ref if not trigger_type_db return Nonepayload_schema getattr trigger_type_db 'payload_schema' {} if not payload_schema return Noneif not is_system_trigger and not cfg.CONF.system.validate_trigger_payload LOG.debug 'Gotnon-systemtrigger"%s" buttriggerpayloadvalidationfornon-systemtriggersisdisabled skippingvalidation.' % trigger_type_ref return Nonecleaned util_schema.validate instance payload schema payload_schema cls util_schema.CustomValidator use_default True allow_default_none True return cleaned
def get_icmp_types permanent True cmd '--get-icmptypes'if permanent cmd + '--permanent'return __firewall_cmd cmd .split
def _simple_init self *args **kw type self .__base__.__init__ self *args **kw
def ops i o ops set variables orphans variables_and_orphans i o for r in variables if r not in i and r not in orphans if r.owner is not None ops.add r.owner return ops
def container_convergence results limit convergence_results [r for r in results if r['metric']['type'] 'wallclock' and r['operation']['type'] 'create-container' ]num_convergences len convergence_results if num_convergences > 0 convergences_within_limit [r for r in convergence_results if r['value'] < limit ]return float len convergences_within_limit / num_convergences return None
def test_main_module cmd [sys.executable '-m' 'bokeh' '--version']v subprocess.check_output cmd stderr subprocess.STDOUT .decode .strip assert v bokeh.__version__
def stream_copy source destination chunk_size 512 * 1024 br 0while True chunk source.read chunk_size destination.write chunk br + len chunk if len chunk < chunk_size breakreturn br
def task_status request task_id result AsyncResult task_id state retval result.state result.result response_data {u'id' task_id u'status' state u'result' retval}if state in states.EXCEPTION_STATES traceback result.tracebackresponse_data.update {u'result' safe_repr retval u'exc' get_full_cls_name retval.__class__ u'traceback' traceback} return JsonResponse {u'task' response_data}
def waitAndCloseHandle processHandle WaitForSingleObject processHandle INFINITE CloseHandle processHandle
def _GetWinLinkRuleNameSuffix embed_manifest return '_embed' if embed_manifest else ''
def next_frame_size socket try data read_exactly socket 8 except SocketError return 0 _ actual struct.unpack '>BxxxL' data return actual
def make_poisoning_report_mac poisoner_canary poisoner_name poisoner_id cache_policy source route_name mac_key g.secrets['cache_poisoning']mac_data poisoner_canary poisoner_name str poisoner_id cache_policy source route_name return hmac.new mac_key '|'.join mac_data hashlib.sha1 .hexdigest
def get_full_cls_name cls return '.'.join [cls.__module__ cls.__name__]
def _dmi_cast key val clean True if clean and not _dmi_isclean key val returnelif not re.match 'serial|part|asset|product' key flags re.IGNORECASE if ' ' in val val [el.strip for el in val.split ' ' ]else try val int val except passreturn val
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def link src dst if platform.system u'Windows' if ctypes.windll.kernel32.CreateHardLinkW ctypes.c_wchar_p unicode dst ctypes.c_wchar_p unicode src None 0 raise ctypes.WinError else ek os.link src dst
def format_image_member_notification image_member return {'image_id' image_member.image_id 'member_id' image_member.member_id 'status' image_member.status 'created_at' timeutils.isotime image_member.created_at 'updated_at' timeutils.isotime image_member.updated_at 'deleted' False 'deleted_at' None}
def manualintegrate f var return _manualintegrate integral_steps f var
def splittype url global _typeprogif _typeprog is None _typeprog re.compile '^ [^/ ]+ ' match _typeprog.match url if match scheme match.group 1 return scheme.lower url[ len scheme + 1 ] return None url
def fname_presuffix fname prefix u'' suffix u'' newpath None use_ext True pth fname ext split_filename fname if not use_ext ext u''if newpath and isdefined newpath pth os.path.abspath newpath return os.path.join pth prefix + fname + suffix + ext
def do_statement source start start pass_white source start if not start < len source return None start if any startswith_keyword source[start ] e for e in {'case' 'default'} return None start rest source[start ]for key meth in KEYWORD_METHODS.iteritems if rest.startswith key if len key len rest or rest[len key ] not in IDENTIFIER_PART return meth source start if rest[0] '{' return do_block source start cand parse_identifier source start False if cand is not None label cand_start candcand_start pass_white source cand_start if source[cand_start] ' ' return do_label source start return do_expression source start
def translation_project_dir_exists language project if project.get_treestyle 'gnu' if language.code 'templates' for dirpath_ dirnames filenames in os.walk project.get_real_path for filename in filenames if project.file_belongs_to_project filename match_templates True and match_template_filename project filename return Trueelse for dirpath_ dirnames filenames in os.walk project.get_real_path for filename in filenames filename_matches project.file_belongs_to_project filename match_templates False and direct_language_match_filename project.lang_mapper.get_upstream_code language.code filename if filename_matches return Trueelse try dirpath_ dirnames filename os.walk project.get_real_path .next lang_code project.lang_mapper.get_upstream_code language.code if lang_code in dirnames return Trueexcept StopIteration passreturn False
def pil_resize maxwidth path_in path_out None path_out path_out or temp_file_for path_in from PIL import Imagelog.debug u'artresizer PILresizing{0}to{1}'.format util.displayable_path path_in util.displayable_path path_out try im Image.open util.syspath path_in size maxwidth maxwidth im.thumbnail size Image.ANTIALIAS im.save path_out return path_outexcept IOError log.error u"PILcannotcreatethumbnailfor'{0}'".format util.displayable_path path_in return path_in
def get_java_version o e exit_status qiime_system_call 'java-version' if exit_status ! 0 return Nonee e.strip .splitlines version_line e[0]if not version_line.startswith 'javaversion' return Noneelse return version_line.split [ -1 ].strip '"'
def group seq multiple True if not seq return [] current groups [seq[0]] [] for elem in seq[1 ] if elem current[ -1 ] current.append elem else groups.append current current [elem]groups.append current if multiple return groupsfor i current in enumerate groups groups[i] current[0] len current return groups
def get_mount_targets filesystemid None mounttargetid None keyid None key None profile None region None **kwargs result Noneclient _get_conn key key keyid keyid profile profile region region if filesystemid response client.describe_mount_targets FileSystemId filesystemid result response['MountTargets']while 'NextMarker' in response response client.describe_mount_targets FileSystemId filesystemid Marker response['NextMarker'] result.extend response['MountTargets'] elif mounttargetid response client.describe_mount_targets MountTargetId mounttargetid result response['MountTargets']return result
def partition_suite_by_case suite groups []suite_class type suite for test_type test_group in itertools.groupby suite type if issubclass test_type unittest.TestCase groups.append suite_class test_group else for item in test_group groups.extend partition_suite_by_case item return groups
def _estimate_gaussian_covariances_diag resp X nk means reg_covar avg_X2 np.dot resp.T X * X / nk[ np.newaxis] avg_means2 means ** 2 avg_X_means means * np.dot resp.T X / nk[ np.newaxis] return avg_X2 - 2 * avg_X_means + avg_means2 + reg_covar
def fresh_output_manager_inst global managerif manager.is_alive manager.in_queue.put POISON_PILL manager.join manager OutputManager manager.start return manager
def abort global __SCHEDif __SCHED logging.debug 'Terminatingscheduler' __SCHED.running False
def getCircleNodesFromLoop loop radius thresholdRatio 0.9 radius abs radius points getPointsFromLoop loop radius thresholdRatio return getCircleNodesFromPoints points radius
def get_save_dir savepaths []if 'APPDATA' in os.environ savepaths + [os.path.join os.environ['APPDATA'] '.minecraft' 'saves' ]if 'HOME' in os.environ savepaths + [os.path.join os.environ['HOME'] 'Library' 'ApplicationSupport' 'minecraft' 'saves' ]savepaths + [os.path.join os.environ['HOME'] '.minecraft' 'saves' ]for path in savepaths if os.path.exists path return path
def _dispatch table action user obj if action in table result table[action] debug '%suser%s object%s action%s' 'ALLOWED' if result else 'DENIED' user obj.location.to_deprecated_string if isinstance obj XBlock else str obj action return resultraise ValueError u"Unknownactionforobjecttype'{0}' '{1}'".format type obj action
def is_iso_time iso try iso_to_datetime_tuple iso return Trueexcept iso8601.ParseError return False
def soft_unicode s if not isinstance s text_type s text_type s return s
def getWiddershinsAverageByVector3 centerMinusBeginComplex endMinusCenterComplex centerMinusBeginWiddershins Vector3 - centerMinusBeginComplex.imag centerMinusBeginComplex.real endMinusCenterWiddershins Vector3 - endMinusCenterComplex.imag endMinusCenterComplex.real return centerMinusBeginWiddershins + endMinusCenterWiddershins .getNormalized
def degap_fasta_aln seqs for label seq in seqs yield DNASequence seq id label .degap
def is_attr_private attrname regex re.compile '^_{2 }.*[^_]+_?$' return regex.match attrname
def JavaSupported if appcfg_java tools_java_dir os.path.join os.path.dirname appcfg_java.__file__ 'java' return os.path.isdir tools_java_dir else return False
def _invertx p x p1 poly_from_expr p x [0]n degree p1 a [ c * x ** n - i for i c in p1.terms ]return Add *a
@deprecated 'useargs.pop 0 ' def pop_arg args_list expected_size_after None msg 'Missingargument' try value args_list.pop 0 except IndexError raise BadCommandUsage msg if expected_size_after is not None and len args_list > expected_size_after raise BadCommandUsage 'toomanyarguments' return value
def _build_time time kwargs tz kwargs.pop 'tz' 'UTC' if time if kwargs raise ValueError 'Cannotpasskwargsandatime' else return ensure_utc time tz elif not kwargs raise ValueError 'Mustpassatimeorkwargs' else return datetime.time **kwargs
def validate_exists args key default None if key in args if len args[key] 0 raise ArgumentError _ 'Argument% key svalue% value sistooshort.' % {'key' key 'value' args[key]} if not ARGUMENT_PATTERN.match args[key] raise ArgumentError _ 'Argument% key svalue% value scontainsinvalidcharacters.' % {'key' key 'value' args[key]} if args[key][0] '-' raise ArgumentError _ 'Argument% key svalue% value sstartswithahyphen.' % {'key' key 'value' args[key]} return args[key]elif default is not None return defaultelse raise ArgumentError _ 'Argument%sisrequired.' % key
def is_byte_range_valid start stop length if start is None ! stop is None return Falseelif start is None return length is None or length > 0 elif length is None return 0 < start < stop elif start > stop return Falsereturn 0 < start < length
def _find_permutation a b t np.argsort a u np.argsort b u_ _inverse_permutation u return t[u_]
def get_args parser cli.build_arg_parser parser.add_argument '-v' '--vm_uuid' required False action 'store' help 'Virtualmachineuuid' parser.add_argument '-r' '--vm_user' required False action 'store' help 'virtualmachineusername' parser.add_argument '-w' '--vm_pwd' required False action 'store' help 'virtualmachinepassword' parser.add_argument '-l' '--path_inside_vm' required False action 'store' help 'PathinsideVMforupload' parser.add_argument '-f' '--upload_file' required False action 'store' help 'Pathofthefiletobeuploadedfromhost' args parser.parse_args cli.prompt_for_password args return args
def _changed_packages_activity_query import ckan.model as modelq model.Session.query model.Activity q q.filter model.Activity.activity_type.endswith 'package' return q
def getTransferredNestedRings insides loop transferredSurroundings []for insideIndex in xrange len insides - 1 -1 -1 insideSurrounding insides[insideIndex]if isPathInsideLoop loop insideSurrounding.boundary transferredSurroundings.append insideSurrounding del insides[insideIndex]return transferredSurroundings
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def test_ros_sk_estimator check_estimator RandomOverSampler
def _get_xqueue_callback_url_prefix xmodule_instance_args return xmodule_instance_args.get 'xqueue_callback_url_prefix' '' if xmodule_instance_args is not None else ''
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def load_package package global _loaded_packages_init if VERBOSE print 'Loadpackage' package if package in _loaded_packages if VERBOSE print 'Package%sisalreadyloaded' % package return_loaded_packages.append package specs failed get_pkg_msg_specs package if VERBOSE print 'Packagecontainsthefollowingmessages %s' % specs for key spec in specs register key spec register package + roslib.names.PRN_SEPARATOR + key spec
def create_eventloop inputhook None recognize_win32_paste True if is_windows from prompt_toolkit.eventloop.win32 import Win32EventLoop as Loopreturn Loop inputhook inputhook recognize_paste recognize_win32_paste else from prompt_toolkit.eventloop.posix import PosixEventLoop as Loopreturn Loop inputhook inputhook
def _callAppFunction function try function except log.err None u'Unexpectedexceptionfrom%s' % fullyQualifiedName function
def parse_args parser argparse.ArgumentParser parser.add_argument '--profile-tool' metavar 'TOOL' action 'store' choices ['kcachegrind' 'snakeviz' 'gprof2dot' 'none'] default 'snakeviz' help 'Thetooltousetoviewtheprofilingdata' parser.add_argument '--profile-file' metavar 'FILE' action 'store' help 'Thefilenametousewith--profile-tool none' return parser.parse_known_args
def _encode_basestring_ascii s try if isinstance s str and HAS_UTF8.search s is not None s s.decode 'utf-8' except passdef replace match s match.group 0 try return ESCAPE_DCT[s]except KeyError n ord s if n < 65536 return '\\u%04x' % n else n - 65536s1 55296 | n >> 10 & 1023 s2 56320 | n & 1023 return '\\u%04x\\u%04x' % s1 s2 return '"' + str ESCAPE_ASCII.sub replace s + '"'
def fixed_ip_get_by_address_detailed context address return IMPL.fixed_ip_get_by_address_detailed context address
def memcache_get request keys request['key']request_short '\n'.join [truncate k for k in keys] namespace ''if 'name_space' in request namespace request['name_space']if len keys > 1 request_short + '\n'else request_short + ''request_short + ' ns %s ' % truncate namespace return request_short
def addAbridgedSettings abridgedSettings repositoryWriter for abridgedSetting in abridgedSettings repositoryWriter.write '%s\n' % abridgedSetting.__repr__
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def shuffle X y idx np.argsort [random.random for i in range len y ] y np.asarray y X [X[i] for i in idx]y y[idx]return X y
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
@np.deprecate message 'splmakeisdeprecatedinscipy0.19.0 usemake_interp_splineinstead.' def splmake xk yk order 3 kind 'smoothest' conds None yk np.asanyarray yk order int order if order < 0 raise ValueError 'ordermustnotbenegative' if order 0 return xk yk[ -1 ] order elif order 1 return xk yk order try func eval '_find_%s' % kind except raise NotImplementedErrorB _fitpack._bsplmat order xk coefs func xk yk order conds B return xk coefs order
def client_start request socket context CLIENTS[socket.session.session_id] request socket context
def rgb2ypbpr rgb return _convert ypbpr_from_rgb rgb
def get_auth_str user token default_token_generator.make_token user auth '{0} {1}'.format user.username token return base64.b64encode auth
def count_records filename outfile sys.stdout from .biffh import biff_count_recordsbk Book bk.biff2_8_load filename filename logfile outfile biff_count_records bk.mem bk.base bk.stream_len outfile
def signup_verify request uidb36 None token None user authenticate uidb36 uidb36 token token is_active False if user is not None user.is_active Trueuser.save auth_login request user info request _ u'Successfullysignedup' return login_redirect request else error request _ u'Thelinkyouclickedisnolongervalid.' return redirect u'/'
def resolve_nested_documents updates original r {}for field value in updates.items if isinstance value dict orig_value original.setdefault field {} if orig_value is None r[field] valueelse orig_value.update resolve_nested_documents value orig_value r[field] orig_valueelse r[field] valuereturn r
@doctest_depends_on modules 'numpy' 'matplotlib' def plot3d_parametric_surface *args **kwargs args list map sympify args show kwargs.pop 'show' True series []plot_expr check_arguments args 3 2 series [ParametricSurfaceSeries *arg **kwargs for arg in plot_expr]plots Plot *series **kwargs if show plots.show return plots
def escape_triple_quotes text return text.replace u'"""' u'\\"\\"\\"'
def get_auth factory Auth key _auth_registry_key request None request request or webapp2.get_request auth request.registry.get key if not auth auth request.registry[key] factory request return auth
def munge_nose_output_for_doctest out out remove_stack_traces out out simplify_warnings out out remove_timings out return out.strip
def test_tryimport from IPython.core.completerlib import try_importassert try_import 'IPython.'
def requires_version library min_version return np.testing.dec.skipif not check_version library min_version 'Requires%sversion> %s' % library min_version
def flavor_extra_specs_get context flavor_id return IMPL.flavor_extra_specs_get context flavor_id
def MinimumSpanningTree G if not isUndirected G raise ValueError 'MinimumSpanningTree inputisnotundirected' for u in G for v in G[u] if G[u][v] ! G[v][u] raise ValueError 'MinimumSpanningTree asymmetricweights' subtrees UnionFind tree []for W u v in sorted G[u][v] u v for u in G for v in G[u] if subtrees[u] ! subtrees[v] tree.append u v subtrees.union u v return tree
def _is_vdi_a_snapshot vdi_rec is_a_snapshot vdi_rec['is_a_snapshot']image_id vdi_rec['other_config'].get 'image-id' return is_a_snapshot and not image_id
def test_pformat_roundtrip 'Readatablewithemptyvaluesandensurethatcorrespondingentriesaremasked'table '\n'.join ['a b c d' '1 3 1.11 1' '2 2 4.0 ss'] dat ascii.read table out ascii.read dat.pformat assert len dat len out assert dat.colnames out.colnames for c in dat.colnames assert np.all dat[c] out[c]
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def heapify x n len x for i in reversed xrange n // 2 _siftup x i
def get_ability course_id content user return {'editable' check_permissions_by_view user course_id content 'update_thread' if content['type'] 'thread' else 'update_comment' 'can_reply' check_permissions_by_view user course_id content 'create_comment' if content['type'] 'thread' else 'create_sub_comment' 'can_delete' check_permissions_by_view user course_id content 'delete_thread' if content['type'] 'thread' else 'delete_comment' 'can_openclose' check_permissions_by_view user course_id content 'openclose_thread' if content['type'] 'thread' else False 'can_vote' not is_content_authored_by content user and check_permissions_by_view user course_id content 'vote_for_thread' if content['type'] 'thread' else 'vote_for_comment' 'can_report' not is_content_authored_by content user and check_permissions_by_view user course_id content 'flag_abuse_for_thread' if content['type'] 'thread' else 'flag_abuse_for_comment' }
def group_purge context data_dict return _group_or_org_purge context data_dict is_org False
def send_password_reset_notice user if config_value 'SEND_PASSWORD_RESET_NOTICE_EMAIL' send_mail config_value 'EMAIL_SUBJECT_PASSWORD_NOTICE' user.email 'reset_notice' user user
def send_email_for_after_purchase_organizers email buyer_email invoice_id order_url event_name event_organiser send_email to email action TICKET_PURCHASED_ORGANIZER subject MAILS[TICKET_PURCHASED_ORGANIZER]['subject'].format invoice_id invoice_id event_name event_name buyer_email buyer_email html MAILS[TICKET_PURCHASED_ORGANIZER]['message'].format order_url order_url buyer_email buyer_email event_name event_name event_organiser event_organiser
def EMSA_PKCS1_V1_5_ENCODE hash emLen with_hash_parameters True if with_hash_parameters digestAlgo DerSequence [DerObjectId _HASH_OIDS[hash.name] .encode DerNull .encode ] else digestAlgo DerSequence [DerObjectId _HASH_OIDS[hash.name] .encode ] digest DerOctetString hash.digest digestInfo DerSequence [digestAlgo.encode digest.encode ] .encode if emLen < len digestInfo + 11 raise TypeError 'Selectedhashalgorithhasatoolongdigest %dbytes .' % len digest PS bchr 255 * emLen - len digestInfo - 3 return b '\x00\x01' + PS + bchr 0 + digestInfo
def create_bootstrap_script extra_text python_version '' filename __file__if filename.endswith '.pyc' filename filename[ -1 ]f codecs.open filename 'r' encoding 'utf-8' content f.read f.close py_exe 'python%s' % python_version content '#!/usr/bin/env%s\n' % py_exe + '##WARNING Thisfileisgenerated\n' + content return content.replace '##EXTEND##' extra_text
def gray2int g size res 0for i in reversed list range size gi g >> i % 2 if i size - 1 bi gielse bi bi ^ gi res + bi * 2 ** i return res
def setMemoryLimit max_mem return False
def _mark_class_skipped cls reason tests [attr for attr in dir cls if _is_test_method_name attr or _is_test_fixture attr ]for test in tests method getattr cls test if callable method setattr cls test _mark_method_skipped method reason return cls
def _format_time_zone_string time_zone date_time format_string return date_time.astimezone time_zone .strftime format_string
def create_clip_in_selected_slot creator song clip_length None selected_slot song.view.highlighted_clip_slotif creator and selected_slot and not selected_slot.has_clip creator.create selected_slot clip_length song.view.detail_clip selected_slot.clipreturn selected_slot.clip
def get_stackstorm_version if 'dev' in stackstorm_version and stackstorm_version.count '.' 1 version stackstorm_version.replace 'dev' '.0' return versionreturn stackstorm_version
def date_format date None format '%Y-%m-%d' return date_cast date .strftime format
def sort_layer2 W2 print 'Sortingsolargest-normlayer2weightsareplottedatthetop' norms np.square W2 .sum axis 0 idxs [elem[1] for elem in sorted zip - norms range norms.shape[0] ]new W2.copy for i in xrange len idxs new[ i] W2[ idxs[i]]W2 newreturn new
def scenario s3db.configure 'scenario_config' deletable False def prep r if r.interactive and r.component if r.component.name ! 'config' s3.crud.submit_button T 'Assign' s3.crud_labels['DELETE'] T 'Remove' if r.component_name 'site' field db.scenario_site.site_idfield.readable field.writable Truereturn Trues3.prep prepoutput s3_rest_controller rheader s3db.scenario_rheader return output
def database dburl None **params if not dburl and not params dburl os.environ['DATABASE_URL']if dburl params dburl2dict dburl dbn params.pop 'dbn' if dbn in _databases return _databases[dbn] **params else raise UnknownDB dbn
def shape_index image sigma 1 mode 'constant' cval 0 Hxx Hxy Hyy hessian_matrix image sigma sigma mode mode cval cval order 'rc' l1 l2 hessian_matrix_eigvals Hxx Hxy Hyy return 2.0 / np.pi * np.arctan l2 + l1 / l2 - l1
def send_verification_mail request user verification_type verify_url reverse verification_type kwargs {u'uidb36' int_to_base36 user.id u'token' default_token_generator.make_token user } + u'?next ' + next_url request or u'/' context {u'request' request u'user' user u'verify_url' verify_url}subject_template_name u'email/%s_subject.txt' % verification_type subject subject_template subject_template_name context send_mail_template subject u'email/%s' % verification_type settings.DEFAULT_FROM_EMAIL user.email context context
def bucket_lister bucket prefix '' delimiter '' marker '' headers None encoding_type None more_results Truek Nonewhile more_results rs bucket.get_all_keys prefix prefix marker marker delimiter delimiter headers headers encoding_type encoding_type for k in rs yield k if k marker rs.next_marker or k.name if marker and encoding_type 'url' marker unquote_str marker more_results rs.is_truncated
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def _words_for_line trigger before num_words None if num_words is None num_words len split_at_whitespace trigger word_list split_at_whitespace before if len word_list < num_words return before.strip else before_words beforefor i in range -1 - num_words + 1 -1 left before_words.rfind word_list[i] before_words before_words[ left]return before[len before_words ].strip
def _upgrade_from_distribute python_cmd use_sudo _easy_install ['-U' 'distribute'] python_cmd use_sudo
def module_to_dict module omittable lambda k k.startswith '_' return dict k repr v for k v in module.__dict__.items if not omittable k
def getmodetype mode return ImageMode.getmode mode .basetype
def tuple_wrapper method def wrap_tuples *args **kw_args newargs []for arg in args if type arg is tuple newargs.append Tuple *arg else newargs.append arg return method *newargs **kw_args return wrap_tuples
def create_voucher voucher Voucher.objects.create name u'D\xf9\uff4d\u03fb\u03d2voucher' code 'test' start_datetime timezone.now end_datetime timezone.now + datetime.timedelta days 12 voucher.offers.add create_offer offer_type 'Voucher' return voucher
def sakurai n A sparse.eye n n d0 array r_[ 5 6 * ones n - 2 5 ] d1 -4 * ones n d2 ones n B sparse.spdiags [d2 d1 d0 d1 d2] [ -2 -1 0 1 2] n n k arange 1 n + 1 w_ex sort 1.0 / 16.0 * pow cos 0.5 * k * pi / n + 1 4 return A B w_ex
def getSubfolderWithBasename basename directory archive.makeDirectory directory directoryListing os.listdir directory for fileName in directoryListing joinedFileName os.path.join directory fileName if os.path.isdir joinedFileName if basename fileName return joinedFileNamereturn None
def _watch_callback obj_weakref method_name *args **kwargs obj obj_weakref if obj is None returngetattr obj method_name *args **kwargs
def more_like_queue pk source top queue result more_like pk source top queue.put result
def authorize api_handle user resource arg1 None arg2 None return True
def _footer_logo_img is_secure logo_name configuration_helpers.get_value 'FOOTER_ORGANIZATION_IMAGE' settings.FOOTER_ORGANIZATION_IMAGE try return _absolute_url_staticfile is_secure logo_name except ValueError default_logo 'images/logo.png'log.info "Failedtofindfooterlogoat'%s' using'%s'instead" logo_name default_logo return staticfiles_storage.url default_logo
@click.command 'backups' def setup_backups from bench.utils import setup_backupssetup_backups
def _fillInOnTimes vector durations nonzeros numpy.array vector .nonzero [0]if len nonzeros 0 returnif len nonzeros 1 durations[nonzeros[0]] 1returnprev nonzeros[0]onTime 1onStartIdx prevendIdx nonzeros[ -1 ]for idx in nonzeros[1 ] if idx ! prev + 1 durations[onStartIdx onStartIdx + onTime ] range 1 onTime + 1 onTime 1onStartIdx idxelse onTime + 1prev idxdurations[onStartIdx onStartIdx + onTime ] range 1 onTime + 1
def svd_flip u v u_based_decision True if u_based_decision max_abs_cols np.argmax np.abs u axis 0 signs np.sign u[ max_abs_cols xrange u.shape[1] ] u * signsv * signs[ np.newaxis]else max_abs_rows np.argmax np.abs v axis 1 signs np.sign v[ xrange v.shape[0] max_abs_rows ] u * signsv * signs[ np.newaxis]return u v
@require_POST@xframe_options_sameorigindef del_image_async request image_id user request.userif not user.is_authenticated message _ 'Youarenotloggedin.' return HttpResponseForbidden json.dumps {'status' 'error' 'message' message} try image ImageAttachment.objects.get pk image_id except ImageAttachment.DoesNotExist message _ 'Therequestedimagecouldnotbefound.' return HttpResponseNotFound json.dumps {'status' 'error' 'message' message} if not user image.creator or user.has_perm 'upload.delete_imageattachment' message _ 'Youdonothavepermissiontodothat.' return HttpResponseForbidden json.dumps {'status' 'error' 'message' message} image.file.delete if image.thumbnail image.thumbnail.delete image.delete return HttpResponse json.dumps {'status' 'success'}
def s3_jaro_winkler_distance_row row1 row2 dw 0num_similar 0if len row1 ! len row2 returnfor x in range 0 len row1 str1 row1[x]str2 row2[x]dw + s3_jaro_winkler str1 str2 dw dw / len row1 dw dw * 100 return dw
def make_map declarations mapper routes.Mapper for route targets in declarations.items allowed_methods []for method in targets mapper.connect route action targets[method] conditions dict method [method] allowed_methods.append method allowed_methods ' '.join allowed_methods mapper.connect route action handle_405 _methods allowed_methods return mapper
def DEFINE_bool name default help CONFIG.AddOption type_info.Bool name name default default description help
def _RestoreFilters _cpplint_state.RestoreFilters
def get_results_df db rev bench DataFrame db.get_benchmarks results DataFrame map list db.get_rev_results rev .values results.columns db._results.c.keys results results.join bench['name'] on 'checksum' .set_index 'checksum' return results
def _run_command_in_extended_path syslog_ng_sbin_dir command params orig_path _add_to_path_envvar syslog_ng_sbin_dir if not salt.utils.which command error_message "Unabletoexecutethecommand'{0}'.ItisnotinthePATH.".format command log.error error_message _restore_path_envvar orig_path raise CommandExecutionError error_message ret _run_command command options params _restore_path_envvar orig_path return ret
def broadcast_collect expr broadcastable Broadcastable want_to_broadcast WantToBroadcast no_recurse None if isinstance expr want_to_broadcast and iscollection expr.dshape leaves leaves_of_type broadcastable expr expr broadcast expr sorted leaves key str if no_recurse is not None and isinstance expr no_recurse return exprchildren broadcast_collect i broadcastable want_to_broadcast no_recurse for i in expr._inputs return expr._subs {e c for e c in zip expr._inputs children }
def flavor_get context id return IMPL.flavor_get context id
def p_varargslist p if len p 4 p[0] p[1] + p[3] else p[0] [p[1]]
def cancel_wait watcher error cancel_wait_ex get_hub .cancel_wait watcher error
def enterprise_login username None password None token None url None two_factor_callback None if not url raise ValueError 'GitHubEnterpriserequiresyouprovidetheURLoftheinstance' g Noneif username and password or token g GitHubEnterprise url g.login username password token two_factor_callback return g
def alignment_summary alignment index '' answer []alignment_len alignment.get_alignment_length rec_count len alignment for i in range min 5 alignment_len answer.append index + col_summary alignment[ i] + 'alignmentcolumn%i' % i if alignment_len > 5 i alignment_len - 1 answer.append index + col_summary '|' * rec_count + '...' answer.append index + col_summary alignment[ i] + 'alignmentcolumn%i' % i return '\n'.join answer
def _unpublicize_activity committer_id activity_id activity_type if not Actor committer_id .can_unpublicize activity_type activity_id logging.error 'User%striedtounpublicizeexploration%sbutwasrefusedpermission.' % committer_id activity_id raise Exception 'Thisexplorationcannotbeunmarkedas"featured".' _change_activity_status committer_id activity_id activity_type ACTIVITY_STATUS_PUBLIC 'Explorationunpublicized.'
def _createBlank cls if isinstance cls type return cls.__new__ cls if not _PY3 and isinstance cls _OldStyleClass return _OldStyleInstance cls
def get_all_reference_api_files base_url r requests.get base_url soup BeautifulSoup r.text 'html.parser' reference soup.find 'h3' text re.compile 'Reference' .next_sibling.next_siblingurls reference.findAll 'a' api_urls []for url in urls api_urls.append REACT_ROOT_URL + url.attrs['href'] return api_urls
def _iostats_dict header stats stats [float sum stat / len stat .quantize decimal.Decimal '.01' for stat in zip *stats ]stats dict zip header stats return stats
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def _handle_ns packageName path_item importer get_importer path_item if importer is None return Noneloader importer.find_module packageName if loader is None return Nonemodule sys.modules.get packageName if module is None module sys.modules[packageName] imp.new_module packageName module.__path__ []_set_parent_ns packageName elif not hasattr module '__path__' raise TypeError 'Notapackage ' packageName handler _find_adapter _namespace_handlers importer subpath handler importer path_item packageName module if subpath is not None path module.__path__path.append subpath loader.load_module packageName for path_item in path if path_item not in module.__path__ module.__path__.append path_item return subpath
def rrStatus a TpPd pd 6 b MessageType mesType 18 c RrCause packet a / b / c return packet
@task name 'all' help {'args' 'Commandlineargsfortestrun.'} def test_all ctx args '' options '' pytest_args select_by_prefix args ctx.pytest.scopes behave_args select_by_prefix args ctx.behave_test.scopes pytest_should_run not args or args and pytest_args behave_should_run not args or args and behave_args if pytest_should_run pytest ctx pytest_args options options if behave_should_run behave ctx behave_args options options
def _list_mock_games path files os.listdir path return os.path.join path f for f in files if _is_sgf f
def list_inactive_vms conn __get_conn vms []for id_ in conn.listDefinedDomains vms.append id_ return vms
def directlyProvides object *interfaces cls getattr object '__class__' None if cls is not None and getattr cls '__class__' None is cls if not isinstance object DescriptorAwareMetaClasses raise TypeError 'Attempttomakeaninterfacedeclarationonanon-descriptor-awareclass' interfaces _normalizeargs interfaces if cls is None cls type object issub Falsefor damc in DescriptorAwareMetaClasses if issubclass cls damc issub Truebreakif issub object.__provides__ ClassProvides object cls *interfaces else object.__provides__ Provides cls *interfaces
def same_name f g return f g or getattr f '__name__' 0 getattr g '__name__' 1
def _sanity_check module zone_name module.params['zone']if not HAS_LIBCLOUD module.fail_json msg 'ThismodulerequiresApachelibcloud%sorgreater' % MINIMUM_LIBCLOUD_VERSION changed False elif LooseVersion LIBCLOUD_VERSION < MINIMUM_LIBCLOUD_VERSION module.fail_json msg 'ThismodulerequiresApachelibcloud%sorgreater' % MINIMUM_LIBCLOUD_VERSION changed False if '.' not in zone_name or len [label for label in zone_name.split '.' if label] 1 module.fail_json msg 'cannotcreatetop-leveldomain %s' % zone_name changed False
def test_gnb_prior_greater_one clf GaussianNB priors np.array [2.0 1.0] assert_raises ValueError clf.fit X y
def security_group_rule_get_by_security_group_grantee context security_group_id return IMPL.security_group_rule_get_by_security_group_grantee context security_group_id
def init_readline_vars try import ctypesexcept ImportError returnlib_name find_readline_lib if lib_name is not None lib ctypes.cdll.LoadLibrary lib_name global rl_completion_suppress_appendrl_completion_suppress_append ctypes.c_int.in_dll lib 'rl_completion_suppress_append'
def set_inheritance obj_name enabled obj_type 'file' clear False if obj_type not in ['file' 'registry' 'registry32'] raise SaltInvocationError 'obj_typecalledwithincorrectparameter {0}'.format obj_name if clear dacl Dacl obj_type obj_type else dacl Dacl obj_name obj_type return dacl.save obj_name not enabled
def get_traceback exc_type exc_value exc_tb sys.exc_info trace_list traceback.format_exception exc_type exc_value exc_tb body u''.join cstr t for t in trace_list return body
def job_show context data_dict return {'success' False}
def decode_signed_varint i if not i & 1 return i >> 1 return i >> 1 ^ ~ 0
def _cache_shop_configuration shop configuration {}configuration.update _get_configuration_from_db None if shop configuration.update _get_configuration_from_db shop cache.set _get_cache_key shop configuration return configuration
def nunpack s default 0 l len s if not l return defaultelif l 1 return ord s elif l 2 return struct.unpack '>H' s [0]elif l 3 return struct.unpack '>L' '\x00' + s [0]elif l 4 return struct.unpack '>L' s [0]else return TypeError 'invalidlength %d' % l
def load_protocol_modules from . import audio_output channels command_list connection current_playlist mount music_db playback reflection status stickers stored_playlists
def binomial_coefficients_list n d [1] * n + 1 a 1for k in range 1 n // 2 + 1 a a * n - k + 1 // k d[k] d[ n - k ] areturn d
def get_specialized_types type assert type.is_fusedif isinstance type FusedType result list type.types for specialized_type in result specialized_type.specialization_string specialized_type.typeof_name else result []for cname f2s in get_all_specialized_permutations type.get_fused_types specialized_type type.specialize f2s specialized_type.specialization_string specialization_signature_string type f2s result.append specialized_type return result
def getLoopsListsIntersections loopsList loopsListsIntersections []for loopsIndex in xrange len loopsList loops loopsList[loopsIndex]for otherLoops in loopsList[ loopsIndex] loopsListsIntersections + getLoopsLoopsIntersections loops otherLoops return loopsListsIntersections
def get_traffic_dates thing now datetime.datetime.now g.tz .replace minute 0 second 0 microsecond 0 start end get_total_run thing end min now end return start end
def get_default_username check_db True from django.contrib.auth import models as auth_appif auth_app.User._meta.swapped return ''default_username get_system_username try default_username unicodedata.normalize 'NFKD' default_username .encode 'ascii' 'ignore' .decode 'ascii' .replace '' '' .lower except UnicodeDecodeError return ''try auth_app.User._meta.get_field 'username' .run_validators default_username except exceptions.ValidationError return ''if check_db and default_username try auth_app.User._default_manager.get username default_username except auth_app.User.DoesNotExist passelse return ''return default_username
def _do_get_file_map file_tree file_map []stack [file_tree]while len stack tree_node stack.pop 0 if tree_node['kind'] 'file' file_map.append tree_node['extra']['hashes']['sha256'] tree_node else stack stack + tree_node['children'] return file_map
def line_nr ana entry rowcol ana.rowcol entry.file_name return rowcol entry.region.begin [0] + 1
def list_members t owner slug get_slug rel {}next_cursor -1 while next_cursor ! 0 m t.lists.members slug slug owner_screen_name owner cursor next_cursor include_entities False for u in m['users'] rel[u['name']] '@' + u['screen_name'] next_cursor m['next_cursor']printNicely 'All ' + str len rel + 'members.' for name in rel user '' + cycle_color name user + color_func c['TWEET']['nick'] '' + rel[name] + '' printNicely user
def connect_db rv sqlite3.connect app.config['DATABASE'] rv.row_factory sqlite3.Rowreturn rv
def load_command_class app_name name module import_module '%s.management.commands.%s' % app_name name return module.Command
def s3_auth_on_logout user s3_clear_session
def colorline x y colors None linewidth 3 alpha 1.0 colors ['r' 'g' 'b' 'c' 'y' 'm' 'k']widths [5 10 20 40 20 10 5]segments make_segments x y lc LineCollection segments colors colors linewidth widths alpha alpha ax plt.gca ax.add_collection lc return lc
def background func def internal *a **kw data ctx _context[currentThread ]_context[currentThread ] storage ctx.copy def newfunc _context[currentThread ] ctxfunc *a **kw t threading.Thread target newfunc background.threaddb[id t ] tt.start ctx.headers []return seeother changequery _t id t return internal
def create_editable_list_form form_base_class form_class widget None if widget is None widget XEditableWidget class ListForm form_base_class list_form_pk HiddenField validators [InputRequired ] for name obj in iteritems form_class.__dict__ if isinstance obj UnboundField obj.kwargs['widget'] widgetsetattr ListForm name obj if name 'list_form_pk' raise Exception 'Formalreadyhasalist_form_pkcolumn.' return ListForm
def make_key_filter include if not include return identitymatchers []for key in include key re.escape key key key.replace '\\*' '.*' matchers.append re.compile key + '$' def filter_ data filtered dict for key value in data.items if any [m.match key for m in matchers] filtered[key] valuereturn filteredreturn filter_
def set_auth auth key _auth_registry_key request None request request or webapp2.get_request request.registry[key] auth
def consistencygroup_include_in_cluster context cluster partial_rename True **filters return IMPL.consistencygroup_include_in_cluster context cluster partial_rename **filters
def widest_numeric_type type1 type2 if type1.is_reference type1 type1.ref_base_typeif type2.is_reference type2 type2.ref_base_typeif type1 type2 widest_type type1elif type1.is_complex or type2.is_complex def real_type ntype if ntype.is_complex return ntype.real_typereturn ntypewidest_type CComplexType widest_numeric_type real_type type1 real_type type2 elif type1.is_enum and type2.is_enum widest_type c_int_typeelif type1.rank < type2.rank widest_type type2elif type1.rank > type2.rank widest_type type1elif type1.signed < type2.signed widest_type type1elif type1.signed > type2.signed widest_type type2elif type1.is_typedef > type2.is_typedef widest_type type1else widest_type type2return widest_type
def deep_update d u for k v in u.iteritems if isinstance v collections.Mapping r deep_update d.get k {} v d[k] relse d[k] u[k]return d
def _coerce_method converter def wrapper self if len self 1 return converter self.iloc[0] raise TypeError 'cannotconverttheseriesto{0}'.format str converter return wrapper
def _split_str s n length len s return [s[i i + n ] for i in range 0 length n ]
def virtual_interface_delete context id return IMPL.virtual_interface_delete context id
def setup_polling conf cfg_file conf.pipeline_cfg_filereturn PollingManager conf cfg_file
def idfunc vals dtype re.compile 'float\\d\\d' .search '{}'.format vals[1] .group return '{}_{}'.format vals[0] dtype
def set_vif_host_backend_ethernet_config conf tapname conf.net_type 'ethernet'conf.target_dev tapnameconf.script ''
def started service if not is_running service if using_systemd systemd.start service else start service
def runtime_rewriter_middleware application return functools.partial _rewriter_middleware _REQUEST_REWRITER_CHAIN _RUNTIME_RESPONSE_REWRITER_CHAIN application
def _split p dash _allowMOSFSNames and p[ 1] '-' if dash q string.find p '-' 1 + 1 elif p[ 1] ' ' q 0else q string.find p ' ' + 1 s string.find p '#' if s -1 or s > q s qelse for c in p[dash s] if c not in string.ascii_letters q 0breakr qif p[q q + 1 ] ' ' r string.find p '.' q + 1 + 1 if r 0 r len p return p[ q] p[q r] p[r ]
def test_lex_mangling_star entry tokenize '*foo*' assert entry [HySymbol 'FOO' ] entry tokenize '*' assert entry [HySymbol '*' ] entry tokenize '*foo' assert entry [HySymbol '*foo' ]
def parse_input args condition True _args []_kwargs {}for arg in args if isinstance arg six.string_types arg_name arg_value parse_kwarg arg if arg_name _kwargs[arg_name] yamlify_arg arg_value else _args.append yamlify_arg arg elif isinstance arg dict if arg.pop '__kwarg__' False is True for key val in six.iteritems arg _kwargs[key] yamlify_arg val else _args.append arg else _args.append arg if condition return condition_input _args _kwargs return _args _kwargs
def add_never_cache_headers response patch_response_headers response cache_timeout -1
def F classify lambda document False documents [] beta 1 average None A P R F1 test classify documents average return beta ** 2 + 1 * P * R / beta ** 2 * P + R or 1
def validate_external_location uri if not uri return Falsescheme urlparse.urlparse uri .schemereturn scheme in store_api.get_known_schemes and scheme not in RESTRICTED_URI_SCHEMAS
def MakePmfFromList t label None return Pmf t label label
def getScaleMatrixTetragrid prefix xmlElement scaleDefaultVector3 Vector3 1.0 1.0 1.0 scale getCumulativeVector3Remove prefix scaleDefaultVector3.copy xmlElement if scale scaleDefaultVector3 return Nonereturn [[scale.x 0.0 0.0 0.0] [0.0 scale.y 0.0 0.0] [0.0 0.0 scale.z 0.0] [0.0 0.0 0.0 1.0]]
def umount module dest umount_bin module.get_bin_path 'umount' required True cmd [umount_bin dest] rc out err module.run_command cmd if rc 0 return 0 '' else return rc out + err
def _dbus_exception_to_reason exc args error exc.get_dbus_name if error 'error.unknown_config' return "Unknownconfiguration'{0}'".format args['config'] elif error 'error.illegal_snapshot' return 'Invalidsnapshot'else return exc.get_dbus_name
def iter_params_for_processing invocation_order declaration_order def sort_key item try idx invocation_order.index item except ValueError idx float 'inf' return not item.is_eager idx return sorted declaration_order key sort_key
def mon_status **kwargs return ceph_cfg.status **kwargs
def _ensure_panel_ids dashboard panel_id 1for row in dashboard.get 'rows' [] for panel in row.get 'panels' [] panel['id'] panel_idpanel_id + 1
def webdoc arg None stable None stable release if stable is None else stable url_or_error _generate_url arg stable if isinstance url_or_error ValueError raise url_or_errorwebbrowser.open url_or_error return None
def group_id_exists group_id context model context['model']session context['session']result session.query model.Group .get group_id if not result raise Invalid '%s %s' % _ 'Notfound' _ 'Group' return group_id
def tar_packages pkgmgr pkg_type pkg_names src_dir temp_dir tarballs []include_string '.'exclude_string Nonenames [p.strip for p in pkg_names.split ' ' ]for name in names print 'Processing%s...' % name if pkg_type 'client' pkg_dir src_direxclude_string get_exclude_string pkg_dir elif pkg_type 'test' pkg_dir os.path.join get_test_dir name src_dir name else pkg_dir os.path.join src_dir name pkg_name pkgmgr.get_tarball_name name pkg_type tarball_path pkgmgr.tar_package pkg_name pkg_name src_dir pkg_dir dest_dir temp_dir include_string include_string exclude_string exclude_string tarballs.append tarball_path return tarballs
def setup_other_plugins all_plugins clone_plugin 'tpope/vim-pathogen' for plugin in all_plugins clone_plugin plugin
def dmp_quo f g u K return dmp_div f g u K [0]
def ck_delete try filename request.args[0]except raise HTTP 401 'Requiredargumentfilenamemissing.' table s3db.doc_ckeditordb table.upload filename .delete filepath os.path.join request.folder 'uploads' filename os.unlink filepath
def import_file_to_ast fpath module_name return hy_compile import_file_to_hst fpath module_name
def _check_estimator estimator if not hasattr estimator 'decision_function' and not hasattr estimator 'predict_proba' raise ValueError 'Thebaseestimatorshouldimplementdecision_functionorpredict_proba!'
def is_a_spanquery obj return isinstance obj SpanTermQuery SpanFirstQuery SpanOrQuery SpanMultiQuery
def zeros_like a dtype None if dtype is None dtype a.dtypereturn zeros a.shape dtype dtype
def test_named t usertypes.Timer name 'foobar' assert t._name 'foobar' assert t.objectName 'foobar' assert repr t "<qutebrowser.utils.usertypes.Timername 'foobar'>"
def setup_logging options None level logging.DEBUG if options is not None and options.debug else logging.WARNING console logging.StreamHandler console.setLevel level formatter logging.Formatter u'% name s % levelname -8s% message s' console.setFormatter formatter logging.getLogger u'parquet' .setLevel level logging.getLogger u'parquet' .addHandler console
def test_escaped_html s '&lt;em&gt;strong&lt;/em&gt;'eq_ s linkify s
def upgrade_available name return latest_version name ! ''
def test_script main []
def git_version process subprocess.Popen [u'git' u'--version'] stdout subprocess.PIPE stdout stderr process.communicate assert process.returncode 0 u'Failedtodeterminegitversion.'matches re.search u'\\s \\d+ ? \\.\\d+ * [\\s\\.]' stdout return Revision.lenient matches.group 1
def user_is_article_course_staff user article wiki_slug article_course_wiki_root_slug article if wiki_slug is None return Falsemodstore modulestore.django.modulestore return _has_wiki_staff_access user wiki_slug modstore
def lv_list cmd 'lvs--all'volumes {}result utils.run cmd lines result.stdout.strip .splitlines if len lines > 1 columns lines[0].split lines lines[1 ]else return volumesfor line in lines details line.split length len details details_dict {}lv_name details[0]details_dict['VG'] details[1]details_dict['Attr'] details[2]details_dict['LSize'] details[3]if length 5 details_dict['Origin_Data'] details[4]elif length > 5 details_dict['Origin_Data'] details[5]details_dict['Pool'] details[4]volumes[lv_name] details_dictreturn volumes
def list_numbering_start attrs if 'start' in attrs return int attrs['start'] - 1 else return 0
def dbcredentials username password location source source_idx Nonewhile source_idx is None source_idx fetch 'SELECTROWIDFROMhostWHEREip ?' source if len source_idx > 0 source_idx source_idx[0][0]else dbhost None source None source_idx Nonereturn insert 'INSERTINTOcredentialsVALUES ? ? ? ? ? ' username password location source_idx _timestamp
def create_update_dashboard orgname None profile 'grafana' **kwargs if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.post '{0}/api/dashboards/db'.format profile.get 'grafana_url' json kwargs auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def do_db_sync db_api.db_sync db_api.get_engine CONF.command.version
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def send_notif_after_export user event_name result if '__error' in result send_notification user user action NOTIF_EVENT_EXPORT_FAIL title NOTIFS[NOTIF_EVENT_EXPORT_FAIL]['title'].format event_name event_name message NOTIFS[NOTIF_EVENT_EXPORT_FAIL]['message'].format error_text result['result']['message'] else send_notification user user action NOTIF_EVENT_EXPORTED title NOTIFS[NOTIF_EVENT_EXPORTED]['title'].format event_name event_name message NOTIFS[NOTIF_EVENT_EXPORTED]['message'].format event_name event_name download_url result['download_url']
@skip 'multiple_execute' def test_critical_parameterless_constructor global calledclr.AddReference 'IronPythonTest' import IronPythonTest.interop.net.type.clrtype as IPTcalled Falseclass MyType type def __clrtype__ self global calledcalled Truereturn IPT.SanityParameterlessConstructorclass X object __metaclass__ MyTypeAreEqual called True AreEqual IPT.SanityParameterlessConstructor.WhichConstructor 0 py_x X AreEqual IPT.SanityParameterlessConstructor.WhichConstructor 1 cs_x IPT.Factory.Get[X] AreEqual IPT.SanityParameterlessConstructor.WhichConstructor 2 AreEqual type py_x type cs_x
def _response code return 'HTTP/1.1%i%s' % code client.responses[code]
def validate_argmin_with_skipna skipna args kwargs skipna args process_skipna skipna args validate_argmin args kwargs return skipna
def update_ports_tree ports_tree _check_config_exists if ports_tree cmd 'poudriereports-u-p{0}'.format ports_tree else cmd 'poudriereports-u'ret __salt__['cmd.run'] cmd return ret
def assign obj **kwargs obj.__dict__.update kwargs
def augment_options options subset fields [attr for attr in dir options if not callable getattr options attr and not attr.startswith '__' ]for field in fields value subset.get field if value ! None setattr options field value return options
def display_name_with_default_escaped block return display_name_with_default block .replace '<' '&lt;' .replace '>' '&gt;'
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def test_wrap_nested_expr wrapped wrap_value HyExpression [long_type 0 ] assert type wrapped HyExpression assert type wrapped[0] HyInteger assert wrapped HyExpression [HyInteger 0 ]
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def get_port_range ports ports ports.encode 'utf8' p ports.replace '\xe2\x80\x93' '-' .split '-' if len p 2 return [int p[0] int p[1] ]else return [int p[0] int p[0] ]
def require_role role 'user' def _deco func def __deco request *args **kwargs request.session['pre_url'] request.pathif not request.user.is_authenticated return HttpResponseRedirect reverse 'login' if role 'admin' if request.user.role 'CU' return HttpResponseRedirect reverse 'index' elif role 'super' if request.user.role in ['CU' 'GA'] return HttpResponseRedirect reverse 'index' return func request *args **kwargs return __decoreturn _deco
def country_code_for_region region_code if not _is_valid_region_code region_code return 0return country_code_for_valid_region region_code
def check_password password encoded setter None preferred u'default' if not password or not is_password_usable encoded return Falsepreferred get_hasher preferred hasher identify_hasher encoded must_update hasher.algorithm ! preferred.algorithm is_correct hasher.verify password encoded if setter and is_correct and must_update setter password return is_correct
def get_dataset_names from bs4 import BeautifulSouphttp urlopen 'https //github.com/mwaskom/seaborn-data/' gh_list BeautifulSoup http return [l.text.replace '.csv' '' for l in gh_list.find_all 'a' {'class' 'js-navigation-open'} if l.text.endswith '.csv' ]
def _set_state pkg state ret {}valid_states 'hold' 'noprune' 'user' 'ok' 'installed' 'unpacked' if state not in valid_states raise SaltInvocationError 'Invalidstate {0}'.format state oldstate _get_state pkg cmd ['opkg' 'flag']cmd.append state cmd.append pkg _out __salt__['cmd.run'] cmd python_shell False ret[pkg] {'old' oldstate 'new' state}return ret
def clear_outbox frappe.db.sql u'deleteq rfrom`tabEmailQueue`asq `tabEmailQueueRecipient`asrwhereq.name r.parentandq.priority 0and\n DCTB DCTB datediff now q.modified >31' frappe.db.sql u"update`tabEmailQueue`asq `tabEmailQueueRecipient`asrsetq.status 'Expired' r.status 'Expired'\n DCTB DCTB whereq.name r.parentanddatediff curdate q.modified >7andq.status 'NotSent'andr.status 'NotSent'"
def _strip_basic_auth url frags list urlsplit url if '@' in frags[1] frags[1] frags[1].split '@' [1]return urlunsplit frags
def pick_configurator config default plugins question 'Howwouldyouliketoauthenticateandinstallcertificates?' return pick_plugin config default plugins question interfaces.IAuthenticator interfaces.IInstaller
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_class_for purpose mapping get_class_mapping class_ mapping[purpose]if isinstance class_ six.string_types class_ get_class_from_string class_ return class_
def split_lib_transform header if header.startswith '>' header header[1 ]fields header.split lib_id fields[0]qual_id fields[1]bc fields[2].split ' ' [1]return ''.join [lib_id 'read_id ' + qual_id 'barcode ' + bc ] qual_id
def _item_to_topic iterator resource return Topic.from_api_repr resource iterator.client
def format_exception msg *args **kwargs tb traceback.extract_tb sys.exc_info [2] limit 1 if len tb > 0 filename lineno func text tb[0]else filename lineno func text u'<unknown>'return msg.format filename filename lineno lineno func func text text *args **kwargs
@command 'mv\\s* \\d{1 3} \\s* %s ' % WORD def playlist_rename_idx _id name _id int _id - 1 playlist_rename sorted g.userpl [_id] + '' + name
def _transform func_name def wrapped self *args **kwargs replacement_string _query_super func_name self *args **kwargs to_string []char_counter 0for index in range 0 len self._raw_string if index in self._code_indexes to_string.append self._raw_string[index] elif index in self._char_indexes to_string.append replacement_string[char_counter] char_counter + 1return ANSIString ''.join to_string decoded True code_indexes self._code_indexes char_indexes self._char_indexes clean_string replacement_string return wrapped
def iprand return 'iprand'
def convert_to_real_indices seq qubit_map if isinstance seq Mul seq seq.argsif not isinstance qubit_map dict msg 'Expecteddictforqubit_map got%r.' % qubit_map raise TypeError msg qubit_map _sympify_qubit_map qubit_map real_seq for item in seq if isinstance item Gate real_item convert_to_real_indices item.args qubit_map elif isinstance item tuple or isinstance item Tuple real_item convert_to_real_indices item qubit_map else real_item qubit_map[item]if isinstance item Gate real_item item.__class__ *real_item real_seq real_seq + real_item return real_seq
def ip_num_to_string ip return '.'.join map lambda n str ip >> n & 255 [24 16 8 0]
def compare_media_types actual expected return compare_tree_to_dict actual expected 'base' 'type'
def uid_to_user uid try return pwd.getpwuid uid .pw_nameexcept KeyError NameError return uid
def getExtentByPaths elementNode transformedPaths elementNode.xmlObject.getTransformedPaths return euclidean.getMaximumByVector3Paths transformedPaths - euclidean.getMinimumByVector3Paths transformedPaths
def normalize_parameter_name name if type name is TupleType return ' %s ' % ' '.join [normalize_parameter_name n for n in name] else return name
def decode_datetime encoded_datetime time_zone_match _TIME_ZONE_RE.search encoded_datetime if time_zone_match time_string encoded_datetime[ time_zone_match.start 1 ].upper else time_string encoded_datetime.upper if '.' in time_string format_string '%Y-%m-%dT%H %M %S.%f'else format_string '%Y-%m-%dT%H %M %S'decoded_datetime datetime.datetime.strptime time_string format_string if not time_zone_match return decoded_datetimeif time_zone_match.group 'z' offset_minutes 0else sign time_zone_match.group 'sign' hours minutes [int value for value in time_zone_match.group 'hours' 'minutes' ]offset_minutes hours * 60 + minutes if sign '-' offset_minutes * -1 return datetime.datetime decoded_datetime.year decoded_datetime.month decoded_datetime.day decoded_datetime.hour decoded_datetime.minute decoded_datetime.second decoded_datetime.microsecond TimeZoneOffset offset_minutes
def check_quota context image_size db_api image_id None remaining get_remaining_quota context db_api image_id image_id if remaining is None returnuser getattr context 'user' '<unknown>' if image_size is None if remaining < 0 LOG.warn _LW 'User% user sattemptedtouploadanimageofunknownsizethatwillexceedthequota.% remaining dbytesremaining.' % {'user' user 'remaining' remaining} raise exception.StorageQuotaFull image_size image_size remaining remaining returnif image_size > remaining LOG.warn _LW 'User% user sattemptedtouploadanimageofsize% size dthatwillexceedthequota.% remaining dbytesremaining.' % {'user' user 'size' image_size 'remaining' remaining} raise exception.StorageQuotaFull image_size image_size remaining remaining return remaining
def subtract_time_from_time time1 time2 result_format 'number' exclude_millis False time Time time1 - Time time2 return time.convert result_format millis is_falsy exclude_millis
def select_fds read_fds timeout selector AutoSelector fd_map dict fd_to_int fd fd for fd in read_fds sel selector try for fd in read_fds sel.register fd result sel.select timeout if result is not None return [fd_map[fd_to_int fd ] for fd in result]finally sel.close
def _get_pubkey_hash cert sha_hash hashlib.sha1 cert.get_pubkey .get_modulus .hexdigest return _pretty_hex sha_hash
def renderXRDS request type_uris endpoint_urls response direct_to_template request 'xrds.xml' {'type_uris' type_uris 'endpoint_urls' endpoint_urls} response['Content-Type'] YADIS_CONTENT_TYPEreturn response
def do_3d_scatter x y z figno None title None fig pyplot.figure figno ax Axes3D fig ax.scatter x y z ax.set_xlabel 'X' ax.set_ylabel 'Y' ax.set_zlabel 'Z' pyplot.suptitle title
def first_key obj return six.next six.iterkeys obj
def bounce sequence N len sequence def f i div mod divmod i N if div % 2 0 return sequence[mod]else return sequence[ N - mod - 1 ]return partial _force sequence _advance f
def init mpstate return CmdlongModule mpstate
def lookupIPV6Address name timeout None return getResolver .lookupIPV6Address name timeout
def strip_blank dic def _is_blank v '\nDeterminesiftheprovidedvaluecontainsnoinformation\n'return isinstance v str and len v.strip 0 return dict [ k v for k v in dic.iteritems if not _is_blank v ]
def dmp_eval f a u K if not u return dup_eval f a K if not a return dmp_TC f K result v dmp_LC f K u - 1 for coeff in f[1 ] result dmp_mul_ground result a v K result dmp_add result coeff v K return result
def test_write_twoline_no_bookend out StringIO ascii.write dat out Writer ascii.FixedWidthTwoLine bookend True delimiter '|' assert_equal_splitlines out.getvalue '|Col1|Col2|Col3|Col4|\n|----|---------|----|----|\n|1.2|"hello"|1|a|\n|2.4|\'sworlds|2|2|\n'
def _link_environment protocol alias local_port hostname remote_port alias alias.upper base u'%s_PORT_%d_%s' % alias local_port protocol.upper return {base u'%s //%s %d' % protocol hostname remote_port base + u'_ADDR' hostname base + u'_PORT' u'%d' % remote_port base + u'_PROTO' protocol}
def spoly p1 p2 ring LM1 p1.LMLM2 p2.LMLCM12 ring.monomial_lcm LM1 LM2 m1 ring.monomial_div LCM12 LM1 m2 ring.monomial_div LCM12 LM2 s1 p1.mul_monom m1 s2 p2.mul_monom m2 s s1 - s2 return s
def is_admin_context context if not context warnings.warn _ 'Useofemptyrequestcontextisdeprecated' DeprecationWarning raise Exception 'die' return context.is_admin
def Bernoulli name p succ 1 fail 0 return rv name BernoulliDistribution p succ fail
def asip ip if isinstance ip IPAddr return ipreturn IPAddr ip
def add_ratelimit_rule range_seconds num_requests global rulesrules.append range_seconds num_requests rules.sort key lambda x x[0]
def add_with_port_collision_retry client unit_name **kw ultimate_ports []def add ultimate_ports[ ] tentative_ports list port.set external_port find_free_port [1] if port.external_port 0 else port for port in kw['ports'] tentative_kw kw.copy tentative_kw['ports'] tentative_portsreturn client.add unit_name **tentative_kw def cleanup return client.remove unit_name if 'ports' in kw trying add trying.addErrback _retry_on_port_collision add cleanup result tryingelse result client.add unit_name **kw result.addCallback lambda app app ultimate_ports return result
def get_ccx_creation_dict course context {'course' course 'create_ccx_url' reverse 'create_ccx' kwargs {'course_id' course.id} 'has_ccx_connector' 'true' if hasattr course 'ccx_connector' and course.ccx_connector else 'false' 'use_ccx_con_error_message' _ 'ACCXcanonlybecreatedonthiscoursethroughanexternalservice.Contactacourseadmintogiveyouaccess.' }return context
def PathCheck path if isinstance path unicode path path.encode 'utf-8' path os.path.expanduser path if not os.path.exists path raise ValueError _ 'File/directorydoesnotexist %s' % path return os.path.abspath path
def test_epoch_multi_ids raw events picks _get_data epochs Epochs raw events {'a/b/a' 1 'a/b/b' 2 'a/c' 3 'b/d' 4 'a_b' 5} tmin tmax picks picks preload False epochs_regular epochs['a/b']epochs_reverse epochs['b/a']epochs_multi epochs[['a/b/a' 'a/b/b']]assert_array_equal epochs_multi.events epochs_regular.events assert_array_equal epochs_reverse.events epochs_regular.events assert_allclose epochs_multi.get_data epochs_regular.get_data assert_allclose epochs_reverse.get_data epochs_regular.get_data
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def parse_schema_string s files {} repr_ Thier_repr with_ns False skip_errors False elt etree.fromstring s parser PARSER return XmlSchemaParser files repr_ repr_ skip_errors skip_errors .parse_schema elt
def setup app app.add_role 'rfc' rfclink return
def test_lex_expression_strings objs tokenize ' foo"bar" ' assert objs [HyExpression [HySymbol 'foo' HyString 'bar' ] ]
def search_issues query sort None order None per_page None text_match False number -1 etag None return gh.search_issues query sort order per_page text_match number etag
def _dump_response http_response output 'HttpResponse\nstatus %s\nreason %s\nheaders ' % http_response.status http_response.reason headers get_headers http_response if isinstance headers dict for header value in headers.iteritems output + '%s %s\n' % header value else for pair in headers output + '%s %s\n' % pair[0] pair[1] return output
def accuracy features labels model preds predict model features return np.mean preds labels
def stdev data xbar None var variance data xbar try return var.sqrt except AttributeError return math.sqrt var
def render s context None if context is None context {}t get_env .from_string s return t.render context
@register_opt @local_optimizer [GpuFromHost tensor.Eye] def local_gpu_eye node if isinstance node.op GpuFromHost host_input node.inputs[0]if host_input.owner and isinstance host_input.owner.op tensor.Eye and host_input.owner.op.dtype 'float32' if tensor.extract_constant host_input.owner.inputs[2] ! 0 returnreturn [gpu_eye *host_input.owner.inputs ]if isinstance node.op tensor.Eye and node.op.dtype 'float32' if any [ i.owner and isinstance i.owner.op HostFromGpu for i in node.inputs] if tensor.extract_constant node.inputs[2] ! 0 returnreturn [host_from_gpu gpu_eye *node.inputs ]return False
def _get_synset synset_key return wn.synset synset_key
def _create_transport_factory reactor transport session_factory if transport.type 'websocket' serializers _create_transport_serializers transport return WampWebSocketClientFactory session_factory url transport.url serializers serializers elif transport.type 'rawsocket' serializer _create_transport_serializer transport.serializer return WampRawSocketClientFactory session_factory serializer serializer else assert False 'shouldnotarrivehere'
def refresh_beacons try ret __salt__['event.fire'] {} 'beacons_refresh' except KeyError log.error 'Eventmodulenotavailable.Modulerefreshfailed.' ret Falsereturn ret
def make_permission_config_key view return 'api_permission_{}'.format view.__class__.__name__
def get_qiime_scripts_dir script_fp which 'print_qiime_config.py' if script_fp is None raise ScriptsDirError 'CouldnotfindthedirectorycontainingQIIMEscripts.QIIMEscriptsmustbeaccessibleviathePATHenvironmentvariable andtheymustbeexecutable.PleaseensurethatyouhaveavalidQIIMEinstallation seetheQIIMEInstallationGuide http //qiime.org/install/install.html .' return dirname script_fp
def treat_machine_dict machine machine.update {'id' machine.get 'id' '' 'image' machine.get 'image' '' 'size' '{0}MB'.format machine.get 'memorySize' 0 'state' machine_get_machinestate_str machine 'private_ips' [] 'public_ips' []} if 'memorySize' in machine del machine['memorySize']return machine
def get_dependencies return config.check_driver_dependencies __virtualname__ {'libcloud' HAS_LIBS}
def auth_keys user None config '.ssh/authorized_keys' if not user user __salt__['user.list_users'] old_output_when_one_user Falseif not isinstance user list user [user]old_output_when_one_user Truekeys {}for u in user full Nonetry full _get_config_file u config except CommandExecutionError passif full and os.path.isfile full keys[u] _validate_keys full if old_output_when_one_user if user[0] in keys return keys[user[0]]else return {}return keys
def expose_request func if not python.callable func raise TypeError 'funcmustbecallable' if isinstance func types.UnboundMethodType setattr func.im_func '_pyamf_expose_request' True else setattr func '_pyamf_expose_request' True return func
def repo_issue_params milestone None state None assignee None mentioned None labels None sort None direction None since None number -1 etag None params {u'assignee' assignee u'mentioned' mentioned}if milestone in u'*' u'none' or isinstance milestone int params[u'milestone'] milestoneRepository._remove_none params params.update issue_params None state labels sort direction since return params
@security.send_mail_taskdef send_email msg common_send_email subject msg.subject recipients msg.recipients html msg.html
def _insert_thousands_sep digits spec min_width 1 sep spec['thousands_sep']grouping spec['grouping']groups []for l in _group_lengths grouping if l < 0 raise ValueError 'grouplengthshouldbepositive' l min max len digits min_width 1 l groups.append '0' * l - len digits + digits[ - l ] digits digits[ - l ]min_width - lif not digits and min_width < 0 breakmin_width - len sep else l max len digits min_width 1 groups.append '0' * l - len digits + digits[ - l ] return sep.join reversed groups
def find_job jid for data in running if data['jid'] jid return datareturn {}
@add_handler 'bookmarks' def qute_bookmarks _url bookmarks sorted objreg.get 'bookmark-manager' .marks.items key lambda x x[1] quickmarks sorted objreg.get 'quickmark-manager' .marks.items key lambda x x[0] html jinja.render 'bookmarks.html' title 'Bookmarks' bookmarks bookmarks quickmarks quickmarks return 'text/html' html
def octahedral_graph create_using None description ['adjacencylist' 'PlatonicOctahedralGraph' 6 [[2 3 4 5] [3 4 6] [5 6] [5 6] [6] []]]G make_small_undirected_graph description create_using return G
def constant_time_compare actual expected actual_len len actual expected_len len expected result actual_len ^ expected_len if expected_len > 0 for i in xrange actual_len result | ord actual[i] ^ ord expected[ i % expected_len ] return result 0
def qualname obj if isinstance obj functools.partial obj obj.funcif hasattr obj '__module__' prefix '{}.'.format obj.__module__ else prefix ''if hasattr obj '__qualname__' return '{}{}'.format prefix obj.__qualname__ elif hasattr obj '__name__' return '{}{}'.format prefix obj.__name__ else return repr obj
def make_s_curve n_samples 100 noise 0.0 random_state None generator check_random_state random_state t 3 * np.pi * generator.rand 1 n_samples - 0.5 x np.sin t y 2.0 * generator.rand 1 n_samples z np.sign t * np.cos t - 1 X np.concatenate x y z X + noise * generator.randn 3 n_samples X X.Tt np.squeeze t return X t
def test_l10n_dups request HttpRequest setattr request '_messages' default_storage request info request _ 'Title' _ 'Body' info request _ 'Title' _ 'Body' info request _ 'AnotherTitle' _ 'AnotherBody' storage django_messages.get_messages request assert len storage 2 'Toofewortoomanymessagesrecorded.'
@scope.definedef callpipe1 fn_list arg for f in fn_list arg f arg return arg
def getLoopCentroid polygonComplex polygonDoubleArea 0.0polygonTorque 0.0for pointIndex in xrange len polygonComplex pointBegin polygonComplex[pointIndex]pointEnd polygonComplex[ pointIndex + 1 % len polygonComplex ]doubleArea pointBegin.real * pointEnd.imag - pointEnd.real * pointBegin.imag doubleCenter complex pointBegin.real + pointEnd.real pointBegin.imag + pointEnd.imag polygonDoubleArea + doubleAreapolygonTorque + doubleArea * doubleCenter torqueMultiplier 0.3333333333333333 / polygonDoubleArea return polygonTorque * torqueMultiplier
@check_login_required@check_local_site_accessdef submitter request username grid None template_name u'datagrids/datagrid.html' local_site None if local_site try user local_site.users.get username username except User.DoesNotExist raise Http404else user get_object_or_404 User username username if grid is None or grid u'review-requests' datagrid_cls UserPageReviewRequestDataGridelif grid u'reviews' datagrid_cls UserPageReviewsDataGridelse raise Http404datagrid datagrid_cls request user local_site local_site datagrid.tabs [ UserPageReviewRequestDataGrid.tab_title local_site_reverse u'user' local_site local_site args [username] UserPageReviewsDataGrid.tab_title local_site_reverse u'user-grid' local_site local_site args [username u'reviews'] ]return datagrid.render_to_response template_name
def select_provider config_parser working_set type name try entry_point working_set.iter_entry_points type name .next except StopIteration raise Exception 'unknown%sprovider %r' % type name else provider_cls entry_point.load if hasattr provider_cls 'config' config_parser.add_spec provider_cls.config return provider_cls
def summarize text ratio 0.2 word_count None split False sentences _clean_text_by_sentences text if len sentences 0 logger.warning 'Inputtextisempty.' returnif len sentences 1 raise ValueError 'inputmusthavemorethanonesentence' if len sentences < INPUT_MIN_LENGTH logger.warning 'Inputtextisexpectedtohaveatleast' + str INPUT_MIN_LENGTH + 'sentences.' corpus _build_corpus sentences most_important_docs summarize_corpus corpus ratio ratio if word_count is None else 1 extracted_sentences _extract_important_sentences sentences corpus most_important_docs word_count extracted_sentences.sort key lambda s s.index return _format_results extracted_sentences split
def _updatePolicyElements policy_item regkey for child in policy_item.getiterator if 'valueName' in child.attrib if 'key' not in child.attrib child.attrib['key'] regkeyreturn policy_item
def _detect_xerial_stream payload if len payload > 16 header struct.unpack '!' + _XERIAL_V1_FORMAT bytes payload [ 16] return header _XERIAL_V1_HEADER return False
def test_prewitt_h_vertical i j np.mgrid[ -5 6 -5 6]image j > 0 .astype float result filters.prewitt_h image assert_allclose result 0 atol 1e-10
def test_suggested_column_names_from_visible_table completer complete_event text u'SELECTfromusers'position len u'SELECT' result set completer.get_completions Document text text cursor_position position complete_event assert set result set testdata.columns u'users' + testdata.functions + list testdata.builtin_functions + testdata.keywords
def post_save_resource instance sender **kwargs current_site Site.objects.get_current master_site Site.objects.get id 1 SiteResources.objects.get site current_site .resources.add instance.get_self_resource SiteResources.objects.get site master_site .resources.add instance.get_self_resource
def get_seqs_to_keep_lookup_from_otu_map seqs_to_keep_f otu_map fields_to_dict seqs_to_keep_f seqs_to_keep []for seq_ids in otu_map.values seqs_to_keep + seq_idsreturn {}.fromkeys seqs_to_keep
def add_test name test_type path author None dependencies None experimental True run_verify None test_class None test_time None test_category None description None sync_count 1 return models.Test.add_object name name test_type test_type path path author author dependencies dependencies experimental experimental run_verify run_verify test_time test_time test_category test_category sync_count sync_count test_class test_class description description .id
def get_app_wx *args **kwargs import wxapp wx.GetApp if app is None if 'redirect' not in kwargs kwargs['redirect'] Falseapp wx.PySimpleApp *args **kwargs return app
def cycle_length f x0 nmax None values False nmax int nmax or 0 power lam 1 tortoise hare x0 f x0 i 0while tortoise ! hare and not nmax or i < nmax i + 1if power lam tortoise harepower * 2lam 0if values yield hare hare f hare lam + 1if nmax and i nmax if values returnelse yield nmax None returnif not values mu 0tortoise hare x0for i in range lam hare f hare while tortoise ! hare tortoise f tortoise hare f hare mu + 1if mu mu - 1 yield lam mu
def _buffered_write_file fobj if PY26 or PY27 and isinstance fobj bz2.BZ2File return closing fobj else return io.BufferedWriter fobj buffer_size _IO_BUFFER_SIZE
def _parse_volume_info connection_data volume_id connection_data['volume_id']target_portal connection_data['target_portal']target_host _get_target_host target_portal target_port _get_target_port target_portal target_iqn connection_data['target_iqn']log_params {'vol_id' volume_id 'host' target_host 'port' target_port 'iqn' target_iqn}LOG.debug ' vol_id host port iqn % vol_id s % host s % port s % iqn s ' log_params if volume_id is None or target_host is None or target_iqn is None raise exception.StorageError reason _ 'Unabletoobtaintargetinformation%s' % strutils.mask_password connection_data volume_info {}volume_info['id'] volume_idvolume_info['target'] target_hostvolume_info['port'] target_portvolume_info['targetIQN'] target_iqnif 'auth_method' in connection_data and connection_data['auth_method'] 'CHAP' volume_info['chapuser'] connection_data['auth_username']volume_info['chappassword'] connection_data['auth_password']return volume_info
def guess_locale_from_lang_windows lang locale_n str LEGAL_VALUES[u'_WINDOWS_LOCALE_GUESSES'].get lang None if not is_valid_locale locale_n locale_n Nonereturn locale_n
def numeric_to_rational numeric if numeric[ 1] '-' sign numeric numeric[0] numeric[1 ] else sign ''parts numeric.split '/' if len parts 2 num den float_to_rational float parts[0] / float parts[1] elif len parts 1 num den float_to_rational float parts[0] else raise ValueError result '%s%s/%s' % sign num den if result.endswith '/1' return result[ -2 ]return result
def _prepare_index_for_memoryview i j x None if i.dtype > j.dtype j j.astype i.dtype elif i.dtype < j.dtype i i.astype j.dtype if not i.flags.writeable or i.dtype not in np.int32 np.int64 i i.astype np.intp if not j.flags.writeable or j.dtype not in np.int32 np.int64 j j.astype np.intp if x is not None if not x.flags.writeable x x.copy return i j x else return i j
def register_cmap_safe name data try return cm.get_cmap name except ValueError cmap LinearSegmentedColormap.from_list name data cm.register_cmap name cmap return cmap
def get_user_display user icon True link False if user is None full_name pgettext u'Noknownuser' u'None' else full_name user.first_nameif full_name.strip u'' full_name user.usernamefull_name escape full_name if icon and appsettings.ENABLE_AVATARS if user is None or user.email u'noreply@weblate.org' avatar get_fallback_avatar_url 32 else avatar reverse u'user_avatar' kwargs {u'user' user.username u'size' 32} full_name u'<imgsrc "{avatar}"class "avatar"/>{name}'.format name full_name avatar avatar if link and user is not None return mark_safe u'<ahref "{link}">{name}</a>'.format name full_name link reverse u'user_page' kwargs {u'user' user.username} else return mark_safe full_name
def _input_placeholder if FLAGS.dataset 'mnist' image_size 28num_channels 1else image_size 32num_channels 3train_node_shape FLAGS.batch_size image_size image_size num_channels return tf.placeholder tf.float32 shape train_node_shape
def SAREXT barDs count startvalue -4e+37 offsetonreverse -4e+37 accelerationinitlong -4e+37 accelerationlong -4e+37 accelerationmaxlong -4e+37 accelerationinitshort -4e+37 accelerationshort -4e+37 accelerationmaxshort -4e+37 return call_talib_with_hl barDs count talib.SAREXT startvalue offsetonreverse accelerationinitlong accelerationlong accelerationmaxlong accelerationinitshort accelerationshort accelerationmaxshort
def cat_file_to_cmd file command ignore_status 0 return_output False if not os.path.isfile file raise NameError 'invalidfile%stocattocommand%s' % file command if return_output run_cmd utils.system_outputelse run_cmd utils.systemif magic.guess_type file 'application/x-bzip2' if base_packages.has_pbzip2 cat 'pbzip2-d-c'else cat 'bzcat'elif magic.guess_type file 'application/x-gzip' cat 'zcat'elif magic.guess_type file 'application/x-xz' cat 'xzcat'else cat 'cat'return run_cmd '%s%s|%s' % cat file command ignore_status ignore_status
def _get_const_index exog effects_idx exog.var 0 ! 0 if np.any ~ effects_idx const_idx np.where ~ effects_idx [0]else const_idx Nonereturn effects_idx const_idx
def assure_snapshot fnc @wraps fnc def _wrapped self snapshot *args **kwargs if not isinstance snapshot CloudBlockStorageSnapshot snapshot self._snapshot_manager.get snapshot return fnc self snapshot *args **kwargs return _wrapped
def is_same_domain host pattern if not pattern return Falsepattern pattern.lower return pattern[0] '.' and host.endswith pattern or host pattern[1 ] or pattern host
def url_to_filetype abs_url path urlparse abs_url .pathif path.endswith '/' path path[ -1 ]path_chunks [x for x in path.split '/' if len x > 0 ]last_chunk path_chunks[ -1 ].split '.' if len last_chunk < 2 return Nonefile_type last_chunk[ -1 ]if len file_type < 5 or file_type.lower in ALLOWED_TYPES return file_type.lower return None
def forwards_problems pending done verbosity return inner_problem_check problems reversed pending done done verbosity
def cell_to_rowcol cell m _re_cell_ex.match cell if not m raise Exception 'Ill-formedsingle_cellreference %s' % cell col_abs col row_abs row m.groups row_abs bool row_abs col_abs bool col_abs row int row - 1 col col_by_name col.upper return row col row_abs col_abs
def is_pycaffe_in_dir dirname None old_path sys.pathif dirname is not None sys.path [dirname]try imp.find_module 'caffe' except ImportError return Falsefinally sys.path old_pathreturn True
def hessian_matrix image sigma 1 mode 'constant' cval 0 order None image img_as_float image gaussian_filtered ndi.gaussian_filter image sigma sigma mode mode cval cval if order is None if image.ndim 2 warn 'deprecationwarning thedefaultorderofthehessianmatrixvalueswillbe"row-column"insteadof"xy"startinginskimageversion0.15.Useorder "rc"ororder "xy"tosetthisexplicitly' order 'xy'else order 'rc'gradients np.gradient gaussian_filtered axes range image.ndim if order 'rc' axes reversed axes H_elems [np.gradient gradients[ax0] axis ax1 for ax0 ax1 in combinations_with_replacement axes 2 ]return H_elems
def locate_app app_id __traceback_hide__ Trueif ' ' in app_id module app_obj app_id.split ' ' 1 else module app_idapp_obj Nonetry __import__ module except ImportError if sys.exc_info [ -1 ].tb_next raiseelse raise NoAppException 'Thefile/pathprovided %s doesnotappeartoexist.Pleaseverifythepathiscorrect.IfappisnotonPYTHONPATH ensuretheextensionis.py' % module mod sys.modules[module]if app_obj is None app find_best_app mod else app getattr mod app_obj None if app is None raise RuntimeError 'Failedtofindapplicationinmodule"%s"' % module return app
def make_model_save model fields fail_message def save self commit True return save_instance self model fields fail_message commit return save
@environmentfilterdef do_sort environment value reverse False case_sensitive False attribute None if not case_sensitive def sort_func item if isinstance item basestring item item.lower return itemelse sort_func Noneif attribute is not None getter make_attrgetter environment attribute def sort_func item processor sort_func or lambda x x return processor getter item return sorted value key sort_func reverse reverse
def CDLSPINNINGTOP barDs count return call_talib_with_ohlc barDs count talib.CDLSPINNINGTOP
def make_binary_tree fn args **kwargs count len args if not count raise ValueError 'Calledmake_binary_treewithemptylist' elif count 1 return args[0]half count // 2 return fn make_binary_tree fn args[ half] **kwargs make_binary_tree fn args[half ] **kwargs **kwargs
def attr_chain obj attr next getattr obj attr while next yield next next getattr next attr
def user_documents user return Document.objects.filter revisions__creator user .exclude html__startswith '<p>REDIRECT<a' .distinct
def rem_z p q x delta degree p x - degree q x + 1 return rem Abs LC q x ** delta * p q x
def nesterov_momentum loss_or_grads params learning_rate momentum 0.9 updates sgd loss_or_grads params learning_rate return apply_nesterov_momentum updates momentum momentum
def clear_expired_sessions for sid in get_expired_sessions delete_session sid reason u'SessionExpired'
@with_setup prepare_stderr def test_feature_without_name filename syntax_feature_name 'feature_without_name' runner Runner filename assert_raises LettuceRunnerError runner.run assert_stderr_lines 'Syntaxerrorat %s\nFeaturesmusthaveaname.e.g "Feature Thisismyname"\n' % filename
def colored text color None on_color None attrs None if os.getenv 'ANSI_COLORS_DISABLED' is None fmt_str '\x1b[%dm%s'if color is not None text fmt_str % COLORS[color] text if on_color is not None text fmt_str % HIGHLIGHTS[on_color] text if attrs is not None for attr in attrs text fmt_str % ATTRIBUTES[attr] text if color is not None text + RESETreturn text
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def adamic_adar_index G ebunch None def predict u v return sum 1 / log G.degree w for w in nx.common_neighbors G u v return _apply_prediction G predict ebunch
def bw_silverman x kernel None A _select_sigma x n len x return 0.9 * A * n ** -0.2
def unchanged argument if argument is None return u''else return argument
def upgrade_available name return latest_version name ! ''
def make_file path content '' permissions None path.setContent content if permissions is not None path.chmod permissions return path
def build_stack obj if type obj is list layers map build_stack obj return Stack layers elif type obj is dict keys 'src' 'layername' 'color' 'colorname' 'mask' 'maskname' 'opacity' 'opacity' 'mode' 'blendmode' 'adjustments' 'adjustments' 'zoom' 'zoom' args [ arg obj[key] for key arg in keys if key in obj ]return Layer **dict args else raise Exception 'Uhoh'
def pre_constant_merge vars seen_var set const_sig_inv {}if isinstance vars graph.Variable vars [vars]def recursive_merge var if var in seen_var return varif not hasattr var 'owner' return varif var.owner and hasattr var.owner 'fgraph' return varseen_var.add var if isinstance var graph.Constant sig var.signature try if sig in const_sig_inv return const_sig_inv[sig]const_sig_inv[sig] varexcept TypeError warnings.warn "Weworkaroundaproblem thefollowingvariablesignatureisn'thashable.Please reportthistotheano-devsothatthebetterfixisdone.%s" % var passreturn varif var.owner for idx inp in enumerate var.owner.inputs var.owner.inputs[idx] recursive_merge inp return varreturn list map recursive_merge vars
def right_d_threshold_sequence n m cs ['d'] + ['i'] * n - 1 if m < n cs[m] 'd'return csif m > n * n - 1 / 2 raise ValueError 'Toomanyedgesforthismanynodes.' ind n - 1 sum n - 1 while sum < m cs[ind] 'd'ind - 1sum + indind m - sum - ind cs[ind] 'd'return cs
def zunpickle zdata return pickle.loads zlib.decompress zdata
def expandvars path global _varprogif '$' not in path return pathif not _varprog import re_varprog re.compile '\\$ \\w+|\\{[^}]*\\} ' i 0while True m _varprog.search path i if not m break i j m.span 0 name m.group 1 if name.startswith '{' and name.endswith '}' name name[1 -1 ]if name in os.environ tail path[j ]path path[ i] + os.environ[name] i len path path + tailelse i jreturn path
def _escape_for_regex text regex re.escape text regex regex.replace '\\\\' '\\\\\\' regex regex.replace '\\$' '\\\\\\$' regex regex.replace "\\'" "'" return regex
def elevation client locations params {'locations' convert.shortest_path locations }return client._get '/maps/api/elevation/json' params ['results']
@patch 'twilio.rest.resources.base.Resource.request' def test_delete_transcription req resp Mock resp.content ''resp.status_code 204req.return_value resp {} app Transcription transcriptions 'TR123' app.delete uri 'https //api.twilio.com/2010-04-01/Accounts/AC123/Transcriptions/TR123'req.assert_called_with 'DELETE' uri
def set_env user name value None lst list_tab user for env in lst['env'] if name env['name'] if value ! env['value'] rm_env user name jret set_env user name value if jret 'new' return 'updated'else return jretreturn 'present'env {'name' name 'value' value}lst['env'].append env comdat _write_cron_lines user _render_tab lst if comdat['retcode'] return comdat['stderr']return 'new'
@frappe.whitelist def remove_tag tag dt dn DocTags dt .remove dn tag
def get_tau_cov mu tau None cov None if tau is None if cov is None cov np.eye len mu tau np.eye len mu else tau tt.nlinalg.matrix_inverse cov elif cov is not None raise ValueError "Can'tpassbothtauandsd" else cov tt.nlinalg.matrix_inverse tau return tau cov
def z_transform_pval z n if n < 3 return nanreturn normprob z * n - 3 ** 0.5 direction 'two-sided'
def heat_decrypt value encryption_key None encryption_key get_valid_encryption_key encryption_key auth base64.b64decode value iv auth[ AES.block_size]cipher AES.new encryption_key AES.MODE_CFB iv res cipher.decrypt auth[AES.block_size ] return res
def ssl_method method if method in _SSL_PROTOCOLS return _SSL_PROTOCOLS[method]else try return ssl.PROTOCOL_SSLv23except AttributeError return _SSL_PROTOCOLS[0]
def paragraph return ''.join sentence for i in range random.randint 1 4
def dmp_sqf_norm f u K if not u return dup_sqf_norm f K if not K.is_Algebraic raise DomainError 'grounddomainmustbealgebraic' g dmp_raise K.mod.rep u + 1 0 K.dom F dmp_raise [K.one - K.unit ] u 0 K s 0while True h _ dmp_inject f u K front True r dmp_resultant g h u + 1 K.dom if dmp_sqf_p r u K.dom breakelse f s dmp_compose f F u K s + 1 return s f r
def make_limited_stream stream limit if not isinstance stream LimitedStream if limit is None raise TypeError 'streamnotlimitedandnolimitprovided.' stream LimitedStream stream limit return stream
def encrypt data iv Random.new .read AES.block_size cipher _create_cipher iv return iv + cipher.encrypt data
def removeBackupFilesByType fileType backupFilePaths getFilesWithFileTypesWithoutWordsRecursively [ fileType + '~' ] for backupFilePath in backupFilePaths os.remove backupFilePath
def _select_sigma X normalize 1.349IQR sap X 75 - sap X 25 / normalize return np.minimum np.std X axis 0 ddof 1 IQR
def _cmd_run cmd as_json False cmd_full ['Import-Module-NamePKI;']if as_json cmd_full.append 'ConvertTo-Json-Compress-Depth4-InputObject@ {0} '.format cmd else cmd_full.append cmd cmd_ret __salt__['cmd.run_all'] str .join cmd_full shell 'powershell' python_shell True if cmd_ret['retcode'] ! 0 _LOG.error 'Unabletoexecutecommand %s\nError %s' cmd cmd_ret['stderr'] if as_json try items json.loads cmd_ret['stdout'] strict False return itemsexcept ValueError _LOG.error 'UnabletoparsereturndataasJson.' return cmd_ret['stdout']
def frag_joiner ack src_ip_port load for ip_port in pkt_frag_loads if src_ip_port ip_port if ack in pkt_frag_loads[src_ip_port] old_load pkt_frag_loads[src_ip_port][ack]concat_load old_load + load return OrderedDict [ ack concat_load ] return OrderedDict [ ack load ]
def _parse_statement options for option in options _create_and_add_option option
def is_directed G return G.is_directed
def _XmlPatternToRegEx xml_pattern result ['^']while xml_pattern if xml_pattern.startswith '**' result.append '.*' xml_pattern xml_pattern[1 ]elif xml_pattern.startswith '*' result.append '[^/]*' elif xml_pattern.startswith '/' result.append '/' else result.append re.escape xml_pattern[0] xml_pattern xml_pattern[1 ]result.append '$' return re.compile ''.join result
def get_disconnect_url provider_id association_id backend_name _get_enabled_provider provider_id .backend_nameif association_id return _get_url 'social disconnect_individual' backend_name url_params {'association_id' association_id} else return _get_url 'social disconnect' backend_name
def get_servers req servers_service_pb.GetServersRequest resp servers_service_pb.GetServersResponse apiproxy_stub_map.MakeSyncCall 'servers' 'GetServers' req resp return list resp.server_list
def decrypt_password private_key password unencoded base64.b64decode password cmd ['openssl' 'rsautl' '-decrypt' '-inkey' private_key]proc subprocess.Popen cmd stdin subprocess.PIPE stdout subprocess.PIPE stderr subprocess.PIPE out err proc.communicate unencoded proc.stdin.close if proc.returncode raise DecryptionFailure err return out
def setElementNodeToEndStart elementNode end start elementNode.attributes['path'] [start end]elementNode.attributes['tiltFollow'] 'true'elementNode.attributes['tiltTop'] Vector3 0.0 0.0 1.0
def _refresh_course_tabs request course_module def update_tab tabs tab_type tab_enabled '\nAddsorremovesacoursetabbaseduponwhetheritisenabled.\n'tab_panel {'type' tab_type.type}has_tab tab_panel in tabs if tab_enabled and not has_tab tabs.append CourseTab.from_json tab_panel elif not tab_enabled and has_tab tabs.remove tab_panel course_tabs copy.copy course_module.tabs for tab_type in CourseTabPluginManager.get_tab_types if not tab_type.is_dynamic and tab_type.is_default tab_enabled tab_type.is_enabled course_module user request.user update_tab course_tabs tab_type tab_enabled CourseTabList.validate_tabs course_tabs if course_tabs ! course_module.tabs course_module.tabs course_tabs
def verify_signature message secret old_sig message.get 'message_signature' new_sig compute_signature message secret return new_sig old_sig
def test_extract_array_1d_trim assert np.all extract_array np.arange 4 2 0 mode u'trim' np.array [0] for i in [1 2 3] assert np.all extract_array np.arange 4 2 i mode u'trim' np.array [ i - 1 i] assert np.all extract_array np.arange 4.0 2 4 mode u'trim' np.array [3]
def _pick_counters log_interpretation for log_type in 'step' 'history' counters log_interpretation.get log_type {} .get 'counters' if counters return counterselse return {}
def test_qtable_read_for_ipac_table_with_char_columns t1 table.QTable [['A']] names 'B' out StringIO t1.write out format 'ascii.ipac' t2 table.QTable.read out.getvalue format 'ascii.ipac' guess False assert t2['B'].unit is None
def im_list_to_blob ims max_shape np.array [im.shape for im in ims] .max axis 0 num_images len ims blob np.zeros num_images max_shape[0] max_shape[1] 3 dtype np.float32 for i in xrange num_images im ims[i]blob[i 0 im.shape[0] 0 im.shape[1] ] imchannel_swap 0 3 1 2 blob blob.transpose channel_swap return blob
def load_tag_library libname if django.VERSION < 1 9 from django.template.base import get_library InvalidTemplateLibrarytry lib get_library libname return libexcept InvalidTemplateLibrary return Noneelse from django.template.backends.django import get_installed_librariesfrom django.template.library import InvalidTemplateLibrarytry lib get_installed_libraries [libname]lib importlib.import_module lib .registerreturn libexcept InvalidTemplateLibrary KeyError return None
def get_restart_delay ret salt.utils.mac_utils.execute_return_result 'systemsetup-getwaitforstartupafterpowerfailure' return salt.utils.mac_utils.parse_return ret
def mount module args mount_bin module.get_bin_path 'mount' required True name args['name']cmd [mount_bin]if ismount name return remount module mount_bin args if get_platform .lower 'openbsd' if module.params['fstab'] is not None module.fail_json msg 'OpenBSDdoesnotsupportalternatefstabfiles.DonotspecifythefstabparameterforOpenBSDhosts' else cmd + _set_fstab_args args['fstab'] cmd + [name] rc out err module.run_command cmd if rc 0 return 0 '' else return rc out + err
def cleanUpScreens errRun 'pkill-9-fmnexec.*socat'
def test_on_valid error_dict {'errors' {'so' 'many'}}expected hug.output_format.json error_dict assert hug.output_format.mp4_video error_dict hug.Response expected assert hug.output_format.png_image error_dict hug.Response expected @hug.output_format.on_valid 'image' hug.output_format.file def my_output_format data raise ValueError 'Thisshouldneverbecalled' assert my_output_format error_dict hug.Response
def undefer v if isinstance v Deferred v v.resolve return v
def enable_animations page enable_jquery_animations page enable_css_animations page
def BrowseMDI ob __main__ MakeTemplate root MakeHLI ob repr ob if not root.IsExpandable raise TypeError 'Browse argumentmusthave__dict__attribute orbeaBrowsersupportedtype' template.OpenObject root
def show_port port profile None conn _auth profile return conn.show_port port
def validate_token_parameters params if u'error' in params raise_from_error params.get u'error' params if not u'access_token' in params raise MissingTokenError description u'Missingaccesstokenparameter.' if not u'token_type' in params if os.environ.get u'OAUTHLIB_STRICT_TOKEN_TYPE' raise MissingTokenTypeError if params.scope_changed message u'Scopehaschangedfrom"{old}"to"{new}".'.format old params.old_scope new params.scope scope_changed.send message message old params.old_scopes new params.scopes if not os.environ.get u'OAUTHLIB_RELAX_TOKEN_SCOPE' None w Warning message w.token paramsw.old_scope params.old_scopesw.new_scope params.scopesraise w
def render_from_task template task variables {u'task' task u'now' datetime.now u'task_name' task.name}return render template variables
def isfunction object return isinstance object types.FunctionType
def test_custom conf try path filename os.path.split conf if path ! ETC_LIRC return Trueelse return Falseexcept return False
def get_sql_indexes_for_model model from django.db import backendoutput []for f in model._meta.fields if f.db_index unique f.unique and 'UNIQUE' or '' output.append style.SQL_KEYWORD 'CREATE%sINDEX' % unique + '' + style.SQL_TABLE '%s_%s' % model._meta.db_table f.column + '' + style.SQL_KEYWORD 'ON' + '' + style.SQL_TABLE backend.quote_name model._meta.db_table + '' + ' %s ;' % style.SQL_FIELD backend.quote_name f.column return output
def addAlreadyFilledArounds alreadyFilledArounds loop radius radius abs radius alreadyFilledLoop []slightlyGreaterThanRadius intercircle.globalIntercircleMultiplier * radius muchGreaterThanRadius 2.5 * radius centers intercircle.getCentersFromLoop loop slightlyGreaterThanRadius for center in centers alreadyFilledInset intercircle.getSimplifiedInsetFromClockwiseLoop center radius if intercircle.isLargeSameDirection alreadyFilledInset center radius alreadyFilledLoop.append alreadyFilledInset if len alreadyFilledLoop > 0 alreadyFilledArounds.append alreadyFilledLoop
def verify cypher key return gluechops cypher key['e'] key['n'] encrypt_int
def pool_dnn bc01 pool_shape pool_stride mode 'max' assert mode in ['max' 'mean'] if mode 'mean' raise NotImplementedError 'MeanpoolingisnotimplementedinPylearn2usingcuDNNasofJanuary19th 2015.' mx dnn_pool bc01 tuple pool_shape tuple pool_stride mode return mx
def _close_conn conn log.debug 'Closingthesqlite3databaseconnection' conn.commit conn.close
def metric_init params global array_dictarray_dict {'array1' {'array_name' 'array1' 'ipaddr' '192.168.1.50' 'user' '3paruser' 'pass' '3parpass'} 'array2' {'array_name' 'array2' 'ipaddr' '192.168.1.51' 'user' '3paruser' 'pass' '3parpass'}}Desc_Skel {'name' 'XXX' 'call_back' get_metric 'time_max' 600 'value_type' 'double' 'format' '%0f' 'units' 'XXX' 'slope' 'both' 'description' 'XXX' 'groups' 'storage'}descriptors []for array in array_dict ip array_dict[array]['ipaddr']user array_dict[array]['user']passwd array_dict[array]['pass']'Getalistofvolumesinthearray'vols get_vol_list ip user passwd 'GetalistofCPGsinthearray'cpgs get_cpg_list ip user passwd 'GetalistofCPUsinthearray-Onlygettingtotalspernodeatthispoint'cpus get_cpu_list ip user passwd 'createdescriptorsforthearray'array_descriptors define_metrics Desc_Skel array_dict[array]['array_name'] vols ip cpgs cpus descriptors descriptors + array_descriptors return descriptors
def merge_dicts d1 d2 result copy.deepcopy d1 for key value in six.iteritems d2 if isinstance value dict result[key] merge_dicts result[key] value elif key not in result or value is not None result[key] valuereturn result
def minutes m return float m / MINUTES_PER_DAY
def get_valid_utf8_str str_or_unicode if isinstance str_or_unicode unicode str_or_unicode _len utf8_encoder str_or_unicode 'replace' valid_utf8_str _len utf8_decoder str_or_unicode 'replace' return valid_utf8_str.encode 'utf-8'
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def _read_dig_fif fid meas_info isotrak dir_tree_find meas_info FIFF.FIFFB_ISOTRAK dig Noneif len isotrak 0 logger.info 'Isotraknotfound' elif len isotrak > 1 warn 'MultipleIsotrakfound' else isotrak isotrak[0]dig []for k in range isotrak['nent'] kind isotrak['directory'][k].kindpos isotrak['directory'][k].posif kind FIFF.FIFF_DIG_POINT tag read_tag fid pos dig.append tag.data dig[ -1 ]['coord_frame'] FIFF.FIFFV_COORD_HEADreturn dig
def translateNegativesPositives negatives positives translation euclidean.translateVector3Path matrix.getVertexes negatives translation euclidean.translateVector3Path matrix.getVertexes positives translation
def socket *args **kwargs return _SocketDecorator *args **kwargs
def _manage_users request course_key user_perms get_user_permissions request.user course_key if not user_perms & STUDIO_VIEW_USERS raise PermissionDenied course_module modulestore .get_course course_key instructors set CourseInstructorRole course_key .users_with_role staff set CourseStaffRole course_key .users_with_role .union instructors formatted_users []for user in instructors formatted_users.append user_with_role user 'instructor' for user in staff - instructors formatted_users.append user_with_role user 'staff' return render_to_response 'manage_users.html' {'context_course' course_module 'show_transfer_ownership_hint' request.user in instructors and len instructors 1 'users' formatted_users 'allow_actions' bool user_perms & STUDIO_EDIT_ROLES }
def _fast_hmac key msg digest dig1 dig2 digest digest if len key > dig1.block_size key digest key .digest key + chr 0 * dig1.block_size - len key dig1.update key.translate _trans_36 dig1.update msg dig2.update key.translate _trans_5c dig2.update dig1.digest return dig2
def is_installed return get_binstar is not None
def test_spans_default_sentiment en_tokenizer text u'goodstuffbadstuff'tokens en_tokenizer text tokens.vocab[tokens[0].text].sentiment 3.0tokens.vocab[tokens[2].text].sentiment -2.0 doc get_doc tokens.vocab [t.text for t in tokens] assert doc[ 2].sentiment 3.0 / 2 assert doc[ -2 ].sentiment -2.0 / 2 assert doc[ -1 ].sentiment 3.0 + -2 / 3.0
def test_refactor refactor_case if 0 refactor_case.run assert_case_equal refactor_case refactor_case.result refactor_case.desired
def model_cr method method._api 'model_cr'return method
def resize device minor start end _validate_device device try int minor except Exception raise CommandExecutionError 'Invalidminornumberpassedtopartition.resize' _validate_partition_boundary start _validate_partition_boundary end out __salt__['cmd.run'] 'parted-m-s--{0}resize{1}{2}{3}'.format device minor start end return out.splitlines
def generate_password_hash password method 'pbkdf2 sha256' salt_length 8 salt method ! 'plain' and gen_salt salt_length or '' h actual_method _hash_internal method salt password return '%s$%s$%s' % actual_method salt h
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
@register.inclusion_tag get_template 'inclusion.html' def inclusion_only_unlimited_args_from_template *args return {'result' 'inclusion_only_unlimited_args_from_template-Expectedresult %s' % ' '.join [unicode arg for arg in args] }
def _TestRemoveViewpoint tester user_cookie request_dict validator tester.validator user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict viewpoint_id request_dict['viewpoint_id']actual_dict tester.SendRequest 'remove_viewpoint' user_cookie request_dict op_dict tester._DeriveNotificationOpDict user_id device_id request_dict request_dict['user_id'] user_idfollower validator.GetModelObject Follower DBKey user_id viewpoint_id if not follower.IsRemoved labels follower.labels.union [Follower.REMOVED] validator.ValidateUpdateDBObject Follower user_id user_id viewpoint_id viewpoint_id labels labels invalidate {'viewpoints' [{'viewpoint_id' viewpoint_id 'get_attributes' True}]}validator.ValidateNotification 'remove_viewpoint' user_id op_dict invalidate viewpoint_id viewpoint_id validator.ValidateViewpointAccounting viewpoint_id tester._CompareResponseDicts 'remove_viewpoint' user_id request_dict {} actual_dict return actual_dict
def make_singlethread inner_func def func *args length len args[0] result np.empty length dtype np.float64 inner_func result *args return resultreturn func
def languages print_available_languages
def _get_closest_ansi_color r g b exclude assert isinstance exclude tuple saturation abs r - g + abs g - b + abs b - r if saturation > 30 exclude + u'ansilightgray' u'ansidarkgray' u'ansiwhite' u'ansiblack' distance 257 * 257 * 3 match u'ansidefault'for name r2 g2 b2 in ANSI_COLORS_TO_RGB.items if name ! u'ansidefault' and name not in exclude d r - r2 ** 2 + g - g2 ** 2 + b - b2 ** 2 if d < distance match namedistance dreturn match
def clearConsoleLine forceOutput False if getattr LOGGER_HANDLER 'is_tty' False dataToStdout '\r%s\r' % '' * getConsoleWidth - 1 forceOutput kb.prependFlag Falsekb.stickyLevel None
def _check_decim info decim offset if decim < 1 or decim ! int decim raise ValueError 'decimmustbeaninteger>0' decim int decim new_sfreq info['sfreq'] / float decim lowpass info['lowpass']if decim > 1 and lowpass is None warn 'Themeasurementinformationindicatesdataisnotlow-passfiltered.Thedecim %iparameterwillresultinasamplingfrequencyof%gHz whichcancausealiasingartifacts.' % decim new_sfreq elif decim > 1 and new_sfreq < 2.5 * lowpass warn 'Themeasurementinformationindicatesalow-passfrequencyof%gHz.Thedecim %iparameterwillresultinasamplingfrequencyof%gHz whichcancausealiasingartifacts.' % lowpass decim new_sfreq offset int offset if not 0 < offset < decim raise ValueError 'decimmustbeatleast0andlessthan%s got%s' % decim offset return decim offset new_sfreq
def der2pem der_string obj 'UNKNOWN' pem_string '-----BEGIN%s-----\n' % obj base64_string base64.b64encode der_string chunks [base64_string[i i + 64 ] for i in range 0 len base64_string 64 ]pem_string + '\n'.join chunks pem_string + '\n-----END%s-----\n' % obj return pem_string
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def getNearestDistanceIndex point loop smallestDistance 1e+18nearestDistanceIndex Nonefor pointIndex in xrange len loop segmentBegin loop[pointIndex]segmentEnd loop[ pointIndex + 1 % len loop ]distance getDistanceToPlaneSegment segmentBegin segmentEnd point if distance < smallestDistance smallestDistance distancenearestDistanceIndex DistanceIndex distance pointIndex return nearestDistanceIndex
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def volume_include_in_cluster context cluster partial_rename True **filters return IMPL.volume_include_in_cluster context cluster partial_rename **filters
def dotproduct x y return sum imap operator.mul x y
def PrintUsage message sys.stderr.write _USAGE if message sys.exit '\nFATALERROR ' + message else sys.exit 0
def most_common_types limit 10 objects None shortnames True stats sorted typestats objects shortnames shortnames .items key operator.itemgetter 1 reverse True if limit stats stats[ limit]return stats
def _replSGMLRefs match ref match.group 1 return sgmlentityget ref ref
def enabled name **kwargs ret {'name' name 'result' True 'changes' {} 'comment' []}current_schedule __salt__['schedule.list'] show_all True return_yaml False if name in current_schedule if 'test' in __opts__ and __opts__['test'] kwargs['test'] Trueresult __salt__['schedule.enable_job'] name **kwargs ret['comment'].append result['comment'] else result __salt__['schedule.enable_job'] name **kwargs if not result['result'] ret['result'] result['result']ret['comment'] result['comment']return retelse ret['comment'].append 'Enabledjob{0}fromschedule'.format name else ret['comment'].append 'Job{0}notpresentinschedule'.format name ret['comment'] '\n'.join ret['comment'] return ret
def security_group_get_all context return IMPL.security_group_get_all context
def cc arg return mcolors.to_rgba arg alpha 0.6
@object_hook_trusted.register 'callable' def numpy_pandas_function_from_str f if f.startswith np.__name__ mod npelif f.startswith pd.__name__ mod pdelif f.startswith builtins.__name__ mod builtinselse msg 'Function{}notrecognized;onlynumpy pandas orbuiltinfunctionsaresupported.'raise wz_ex.NotImplemented msg.format f fcn reduce getattr f.split '.' [1 ] mod return fcn
def validate_head_files config contract_head _get_contract_head_file_path config expand_head _get_expand_head_file_path config if not os.path.exists contract_head or not os.path.exists expand_head alembic_util.warn _ 'RepositorydoesnotcontainHEADfilesforcontractandexpandbranches.' returnhead_map _get_heads_map config _check_head CONTRACT_BRANCH contract_head head_map[CONTRACT_BRANCH] _check_head EXPAND_BRANCH expand_head head_map[EXPAND_BRANCH]
def get_json_stats request days step project None subproject None lang None user None if project is None and lang is None and user is None project Nonesubproject Nonetranslation Nonelanguage Noneuser Noneelif user is not None project Nonesubproject Nonetranslation Nonelanguage Noneuser get_object_or_404 User username user elif project is None project Nonesubproject Nonetranslation Nonelanguage get_object_or_404 Language code lang user Noneelse project subproject translation get_project_translation request project subproject lang language Noneuser Nonereturn Change.objects.base_stats days step project subproject translation language user
def api_config path opts DEFAULT_API_OPTSopts.update client_config path defaults DEFAULT_MASTER_OPTS opts.update {'pidfile' opts.get 'api_pidfile' DEFAULT_API_OPTS['api_pidfile'] 'log_file' opts.get 'api_logfile' DEFAULT_API_OPTS['api_logfile'] } prepend_root_dir opts ['api_pidfile' 'api_logfile' 'log_file' 'pidfile'] return opts
def xblock_resource request block_type uri try xblock_class XBlock.load_class block_type select settings.XBLOCK_SELECT_FUNCTION content xblock_class.open_local_resource uri except IOError log.info 'Failedtoloadxblockresource' exc_info True raise Http404except Exception log.error 'Failedtoloadxblockresource' exc_info True raise Http404 mimetype _ mimetypes.guess_type uri return HttpResponse content content_type mimetype
def list_nodes_full call None if call 'action' raise SaltCloudSystemExit 'Thelist_nodes_fullfunctionmustbecalledwith-for--function.' return get_resources_vms includeConfig True
def set_in_sighandler value global _in_sighandler_in_sighandler value
def name_that_thing thing if hasattr thing 'im_class' if hasattr thing 'mock_calls' return '<mock>'return name_that_thing thing.im_class + '.' + thing.im_func.func_name if hasattr thing '__name__' if hasattr thing '__class__' and not isinstance thing types.FunctionType types.MethodType if thing.__class__ is not type and not issubclass thing.__class__ type return name_that_thing thing.__class__ if hasattr thing '__self__' return '%s.%s' % thing.__self__.__module__ thing.__self__.__name__ if hasattr thing '__module__' return '%s.%s' % thing.__module__ thing.__name__ if hasattr thing '__class__' return name_that_thing thing.__class__ return repr thing
def find_elements_by_sizzle driver sizzle_selector if not _is_sizzle_loaded driver _inject_sizzle driver SIZZLE_URL SIZZLE_LOAD_TIMEOUT elements driver.execute_script _make_sizzle_string sizzle_selector return elements
def task_decorator method @wraps method def _wrapper self *args **kwds rnd_id random.randint 1 MAX_RAND function_id '%s_%s' % method.__name__ rnd_id self._add_task function_id try result method self function_id *args **kwds except self._task_done function_id raiseelse self._task_done function_id return resultreturn _wrapper
def encodeExecutableAndArgs executable args encoding 'utf-8' if isinstance executable text_type executable executable.encode encoding argsBytes []for arg in args if isinstance arg text_type arg arg.encode encoding argsBytes.append arg return executable argsBytes
@login_required@expect_jsondef _create_item request parent_locator request.json['parent_locator']usage_key usage_key_with_run parent_locator if not has_studio_write_access request.user usage_key.course_key raise PermissionDenied category request.json['category']if isinstance usage_key LibraryUsageLocator if category not in ['html' 'problem' 'video'] return HttpResponseBadRequest "Category'%s'notsupportedforLibraries" % category content_type 'text/plain' created_block create_xblock parent_locator parent_locator user request.user category category display_name request.json.get 'display_name' boilerplate request.json.get 'boilerplate' return JsonResponse {'locator' unicode created_block.location 'courseKey' unicode created_block.location.course_key }
def platform_name res platform.platform if isinstance res bytes res res.decode preferredencoding assert isinstance res compat_str return res
def profile_stop driver.cuProfilerStop
def get_certificates_for_user username return [format_certificate_for_user username cert for cert in GeneratedCertificate.eligible_certificates.filter user__username username .order_by 'course_id' ]
def verbose_field_name model field_name if field_name is None return '[invalidname]'parts get_field_parts model field_name if not parts return '[invalidname]'names []for part in parts if isinstance part ForeignObjectRel names.append force_text part.related_name else names.append force_text part.verbose_name return ''.join names
def _sqkey sq_operator return sq_operator._sortkey
def create_git_repository test_case bare False directory FilePath test_case.mktemp repository Repo.init path directory.path bare bare if not bare directory.child 'README' .makedirs directory.child 'README' .touch repository.index.add ['README'] repository.index.commit 'Initialcommit' repository.create_head 'master' return repository
@api_versions.wraps '2.23' @utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_server_migration_list cs args server _find_server cs args.server migrations cs.server_migrations.list server fields ['Id' 'SourceNode' 'DestNode' 'SourceCompute' 'DestCompute' 'DestHost' 'Status' 'ServerUUID' 'CreatedAt' 'UpdatedAt']format_name ['TotalMemoryBytes' 'ProcessedMemoryBytes' 'RemainingMemoryBytes' 'TotalDiskBytes' 'ProcessedDiskBytes' 'RemainingDiskBytes']format_key ['memory_total_bytes' 'memory_processed_bytes' 'memory_remaining_bytes' 'disk_total_bytes' 'disk_processed_bytes' 'disk_remaining_bytes']formatters map lambda field utils.make_field_formatter field [1] format_key formatters dict zip format_name formatters utils.print_list migrations fields + format_name formatters
def rollback_unless_managed if not is_managed connection._rollback else set_dirty
def _start_subprocess_for_result cmd task subprocess.Popen cmd stdout subprocess.PIPE stderr subprocess.PIPE out err task.communicate return out err
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg 'port_id' metavar '<port_id>' help _ 'PortID.' def do_interface_detach cs args server _find_server cs args.server res server.interface_detach args.port_id if isinstance res dict utils.print_dict res
def _GetDatastoreType app None current_app datastore_types.ResolveAppId None if app not in current_app None return BaseConnection.UNKNOWN_DATASTORE partition _ _ app_identity._ParseFullAppId current_app if partition return BaseConnection.HIGH_REPLICATION_DATASTOREreturn BaseConnection.MASTER_SLAVE_DATASTORE
def setcopyright __builtin__.copyright _Printer 'copyright' sys.copyright if sys.platform[ 4] 'java' __builtin__.credits _Printer 'credits' 'JythonismaintainedbytheJythondevelopers www.jython.org .' elif sys.platform 'cli' __builtin__.credits _Printer 'credits' 'IronPythonismaintainedbytheIronPythondevelopers www.ironpython.net .' else __builtin__.credits _Printer 'credits' 'ThankstoCWI CNRI BeOpen.com ZopeCorporationandacastofthousands\nforsupportingPythondevelopment.Seewww.python.orgformoreinformation.' here os.path.dirname os.__file__ __builtin__.license _Printer 'license' 'Seehttp //www.python.org/%.3s/license.html' % sys.version ['LICENSE.txt' 'LICENSE'] [os.path.join here os.pardir here os.curdir]
def exact_filter query model filters filter_dict {}if filters is None filters {}for key value in six.iteritems filters if isinstance value list tuple set frozenset column_attr getattr model key query query.filter column_attr.in_ value else filter_dict[key] valueif filter_dict query query.filter_by **filter_dict return query
def _get_median data n_zeros n_elems len data + n_zeros if not n_elems return np.nann_negative np.count_nonzero data < 0 middle is_odd divmod n_elems 2 data.sort if is_odd return _get_elem_at_rank middle data n_negative n_zeros return _get_elem_at_rank middle - 1 data n_negative n_zeros + _get_elem_at_rank middle data n_negative n_zeros / 2.0
def test_prefer_broker_nodes a b c 'abc'dsk { a 0 f a 1 f b 0 f a 0 b 1 f a 1 b 2 f a 1 }o order dsk assert o[ a 1 ] < o[ a 0 ] dsk { a 0 f a 1 f b 0 f a 0 b 1 f a 1 b 2 f a 0 }o order dsk assert o[ a 1 ] > o[ a 0 ]
def uni_check_output *args **kwargs o subprocess.check_output *args **kwargs return o.decode 'utf-8'
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def test_pick_chpi info read_info op.join io_dir 'tests' 'data' 'test_chpi_raw_sss.fif' channel_types set [channel_type info idx for idx in range info['nchan'] ] assert_true 'chpi' in channel_types assert_true 'seeg' not in channel_types assert_true 'ecog' not in channel_types
def organization_followee_list context data_dict _check_access 'organization_followee_list' context data_dict return _group_or_org_followee_list context data_dict is_org True
def ethtype_to_str t if t < 1500 return '802.3/%04x' % t return _ethtype_to_str.get t '%04x' % t
def wait_for_xblock_initialization page xblock_css def _is_finished_loading is_done page.browser.execute_script "return$ {!r} .data 'initialized' ".format xblock_css return is_done is_done return Promise _is_finished_loading 'Finishedinitializingthexblock.' .fulfill
def reset_growl global _GROWL _GROWL_REG_GROWL None_GROWL_REG False
def check_allprop values target for value in values assert_equal value target
def test_no_output assert_raises BundleError bundle_to_joblist Bundle 's1' 's2' bundle_to_joblist Bundle 's1' Bundle 's2' output 'foo' bundle_to_joblist Bundle Bundle 's1' output 'foo' Bundle 's2' output 'bar' assert_raises BundleError bundle_to_joblist Bundle Bundle 's1' output 'foo' Bundle 's2'
def makeLayer element kwargs {}if element.hasAttribute 'src' kwargs['layername'] element.getAttribute 'src' if element.hasAttribute 'color' kwargs['colorname'] element.getAttribute 'color' for child in element.childNodes if child.nodeType child.ELEMENT_NODE if child.tagName 'mask' and child.hasAttribute 'src' kwargs['maskname'] child.getAttribute 'src' print >>sys.stderr 'Makingalayerfrom' kwargsreturn Layer **kwargs
def chopstring message key n funcref msglen len message mbits msglen * 8 nbits int math.floor math.log n 2 nbytes nbits / 8 blocks msglen / nbytes if msglen % nbytes > 0 blocks + 1cypher []for bindex in range blocks offset bindex * nbytes block message[offset offset + nbytes ]value bytes2int block cypher.append funcref value key n return picklechops cypher
def words_graph import gzipfh gzip.open 'words_dat.txt.gz' 'r' words set for line in fh.readlines line line.decode if line.startswith '*' continuew str line[0 5] words.add w return generate_graph words
def client_exceptions *exceptions def outer func def inner *args **kwargs return catch_client_exception exceptions func *args **kwargs return innerreturn outer
def make_bytearray buf b bytearray buf n len b return ir.Constant ir.ArrayType ir.IntType 8 n b
def _resolve_prop prop if hasattr prop '_proxied_property' return prop._proxied_propertyreturn prop
def beta_from_design design min_var 1e-06 max_var 1000000.0 return 1.0 / np.clip design.var axis 0 min_var max_var
def _read_link name alt_link_path '/etc/alternatives/{0}'.format name return os.readlink alt_link_path
def proxy_info_from_url url method 'http' url urlparse.urlparse url username Nonepassword Noneport Noneif '@' in url[1] ident host_port url[1].split '@' 1 if ' ' in ident username password ident.split ' ' 1 else password identelse host_port url[1]if ' ' in host_port host port host_port.split ' ' 1 else host host_portif port port int port else port dict https 443 http 80 [method]proxy_type 3return ProxyInfo proxy_type proxy_type proxy_host host proxy_port port proxy_user username or None proxy_pass password or None
@app.route '/' def main_page user users.get_current_user game_key request.args.get 'g' if not game_key game_key user.user_id game Game id game_key userX user moveX True board '' * 9 game.put else game Game.get_by_id game_key if not game return 'Nosuchgame' 404 if not game.userO game.userO usergame.put channel_id user.user_id + game_key client_auth_token create_custom_token channel_id _send_firebase_message channel_id message game.to_json game_link '{}?g {}'.format request.base_url game_key template_values {'token' client_auth_token 'channel_id' channel_id 'me' user.user_id 'game_key' game_key 'game_link' game_link 'initial_message' urllib.unquote game.to_json }return flask.render_template 'fire_index.html' **template_values
def sprModelSynth tfreq tmag tphase xr N H fs ys SM.sineModelSynth tfreq tmag tphase N H fs y ys[ min ys.size xr.size ] + xr[ min ys.size xr.size ] return y ys
def image_to_scratch im scratch_image_name im.save scratch_image_name dpi 200 200
def codex_list module codex {}cmd_scribe '%sindex' % SORCERY['scribe'] rc stdout stderr module.run_command cmd_scribe if rc ! 0 module.fail_json 'unabletolistgrimoirecollection fixyourCodex' rex re.compile '^\\s*\\[\\d+\\] ?P<grim>[\\w\\-\\+\\.]+ [\\w\\-\\+\\./]+ ? ?P<ver>[\\w\\-\\+\\.]+ ?\\s*$' for line in stdout.splitlines [4 -1 ] match rex.match line if match codex[match.group 'grim' ] match.group 'ver' if not codex module.fail_json msg 'nogrimoirestooperateon;addatleastone' return codex
def vector_subtract v w return [ v_i - w_i for v_i w_i in zip v w ]
def _save_request_status request key status session_status request.session.get 'import_status' if session_status is None session_status request.session.setdefault 'import_status' {} session_status[key] statusrequest.session.save
def save_fibers oldhdr oldfib fname indices hdrnew oldhdr.copy outstreams []for i in indices outstreams.append oldfib[i] n_fib_out len outstreams hdrnew[u'n_count'] n_fib_outiflogger.info u'Writingfinalnon-orphanfibersas%s' % fname nb.trackvis.write fname outstreams hdrnew return n_fib_out
def diamond radius dtype np.uint8 L np.arange 0 radius * 2 + 1 I J np.meshgrid L L return np.array np.abs I - radius + np.abs J - radius < radius dtype dtype
def _ModifiedSizer compute_value_size modify_value def SpecificSizer field_number is_repeated is_packed tag_size _TagSize field_number if is_packed local_VarintSize _VarintSizedef PackedFieldSize value result 0for element in value result + compute_value_size modify_value element return result + local_VarintSize result + tag_size return PackedFieldSizeelif is_repeated def RepeatedFieldSize value result tag_size * len value for element in value result + compute_value_size modify_value element return resultreturn RepeatedFieldSizeelse def FieldSize value return tag_size + compute_value_size modify_value value return FieldSizereturn SpecificSizer
def ecp_auth_request cls entityid None relay_state '' sign False eelist []my_url cls.service_url BINDING_PAOS paos_request paos.Request must_understand '1' actor ACTOR response_consumer_url my_url service SERVICE eelist.append element_to_extension_element paos_request relay_state ecp.RelayState actor ACTOR must_understand '1' text relay_state eelist.append element_to_extension_element relay_state header soapenv.Header header.extension_elements eelistlogger.info 'entityid %s binding %s' % entityid BINDING_SOAP location cls._sso_location entityid binding BINDING_SOAP req_id authn_req cls.create_authn_request location binding BINDING_PAOS service_url_binding BINDING_PAOS body soapenv.Body body.extension_elements [element_to_extension_element authn_req ]soap_envelope soapenv.Envelope header header body body return req_id '%s' % soap_envelope
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def create_deep_key *path_info validated_path_info []for level_info in path_info if len level_info 3 key_is_id level_info[2]elif len level_info 2 key_is_id Falseelse raise bulkloader_errors.InvalidConfiguration 'Eachlistincreate_deep_keymustspecifyexactly2or3parameters kind property is_id False .Youspecified %s' % repr path_info kind_name level_info[0]property_name level_info[1]validated_path_info.append kind_name property_name key_is_id def create_deep_key_lambda value bulkload_state path []for kind_name property_name key_is_id in validated_path_info if property_name is CURRENT_PROPERTY name_or_id valueelse name_or_id bulkload_state.current_dictionary[property_name]if key_is_id name_or_id int name_or_id path + [kind_name name_or_id]return datastore.Key.from_path *path return create_deep_key_lambda
def _get_marker_param request return request.GET['marker']
def addPixelTableToPixelTable fromPixelTable intoPixelTable for fromPixelTableKey in fromPixelTable.keys intoPixelTable[fromPixelTableKey] fromPixelTable[fromPixelTableKey]
def fail msg None _report_failure msg
def check_paired_arrays X Y X Y check_pairwise_arrays X Y if X.shape ! Y.shape raise ValueError 'XandYshouldbeofsameshape.Theywererespectively%rand%rlong.' % X.shape Y.shape return X Y
def shlex_split s if not six.PY2 or isinstance s bytes return shlex.split s elif isinstance s six.text_type bs s.encode 'utf-8' return [c.decode 'utf-8' for c in shlex.split bs ]else raise TypeError u'shlex_splitcalledwithnon-string'
def _search_dialog parent from tkinter import Toplevel Textfrom tkinter.ttk import Buttonbox Toplevel parent box.title 'TestSearchDialog' x y map int parent.geometry .split '+' [1 ] box.geometry '+%d+%d' % x y + 175 text Text box inactiveselectbackground 'gray' text.pack text.insert 'insert' 'Thisisasamplestring.\n' * 5 def show_find text.tag_add 'sel' '1.0' 'end' _setup text .open text text.tag_remove 'sel' '1.0' 'end' button Button box text 'Search selectionignored ' command show_find button.pack
def find_uncommitted_filefields sender instance **kwargs uncommitted instance._uncommitted_filefields []fields sender._meta.fieldsif kwargs.get 'update_fields' None update_fields set kwargs['update_fields'] fields update_fields.intersection fields for field in fields if isinstance field FileField if not getattr instance field.name ._committed uncommitted.append field.name
def delete_neutron_ports ports for port in ports device ip_lib.IPDevice port if device.exists device.link.delete LOG.info _LI 'Deletingport %s' port
def create_xml_str xml conn __get_conn return conn.createXML xml 0 is not None
def caller_name skip 2 stack inspect.stack start 0 + skip if len stack < start + 1 return ''parentframe stack[start][0]name []module inspect.getmodule parentframe if module name.append module.__name__ if 'self' in parentframe.f_locals name.append parentframe.f_locals['self'].__class__.__name__ codename parentframe.f_code.co_nameif codename ! '<module>' name.append codename del parentframereturn '.'.join name
def p_rule p p[0] p[1] [p[3]]
def _dismiss_notification request course_action_state_id try action_state CourseRerunState.objects.find_first id course_action_state_id except CourseActionStateItemNotFoundError return HttpResponseBadRequest if action_state.state CourseRerunUIStateManager.State.FAILED remove_all_instructors action_state.course_key action_state.delete return JsonResponse {'success' True}
def decode_dict data rv {}for key value in six.iteritems data if isinstance key six.text_type and six.PY2 key key.encode 'utf-8' if isinstance value six.text_type and six.PY2 value value.encode 'utf-8' elif isinstance value list value decode_list value elif isinstance value dict value decode_dict value rv[key] valuereturn rv
def no_debug_mode fn @functools.wraps fn def wrapped *args **kwargs orig_mode config.modeif orig_mode in ['DebugMode' 'DEBUG_MODE'] config.mode 'FAST_RUN'try return fn *args **kwargs finally config.mode orig_modereturn wrapped
def walk_directory basedir followlinks True import loggertraversed [os.path.abspath basedir ]def _inner root directories files for directory in directories path os.path.join root directory if followlinks and os.path.islink path real_path os.path.abspath os.readlink path if real_path in traversed logger.debug "Skipping'%s'sinceitisasymlinkto'%s' whichisalreadyvisited." path real_path else traversed.append real_path for args in os.walk real_path for result in _inner *args yield result yield root directories files for args in os.walk basedir for result in _inner *args yield result
def decade_down x base 10 lx math.floor math.log x / math.log base return base ** lx
def _rec_validate f g i K if type g is not list if K is not None and not K.of_type g raise TypeError '%sin%sinnotoftype%s' % g f K.dtype return set [ i - 1 ] elif not g return set [i] else j levels i + 1 set [] for c in g levels | _rec_validate f c i + 1 K return levels
def MarkFlagAsRequired flag_name flag_values FLAGS RegisterValidator flag_name lambda value value is not None message 'Flag--%smustbespecified.' % flag_name flag_values flag_values
def validate_css stylesheet images assert isinstance stylesheet unicode validator StylesheetValidator images return validator.parse_and_validate stylesheet
def ensureNotImported moduleNames errorMessage preventImports [] for name in moduleNames if sys.modules.get name is not None raise ImportError errorMessage for name in preventImports sys.modules[name] None
def post_delete_profile instance sender **kwargs if not instance.is_superuser current_site Site.objects.get_current SitePeople.objects.get site current_site .people.remove instance
@mobile_template 'users/{mobile/}pw_reset_sent.html' def password_reset_sent request template return render request template
def is_valid_port entry allow_zero False try value int entry if str value ! str entry return Falseelif allow_zero and value 0 return Trueelse return value > 0 and value < 65536 except TypeError if isinstance entry tuple list for port in entry if not is_valid_port port allow_zero return Falsereturn Trueelse return Falseexcept ValueError return False
@must_have_addon SHORT_NAME 'node' @must_be_addon_authorizer SHORT_NAME def s3_folder_list node_addon **kwargs return node_addon.get_folders
def urlsafe_decrypt key ciphertext ciphertext base64.urlsafe_b64decode str ciphertext cypher AES.new key AES.MODE_CBC ciphertext[ 16] padded cypher.decrypt ciphertext[16 ] return padded[ padded.rfind chr 0 ]
def easy_install package try easy.main ['-U' package] return Trueexcept print 'Unabletoinstall%susingeasy_install.Pleasereadtheinstructionsformanualinstallation..Exiting' % package print 'Error %s %s' % exc_info [0] exc_info [1] return False
def _fiff_get_fid fname if isinstance fname string_types if op.splitext fname [1].lower '.gz' logger.debug 'Usinggzip' fid GzipFile fname 'rb' else logger.debug 'UsingnormalI/O' fid open fname 'rb' else fid fnamefid.seek 0 return fid
def test_roc_auc_one_vs_one skip_if_no_sklearn trainer yaml_parse.load test_yaml_ovo trainer.main_loop
def iter_item item for i in range item.rowCount yield item.child i
def enumeration *values **kwargs if not values and all isinstance value string_types and value for value in values raise ValueError 'expectedanon-emptysequenceofstrings got%s' % values if len values ! len set values raise ValueError 'enumerationitemsmustbeunique got%s' % values attrs dict [ value value for value in values] attrs.update {'_values' list values '_default' values[0] '_case_sensitive' kwargs.get 'case_sensitive' True } return type 'Enumeration' Enumeration attrs
def complete_base prefix line start end ctx if line.strip '' out complete_python prefix line start end ctx | complete_command prefix line start end ctx paths complete_path prefix line start end ctx False return out | paths[0] paths[1] elif prefix line python_comps complete_python prefix line start end ctx if isinstance python_comps cabc.Sequence return python_comps[0] | complete_command prefix line start end ctx python_comps[1] else return python_comps | complete_command prefix line start end ctx return set
def wminkowski u v p w u _validate_vector u v _validate_vector v w _validate_vector w if p < 1 raise ValueError 'pmustbeatleast1' dist norm w * u - v ord p return dist
def commit_manually using None warnings.warn 'commit_manuallyisdeprecatedinfavorofset_autocommit.' PendingDeprecationWarning stacklevel 2 def entering using enter_transaction_management using using def exiting exc_type using leave_transaction_management using using return _transaction_func entering exiting using
def build_all html latex
def _dict_from_path path val delimiter DEFAULT_TARGET_DELIM nested_dict _infinitedict keys path.rsplit delimiter lastplace reduce operator.getitem keys[ -1 ] nested_dict lastplace[keys[ -1 ]] valreturn nested_dict
def term_translation_update_many context data_dict model context['model']if not data_dict.get 'data' and isinstance data_dict.get 'data' list raise ValidationError {'error' 'term_translation_update_manyneedstohavealistofdictsinfielddata'} context['defer_commit'] Trueaction _get_action 'term_translation_update' for num row in enumerate data_dict['data'] action context row model.Session.commit return {'success' '%srowsupdated' % num + 1 }
def wavread filename if os.path.isfile filename False raise ValueError 'Inputfileiswrong' fs x read filename if len x.shape ! 1 raise ValueError 'Audiofileshouldbemono' if fs ! 44100 raise ValueError 'Samplingrateofinputsoundshouldbe44100' x np.float32 x / norm_fact[x.dtype.name] return fs x
def pretty_choice_dict d return pretty_choice_list [ '%s %s' % k d[k] for k in sorted d.keys ]
def roles_list roles []for role in ROLE_PERMISSIONS roles.append dict text trans_role role value role return roles
@pytest.mark.parametrize u'text1 text2' [ u'cat' u'dog' ] def test_issue361 en_vocab text1 text2 assert en_vocab[text1] en_vocab[text1] assert en_vocab[text1] ! en_vocab[text2]
def length_of_geographical_area_code numobj metadata PhoneMetadata.metadata_for_region region_code_for_number numobj None if metadata is None return 0if metadata.national_prefix is None and not numobj.italian_leading_zero return 0if not _is_number_geographical numobj return 0return length_of_national_destination_code numobj
def xticks *args **kwargs ax gca if len args 0 locs ax.get_xticks labels ax.get_xticklabels elif len args 1 locs ax.set_xticks args[0] labels ax.get_xticklabels elif len args 2 locs ax.set_xticks args[0] labels ax.set_xticklabels args[1] **kwargs else raise TypeError u'Illegalnumberofargumentstoxticks' if len kwargs for l in labels l.update kwargs return locs silent_list u'Textxticklabel' labels
def osx_hibernate osx_standby
def parse_iscsiname rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 args clean_args vars parser.parse_args rules parser Nonereturn args
def _limit query hints if hints.limit original_len query.count limit_query query.limit hints.limit['limit'] if limit_query.count < original_len hints.limit['truncated'] Truequery limit_queryreturn query
def protocolNegotiationMechanisms support ProtocolNegotiationSupport.NOSUPPORTctx SSL.Context SSL.SSLv23_METHOD try ctx.set_npn_advertise_callback lambda c None except AttributeError NotImplementedError passelse support | ProtocolNegotiationSupport.NPNtry ctx.set_alpn_select_callback lambda c None except AttributeError NotImplementedError passelse support | ProtocolNegotiationSupport.ALPNreturn support
def test_mpl_preserve_face_color f create_figure width height f.canvas.get_width_height s mplhooks.figure_to_tight_array f 0.5 * width 0.5 * height True exp FACE_COLORobs f.get_facecolor plt.close f assert exp obs
def mofile mofile **kwargs return _pofile_or_mofile mofile 'mofile' **kwargs
def survey_getAllWidgetsForTemplate template_id s3db current.s3dbqltable s3db.survey_question_listqtable s3db.survey_questionquery qltable.template_id template_id & qltable.question_id qtable.id rows current.db query .select qtable.id qtable.code qtable.type qltable.posn widgets {}for row in rows sqrow row.survey_questionqstn_type sqrow.typeqstn_id sqrow.idqstn_code sqrow.codeqstn_posn row.survey_question_list.posnwidget_obj survey_question_type[qstn_type] qstn_id widgets[qstn_code] widget_objwidget_obj.question['posn'] qstn_posnreturn widgets
@register_opt @local_optimizer [SparseBlockGemv GpuFromHost] def gpu_sparse_block_gemv_opt node if isinstance node.op SparseBlockGemv and any _owner_isinstance inp HostFromGpu for inp in node.inputs inputs _clear_host_from_gpu node.inputs return [host_from_gpu GpuSparseBlockGemv node.op.inplace *inputs ]elif isinstance node.op GpuFromHost and _owner_isinstance node.inputs[0] SparseBlockGemv meta_node node.inputs[0].ownerinputs _clear_host_from_gpu meta_node.inputs return [GpuSparseBlockGemv meta_node.op.inplace *inputs ]
def dnsdomain_get_all context return IMPL.dnsdomain_get_all context
def date value arg None from django.utils.dateformat import formatif not value return ''if arg is None arg settings.DATE_FORMATreturn format value arg
def _convert_colors colors to_rgb mpl.colors.colorConverter.to_rgbif isinstance colors pd.DataFrame return pd.DataFrame {col colors[col].map to_rgb for col in colors} elif isinstance colors pd.Series return colors.map to_rgb else try to_rgb colors[0] return list map to_rgb colors except ValueError return [list map to_rgb l for l in colors]
def _diff_env a b seta set [ k a[k] for k in a] setb set [ k b[k] for k in b] return dict seta - setb dict setb - seta
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def has_targets available required grouped group_list_of_dict available for value field in required if field not in grouped or value not in grouped[field] return Falsereturn True
def load_fp source module_name thrift parse_fp source module_name sys.modules[module_name] thriftreturn thrift
@register.inclusion_tag 'downloads/templatetags/os_release_files.html' def os_release_files release os_slug return {'release' release 'files' release.files_for_os os_slug }
def random_normal return inverse_normal_cdf random.random
def stats_data return s3_rest_controller
def _schema_validation_helper schema target min_version max_version args kwargs is_body True min_ver api_version.APIVersionRequest min_version max_ver api_version.APIVersionRequest max_version if 'req' in kwargs ver kwargs['req'].api_version_requestlegacy_v2 kwargs['req'].is_legacy_v2 else ver args[1].api_version_requestlegacy_v2 args[1].is_legacy_v2 if legacy_v2 if min_version is None or min_version '2.0' schema_validator validators._SchemaValidator schema legacy_v2 is_body schema_validator.validate target return Trueelif ver.matches min_ver max_ver schema_validator validators._SchemaValidator schema legacy_v2 is_body schema_validator.validate target return Truereturn False
def is_affiliated if not auth.is_logged_in return Falseelif s3_has_role ADMIN return Trueelse table auth.settings.table_userauth_user db table.id auth.user.id .select table.organisation_id limitby 0 1 .first if auth_user and auth_user.organisation_id return Trueelse return False
def process_bezout_output poly_seq x L poly_seq[ ]d degree L[1] x i 2while i < len L d_i degree L[i] x if d_i < 0 L.remove L[i] i i - 1 if d d_i L.remove L[i] i i - 1 if d_i > 0 d d_ii i + 1 return L
def get_first_loader if settings.TEMPLATES loaders settings.TEMPLATES[0].get u'OPTIONS' {} .get u'loaders' [[u'']] else loaders settings.TEMPLATE_LOADERSif isinstance loaders[0] six.string_types return loaders[0]return loaders[0][0]
def get_ninja_file path extension only_first False files os.listdir path if not extension.startswith '.' extension '.'.join extension found list [y for y in files if y.endswith extension ] if only_first found found[0] if found else [] return found
def body_length bytearray return sum len _QUOPRI_BODY_MAP[octet] for octet in bytearray
def _Strptime arg strptime_format split_arg arg.split '.' datetime_obj datetime.datetime.strptime split_arg[0] strptime_format if len split_arg 2 datetime_obj datetime_obj.replace microsecond int split_arg[1] return datetime_obj
def before_scenario context scenario context.messages StringIO jrnl.util.STDERR context.messagesjrnl.util.TEST Truefor folder in 'configs' 'journals' working_dir os.path.join 'features' folder if os.path.exists working_dir shutil.rmtree working_dir for folder in 'configs' 'journals' original os.path.join 'features' 'data' folder working_dir os.path.join 'features' folder if not os.path.exists working_dir os.mkdir working_dir for filename in os.listdir original source os.path.join original filename if os.path.isdir source shutil.copytree source os.path.join working_dir filename else shutil.copy2 source working_dir
def binned_statistic_2d x y values statistic 'mean' bins 10 range None expand_binnumbers False try N len bins except TypeError N 1if N ! 1 and N ! 2 xedges yedges np.asarray bins float bins [xedges yedges] medians edges binnumbers binned_statistic_dd [x y] values statistic bins range expand_binnumbers expand_binnumbers return BinnedStatistic2dResult medians edges[0] edges[1] binnumbers
def antidivisors n generator False n as_int abs n if n < 2 return []rv _antidivisors n if not generator return sorted rv return rv
def matrix m n a 0.0 b 0.0 if a b 0 return [ [0.0] * n for i in xrange m ]return [[uniform a b for j in xrange n ] for i in xrange m ]
def print_trends trends for topic in trends[ c['TREND_MAX']] name topic['name']url topic['url']line cycle_color name + ' ' + color_func c['TREND']['url'] url printNicely line printNicely ''
def oauth_token_info_from_url url if isinstance url str unicode url atom.http_core.Uri.parse_uri url token Noneverifier Noneif 'oauth_token' in url.query token urllib.unquote url.query['oauth_token'] if 'oauth_verifier' in url.query verifier urllib.unquote url.query['oauth_verifier'] return token verifier
def name_from_path path collection path path.strip '/' + '/' start collection.path + '/' if not path.startswith start raise ValueError "'%s'doesn'tstartwith'%s'" % path start return path[len start ].rstrip '/'
def get_prefetcher instance attr prefetcher Noneattr_found Falseis_fetched Falserel_obj_descriptor getattr instance.__class__ attr None if rel_obj_descriptor is None try rel_obj getattr instance attr attr_found Trueexcept AttributeError passelse attr_found Trueif rel_obj_descriptor if hasattr rel_obj_descriptor 'get_prefetch_query_set' prefetcher rel_obj_descriptorif rel_obj_descriptor.is_cached instance is_fetched Trueelse rel_obj getattr instance attr if hasattr rel_obj 'get_prefetch_query_set' prefetcher rel_objreturn prefetcher rel_obj_descriptor attr_found is_fetched
def count_newlines value return len newline_re.findall value
def test_skipping_setuptools_doesnt_skip_legacy script data result script.pip 'install' 'script.wheel2 0.1' '--no-index' '--find-links ' + data.find_links expect_error False legacy_file1 script.bin / 'testscript1.bat' legacy_file2 script.bin / 'testscript2' wrapper_helper script.bin / 't1-script.py' assert legacy_file1 in result.files_created assert legacy_file2 in result.files_created assert wrapper_helper not in result.files_created
def create_var size var_id None if var_id is None var_id get_id return lo.LinOp lo.VARIABLE size [] var_id
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def generate_bin_search_paths program extra_dirs if os.sep in program paths [program]else arg_paths itertools.chain os.environ.get 'PATH' '' .split os.pathsep extra_dirs search_paths unique_not_false_list arg_paths paths path_joiner program search_paths return paths
def format_number numobj num_format if numobj.national_number 0 and numobj.raw_input is not None if len numobj.raw_input > 0 return numobj.raw_inputcountry_calling_code numobj.country_codensn national_significant_number numobj if num_format PhoneNumberFormat.E164 return _prefix_number_with_country_calling_code country_calling_code num_format nsn if not _has_valid_country_calling_code country_calling_code return nsnregion_code region_code_for_country_code country_calling_code metadata PhoneMetadata.metadata_for_region_or_calling_code country_calling_code region_code.upper formatted_number _format_nsn nsn metadata num_format formatted_number _maybe_append_formatted_extension numobj metadata num_format formatted_number return _prefix_number_with_country_calling_code country_calling_code num_format formatted_number
def p_multiplicative_expression_3 t pass
def tree plist l a f if l > 3 lst []for p in plist p.forward l q p.clone p.left a q.right a lst.append p lst.append q for x in tree lst l * f a f yield None
def shrunk_covariance emp_cov shrinkage 0.1 emp_cov check_array emp_cov n_features emp_cov.shape[0]mu np.trace emp_cov / n_features shrunk_cov 1.0 - shrinkage * emp_cov shrunk_cov.flat[ n_features + 1 ] + shrinkage * mu return shrunk_cov
def test_xtfuncs cosmo core.LambdaCDM 70 0.3 0.5 z np.array [2.0 3.2] assert allclose cosmo.lookback_time_integrand 3 0.05221897665496938 rtol 0.0001 assert allclose cosmo.lookback_time_integrand z [0.10333179 0.04644541] rtol 0.0001 assert allclose cosmo.abs_distance_integrand 3 3.34201450591804 rtol 0.0001 assert allclose cosmo.abs_distance_integrand z [2.7899584 3.44104758] rtol 0.0001
def MakeResponse code 500 data '' response requests.Response response.status_code coderesponse._content datareturn response
@require_context@pick_context_manager_writerdef instance_remove_security_group context instance_uuid security_group_id model_query context models.SecurityGroupInstanceAssociation .filter_by instance_uuid instance_uuid .filter_by security_group_id security_group_id .soft_delete
def check name port None **kwargs host nameret {'name' name 'result' True 'changes' {} 'comment' ''}if 'test' not in kwargs kwargs['test'] __opts__.get 'test' False if kwargs['test'] ret['result'] Trueret['comment'] 'Theconnectionwillbetested'else results __salt__['network.connect'] host port **kwargs ret['result'] results['result']ret['comment'] results['comment']return ret
def cons el seq yield el for s in seq yield s
def SequenceToConjunction node return ConvertNodes node QueryParser.SEQUENCE QueryParser.CONJUNCTION 'CONJUNCTION'
def user_messages_nocache user from r2.lib.db import queriesinbox queries.get_inbox_messages user sent queries.get_sent user messages _load_messages list chain inbox sent return compute_message_trees messages
def _transform_index index func if isinstance index MultiIndex items [tuple func y for y in x for x in index]return MultiIndex.from_tuples items names index.names else items [func x for x in index]return Index items name index.name
def SerialCorr series lag 1 xs series[lag ]ys series.shift lag [lag ]corr Corr xs ys return corr
def teardown_paste_factories global app_factory filter_factorydel app_factorydel filter_factory
def set_owner_process uid gid initgroups False if gid if uid try username get_username uid except KeyError initgroups Falsegid abs gid & 2147483647 if initgroups os.initgroups username gid else os.setgid gid if uid os.setuid uid
def _exec_query_ps cmd fields if not WINDOWS returnps sp.Popen [conf.prog.powershell] + cmd + ['|' 'select%s' % ' '.join fields '|' 'fl'] stdout sp.PIPE universal_newlines True l []for line in ps.stdout if not line.strip continuesl line.split ' ' 1 if len sl 1 l[ -1 ] + sl[0].strip continueelse l.append sl[1].strip if len l len fields yield l l []
def normalizeColumn column median getMedian column asd sum [abs x - median for x in column] / len column result [ x - median / asd for x in column]return result
def _blkid fs_type None flt lambda data [el for el in data if el.strip ] data dict for dev_meta in flt os.popen 'blkid-ofull' .read .split os.linesep dev_meta dev_meta.strip if not dev_meta continuedevice dev_meta.split '' dev_name device.pop 0 [ -1 ]data[dev_name] dict for k_set in device ks_key ks_value [elm.replace '"' '' for elm in k_set.split ' ' ]data[dev_name][ks_key.lower ] ks_valueif fs_type mounts _get_mounts fs_type for device in six.iterkeys mounts if data.get device data[device]['mounts'] mounts[device]return data
def get_all_vlanids LOG.debug _ 'get_all_vlanids called' session db.get_session try vlanids session.query network_models_v2.VlanID .all return vlanidsexcept exc.NoResultFound return []
def query2str items max_length 1024 kvs []for k v in items if k ! PASSWORD_FORM_FIELD kvs.append six.u '%s %s' % k v return '\n'.join kvs [ max_length]
def volume_type_access_get_all context type_id return IMPL.volume_type_access_get_all context type_id
def id return _distro.id
def _AdjustSplitPenalty uwline bracket_level 0for index token in enumerate uwline.tokens if index and not bracket_level pytree_utils.SetNodeAnnotation token.node pytree_utils.Annotation.SPLIT_PENALTY split_penalty.UNBREAKABLE if token.value in pytree_utils.OPENING_BRACKETS bracket_level + 1elif token.value in pytree_utils.CLOSING_BRACKETS bracket_level - 1
def _get_api_params api_url None page_id None api_key None api_version None statuspage_cfg __salt__['config.get'] 'statuspage' if not statuspage_cfg statuspage_cfg {}return {'api_url' api_url or statuspage_cfg.get 'api_url' or BASE_URL 'api_page_id' page_id or statuspage_cfg.get 'page_id' 'api_key' api_key or statuspage_cfg.get 'api_key' 'api_version' api_version or statuspage_cfg.get 'api_version' or DEFAULT_VERSION }
@require_POST@login_required@permitteddef create_sub_comment request course_id comment_id if is_comment_too_deep parent cc.Comment comment_id return JsonError _ 'Commentleveltoodeep' return _create_comment request CourseKey.from_string course_id parent_id comment_id
def _is_unpacked_egg path return path.lower .endswith '.egg'
def _SimpleSizer compute_value_size def SpecificSizer field_number is_repeated is_packed tag_size _TagSize field_number if is_packed local_VarintSize _VarintSizedef PackedFieldSize value result 0for element in value result + compute_value_size element return result + local_VarintSize result + tag_size return PackedFieldSizeelif is_repeated def RepeatedFieldSize value result tag_size * len value for element in value result + compute_value_size element return resultreturn RepeatedFieldSizeelse def FieldSize value return tag_size + compute_value_size value return FieldSizereturn SpecificSizer
def has_python_3 if 'win' in sys.platform py_bin 'py.exe'else py_bin 'python3'for path in os.environ['PATH'].split os.pathsep if os.access os.path.join path py_bin os.X_OK return Truereturn False
def sign_and_send_replace_result assignment xml outcome_service assignment.outcome_serviceconsumer outcome_service.lti_consumerconsumer_key consumer.consumer_keyconsumer_secret consumer.consumer_secretoauth requests_oauthlib.OAuth1 consumer_key consumer_secret signature_method 'HMAC-SHA1' force_include_body True headers {'content-type' 'application/xml'}response requests.post assignment.outcome_service.lis_outcome_service_url data xml auth oauth headers headers return response
def load_extra_vi_page_navigation_bindings registry ConditionalRegistry Registry ViMode handle registry.add_bindinghandle Keys.ControlF scroll_forward handle Keys.ControlB scroll_backward handle Keys.ControlD scroll_half_page_down handle Keys.ControlU scroll_half_page_up handle Keys.ControlE scroll_one_line_down handle Keys.ControlY scroll_one_line_up handle Keys.PageDown scroll_page_down handle Keys.PageUp scroll_page_up return registry
def expr expr c test_expr expr _expr_codes return eval c
def _aggr_sum inList aggrMean _aggr_mean inList if aggrMean None return NoneaggrSum 0for elem in inList if elem ! SENTINEL_VALUE_FOR_MISSING_DATA aggrSum + elemelse aggrSum + aggrMeanreturn aggrSum
def ComputeErrorRates label_counts word_counts seq_errors num_seqs label_errors label_counts.fn + label_counts.fp num_labels label_counts.truth_count + label_counts.test_count return ErrorRates ComputeErrorRate label_errors num_labels ComputeErrorRate word_counts.fn word_counts.truth_count ComputeErrorRate word_counts.fp word_counts.test_count ComputeErrorRate seq_errors num_seqs
def socket_exception func def read self *args **kwargs try return func self *args **kwargs except socket.error self.close return read
def _api_queue_delete_nzf output value kwargs value2 kwargs.get 'value2' if value and value2 removed NzbQueue.do.remove_nzf value value2 force_delete True return report output keyword '' data {'status' bool removed 'nzf_ids' removed} else return report output _MSG_NO_VALUE2
def encode_deflate content return zlib.compress content
def REGIONS_LIST_SORTED_BY_NAME from mkt.regions.utils import remove_accentsby_name sorted [v for k v in DEFINED if v.id and v.weight > -1 ] key lambda v remove_accents unicode v.name by_name.append RESTOFWORLD return by_name
def E_nl n Z 1 n Z S n S Z if n.is_integer and n < 1 raise ValueError "'n'mustbepositiveinteger" return - Z ** 2 / 2 * n ** 2
def cleanup_dirs patterns dry_run False workdir '.' current_dir Path workdir python_basedir Path Path sys.executable .dirname .joinpath '..' .abspath warn2_counter 0for dir_pattern in patterns for directory in path_glob dir_pattern current_dir directory2 directory.abspath if sys.executable.startswith directory2 print "SKIP-SUICIDE '%s'containscurrentpythonexecutable" % directory continueelif directory2.startswith python_basedir if warn2_counter < 4 print "SKIP-SUICIDE '%s'" % directory warn2_counter + 1continueif dry_run print 'RMTREE %s dry-run ' % directory else print 'RMTREE %s' % directory directory.rmtree_p
@_ConfigurableFilter executable 'HTML_TIDY_EXECUTABLE' def html_tidy_wrap_attr infile executable 'tidy5' return _html_tidy_runner infile '-quiet--show-infono--show-warningsno-utf8-indent--indent-attributesyes--sort-attributesalpha--wrap80--wrap-sectionsno--drop-empty-elementsno--tidy-markno-modify%1' executable executable
def dmp_grounds c n u if not n return []if u < 0 return [c] * n else return [dmp_ground c u for i in range n ]
@permission_required 'questions.tag_question' @require_POSTdef remove_tag_async request question_id name request.POST.get 'name' if name question get_object_or_404 Question pk question_id question.tags.remove name question.clear_cached_tags return HttpResponse '{}' content_type 'application/json' return HttpResponseBadRequest json.dumps {'error' unicode NO_TAG } content_type 'application/json'
def dict_to_vec val_dict var_offsets var_sizes vec_len vector np.zeros vec_len for id_ value in val_dict.items size var_sizes[id_]offset var_offsets[id_]for col in range size[1] if np.isscalar value vector[offset size[0] + offset ] valueelse vector[offset size[0] + offset ] np.squeeze value[ col] offset + size[0]return vector
def submit_executive_summary_report request course_key task_type 'exec_summary_report'task_class exec_summary_report_csvtask_input {}task_key ''return submit_task request task_type task_class course_key task_input task_key
def flatten expr new new cls expr.__class__args []for arg in expr.args if arg.__class__ cls args.extend arg.args else args.append arg return new expr.__class__ *args
def unescape_glob string def unescape s for pattern in '*[]!?' s s.replace '\\{0}'.format pattern pattern return sreturn '\\'.join map unescape string.split '\\\\'
def shade_other_data y x np.mgrid[ -4 2 200j -4 2 200j]z1 np.sin x ** 2 z2 np.cos x ** 2 + y ** 2 norm Normalize z2.min z2.max cmap plt.cm.RdBuls LightSource 315 45 rgb ls.shade_rgb cmap norm z2 z1 fig ax plt.subplots ax.imshow rgb interpolation 'bilinear' ax.set_title 'Shadebyonevariable colorbyanother' size 'x-large'
def ec2_client region zone access_key_id secret_access_key session_token None validate_region True connection boto3.session.Session aws_access_key_id access_key_id aws_secret_access_key secret_access_key aws_session_token session_token connection._session.set_config_variable 'metadata_service_num_attempts' BOTO_NUM_RETRIES ec2_resource connection.resource 'ec2' region_name region if validate_region try zones ec2_resource.meta.client.describe_availability_zones except EndpointConnectionError raise InvalidRegionError region available_zones [available_zone['ZoneName'] for available_zone in zones['AvailabilityZones']]if zone not in available_zones raise InvalidZoneError zone available_zones return _EC2 zone zone connection ec2_resource
def _find_review_request request review_request_id local_site review_request _find_review_request_object review_request_id local_site if review_request.is_accessible_by request.user return review_request None else return None _render_permission_denied request
def provides_cors_features freq url_opener response url_opener.GET freq.get_url ac_value retrieve_cors_header response ACCESS_CONTROL_ALLOW_ORIGIN if ac_value is not None return Trueheaders Headers {'Origin' 'www.w3af.org'}.items response url_opener.GET freq.get_url headers headers ac_value retrieve_cors_header response ACCESS_CONTROL_ALLOW_ORIGIN if ac_value is not None return Truereturn False
def increment_ipv4_segments segments segments [int segment for segment in segments]segments[3] + 1if segments[3] 256 segments[3] 0segments[2] + 1if segments[2] 256 segments[2] 0segments[1] + 1if segments[1] 256 segments[1] 0segments[0] + 1return segments
def get_tukeyQcrit2 k df alpha 0.05 from statsmodels.stats.libqsturng import qsturngreturn qsturng 1 - alpha k df
def authenticationRequest a TpPd pd 5 b MessageType mesType 18 c CiphKeySeqNrAndSpareHalfOctets d AuthenticationParameterRAND packet a / b / c / d return packet
def _SplitMIMEType mime_type if mime_type mime_type_array mime_type.split '/' if len mime_type_array 1 raise InvalidMIMETypeFormatError 'MissingMIMEsub-type.' elif len mime_type_array 2 main_type sub_type mime_type_arrayif not main_type and sub_type raise InvalidMIMETypeFormatError 'IncorrectlyformattedMIMEtype %s' % mime_type return main_type sub_type else raise InvalidMIMETypeFormatError 'IncorrectlyformattedMIMEtype %s' % mime_type else return 'application' 'octet-stream'
def input_loop while mestate.exit ! True try if mestate.exit ! True line raw_input mestate.rl.prompt except EOFError mestate.exit Truesys.exit 1 mestate.input_queue.put line
def denumify string pattern out []for c in pattern if c 'X' out.append string[0] string string[1 ]else out.append c return ''.join out
def testComms p snap.Packet snap.localAddress snap.localAddress 0 1 [255 0] p.send notif _getNotification serialPort if notif.dataBytes[0] 255 return Truereturn False
def sample prediction size vocabulary_size p np.zeros shape [1 size] dtype np.float p[ 0 sample_distribution prediction[0] ] 1.0return p
def current_service request if request.matched_route services request.registry.cornice_servicespattern request.matched_route.patterntry service services[pattern]except KeyError return Noneelse return service
def getboolean s return _default_root.tk.getboolean s
def sha1_hash_digest payload return base64.b64encode hashlib.sha1 payload .digest
def transact_block request connection error connection.send request reply Noneif error return error reply ovs_poller poller.Poller while not error ovs_poller.immediate_wake error reply connection.recv if error ! errno.EAGAIN breakif reply and reply.id request.id and reply.type in jsonrpc.Message.T_REPLY jsonrpc.Message.T_ERROR breakconnection.run connection.wait ovs_poller connection.recv_wait ovs_poller ovs_poller.block hub.sleep 0 return error reply
def command_shell command command_args [] **kwds return argv_to_str command_list command command_args **kwds
@ioflo.base.deeding.deedify 'SaltRaetMaintFork' ioinits {'opts' '.salt.opts' 'proc_mgr' '.salt.usr.proc_mgr'} def maint_fork self self.proc_mgr.value.add_process Maintenance args self.opts.value
def message_destroy context message_id return IMPL.message_destroy context message_id
def MakeHistFromDict d label None return Hist d label
def apply_with_random_selector x func num_cases sel tf.random_uniform [] maxval num_cases dtype tf.int32 return control_flow_ops.merge [func control_flow_ops.switch x tf.equal sel case [1] case for case in range num_cases ] [0]
def gpu_count try output subprocess.check_output 'nvidia-smi-L' return len output.strip .split '\n' except return 0
def random_string_param registry xml_parent data pdef XML.SubElement xml_parent 'hudson.plugins.random__string__parameter.RandomStringParameterDefinition' if 'name' not in data raise JenkinsJobsException 'random-stringmusthaveanameparameter.' XML.SubElement pdef 'name' .text data['name']XML.SubElement pdef 'description' .text data.get 'description' '' XML.SubElement pdef 'failedValidationMessage' .text data.get 'failed-validation-message' ''
def koans filename KOANS_FILENAME names names_from_file filename return koans_suite names
@lru_cache 1 def get_user_flagger user_klass get_user_model try user user_klass.objects.get pk COMMENT_FLAG_USER_ID except user_klass.DoesNotExist try user user_klass.objects.get **{user_klass.USERNAME_FIELD FLAGGER_USERNAME} except user_klass.DoesNotExist user user_klass.objects.create_user FLAGGER_USERNAME return user
def query_from_strings query_cls model_cls prefixes query_parts subqueries []for part in query_parts subqueries.append construct_query_part model_cls prefixes part if not subqueries subqueries [query.TrueQuery ]return query_cls subqueries
def collect_addon_js node visited None filename 'files.js' config_entry 'files' js []for addon_config in settings.ADDONS_AVAILABLE_DICT.values js.extend addon_config.include_js.get config_entry [] js_path paths.resolve_addon_path addon_config filename if js_path js.append js_path return js
def redo_patch Request.send _request_send_hook
@require_POST@login_required@expect_jsondef handle_ajax request course_key_string course_key CourseKey.from_string course_key_string masquerade_settings request.session.get MASQUERADE_SETTINGS_KEY {} request_json request.jsonrole request_json.get 'role' 'student' group_id request_json.get 'group_id' None user_partition_id request_json.get 'user_partition_id' None if group_id is not None else None user_name request_json.get 'user_name' None if user_name users_in_course CourseEnrollment.objects.users_enrolled_in course_key try if '@' in user_name user_name users_in_course.get email user_name .usernameelse users_in_course.get username user_name except User.DoesNotExist return JsonResponse {'success' False 'error' _ 'Thereisnouserwiththeusernameoremailaddress{user_name}enrolledinthiscourse.' .format user_name user_name } masquerade_settings[course_key] CourseMasquerade course_key role role user_partition_id user_partition_id group_id group_id user_name user_name request.session[MASQUERADE_SETTINGS_KEY] masquerade_settingsreturn JsonResponse {'success' True}
def test_cirs_itrs ra dec _ randomly_sample_sphere 200 cirs CIRS ra ra dec dec obstime u'J2000' cirs6 CIRS ra ra dec dec obstime u'J2006' cirs2 cirs.transform_to ITRS .transform_to cirs cirs6_2 cirs6.transform_to ITRS .transform_to cirs assert_allclose cirs.ra cirs2.ra assert_allclose cirs.dec cirs2.dec assert not allclose cirs.ra cirs6_2.ra assert not allclose cirs.dec cirs6_2.dec
def blockmodel G partition multigraph False if multigraph return nx.quotient_graph G partition create_using nx.MultiGraph relabel True else return nx.quotient_graph G partition relabel True
def get_lighting_value label return _check_range_and_return 'lighting' label -1 5 -1
def lower_column col old Nonewhile col is not None and col is not old old colif not hasattr col 'table' or not hasattr col.table 'froms' return colfor f in col.table.froms if f.corresponding_column col is not None col f.corresponding_column col return old
def inherit_metadata descriptor inherited_data try descriptor.xblock_kvs.inherited_settings inherited_dataexcept AttributeError pass
def finished ignored reactor.stop
def get_shell_code extension command force_extension False result []shellcodes _get_file_list 'code' extension force_extension for file_content real_extension in shellcodes custom_replacer functools.partial cmd_replace file_content this_shellcode custom_replacer command result.append this_shellcode real_extension custom_replacer return result
def get_group_obj_perms_model obj from guardian.models import GroupObjectPermissionBasefrom guardian.models import GroupObjectPermissionreturn get_obj_perms_model obj GroupObjectPermissionBase GroupObjectPermission
def rate_limited min_interval def decorate func last_time_called [0.0]def rate_limited_function *args **kargs elapsed time.time - last_time_called[0] log.debug 'Elapsed%fsincelastcall' % elapsed left_to_wait min_interval - elapsed if left_to_wait > 0 log.debug 'Wait%fduetoratelimiting...' % left_to_wait time.sleep left_to_wait ret func *args **kargs last_time_called[0] time.time return retreturn rate_limited_functionreturn decorate
def dot_mavproxy name None dir os.path.join os.environ['HOME'] '.mavproxy' mkdir_p dir if name is None return dirreturn os.path.join dir name
def perimeter image neighbourhood 4 if neighbourhood 4 strel STREL_4else strel STREL_8image image.astype np.uint8 eroded_image ndi.binary_erosion image strel border_value 0 border_image image - eroded_image perimeter_weights np.zeros 50 dtype np.double perimeter_weights[[5 7 15 17 25 27]] 1perimeter_weights[[21 33]] sqrt 2 perimeter_weights[[13 23]] 1 + sqrt 2 / 2 perimeter_image ndi.convolve border_image np.array [[10 2 10] [2 1 2] [10 2 10]] mode 'constant' cval 0 perimeter_histogram np.bincount perimeter_image.ravel minlength 50 total_perimeter np.dot perimeter_histogram perimeter_weights return total_perimeter
def load_table bigquery project_id dataset_id table_name source_schema source_path num_retries 5 job_data {'jobReference' {'projectId' project_id 'jobId' str uuid.uuid4 } 'configuration' {'load' {'sourceUris' [source_path] 'schema' {'fields' source_schema} 'destinationTable' {'projectId' project_id 'datasetId' dataset_id 'tableId' table_name}}}}return bigquery.jobs .insert projectId project_id body job_data .execute num_retries num_retries
def _system_compute_nrhs b raise NotImplementedError
def null_graph create_using None G empty_graph 0 create_using G.name 'null_graph 'return G
def tb_filename tb return tb.tb_frame.f_code.co_filename
def complete_parameter text return rline_mpstate.mav_param.keys
def keyword_context_from_sample keywords dirname desc uri if uri is None uri BASE_HG_URI + dirname.replace '/' '%2F' else uri ''.join uri context {'keywords' keywords 'dir' dirname 'uri' uri 'desc' wiki_escape desc }return context
def get_cudart if platform.system 'Windows' arch platform.architecture [0]for ver in range 90 50 -5 cudart get_library 'cudart%s_%d.dll' % arch[ 2] ver if cudart is not None return cudartelif platform.system 'Darwin' for major in xrange 9 5 -1 for minor in 5 0 cudart get_library 'libcudart.%d.%d.dylib' % major minor if cudart is not None return cudartreturn get_library 'libcudart.dylib' else for major in xrange 9 5 -1 for minor in 5 0 cudart get_library 'libcudart.so.%d.%d' % major minor if cudart is not None return cudartreturn get_library 'libcudart.so' return None
def getGeometryOutputByLoop elementNode sideLoop sideLoop.rotate elementNode return getGeometryOutputByManipulation elementNode sideLoop
def _has_user_permission_for_groups user_id permission group_ids capacity None if not group_ids return Falseq model.Session.query model.Member .filter model.Member.group_id.in_ group_ids .filter model.Member.table_name 'user' .filter model.Member.state 'active' .filter model.Member.table_id user_id if capacity q q.filter model.Member.capacity capacity for row in q.all perms ROLE_PERMISSIONS.get row.capacity [] if 'admin' in perms or permission in perms return Truereturn False
def _extract_loop_lifting_candidates cfg blocks def same_exit_point loop 'allexitsmustpointtothesamelocation'outedges set for k in loop.exits outedges | set x for x _ in cfg.successors k return len outedges 1 def one_entry loop 'thereisoneentry'return len loop.entries 1 def cannot_yield loop 'cannothaveyieldinsidetheloop'insiders set loop.body | set loop.entries | set loop.exits for blk in map blocks.__getitem__ insiders for inst in blk.body if isinstance inst ir.Assign if isinstance inst.value ir.Yield return Falsereturn Truereturn [loop for loop in find_top_level_loops cfg if same_exit_point loop and one_entry loop and cannot_yield loop ]
def goodDecorator fn def nameCollision *args **kwargs return fn *args **kwargs return mergeFunctionMetadata fn nameCollision
def taint taintedSet taintedAttribute taintedSet.add taintedAttribute if taintedAttribute 'marker' taintedSet | set ['marker-start' 'marker-mid' 'marker-end'] if taintedAttribute in ['marker-start' 'marker-mid' 'marker-end'] taintedSet.add 'marker' return taintedSet
def patch_vary_headers response newheaders if response.has_header 'Vary' vary_headers cc_delim_re.split response['Vary'] else vary_headers []existing_headers set [header.lower for header in vary_headers] additional_headers [newheader for newheader in newheaders if newheader.lower not in existing_headers ]response['Vary'] ' '.join vary_headers + additional_headers
def _SuffixName name suffix parts name.rsplit '#' 1 parts[0] '%s_%s' % parts[0] suffix return '#'.join parts
def register_auth key None cert None store None digest u'sha1' serializer u'json' s SecureSerializer key and PrivateKey key cert and Certificate cert store and FSCertStore store digest digest serializer serializer registry.register u'auth' s.serialize s.deserialize content_type u'application/data' content_encoding u'utf-8'
def set_default_region region global default_regiondefault_region region
def find_unit_clause_int_repr clauses model bound set model | set - sym for sym in model for clause in clauses unbound clause - bound if len unbound 1 p unbound.pop if p < 0 return - p False else return p True return None None
@cmddef test install sh '%s%s' % PYTHON TSCRIPT
def parole2penntreebank token tag return token parole.get tag tag
def eglGetError return _lib.eglGetError
def str2file sourcestring outfile colors None title '' markup 'html' header None footer None linenumbers 0 show 0 dosheet 1 form None css html str2markup sourcestring colors colors title '' markup markup header header footer footer linenumbers linenumbers form form f open outfile 'wt' f.writelines html f.close if css ! None and dosheet dir os.path.dirname outfile outcss os.path.join dir 'pystyle.css' f open outcss 'wt' f.writelines css f.close if show showpage outfile
def _fix_up_parameters method_desc root_desc http_method parameters method_desc.setdefault 'parameters' {} for name description in six.iteritems root_desc.get 'parameters' {} parameters[name] descriptionfor name in STACK_QUERY_PARAMETERS parameters[name] STACK_QUERY_PARAMETER_DEFAULT_VALUE.copy if http_method in HTTP_PAYLOAD_METHODS and 'request' in method_desc body BODY_PARAMETER_DEFAULT_VALUE.copy body.update method_desc['request'] parameters['body'] bodyreturn parameters
def hold a TpPd pd 3 b MessageType mesType 24 packet a / b return packet
def kendall v1 v2 v1 v2 array v1 array v2 if not v1.size v2.size > 1 raise ValueError "Oneormorevectorsisn'tlongenoughtocorrelateortheyhaveunequallengths." return kendalltau v1 v2 [0]
def getXRDExpiration xrd_element default None expires_element xrd_element.find expires_tag if expires_element is None return defaultelse expires_string expires_element.textexpires_time strptime expires_string '%Y-%m-%dT%H %M %SZ' return datetime *expires_time[0 6]
def _get_thread_and_context request thread_id retrieve_kwargs None retrieve_kwargs retrieve_kwargs or {} try if 'with_responses' not in retrieve_kwargs retrieve_kwargs['with_responses'] Falseif 'mark_as_read' not in retrieve_kwargs retrieve_kwargs['mark_as_read'] Falsecc_thread Thread id thread_id .retrieve **retrieve_kwargs course_key CourseKey.from_string cc_thread['course_id'] course _get_course course_key request.user context get_context course request cc_thread if not context['is_requester_privileged'] and cc_thread['group_id'] and is_commentable_cohorted course.id cc_thread['commentable_id'] requester_cohort get_cohort_id request.user course.id if requester_cohort is not None and cc_thread['group_id'] ! requester_cohort raise ThreadNotFoundError 'Threadnotfound.' return cc_thread context except CommentClientRequestError raise ThreadNotFoundError 'Threadnotfound.'
def compute_P_from_essential E U S V svd E if det dot U V < 0 V - V E dot U dot diag [1 1 0] V Z skew [0 0 -1 ] W array [[0 -1 0] [1 0 0] [0 0 1]] P2 [vstack dot U dot W V .T U[ 2] .T vstack dot U dot W V .T - U[ 2] .T vstack dot U dot W.T V .T U[ 2] .T vstack dot U dot W.T V .T - U[ 2] .T]return P2
def to_remote_error error exc_info type error error None serialized rpc_common.serialize_remote_exception exc_info remote_error rpc_common.deserialize_remote_exception serialized ['heat.common.exception'] return remote_error
def _get_conf_tpls image_name kube_annotations None kube_pod_name None kube_container_name None return [ x y for x y in copy.deepcopy TestServiceDiscovery.mock_templates.get image_name [0] ]
def _get_high_intensity_peaks image mask num_peaks coord np.nonzero mask intensities image[coord]sorted_indices np.argsort intensities [ -1 ]if len coord[0] > num_peaks sorted_indices sorted_indices[ num_peaks]return np.transpose coord [sorted_indices]
def _str_to_num val try num int val except ValueError num float val return num
def _has_access_error_desc user action descriptor course_key def check_for_staff return _has_staff_access_to_descriptor user descriptor course_key checkers {'load' check_for_staff 'staff' check_for_staff 'instructor' lambda _has_instructor_access_to_descriptor user descriptor course_key }return _dispatch checkers action user descriptor
def project_info result project_path str result.project project_slug os.path.split project_path [ -1 ]project_dir os.path.join project_path project_slug return project_path project_slug project_dir
def rotate_axes xs ys zs zdir if zdir u'x' return ys zs xs elif zdir u'-x' return zs xs ys elif zdir u'y' return zs xs ys elif zdir u'-y' return ys zs xs else return xs ys zs
@environmentfilterdef do_attr environment obj name try name str name except UnicodeError passelse try value getattr obj name except AttributeError passelse if environment.sandboxed and not environment.is_safe_attribute obj name value return environment.unsafe_undefined obj name return valuereturn environment.undefined obj obj name name
def col_copy col copy_indices True if isinstance col BaseColumn return col.copy parent_table col.info.parent_tableindices col.info.indicescol.info.parent_table Nonecol.info.indices []try newcol col.copy if hasattr col u'copy' else deepcopy col newcol.info col.infonewcol.info.indices deepcopy indices or [] if copy_indices else [] for index in newcol.info.indices index.replace_col col newcol finally col.info.parent_table parent_tablecol.info.indices indicesreturn newcol
def _disabled funs ret []_disabled __salt__['grains.get'] 'state_runs_disabled' for state in funs for _state in _disabled if '.*' in _state target_state _state.split '.' [0]target_state target_state + '.' if not target_state.endswith '.' else target_state if state.startswith target_state err 'Thestatefile"{0}"iscurrentlydisabledby"{1}" tore-enable runstate.enable{1}.'.format state _state ret.append err continueelif _state state err 'Thestatefile"{0}"iscurrentlydisabled tore-enable runstate.enable{0}.'.format _state ret.append err continuereturn ret
def get_env_setting setting try return environ[setting]except KeyError error_msg 'Setthe%senvvariable' % setting raise ImproperlyConfigured error_msg
def is_conflict exception exception_string str exception return any s in exception_string for s in CONFLICT_INDICATORS
def get_principal name ret {}cmd __execute_kadmin 'get_principal{0}'.format name if cmd['retcode'] ! 0 or cmd['stderr'] ret['comment'] cmd['stderr'].splitlines [ -1 ]ret['result'] Falsereturn retfor i in cmd['stdout'].splitlines [1 ] prop val i.split ' ' 1 ret[prop] valreturn ret
def runWithWarningsSuppressed suppressedWarnings f *a **kw for args kwargs in suppressedWarnings warnings.filterwarnings *args **kwargs addedFilters warnings.filters[ len suppressedWarnings ]try result f *a **kw except exc_info sys.exc_info _resetWarningFilters None addedFilters reraise exc_info[1] exc_info[2] else if isinstance result defer.Deferred result.addBoth _resetWarningFilters addedFilters else _resetWarningFilters None addedFilters return result
def _register_make cls assert cls.nxm_headers is not None assert cls.nxm_headers is not [] for nxm_header in cls.nxm_headers assert nxm_header not in _MF_FIELDS _MF_FIELDS[nxm_header] cls.makereturn cls
@publicdef together expr deep False def _together expr if isinstance expr Basic if expr.is_Atom or expr.is_Function and not deep return exprelif expr.is_Add return gcd_terms list map _together Add.make_args expr elif expr.is_Pow base _together expr.base if deep exp _together expr.exp else exp expr.expreturn expr.__class__ base exp else return expr.__class__ *[_together arg for arg in expr.args] elif iterable expr return expr.__class__ [_together ex for ex in expr] return exprreturn _together sympify expr
def test_suggested_multiple_column_names_with_alias completer complete_event text u'SELECTu.id u.fromusersu'position len u'SELECTu.id u.' result set completer.get_completions Document text text cursor_position position complete_event assert set result set testdata.columns u'users'
def _write_table lstrs fp o open fp 'w' o.writelines '\n'.join lstrs o.close
def _ping_ponger connection event connection.pong event.target
def dup_integrate f m K if m < 0 or not f return fg [K.zero] * m for i c in enumerate reversed f n i + 1 for j in range 1 m n * i + j + 1 g.insert 0 K.exquo c K n return g
def parse_group rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--name' dest 'name' action 'store' parser.add_argument '--gid' dest 'gid' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
def _has_beta version dev_releases return version in [re.search ' \\d+\\. +\\d+' s .group 0 for s in dev_releases.keys ]
def _num_samples x if hasattr x 'fit' raise TypeError 'Expectedsequenceorarray-like gotestimator%s' % x if not hasattr x '__len__' and not hasattr x 'shape' if hasattr x '__array__' x np.asarray x else raise TypeError 'Expectedsequenceorarray-like got%s' % type x if hasattr x 'shape' if len x.shape 0 raise TypeError 'Singletonarray%rcannotbeconsideredavalidcollection.' % x return x.shape[0]else return len x
def CheckPrintf filename clean_lines linenum error line clean_lines.elided[linenum]match Search 'snprintf\\s*\\ [^ ]* \\s* [0-9]* \\s* ' line if match and match.group 2 ! '0' error filename linenum 'runtime/printf' 3 'Ifyoucan usesizeof %s insteadof%sasthe2ndargtosnprintf.' % match.group 1 match.group 2 if Search '\\bsprintf\\s*\\ ' line error filename linenum 'runtime/printf' 5 'Neverusesprintf.Usesnprintfinstead.' match Search '\\b strcpy|strcat \\s*\\ ' line if match error filename linenum 'runtime/printf' 4 'Almostalways snprintfisbetterthan%s' % match.group 1
def update_provider_location provider_location items location_dict {tp.split '^' [0] tp.split '^' [1] for tp in provider_location.split '|' }for key value in items.items location_dict[key] valuereturn dump_provider_location location_dict
@command 'save' def save_last if g.last_opened open_save_view 'save' g.last_opened else saveas ''if g.model saveas g.model[0].title[ 18].strip saveas re.sub '[^-\\w]' '-' saveas re.UNICODE post 0while g.userpl.get saveas post + 1saveas g.model[0].title[ 18].strip + '-' + str post saveas saveas.lstrip '0123456789' open_save_view 'save' saveas
def het_white resid exog retres False x np.asarray exog y np.asarray resid if x.ndim 1 raise ValueError 'xshouldhaveconstantandatleastonemorevariable' nobs nvars0 x.shape i0 i1 np.triu_indices nvars0 exog x[ i0] * x[ i1] nobs nvars exog.shapeassert nvars nvars0 * nvars0 - 1 / 2.0 + nvars0 resols OLS y ** 2 exog .fit fval resols.fvaluefpval resols.f_pvaluelm nobs * resols.rsquared assert resols.df_model np_matrix_rank exog - 1 lmpval stats.chi2.sf lm resols.df_model return lm lmpval fval fpval
def _rename columns df assert not isinstance df _Frame if columns is no_default return dfif isinstance columns Iterator columns list columns if isinstance df pd.DataFrame if isinstance columns pd.DataFrame columns columns.columnsif not isinstance columns pd.Index columns pd.Index columns if len columns len df.columns and type columns is type df.columns and columns.equals df.columns return dfdf df.copy deep False df.columns columnsreturn dfelif isinstance df pd.Series pd.Index if isinstance columns pd.Series pd.Index columns columns.nameif df.name columns return dfreturn df.rename columns return df
def libvlc_video_get_teletext p_mi f _Cfunctions.get 'libvlc_video_get_teletext' None or _Cfunction 'libvlc_video_get_teletext' 1 None ctypes.c_int MediaPlayer return f p_mi
def _bio_to_string bio result_buffer _ffi.new 'char**' buffer_length _lib.BIO_get_mem_data bio result_buffer return _ffi.buffer result_buffer[0] buffer_length [ ]
def event_return events opts _get_options {} opts['skip'] Truefor event in events log.trace 'Carbonreturnerreceivedevent {0}'.format event metric_base event['tag']saltdata event['data'].get 'data' _send saltdata metric_base opts
def edns_to_text flags return _to_text flags _edns_by_value _edns_flags_order
def run _task
@_default_selemdef median image selem None out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._median image selem out out mask mask shift_x shift_x shift_y shift_y
def ipaddrs return __proxy__['napalm.call'] 'get_interfaces_ip' **{}
def check_sql_input f def new_f widget data *args **kwargs widget.Error.add_message 'download_sql_data' _download_sql_data widget.Error.download_sql_data.clear if isinstance data SqlTable if data.approx_len < AUTO_DL_LIMIT data Table data else widget.Error.download_sql_data data Nonereturn f widget data *args **kwargs return new_f
def handle_nan value if isinstance value float if value float 'inf' return '<inf>'if value float '-inf' return '<-inf>'if value ! value return '<nan>'return value
def _match_task_log_path path application_id None job_id None m _PRE_YARN_TASK_LOG_PATH_RE.match path if m if job_id and job_id ! _to_job_id m.group 'attempt_id' return Nonereturn dict attempt_id m.group 'attempt_id' log_type m.group 'log_type' m _YARN_TASK_LOG_PATH_RE.match path if m if application_id and application_id ! m.group 'application_id' return Nonereturn dict application_id m.group 'application_id' container_id m.group 'container_id' log_type m.group 'log_type' return None
def getClockFormat **kwargs _gsession _GSettings user kwargs.get 'user' schema 'org.gnome.desktop.interface' key 'clock-format' return _gsession._get
def get_module_and_frameid node frame node.frame module obj '' [] while frame if isinstance frame Module module frame.nameelse obj.append getattr frame 'name' '<lambda>' try frame frame.parent.frame except AttributeError frame Noneobj.reverse return module '.'.join obj
def replace_subcircuit circuit subcircuit replace None pos 0 if pos < 0 pos 0if isinstance circuit Mul circuit circuit.argsif isinstance subcircuit Mul subcircuit subcircuit.argsif isinstance replace Mul replace replace.argselif replace is None replace loc find_subcircuit circuit subcircuit start pos if loc > -1 left circuit[0 loc]right circuit[ loc + len subcircuit len circuit ]circuit left + replace + right return circuit
def schaffer_mo individual return individual[0] ** 2 individual[0] - 2 ** 2
def wait_for_quorum keyname db_nodes replication command cassandra_interface.NODE_TOOL + '' + 'status' key_file '{}/{}.key'.format utils.KEY_DIRECTORY keyname ssh_cmd ['ssh' '-i' key_file appscale_info.get_db_master_ip command]if db_nodes < 1 or replication < 1 raise dbconstants.AppScaleDBError 'Atleast1databasemachineisneeded.' if replication > db_nodes raise dbconstants.AppScaleDBError 'Thereplicationfactorcannotexceedthenumberofdatabasemachines.' can_fail math.ceil replication / 2.0 - 1 needed int db_nodes - can_fail while True output subprocess.check_output ssh_cmd nodes_ready len [line for line in output.splitlines if line.startswith 'UN' ] logging.info '{}nodesareup.{}areneeded.'.format nodes_ready needed if nodes_ready > needed breaktime.sleep 1
def discover_static_files base_path sub_path '' js_files discover_files base_path sub_path sub_path ext '.js' trim_base_path True sources mocks specs sort_js_files js_files html_files discover_files base_path sub_path sub_path ext '.html' trim_base_path True p path.join base_path sub_path _log sources 'JavaScriptsource' p _log mocks 'JavaScriptmock' p _log specs 'JavaScriptspec' p _log html_files 'HTMLtemplate' p return sources mocks specs html_files
def inject_field_overrides blocks course user OverrideFieldData.provider_classes Nonefor block in blocks block._field_data OverrideFieldData.wrap user course block._field_data
def test_weights_iris clf1 LogisticRegression random_state 123 clf2 RandomForestClassifier random_state 123 clf3 GaussianNB eclf VotingClassifier estimators [ 'lr' clf1 'rf' clf2 'gnb' clf3 ] voting 'soft' weights [1 2 10] scores cross_val_score eclf X y cv 5 scoring 'accuracy' assert_almost_equal scores.mean 0.93 decimal 2
def _srvmgr func as_json False command 'Import-ModuleWebAdministration;'if as_json command '{0}ConvertTo-Json-Compress-Depth4-InputObject@ {1} '.format command func else command '{0}{1}'.format command func cmd_ret __salt__['cmd.run_all'] command shell 'powershell' python_shell True if cmd_ret['retcode'] ! 0 _LOG.error 'Unabletoexecutecommand %s\nError %s' command cmd_ret['stderr'] return cmd_ret
def aggregate_cov x d r None weights None nobs x.shape[0]count 0res 0 * np.outer x[0] x[0] for ii in range nobs for jj in range nobs w kernel d[ii] d[jj] r r weights weights if w res + w * np.outer x[0] x[0] count * 1return res count
def get_vlan_config_commands vlan vid reverse_value_map {'admin_state' {'down' 'shutdown' 'up' 'noshutdown'}}if vlan.get 'admin_state' vlan apply_value_map reverse_value_map vlan VLAN_ARGS {'name' 'name{0}' 'vlan_state' 'state{0}' 'admin_state' '{0}' 'mode' 'mode{0}' 'mapped_vni' 'vn-segment{0}'}commands []for param value in vlan.iteritems if param 'mapped_vni' and value 'default' command 'novn-segment'else command VLAN_ARGS.get param .format vlan.get param if command commands.append command commands.insert 0 'vlan' + vid commands.append 'exit' return commands
def include d e return d [f for f in glob.glob '%s/%s' % d e if os.path.isfile f ]
def is_client_error status return 400 < status < 499
def truncate_name name length None hash_len 4 if length is None or len name < length return namehsh hashlib.md5 name .hexdigest [ hash_len]return '%s%s' % name[ length - hash_len ] hsh
def _get_local_ip s socket.socket socket.AF_INET socket.SOCK_DGRAM s.connect 'google.com' 80 ip s.getsockname [0]s.close return ip
def path_exists_glob path return True if glob.glob os.path.expanduser path else False
def _render_template config_file dirname filename os.path.split config_file env Environment loader FileSystemLoader dirname template env.get_template filename config template.render __grains__ return config
def addMethodNamesToDict classObj dict prefix baseClass None for base in classObj.__bases__ addMethodNamesToDict base dict prefix baseClass if baseClass is None or baseClass in classObj.__bases__ for name method in classObj.__dict__.items optName name[len prefix ]if type method is types.FunctionType and name[ len prefix ] prefix and len optName dict[optName] 1
def p_statements_1 t pass
@LocalContextdef run_assembly assembly return ELF.from_assembly assembly .process
def send_message module client_id client_secret topic msg try access_token get_access_token module client_id client_secret url 'https //typetalk.in/api/v1/topics/%d' % topic headers {'Authorization' 'Bearer%s' % access_token }do_request module url {'message' msg} headers return True {'access_token' access_token} except ConnectionError e get_exception return False e
def adjacency_spectrum G weight 'weight' from scipy.linalg import eigvalsreturn eigvals nx.adjacency_matrix G weight weight .todense
def ensure_port_cleanup bound_addresses maxtries 30 sleeptime 2 atexit.register _cleanup_ports bound_addresses maxtries maxtries sleeptime sleeptime
def get_PATH return os.getenv 'PATH'
def NamedTemporaryFile mode 'w+b' bufsize -1 suffix '' prefix template dir None delete True if dir is None dir gettempdir if 'b' in mode flags _bin_openflagselse flags _text_openflagsif _os.name 'nt' and delete flags | _os.O_TEMPORARY fd name _mkstemp_inner dir prefix suffix flags file _os.fdopen fd mode bufsize return _TemporaryFileWrapper file name delete
def redact string return global_redaction_engine.redact string
def ndb_config NDBConfig.initialize return NDBConfig
def DEFINE_float name default help CONFIG.AddOption type_info.Float name name default default description help
def _footer_mobile_links is_secure platform_name configuration_helpers.get_value 'platform_name' settings.PLATFORM_NAME mobile_links []if settings.FEATURES.get 'ENABLE_FOOTER_MOBILE_APP_LINKS' mobile_links [{'name' 'apple' 'title' _ 'Downloadthe{platform_name}mobileappfromtheAppleAppStore' .format platform_name platform_name 'url' settings.MOBILE_STORE_URLS.get 'apple' '#' 'image' _absolute_url_staticfile is_secure 'images/app/app_store_badge_135x40.svg' } {'name' 'google' 'title' _ 'Downloadthe{platform_name}mobileappfromGooglePlay' .format platform_name platform_name 'url' settings.MOBILE_STORE_URLS.get 'google' '#' 'image' _absolute_url_staticfile is_secure 'images/app/google_play_badge_45.png' }]return mobile_links
def dct_matrix rows cols unitary True rval numpy.zeros rows cols col_range numpy.arange cols scale numpy.sqrt 2.0 / cols for i in xrange rows rval[i] numpy.cos i * col_range * 2 + 1 / 2.0 * cols * numpy.pi * scale if unitary rval[0] * numpy.sqrt 0.5 return rval
def _loopbackAsyncBody server serverToClient client clientToServer pumpPolicy def pump source q target sent Falseif q pumpPolicy q target sent Trueif sent and not q source.transport._pollProducer return sentwhile 1 disconnect clientSent serverSent FalseserverSent pump server serverToClient client clientSent pump client clientToServer server if not clientSent and not serverSent d defer.Deferred clientToServer._notificationDeferred dserverToClient._notificationDeferred dd.addCallback _loopbackAsyncContinue server serverToClient client clientToServer pumpPolicy return dif serverToClient.disconnect disconnect Truepump server serverToClient client elif clientToServer.disconnect disconnect Truepump client clientToServer server if disconnect server.connectionLost failure.Failure main.CONNECTION_DONE client.connectionLost failure.Failure main.CONNECTION_DONE return defer.succeed None
def test_run_method_should_return_success_when_finds_command_name options_mock Mock args 'freeze' help_cmd HelpCommand status help_cmd.run options_mock args assert status SUCCESS
def author_addon_clicked f @functools.wraps f def decorated request *args **kwargs redirect_id request.GET.get 'addons-author-addons-select' None if not redirect_id return f request *args **kwargs try target_id int redirect_id return http.HttpResponsePermanentRedirect reverse 'addons.detail' args [target_id] except ValueError return http.HttpResponseBadRequest 'Invalidadd-onID.' return decorated
def anovadict res ad {}ad.update res.__dict__ anova_attr ['df_model' 'df_resid' 'ess' 'ssr' 'uncentered_tss' 'mse_model' 'mse_resid' 'mse_total' 'fvalue' 'f_pvalue' 'rsquared']for key in anova_attr ad[key] getattr res key ad['nobs'] res.model.nobsad['ssmwithmean'] res.uncentered_tss - res.ssr return ad
def restore_text text character_map mapped_chars if not text return textfor key value in character_map.items text text.replace value key return text
def _GetActivationURL user secret return 'https //www.google.com/chart?chs 200x200&chld M|0&cht qr&chl otpauth //totp/{0}@www.{1}%3Fsecret%3D{2}'.format user options.options.domain secret
def get_ftp_proxy network_service 'Ethernet' if __grains__['os'] 'Windows' return _get_proxy_windows ['ftp'] return _get_proxy_osx 'getftpproxy' network_service
def cooperate iterator return _theCooperator.cooperate iterator
def print_node node s '%s %s\n' % node.__class__.__name__ str node d node._assumptionsif len d > 0 for a in sorted d v d[a]if v is None continues + '%s %s\n' % a v return s
def stMFCC X fbank nceps mspec numpy.log10 numpy.dot X fbank.T + eps ceps dct mspec type 2 norm 'ortho' axis -1 [ nceps]return ceps
def abhirajbutala logging.info 'Ijustaddedloggingsupportforthisimportantproject!' return
def randi N return int uniform 0 N
def check_archive_formats formats for format in formats if format not in ARCHIVE_FORMATS return formatreturn None
def register_backend format backend description None if description is None description u''_default_backends[format] backend_default_filetypes[format] description
def is_not_nat builder val return builder.icmp lc.ICMP_NE val NAT
def max_power_of_two x exponent 0while x x x >> 1 exponent + 1return max exponent - 1 0
def test_assertion name result expected assert result expected 'Expected%s got%sfor%s' % expected result name
def _list_from_csv csv_string caster None if caster is None return [x for x in csv_string.split ' ' if x]else return [caster x for x in csv_string.split ' ' if x]
def _get_media_info media_id media_type media_format Noneif media_type 'image' media get_object_or_404 Image pk media_id try media_format imghdr.what media.file.path except UnicodeEncodeError passelif media_type 'video' media get_object_or_404 Video pk media_id else raise Http404return media media_format
def analyze_module pycore pymodule should_analyze search_subscopes followed_calls _analyze_node pycore pymodule should_analyze search_subscopes followed_calls
def find_campaigns srs start end ignore all_sr_names set all_campaigns set srs set srs while srs all_sr_names | {sr.name for sr in srs}new_campaigns_by_date get_campaigns_by_date srs start end ignore new_campaigns set chain.from_iterable new_campaigns_by_date.itervalues all_campaigns.update new_campaigns new_sr_names set chain.from_iterable campaign.target.subreddit_names for campaign in new_campaigns new_sr_names - all_sr_namessrs set Subreddit._by_name new_sr_names .values return all_campaigns
def encode_method_selection_message version method return struct.pack '!BB' version method
def _check_guts_toc_mtime attr old toc last_build pyc 0 for nm fnm typ in old if misc.mtime fnm > last_build logger.info 'Buildingbecause%schanged' fnm return Trueelif pyc and misc.mtime fnm[ -1 ] > last_build logger.info 'Buildingbecause%schanged' fnm[ -1 ] return Truereturn False
def report_missing dir flist globstr os.path.join dir '*.py' fnames glob.glob globstr pyfiles {os.path.split fullpath [ -1 ] for fullpath in set fnames }exclude set excluded.get dir [] flist set flist missing list pyfiles - flist - exclude if missing print '%sfilesnottested %s' % dir ' '.join sorted missing
def toggleHashtable hashtable key value if key in hashtable del hashtable[key]else hashtable[key] value
def get_user_from_cookie cookies app_id app_secret cookie cookies.get 'fbsr_' + app_id '' if not cookie return Noneparsed_request parse_signed_request cookie app_secret try result get_access_token_from_code parsed_request['code'] '' app_id app_secret except GraphAPIError return Noneresult['uid'] parsed_request['user_id']return result
def dictsort value arg var_resolve Variable arg .resolvedecorated [ var_resolve item item for item in value]decorated.sort return [item[1] for item in decorated]
def _getscreen if Turtle._screen is None Turtle._screen Screen return Turtle._screen
def dc_rheader r tabs None T current.Tif r.representation ! 'html' return Noneresourcename r.nameif resourcename 'template' tabs T 'BasicDetails' None T 'Questions' 'question' rheader_fields ['name'] rheader S3ResourceHeader rheader_fields tabs r elif resourcename 'question' tabs T 'QuestionDetails' None T 'Translations' 'question_l10n' rheader_fields ['question'] rheader S3ResourceHeader rheader_fields tabs r elif resourcename 'collection' tabs T 'BasicDetails' None T 'Answers' 'answer' T 'Attachments' 'document' rheader_fields ['template_id'] ['location_id'] ['date'] rheader S3ResourceHeader rheader_fields tabs r elif resourcename 'target' tabs T 'BasicDetails' None T 'Collections' 'collection' rheader_fields ['template_id'] ['location_id'] ['date'] rheader S3ResourceHeader rheader_fields tabs r else rheader ''return rheader
def is_comment_too_deep parent return MAX_COMMENT_DEPTH is not None and MAX_COMMENT_DEPTH < 0 or parent and parent['depth'] > MAX_COMMENT_DEPTH
@step u'[Mm]y" [^"]* "answeris NOT ?marked" [^"]* "' def assert_answer_mark _step problem_type isnt_marked correctness assert correctness in ['correct' 'incorrect' 'unanswered'] assert problem_type in PROBLEM_DICT for sel in PROBLEM_DICT[problem_type][correctness] if bool isnt_marked world.wait_for lambda _ world.is_css_not_present sel has_expected world.is_css_not_present sel else world.css_find sel has_expected world.is_css_present sel if has_expected breakassert has_expected
def migrate_resource_table conn table resource_table conn.table table resource_filter "QualifierFilter 'regexstring m_\\d{19}\\+[\\w-\\._]*\\+[\\w-\\._!]' "gen resource_table.scan filter resource_filter for row data in gen columns []updated_columns dict column_prefix 'f 'for column value in data.items if column.startswith 'f m_' columns.append column parts column[2 ].split '+' 2 parts.extend parts.pop 2 .split '!' column hbase_utils.prepare_key *parts updated_columns[ column_prefix + column ] valueresource_table.put row updated_columns resource_table.delete row columns
def cell_get_all context return IMPL.cell_get_all context
def _xml_oneliner_re_from_tab_width tab_width return re.compile '\n ? \n ?< \\n\\n #Startingafterablankline\n|#or\n\\A\\n?#thebeginningofthedoc\n \n #savein$1\n[]{0 %d}\n ? \n<\\?\\w+\\b\\s+.*?\\?>#XMLprocessinginstruction\n|\n<\\w+ \\w+\\b\\s+.*?/>#namespacedsingletag\n \n[\\t]*\n ? \\n{2 }|\\Z #followedbyablanklineorendofdocument\n \n' % tab_width - 1 re.X
def _fmt_msg msg if not msg return ''return msg + '\n'
def _lock_file id if os.path.exists '/dev/shm' return '/dev/shm/gpu_lock_%d' % id else return '/tmp/gpu_lock_%d' % id
def parse_sents inputs grammar trace 0 from nltk.grammar import FeatureGrammarfrom nltk.parse import FeatureChartParser load_parserif isinstance grammar FeatureGrammar cp FeatureChartParser grammar else cp load_parser grammar trace trace parses []for sent in inputs tokens sent.split syntrees list cp.parse tokens parses.append syntrees return parses
def generic_multiedge_match attr default op if nx.utils.is_string_like attr attr [attr]default [default]op [op]attrs list zip attr default def match datasets1 datasets2 values1 []for data1 in datasets1.values x tuple data1.get attr d for attr d in attrs values1.append x values2 []for data2 in datasets2.values x tuple data2.get attr d for attr d in attrs values2.append x for vals2 in permutations values2 for xi yi in zip values1 vals2 if not all map lambda x y z z x y xi yi op breakelse return Trueelse return Falsereturn match
def method_decorator decorator def _dec func def _wrapper self *args **kwargs @decoratordef bound_func *args2 **kwargs2 return func self *args2 **kwargs2 return bound_func *args **kwargs @decoratordef dummy *args **kwargs passupdate_wrapper _wrapper dummy update_wrapper _wrapper func return _wrapperupdate_wrapper _dec decorator _dec.__name__ 'method_decorator %s ' % decorator.__name__ return _dec
def slow_responder ctx zmq.Context.instance socket ctx.socket zmq.REP socket.linger 0socket.bind 'tcp //127.0.0.1 5555' i 0while True msg socket.recv print '\nworkerreceived%r\n' % msg time.sleep random.randint 1 5 socket.send msg + 'toyoutoo #%i' % i i + 1
def filter_paths path_list return [p for p in path_list if os.path.exists os.path.realpath p ]
@anonymous_user_requireddef token_login token expired invalid user login_token_status token if invalid do_flash *get_message 'INVALID_LOGIN_TOKEN' if expired send_login_instructions user do_flash *get_message 'LOGIN_EXPIRED' email user.email within _security.login_within if invalid or expired return redirect url_for 'login' login_user user after_this_request _commit do_flash *get_message 'PASSWORDLESS_LOGIN_SUCCESSFUL' return redirect get_post_login_redirect
def aggregation_most_frequent logits labels labels_from_probs logits labels_shape np.shape labels labels labels.reshape labels_shape[0] labels_shape[1] result np.zeros int labels_shape[1] for i in xrange int labels_shape[1] label_counts np.bincount labels[ i] minlength 10 label_counts np.asarray label_counts dtype np.int32 result[i] np.argmax label_counts return np.asarray result dtype np.int32
def fake_get_network *args **kwargs return {'type' 'fake'}
def runTestFast test_name old_stderr sys.stderrold_stdout sys.stdoutf open 'temp.log' 'w' ec 0errors ''try sys.stdout fsys.stderr f__import__ test_name.split '.py' [0] except SystemExit ec int str sys.exc_value except ec 1finally sys.stderr old_stderrsys.stdout old_stdoutf.close if ec ! 0 f open 'temp.log' 'r' for line in f.readlines errors errors + line f.close return ec errors
def Dependencies lTOC xtrapath None manifest None redirects None lTOC _extract_from_egg lTOC for nm pth typ in lTOC if nm.upper in seen continuelogger.debug 'Analyzing%s' pth seen.add nm.upper if is_win for ftocnm fn in getAssemblyFiles pth manifest redirects lTOC.append ftocnm fn 'BINARY' for lib npth in selectImports pth xtrapath if lib.upper in seen or npth.upper in seen continueseen.add npth.upper lTOC.append lib npth 'BINARY' return lTOC
def set_builtins_dir path global _handler_dir _available_builtins_handler_dir path_available_builtins []_initialize_builtins
def show_lists t rel t.lists.list screen_name g['original_name'] if rel print_list rel else printNicely light_magenta 'Youbelongtonolists '
def _handle_put gs_stub filename param_dict headers payload token _get_param 'upload_id' param_dict content_range _ContentRange headers if content_range.value and not content_range.finished gs_stub.put_continue_creation token payload content_range.start content_range.end response_headers {}response_status 308elif content_range.value and content_range.finished gs_stub.put_continue_creation token payload content_range.start content_range.end last True filestat gs_stub.head_object filename response_headers {'content-length' filestat.st_size}response_status 200elif not payload gs_stub.put_continue_creation token '' None True filestat gs_stub.head_object filename response_headers {'content-length' filestat.st_size}response_status 200else raise ValueError 'Missingheadercontent-rangebuthaspayload' return _FakeUrlFetchResult response_status response_headers ''
def make_suite path test_dir loader unittest.TestLoader python_module_names get_python_module_names os.listdir path test_module_names get_test_module_names python_module_names suite loader.loadTestsFromNames test_module_names return suite
def scharr_h image mask None assert_nD image 2 image img_as_float image result convolve image HSCHARR_WEIGHTS return _mask_filter_result result mask
def gps_distance lat1 lon1 lat2 lon2 lat1 math.radians lat1 lat2 math.radians lat2 lon1 math.radians lon1 lon2 math.radians lon2 dLat lat2 - lat1 dLon lon2 - lon1 a math.sin 0.5 * dLat ** 2 + math.sin 0.5 * dLon ** 2 * math.cos lat1 * math.cos lat2 c 2.0 * math.atan2 math.sqrt a math.sqrt 1.0 - a return radius_of_earth * c
def get_last_line_number_in_diff context filediff interfilediff f get_file_from_filediff context filediff interfilediff last_chunk f[u'chunks'][ -1 ]last_line last_chunk[u'lines'][ -1 ]return last_line[0]
def head url **kwargs return request 'head' url **kwargs
def advanced_indexing_op input index batch_size tf.shape input [0]max_length tf.shape input [1]dim_size int input.get_shape [2] index tf.range 0 batch_size * max_length + index - 1 flat tf.reshape input [ -1 dim_size] relevant tf.gather flat index return relevant
def libvlc_media_tracks_get p_md tracks f _Cfunctions.get 'libvlc_media_tracks_get' None or _Cfunction 'libvlc_media_tracks_get' 1 1 None ctypes.c_uint Media ctypes.POINTER ctypes.POINTER MediaTrack return f p_md tracks
def jsonc_to_string jsonc_obj return simplejson.dumps _convert_to_object jsonc_obj
def jsonpify func *args **kwargs data func *args **kwargs return to_jsonp data
def geom_index func return geom_output func [GEOM_PTR c_int]
def detect stream try json.loads stream return Trueexcept ValueError return False
def alterWiddershinsSupportedPathByPoint alongAway overhangWiddershinsLeft overhangWiddershinsRight point if alongAway.getIsWiddershinsPointSupported point returnoverhangWiddershins overhangWiddershinsLeftif overhangWiddershinsRight.getDistance < overhangWiddershinsLeft.getDistance overhangWiddershins overhangWiddershinsRightoverhangWiddershins.alterLoop
def _get_message_from_model message_model return feedback_domain.FeedbackMessage message_model.id message_model.thread_id message_model.message_id message_model.author_id message_model.updated_status message_model.updated_subject message_model.text message_model.created_on message_model.last_updated
def strip_one path return path.strip u'/' .split u'/' 1 [ -1 ]
def collect_dynamic_libs package destdir None if not isinstance package string_types raise ValueErrorlogger.debug 'Collectingdynamiclibrariesfor%s' % package pkg_base pkg_dir get_package_paths package dylibs []for dirpath _ __ in os.walk pkg_dir for pattern in PY_DYLIB_PATTERNS files glob.glob os.path.join dirpath pattern for source in files if destdir dest destdirelse dest remove_prefix dirpath os.path.dirname pkg_base + os.sep logger.debug '%s %s' % source dest dylibs.append source dest return dylibs
def slice_to_str slc if is_single_index slc return str slc.start endpoints [none_to_empty val for val in slc.start slc.stop ]if slc.step is not None and slc.step ! 1 return '%s %s %s' % endpoints[0] endpoints[1] slc.step else return '%s %s' % endpoints[0] endpoints[1]
@deprecated u'2.1' def soundex name len 4 soundex_digits u'01230120022455012623010202'sndx u''fc u''for c in name.upper if c.isalpha if not fc fc cd soundex_digits[ ord c - ord u'A' ]if not sndx or d ! sndx[ -1 ] sndx + dsndx fc + sndx[1 ] sndx sndx.replace u'0' u'' return sndx + len * u'0' [ len]
def split_dataset_random dataset first_size seed None order numpy.random.RandomState seed .permutation len dataset return split_dataset dataset first_size order
def _parse_config_file filename parser ConfigParser parser.read filename name parser.sections [0]meta_data {}for opt in parser.options name meta_data[opt] parser.get name opt return name meta_data
def attach_webhook project request None for service_cls in registry if service_cls.is_project_service project service service_clsbreakelse return Noneuser_accounts service.for_user request.user for account in user_accounts success resp account.setup_webhook project if success messages.success request _ 'Webhookactivated' project.has_valid_webhook Trueproject.save breakelse if user_accounts messages.error request _ 'Webhookactivationfailed.Makesureyouhavepermissionstosetit.' else messages.error request _ 'Noaccountsavailabletosetwebhookon.Pleaseconnectyour{network}account.'.format network service.adapter .get_provider .name
def start_all_dummy_clients nclients global NCLIENTSNCLIENTS int nclients actions DUMMYRUNNER_SETTINGS.ACTIONSif len actions < 2 print ERROR_FEW_ACTIONS returnpratio 1.0 / sum tup[0] for tup in actions[2 ] flogin flogout probs cfuncs actions[0] actions[1] [ tup[0] * pratio for tup in actions[2 ]] [tup[1] for tup in actions[2 ]] cprobs [sum v for i v in enumerate probs if i < k for k in range len probs ]actions flogin flogout + tuple zip cprobs cfuncs factory DummyFactory actions for i in range NCLIENTS reactor.connectTCP 'localhost' TELNET_PORT factory reactor.run
def parsed2datadict d if d['uri'] is None uri '/'else uri d['uri']url 'http //' + d['vhost'] + uri musecs int d['musecs'] if '+' in d['musecs'] url url.replace 'http' 'wrong' if d['responsebytes'].strip '-' responsebytes 0else responsebytes int d['responsebytes'].strip return dict url url musecs musecs responsebytes responsebytes
def _get_session server if server in _sessions return _sessions[server]config _get_spacewalk_configuration server if not config raise Exception "Noconfigfor'{0}'foundonmaster".format server session _get_client_and_key config['api_url'] config['username'] config['password'] atexit.register _disconnect_session session client session['client']key session['key']_sessions[server] client key return client key
def install_conda_target conda_target conda_context None conda_context _ensure_conda_context conda_context conda_context.ensure_channels_configured create_args ['--name' conda_target.install_environment conda_target.package_specifier]return conda_context.exec_create create_args
def has_verdana import matplotlib.font_manager as mplfmtry verdana_font mplfm.findfont 'Verdana' fallback_to_default False except return Falsetry unlikely_font mplfm.findfont 'very_unlikely_to_exist1234' fallback_to_default False except return Truereturn verdana_font ! unlikely_font
def summary_params_frame results yname None xname None alpha 0.05 use_t True if isinstance results tuple results params std_err tvalues pvalues conf_int resultselse params results.paramsstd_err results.bsetvalues results.tvaluespvalues results.pvaluesconf_int results.conf_int alpha alp str 1 - alpha * 100 + '%' if use_t param_header ['coef' 'stderr' 't' 'P>|t|' 'Conf.Int.Low' 'Conf.Int.Upp.']else param_header ['coef' 'stderr' 'z' 'P>|z|' 'Conf.Int.Low' 'Conf.Int.Upp.'] _ xname _getnames results yname yname xname xname from pandas import DataFrametable np.column_stack params std_err tvalues pvalues conf_int return DataFrame table columns param_header index xname
def get_users_with_role role_prefix return User.objects.filter groups__name__startswith role_prefix
def model_cr_context method method._api 'model_cr_context'return method
def getSummarizedFileName fileName if os.getcwd os.path.dirname fileName return os.path.basename fileName return fileName
def icon_dir theme if not theme or theme _default_icon_theme icons share u'icons' else theme_dir share u'icons' theme if os.path.isabs theme and os.path.isdir theme icons themeelif os.path.isdir theme_dir icons theme_direlse icons share u'icons' return icons
def blend_palette colors n_colors 6 as_cmap False input 'rgb' colors [_color_to_rgb color input for color in colors]name 'blend'pal mpl.colors.LinearSegmentedColormap.from_list name colors if not as_cmap pal _ColorPalette pal np.linspace 0 1 n_colors return pal
def get_nonphylogenetic_metric name try return getattr distance_transform 'dist_' + name.lower except AttributeError try return getattr distance_transform name.replace 'binary' 'binary_dist' .lower except AttributeError return getattr distance_transform name.lower
def unexpected_error_msg error return 'Unexpectedresponse %s .Detail %s' % str error traceback.format_exc error
@pytest.mark.parametrize 'parallel' [True False] def test_empty_lines parallel read_basic table read_basic '\n\nABC\n123\n\n\n456\n\n\n\n' parallel parallel expected Table [[1 4] [2 5] [3 6]] names 'A' 'B' 'C' assert_table_equal table expected
def referer pattern accept True accept_missing False error 403 message 'ForbiddenRefererheader.' debug False try ref cherrypy.serving.request.headers['Referer']match bool re.match pattern ref if debug cherrypy.log 'Referer%rmatches%r' % ref pattern 'TOOLS.REFERER' if accept match returnexcept KeyError if debug cherrypy.log 'NoRefererheader' 'TOOLS.REFERER' if accept_missing returnraise cherrypy.HTTPError error message
def TimestampISO8601 t return time.strftime '%Y-%m-%dT%H %M %SZ' time.gmtime t
def serviceRoads stacks duration 1.0 start time.time while start + duration > time.time for stack in stacks stack.serviceAll if all [ not stack.transactions for stack in stacks] console.terse 'Servicestacksdonenormally\n' breaktime.sleep 0.05 for stack in stacks console.terse 'Stack{0}remotes {1}\n'.format stack.name stack.nameRemotes console.terse 'Servicestacksexit\n'
def schedule delay func t time + delay insort scheduled_calls t func
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def words count common True word_list list COMMON_WORDS if common else [] c len word_list if count > c count - cwhile count > 0 c min count len WORDS count - cword_list + random.sample WORDS c else word_list word_list[ count]return ''.join word_list
def get_admin_path name future if future return os.path.join cfg.admin_dir.get_path FUTURE_Q_FOLDER else return os.path.join os.path.join cfg.download_dir.get_path name JOB_ADMIN
def keyring_purge **kwargs return ceph_cfg.keyring_purge **kwargs
def test_modulepickling_change_cache_dir monkeypatch tmpdir dir_1 str tmpdir.mkdir 'first' dir_2 str tmpdir.mkdir 'second' item_1 ParserCacheItem 'fakeparser1' item_2 ParserCacheItem 'fakeparser2' path_1 'fakepath1'path_2 'fakepath2'monkeypatch.setattr settings 'cache_directory' dir_1 ParserPickling.save_parser path_1 item_1 cached load_stored_item ParserPickling path_1 item_1 assert cached item_1.parser monkeypatch.setattr settings 'cache_directory' dir_2 ParserPickling.save_parser path_2 item_2 cached load_stored_item ParserPickling path_1 item_1 assert cached is None
def test_find_number_3 s 'jq%misdirect/82ghn931'r find_number s assert s[r[0] r[1]] '82'
def _clear_ignore_list lst return [_clear_ignore ele for ele in lst]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_computer_name ret salt.utils.mac_utils.execute_return_result 'systemsetup-getcomputername' return salt.utils.mac_utils.parse_return ret
def strip_variants address address _ parse_variants address return address
def _skip_answer_ratelimit request return 'delete_images' in request.POST or 'upload_image' in request.POST
def __determine_delete_kwargs options delete_kwargs __kwargs_option_to_dict options.delete_kwargs project delete_kwargs.get 'project' options.project if project '' try project get_metadata 'project/project-id' except raise ValueError 'projectisrequiredwhennotrunningonGCP' delete_kwargs['project'] projectreturn delete_kwargs
def attachReject a TpPd pd 3 b MessageType mesType 1 c GmmCause packet a / b / c return packet
def get_qiime_hex_string_color index assert index > 0 'TherearenonegativeindicesfortheQIIMEcolors'n_colors len data_color_order if index > n_colors index int index - floor index / n_colors * n_colors return data_colors[data_color_order[index]].toHex
def enable_root_login sshd_config '/etc/ssh/sshd_config' _update_ssh_setting sshd_config 'PermitRootLogin' 'yes'
def format_histograms raw_hist pre_hist post_hist bin_edges lines []lines.append '#binsrawsequencelengths lengthofsequencesthatpassqualityfiltersbeforeprocessing andlengthsofsequencesthatpassqualityfilterspostprocessing.' lines.append 'Length DCTB Raw DCTB Before DCTB After' for edge raw pre post in zip bin_edges raw_hist pre_hist post_hist lines.append ' DCTB '.join map str [edge raw pre post] return '\n'.join lines
def with_metaclass meta *bases class metaclass meta __call__ type.__call____init__ type.__init__def __new__ cls name this_bases d if this_bases is None return type.__new__ cls name d return meta name bases d return metaclass 'DummyMetaClass' None {}
def _decode_data packet packet_buff offset if len packet_buff < offset + 2 raise InvalidPacketException u'DATApackettoosmall <4 %s' % repr packet_buff block_number struct.unpack_from '!H' packet_buff offset data packet_buff[ offset + 2 ]packet['block_number'] block_numberpacket['data'] datareturn packet
def renders col_name def wrap f if not hasattr f '_col_name' f._col_name col_namereturn freturn wrap
def set_username user_id new_username user_settings get_user_settings user_id strict True UserSettings.require_valid_username new_username if is_username_taken new_username raise utils.ValidationError 'Sorry theusername"%s"isalreadytaken!Pleasepickadifferentone.' % new_username user_settings.username new_username_save_user_settings user_settings
def ec2_credentials_list user_id None name None profile None **connection_args kstone auth profile **connection_args ret {}if name for user in kstone.users.list if user.name name user_id user.idbreakif not user_id return {'Error' 'Unabletoresolveuserid'}for ec2_credential in kstone.ec2.list user_id ret[ec2_credential.user_id] {'user_id' ec2_credential.user_id 'tenant_id' ec2_credential.tenant_id 'access' ec2_credential.access 'secret' ec2_credential.secret}return ret
def create_user_profile sender **kwargs user kwargs['instance']if not UserProfile.objects.filter user user UserProfile user user .save
def ensure_str_or_int x if isinstance x int return xx x if isinstance x str else str x try x ast.literal_eval x except ValueError SyntaxError passif not isinstance x int str msg '{0!r}couldnotbeconvertedtointorstr'.format x raise ValueError msg return x
def kstatvar data n 2 data ravel data N len data if n 1 return kstat data n 2 * 1.0 / N elif n 2 k2 kstat data n 2 k4 kstat data n 4 return 2 * N * k2 ** 2 + N - 1 * k4 / N * N + 1 else raise ValueError 'Onlyn 1orn 2supported.'
def docstrings_disabled return docstrings_disabled.__doc__ is None
def was_active reference_date_value asset return asset.start_date.value < reference_date_value < asset.end_date.value
def test_deriv np.random.seed 24235 for link in Links for k in range 10 p np.random.uniform 0 1 d link.deriv p da nd.approx_fprime np.r_[p] link assert_allclose d da rtol 1e-06 atol 1e-06 err_msg str link
def get_thread_list_url request course_key topic_id_list None following False path reverse 'thread-list' query_list [ 'course_id' unicode course_key ] + [ 'topic_id' topic_id for topic_id in topic_id_list or [] ] + [ 'following' following ] if following else [] return request.build_absolute_uri urlunparse '' '' path '' urlencode query_list ''
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _to_jsonc_name member_name characters []uppercase_next Falsefor character in member_name if character '_' uppercase_next Trueelif uppercase_next characters.append character.upper uppercase_next Falseelse characters.append character return ''.join characters
@staff_member_requireddef cache_stats request template_name u'admin/cache_stats.html' cache_stats get_cache_stats cache_info settings.CACHES[DEFAULT_FORWARD_CACHE_ALIAS]return render_to_response template_name RequestContext request {u'cache_hosts' cache_stats u'cache_backend' cache_info[u'BACKEND'] u'title' _ u'ServerCache' u'root_path' settings.SITE_ROOT + u'admin/db/' }
def parse_path_data path_data path []for item in path_data usage_key UsageKey.from_string item[0] usage_key usage_key.replace course_key modulestore .fill_in_run usage_key.course_key path.append PathItem usage_key item[1] return path
def GetSecret secret return GetSecretsManagerForSecret secret .GetSecret secret
def removeduppaths L []known_paths set for dir in sys.path dir dircase makepath dir if not dircase in known_paths L.append dir known_paths.add dircase sys.path[ ] Lreturn known_paths
def get_registered_auth_backend backend_id warn u'reviewboard.accounts.backends.get_registered_auth_backend isdeprecated.Usereviewboard.accounts.backends.auth_backends.register instead.' DeprecationWarning return auth_backends.get u'backend_id' backend_id
def create_gradient base_color stop QPointF 0 0 finalStop QPointF 0 1 grad QLinearGradient stop finalStop grad.setStops [ 0.0 base_color 0.5 base_color 0.8 base_color.darker 105 1.0 base_color.darker 110 ] grad.setCoordinateMode QLinearGradient.ObjectBoundingMode return grad
def validate_method method dy fit_mean nterms frequency assume_regular_frequency methods available_methods fast_method_ok 'fast' in methods prefer_fast fast_method_ok and len frequency > 200 and assume_regular_frequency or _is_regular frequency prefer_scipy 'scipy' in methods and dy is None and not fit_mean if method 'auto' if not fast_method_ok warnings.warn 'FastLomb-Scarglemethodsrequirenumpyversion1.8ornewer.Usingslowermethodsinstead.' if nterms ! 1 if prefer_fast method 'fastchi2'else method 'chi2'elif prefer_fast method 'fast'elif prefer_scipy method 'scipy'else method 'cython'if method not in METHODS raise ValueError 'invalidmethod {0}'.format method return method
def parse_external_id output type EXTERNAL_ID_TYPE_ANY external_id Nonefor pattern_type pattern in EXTERNAL_ID_PATTERNS if type ! EXTERNAL_ID_TYPE_ANY and type ! pattern_type continuematch search pattern output if match external_id match.group 1 breakreturn external_id
def _build_session username password trans_label None bigip requests.session bigip.auth username password bigip.verify Falsebigip.headers.update {'Content-Type' 'application/json'} if trans_label trans_id __salt__['grains.get'] 'bigip_f5_trans {label}'.format label trans_label if trans_id bigip.headers.update {'X-F5-REST-Coordination-Id' trans_id} else bigip.headers.update {'X-F5-REST-Coordination-Id' None} return bigip
def _create_unit_form request language unit form_class unit_form_factory language request request return form_class request.POST instance unit request request
def decorator wrapped_decorator def helper _func None **options def outer_wrapper func @wrapping func def inner_wrapper *args **kwds return wrapped_decorator func args kwds **options return inner_wrapperif _func is None return outer_wrapperif options raise TypeError 'positionalargumentsnotsupported' return outer_wrapper _func helper.wrapped_decorator wrapped_decoratorreturn helper
def _records_match old_ttl old_record_data new_ttl new_record_data matches Trueif old_ttl ! new_ttl matches Falseif old_record_data ! new_record_data matches Falsereturn matches
def _get_hub global _threadlocaltry return _threadlocal.hubexcept AttributeError pass
def test_mnist_valid skip_if_no_data mode get_default_mode if hasattr mode 'check_py_code' old_value mode.check_py_codemode.check_py_code Falsetry if config.mode 'DEBUG_MODE' yaml_file 'mnist_valid_fast'else yaml_file 'mnist_valid'limited_epoch_train os.path.join yaml_file_path '%s.yaml' % yaml_file try os.remove os.path.join save_path '%s.pkl' % yaml_file os.remove os.path.join save_path '%s_best.pkl' % yaml_file except Exception passfinally if hasattr mode 'check_py_code' mode.check_py_code old_value
def set_implicit_options role_fn if not hasattr role_fn 'options' or role_fn.options is None role_fn.options {'class' directives.class_option}elif not role_fn.options.has_key 'class' role_fn.options['class'] directives.class_option
def delete_instance model *instance_or_pk cache.delete_many [instance_key model x for x in instance_or_pk]
def _expand_cloned elements return itertools.chain *[x._cloned_set for x in elements]
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
@register_canonicalize 'fast_compile' 'local_cut_useless_reduce' @register_useless 'local_cut_useless_reduce' @gof.local_optimizer ALL_REDUCE def local_useless_reduce node if isinstance node.op T.CAReduce summed node.inputsif summed.type node.outputs[0].type return [summed]
def _getMethodNameInClass method if getattr method.im_class method.__name__ object ! method for alias in dir method.im_class if getattr method.im_class alias object method return aliasreturn method.__name__
def make_insecure_stub stub_class host port None if port is None target hostelse target '%s %d' % host port channel grpc.insecure_channel target return stub_class channel
def is_pyflakes_installed return programs.is_module_installed 'pyflakes' PYFLAKES_REQVER
def get_func_defaults func if PY2 return func.func_defaultselse return func.__defaults__
def invalidate_invoice obj_invoice if not obj_invoice.is_valid return HttpResponseBadRequest _ 'Thesaleassociatedwiththisinvoicehasalreadybeeninvalidated.' obj_invoice.is_valid Falseobj_invoice.save message _ 'Invoicenumber{0}hasbeeninvalidated.' .format obj_invoice.id return JsonResponse {'message' message}
def _atan p iv prec R p.ringmo R -1 c [ - mo ]p2 rs_square p iv prec for k in range 1 prec c.append mo ** k / 2 * k + 1 s rs_series_from_list p2 c iv prec s rs_mul s p iv prec return s
def get_string_module project code resource None force_errors False return pyobjectsdef.PyModule project.pycore code resource force_errors force_errors
def failed seg return seg._marked is False and seg._uploaded is False
def _get_weights max_length weights [1]for i in range 1 max_length weights.append weights[ i - 1 ] * len _ALPHABET + 1 weights.reverse return weights
def getTransformedOutlineByPath path xmlElement yAxisPointingUpward aroundsFromPath intercircle.getAroundsFromPath path getStrokeRadius xmlElement return getChainMatrixSVGIfNecessary xmlElement yAxisPointingUpward .getTransformedPaths aroundsFromPath
def salt_run import salt.cli.runif '' in sys.path sys.path.remove '' client salt.cli.run.SaltRun _install_signal_handlers client client.run
def _find_migrate_repo path os.path.join os.path.abspath os.path.dirname __file__ 'migrate_repo' assert os.path.exists path return path
def _remove_dots src output {}for key val in six.iteritems src if isinstance val dict val _remove_dots val output[key.replace '.' '-' ] valreturn output
def first_or_default items default None for item in items return itemreturn default
def is_error_status status status.check_initialized return RpcError.from_state status.state is not None
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
@jit nopython True def _generate_a_indptr num_states s_indices out idx 0out[0] 0for s in range num_states - 1 while s_indices[idx] s idx + 1out[ s + 1 ] idxout[num_states] len s_indices
def GetLoadBalancers region node_types None elb_names []if node_types is not None for n in node_types assert n in kLoadBalancerNames.keys 'node_type%sdoesnothaveanassociatedloadbalancer %r ' % n kLoadBalancerNames elb_names.append kLoadBalancerNames[n] if not elb_names elb_names Noneec2_elb _ConnectELB region return ec2_elb.get_all_load_balancers load_balancer_names elb_names
def dmp_integrate f m u K if not u return dup_integrate f m K if m < 0 or dmp_zero_p f u return f g v dmp_zeros m u - 1 K u - 1 for i c in enumerate reversed f n i + 1 for j in range 1 m n * i + j + 1 g.insert 0 dmp_quo_ground c K n v K return g
def ask_to_proceed_with_overwrite filepath get_input inputif sys.version_info[ 2] < 2 7 get_input raw_inputoverwrite get_input '[WARNING]%salreadyexists-overwrite?[y/n]' % filepath while overwrite not in ['y' 'n'] overwrite get_input 'Enter"y" overwrite or"n" cancel .' if overwrite 'n' return Falseprint '[TIP]Nexttimespecifyoverwrite True!' return True
def getFirstWordFromLine line return getFirstWord line.split
def unzip ls nout out list zip *ls if not out out [ ] * nout return out
def dijkstra_path G source target weight 'weight' length path single_source_dijkstra G source target target weight weight try return path[target]except KeyError raise nx.NetworkXNoPath 'node%snotreachablefrom%s' % target source
def getCentersFromPoints points radius circleNodes getCircleNodesFromPoints points abs radius return getCentersFromCircleNodes circleNodes abs radius
def is_acme_error err return ERROR_PREFIX in str err or OLD_ERROR_PREFIX in str err
@task name 'geonode.tasks.deletion.delete_layer' queue 'cleanup' def delete_layer object_id try layer Layer.objects.get id object_id except Layer.DoesNotExist returnlayer.delete
def apply_temporary_fixes font is_for_cros False font_name font_data.font_name font weight noto_fonts.parse_weight font_name weight_number noto_fonts.WEIGHTS[weight]if is_for_cros and weight 'Thin' weight_number 100font['OS/2'].usWeightClass weight_numbername_records font_data.get_name_records font family_name name_records[1]if family_name.endswith 'Black' font['head'].macStyle | 1 << 0 font['OS/2'].fsSelection | 1 << 5 font['OS/2'].fsSelection & ~ 1 << 6
def check_depends name def check n filename nodes get_nodes_by_name n name depends [e.attributes for e in nodes if 'thirdparty' not in e.attributes.keys ]try packages [d['package'].value for d in depends]except KeyError raise ManifestException "Invalidmanifestfile dependsismissing'package'attribute" return [Depend p for p in packages]return check
def only name hostnames ret {'name' name 'changes' {} 'result' None 'comment' ''}if isinstance hostnames six.string_types hostnames [hostnames]old ''.join __salt__['hosts.get_alias'] name new ''.join x.strip for x in hostnames if old new ret['comment'] 'IPaddress{0}alreadysetto"{1}"'.format name new ret['result'] Truereturn retif __opts__['test'] ret['comment'] 'Wouldchange{0}from"{1}"to"{2}"'.format name old new return retret['result'] __salt__['hosts.set_host'] name new if not ret['result'] ret['comment'] 'hosts.set_hostfailedtochange{0}' + 'from"{1}"to"{2}"' .format name old new return retret['comment'] 'successfullychanged{0}from"{1}"to"{2}"'.format name old new ret['changes'] {name {'old' old 'new' new}}return ret
def CheckFile filename if not os.path.exists filename raise FileNotFoundError '%s filenotfound' % filename elif not os.access filename os.R_OK raise FileNotReadableError '%s filenotreadable' % filename
def encode_for_querystring s if not isinstance s unicode raise TypeError u'unicoderequired' return urlsafe_b64encode s.encode u'utf8' .replace ' ' '~' .decode u'ascii'
def split_data data prob results [] [] for row in data results[ 0 if random.random < prob else 1 ].append row return results
def link src dst if platform.system u'Windows' if ctypes.windll.kernel32.CreateHardLinkW ctypes.c_wchar_p unicode dst ctypes.c_wchar_p unicode src None 0 raise ctypes.WinError else ek os.link src dst
def CodeRanges code_list re_list [CodeRange code_list[i] code_list[ i + 1 ] for i in range 0 len code_list 2 ]return Alt *re_list
def null_image return QImage
def recursive_filelisting base_directories for base_directory in base_directories for root _ files in os.walk base_directory for leaffile in files yield os.path.join root leaffile
def get_ogr_db_string db connections.databases['default']drivers {'django.contrib.gis.db.backends.postgis' 'PostgreSQL' "PG dbname '% db_name s'" '' 'django.contrib.gis.db.backends.mysql' 'MySQL' 'MYSQL "% db_name s"' ' ' 'django.contrib.gis.db.backends.spatialite' 'SQLite' '% db_name s' '' } drv_name db_str param_sep drivers[db['ENGINE']]try Driver drv_name except return Noneif db['NAME'] ' memory ' return Noneparams [ db_str % {'db_name' db['NAME']} ]def add key template value db.get key None if value params.append template % value add 'HOST' "host '%s'" add 'PORT' "port '%s'" add 'USER' "user '%s'" add 'PASSWORD' "password '%s'" return param_sep.join params
def x11FontDirectory fontpaths []def add arg directory files fontpaths.append directory for fontdir in X11FontDirectories try if os.path.isdir fontdir os.path.walk fontdir add None except IOError OSError TypeError ValueError passreturn fontpaths
def get_http_prompt_path python_dir os.path.dirname sys.executable bin_name 'http-prompt'if sys.platform 'win32' bin_name + '.exe'paths [os.path.join python_dir bin_name os.path.join python_dir 'Scripts' bin_name '/usr/bin/http-prompt']for path in paths if os.path.exists path return pathraise OSError 'couldnotlocatehttp-promptexecutable Pythondirectory %s' % python_dir
def get_subnet_length mask if not salt.utils.validate.net.netmask mask raise SaltInvocationError "'{0}'isnotavalidnetmask".format mask return salt.utils.network.get_net_size mask
@cli.command def build_webui cwd os.path.join 'flexget' 'ui' click.echo 'cleaningpreviousbuilds' for folder in ['bower_componentsnode_modules'] folder os.path.join cwd folder if os.path.exists folder click.echo 'Deletingrecursively{}'.format folder shutil.rmtree folder click.echo 'running`npminstall`' subprocess.check_call 'npminstall' cwd cwd shell True click.echo 'running`bowerinstall`' subprocess.check_call 'bowerinstall' cwd cwd shell True click.echo 'running`gulpbuildapp`' subprocess.check_call 'gulpbuildapp' cwd cwd shell True
def insert_doc doc new_items doclist doc.split u'\n' tmpdoc doclist[ 2]tmpdoc.extend new_items tmpdoc.extend doclist[2 ] newdoc []for line in tmpdoc newdoc.append line newdoc.append u'\n' newdoc.pop -1 return u''.join newdoc
def compute_sequence_shape context builder ndim seqty seq intp_t context.get_value_type types.intp zero Constant.int intp_t 0 def get_first_item seqty seq if isinstance seqty types.BaseTuple if len seqty 0 return None None else return seqty[0] builder.extract_value seq 0 else getitem_impl _get_borrowing_getitem context seqty return seqty.dtype getitem_impl builder seq zero shapes [] innerty inner seqty seq for i in range ndim shapes.append _get_seq_size context builder innerty inner innerty inner get_first_item innerty inner return tuple shapes
def find_links line l line.replace '%' '%%' regex ' https? //[^ ]+ 'return re.sub regex '%s' l [m.group 1 for m in re.finditer regex l ]
def _trans_from_params param_info params do_rotate do_translate do_scale param_infoi 0trans []if do_rotate x y z params[ 3]trans.append rotation x y z i + 3if do_translate x y z params[i i + 3 ]trans.insert 0 translation x y z i + 3if do_scale 1 s params[i]trans.append scaling s s s elif do_scale 3 x y z params[i i + 3 ]trans.append scaling x y z trans reduce dot trans return trans
def augParseCategory line primitives families var None cat_string rest nextCategory line if cat_string.startswith u' ' res var augParseCategory cat_string[1 -1 ] primitives families var else res var parsePrimitiveCategory PRIM_RE.match cat_string .groups primitives families var while rest ! u'' app APP_RE.match rest .groups direction parseApplication app[0 3] rest app[3] cat_string rest nextCategory rest if cat_string.startswith u' ' arg var augParseCategory cat_string[1 -1 ] primitives families var else arg var parsePrimitiveCategory PRIM_RE.match cat_string .groups primitives families var res FunctionalCategory res arg direction return res var
def p_type_specifier t pass
def safe_dict d if isinstance d dict return dict [ k.encode 'utf-8' safe_dict v for k v in d.items ] elif isinstance d list return [safe_dict x for x in d]else return d
def make_tree_defs mod_files_list tree_defs {}for mod files in mod_files_list node tree_defs for prefix in mod.split '.' node node[0].setdefault prefix [{} []] node[1] + filesreturn tree_defs
@auth.s3_requires_membership 2 def submission_old response.headers['Content-Type'] 'text/xml'xml str request.post_vars.xml_submission_file.value if len xml 0 raise HTTP 400 'Needsomexml!' importxml db xml r HTTP 201 'Saved.' r.headers['Location'] request.env.http_hostraise r
def _log_wishart_norm degrees_of_freedom log_det_precisions_chol n_features return - degrees_of_freedom * log_det_precisions_chol + degrees_of_freedom * n_features * 0.5 * math.log 2.0 + np.sum gammaln 0.5 * degrees_of_freedom - np.arange n_features [ np.newaxis] 0
def check_link_status tnow time.time if mpstate.status.last_message ! 0 and tnow > mpstate.status.last_message + 5 say 'nolink' mpstate.status.heartbeat_error Truefor master in mpstate.mav_master if not master.linkerror and tnow > master.last_message + 5 or master.portdead say 'link%udown' % master.linknum + 1 master.linkerror True
def _date_from_json value field if _not_null value field return _date_from_iso8601_date value
def test_all_pr pos_scores [ -1.0 0.0 2.0]neg_scores [ -2.0 0.0 1.0]precision [1.0 1.0 0.5 0.5 0.6 3.0 / 6.0 ]recall [0.0 1.0 / 3.0 1.0 / 3.0 2.0 / 3.0 1.0 1.0] p r all_pr pos_scores neg_scores assert len p len precision assert len r len recall for i in xrange len p assert p[i] precision[i] i p[i] precision[i] assert recall[i] recall[i]
def cumdims_label chunks const return [tuple zip const * 1 + len bds accumulate add 0 + bds for bds in chunks]
def pretaxonomy_hook generator category_objects {}real_articles []for article in generator.articles dirname fname os.path.split article.source_path fname _ os.path.splitext fname if fname 'index' category_objects[dirname] make_category article os.path.basename dirname else real_articles.append article category_assignment re.compile '^ ' + '|'.join re.escape prefix for prefix in category_objects.keys + ' /' for article in real_articles m category_assignment.match article.source_path if not m or m.group 1 not in category_objects logger.error 'Nocategoryassignmentfor%s %s ' article article.source_path continuearticle.category category_objects[m.group 1 ]patch_urlformat article generator.articles real_articles
def postgres command show not command.startswith u'psql' return sudo command show show user u'postgres'
def darker image1 image2 image1.load image2.load return image1._new image1.im.chop_darker image2.im
def format_qual_output qual_array qual_line_size 60qual_scores ''for slice in range 0 len qual_array qual_line_size current_segment qual_array[slice slice + qual_line_size ]current_segment ''.join str score for score in current_segment + '\n' qual_scores + current_segment"qual_array str qual_array \nqual_array qual_array.replace '[' '' \nqual_array qual_array.replace ']' '' "return qual_scores
def facebook_profile open_graph_share user open_graph_share.userprofile get_profile user facebook_id profile.facebook_idfacebook_url 'http //www.facebook.com/%s/' % facebook_id link '<p><ahref "%s"><imgsrc "http //graph.facebook.com/%s/picture/?type large"width "100px"style "float left"/>%s</a><br/></p>' % facebook_url facebook_id facebook_id return link
def activate_matplotlib backend import matplotlibmatplotlib.interactive True matplotlib.rcParams['backend'] backendimport matplotlib.pyplotmatplotlib.pyplot.switch_backend backend import matplotlib.pyplot as pltplt.show._needmain Falseplt.draw_if_interactive flag_calls plt.draw_if_interactive
def date value arg None from django.utils.dateformat import formatif not value return ''if arg is None arg settings.DATE_FORMATreturn format value arg
def test_ast_bad_while cant_compile u' while ' cant_compile u' while True '
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def relMatches rel_attr target_rel rels rel_attr.strip .split for rel in rels rel rel.lower if rel target_rel return 1return 0
def test_bc_fit ratio 'auto'bc BalanceCascade ratio ratio random_state RND_SEED bc.fit X Y assert_equal bc.min_c_ 0 assert_equal bc.maj_c_ 1 assert_equal bc.stats_c_[0] 8 assert_equal bc.stats_c_[1] 12
def CreateUploadSession creation success_path user max_bytes_per_blob max_bytes_total bucket_name None entity datastore.Entity _UPLOAD_SESSION_KIND namespace '' entity_dict {'creation' creation 'success_path' success_path 'user' user 'state' 'init' 'max_bytes_per_blob' max_bytes_per_blob 'max_bytes_total' max_bytes_total}if bucket_name entity_dict['gs_bucket_name'] bucket_nameentity.update entity_dict datastore.Put entity return str entity.key
def format_acl version 1 **kwargs if version 1 return format_acl_v1 groups kwargs.get 'groups' referrers kwargs.get 'referrers' header_name kwargs.get 'header_name' elif version 2 return format_acl_v2 kwargs.get 'acl_dict' raise ValueError 'InvalidACLversion %r' % version
def get_redis **kwargs redis_cls kwargs.pop 'redis_cls' defaults.REDIS_CLS url kwargs.pop 'url' None if url return redis_cls.from_url url **kwargs else return redis_cls **kwargs
def get_mod_func callback try dot callback.rindex u'.' except ValueError return callback u'' return callback[ dot] callback[ dot + 1 ]
def get_file_lines path data get_file_content path if data ret data.splitlines else ret []return ret
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def get_organization organization_id if not organizations_enabled return []from organizations import api as organizations_apireturn organizations_api.get_organization organization_id
def parse_mapping fileobj filename None extractors {}method_map []options_map {}parser RawConfigParser parser._sections odict parser._sections parser.readfp fileobj filename for section in parser.sections if section 'extractors' extractors dict parser.items section else method pattern [part.strip for part in section.split ' ' 1 ]method_map.append pattern method options_map[pattern] dict parser.items section if extractors for idx pattern method in enumerate method_map if method in extractors method extractors[method]method_map[idx] pattern method return method_map options_map
def write fd data return WriteEvent fd data
def make_url_for_lib key if isinstance key LibraryLocator key unicode key return LIBRARY_REST_URL + key
def generate_tokens readline try for token in tokenize2.generate_tokens readline yield token except tokenize2.TokenError return
def dump_neigh_entries ip_version device None namespace None **kwargs return list privileged.dump_neigh_entries ip_version device namespace **kwargs
def sampling_P condition given_condition None numsamples 1 evalf True **kwargs count_true 0count_false 0samples sample_iter condition given_condition numsamples numsamples **kwargs for x in samples if x ! True and x ! False raise ValueError 'Conditionsmustnotcontainfreesymbols' if x count_true + 1else count_false + 1result S count_true / numsamples if evalf return result.evalf else return result
def get_image vm_ vm_image config.get_cloud_config_value 'image' vm_ __opts__ .encode 'ascii' 'salt-cloud-force-ascii' images avail_images for key value in images.iteritems if vm_image and vm_image in images[key]['id'] images[key]['name'] return images[key]raise SaltCloudNotFound "Thespecifiedimage '{0}' couldnotbefound.".format vm_image
def load_tests loader tests pattern suite unittest.TestSuite test_names loader.getTestCaseNames ModuleTest for module in iter_modules suite.addTests [ModuleTest name module for name in test_names] return suite
def GetLevel return _Level
def get_full_index route None app None if not frappe.local.flags.children_map from frappe.website.router import get_pageschildren_map {}pages get_pages app app for route page_info in pages.iteritems parent_route os.path.dirname route children_map.setdefault parent_route [] .append page_info if frappe.flags.local_docs page_info.extn u'.html'for route children in children_map.items page_info pages[route]if page_info.index new_children []page_info.extn u''for name in page_info.index child_route page_info.route + u'/' + name if child_route in pages new_children.append pages[child_route] for c in children if c not in new_children new_children.append c children_map[route] new_childrenfrappe.local.flags.children_map children_mapreturn frappe.local.flags.children_map
def test_option_w_unset pyi_builder pyi_builder.test_source "\nimportsys\nassert'ignore'notinsys.warnoptions\n"
def render_live_params runner_parameters action_parameters params action_context G _create_graph action_context [_process G name value for name value in six.iteritems params ]_process_defaults G [action_parameters runner_parameters] _validate G context _resolve_dependencies G live_params _cast_params_from params context [action_parameters runner_parameters] return live_params
def _use_inf_as_null key from pandas.core.config import get_optionflag get_option key if flag globals ['_isnull'] _isnull_oldelse globals ['_isnull'] _isnull_new
def sz_margins start None end None retry_count 3 pause 0.001 data pd.DataFrame if start is None and end is None end du.today start du.day_last_week if start is None or end is None ct._write_msg rv.MAR_SZ_HZ_MSG2 return Nonetry date_range pd.date_range start start end end freq 'B' if len date_range > 261 ct._write_msg rv.MAR_SZ_HZ_MSG else ct._write_head for date in date_range data data.append _sz_hz str date.date retry_count pause except ct._write_msg ct.DATA_INPUT_ERROR_MSG else return data
def export_stats_project request project obj get_project request project data get_project_stats obj return export_response request 'stats-%s.csv' % obj.slug 'language' 'code' 'total' 'translated' 'translated_percent' 'total_words' 'translated_words' 'words_percent' data
def get_nom_val atrv r_nominal re.compile '{ .+ }' m r_nominal.match atrv if m return tuple i.strip for i in m.group 1 .split ' ' else raise ValueError 'Thisdoesnotlooklikeanominalstring'
def translate s table deletions '' return s.translate table deletions
def get_users_with_perms obj ctype ContentType.objects.get_for_model obj permissions {}PERMISSIONS_TO_FETCH ADMIN_PERMISSIONS + LAYER_ADMIN_PERMISSIONS for perm in Permission.objects.filter codename__in PERMISSIONS_TO_FETCH content_type_id ctype.id permissions[perm.id] perm.codenameuser_model get_user_obj_perms_model obj users_with_perms user_model.objects.filter object_pk obj.pk content_type_id ctype.id permission_id__in permissions .values 'user_id' 'permission_id' users {}for item in users_with_perms if item['user_id'] in users users[item['user_id']].append permissions[item['permission_id']] else users[item['user_id']] [permissions[item['permission_id']]]profiles {}for profile in get_user_model .objects.filter id__in users.keys profiles[profile] users[profile.id]return profiles
def format_to_httpie context method None cmd ['http'] + _extract_httpie_options context quote True join_key_value True if method cmd.append method.upper cmd.append context.url cmd + _extract_httpie_request_items context quote True return ''.join cmd + '\n'
def getcwd cwd os.getcwd if is_win and is_py2 try unicode cwd except UnicodeDecodeError try import win32apicwd win32api.GetShortPathName cwd except ImportError passreturn cwd
def _rankdata a method 'average' if method ! 'max' raise NotImplementedError unique_all inverse np.unique a return_inverse True count bincount inverse minlength unique_all.size cum_count count.cumsum rank cum_count[inverse]return rank
def confirm_vote_message object_description vote_direction if vote_direction 'clear' message 'Confirmclearingyourvotefor<strong>%s</strong>.'else message 'Confirm<strong>%s</strong>votefor<strong>%%s</strong>.' % vote_direction return message % escape object_description
def get_user_by_email email try return EmailAddress.objects.get email__iexact email .userexcept EmailAddress.DoesNotExist try User get_user_model return User.objects.get email__iexact email except User.DoesNotExist return None
def _send_email user_id subject message from_address configuration_helpers.get_value 'email_from_address' settings.DEFAULT_FROM_EMAIL user User.objects.get id user_id user.email_user subject message from_address
def _post_logging_setup config plugins cli_args if config.validate_hooks hooks.validate_hooks config cli.possible_deprecation_warning config logger.debug 'certbotversion %s' certbot.__version__ logger.debug 'Arguments %r' cli_args logger.debug 'Discoveredplugins %r' plugins
def match document topic None result_key None result_relative_url '/_ah/prospective_search' result_task_queue 'default' result_batch_size DEFAULT_RESULT_BATCH_SIZE result_return_document True from google.appengine.ext import dbrequest prospective_search_pb.MatchRequest if isinstance document db.Model topic _get_document_topic document topic doc_pb db.model_to_protobuf document if result_return_document request.set_result_python_document_class _doc_class.MODEL elif isinstance document datastore.Entity topic _get_document_topic document topic doc_pb document.ToPb if result_return_document request.set_result_python_document_class _doc_class.ENTITY else raise DocumentTypeError request.set_topic topic request.mutable_document .CopyFrom doc_pb if result_key request.set_result_key result_key request.set_result_relative_url result_relative_url request.set_result_task_queue result_task_queue request.set_result_batch_size result_batch_size response prospective_search_pb.MatchResponse _make_sync_call 'matcher' 'Match' request response
def error_page_namespace k v if k ! 'default' k int k cherrypy.serving.request.error_page[k] v
def route_through_array array start end fully_connected True geometric True start end tuple start tuple end if geometric mcp_class MCP_Geometricelse mcp_class MCPm mcp_class array fully_connected fully_connected costs traceback_array m.find_costs [start] [end] return m.traceback end costs[end]
def replace_query_param url key val scheme netloc path query fragment urlparse.urlsplit url query_dict QueryDict query .copy query_dict[key] valquery query_dict.urlencode return urlparse.urlunsplit scheme netloc path query fragment
def encode string encoding None if type string is not ustr return stringreturn string.encode encoding or u'utf-8' u'replace'
def resource_add_path path if path in resource_paths returnLogger.debug 'Resource add<%s>inpathlist' % path resource_paths.append path
def getRotationBySplitLine splitLine return complex splitLine[1].replace ' ' '' .replace ' ' ''
def test_no_exception exception_app request response sanic_endpoint_test exception_app assert response.status 200 assert response.text 'OK'
def convert_TimeProperty model prop kwargs if prop.auto_now or prop.auto_now_add return Nonereturn f.DateTimeField format '%H %M %S' **kwargs
def Jitter values jitter 0.5 n len values return np.random.uniform - jitter + jitter n + values
def redis_is_running try queue get_queue Worker.all queue.connection except ConnectionError return Falsereturn True
def asset_type asset_type_choices 95 'asset' 100 'video' d100 random.randint 0 100 for choice in asset_type_choices if d100 < choice[0] return choice[1]return asset_type_choices[ -1 ][1]
def source_url farm server id secret size if size 'small' img_size 'n'elif size 'medium' img_size 'c'elif size 'large' img_size 'b'return 'https //farm{}.staticflickr.com/{}/{}_{}_{}.jpg'.format farm server id secret img_size
def lookahead n iterable for value in islice copy.copy iterable n None return valueraise IndexError n
def HandleRequestDirectly request client_address BaseHTTPServer.HTTPServer.process_request HttpServer request client_address
@frappe.whitelist def get_linked_doctypes doctype return frappe.cache .hget u'linked_doctypes' doctype lambda _get_linked_doctypes doctype
def tanh X return np.tanh X out X
def nova_to_osvif_instance instance info objects.instance_info.InstanceInfo uuid instance.uuid name instance.name if instance.obj_attr_is_set 'project_id' and instance.project_id is not None info.project_id instance.project_idreturn info
def flatten expr new new cls expr.__class__args []for arg in expr.args if arg.__class__ cls args.extend arg.args else args.append arg return new expr.__class__ *args
def detrend x order 1 axis -1 from scipy.signal import detrendif axis > len x.shape raise ValueError 'xdoesnothave%daxes' % axis if order 0 fit 'constant'elif order 1 fit 'linear'else raise ValueError 'ordermustbe0or1' y detrend x axis axis type fit return y
def test_elemwise_collapse4 shape 4 5 a cuda_ndarray.CudaNdarray theano._asarray numpy.random.rand *shape dtype 'float32' a theano._asarray numpy.random.rand *shape dtype 'float32' a2 tcn.shared_constructor a 'a' a3 a2.dimshuffle 'x' 0 1 'x' b tcn.CudaNdarrayType False False False False c a3 + b + 2 f pfunc [b] [c] mode mode_with_gpu v theano._asarray numpy.random.rand 5 shape[0] shape[1] 4 dtype 'float32' v cuda_ndarray.CudaNdarray v out f v [0]assert numpy.allclose out a.reshape 1 shape[0] shape[1] 1 + v + 2
def convert_to_grayscale imlist for imname in imlist im Image.open imname .convert 'L' im.save imname
def get_per_language_stats project result []languages Translation.objects.filter subproject__project project .values_list u'language' flat True .distinct total 0total_words 0for component in project.subproject_set.all try translation component.translation_set.all [0]total + translation.totaltotal_words + translation.total_wordsexcept IndexError passfor language in Language.objects.filter pk__in languages data Translation.objects.filter language language subproject__project project .aggregate Sum u'translated' Sum u'translated_words' translated data[u'translated__sum']translated_words data[u'translated_words__sum']pos Nonefor i data in enumerate result if translated > data[1] pos ibreakvalue language translated total translated_words total_words if pos is not None result.insert pos value else result.append value return result
def execute_java_async classpath main jvm_options None args None executor None workunit_factory None workunit_name None workunit_labels None cwd None workunit_log_config None distribution None create_synthetic_jar True synthetic_jar_dir None runner _get_runner classpath main jvm_options args executor cwd distribution create_synthetic_jar synthetic_jar_dir workunit_name workunit_name or main return execute_runner_async runner workunit_factory workunit_factory workunit_name workunit_name workunit_labels workunit_labels workunit_log_config workunit_log_config
def tensor_shape tensor result []for d in xrange len tensor.get_shape result.append tensor_dim tensor d return result
@api.errorhandlerdef default_error_handler error error ServerError return error.to_dict getattr error 'code' 500
def _configure changes cfgred Truereasons []fun 'update_config'for key in ['added' 'updated' 'removed'] _updated_changes changes.get key {} if not _updated_changes continue_location _updated_changes.get 'location' '' _contact _updated_changes.get 'contact' '' _community _updated_changes.get 'community' {} _chassis_id _updated_changes.get 'chassis_id' '' if key 'removed' fun 'remove_config'_ret __salt__['snmp.{fun}'.format fun fun ] location _location contact _contact community _community chassis_id _chassis_id commit False cfgred cfgred and _ret.get 'result' if not _ret.get 'result' and _ret.get 'comment' reasons.append _ret.get 'comment' return {'result' cfgred 'comment' '\n'.join reasons if reasons else '' }
def activity_stream context stream_type *args **kwargs if stream_type 'model' stream_type 'model_actions'if not hasattr Action.objects stream_type raise TemplateSyntaxError 'Actionmanagerhasnoattribute %s' % stream_type ctxvar kwargs.pop 'as' 'stream' context[ctxvar] getattr Action.objects stream_type *args **kwargs return ''
def attrsetter attr value return lambda method setattr method attr value or method
def _get_block_summary_totals course_data block_summary_counts {}unique_course_counts {}for course in course_data block_counts course.get BLOCK_COUNTS_KEY for count_label value in block_counts.items unique 0if value > 0 unique 1if count_label in block_summary_counts block_summary_counts[count_label] + valueunique_course_counts[count_label] + uniqueelse block_summary_counts[count_label] valueunique_course_counts[count_label] uniquereturn block_summary_counts unique_course_counts
@hug.default_input_format 'application/made-up' apply_globally True def made_up_formatter_global data return data
def seed_target_indices seeds targets seeds np.asarray seeds .ravel targets np.asarray targets .ravel n_seeds len seeds n_targets len targets indices np.concatenate [np.tile i n_targets for i in seeds] np.tile targets n_seeds return indices
def _get_kernel_context return _kernel_context
def _parse_snippet line lines filename start_line_index lines.line_index trigger description head_tail line[len 'snippet' ].lstrip content ''while True next_line lines.peek if next_line is None breakif next_line.strip and not next_line.startswith ' DCTB ' breakline next lines if line[0] ' DCTB ' line line[1 ]content + linecontent content[ -1 ]return 'snippet' SnipMateSnippetDefinition trigger content description '%s %i' % filename start_line_index
def _get_page_links page_numbers current url_func page_links []for page_number in page_numbers if page_number is None page_link PAGE_BREAKelse page_link PageLink url url_func page_number number page_number is_active page_number current is_break False page_links.append page_link return page_links
def _privateCertFromPaths certificatePath keyPath if certificatePath is None return NonecertBytes FilePath certificatePath .getContent if keyPath is None return PrivateCertificate.loadPEM certBytes else return PrivateCertificate.fromCertificateAndKeyPair Certificate.loadPEM certBytes KeyPair.load FilePath keyPath .getContent 1
def cleanup_subject subject_str if subject_str is None return ''cleanup_regexp ' ?i ^ re|fw|fwd|aw|wg|undeliverable|undelivered \\s* +'return re.sub cleanup_regexp '' subject_str
@webob.dec.wsgify@microversion.version_handler 1.2 @util.check_accept 'application/json' def list_resource_classes req context req.environ['placement.context']rcs objects.ResourceClassList.get_all context response req.responseresponse.body encodeutils.to_utf8 jsonutils.dumps _serialize_resource_classes req.environ rcs response.content_type 'application/json'return response
def dblint xa xb ya yb tck tx ty c kx ky tckreturn dfitpack.dblint tx ty c kx ky xa xb ya yb
def is_model_registered app_label model_name try apps.get_registered_model app_label model_name except LookupError return Falseelse return True
def _is_best_match class1 class2 format_classes return class1 is class2 or issubclass class1 class2 and class1 not in {cls for fmt cls in format_classes}
def set_app_global key value key value process_app_global key value setattr app_globals key value
def setDecoderPath decoder_path paths []paths.append decoder_path for root dirs files in os.walk decoder_path [dirs.remove d for d in dirs if d.startswith '.' ]for d in sorted dirs paths.append os.path.join root d return paths
def test_mpl_preserve_font_size f create_figure width height f.canvas.get_width_height s mplhooks.figure_to_tight_array f 0.5 * width 0.5 * height True exp FONT_SIZEobs matplotlib.rcParams['font.size']plt.close f assert exp obs
def test_unbalanced_exception try tokenize ' bar ' assert True is False except LexException passtry tokenize ' baz[quux]] ' assert True is False except LexException pass
def _dict_pprinter_factory start end basetype None def inner obj p cycle typ type obj if basetype is not None and typ is not basetype and typ.__repr__ ! basetype.__repr__ return p.text typ.__repr__ obj if cycle return p.text '{...}' step len start p.begin_group step start keys obj.keys if not p.max_seq_length and len obj > p.max_seq_length try keys sorted keys except Exception passfor idx key in p._enumerate keys if idx p.text ' ' p.breakable p.pretty key p.text ' ' p.pretty obj[key] p.end_group step end return inner
def split_trailing_whitespace word stripped_length len word.rstrip return word[0 stripped_length] word[stripped_length ]
def get_module_constant module symbol default -1 paths None try f path suffix mode kind find_module module paths except ImportError return Nonetry if kind PY_COMPILED f.read 8 code marshal.load f elif kind PY_FROZEN code imp.get_frozen_object module elif kind PY_SOURCE code compile f.read path 'exec' else if module not in sys.modules imp.load_module module f path suffix mode kind return getattr sys.modules[module] symbol None finally if f f.close return extract_constant code symbol default
def skip_backend unsupported reason def decorator test_method '\n paramtest_method Thetestmethodthatshouldbeskipped.\n'@wraps test_method def wrapper test_case *args **kwargs backend get_dataset_backend test_case if backend in unsupported raise SkipTest 'Backendnotsupported {backend} {reason} .'.format backend backend reason reason return test_method test_case *args **kwargs return wrapperreturn decorator
def plugin return BracketRemove
def output string_ context.output + str string_
def _check_thicknesses surfs for surf_1 surf_2 in zip surfs[ -1 ] surfs[1 ] min_dist _compute_nearest surf_1['rr'] surf_2['rr'] return_dists True [0]min_dist min_dist.min logger.info 'Checkingdistancebetween%sand%ssurfaces...' % _surf_name[surf_1['id']] _surf_name[surf_2['id']] logger.info 'Minimumdistancebetweenthe%sand%ssurfacesisapproximately%6.1fmm' % _surf_name[surf_1['id']] _surf_name[surf_2['id']] 1000 * min_dist
def test_nm2_sample_wt_fit ratio 'auto'nm2 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS assert_raises RuntimeError nm2.sample X Y
def normalize_uri uri encoding 'utf-8' normalized_reference URIReference.from_string uri encoding .normalize return normalized_reference.unsplit
def list_keypairs call None if call ! 'function' log.error 'Thelist_keypairsfunctionmustbecalledwith-for--function.' return Falsefetch Truepage 1ret {}while fetch items query method 'account/keys' command '?page ' + str page + '&per_page 100' for key_pair in items['ssh_keys'] name key_pair['name']if name in ret raise SaltCloudSystemExit "Aduplicatekeypairname '{0}' wasfoundinDigitalOcean'skeypairlist.PleasechangethekeynamestoredbyDigitalOcean.Besuretoadjustthevalueof'ssh_key_file'inyourcloudprofileorproviderconfiguration ifnecessary.".format name ret[name] {}for item in six.iterkeys key_pair ret[name][item] str key_pair[item] page + 1try fetch 'next' in items['links']['pages'] except KeyError fetch Falsereturn ret
def test_meta_config from pygal.config import CONFIG_ITEMSassert all c.name ! 'Unbound' for c in CONFIG_ITEMS
def loose_mock request name None **kwargs if name is None name request.fixturenamereturn Mock name name **kwargs
def is_subclass_at_all cls class_info try return issubclass cls class_info except TypeError return False
def _ToLocalPath toplevel_dir path if path toplevel_dir return ''if path.startswith toplevel_dir + '/' return path[ len toplevel_dir + len '/' ]return path
def pr_import_prep data db current.dbs3db current.s3dbset_record_owner current.auth.s3_set_record_ownerupdate_super s3db.update_supertable s3db.org_organisation resource tree dataelements tree.getroot .xpath "/s3xml//resource[@name 'pr_contact']/data[@field 'pe_id']" looked_up {}for element in elements org element.textif not org continueif org in looked_up element.text looked_up[org]continuerecord db table.name org .select table.pe_id limitby 0 1 .first if not record record_id table.insert **{'name' org} update_super table Storage id record_id set_record_owner table record_id record db table.id record_id .select table.pe_id limitby 0 1 .first pe_id record.pe_idelement.text str pe_id looked_up[org] pe_id
def sdk_normalize filename if filename.startswith '/Developer/SDKs/' pathcomp filename.split '/' del pathcomp[1 4]filename '/'.join pathcomp return filename
def symbology s symbols sorted ord c for c in s current_charset 0char_tally Counter for symbol in symbols while CHARSET_RANGES[current_charset].end < symbol current_charset + 1if CHARSET_RANGES[current_charset].start < symbol name CHARSET_RANGES[current_charset].nameelse name 'Unknown'char_tally[name] + 1return char_tally
def dump_pyopenssl_chain chain filetype OpenSSL.crypto.FILETYPE_PEM def _dump_cert cert if isinstance cert jose.ComparableX509 cert cert.wrappedreturn OpenSSL.crypto.dump_certificate filetype cert return ''.join _dump_cert cert for cert in chain
def dup_content f K from sympy.polys.domains import QQif not f return K.zerocont K.zeroif K QQ for c in f cont K.gcd cont c else for c in f cont K.gcd cont c if K.is_one cont breakreturn cont
def dmp_eval_in f a j u K if j < 0 or j > u raise IndexError '0< j< %sexpected got%s' % u j return _rec_eval_in f a u 0 j K
def default_on_success request identity_url openid_response **kwargs request.session['openid'] from_openid_response openid_response return HttpResponseRedirect clean_next request.GET.get 'next'
def nose_config_and_run argv None env None ignore_files [] plugins None if env is None env os.environif plugins is None plugins nose.plugins.manager.DefaultPluginManager if argv is None argv sys.argvtest_config nose.config.Config env os.environ ignoreFiles ignore_files plugins plugins test_config.plugins.addPlugin StructuredTestDataPlugin test_config.configure argv result run test_config success result.wasSuccessful return success
def gpi_iterator handle inline handle.readline if inline.strip '!gpi-version 1.1' return _gpi11iterator handle elif inline.strip '!gpi-version 1.0' return _gpi10iterator handle elif inline.strip '!gpi-version 2.1' return _gpi20iterator handle else raise ValueError 'UnknownGPIversion{0}\n'.format inline
def _coo_gen_triples A row col data A.row A.col A.data return zip row col data
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def tk_window_focus if rcParams[u'backend'] ! u'TkAgg' return Falsereturn rcParams[u'tk.window_focus']
def register_for_indexing app sender_class instance_to_indexee _identity m2m False def maybe_call_method instance is_raw method_name 'Callan un- indexingmethodoninstanceifappropriate.'obj instance_to_indexee instance if obj is not None and not is_raw getattr obj method_name def update sender instance **kw 'Fileanadd-to-indextaskfortheindicatedobject.'maybe_call_method instance kw.get 'raw' 'index_later' def delete sender instance **kw 'Filearemove-from-indextaskfortheindicatedobject.'maybe_call_method instance kw.get 'raw' 'unindex_later' def indexing_receiver signal signal_name 'Returnaroutinethatregisterssignalhandlersforindexers.\n\nThereturnedregistrationroutineusesstrongrefs makesupa\ndispatch_uid anduses``sender_class``asthesender.\n\n'return receiver signal sender sender_class dispatch_uid '%s.%s.elastic.%s' % app sender_class.__name__ signal_name weak False if m2m indexing_receiver m2m_changed 'm2m_changed' update else indexing_receiver post_save 'post_save' update indexing_receiver pre_delete 'pre_delete' delete if instance_to_indexee is _identity else update
def prepare_exec_for_file filename module []if os.path.split filename [1] '__init__.py' filename os.path.dirname filename elif filename.endswith '.py' filename filename[ -3 ]else raise NoAppException 'Thefileprovided %s doesexistbutisnotavalidPythonfile.Thismeansthatitcannotbeusedasapplication.Pleasechangetheextensionto.py' % filename filename os.path.realpath filename dirpath filenamewhile 1 dirpath extra os.path.split dirpath module.append extra if not os.path.isfile os.path.join dirpath '__init__.py' breaksys.path.insert 0 dirpath return '.'.join module[ -1 ]
def silent_call cmd return subprocess.call cmd stderr subprocess.PIPE stdout subprocess.PIPE
@ssl_required@anonymous_csrf@logout_required@require_http_methods ['GET' 'POST'] def user_auth request contributor False register_form None login_form None next_url get_next_url request or reverse 'home' if login_form is None login_form AuthenticationForm if register_form is None register_form RegisterForm return render request 'users/auth.html' {'login_form' login_form 'register_form' register_form 'contributor' contributor 'next_url' next_url}
def find_meta_property obj name meta obj.metaObject index meta.indexOfProperty name if index -1 raise AttributeError '%sdoesnohaveapropertynamed%r.' % meta.className name return meta.property index
def synonyms word2nums num2words word keys word2nums[word]syns set for key in keys syns syns.union num2words[key] if word in syns syns.remove word return sorted syns
def HeaderPrintMUADetails message mta None details []for header in MUA_ID_HEADERS value message.get header if value value ''.join [v for v in HP_MUA_ID_SPLIT.split value.strip if not HP_MUA_ID_IGNORE.search v ] details.extend [header value.strip ] if not details if mta and mta[0].startswith 'Receivedbygoogle.com' details.extend ['Guessed' 'GMail'] elif 'x-ms-tnef-correlator' in message or 'x-ms-has-attach' in message details.extend ['Guessed' 'Exchange'] elif '@mailpile' in message.get 'message-id' '' details.extend ['Guessed' 'Mailpile'] return details
def list_routers profile None conn _auth profile return conn.list_routers
def award_type mode session.s3.hrm.modedef prep r if mode is not None auth.permission.fail return Trues3.prep prepoutput s3_rest_controller return output
@register.inclusion_tag engine.get_template 'inclusion.html' def inclusion_one_param_from_template arg return {'result' 'inclusion_one_param_from_template-Expectedresult %s' % arg }
def colgen *lstcol **kargs if len lstcol < 2 lstcol * 2trans kargs.get 'trans' lambda x y z x y z while 1 for i in range len lstcol for j in range len lstcol for k in range len lstcol if i ! j or j ! k or k ! i yield trans lstcol[ i + j % len lstcol ] lstcol[ j + k % len lstcol ] lstcol[ k + i % len lstcol ]
def black_hole queue def _ignore msg print 'Ignoringmsg %r' % msg.body consume_items queue _ignore
def initial form data {}for name field in form.fields.items if form.is_bound data[name] form[name].dataelse data[name] form.initial.get name field.initial if isinstance field forms.BooleanField val field.to_python data[name] if not val del data[name]return data
def _gpg return salt.utils.which 'gpg'
def _ensure_annotations dashboard if 'annotation_tags' not in dashboard returntags dashboard['annotation_tags']annotations {'enable' True 'list' []}for tag in tags annotations['list'].append {'datasource' 'graphite' 'enable' False 'iconColor' '#C0C6BE' 'iconSize' 13 'lineColor' 'rgba 255 96 96 0.592157 ' 'name' tag 'showLine' True 'tags' tag} del dashboard['annotation_tags']dashboard['annotations'] annotations
def hijack_translation translation.check_for_language lambda lang_code True trans_real.check_for_language lambda lang_code True translation.get_language_from_request get_language_from_requesttranslation.get_language_bidi get_language_bidi
def _iterate_sparse_X X n_samples X.shape[0]X_indices X.indicesX_data X.dataX_indptr X.indptrfor i in xrange n_samples row np.zeros X.shape[1] startptr endptr X_indptr[i] X_indptr[ i + 1 ] nonzero_indices X_indices[startptr endptr]row[nonzero_indices] X_data[startptr endptr] yield row
def isstdin if not _state raise RuntimeError 'noactiveinput ' return _state.isstdin
def get_course_run course_key user catalog_integration CatalogIntegration.current if catalog_integration.enabled api create_catalog_api_client user catalog_integration data get_edx_api_data catalog_integration user 'course_runs' resource_id unicode course_key cache_key catalog_integration.CACHE_KEY if catalog_integration.is_cache_enabled else None api api querystring {'exclude_utm' 1} return data if data else {} else return {}
def _preferred_string value1 value2 if value1 value2 return value1if value1.istitle and not value2.istitle return value1if not value1.isupper and value2.isupper return value1if not value1.isupper and value1[0].isupper and not value2[0].isupper return value1if _count_title_words value1 > _count_title_words value2 return value1return value2
@command 'reverse' def reverse_songs g.model.songs g.model.songs[ -1 ]g.message c.y + 'Reverseddisplayedsongs' + c.w g.content content.generate_songlist_display
def _range_prod lo hi if lo + 1 < hi mid hi + lo // 2 return _range_prod lo mid * _range_prod mid + 1 hi if lo hi return loreturn lo * hi
def time_tensorflow_run session target info_string num_steps_burn_in 10total_duration 0.0total_duration_squared 0.0for i in xrange FLAGS.num_batches + num_steps_burn_in start_time time.time _ session.run target duration time.time - start_time if i > num_steps_burn_in if not i % 10 print '%s step%d duration %.3f' % datetime.now i - num_steps_burn_in duration total_duration + durationtotal_duration_squared + duration * duration mn total_duration / FLAGS.num_batches vr total_duration_squared / FLAGS.num_batches - mn * mn sd math.sqrt vr print '%s %sacross%dsteps %.3f+/-%.3fsec/batch' % datetime.now info_string FLAGS.num_batches mn sd
def _setup_args info coils _create_meg_coils info['chs'] 'normal' info['dev_head_t'] int_rad noise lut_fun n_fact _setup_dots 'fast' coils 'meg' my_origin np.array [0.0 0.0 0.04] args_dict dict intrad int_rad volume False coils1 coils r0 my_origin ch_type 'meg' lut lut_fun n_fact n_fact return args_dict
def libvlc_audio_equalizer_get_preset_count f _Cfunctions.get 'libvlc_audio_equalizer_get_preset_count' None or _Cfunction 'libvlc_audio_equalizer_get_preset_count' None ctypes.c_uint return f
@support_nddatadef block_reduce data block_size func np.sum from skimage.measure import block_reducedata np.asanyarray data block_size np.atleast_1d block_size if data.ndim > 1 and len block_size 1 block_size np.repeat block_size data.ndim if len block_size ! data.ndim raise ValueError u'`block_size`mustbeascalarorhavethesamelengthas`data.shape`' block_size np.array [int i for i in block_size] size_resampled np.array data.shape // block_size size_init size_resampled * block_size for i in range data.ndim if data.shape[i] ! size_init[i] data data.swapaxes 0 i data data[ size_init[i]]data data.swapaxes 0 i return block_reduce data tuple block_size func func
def _optional argument default if argument is _unspecified return defaultelse return argument
def skip_if_offline func @functools.wraps func def decorator *args **kwargs if context.is_offline_mode returnreturn func *args **kwargs return decorator
def select_command_with_arrows proc TIMEOUT _set_confirmation proc True proc.sendline u'gith' assert proc.expect [TIMEOUT u"git 'h'isnotagitcommand."] proc.sendline u'fuck' assert proc.expect [TIMEOUT u'gitshow'] proc.send '\x1b[B' assert proc.expect [TIMEOUT u'gitpush'] proc.send '\x1b[B' assert proc.expect [TIMEOUT u'githelp'] proc.send '\x1b[A' assert proc.expect [TIMEOUT u'gitpush'] proc.send '\x1b[B' assert proc.expect [TIMEOUT u'githelp'] proc.send '\n' assert proc.expect [TIMEOUT u'usage']
def test_teardown_issue1649 testdir testpath testdir.makepyfile '\nimportunittest\nclassTestCaseObjectsShouldBeCleanedUp unittest.TestCase \ndefsetUp self \nself.an_expensive_object 1\ndeftest_demo self \npass\n\n' testdir.inline_run '-s' testpath gc.collect for obj in gc.get_objects assert type obj .__name__ ! 'TestCaseObjectsShouldBeCleanedUp'
def exec_pg_environ env os.environ.copy if odoo.tools.config['db_host'] env['PGHOST'] odoo.tools.config['db_host']if odoo.tools.config['db_port'] env['PGPORT'] str odoo.tools.config['db_port'] if odoo.tools.config['db_user'] env['PGUSER'] odoo.tools.config['db_user']if odoo.tools.config['db_password'] env['PGPASSWORD'] odoo.tools.config['db_password']return env
def calc_at_content sequence d {}for nt in ['A' 'T' 'G' 'C'] d[nt] sequence.count nt + sequence.count nt.lower at d.get 'A' 0 + d.get 'T' 0 if at 0 return 0return at * 1.0 / d['G'] + d['G'] + at
def get_poetry host port timeout d defer.Deferred from twisted.internet import reactorfactory PoetryClientFactory d timeout reactor.connectTCP host port factory return d
def scopes_to_string scopes if isinstance scopes six.string_types return scopeselse return ''.join scopes
def _ValidateExclusionSetting setting settings error_msg stderr sys.stderr unrecognized Truem re.match _EXCLUDED_SUFFIX_RE setting if m root_setting m.group 1 unrecognized root_setting not in settings if unrecognized print >>stderr error_msg
def hexescape char hex_repr hex ord char [2 ].upper if len hex_repr 1 hex_repr '0%s' % hex_repr return '%' + hex_repr
def merge_traces mtraces base_mtrace mtraces[0]for new_mtrace in mtraces[1 ] for new_chain strace in new_mtrace._straces.items if new_chain in base_mtrace._straces raise ValueError 'Chainsarenotunique.' base_mtrace._straces[new_chain] stracereturn base_mtrace
def sort_by_attr seq attr intermed map None map getattr seq attr * len seq xrange len seq seq intermed.sort return map operator.getitem intermed -1 * len intermed
def unico string if is_python2 and not isinstance string unicode return unicode string encoding 'utf-8' errors 'replace' return string
def import_image src repo tag None client _get_client status base_status.copy try ret client.import_image src repository repo tag tag if ret image_logs _info _parse_image_multilogs_string ret _create_image_assemble_error_status status ret image_logs if status['status'] is not False infos _get_image_infos image_logs[0]['status'] _valid status comment 'Image{0}wascreated'.format infos['Id'] id_ infos['Id'] out ret else _invalid status except Exception _invalid status out traceback.format_exc return status
def test_rgb_to_hsl_part_0 assert rgb_to_hsl 255 0 0 0 100 50 assert rgb_to_hsl 255 255 0 60 100 50 assert rgb_to_hsl 0 255 0 120 100 50 assert rgb_to_hsl 0 255 255 180 100 50 assert rgb_to_hsl 0 0 255 240 100 50 assert rgb_to_hsl 255 0 255 300 100 50
def parse_change_values_from_opts opts change_values {}for key in 'change_ip' 'change_port' 'change_replication_ip' 'change_replication_port' 'change_device' 'change_meta' value getattr opts key None if value if key 'change_ip' or key 'change_replication_ip' value validate_and_normalize_address value change_values[key.replace 'change_' '' ] valuereturn change_values
def noguess method method._api Nonereturn method
@njitdef _repeat_1d x K out N x.shape[0]L out.shape[0] // K * N for n in range N val x[n]for k in range K for l in range L ind k * N * L + n * L + l out[ind] val
def _send_request payload None session None stub sessionhost_port stub.hosturl 'https //{0}/sdk'.format host_port logging.debug 'Sending{0}to{1}'.format payload url res requests.post url url data payload headers {'Cookie' stub.cookie 'SOAPAction' 'urn vim25' 'Content-Type' 'application/xml'} verify False if res.status_code ! 200 logging.debug 'Failedtoresetalarm.HTTPStatus {0}'.format res.status_code return Falsereturn True
def use_oslo_logger vlog.Vlog.emer LOG.criticalvlog.Vlog.err LOG.errorvlog.Vlog.warn LOG.warningvlog.Vlog.info LOG.infovlog.Vlog.dbg LOG.debug
@control_command def pool_restart state modules None reload False reloader None **kwargs if state.app.conf.worker_pool_restarts state.consumer.controller.reload modules reload reloader reloader return ok u'reloadstarted' else raise ValueError u'Poolrestartsnotenabled'
def will_write fn def _fn *a **kw if disallow_db_writes raise CassandraException 'Notsofast!DBwriteshavebeendisabled' return fn *a **kw return _fn
def auto_delete_files cls pre_delete.connect delete_files_for_obj sender cls return cls
def _convert_to_jsonc x if isinstance x dict jsonc_obj Jsonc for key value in x.iteritems jsonc_obj._dict[key] _convert_to_jsonc value return jsonc_objelif isinstance x list members []for item in x members.append _convert_to_jsonc item return memberselse return x
def getPluginsDirectoryPath return archive.getAbsoluteFolderPath os.path.dirname __file__ os.path.join 'skeinforge_plugins' 'analyze_plugins'
def smStatus a TpPd pd 8 b MessageType mesType 85 c SmCause packet a / b / c return packet
def transferClosestPath oldOrderedLocation remainingPaths skein closestDistance 1e+18closestPath NoneoldOrderedLocationComplex oldOrderedLocation.dropAxis 2 for remainingPath in remainingPaths distance min abs oldOrderedLocationComplex - remainingPath[0] abs oldOrderedLocationComplex - remainingPath[ -1 ] if distance < closestDistance closestDistance distanceclosestPath remainingPathremainingPaths.remove closestPath skein.addGcodeFromThreadZ closestPath oldOrderedLocation.z oldOrderedLocation.x closestPath[ -1 ].realoldOrderedLocation.y closestPath[ -1 ].imag
def requires_json_api_mimetype func @wraps func def new_func *args **kw 'Executes``func *args **kw ``onlyaftercheckingforthe\ncorrectJSONAPI http header `Content-Type`header.\n\n'if request.method not in 'PATCH' 'POST' return func *args **kw header request.headers.get 'Content-Type' content_type extra parse_options_header header content_is_json content_type.startswith JSONAPI_MIMETYPE is_msie _is_msie8or9 if not is_msie and not content_is_json detail 'Requestmusthave"Content-Type {0}"header'.format JSONAPI_MIMETYPE return error_response 415 detail detail if extra detail 'Content-Typeheadermustnothaveanymediatypeparametersbutfound{0}'.format extra return error_response 415 detail detail return func *args **kw return new_func
def _initialize_builtins for filename in os.listdir _handler_dir if os.path.isfile _get_yaml_path filename '' _available_builtins.append filename
def _image_type vda out __salt__['cmd.run'] 'qemu-imginfo{0}'.format vda if 'fileformat qcow2' in out return 'qcow2'else return 'raw'
def get_connected_hosts session datastore host_mounts session._call_method vutil 'get_object_property' datastore 'host' if not hasattr host_mounts 'DatastoreHostMount' return []connected_hosts []for host_mount in host_mounts.DatastoreHostMount connected_hosts.append host_mount.key.value return connected_hosts
def evaluate_old_assump pred return pred.xreplace Transform _old_assump_replacer
def get_configuration options agent_config options[u'agent-config']configuration yaml.safe_load agent_config.getContent validate_configuration configuration configuration configuration['control-service'].setdefault 'port' 4524 path agent_config.parent configuration['ca-certificate'] Certificate.loadPEM path.child 'cluster.crt' .getContent configuration['node-credential'] NodeCredential.from_path path 'node' return configuration
def set_standby_timeout timeout power 'ac' scheme None return _set_powercfg_value scheme 'SUB_SLEEP' 'STANDBYIDLE' power timeout
def StandardAnalyzer expression default_pattern stoplist STOP_WORDS minsize 2 maxsize None gaps False ret RegexTokenizer expression expression gaps gaps chain ret | LowercaseFilter if stoplist is not None chain chain | StopFilter stoplist stoplist minsize minsize maxsize maxsize return chain
def has_header headers name name name.lower for header value in headers if header.lower name return Truereturn False
def parse_rfc2822_date s date_tuple parsedate s if date_tuple is None return Nonereturn datetime.datetime *date_tuple[ 6]
def PBKDF1 password salt dkLen count 1000 hashAlgo None if not hashAlgo hashAlgo SHA1password tobytes password pHash hashAlgo.new password + salt digest pHash.digest_sizeif dkLen > digest raise TypeError 'Selectedhashalgorithmhasatooshortdigest %dbytes .' % digest if len salt ! 8 raise ValueError 'Saltisnot8byteslong.' for i in xrange count - 1 pHash pHash.new pHash.digest return pHash.digest [ dkLen]
def _appendReportKeys keys prefix results allKeys results.keys allKeys.sort for key in allKeys if hasattr results[key] 'keys' _appendReportKeys keys '%s%s ' % prefix key results[key] else keys.add '%s%s' % prefix key
def read_plain_boolean file_obj count return read_bitpacked file_obj count << 1 1 logger.isEnabledFor logging.DEBUG
def derived_sequence graph deriv_seq [graph]deriv_interv []single_node Falsewhile not single_node interv_graph interv_heads intervals graph deriv_interv.append interv_heads single_node len interv_graph 1 if not single_node deriv_seq.append interv_graph graph interv_graphgraph.compute_rpo return deriv_seq deriv_interv
def setup_conf opts [cfg.StrOpt 'dhcp_driver' default 'quantum.agent.linux.dhcp.Dnsmasq' help _ 'ThedriverusedtomanagetheDHCPserver.' cfg.BoolOpt 'force' default False help _ 'Deletethenamespacebyremovingalldevices.' ]conf cfg.CONFconf.register_opts opts agent_config.register_root_helper conf conf.register_opts dhcp.OPTS return conf
def fk4_e_terms equinox k 0.0056932k np.radians k e earth.eccentricity equinox.jd g earth.mean_lon_of_perigee equinox.jd g np.radians g o earth.obliquity equinox.jd algorithm 1980 o np.radians o return e * k * np.sin g - e * k * np.cos g * np.cos o - e * k * np.cos g * np.sin o
def TextParser *args **kwds kwds['engine'] 'python'return TextFileReader *args **kwds
def get_channel model dataset channel cost batch_size monitor Monitor model monitor.setup dataset dataset cost cost batch_size batch_size monitor channels monitor.channelschannel channels[channel]val_record channel.val_record value val_recordreturn value
def isascii text try text.encode u'ascii' except UnicodeEncodeError return Falsereturn True
def reliable_unpack_names if sabnzbd.WIN32 or sabnzbd.DARWIN return Trueelse return gUTF
def add_profiler name description None return models.Profiler.add_object name name description description .id
def _meijerint_definite_2 f x dummy _dummy 'x' 'meijerint-definite2' f positive True f f.subs x dummy x dummyif f 0 return S 0 True for g explanation in _guess_expansion f x _debug 'Trying' explanation res _meijerint_definite_3 g x if res return res
def get_conv_gradweights_shape image_shape top_shape border_mode subsample filter_dilation None nkern imshp image_shape[1] image_shape[2 ] nchan topshp top_shape[1] top_shape[2 ] if filter_dilation is None filter_dilation numpy.ones len subsample dtype 'int' if isinstance border_mode tuple out_shp tuple get_conv_gradweights_shape_1axis imshp[i] topshp[i] border_mode[i] subsample[i] filter_dilation[i] for i in range len subsample else out_shp tuple get_conv_gradweights_shape_1axis imshp[i] topshp[i] border_mode subsample[i] filter_dilation[i] for i in range len subsample return nchan nkern + out_shp
def create_folder root '.' folder None folder_path os.path.join root folder if folder and not os.path.isdir folder_path try os.makedirs folder_path except OSError raise CuckooOperationalError 'Unabletocreatefolder %s' % folder_path
def zen request project subproject lang translation get_translation request project subproject lang search_result unitdata get_zen_unitdata translation request if isinstance search_result HttpResponse return search_resultreturn render request u'zen.html' {u'object' translation u'project' translation.subproject.project u'unitdata' unitdata u'search_query' search_result[u'query'] u'filter_name' search_result[u'name'] u'filter_count' len search_result[u'ids'] u'last_section' search_result[u'last_section'] u'search_id' search_result[u'search_id'] u'offset' search_result[u'offset'] u'search_form' search_result[u'form'] u'update_lock' translation.lock_user request.user }
def eggs x y global fr stfr inspect.currentframe st inspect.stack p xq y / 0
def get_net_start ipaddr netmask net ipaddress.ip_network '{0}/{1}'.format ipaddr netmask strict False return str net.network_address
def gethist codetbl db.codeacid request.vars.acidif request.vars.sid sid request.vars.sidcourse_id db db.auth_user.username sid .select db.auth_user.course_id .first .course_idelif auth.user sid auth.user.usernamecourse_id auth.user.course_idelse sid Nonecourse_id Noneres {}if sid query codetbl.sid sid & codetbl.acid acid & codetbl.course_id course_id & codetbl.timestamp ! None res['acid'] acidres['sid'] sidr db query .select orderby codetbl.id res['history'] [row.code for row in r]res['timestamps'] [row.timestamp.isoformat for row in r]response.headers['content-type'] 'application/json'return json.dumps res
def _broadcast_axis a b if a b return aelif a 1 return belif b 1 return aelse raise ValueError 'failedtobroadcast{0}and{1}'.format a b
def getTextLines text return text.replace '\r' '\n' .split '\n'
@conf.commands.registerdef split_layers lower upper __fval None **fval if __fval is not None fval.update __fval split_bottom_up lower upper **fval split_top_down lower upper **fval
@bdd.then bdd.parsers.parse 'thejavascriptmessage"{message}"shouldbelogged' def javascript_message_logged quteproc message quteproc.wait_for_js message
def arccsc val return numpy.arcsin 1.0 / val
def new_class_from_gtype gtype if gtype.is_a PGType.from_name 'GObject' parent gtype.parent.pytypeif parent is None or parent PGType.from_name 'void' returninterfaces [i.pytype for i in gtype.interfaces]bases tuple [parent] + interfaces cls type gtype.name bases dict cls.__gtype__ gtypereturn clselif gtype.is_a PGType.from_name 'GEnum' from pgi.enum import GEnumBasereturn GEnumBase
def findUser return os.environ.get 'SUDO_USER' False or quietRun 'whoami' .split or [False] [0] or quietRun 'whoami' .strip
def _getDeprecationDocstring version replacement None doc 'Deprecatedin%s' % getVersionString version if replacement doc '%s;%s' % doc _getReplacementString replacement return doc + '.'
def cmd *args return ''.join str arg for arg in args if arg
def sqllist lst if isinstance lst str return lstelse return ' '.join lst
def make_saucelabs_desired_capabilities desired_capabilities settings.SAUCE.get 'BROWSER' DesiredCapabilities.CHROME desired_capabilities['platform'] settings.SAUCE.get 'PLATFORM' desired_capabilities['version'] settings.SAUCE.get 'VERSION' desired_capabilities['device-type'] settings.SAUCE.get 'DEVICE' desired_capabilities['name'] settings.SAUCE.get 'SESSION' desired_capabilities['build'] settings.SAUCE.get 'BUILD' desired_capabilities['video-upload-on-pass'] Falsedesired_capabilities['sauce-advisor'] Falsedesired_capabilities['capture-html'] Truedesired_capabilities['record-screenshots'] Truedesired_capabilities['selenium-version'] '2.34.0'desired_capabilities['max-duration'] 3600desired_capabilities['public'] 'publicrestricted'return desired_capabilities
def cumulant_from_moments momt n if n < 1 raise ValueError 'Expectedapositiveinteger.Got%sinstead.' % n if len momt < n raise ValueError '%s-thcumulantrequires%smoments onlygot%s.' % n n len momt kappa 0.0for p in _faa_di_bruno_partitions n r sum k for m k in p term -1 ** r - 1 * factorial r - 1 for m k in p term * np.power momt[ m - 1 ] / factorial m k / factorial k kappa + termkappa * factorial n return kappa
def members_set_option arg if arg is None return ALLreturn set x.strip for x in arg.split ' '
def dataset headers data encoding None dataset tablib.Dataset if headers dataset.headers encode_row headers encoding for row in data dataset.append encode_row row encoding return dataset
def extract_messages_from_code code is_py False try code render_include code except TemplateError ImportError InvalidIncludePath passmessages []messages + [ m.start m.groups [0] for m in re.compile u'_\\ " [^"]* "' .finditer code ]messages + [ m.start m.groups [0] for m in re.compile u"_\\ ' [^']* '" .finditer code ]if is_py messages + [ m.start m.groups [0] for m in re.compile u'_\\ "{3} [^"]* "{3}.*\\ ' .finditer code ]messages [ pos message for pos message in messages if is_translatable message ]return pos_to_line_no messages code
def alias_delete indices aliases hosts None body None profile None es _get_instance hosts profile try result es.indices.delete_alias index indices name aliases if result.get 'acknowledged' False return Trueexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def get_detail request project subproject checksum subproject get_subproject request project subproject units Unit.objects.filter checksum checksum translation__subproject subproject try source units[0].source_infoexcept IndexError raise Http404 'Nonexistingunit!' check_flags [ CHECKS[x].ignore_string CHECKS[x].name for x in CHECKS]extra_flags [ x EXTRA_FLAGS[x] for x in EXTRA_FLAGS]return render request 'js/detail.html' {'units' units 'source' source 'project' subproject.project 'next' request.GET.get 'next' '' 'priority_form' PriorityForm initial {'priority' source.priority} 'check_flags_form' CheckFlagsForm initial {'flags' source.check_flags} 'screenshot_form' ScreenshotUploadForm instance source 'extra_flags' extra_flags 'check_flags' check_flags}
def im_resize maxwidth path_in path_out None path_out path_out or temp_file_for path_in log.debug u'artresizer ImageMagickresizing{0}to{1}' util.displayable_path path_in util.displayable_path path_out try util.command_output ['convert' util.syspath path_in prefix False '-resize' '{0}x^>'.format maxwidth util.syspath path_out prefix False ] except subprocess.CalledProcessError log.warning u'artresizer IMconvertfailedfor{0}' util.displayable_path path_in return path_inreturn path_out
def patch_flush_fsync db_obj def always_fsync ind_obj def _inner ind_obj.orig_flush ind_obj.fsync return _innerfor index in db_obj.indexes setattr index 'orig_flush' index.flush setattr index 'flush' always_fsync index setattr db_obj 'orig_flush' db_obj.flush setattr db_obj 'flush' always_fsync db_obj return
def on_doctype_update if not frappe.db.sql u'showindexfrom`tabDefaultValue`\n DCTB DCTB whereKey_name "defaultvalue_parent_defkey_index"' frappe.db.commit frappe.db.sql u'altertable`tabDefaultValue`\n DCTB DCTB DCTB addindexdefaultvalue_parent_defkey_index parent defkey ' if not frappe.db.sql u'showindexfrom`tabDefaultValue`\n DCTB DCTB whereKey_name "defaultvalue_parent_parenttype_index"' frappe.db.commit frappe.db.sql u'altertable`tabDefaultValue`\n DCTB DCTB DCTB addindexdefaultvalue_parent_parenttype_index parent parenttype '
def format_options_as_lines options option_lines []option_fields str options .split ' ' for field in option_fields option_lines.append str field .strip '{' .strip '}' return option_lines
def GetWsdlNamespace version return 'urn ' + serviceNsMap[version]
def serialize A if isinstance A str return 0 A if isinstance A numpy.ndarray dt A.dtypeif not dt.isnative or dt.num < 1 or dt.num > len dataType return DATATYPE_UNKNOWN None ft dataType[dt.num]if ft -1 return DATATYPE_UNKNOWN None if A.flags['C_CONTIGUOUS'] return ft str A.data AC A.copy 'C' return ft str AC.data if isinstance A int return DATATYPE_INT32 struct.pack 'i' A if isinstance A float return DATATYPE_FLOAT64 struct.pack 'd' A return DATATYPE_UNKNOWN None
def convert_date_input date_to_convert if date_to_convert try converted_date datetime.datetime.strptime date_to_convert '%m/%d/%Y' except raise InvalidDateFormat return converted_dateelse return date_to_convert
def import_module name required True try __import__ name globals locals [] except ImportError if not required and module_not_found return Noneraisereturn sys.modules[name]
def survey_getAllTranslationsForTemplate template_id table current.s3db.survey_translaterow current.db table.template_id template_id .select return row
def is_gm_id s return re.match gm_id_regex s is not None
def bootstrap_trees msa times tree_constructor msas bootstrap msa times for aln in msas tree tree_constructor.build_tree aln yield tree
def append_slash_redirect environ code 301 new_path environ['PATH_INFO'].strip '/' + '/' query_string environ.get 'QUERY_STRING' if query_string new_path + '?' + query_string return redirect new_path code
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def pad num n 2 sign False s unicode abs num if len s < n s '0' * n - len s + s if not sign return sif num > 0 return '+' + s else return '-' + s
def getDftBins data None sampleRate None low 100 high 8000 chunk 64 if data is None data []bins []i chunkif sampleRate _junk freq getDft data[ chunk] sampleRate band freq > low & freq < high while i < len data magn getDft data[ i - chunk i] if sampleRate bins.append np.std magn[band] else bins.append np.std magn i + chunkreturn np.array bins
def parse_autostep rule parser argparse.ArgumentParser rules shlex.split rule rules.pop 0 parser.add_argument '--autoscreenshot' dest 'autoscreenshot' action 'store' args clean_args vars parser.parse_args rules parser Nonereturn args
def trained return s3_rest_controller
def p_struct_declarator_3 t pass
@util.decoratordef _generative fn *args **kw self args[0]._generate fn self *args[1 ] **kw return self
def getPrivacyLists disp try dict {'lists' []}resp disp.SendAndWaitForResponse Iq 'get' NS_PRIVACY if not isResultNode resp returnfor list in resp.getQueryPayload if list.getName 'list' dict['lists'].append list.getAttr 'name' else dict[list.getName ] list.getAttr 'name' return dictexcept pass
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def pcap_name devname try pcap_name ifaces.pcap_name devname except ValueError pcap_name Nonereturn pcap_name
def test_write assert not getattr django_conf.settings 'FOOBAR' None 1234 assets_conf.settings.FOOBAR 1234assert django_conf.settings.FOOBAR 1234
def cleanBlockQuotedText text joiner '' L filter truth map _lineClean split text '\n' return joiner.join L
def wrapmodule module if _defaultproxy ! None module.socket.socket socksocketelse raise GeneralProxyError 4 'noproxyspecified'
def image_member_delete context memb_id session None session session or get_session member_ref _image_member_get context memb_id session _image_member_delete context member_ref session
def _get_return_dict success True data None errors None warnings None data {} if data is None else data errors [] if errors is None else errors warnings [] if warnings is None else warnings ret {'success' success 'data' data 'errors' errors 'warnings' warnings}return ret
def test_root_mean_square_error y_real np.array [0.0 1.0 0.0 2.0 3.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_equals 0.0 root_mean_square_error y_real y_pred y_real np.array [3.0 1.0 2.0 1.0 1.0] y_pred np.array [0.0 1.0 0.0 2.0 3.0] assert_almost_equals 1.8973665961 root_mean_square_error y_real y_pred
def Pipe duplex True from multiprocessing.connection import Pipereturn Pipe duplex
def read_channel model channel_name monitor_name 'monitor' return getattr model monitor_name .channels[channel_name].val_record[ -1 ]
def get_milestone number None name None repo_name None profile 'github' output 'min' ret {}if not any [number name] raise CommandExecutionError "Eitheramilestone'name'or'number'mustbeprovided." org_name _get_config_value profile 'org_name' if repo_name is None repo_name _get_config_value profile 'repo_name' action '/'.join ['repos' org_name repo_name] if number command 'milestones/' + str number milestone_data _query profile action action command command milestone_id milestone_data.get 'id' if output 'full' ret[milestone_id] milestone_dataelse milestone_data.pop 'creator' milestone_data.pop 'html_url' milestone_data.pop 'labels_url' ret[milestone_id] milestone_datareturn retelse milestones get_milestones repo_name repo_name profile profile output output for key val in six.iteritems milestones if val.get 'title' name ret[key] valreturn retreturn ret
def make_secret form_instance secret_fields None from django.contrib.auth.models import get_hexdigestif secret_fields is None secret_fields ['business' 'item_name']data ''for name in secret_fields if hasattr form_instance 'cleaned_data' if name in form_instance.cleaned_data data + unicode form_instance.cleaned_data[name] elif name in form_instance.initial data + unicode form_instance.initial[name] elif name in form_instance.fields and form_instance.fields[name].initial is not None data + unicode form_instance.fields[name].initial secret get_hexdigest 'sha1' settings.SECRET_KEY data return secret
def job_design_migration_for_jar jd data json.loads jd.data action OozieJavaAction action_type OozieJavaAction.ACTION_TYPE jar_path data['jarfile'] main_class 'please.specify.in.the.job.design' args data['arguments'] action.save design OozieDesign owner jd.owner name jd.name + ' incomplete ' description jd.description root_action action design.save
def test_json_getsysinfo json.dumps sysinfo.get_sys_info
def p_expression_uminus t t[0] - t[2]
def validated_parameter args name values None default None case_sensitive False param args.get name if param param param.lower else param defaultif not values return paramelse if values and param not in values list_str ' '.join values raise RequestError "Parameter'%s'shouldbeoneof %s" % name list_str return param
def _get_deployment_flavor flavor None if not flavor flavor CONF.paste_deploy.flavorreturn '' if not flavor else '-' + flavor
def key_not_string d for k v in d.items if not isinstance k six.string_types or isinstance v dict and key_not_string v return True
def _dup_zz_gcd_interpolate h x K f []while h g h % x if g > x // 2 g - xf.insert 0 g h h - g // x return f
def tmax a upperlimit None axis 0 inclusive True nan_policy 'propagate' a axis _chk_asarray a axis am _mask_to_limits a None upperlimit False inclusive contains_nan nan_policy _contains_nan am nan_policy if contains_nan and nan_policy 'omit' am ma.masked_invalid am res ma.maximum.reduce am axis .dataif res.ndim 0 return res[ ]return res
def detect stream try json.loads stream return Trueexcept ValueError return False
def _stub_armor s return s.encode 'hex'
def send_mail sender_email recipient_email subject plaintext_body html_body bcc_admin False if not feconf.MAILGUN_API_KEY raise Exception 'MailgunAPIkeyisnotavailable.' if not feconf.MAILGUN_DOMAIN_NAME raise Exception 'Mailgundomainnameisnotset.' mailgun_domain_name 'https //api.mailgun.net/v3/%s/messages' % feconf.MAILGUN_DOMAIN_NAME if not feconf.CAN_SEND_EMAILS raise Exception 'Thisappcannotsendemailstousers.' data {'from' sender_email 'to' recipient_email 'subject' subject 'text' plaintext_body 'html' html_body}if bcc_admin data['bcc'] feconf.ADMIN_EMAIL_ADDRESSrequests.post mailgun_domain_name auth 'api' feconf.MAILGUN_API_KEY data data
def remove_ids mul factor mmul mul.as_coeff_mmul result rm_id lambda x x.is_Identity is True mmul if result ! mmul return newmul factor *result.args else return mul
def virtual_position line col nbytes col2byte line col return line int eval 'virtcol [%d %d] ' % line nbytes
def get_hexdigest algorithm salt raw_password raw_password salt smart_str raw_password smart_str salt if algorithm 'crypt' try import cryptexcept ImportError raise ValueError '"crypt"passwordalgorithmnotsupportedinthisenvironment' return crypt.crypt raw_password salt if algorithm 'md5' return md5_constructor salt + raw_password .hexdigest elif algorithm 'sha1' return sha_constructor salt + raw_password .hexdigest raise ValueError 'Gotunknownpasswordalgorithmtypeinpassword.'
def bool_from_str val if not val return Falsetry return True if int val else False except ValueError return val.lower 'true' or val.lower 'yes' or val.lower 'y'
def get_repository_metadata_by_changeset_revision app id changeset_revision sa_session app.model.context.currentall_metadata_records sa_session.query app.model.RepositoryMetadata .filter and_ app.model.RepositoryMetadata.table.c.repository_id app.security.decode_id id app.model.RepositoryMetadata.table.c.changeset_revision changeset_revision .order_by app.model.RepositoryMetadata.table.c.update_time.desc .all if len all_metadata_records > 1 for repository_metadata in all_metadata_records[1 ] sa_session.delete repository_metadata sa_session.flush return all_metadata_records[0]elif all_metadata_records return all_metadata_records[0]return None
def PseudoBreadcrumbs key path key.to_path parts []for i in range 0 len path // 2 kind path[ i * 2 ]if isinstance kind unicode kind kind.encode 'utf8' value path[ i * 2 + 1 ]if isinstance value int long parts.append '%s id %d' % kind value else if isinstance value unicode value value.encode 'utf8' parts.append '%s name %s' % kind value return '>'.join parts
def tab_in_leading s n len s - len s.lstrip if not s[n n + 3 ] in ['...' '>>>'] check s[ n]else smore s[ n + 3 ]check s[ n] + smore[ len smore - len smore.lstrip ] return not check.expandtabs check
def script vm_ deploy_script salt.utils.cloud.os_script config.get_cloud_config_value 'script' vm_ __opts__ vm_ __opts__ salt.utils.cloud.salt_config_to_yaml salt.utils.cloud.minion_config __opts__ vm_ return deploy_script
def GetConfigBinaryPathType aff4_path if not aff4_path.Path .startswith '/config' returncomponents aff4_path.RelativeName 'aff4 /config' .split '/' if components[0] 'executables' and components[1] in SUPPORTED_PLATFORMS return 'GRRSignedBlob'elif components[0] 'python_hacks' return 'GRRSignedBlob'else return
def handle_command request command path request.POST.get 'path' or request.META.get 'HTTP_REFERER' or '/' if command 'edit_on' or command 'edit_off' set_edit_mode request command.endswith '_on' return HttpResponseRedirect path
def i32le c o 0 return unpack '<I' c[o o + 4 ] [0]
def _create_titled_group root key title out root.create_group key out.attrs['TITLE'] titlereturn out
@intercept_errors UserAPIInternalError ignore_errors [UserAPIRequestError] @transaction.atomicdef create_account username password email _validate_username username _validate_password password username _validate_email email user User username username email email is_active False user.set_password password try user.save except IntegrityError raise AccountUserAlreadyExistsregistration Registration registration.register user UserProfile user user .save return registration.activation_key
def make_lupton_rgb image_r image_g image_b minimum 0 stretch 5 Q 8 filename None asinhMap AsinhMapping minimum stretch Q rgb asinhMap.make_rgb_image image_r image_g image_b if filename import matplotlib.imagematplotlib.image.imsave filename rgb origin u'lower' return rgb
def store_email strategy backend user social details **kwargs if u'email' not in details or details[u'email'] is None raise AuthMissingParameter backend u'email' verified dummy VerifiedEmail.objects.get_or_create social social if verified.email ! details[u'email'] verified.email details[u'email']verified.save
def BufferIsVisibleForFilename filename buffer_number GetBufferNumberForFilename filename False return BufferIsVisible buffer_number
def check_ownership request obj require_owner False require_author False ignore_disabled False admin True if hasattr obj 'check_ownership' return obj.check_ownership request require_owner require_owner require_author require_author ignore_disabled ignore_disabled admin admin return False
def test_gcrs_itrs ra dec _ randomly_sample_sphere 200 gcrs GCRS ra ra dec dec obstime u'J2000' gcrs6 GCRS ra ra dec dec obstime u'J2006' gcrs2 gcrs.transform_to ITRS .transform_to gcrs gcrs6_2 gcrs6.transform_to ITRS .transform_to gcrs assert_allclose gcrs.ra gcrs2.ra assert_allclose gcrs.dec gcrs2.dec assert not allclose gcrs.ra gcrs6_2.ra assert not allclose gcrs.dec gcrs6_2.dec gcrsc gcrs.realize_frame gcrs.data gcrsc.representation CartesianRepresentationgcrsc2 gcrsc.transform_to ITRS .transform_to gcrsc assert_allclose gcrsc.spherical.lon.deg gcrsc2.ra.deg assert_allclose gcrsc.spherical.lat gcrsc2.dec
def generate_client_secret client_secret_generator oauth2_settings.CLIENT_SECRET_GENERATOR_CLASS return client_secret_generator.hash
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def _funcOfMethod methodObject if _PY3 return methodObject.__func__return methodObject.im_func
def p_identifier_list_2 t pass
def format_html html return html.replace u'\n' u'' .replace u'' u''
def on_slave_report client_id data stats['content-length'] + data['content-length']
def test_derived_cols_from_lists test_data ds ChartDataSource.from_data test_data.array_data dims 'y' 'x' assert ds['y'] ['a' 'b']
def get_db_connection path timeout 30 okay_to_create False try connect_time time.time conn sqlite3.connect path check_same_thread False factory GreenDBConnection timeout timeout if path ! ' memory ' and not okay_to_create stat os.stat path if stat.st_size 0 and stat.st_ctime > connect_time os.unlink path raise DatabaseConnectionError path 'DBfilecreatedbyconnect?' conn.row_factory sqlite3.Rowconn.text_factory strconn.execute 'PRAGMAsynchronous NORMAL' conn.execute 'PRAGMAcount_changes OFF' conn.execute 'PRAGMAtemp_store MEMORY' conn.execute 'PRAGMAjournal_mode DELETE' conn.create_function 'chexor' 3 chexor except sqlite3.DatabaseError import tracebackraise DatabaseConnectionError path traceback.format_exc timeout timeout return conn
def _test_number_length_against_pattern possible_re national_number match fullmatch possible_re national_number if match return ValidationResult.IS_POSSIBLEsearch possible_re.match national_number if search return ValidationResult.TOO_LONGelse return ValidationResult.TOO_SHORT
def unauthenticated_userid request return request.unauthenticated_userid
def ReadRocheXmlManifest handle number_of_reads header_length index_offset index_length xml_offset xml_size read_index_offset read_index_size _sff_find_roche_index handle if not xml_offset or not xml_size raise ValueError 'NoXMLmanifestfound' handle.seek xml_offset return _bytes_to_string handle.read xml_size
def _replace_node node replace_node prev_node node.getprevious parent_node node.getparent node_tail node.tail or '' if isinstance replace_node basestring if prev_node is not None prev_text prev_node.tail or '' prev_node.tail prev_text + replace_node + node_tail elif parent_node is not None parent_text parent_node.text or '' parent_node.text parent_text + replace_node + node_tail else replace_node.tail node_tailnode.addprevious replace_node if parent_node is not None parent_node.remove node
def list_elbs region None key None keyid None profile None return [e.name for e in get_all_elbs region region key key keyid keyid profile profile ]
def _ShouldPrintError category confidence linenum if IsErrorSuppressedByNolint category linenum return Falseif confidence < _cpplint_state.verbose_level return Falseis_filtered Falsefor one_filter in _Filters if one_filter.startswith '-' if category.startswith one_filter[1 ] is_filtered Trueelif one_filter.startswith '+' if category.startswith one_filter[1 ] is_filtered Falseelse assert Falseif is_filtered return Falsereturn True
def get_data_home data_home None if data_home is None data_home os.environ.get 'SEABORN_DATA' os.path.join '~' 'seaborn-data' data_home os.path.expanduser data_home if not os.path.exists data_home os.makedirs data_home return data_home
def filter_protocol hostmap protocol 's' eligible []for host portmap in hostmap.items port portmap.get protocol if port eligible.append serialize_server host port protocol return eligible
def grad_not_implemented op x_pos x comment '' return NullType 'ThisvariableisNullbecausethegradmethodforinput%s %s ofthe%sopisnotimplemented.%s' % x_pos x op comment
def test_freeze_user script virtualenv virtualenv.system_site_packages Truescript.pip_install_local '--user' 'simple 2.0' script.pip_install_local 'simple2 3.0' result script.pip 'freeze' '--user' expect_stderr True expected textwrap.dedent 'simple 2.0\n<BLANKLINE>' _check_output result.stdout expected assert 'simple2' not in result.stdout
def _is_central_object_admin object_list bundle user bundle.request.userif not user.is_authenticated return Falseelse for obj in object_list if not user.get_profile .has_permission_for_object obj return Falsereturn True
def fix_parsed m if m is None return {'type' 'raw' 'data' []}if isinstance m basestring return {'type' 'raw' 'data' [ord b for b in m]}assert isinstance m packet_base if not m.parsed u fix_parsed m.raw u['unparsed_type'] m.__class__.__name__return ur {}for k v in fields_of m primitives_only False .iteritems if is_scalar v r[k] velif isinstance v IPAddr EthAddr r[k] str v if hasattr m 'payload' r['payload'] fix_parsed m.payload if 'raw' in r del r['raw']if 'next' in r del r['next']r['type'] m.__class__.__name__return r
def ipdocstring func if func.__doc__ is not None func.__doc__ ip2py func.__doc__ return func
def _apparent_position_in_true_coordinates skycoord jd1 jd2 get_jd12 skycoord.obstime u'tt' _ _ _ _ _ _ _ rbpn erfa.pn00a jd1 jd2 return SkyCoord skycoord.frame.realize_frame skycoord.cartesian.transform rbpn
def set_default_interface etree global types ET modulest _get_etree_type etree _types set types or [] _types.update [t] types tuple _types modules[t] etree old ET ET etree return old
def MakePmfFromDict d label None return Pmf d label label
def new_dd_object dsk _name meta divisions return _get_return_type meta dsk _name meta divisions
def create_profile_when_user_created instance created raw *args **kwargs if created and not raw person p_created Person.objects.get_or_create user instance
def add_edit_resources context request context.get 'request' if not request and could_edit request and may_inject context returnfrom ._theme import get_current_themefrom .rendering import get_view_configview_config get_view_config context theme get_current_theme request request if not theme returnadd_resource context 'body_end' InlineScriptResource.from_vars 'XthemeEditorConfig' {'commandUrl' '/xtheme/' 'editUrl' '/xtheme/editor/' 'themeIdentifier' theme.identifier 'viewName' view_config.view_name 'edit' is_edit_mode request 'csrfToken' get_token request } add_resource context 'body_end' staticfiles_storage.url 'xtheme/editor-injection.js'
def null return ValueEvent None
def accumulate_from_superclasses cls propname cachename '__cached_all' + propname if cachename not in cls.__dict__ s set for c in inspect.getmro cls if issubclass c HasProps and hasattr c propname base getattr c propname s.update base setattr cls cachename s return cls.__dict__[cachename]
def aggregate_host_delete context aggregate_id host IMPL.aggregate_host_delete context aggregate_id host
@raises TypeError def test_bootstrap_noncallable non_func 'mean'algo.bootstrap a_norm 100 non_func
def log_error message None title None get_doc dict doctype u'ErrorLog' error str message or get_traceback method title .insert ignore_permissions True
def test_add_accepts_to_naked_function_3 def foo int_1 int_2 int_3 passt time.time for i in range 0 10000 accepts int_2 int int_1 int int_3 int foo return time.time - t
def mock_sign version_id reviewer False version Version.objects.get pk version_id file_obj version.all_files[0]if reviewer path file_obj.signed_reviewer_file_pathstorage private_storageelse path file_obj.signed_file_pathstorage public_storagecopy_stored_file file_obj.file_path path src_storage private_storage dst_storage storage return path
def is_mapped_class cls try sqlalchemy_inspect cls except NoInspectionAvailable return Falseelse return True
def fire_coroutine_threadsafe coro loop ident loop.__dict__.get '_thread_ident' if ident is not None and ident threading.get_ident raise RuntimeError 'Cannotbecalledfromwithintheeventloop' if not coroutines.iscoroutine coro raise TypeError 'Acoroutineobjectisrequired %s' % coro def callback 'Callbacktofirecoroutine.'ensure_future coro loop loop loop.call_soon_threadsafe callback return
@functools.lru_cache maxsize None def get_callable lookup_view if callable lookup_view return lookup_viewif not isinstance lookup_view str raise ViewDoesNotExist "'%s'isnotacallableoradot-notationpath" % lookup_view mod_name func_name get_mod_func lookup_view if not func_name raise ImportError "Couldnotimport'%s'.Thepathmustbefullyqualified." % lookup_view try mod import_module mod_name except ImportError parentmod submod get_mod_func mod_name if submod and not module_has_submodule import_module parentmod submod raise ViewDoesNotExist "Couldnotimport'%s'.Parentmodule%sdoesnotexist." % lookup_view mod_name else raiseelse try view_func getattr mod func_name except AttributeError raise ViewDoesNotExist "Couldnotimport'%s'.Viewdoesnotexistinmodule%s." % lookup_view mod_name else if not callable view_func raise ViewDoesNotExist "Couldnotimport'%s.%s'.Viewisnotcallable." % mod_name func_name return view_func
def subXMLHTMLSGMLRefs s return re_everyentcharrefssub _replAllXMLRef s
def test_wraps_keep_orig_name def foo passassigned list functools.WRAPPER_ASSIGNMENTS assigned.remove u'__name__' def bar passorig_bar barbar wraps foo assigned assigned bar assert bar is not orig_bar assert bar.__name__ u'bar'
def _atrun_enabled return __salt__['service.enabled'] 'com.apple.atrun'
def glom key count combine def conglomerate expr 'Conglomeratetogetheridenticalargsx+x->2x'groups sift expr.args key counts dict k sum map count args for k args in groups.items newargs [combine cnt mat for mat cnt in counts.items ]if set newargs ! set expr.args return new type expr *newargs else return exprreturn conglomerate
def remove_refct_calls func for bb in func.basic_blocks remove_null_refct_call bb remove_refct_pairs bb
def fakeprofiledloopbackblockdeviceapi_for_test test_case allocation_unit None return FakeProfiledLoopbackBlockDeviceAPI loopback_blockdevice_api loopbackblockdeviceapi_for_test test_case allocation_unit allocation_unit
def parse_module module_text filename ast compiler.parse module_text token_parser TokenParser module_text visitor ModuleVisitor filename token_parser compiler.walk ast visitor walker visitor return visitor.module
@register.simple_tag takes_context True def diff_chunk_header context header lines_of_context context[u'lines_of_context']chunk context[u'chunk']line chunk[u'lines'][0]if header[u'line'] > line[1] expand_offset line[1] + chunk[u'numlines'] - header[u'line'] expandable Trueelse expand_offset 0expandable Falsereturn _diff_expand_link context expandable u'<code>%s</code>' % escape header[u'text'] _ u'Expandtoheader' lines_of_context[0] expand_offset + lines_of_context[1] u'rb-icon-diff-expand-header'
def _parse_till_closing_brace stream rv ''in_braces 1while True if EscapeCharToken.starts_here stream '{}' rv + next stream + next stream else char next stream if char '{' in_braces + 1elif char '}' in_braces - 1if in_braces 0 breakrv + charreturn rv
def get_default_timezone_name return _get_timezone_name get_default_timezone
def collapsedTransitions Ts policy res zeros_like Ts[0] dim len Ts[0] for ai ap in enumerate policy.T res + Ts[ai] * repmat ap dim 1 .T return res
def getPathLength path pathLength 0.0for pointIndex in xrange len path - 1 firstPoint path[pointIndex]secondPoint path[ pointIndex + 1 ]pathLength + abs firstPoint - secondPoint return pathLength
def _netinfo_freebsd_netbsd ret {}out __salt__['cmd.run'] 'sockstat-46{0}|tail-n+2'.format '-n' if __grains__['kernel'] 'NetBSD' else '' python_shell True for line in out.splitlines user cmd pid _ proto local_addr remote_addr line.split local_addr '.'.join local_addr.rsplit ' ' 1 remote_addr '.'.join remote_addr.rsplit ' ' 1 ret.setdefault local_addr {} .setdefault remote_addr {} .setdefault proto {} .setdefault pid {} ['user'] userret[local_addr][remote_addr][proto][pid]['cmd'] cmdreturn ret
def fanout_cast_to_server conf context server_params topic msg return rpc_amqp.fanout_cast_to_server conf context server_params topic msg rpc_amqp.get_connection_pool conf Connection
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_model_instance app_label model_name pk model apps.get_model app_label model_name if not model return Nonetry instance model._default_manager.get pk pk return instanceexcept model.ObjectDoesNotExist passreturn None
def instance_info_cache_get context instance_uuid return IMPL.instance_info_cache_get context instance_uuid
def verbose_loader filename screed_iter clean_input_reads screed.open filename for num record in enumerate screed_iter if num % 100000 0 log_info u'...filtering{num}' num num yield record
def test_blacklist_all keyhint config_stub key_config_stub config_stub.set 'ui' 'keyhint-blacklist' ['*'] key_config_stub.set_bindings_for 'normal' OrderedDict [ 'aa' 'cmd-aa' 'ab' 'cmd-ab' 'aba' 'cmd-aba' 'abb' 'cmd-abb' 'xd' 'cmd-xd' 'xe' 'cmd-xe' ] keyhint.update_keyhint 'normal' 'a' assert not keyhint.text
def fixed_ip_disassociate context address return IMPL.fixed_ip_disassociate context address
def unit key _check_obsolete key return physical_constants[key][1]
def clean_for_iam name return re.sub '[^A-Za-z0-9+ .@_-]+' '-' name
def list_items queue itemstuple _list_items queue items [item[0] for item in itemstuple]return items
def getRefreshRate screen 0 if importCtypesFailed return FalsescrID getScreen screen mode cocoa.CGDisplayCurrentMode scrID refreshCF cocoa.CFDictionaryGetValue mode _create_cfstring 'RefreshRate' refresh ctypes.c_long cocoa.CFNumberGetValue refreshCF kCFNumberLongType ctypes.byref refresh if refresh.value 0 return 60else return refresh.value
def _MSBuildOnly tool name setting_type def _Translate value msbuild_settings tool_settings msbuild_settings.setdefault tool.msbuild_name {} tool_settings[name] value_msbuild_validators[tool.msbuild_name][name] setting_type.ValidateMSBuild_msvs_to_msbuild_converters[tool.msvs_name][name] _Translate
def config_help name hidden False if hidden return argparse.SUPPRESSelse return interfaces.IConfig[name].__doc__
@bdd.then bdd.parsers.parse '"{pattern}"shouldnotbelogged' def ensure_not_logged quteproc pattern quteproc.ensure_not_logged message pattern
def ordered_dict_factory colnames rows return [OrderedDict zip colnames row for row in rows]
def bitswap_int n width n & 1 << width - 1 s bits_str n endian 'little' .ljust width '0' [ width]return int s 2
def test_wavelet_denoising_args img astronoisy img.copy + 0.1 * np.random.randn *img.shape for convert2ycbcr in [True False] for multichannel in [True False] for sigma in [0.1 [0.1 0.1 0.1] None] if not multichannel and not convert2ycbcr or isinstance sigma list and not multichannel continuerestoration.denoise_wavelet noisy sigma sigma convert2ycbcr convert2ycbcr multichannel multichannel
def sympy_to_numpy m **options if not np raise ImportErrordtype options.get 'dtype' 'complex' if isinstance m Matrix return np.matrix m.tolist dtype dtype elif isinstance m Expr if m.is_Number or m.is_NumberSymbol or m I return complex m raise TypeError 'ExpectedMatrixorcomplexscalar got %r' % m
def uri_for _name _request None *args **kwargs request _request or get_request return request.app.router.build request _name args kwargs
def _transfer_result fut1 fut2 exc fut1.get_exception if exc is not None tb fut1.get_traceback fut2.set_exception exc tb else val fut1.get_result fut2.set_result val
def test_postgresql from openid.store import sqlstoretry import psycopgexcept ImportError passelse db_name getTmpDbName db_user 'openid_test'conn_create psycopg.connect database 'template1' user db_user host db_host conn_create.autocommit cursor conn_create.cursor cursor.execute 'CREATEDATABASE%s;' % db_name conn_create.close conn_test psycopg.connect database db_name user db_user host db_host store sqlstore.PostgreSQLStore conn_test store.createTables testStore store conn_test.close import timetime.sleep 1 conn_remove psycopg.connect database 'template1' user db_user host db_host conn_remove.autocommit cursor conn_remove.cursor cursor.execute 'DROPDATABASE%s;' % db_name conn_remove.close
def _as_truncated value if isinstance value _truncated_label return valueelse return _truncated_label value
@jit nopython True cache True def next_k_array a k len a if k 0 return ax 0for i in range k x + 1 << a[i] x next_k_combination x pos 0for i in range k while x & 1 0 x x >> 1 pos + 1a[i] posx x >> 1 pos + 1return a
def _make_spec_test expected template context partials description test_name file_path file_name os.path.basename file_path test_method_name 'Mustachespec %s %s' % file_name repr test_name class SpecTest SpecTestBase passdef run_test self self._runTest setattr SpecTest test_method_name run_test case SpecTest test_method_name case._context contextcase._description descriptioncase._expected expectedcase._file_path file_pathcase._partials partialscase._template templatecase._test_name test_namereturn case
def xml_encode string string string.replace '&' '&amp;' string string.replace '<' '&lt;' string string.replace '>' '&gt;' string string.replace '"' '&quot;' string string.replace SLASH '/' return string
def _SffTrimIterator handle alphabet Alphabet.generic_dna return SffIterator handle alphabet trim True
def dmp_add f g u K if not u return dup_add f g K df dmp_degree f u if df < 0 return gdg dmp_degree g u if dg < 0 return fv u - 1 if df dg return dmp_strip [dmp_add a b v K for a b in zip f g ] u else k abs df - dg if df > dg h f f[ k] f[k ] else h g g[ k] g[k ] return h + [dmp_add a b v K for a b in zip f g ]
def GetBackendsYaml unused_application backends_xml_str backend_list BackendsXmlParser .ProcessXml backends_xml_str statements ['backends ']for backend in backend_list statements + backend.ToYaml return '\n'.join statements + '\n'
def matchSetStrength match_set target_set sum 0.0for t in target_set sum + max matchStrength m t for m in match_set return sum / len target_set
def GetELBInstancesByHealth region node_types None balancers GetLoadBalancers region node_types node_types res defaultdict list for b in balancers for state in b.get_instance_health res[state.state].append state.instance_id return res
def createFillForSurroundings radius shouldExtraLoopsBeAdded surroundingLoops for surroundingLoop in surroundingLoops createExtraFillLoops radius shouldExtraLoopsBeAdded surroundingLoop
def bilinear_kernel_2D ratio normalize True hkern bilinear_kernel_1D ratio ratio normalize normalize .dimshuffle 'x' 0 vkern bilinear_kernel_1D ratio ratio normalize normalize .dimshuffle 0 'x' kern hkern * vkern return kern
def _qs_for model_cls return model_cls.objects.filter created__gte date 2011 1 1 .extra select {'day' 'extract dayfromcreated ' 'month' 'extract monthfromcreated ' 'year' 'extract yearfromcreated '} .values 'year' 'month' 'day' .annotate count Count 'created'
def save filename None family 'ipv4' if _conf and not filename filename _conf family log.debug 'Savingrulesto{0}'.format filename parent_dir os.path.dirname filename if not os.path.isdir parent_dir os.makedirs parent_dir cmd '{0}-save'.format _iptables_cmd family ipt __salt__['cmd.run'] cmd if len _conf_save_filters > 0 ipt _regex_iptables_save ipt out __salt__['file.write'] filename ipt return out
def get_comment_app comments_app get_comment_app_name if comments_app not in settings.INSTALLED_APPS raise ImproperlyConfigured 'TheCOMMENTS_APP %r mustbeinINSTALLED_APPS' % settings.COMMENTS_APP try package import_module comments_app except ImportError raise ImproperlyConfigured 'TheCOMMENTS_APPsettingreferstoanon-existingpackage.' return package
def associate qs assoc_secret assoc_handle q parseQuery qs assert q['openid.mode'] 'associate' assert q['openid.assoc_type'] 'HMAC-SHA1' reply_dict {'assoc_type' 'HMAC-SHA1' 'assoc_handle' assoc_handle 'expires_in' '600'}if q.get 'openid.session_type' 'DH-SHA1' assert len q 6 or len q 4 message Message.fromPostArgs q session DiffieHellmanSHA1ServerSession.fromMessage message reply_dict['session_type'] 'DH-SHA1'else assert len q 2 session PlainTextServerSession.fromQuery q reply_dict.update session.answer assoc_secret return kvform.dictToKV reply_dict
def localOutp images hidSums targets numModulesX paddingStart filterSizeX moduleStride numImgColors numGroups 1partialSum 0numImages images.shape[0]numFilters hidSums.shape[1] / numModulesX ** 2 assert targets.shape numFilters numModulesX ** 2 * numImgColors * filterSizeX ** 2 '%s%d%d-%d-%d' % targets.shape.__str__ numFilters numImgColors filterSizeX filterSizeX _ConvNet.localOutp images.p_mat hidSums.p_mat targets.p_mat numModulesX filterSizeX - paddingStart moduleStride numImgColors numGroups partialSum
def sysctl_kernel key value None if value is not None utils.write_one_line '/proc/sys/kernel/%s' % key str value else out utils.read_one_line '/proc/sys/kernel/%s' % key return int re.search '\\d+' out .group 0
def _split_string text m ITEM_REGEX.match text try parts m.groupdict except AttributeError warn 'Cannotparseheaderorfootersoitwillbeignored' parts {'left' '' 'right' '' 'center' ''}return parts
def filterwarnings action message '' category Warning module '' lineno 0 append 0 import reassert action in 'error' 'ignore' 'always' 'default' 'module' 'once' 'invalidaction %r' % action assert isinstance message basestring 'messagemustbeastring'assert isinstance category type types.ClassType 'categorymustbeaclass'assert issubclass category Warning 'categorymustbeaWarningsubclass'assert isinstance module basestring 'modulemustbeastring'assert isinstance lineno int and lineno > 0 'linenomustbeanint> 0'item action re.compile message re.I category re.compile module lineno if append filters.append item else filters.insert 0 item
@jit 'void double[ ] double[ ] double[ ] ' nopython True nogil True def inner_func_nb result a b for i in range len result result[i] math.exp 2.1 * a[i] + 3.2 * b[i]
def wang_ryzin h Xi x Xi Xi.reshape Xi.size kernel_value 0.5 * 1 - h * h ** abs Xi - x idx Xi x kernel_value[idx] idx * 1 - h [idx]return kernel_value
def batch iterable batch_size BATCH_SIZE b []for i in iterable b.append i if len b batch_size yield tuple b b []if b yield tuple b
def _decompress source target delete_after_decompression True f_in gzip.open source u'rb' f_out open target u'wb' f_out.writelines f_in f_out.close f_in.close if delete_after_decompression os.remove source
def file_from_modpath modpath path None context_file None if context_file is not None context dirname context_file else context context_fileif modpath[0] 'xml' try return _file_from_modpath ['_xmlplus'] + modpath[1 ] path context except ImportError return _file_from_modpath modpath path context elif modpath ['os' 'path'] return os.path.__file__return _file_from_modpath modpath path context
def trim_cflags value return trim_var 'CFLAGS' value
def dump_environ environ start_response output []keys list environ.keys keys.sort for k in keys v str environ[k] .replace '\n' '\n' output.append '%s %s\n' % k v output.append '\n' content_length environ.get 'CONTENT_LENGTH' '' if content_length output.append environ['wsgi.input'].read int content_length output.append '\n' output ''.join output if six.PY3 output output.encode 'utf8' headers [ 'Content-Type' 'text/plain' 'Content-Length' str len output ]start_response '200OK' headers return [output]
def p_abstract_declarator_opt_2 t pass
def load_dataset dataset_yml use_test_set print 'Loadingdata...' dataset yaml_parse.load dataset_yml if use_test_set 'y' dataset dataset.get_test_set else assert use_test_set 'n' return dataset
def match_fuzzy needles haystack ignore_case False threshold 0.6 end_dir lambda path last os.path.split path if ignore_case needle last needles .lower match_percent lambda entry SequenceMatcher a needle b end_dir entry.path.lower .ratio else needle last needles match_percent lambda entry SequenceMatcher a needle b end_dir entry.path .ratio meets_threshold lambda entry match_percent entry > threshold return ifilter meets_threshold haystack
def addPath infillWidth infillPaths path rotationPlaneAngle simplifiedPath euclidean.getSimplifiedPath path infillWidth if len simplifiedPath < 2 returnplaneRotated euclidean.getPointsRoundZAxis rotationPlaneAngle simplifiedPath infillPaths.append planeRotated
def duplicated values keep 'first' dtype values.dtypeif needs_i8_conversion dtype values values.view np.int64 elif is_period_arraylike values from pandas.tseries.period import PeriodIndexvalues PeriodIndex values .asi8elif is_categorical_dtype dtype values values.values.codeselif isinstance values ABCSeries ABCIndex values values.valuesif is_signed_integer_dtype dtype values _ensure_int64 values duplicated htable.duplicated_int64 values keep keep elif is_unsigned_integer_dtype dtype values _ensure_uint64 values duplicated htable.duplicated_uint64 values keep keep elif is_float_dtype dtype values _ensure_float64 values duplicated htable.duplicated_float64 values keep keep else values _ensure_object values duplicated htable.duplicated_object values keep keep return duplicated
def NameValueListToDict name_value_list result {}for item in name_value_list tokens item.split ' ' 1 if len tokens 2 try token_value int tokens[1] except ValueError token_value tokens[1]result[tokens[0]] token_valueelse result[tokens[0]] Truereturn result
def format_yaml_dict yamldict type_prefix yamldict['type'] type_prefix + yamldict['type'] return yamldict
def addToProfileMenu menu settings.ToolDialog .addPluginToMenu menu archive.getUntilDot archive.getSkeinforgePluginsPath 'profile.py' menu.add_separator directoryPath skeinforge_profile.getPluginsDirectoryPath pluginFileNames skeinforge_profile.getPluginFileNames craftTypeName skeinforge_profile.getCraftTypeName profileRadioVar settings.Tkinter.StringVar for pluginFileName in pluginFileNames addSubmenus craftTypeName menu pluginFileName os.path.join directoryPath pluginFileName profileRadioVar
def wire_decode data def decode dictionary class_name dictionary.get _CLASS_MARKER None if class_name u'FilePath' return FilePath dictionary.get u'path' .encode 'utf-8' elif class_name u'PMap' return pmap dictionary[u'values'] elif class_name u'UUID' return UUID dictionary[u'hex'] elif class_name u'datetime' return datetime.fromtimestamp dictionary[u'seconds'] UTC elif class_name in _CONFIG_CLASS_MAP dictionary dictionary.copy dictionary.pop _CLASS_MARKER return _CONFIG_CLASS_MAP[class_name].create dictionary else return dictionaryreturn loads data object_hook decode
def test_topic_move topic forum_other Forum title 'TestForum2' category_id 1 forum_other.save forum_old Forum.query.filter_by id topic.forum_id .first assert topic.move forum_other assert forum_old.topics.all [] assert forum_old.last_post_id is None assert forum_old.topic_count 0 assert forum_old.post_count 0 assert forum_other.last_post_id topic.last_post_id assert forum_other.topic_count 1 assert forum_other.post_count 1
def isAlphanum c return c > 'a' and c < 'z' or c > '0' and c < '9' or c > 'A' and c < 'Z' or c '_' or c '$' or c '\\' or c is not None and ord c > 126
def OverlapLength left_string right_string left_string_length len left_string right_string_length len right_string if not left_string_length or not right_string_length return 0if left_string_length > right_string_length left_string left_string[ - right_string_length ]elif left_string_length < right_string_length right_string right_string[ left_string_length]if left_string right_string return min left_string_length right_string_length best 0length 1while True pattern left_string[ - length ]found right_string.find pattern if found < 0 return bestlength + foundif left_string[ - length ] right_string[ length] best lengthlength + 1
def _check_mat_struct fname if not check_version 'scipy' '0.12' raise RuntimeError 'scipy> 0.12mustbeinstalledforreadingEEGLABfiles.' from scipy import iomat io.whosmat fname struct_as_record False squeeze_me True if 'ALLEEG' in mat[0] raise NotImplementedError 'LoadinganALLEEGarrayisnotsupported.Pleasecontactmne-pythondevelopersformoreinformation.' elif 'EEG' not in mat[0] msg 'Unknownarrayinthe.setfile.'raise ValueError msg
def set_logging_format logging.basicConfig level logging.INFO format '% asctime s% levelname s% filename s % lineno s% message s'
def ipv4_to_str ip if isinstance ip int return addrconv.ipv4.bin_to_text struct.pack '!I' ip else return addrconv.ipv4.bin_to_text ip
def workspace registry xml_parent data workspace XML.SubElement xml_parent 'scm' {'class' 'hudson.plugins.cloneworkspace.CloneWorkspaceSCM'} XML.SubElement workspace 'parentJobName' .text str data.get 'parent-job' '' criteria_list ['Any' 'NotFailed' 'Successful']criteria data.get 'criteria' 'Any' .title if 'criteria' in data and criteria not in criteria_list raise JenkinsJobsException 'clone-workspacecriteriamustbeoneof ' + ' '.join criteria_list else XML.SubElement workspace 'criteria' .text criteria
def compute_days_since_epoch day month year d datetime int year int month int day epoch datetime.utcfromtimestamp 0 return d - epoch .days
def applyFunctionRecursively value function if isListLike value retVal [applyFunctionRecursively _ function for _ in value]else retVal function value return retVal
def get_cms_course_link course page 'course' return u'//{}/{}/{}'.format settings.CMS_BASE page unicode course.id
def video_cv video import cvvideo video[ -1 ]image cv.CreateImageHeader video.shape[1] video.shape[0] cv.IPL_DEPTH_8U 3 cv.SetData image video.tostring video.dtype.itemsize * 3 * video.shape[1] return image
def serialize_html_fragment el skip_outer False assert not isinstance el basestring 'Youshouldpassinanelement notastringlike%r' % el html etree.tostring el method 'html' encoding _unicode if skip_outer html html[ html.find '>' + 1 ]html html[ html.rfind '<' ]return html.strip else return html
def command from fabtools.require.deb import package as require_deb_packagefrom fabtools.require.rpm import package as require_rpm_packagefrom fabtools.require.portage import package as require_portage_packagefrom fabtools.system import distrib_familyres run 'bzr--version' quiet True if res.failed family distrib_family if family 'debian' require_deb_package 'bzr' elif family 'gentoo' require_portage_package 'bzr' elif family 'redhat' require_rpm_package 'bzr' else raise UnsupportedFamily supported ['debian' 'redhat' 'gentoo']
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def floating_ip_bulk_destroy context ips return IMPL.floating_ip_bulk_destroy context ips
def get_comment_permalink comment anchor_pattern None if anchor_pattern return comment.get_absolute_url anchor_pattern return comment.get_absolute_url
def repr_wrapper klass if six.PY2 if '__repr__' not in klass.__dict__ raise ValueError "@repr_wrappercannotbeappliedto%sbecauseitdoesn'tdefine__repr__ ." % klass.__name__ klass._repr klass.__repr__klass.__repr__ lambda self encodeutils.safe_encode self._repr return klass
def render_value_in_context value context value template_localtime value use_tz context.use_tz value localize value use_l10n context.use_l10n value force_text value if context.autoescape and not isinstance value SafeData or isinstance value EscapeData return escape value else return value
def body_string body_dict prefix '' body_list []for key value in sorted body_dict.items if isinstance value list tuple for i arr in enumerate value if isinstance arr dict body_list.append body_string arr u'{}.{}.'.format key i else body_list.append u'{}.{} {}\n'.format key i arr .encode 'utf-8' elif isinstance value dict body_list.append body_string value key + ' ' else if value is None value 'null'body_list.append u'{}{} {}\n'.format prefix key value .encode 'utf-8' return ''.join body_list
def is_valid_joint_degree joint_degrees degree_count {}for k in joint_degrees if k > 0 k_size sum joint_degrees[k].values / k if not k_size.is_integer return Falsedegree_count[k] k_sizefor k in joint_degrees for l in joint_degrees[k] if not float joint_degrees[k][l] .is_integer return Falseif k ! l and joint_degrees[k][l] > degree_count[k] * degree_count[l] return Falseelif k l if joint_degrees[k][k] > degree_count[k] * degree_count[k] - 1 return Falseif joint_degrees[k][k] % 2 ! 0 return Falsereturn True
def BM_elements predicate expr assumptions return all ask predicate b assumptions for b in expr.blocks
def _ensure_regexp source n markers ' +~"\' [% ?!*^|&- ;/\\'k 0while True k + 1if n - k < 0 return Truechar source[ n - k ]if char in markers return Trueif char ! '' and char ! '\n' breakreturn False
def illumina_data_to_fastq record_data number_of_bases None seq_index 8qual_index 9pass_filter_index 10try pass_filter int record_data[pass_filter_index] except IndexError pass_filter 2if number_of_bases is None seq record_data[seq_index].replace '.' 'N' qual record_data[qual_index]else seq record_data[seq_index][ number_of_bases].replace '.' 'N' qual record_data[qual_index][ number_of_bases]header '%s_%s %s %s %s %s#%s/%s' % record_data[0] record_data[1] record_data[2] record_data[3] record_data[4] record_data[5] record_data[6] record_data[7] return '@%s\n%s\n+\n%s' % header seq qual pass_filter
def _environment_sanity_check environment assert issubclass environment.undefined Undefined 'undefinedmustbeasubclassofundefinedbecausefiltersdependonit.'assert environment.block_start_string ! environment.variable_start_string ! environment.comment_start_string 'block variableandcommentstartstringsmustbedifferent'assert environment.newline_sequence in '\r' '\r\n' '\n' 'newline_sequencesettounknownlineendingstring.'return environment
def get_object_or_none klass *args **kwargs queryset _get_queryset klass try return queryset.get *args **kwargs except queryset.model.DoesNotExist return None
def hue_permission_required action app def decorator view_func @wraps view_func def decorated request *args **kwargs if not request.user.has_hue_permission action app raise PopupException _ 'Permissiondenied % action s/% app s .' % {'action' action 'app' app} return view_func request *args **kwargs return decoratedreturn decorator
def set_fonts self font_set current.deployment_settings.get_pdf_export_font if font_set try font_name font_set[0]font_name_bold font_set[1]folder current.request.folderpdfmetrics.registerFont TTFont font_name os.path.join folder 'static' 'fonts' '%s.ttf' % font_name pdfmetrics.registerFont TTFont font_name_bold os.path.join folder 'static' 'fonts' '%s.ttf' % font_name_bold except current.log.error '%sFontnotfound PleaseinstallittoseethecorrectfontsinPDFexports' % font_set[0] self.font_name 'Helvetica'self.font_name_bold 'Helvetica-Bold'else self.font_name font_nameself.font_name_bold font_name_boldelse self.font_name 'Helvetica'self.font_name_bold 'Helvetica-Bold'
@with_setup reset def test_new_bundle b Bundle register 'foo' b 's2' 's3' assert b in _get 'foo' .contents register 'footon' 's1' assert 's1' in _get 'footon' .contents register 'foofighters' b output 'bar' assert b in _get 'foofighters' .contents
def getCumulativeVector3Remove defaultVector3 elementNode prefix if prefix '' defaultVector3.x evaluate.getEvaluatedFloat defaultVector3.x elementNode 'x' defaultVector3.y evaluate.getEvaluatedFloat defaultVector3.y elementNode 'y' defaultVector3.z evaluate.getEvaluatedFloat defaultVector3.z elementNode 'z' euclidean.removeElementsFromDictionary elementNode.attributes ['x' 'y' 'z'] prefix 'cartesian'defaultVector3 evaluate.getVector3ByPrefix defaultVector3 elementNode prefix euclidean.removePrefixFromDictionary elementNode.attributes prefix return defaultVector3
def _get_social_page_image_url file_attachments for file_attachment in file_attachments if file_attachment.mimetype.startswith u'image/' return file_attachment.get_absolute_url return None
def hash_file filename return u'ed2k //|file|%s|%d|%s|/' % os.path.basename filename os.path.getsize filename hash_filehash filename .upper
def send_arrays socket arrays stop False if arrays arrays [numpy.ascontiguousarray array for array in arrays]if stop headers {'stop' True}socket.send_json headers else headers [header_data_from_array_1_0 array for array in arrays]socket.send_json headers zmq.SNDMORE for array in arrays[ -1 ] socket.send array zmq.SNDMORE socket.send arrays[ -1 ]
def get_redis_from_settings settings params defaults.REDIS_PARAMS.copy params.update settings.getdict 'REDIS_PARAMS' for source dest in SETTINGS_PARAMS_MAP.items val settings.get source if val params[dest] valif isinstance params.get 'redis_cls' six.string_types params['redis_cls'] load_object params['redis_cls'] return get_redis **params
def create_http_method_map resource method_map {}for method in HTTP_METHODS try responder getattr resource 'on_' + method.lower except AttributeError passelse if callable responder method_map[method] responderallowed_methods sorted list method_map.keys if 'OPTIONS' not in method_map opt_responder responders.create_default_options allowed_methods method_map['OPTIONS'] opt_responderallowed_methods.append 'OPTIONS' na_responder responders.create_method_not_allowed allowed_methods for method in HTTP_METHODS if method not in allowed_methods method_map[method] na_responderreturn method_map
def get_plug_point_class_instances global pp_class_instancesif pp_class_instances is None pp_class_instances []pp_classes []try slps resources.global_env .get_stack_lifecycle_plugins pp_classes [cls for name cls in slps]except Exception LOG.exception _LE 'failedtogetlifecycleplugpointclasses' for ppc in pp_classes try pp_class_instances.append ppc except Exception LOG.exception _LE 'failedtoinstantiatestacklifecycleclass%s' ppc try pp_class_instances sorted pp_class_instances key lambda ppci ppci.get_ordinal except Exception LOG.exception _LE 'failedtosortlifecycleplugpointclasses' return pp_class_instances
def file_has_articles nzf has Falsedecodetable nzf.decodetablefor articlenum in decodetable sleep 0.01 article decodetable[articlenum]data ArticleCache.do.load_article article if data has Truereturn has
def rmul_expr lh_op rh_op size return lo.LinOp lo.RMUL size [lh_op] rh_op
def resize_async image_data width 0 height 0 output_encoding PNG quality None correct_orientation UNCHANGED_ORIENTATION crop_to_fit False crop_offset_x 0.5 crop_offset_y 0.5 allow_stretch False rpc None transparent_substitution_rgb None image Image image_data image.resize width height crop_to_fit crop_to_fit crop_offset_x crop_offset_x crop_offset_y crop_offset_y allow_stretch allow_stretch image.set_correct_orientation correct_orientation return image.execute_transforms_async output_encoding output_encoding quality quality rpc rpc transparent_substitution_rgb transparent_substitution_rgb
def dont_use_config_in_tempest_lib logical_line filename if 'tempest/lib/' not in filename returnif 'tempest.config' in logical_line or 'fromtempestimportconfig' in logical_line or 'oslo_config' in logical_line msg 'T114 tempest.libcannothaveanydependencyontempestconfig.' yield 0 msg
def decipher_hill msg key symbols None assert key.is_square msg _ A _prep msg '' symbols map {c i for i c in enumerate A }C [map[c] for c in msg]N len A k key.colsn len C m r divmod n k if r C C + [0] * k - r m + 1key_inv key.inv_mod N rv ''.join [A[ p % N ] for j in range m for p in list key_inv * Matrix k 1 [C[i] for i in range k * j k * j + 1 ] ] return rv
def modbus_context_decoder mapping_blocks blocks defaultdict dict for block in mapping_blocks.itervalues for mapping in block.itervalues value int mapping['value'] address int mapping['address'] function mapping['function']blocks[function][address] valuereturn ModbusSlaveContext **blocks
def Define d flavor if flavor 'win' d d.replace '#' '\\%03o' % ord '#' return QuoteShellArgument ninja_syntax.escape '-D' + d flavor
def dict_from_int version_int d {}rem version_int rem d['pre_ver'] divmod rem 100 rem d['pre'] divmod rem 10 rem d['alpha_ver'] divmod rem 100 rem d['alpha'] divmod rem 10 rem d['minor3'] divmod rem 100 rem d['minor2'] divmod rem 100 rem d['minor1'] divmod rem 100 rem d['major'] divmod rem 100 d['pre'] None if d['pre'] else 'pre' d['alpha'] {0 'a' 1 'b'}.get d['alpha'] return d
def test_raises_value_error_non_sum_one P np.array [[0.4 0.6] [0.2 0.9]] assert_raises ValueError MarkovChain P assert_raises ValueError MarkovChain sparse.csr_matrix P
def mp_from_ids s3server mp_id mp_keyname mp_bucketname if s3server['host'] conn boto.connect_s3 aws_access_key_id s3server['access_key'] aws_secret_access_key s3server['secret_key'] is_secure s3server['is_secure'] host s3server['host'] port s3server['port'] calling_format boto.s3.connection.OrdinaryCallingFormat path s3server['conn_path'] else conn S3Connection s3server['access_key'] s3server['secret_key'] bucket conn.lookup mp_bucketname mp boto.s3.multipart.MultiPartUpload bucket mp.key_name mp_keynamemp.id mp_idreturn mp
def _lazy_re_compile regex flags 0 def _compile if isinstance regex str return re.compile regex flags else assert not flags 'flagsmustbeemptyifregexispassedpre-compiled'return regexreturn SimpleLazyObject _compile
def run _task
def evennia_version version 'Unknown'try import evenniaversion evennia.__version__except ImportError passtry rev check_output 'gitrev-parse--shortHEAD' shell True cwd EVENNIA_ROOT stderr STDOUT .strip version '%s rev%s ' % version rev except IOError CalledProcessError passreturn version
def get_valid_salt_views ret {}ret['minions'] {}ret['minions']['map'] 'function doc {emit doc.id null ;}'ret['minions']['reduce'] 'function keys values rereduce {returnkey[0];}'ret['by-minion-fun-timestamp'] {}ret['by-minion-fun-timestamp']['map'] 'function doc {emit [doc.id doc.fun doc.timestamp] doc ;}'return ret
def rayleightest data axis None weights None n np.size data axis axis Rbar _length data 1 0.0 axis weights z n * Rbar * Rbar tmp 1.0if n < 50 tmp 1.0 + 2.0 * z - z * z / 4.0 * n - 24.0 * z - 132.0 * z ** 2.0 + 76.0 * z ** 3.0 - 9.0 * z ** 4.0 / 288.0 * n * n p_value np.exp - z * tmp return p_value
@requires_application def test_close_keys c Canvas keys 'interactive' x list @c.events.close.connectdef closer event x.append 'done' c.events.key_press key keys.ESCAPE text '' modifiers [] assert_equal len x 1 c.app.process_events
def getClientRoot output p4CmdList 'client-o' if len output ! 1 die 'Outputfrom"client-o"is%dlines expecting1' % len output entry output[0]if 'Root' not in entry die 'Clienthasno"Root"' return entry['Root']
def _reexec updated_modules None if odoo.tools.osutil.is_running_as_nt_service subprocess.call 'netstop{0}&&netstart{0}'.format nt_service_name shell True exe os.path.basename sys.executable args stripped_sys_argv if updated_modules args + ['-u' ' '.join updated_modules ]if not args or args[0] ! exe args.insert 0 exe os.execv sys.executable args
def process_contexts server contexts p_ctx error None for ctx in contexts ctx.descriptor.aux.initialize_context ctx p_ctx error if error is None or ctx.descriptor.aux.process_exceptions ctx.descriptor.aux.process_context server ctx
def infer_named_tuple node context None class_node name attributes infer_func_form node nodes.Tuple._proxied context context fake AstroidBuilder MANAGER .string_build "\nclass% name s tuple \n_fields % fields r\ndef_asdict self \nreturnself.__dict__\n@classmethod\ndef_make cls iterable new tuple.__new__ len len \nreturnnew cls iterable \ndef_replace _self **kwds \nresult _self._make map kwds.pop % fields r _self \nifkwds \nraiseValueError 'Gotunexpectedfieldnames %%r'%%list kwds \nreturnresult\n" % {'name' name 'fields' attributes} class_node.locals['_asdict'] fake.body[0].locals['_asdict']class_node.locals['_make'] fake.body[0].locals['_make']class_node.locals['_replace'] fake.body[0].locals['_replace']class_node.locals['_fields'] fake.body[0].locals['_fields']return iter [class_node]
def askcolor color None **options global _chooserif not _chooser _chooser apply Chooser options return _chooser.show color options
def install_flocker nodes package_source return _run_on_all_nodes nodes task lambda node sequence [task_install_flocker distribution node.distribution package_source package_source task_install_docker_plugin distribution node.distribution package_source package_source ]
def get_s3a_secret_key return get_conf .get _CNF_S3A_SECRET_KEY
def optwrap text if not BODY_WIDTH return textassert wrap 'RequiresPython2.3.'result ''newlines 0for para in text.split '\n' if len para > 0 if para[0] is not '' and para[0] is not '-' and para[0] is not '*' for line in wrap para BODY_WIDTH result + line + '\n' result + '\n'newlines 2elif not onlywhite para result + para + '\n' newlines 1elif newlines < 2 result + '\n'newlines + 1return result
def _get_volume_region volume return getattr volume.driver 'region' None or getattr volume.driver 'region_name' None
def _rereview_to_theme rereview theme if rereview return theme.themereturn theme
def check_all_ids fasta_labels sample_ids raw_fasta_labels set [label.split '_' [0] for label in fasta_labels] sample_ids_not_found []for curr_id in sample_ids if curr_id not in raw_fasta_labels sample_ids_not_found.append curr_id if len sample_ids_not_found 0 sample_ids_not_found Truereturn sample_ids_not_found
def require_auth view_func from horizon.exceptions import NotAuthenticated@functools.wraps view_func assigned available_attrs view_func def dec request *args **kwargs if request.user.is_authenticated return view_func request *args **kwargs raise NotAuthenticated _ 'Pleaselogintocontinue.' return dec
def keyToXML key return _tagAttr key '' [0]
def _fsencoding encoding sys.getfilesystemencoding or sys.getdefaultencoding if encoding 'mbcs' encoding 'utf8'return encoding
def rotate color percent return adjust color 0 percent
def generate_go_test target source env go go_home env['GOCMD'] env['GOHOME'] cmd 'GOPATH %s%stest-c-o%s%s' % go_home go target[0] env['GOPACKAGE'] return echospawn args [cmd] env os.environ sh None cmd None escape None
@blueprint.route '/users/<user>/meters/<meter>' def list_samples_by_user user meter return _list_samples user user meter meter project acl.get_limited_to_project flask.request.headers
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _indent text amount indentation amount * '' return indentation + '\n' + indentation .join text.split '\n'
def update_admin_ids committer_id admin_usernames admin_ids []for username in admin_usernames user_id user_services.get_user_id_from_username username if user_id is not None admin_ids.append user_id else raise Exception 'Badadminusername %s' % username Registry.get_config_property 'admin_ids' .set_value committer_id admin_ids
def set_index df index npartitions None shuffle None compute False drop True upsample 1.0 divisions None **kwargs if isinstance index Series and index._name df.index._name return dfif isinstance index DataFrame tuple list raise NotImplementedError 'Daskdataframedoesnotyetsupportmulti-indexes.\nYoutriedtoindexwiththisindex %s\nIndexesmustbesinglecolumnsonly.' % str index npartitions npartitions or df.npartitions if not isinstance index Series index2 df[index]else index2 indexif divisions is None divisions index2._repartition_quantiles npartitions upsample upsample .compute .tolist return set_partition df index divisions shuffle shuffle drop drop compute compute **kwargs
def organization_follower_list context data_dict _check_access 'organization_follower_list' context data_dict return _follower_list context data_dict ckan.logic.schema.default_follow_group_schema context['model'].UserFollowingGroup
def metrics request locale_code None template 'questions/metrics.html'product request.GET.get 'product' if product product get_object_or_404 Product slug product form StatsForm request.GET if form.is_valid bucket_days form.cleaned_data['bucket']start form.cleaned_data['start']end form.cleaned_data['end']else bucket_days 1start date.today - timedelta days 30 end date.today graph_data stats_topic_data bucket_days start end locale_code product for group in graph_data for name count in group.items if count 0 del group[name]data {'graph' graph_data 'form' form 'current_locale' locale_code 'product' product 'products' Product.objects.filter visible True }return render request template data
def search_count db query global _search_db_namesif _search_db_names is None _search_db_names _get_fields _BASE_URL + '/search' if db not in _search_db_names import warningswarnings.warn "TogoWSsearchdoesnotofficiallysupportdatabase'%s'.See%s/search/foroptions." % db _BASE_URL url _BASE_URL + '/search/%s/%s/count' % db _quote query handle _open url data handle.read handle.close try count int data.strip except ValueError raise ValueError 'ExpectedanintegerfromURL%s got %r' % url data return count
def cldr_modulo a b reverse 0if a < 0 a * -1 reverse 1if b < 0 b * -1 rv a % b if reverse rv * -1 return rv
@decorators.which 'ssh-keygen' def hash_known_hosts user None config None full _get_known_hosts_file config config user user if isinstance full dict return fullif not os.path.isfile full return {'status' 'error' 'error' 'Knownhostsfile{0}doesnotexist'.format full }origmode os.stat full .st_modecmd ['ssh-keygen' '-H' '-f' full]cmd_result __salt__['cmd.run'] cmd python_shell False os.chmod full origmode if os.geteuid 0 and user uinfo __salt__['user.info'] user os.chown full uinfo['uid'] uinfo['gid'] return {'status' 'updated' 'comment' cmd_result}
def worker_activate worker lbn profile 'default' return _worker_ctl worker lbn 'a' profile
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def rewrite_legacy config bridges config.get CONF_BRIDGES [config] new_bridges []for bridge_conf in bridges groups []if 'groups' in bridge_conf groups bridge_conf['groups']else _LOGGER.warning 'Legacyconfigurationformatdetected' for i in range 1 5 name_key 'group_%d_name' % i if name_key in bridge_conf groups.append {'number' i 'type' bridge_conf.get 'group_%d_type' % i DEFAULT_LED_TYPE 'name' bridge_conf.get name_key } new_bridges.append {'host' bridge_conf.get CONF_HOST 'groups' groups} return {'bridges' new_bridges}
def test_keypoints_censure_moon_image_star detector CENSURE mode 'star' detector.detect rescale img 0.25 expected_keypoints np.array [[23 27] [29 89] [30 86] [107 59] [109 64] [111 67] [113 70]] expected_scales np.array [3 2 4 2 5 3 2] assert_array_equal expected_keypoints detector.keypoints assert_array_equal expected_scales detector.scales
def no_direct_use_of_unicode_function logical_line if unicode_func_re.match logical_line yield 0 'G320 Usesix.text_type insteadofunicode '
def clean_object_caches obj global _TYPECLASSMODELS _OBJECTMODELSif not _TYPECLASSMODELS from evennia.typeclasses import models as _TYPECLASSMODELSif not obj returntry _SA obj '_contents_cache' None except AttributeError pass[_DA obj cname for cname in viewkeys obj.__dict__ if cname.startswith '_cached_db_' ]try hashid _GA obj 'hashid' _TYPECLASSMODELS._ATTRIBUTE_CACHE[hashid] {}except AttributeError pass
def user_find client user db_name for mongo_user in client['admin'].system.users.find if mongo_user['user'] user if 'db' not in mongo_user return mongo_userif mongo_user['db'] db_name return mongo_userreturn False
def get_unseen_likes return frappe.db.sql u"selectcount * from`tabCommunication`\n DCTB DCTB where\n DCTB DCTB DCTB communication_type 'Comment'\n DCTB DCTB DCTB andmodified> DATE_SUB NOW INTERVAL1YEAR \n DCTB DCTB DCTB andcomment_type 'Like'\n DCTB DCTB DCTB andownerisnotnullandowner! % user s\n DCTB DCTB DCTB andreference_owner % user s\n DCTB DCTB DCTB andseen 0" {u'user' frappe.session.user} [0][0]
def show_address kwargs None call None if call ! 'function' raise SaltCloudSystemExit 'Theshow_snapshotfunctionmustbecalledwith-for--function.' if not kwargs or 'name' not in kwargs log.error 'Mustspecifyname.' return Falseif not kwargs or 'region' not in kwargs log.error 'Mustspecifyregion.' return Falseconn get_conn return _expand_address conn.ex_get_address kwargs['name'] kwargs['region']
def _resize_error src instance user mkt.log mkt.LOG.VIDEO_ERROR instance user user instance.delete
def laxnodeset v if not isinstance v NodeSet v immnodeset v return v
def makeService config if config['file'] quoter quoters.FortuneQuoter [config['file']] else quoter quoters.StaticQuoter config['static'] port int config['port'] factory quoteproto.QOTDFactory quoter return internet.TCPServer port factory
def norm_html_from_html html if not isinstance html unicode html html.decode 'utf-8' html _markdown_email_link_re.sub _markdown_email_link_sub html if sys.platform 'win32' html html.replace '\r\n' '\n' return html
def stdout_print print 'foo' return 'bar'
def _unquote_path path return urllib.unquote path
def minion_config opts vm_ minion {'master' 'salt' 'log_level' 'info' 'hash_type' 'sha256'}minion['id'] vm_['name']master_finger salt.config.get_cloud_config_value 'master_finger' vm_ opts if master_finger is not None minion['master_finger'] master_fingerminion.update salt.config.get_cloud_config_value 'minion' vm_ opts default {} search_global True make_master salt.config.get_cloud_config_value 'make_master' vm_ opts if 'master' not in minion and make_master is not True raise SaltCloudConfigError "Amastersettingwasnotdefinedintheminion'sconfiguration." minion.setdefault 'grains' {} .update salt.config.get_cloud_config_value 'grains' vm_ opts default {} search_global True return minion
def NoCase re return SwitchCase re nocase 1
def convert_gff_coords_to_bed interval if isinstance interval GenomicInterval interval.start - 1if isinstance interval GFFFeature for subinterval in interval.intervals convert_gff_coords_to_bed subinterval elif isinstance interval list interval[0] - 1return interval
def listen_tcp portrange host factory assert len portrange < 2 'invalidportrange %s' % portrange if not hasattr portrange '__iter__' return reactor.listenTCP portrange factory interface host if not portrange return reactor.listenTCP 0 factory interface host if len portrange 1 return reactor.listenTCP portrange[0] factory interface host for x in range portrange[0] portrange[1] + 1 try return reactor.listenTCP x factory interface host except error.CannotListenError if x portrange[1] raise
def run_git_or_fail args git_path _DEFAULT_GIT input None **popen_kwargs if 'stderr' not in popen_kwargs popen_kwargs['stderr'] subprocess.STDOUT returncode stdout run_git args git_path git_path input input capture_stdout True **popen_kwargs if returncode ! 0 raise AssertionError 'gitwithargs%rfailedwith%d %r' % args returncode stdout return stdout
def update_arc_indexes geometry merged_arcs old_arcs if geometry['type'] in 'Point' 'MultiPoint' returnelif geometry['type'] 'LineString' for arc_index old_arc in enumerate geometry['arcs'] geometry['arcs'][arc_index] len merged_arcs merged_arcs.append old_arcs[old_arc] elif geometry['type'] 'Polygon' for ring in geometry['arcs'] for arc_index old_arc in enumerate ring ring[arc_index] len merged_arcs merged_arcs.append old_arcs[old_arc] elif geometry['type'] 'MultiLineString' for part in geometry['arcs'] for arc_index old_arc in enumerate part part[arc_index] len merged_arcs merged_arcs.append old_arcs[old_arc] elif geometry['type'] 'MultiPolygon' for part in geometry['arcs'] for ring in part for arc_index old_arc in enumerate ring ring[arc_index] len merged_arcs merged_arcs.append old_arcs[old_arc] else raise NotImplementedError "Can'tdo%sgeometries" % geometry['type']
def has_filename_filter module return getattr module 'filename' None is not None
def find_folders_under root db add_root True follow_links False cancel_callback lambda False lp db.library_pathif lp lp os.path.abspath lp root os.path.abspath root ans set [] for dirpath dirnames __ in os.walk root topdown True followlinks follow_links if cancel_callback breakfor x in list dirnames path os.path.join dirpath x if lp and path.startswith lp dirnames.remove x if lp and dirpath.startswith lp continueans.add dirpath if not add_root ans.remove root return ans
def num_answers user return Answer.objects.filter creator user .count
def _is_partial_args func args kwargs if func not in signatures return Nonesigs signatures[func]return any check_partial sig args kwargs for sig in sigs
@frappe.whitelist def get_grade grading_scale percentage grading_scale_intervals {}for d in frappe.get_all u'GradingScaleInterval' fields [u'grade_code' u'threshold'] filters {u'parent' grading_scale} grading_scale_intervals.update {d.threshold d.grade_code} intervals sorted grading_scale_intervals.keys key float reverse True for interval in intervals if flt percentage > interval grade grading_scale_intervals.get interval breakelse grade u''return grade
def validate_api_key api_key api_key_db ApiKey.get api_key if not api_key_db.enabled raise exceptions.ApiKeyDisabledError 'APIkeyisdisabled.' LOG.audit 'APIkeywithid"%s"isvalidated.' % api_key_db.id return api_key_db
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def CDLHARAMICROSS barDs count return call_talib_with_ohlc barDs count talib.CDLHARAMICROSS
def _stdin_ready_nt return msvcrt.kbhit
def lineage resource while resource is not None yield resource try resource resource.__parent__except AttributeError resource None
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def _cmidrule colindex dataset_width rule '\\cmidrule %s {%d-%d}'if colindex 1 return rule % 'r' colindex colindex if colindex dataset_width return rule % 'l' colindex colindex return rule % 'lr' colindex colindex
def split_names voters voters voters.split ' ' 1 [ -1 ]voters re.sub ' Senator|Representative \\ s\\ ?' '' voters voters re.sub '\\s+' '' voters voters [x.strip for x in re.split ' ? \\s ?![A-Z]\\. | ? \\sand\\s ' voters ]return voters
def MomentumAdjustor final_momentum start saturate warnings.warn 'sgd.MomentumAdjustorinterfaceisdeprecatedandwillbecomeofficiallyunsupportedasofMay9 2014.Pleaseuse`learning_rule.MomentumAdjustor`instead.' return LRMomentumAdjustor final_momentum start saturate
def shared_cluster conf False cluster shared_cluster_internal closers []if conf closers.extend [hadoop.conf.HDFS_CLUSTERS['default'].NN_HOST.set_for_testing 'localhost' hadoop.conf.HDFS_CLUSTERS['default'].NN_HDFS_PORT.set_for_testing cluster.namenode_port hadoop.conf.MR_CLUSTERS['default'].HOST.set_for_testing 'localhost' hadoop.conf.MR_CLUSTERS['default'].JT_THRIFT_PORT.set_for_testing cluster.jt.thrift_port ] old_caches clear_sys_caches def finish if conf restore_sys_caches old_caches for x in closers x cluster.shutdown finishreturn cluster
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def invhilbert n exact False from scipy.special import combif exact if n > 14 dtype objectelse dtype np.int64else dtype np.float64invh np.empty n n dtype dtype for i in xrange n for j in xrange 0 i + 1 s i + j invh[ i j ] -1 ** s * s + 1 * comb n + i n - j - 1 exact * comb n + j n - i - 1 exact * comb s i exact ** 2 if i ! j invh[ j i ] invh[ i j ]return invh
def _EscapeCppDefineForMSVS s s _EscapeEnvironmentVariableExpansion s s _EscapeCommandLineArgumentForMSVS s s _EscapeVCProjCommandLineArgListItem s s s.replace '#' '\\%03o' % ord '#' return s
def getFaceGivenLine line triangleMesh faceGivenLine face.Face faceGivenLine.index len triangleMesh.faces splitLine line.split for vertexStringIndex in xrange 1 4 vertexString splitLine[vertexStringIndex]vertexStringWithSpaces vertexString.replace '/' '' vertexStringSplit vertexStringWithSpaces.split vertexIndex int vertexStringSplit[0] - 1 faceGivenLine.vertexIndexes.append vertexIndex return faceGivenLine
def maximum x1 x2 return Maximum x1 x2
def log2 x ln2 math.log 2.0 try bin_n binary_repr x [1 ]except AssertionError TypeError return math.log x / ln2 else if u'1' in bin_n return math.log x / ln2 else return len bin_n
def askpassword title prompt **kw d apply _QueryPassword title prompt kw return d.result
def one_to_three s i d1_to_index[s]return dindex_to_3[i]
@task_filter protocol 'size' def filter_by_size keyword task m re.match '^ [<>] ? \\d+ ? \\.\\d+ ? [GM] ? [+-] ?$' keyword flags re.I assert m keyword less_or_great n u less_or_more m.groups assert bool less_or_great ^ bool less_or_more 'mustbt<size >size size- orsize+'size float n * {None 1 'G' 1000 ** 3 'g' 1000 ** 3 'M' 1000 ** 2 'm' 1000 ** 2 }[u] if less_or_great '<' or less_or_more '-' return task['size'] < size else return task['size'] > size
def maybe_to_categorical array if isinstance array ABCSeries ABCCategoricalIndex return array._valuesreturn array
def in_loop node parent node.parentwhile parent is not None if isinstance parent astroid.For astroid.ListComp astroid.SetComp astroid.DictComp astroid.GenExpr return Trueparent parent.parentreturn False
def rename_file source dest os.rename source dest __remove_pyc_pyo source
def overridable_property name doc None getter_name intern 'get_' + name setter_name intern 'set_' + name return property lambda self getattr self getter_name lambda self value getattr self setter_name value None doc
def inv_quick M from sympy.matrices import zerosif any i.has Symbol for i in M if all i.has Symbol for i in M det lambda _ det_perm _ else det lambda _ det_minor _ else return M.inv n M.rowsd det M if d is S.Zero raise ValueError 'Matrixdet 0;notinvertible.' ret zeros n s1 -1 for i in range n s s1 - s1 for j in range n di det M.minorMatrix i j ret[ j i ] s * di / d s - s return ret
def get_default_persistent_db_instance return get_default_temp_db_instance
def _get_phred_quality record try return record.letter_annotations['phred_quality']except KeyError passtry return [phred_quality_from_solexa q for q in record.letter_annotations['solexa_quality']]except KeyError raise ValueError 'Nosuitablequalityscoresfoundinletter_annotationsofSeqRecord id %s .' % record.id
def setup app app.add_role 'rfc' rfclink return
def get_all_sharing_strategies return _all_sharing_strategies
def get_source_inputs tensor layer None node_index None if not hasattr tensor '_keras_history' return tensorif layer is None or node_index layer node_index _ tensor._keras_historyif not layer.inbound_nodes return [tensor]else node layer.inbound_nodes[node_index]if not node.inbound_layers return node.input_tensorselse source_tensors []for i in range len node.inbound_layers x node.input_tensors[i]layer node.inbound_layers[i]node_index node.node_indices[i]previous_sources get_source_inputs x layer node_index for x in previous_sources if x not in source_tensors source_tensors.append x return source_tensors
def fmin_bfgs f x0 fprime None args gtol 1e-05 norm Inf epsilon _epsilon maxiter None full_output 0 disp 1 retall 0 callback None opts {'gtol' gtol 'norm' norm 'eps' epsilon 'disp' disp 'maxiter' maxiter 'return_all' retall}res _minimize_bfgs f x0 args fprime callback callback **opts if full_output retlist res['x'] res['fun'] res['jac'] res['hess_inv'] res['nfev'] res['njev'] res['status'] if retall retlist + res['allvecs'] return retlistelif retall return res['x'] res['allvecs'] else return res['x']
@register.inclusion_tag get_template 'inclusion.html' def inclusion_two_params_from_template one two return {'result' 'inclusion_two_params_from_template-Expectedresult %s %s' % one two }
def boundaries x depth None kind None if not isinstance kind dict kind dict i kind for i in range x.ndim if not isinstance depth dict depth dict i depth for i in range x.ndim for i in range x.ndim d depth.get i 0 if d 0 continuethis_kind kind.get i 'none' if this_kind 'none' continueelif this_kind 'periodic' x periodic x i d elif this_kind 'reflect' x reflect x i d elif this_kind 'nearest' x nearest x i d elif i in kind x constant x i d kind[i] return x
def _retrieve_ntp_servers return __salt__['ntp.servers']
def get_public_key ssh_conf_path os.path.expanduser '~/.ssh' dsa_public_key_path os.path.join ssh_conf_path 'id_dsa.pub' dsa_private_key_path os.path.join ssh_conf_path 'id_dsa' rsa_public_key_path os.path.join ssh_conf_path 'id_rsa.pub' rsa_private_key_path os.path.join ssh_conf_path 'id_rsa' has_dsa_keypair os.path.isfile dsa_public_key_path and os.path.isfile dsa_private_key_path has_rsa_keypair os.path.isfile rsa_public_key_path and os.path.isfile rsa_private_key_path if has_dsa_keypair logging.info 'DSAkeypairfound usingit' public_key_path dsa_public_key_pathelif has_rsa_keypair logging.info 'RSAkeypairfound usingit' public_key_path rsa_public_key_pathelse logging.info 'NeitherRSAnorDSAkeypairfound creatingDSAsshkeypair' utils.system 'ssh-keygen-tdsa-q-N""-f%s' % dsa_private_key_path public_key_path dsa_public_key_pathpublic_key open public_key_path 'r' public_key_str public_key.read public_key.close return public_key_str
def postprocess_for_cse expr optimizations for pre post in reversed optimizations if post is not None expr post expr return expr
def handle_error code from website.routes import OsfWebRendererjson_renderer JSONRenderer web_renderer OsfWebRenderer '' render_mako_string error HTTPError code renderer json_renderer if is_json_request else web_renderer return make_response renderer.handle_error error
def rs_series_reversion p x n y if rs_is_puiseux p x raise NotImplementedErrorR p.ringnx R.gens.index x y R y ny R.gens.index y if _has_constant_term p x raise ValueError 'pmustnotcontainaconstanttermintheseriesvariable' a _coefficient_t p nx 1 zm R.zero_monomassert zm in a and len a 1 a a[zm]r y / a for i in range 2 n sp rs_subs p {x r} y i + 1 sp _coefficient_t sp ny i * y ** i r - sp / a return r
def parse_date date_string assume_utc False as_utc True default None from dateutil.parser import parseif not date_string return UNDEFINED_DATEif default is None func datetime.utcnow if assume_utc else datetime.now default func .replace day 15 hour 0 minute 0 second 0 microsecond 0 tzinfo _utc_tz if assume_utc else _local_tz if iso_pat .match date_string is not None dt parse date_string default default else dt parse date_string default default dayfirst parse_date_day_first if dt.tzinfo is None dt dt.replace tzinfo _utc_tz if assume_utc else _local_tz return dt.astimezone _utc_tz if as_utc else _local_tz
def InstallTemplatePackage virtualenv_bin os.path.dirname sys.executable extension os.path.splitext sys.executable [1]pip '%s/pip%s' % virtualenv_bin extension major_minor_version '.'.join pkg_resources.get_distribution 'grr-response-core' .version.split '.' [0 2] subprocess.check_call [sys.executable pip 'install' '--upgrade' '-f' 'https //storage.googleapis.com/releases.grr-response.com/index.html' 'grr-response-templates %s.*' % major_minor_version ]
def build_mock_object obj_id mock_object Mock object_config {'pk' obj_id 'name' 'object{}'.format obj_id }mock_object.configure_mock **object_config return mock_object
def remove_protocol_from_url url if url is None return urlif url.find ' //' > 0 new_url url.split ' //' [1]else new_url urlreturn new_url.rstrip '/'
def _expected observed o observedif len o 0 return []if len o 1 return [ [ sum o[0] / float len o[0] ] * len o[0] ]n [sum o[i] for i in xrange len o ]m [sum o[i][j] for i in xrange len o for j in xrange len o[0] ]s float sum n return [[ n[i] * m[j] / s for j in xrange len o[i] ] for i in xrange len o ]
def append table 'filter' chain None rule None family 'ipv4' if not chain return 'Error Chainneedstobespecified'if not rule return 'Error Ruleneedstobespecified'wait '--wait' if _has_option '--wait' family else '' returnCheck check table chain rule family if isinstance returnCheck bool and returnCheck return Falsecmd '{0}{1}-t{2}-A{3}{4}'.format _iptables_cmd family wait table chain rule out __salt__['cmd.run'] cmd if len out 0 return Trueelse return False
def format_isodate_for_user_timezone value config get_config timezone config.get 'cli' {} .get 'timezone' 'UTC' result format_isodate value value timezone timezone return result
def _tree_namespace_handler k v cherrypy.tree.graft v v.script_name cherrypy.engine.log 'Mounted %son%s' % v v.script_name or '/'
def get_approved_tools app sa_session tools []for tool in sa_session.query app.model.Tool .order_by app.model.Tool.table.c.name if tool.state app.model.Tool.states.APPROVED tools.append tool return tools
def pseudocorpus source_vocab sep for k in source_vocab if sep not in k continueunigrams k.split sep for i in range 1 len unigrams yield [sep.join unigrams[ i] sep.join unigrams[i ] ]
def update_exc exc msg before True separator '\n' emsg exc.messageif before parts msg separator emsg else parts emsg separator msg new_msg '%s%s%s' % parts new_args new_msg + exc.args[1 ] exc.message new_msgexc.args new_argsreturn exc
def assertion assertion assert assertion
def runExperiment args model None opt _parseCommandLineOptions args model _runExperimentImpl opt model return model
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def write_zfile file_handle data compress 1 file_handle.write _ZFILE_PREFIX length hex_str len data file_handle.write asbytes length.ljust _MAX_LEN file_handle.write zlib.compress asbytes data compress
def check_err code if code OGRERR_NONE returnelif code in OGRERR_DICT e msg OGRERR_DICT[code]raise e msg else raise OGRException 'Unknownerrorcode "%s"' % code
def doctype_matches text regex m doctype_lookup_re.match text if m is None return Falsedoctype m.group 2 return re.compile regex .match doctype.strip is not None
def _numpy_checker x y x y x[0] y[0] if x.dtype ! y.dtype or x.shape ! y.shape or numpy.any numpy.abs x - y > 1e-10 raise Exception 'Outputmismatch.' {'performlinker' x 'clinker' y}
def returner ret conn mdb _get_conn ret if isinstance ret['return'] dict back _remove_dots ret['return'] else back ret['return']if isinstance ret dict full_ret _remove_dots ret else full_ret retlog.debug back sdata {'minion' ret['id'] 'jid' ret['jid'] 'return' back 'fun' ret['fun'] 'full_ret' full_ret}if 'out' in ret sdata['out'] ret['out']if float version > 2.3 mdb.saltReturns.insert_one sdata.copy else mdb.saltReturns.insert sdata.copy
def parse_params params ignore_keys None parsed {}for key in params if ignore_keys and key in ignore_keys continuevalue params.getall key if not value value ''if len value 1 value value[0]parsed[key] valuereturn parsed
def _oauth_signature consumer_token method url parameters {} token None parts urlparse.urlparse url scheme netloc path parts[ 3]normalized_url scheme.lower + ' //' + netloc.lower + path base_elems []base_elems.append method.upper base_elems.append normalized_url base_elems.append '&'.join '%s %s' % k _oauth_escape str v for k v in sorted parameters.items base_string '&'.join _oauth_escape e for e in base_elems key_elems [escape.utf8 consumer_token['secret'] ]key_elems.append escape.utf8 token['secret'] if token else '' key '&'.join key_elems hash hmac.new key escape.utf8 base_string hashlib.sha1 return binascii.b2a_base64 hash.digest [ -1 ]
def scalarconsts_rest inputs elemwise True only_process_constants False consts []origconsts []nonconsts []for i in inputs try v get_scalar_constant_value i elemwise elemwise only_process_constants only_process_constants consts.append v origconsts.append i except NotScalarConstantError nonconsts.append i return consts origconsts nonconsts
def getInterpretPluginsPath subName '' return getJoinedPath getFabmetheusToolsPath 'interpret_plugins' subName
def _smooth_bootstrap args n_boot func func_kwargs n len args[0] boot_dist []kde [stats.gaussian_kde np.transpose a for a in args]for i in range int n_boot sample [a.resample n .T for a in kde]boot_dist.append func *sample **func_kwargs return np.array boot_dist
def test_unused_method_camelcase vultdir vultdir.makepyfile foo '\nclassFoo \n\ndeffooBar self \npass\n\nFoo \n' assert not vultdir.run
def gen_state_tag low return '{0[state]}_|-{0[__id__]}_|-{0[name]}_|-{0[fun]}'.format low
def _create_and_add_parameters params global _current_parameterif _is_simple_type params _current_parameter SimpleParameter params _current_option.add_parameter _current_parameter else for i in params if _is_simple_type i _current_parameter SimpleParameter i else _current_parameter TypedParameter _parse_typed_parameter i _current_option.add_parameter _current_parameter
@register u'yank-pop' def yank_pop event buff event.current_bufferdoc_before_paste buff.document_before_pasteclipboard event.cli.clipboardif doc_before_paste is not None buff.document doc_before_pasteclipboard.rotate buff.paste_clipboard_data clipboard.get_data paste_mode PasteMode.EMACS
def _record_payment_info params order if settings.FEATURES.get 'LOG_POSTPAY_CALLBACKS' log.info 'Order%dprocessed butnotcompleted withparams %s' order.id json.dumps params order.processor_reply_dump json.dumps params order.save
def _multi_call function contentkey *args **kwargs ret function *args **kwargs position ret.get 'position' while position more function position position *args **kwargs ret[contentkey].extend more[contentkey] position more.get 'position' return ret.get contentkey
def _prepare_fit_binary est y i y_i np.ones y.shape dtype np.float64 order 'C' y_i[ y ! est.classes_[i] ] -1.0 average_intercept 0average_coef Noneif len est.classes_ 2 if not est.average coef est.coef_.ravel intercept est.intercept_[0]else coef est.standard_coef_.ravel intercept est.standard_intercept_[0]average_coef est.average_coef_.ravel average_intercept est.average_intercept_[0]elif not est.average coef est.coef_[i]intercept est.intercept_[i]else coef est.standard_coef_[i]intercept est.standard_intercept_[i]average_coef est.average_coef_[i]average_intercept est.average_intercept_[i]return y_i coef intercept average_coef average_intercept
@require_role 'admin' def idc_add request header_title path1 path2 u'\u6dfb\u52a0IDC' u'\u8d44\u4ea7\u7ba1\u7406' u'\u6dfb\u52a0IDC' if request.method 'POST' idc_form IdcForm request.POST if idc_form.is_valid idc_name idc_form.cleaned_data['name']if IDC.objects.filter name idc_name emg u'\u6dfb\u52a0\u5931\u8d25 \u6b64IDC%s\u5df2\u5b58\u5728!' % idc_name return my_render 'jasset/idc_add.html' locals request else idc_form.save smg u'IDC %s\u6dfb\u52a0\u6210\u529f' % idc_name return HttpResponseRedirect reverse 'idc_list' else idc_form IdcForm return my_render 'jasset/idc_add.html' locals request
def _interpret_history_log fs matches for match in matches path match['path']if match['yarn'] result _parse_yarn_history_log _cat_log fs path else result _parse_pre_yarn_history_log _cat_log fs path for error in result.get 'errors' or if 'hadoop_error' in error error['hadoop_error']['path'] path_add_implied_task_id error return resultreturn {}
def datetime_format_to_js_datetime_format format converted formatreplacements {'%Y' 'yyyy' '%y' 'yy' '%m' 'mm' '%d' 'dd' '%H' 'hh' '%I' 'HH' '%M' 'ii' '%S' 'ss'}for search replace in replacements.items converted converted.replace search replace return converted.strip
def test_parse_options m DummyMagics _ip nt.assert_equal m.parse_options 'foo' '' [1] 'foo' nt.assert_equal m.parse_options u'foo' '' [1] u'foo'
def expect_dimensions __funcname _qualified_name **dimensions if isinstance __funcname str def get_funcname _ return __funcnameelse get_funcname __funcnamedef _expect_dimension expected_ndim def _check func argname argvalue actual_ndim argvalue.ndimif actual_ndim ! expected_ndim if actual_ndim 0 actual_repr 'scalar'else actual_repr '%d-Darray' % actual_ndim raise ValueError '{func} expecteda{expected d}-Darrayforargument{argname!r} butgota{actual}instead.'.format func get_funcname func expected expected_ndim argname argname actual actual_repr return argvaluereturn _checkreturn preprocess **valmap _expect_dimension dimensions
def build_binary_response request data code return build_response request data code None
def _exact_ratio x try if type x is float or type x is Decimal return x.as_integer_ratio try return x.numerator x.denominator except AttributeError try return x.as_integer_ratio except AttributeError passexcept OverflowError ValueError assert not _isfinite x return x None msg "can'tconverttype'{}'tonumerator/denominator"raise TypeError msg.format type x .__name__
def section def prep r s3db.configure r.tablename deletable False orderby '%s.posn' % r.tablename return Trues3.prep prepdef postp r output 'Addthesectionselectwidgettotheform'try template_id int request.args[0] except template_id NonesectionSelect s3.survey_section_select_widget template_id output['sectionSelect'] sectionSelectreturn outputoutput s3_rest_controller return output
def reverse_dict d result {}for key in d for val in d[key] result[val] result.get val tuple + key return result
def delete_manifestation node_state manifestation dataset_id manifestation.dataset.dataset_idnode_state node_state.transform ['manifestations' dataset_id] discard node_state node_state.transform ['paths' dataset_id] discard node_state node_state.transform ['devices' UUID dataset_id ] discard return node_state
def human_size_to_bytes human_size size_exp_map {'K' 1 'M' 2 'G' 3 'T' 4 'P' 5}human_size_str str human_size match re.match '^ \\d+ [KMGTP] ?$' human_size_str if not match raise ValueError 'Sizemustbealldigits withanoptionalunittype K M G T orP ' size_num int match.group 1 unit_multiplier 1024 ** size_exp_map.get match.group 2 0 return size_num * unit_multiplier
def PrintFeed feed for entry in feed.entry PrintResource entry
def consecutive l fn it iter l ll []try while True x it.next if fn x ll.append x else if ll yield ll ll [] yield [x] except StopIteration if ll yield ll
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def render_alert content alert_type None dismissable True button u''if not alert_type alert_type u'info'css_classes [u'alert' u'alert-' + text_value alert_type ]if dismissable css_classes.append u'alert-dismissable' button u'<buttontype "button"class "close"' + u'data-dismiss "alert"aria-hidden "true">&times;</button>' button_placeholder u'__BUTTON__'return mark_safe render_tag u'div' attrs {u'class' u''.join css_classes } content button_placeholder + text_value content .replace button_placeholder button
def pycodestylemod_update_margin_line_length new_margin_line pycodestylemod.MAX_LINE_LENGTH new_margin_line
def occupation request pk occupation get_object_or_404 Occupation pk pk return HttpResponse 'Occupation %s' % occupation
def evdump app None out sys.stdout app app_or_default app dumper Dumper out out dumper.say u'->evdump startingcapture...' conn app.connection_for_read .clone def _error_handler exc interval dumper.say CONNECTION_ERROR % conn.as_uri exc humanize_seconds interval u'in' u'' while 1 try conn.ensure_connection _error_handler recv app.events.Receiver conn handlers {u'*' dumper.on_event} recv.capture except KeyboardInterrupt SystemExit return conn and conn.close except conn.connection_errors + conn.channel_errors dumper.say u'->Connectionlost attemptingreconnect'
def libvlc_video_get_cursor p_mi num f _Cfunctions.get 'libvlc_video_get_cursor' None or _Cfunction 'libvlc_video_get_cursor' 1 1 2 2 None ctypes.c_int MediaPlayer ctypes.c_uint ctypes.POINTER ctypes.c_int ctypes.POINTER ctypes.c_int return f p_mi num
def _apply_global_addr_ssl addr_to_ssl parsed_server for addr in parsed_server['addrs'] addr.ssl addr_to_ssl[addr.normalized_tuple ]if addr.ssl parsed_server['ssl'] True
def _get_device devnum 0 if not _custack _custack.push get_gpu devnum return _custack.top
def is_ambiguous at if isinstance at datetime return Falsereturn any getattr at attr is None for attr in adatetime.units
@login_required@require_POSTdef join_contributors request next get_next_url request or reverse 'home' group Group.objects.get name 'Contributors' request.user.groups.add group messages.add_message request messages.SUCCESS _ 'YouarenowpartoftheContributorsgroup!' return HttpResponseRedirect next
def dmp_gcdex f g u K if not u return dup_gcdex f g K else raise MultivariatePolynomialError f g
def _zipf_rv_below gamma xmin threshold result nx.utils.zipf_rv gamma xmin while result > threshold result nx.utils.zipf_rv gamma xmin return result
def test_dcae ae Autoencoder 5 7 act_enc 'tanh' act_dec 'cos' tied_weights True model DeepComposedAutoencoder [ae] model._ensure_extensions data np.random.randn 10 5 .astype config.floatX model.perform data
def get_field_precision df doc None currency None from frappe.utils import get_number_format_infoif cint df.precision precision cint df.precision elif df.fieldtype u'Currency' number_format Noneif not currency and doc currency get_field_currency df doc if not currency currency frappe.db.get_default u'currency' if currency number_format frappe.db.get_value u'Currency' currency u'number_format' cache True if not number_format number_format frappe.db.get_default u'number_format' or u'# ###.##' decimal_str comma_str precision get_number_format_info number_format else precision cint frappe.db.get_default u'float_precision' or 3 return precision
def monkeypatch_method cls def decorator func setattr cls func.__name__ func return funcreturn decorator
def enabled name **kwargs ret {'name' name 'result' True 'changes' {} 'comment' []}current_schedule __salt__['schedule.list'] show_all True return_yaml False if name in current_schedule if 'test' in __opts__ and __opts__['test'] kwargs['test'] Trueresult __salt__['schedule.enable_job'] name **kwargs ret['comment'].append result['comment'] else result __salt__['schedule.enable_job'] name **kwargs if not result['result'] ret['result'] result['result']ret['comment'] result['comment']return retelse ret['comment'].append 'Enabledjob{0}fromschedule'.format name else ret['comment'].append 'Job{0}notpresentinschedule'.format name ret['comment'] '\n'.join ret['comment'] return ret
def key_pair_get_all_by_user context user_id return IMPL.key_pair_get_all_by_user context user_id
def is_integer_like val try int val return Trueexcept TypeError ValueError AttributeError return False
def system_data if sys.platform.startswith 'linux' path '/usr/share/qutebrowser'if not os.path.exists path path data else path data return path
def run_with_reloader main_func extra_files None interval 1 import signalsignal.signal signal.SIGTERM lambda *args sys.exit 0 if os.environ.get 'WERKZEUG_RUN_MAIN' 'true' thread.start_new_thread main_func try reloader_loop extra_files interval except KeyboardInterrupt returntry sys.exit restart_with_reloader except KeyboardInterrupt pass
def _normalize_ids arg atoms set IdType if not arg return if arg.__class__ in atoms return arg return tuple arg
def _strip_uri repo splits repo.split for idx in range len splits if any splits[idx].startswith x for x in 'http //' 'https //' 'ftp //' splits[idx] splits[idx].rstrip '/' return ''.join splits
def sub_environment env os.environ.copy env['LANG'] 'C'return env
def merge_source_requirements sources projects set merged_requirements []for infile_path in locate_file p must_exist True for p in sources for req in load_requirements infile_path if req.req if req.name in projects continueprojects.add req.name merged_requirements.append req elif req.link merged_requirements.append req else raise RuntimeError 'Unexpectedrequirement{0}'.format req return merged_requirements
def get_pending_servermanager vname 'CurrentRebootAttempts'key 'SOFTWARE\\Microsoft\\ServerManager'reg_ret __salt__['reg.read_value'] 'HKLM' key vname if reg_ret['success'] log.debug 'Foundkey %s' key try if int reg_ret['vdata'] > 0 return Trueexcept ValueError passelse log.debug 'Unabletoaccesskey %s' key return False
def println text *colors sys.stdout.write sprint text *colors + '\n'
def submit_row context opts context['opts']change context['change']is_popup context['is_popup']save_as context['save_as']return {'onclick_attrib' opts.get_ordered_objects and change and 'onclick "submitOrderForm ;"' or '' 'show_delete_link' not is_popup and context['has_delete_permission'] and change or context['show_delete'] 'show_save_as_new' not is_popup and change and save_as 'show_save_and_add_another' context['has_add_permission'] and not is_popup and not save_as or context['add'] 'show_save_and_continue' not is_popup and context['has_change_permission'] 'is_popup' is_popup 'show_save' True}
def squared_norm x x _ravel x return np.dot x x
def _find_git_files dirname '' git_dir None file_list []if git_dir is None git_dir pbr.git._run_git_functions if git_dir file_list pbr.git._run_git_command ['ls-files' '-z'] git_dir file_list + pbr.git._run_git_command ['submodule' 'foreach' '--quiet' 'ls-files' '-z'] git_dir file_list file_list.split '\x00'.decode 'utf-8' submodules _get_submodules git_dir return [f for f in file_list if f and f not in submodules ]
def build_property_filter_spec client_factory property_specs object_specs property_filter_spec client_factory.create 'ns0 PropertyFilterSpec' property_filter_spec.propSet property_specsproperty_filter_spec.objectSet object_specsreturn property_filter_spec
def jsonpify func *args **kwargs data func *args **kwargs return to_jsonp data
def find_packages where '.' exclude out []stack [ convert_path where '' ]while stack where prefix stack.pop 0 for name in os.listdir where fn os.path.join where name if '.' not in name and os.path.isdir fn and os.path.isfile os.path.join fn '__init__.py' out.append prefix + name stack.append fn prefix + name + '.' for pat in list exclude + ['ez_setup' 'distribute_setup'] from fnmatch import fnmatchcaseout [item for item in out if not fnmatchcase item pat ]return out
def current_process return _current_process
def publicize_collection committer_id collection_id _publicize_activity committer_id collection_id feconf.ACTIVITY_TYPE_COLLECTION
def int2str64 number if not type number is types.LongType or type number is types.IntType raise TypeError 'Youmustpassalongoranint' string ''while number > 0 string '%s%s' % to64 number & 63 string number / 64return string
def get_token_url course_id return reverse 'get_token' kwargs {'course_id' unicode course_id }
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def build_kwargs registry_id if not registry_id return dict else return dict registryId registry_id
def detrend_pcoa input_fp map_fp None gradient_variable None suppress_prerotate False output_dir '.' HALT_EXEC False dt Detrender HALT_EXEC HALT_EXEC if map_fp is not None dt.Parameters['-m'].on map_fp if gradient_variable is not None dt.Parameters['-c'].on gradient_variable if suppress_prerotate dt.Parameters['-r'].on dt.Parameters['-o'].on output_dir app_result dt input_fp return app_result
def text_repr value try return pydoc.text.repr value except KeyboardInterrupt raiseexcept try return repr value except KeyboardInterrupt raiseexcept try name getattr value '__name__' None if name return text_repr name klass getattr value '__class__' None if klass return '%sinstance' % text_repr klass except KeyboardInterrupt raiseexcept return 'UNRECOVERABLEREPRFAILURE'
def SegmentCollection mode 'agg-fast' *args **kwargs if mode 'raw' return RawSegmentCollection *args **kwargs return AggSegmentCollection *args **kwargs
def dup_inflate f m K if m < 0 raise IndexError "'m'mustbepositive got%s" % m if m 1 or not f return fresult [f[0]]for coeff in f[1 ] result.extend [K.zero] * m - 1 result.append coeff return result
@validation_taskdef validate_file_path path hash_ listed True is_webextension False **kw if is_webextension return run_addons_linter path listed listed return run_validator path listed listed
def decodeerror arguments errn arguments['errn']err_a1 errnif 'errs' in arguments err_a2 arguments['errs']else err_a2 MacOS.GetErrorString errn if 'erob' in arguments err_a3 arguments['erob']else err_a3 Nonereturn err_a1 err_a2 err_a3
def _expect_extra expected present exc_unexpected exc_missing exc_args if present if not expected raise exc_unexpected *exc_args elif expected and expected is not Argument.ignore raise exc_missing *exc_args
def skipIf condition reason if condition return skip reason return lambda obj obj
def render_purchase_form_html cart callback_url None extra_data None return render_to_string 'shoppingcart/cybersource_form.html' {'action' get_purchase_endpoint 'params' get_signed_purchase_params cart callback_url callback_url extra_data extra_data }
def nop name **kwargs return succeed_without_changes name
def is_in_grace_period get_installation_key installation_time PersistentCacheEntry.objects.get **INSTALLATION_KEY_KWARGS .timereturn now - installation_time .total_seconds < 60 * 60 * 24
def p_conditional_expression_2 t pass
@with_config DEBUG True ASSETS_DEBUG True def test_unmergable b Bundle 's1' 's2' Bundle 's3' debug False filters css output 'bar' output 'foo' filters js jl bundle_to_joblist b assert len jl 3 assert 's1' in jl and 's2' in jl assert jl['bar'][0][0] [css] assert 's3' in jl['bar'][0][1] assert_raises BundleError bundle_to_joblist Bundle 's1' Bundle 's2' debug False output 'foo'
def datestr2num d if cbook.is_string_like d dt dateutil.parser.parse d return date2num dt else return date2num [dateutil.parser.parse s for s in d]
def get_device_languages hub_handle device_port buf None buf alloc_descriptor_buf buf def initbuf b p cast b PUSB_DESCRIPTOR_REQUEST .contentsp.ConnectionIndex device_portsp p.SetupPacket sp.bmRequest sp.bRequest 128 USB_REQUEST_GET_DESCRIPTOR sp.wValue[1] USB_STRING_DESCRIPTOR_TYPEsp.wLength MAXIMUM_USB_STRING_LENGTH + 2 buf bytes_returned device_io_control hub_handle IOCTL_USB_GET_DESCRIPTOR_FROM_NODE_CONNECTION buf buf initbuf data cast buf PUSB_DESCRIPTOR_REQUEST .contents.Data sz dtype data.bLength data.bType if dtype ! 3 raise WindowsError u'Invaliddatatypeforstringdescriptor 0x%x' % dtype data cast data.String POINTER USHORT * sz // 2 return buf filter None data.contents
def adb argv *a **kw if isinstance argv str unicode argv [argv]log.debug '$' + ''.join context.adb + argv if argv[0] 'shell' return process argv[1 ] *a **kw .recvall return tubes.process.process context.adb + argv *a **kw .recvall
def regex site reg_ex str site for base in reg_ex if base in 'A' 'T' 'C' 'G' 'a' 'c' 'g' 't' passif base in 'N' 'n' reg_ex '.'.join reg_ex.split 'N' reg_ex '.'.join reg_ex.split 'n' if base in 'R' 'Y' 'W' 'M' 'S' 'K' 'H' 'D' 'B' 'V' expand '[' + amb_dna[base.upper ] + ']' reg_ex expand.join reg_ex.split base return reg_ex
def resolve_embedded_documents document resource embedded_fields for field in sorted embedded_fields key lambda a a.count '.' data_relation field_definition resource field ['data_relation']getter lambda ref embedded_document ref data_relation field fields_chain field.split '.' last_field fields_chain[ -1 ]for subdocument in subdocuments fields_chain[ -1 ] resource document if last_field not in subdocument continueif isinstance subdocument[last_field] list subdocument[last_field] list map getter subdocument[last_field] else subdocument[last_field] getter subdocument[last_field]
def is_jail name jails list_jails for jail in jails if jail.split [0] name return Truereturn False
def test_io_w tempdir _TempDir stc _fake_stc n_time 1 w_fname op.join tempdir 'fake' stc.save w_fname ftype 'w' src read_source_estimate w_fname src.save op.join tempdir 'tmp' ftype 'w' src2 read_source_estimate op.join tempdir 'tmp-lh.w' assert_array_almost_equal src.data src2.data assert_array_almost_equal src.lh_vertno src2.lh_vertno assert_array_almost_equal src.rh_vertno src2.rh_vertno
def _cluster_indices_to_mask components n_tot for ci c in enumerate components components[ci] np.zeros n_tot dtype bool components[ci][c] Truereturn components
def in_range_list num range_list return num int num and within_range_list num range_list
def traverse_imports names pending [names]while pending node pending.pop if node.type token.NAME yield node.value elif node.type syms.dotted_name yield ''.join [ch.value for ch in node.children] elif node.type syms.dotted_as_name pending.append node.children[0] elif node.type syms.dotted_as_names pending.extend node.children[ -2 ] else raise AssertionError 'unkownnodetype'
def _arcball xy wh x y xy w h whr w + h / 2.0 x y - 2.0 * x - w / r 2.0 * y - h / r h np.sqrt x * x + y * y return 0.0 x / h y / h 0.0 if h > 1.0 else 0.0 x y np.sqrt 1.0 - h * h
def convert in_file in_format out_file out_format in_kwargs None out_kwargs None if in_kwargs is None in_kwargs {}if out_kwargs is None out_kwargs {}qresults parse in_file in_format **in_kwargs return write qresults out_file out_format **out_kwargs
def _is_inherited_from_object cls op if PYVERSION > 3 object_op getattr object op cls_op getattr cls op return object_op is cls_op else return op not in dir cls
def iterfind data string offset data.find string 0 while offset > 0 yield offset offset data.find string offset + len string
def test_senn_bad_ratio ratio -1.0 smote SMOTEENN ratio ratio assert_raises ValueError smote.fit X Y ratio 100.0smote SMOTEENN ratio ratio assert_raises ValueError smote.fit X Y ratio 'rnd'smote SMOTEENN ratio ratio assert_raises ValueError smote.fit X Y ratio [0.5 0.5]smote SMOTEENN ratio ratio assert_raises ValueError smote.fit X Y
def _try_weakref arg remove_callback try arg weakref.ref arg remove_callback except TypeError passreturn arg
def bench_R3 f x + y + z a [bool f f for _ in range 10 ]
def nowdate return now_datetime .strftime DATE_FORMAT
def _href collection href return '%s%s' % collection.configuration.get 'server' 'base_prefix' href.lstrip '/'
def _api_disconnect name output kwargs Downloader.do.disconnect return report output
def is_float_list value min None max None return [is_float mem for mem in is_list value min max ]
def task_project if auth.permission.format ! 's3json' return ''def prep r if r.method ! 'options' return Falsereturn Trues3.prep prepreturn s3_rest_controller
def _view_text content total limit txt []for i in netlib.utils.cleanBin content .splitlines txt.append urwid.Text 'text' i wrap 'any' trailer total txt limit return txt
def ensure_list obj return obj if is_nonstring_iterable obj else [obj]
def resolve1 x while isinstance x PDFObjRef x x.resolve return x
def deepsize obj max_depth 4 def _recurse o dct depth if max_depth > 0 and depth > max_depth returnfor ref in get_referents o idr id ref if not idr in dct dct[idr] ref getsizeof ref default 0 _recurse ref dct depth + 1 sizedict {}_recurse obj sizedict 0 size getsizeof obj + sum [p[1] for p in sizedict.values ] return size
def test_byte_order_median a np.arange 9 dtype '<f4' .reshape 3 3 ref ndimage.filters.median_filter a 3 3 b np.arange 9 dtype '>f4' .reshape 3 3 t ndimage.filters.median_filter b 3 3 assert_array_almost_equal ref t
def get_tax_class_proportions lines if not lines return []zero lines[0].price.new 0 total_by_tax_class defaultdict lambda zero total zerofor line in lines total_by_tax_class[line.tax_class] + line.pricetotal + line.priceif not total return []return [ tax_class tax_class_total / total for tax_class tax_class_total in total_by_tax_class.items ]
def split_path path path path.lstrip '/' first _ rest path.partition '/' lang find_supported [ first 1.0 ] if lang return lang rest else return '' path
def _whctrs anchor w anchor[2] - anchor[0] + 1 h anchor[3] - anchor[1] + 1 x_ctr anchor[0] + 0.5 * w - 1 y_ctr anchor[1] + 0.5 * h - 1 return w h x_ctr y_ctr
def cfg2dict cfg d {}for section in cfg.sections d[section] dict cfg.items section return d
def _find_statement_by_line node line if isinstance node nodes.Class nodes.Function node_line node.fromlinenoelse node_line node.linenoif node_line line return nodefor child in node.get_children result _find_statement_by_line child line if result return resultreturn None
def ensure_tables global tablesif tables is None import tables
def jsonrpc_result id result return {'jsonrpc' '2.0' 'result' result 'id' id}
def AddBatchJob client batch_job_service client.GetService 'BatchJobService' version 'v201605' batch_job_operations [{'operand' {} 'operator' 'ADD'}]return batch_job_service.mutate batch_job_operations ['value'][0]
def FakeUTime path times raise OSError errno.EPERM 'Operationnotpermitted' path
@constructordef argmin x axis None keepdims False x as_tensor_variable x str_x_type str x.dtype if str_x_type.startswith 'float' or str_x_type in int_dtypes return argmax - x axis axis keepdims keepdims else raise NotImplementedError
def reply_all t Twitter auth authen try id int g['stuff'].split [0] except printNicely red "SorryIcan'tunderstand." returntid c['tweet_dict'][id]original_tweet t.statuses.show id tid text original_tweet['text']nick_ary [original_tweet['user']['screen_name']]for user in list original_tweet['entities']['user_mentions'] if user['screen_name'] not in nick_ary and user['screen_name'] ! g['original_name'] nick_ary.append user['screen_name'] status ''.join g['stuff'].split [1 ] status ''.join [ '@' + nick for nick in nick_ary] + '' + str2u status t.statuses.update status status in_reply_to_status_id tid
def frequencyRedefinition CellChannelDescription_presence 0 a TpPd pd 6 b MessageType mesType 20 c ChannelDescription d MobileAllocation e StartingTime packet a / b / c / d / e if CellChannelDescription_presence is 1 f CellChannelDescriptionHdr ieiCCD 98 eightBitCCD 0 packet packet / f return packet
def transfield_changed field initial data initial [ k v.localized_string for k v in initial.iteritems if '%s_' % field in k and v is not None ]data [ '%s_%s' % field k v for k v in data[field].iteritems if k ! 'init' ]return set initial ! set data
def _filter_entrance_exam_grader graders if is_entrance_exams_enabled graders [grader for grader in graders if grader.get 'type' ! u'EntranceExam' ]return graders
def _reset_syslog_config_params host username password cmd resets valid_resets protocol None port None esxi_host None ret_dict {}all_success Trueif not isinstance resets list resets [resets]for reset_param in resets if reset_param in valid_resets ret salt.utils.vmware.esxcli host username password cmd + reset_param protocol protocol port port esxi_host esxi_host ret_dict[reset_param] {}ret_dict[reset_param]['success'] ret['retcode'] 0 if ret['retcode'] ! 0 all_success Falseret_dict[reset_param]['message'] ret['stdout']else all_success Falseret_dict[reset_param] {}ret_dict[reset_param]['success'] Falseret_dict[reset_param]['message'] 'Invalidsyslogconfigurationparameter'ret_dict['success'] all_successreturn ret_dict
def _nova_to_osvif_ips ips return objects.fixed_ip.FixedIPList objects [_nova_to_osvif_ip ip for ip in ips]
def add module check parse_check module service parse_service module if not service and not check module.fail_json msg 'anameandportarerequiredtoregisteraservice' if service if check service.add_check check add_service module service elif check add_check module check
def umount module dest umount_bin module.get_bin_path 'umount' required True cmd [umount_bin dest] rc out err module.run_command cmd if rc 0 return 0 '' else return rc out + err
def addXIntersectionIndexesFromLoops frontOverWidth loops solidIndex xIntersectionIndexLists width yList for loop in loops addXIntersectionIndexesFromLoop frontOverWidth loop solidIndex xIntersectionIndexLists width yList
@util.positional 1 def service_mappings services registry_path DEFAULT_REGISTRY_PATH if isinstance services dict services services.iteritems final_mapping []paths set registry_map {} if registry_path else None for service_path service_factory in services try service_class service_factory.service_classexcept AttributeError service_class service_factoryif service_path not in paths paths.add service_path else raise remote.ServiceConfigurationError 'Path%risalreadydefinedinservicemapping' % service_path.encode 'utf-8' if registry_map is not None registry_map[service_path] service_classfinal_mapping.append service_mapping service_factory service_path if registry_map is not None final_mapping.append service_mapping registry.RegistryService.new_factory registry_map registry_path return wsgi_util.first_found final_mapping
def messages request return {'messages' get_messages request }
@route bp '/' def whoami return current_user._get_current_object
def get_user_id username rv query_db 'selectuser_idfromuserwhereusername ?' [username] one True return rv[0] if rv else None
def _validate_usecols_arg usecols msg "'usecols'musteitherbeallstrings allunicode allintegersoracallable"if usecols is not None if callable usecols return usecols None usecols_dtype lib.infer_dtype usecols if usecols_dtype not in 'empty' 'integer' 'string' 'unicode' raise ValueError msg return set usecols usecols_dtype return usecols None
def getRepositoryCommand directory try GitCommand.ensureIsWorkingDirectory directory return GitCommandexcept NotWorkingDirectory OSError passraise NotWorkingDirectory 'NosupportedVCScanbefoundin%s' % directory.path
def mmap_read f sz 0 close True return _mmap_do f sz mmap.MAP_PRIVATE mmap.PROT_READ close
def gather_configuration acquire_settings log_printer arg_list None arg_parser None arg_list sys.argv[1 ] if arg_list is None else arg_list sections targets load_configuration arg_list log_printer arg_parser local_bears global_bears fill_settings sections acquire_settings log_printer save_sections sections warn_nonexistent_targets targets sections log_printer return sections local_bears global_bears targets
def test_generate_import_code tpot_obj TPOTClassifier pipeline creator.Individual.from_string 'DecisionTreeClassifier SelectKBest input_matrix 7 0.5 ' tpot_obj._pset expected_code "importnumpyasnp\n\nfromsklearn.ensembleimportVotingClassifier\nfromsklearn.feature_selectionimportSelectKBest f_classif\nfromsklearn.model_selectionimporttrain_test_split\nfromsklearn.pipelineimportmake_pipeline make_union\nfromsklearn.preprocessingimportFunctionTransformer\nfromsklearn.treeimportDecisionTreeClassifier\n\n#NOTE Makesurethattheclassislabeled'class'inthedatafile\ntpot_data np.recfromcsv 'PATH/TO/DATA/FILE' delimiter 'COLUMN_SEPARATOR' dtype np.float64 \nfeatures np.delete tpot_data.view np.float64 .reshape tpot_data.size -1 tpot_data.dtype.names.index 'class' axis 1 \ntraining_features testing_features training_classes testing_classes \\\ntrain_test_split features tpot_data['class'] random_state 42 \n"assert expected_code generate_import_code pipeline
def classname object modname name object.__name__if object.__module__ ! modname name object.__module__ + '.' + name return name
def merge dict1 dict2 for key val2 in dict2.items if val2 is not None val1 dict1.get key if isinstance val2 dict if val1 is None val1 {}if isinstance val1 Alias val1 val1 val2 elif isinstance val1 tuple alias others val1others others.copy merge others val2 val1 alias others else val1 val1.copy merge val1 val2 else val1 val2dict1[key] val1
def sorted_allowed_list allowed_list allowed_by_protocol sorted allowed_list key lambda x x['IPProtocol'] return sorted allowed_by_protocol key lambda y y['ports'].sort
def get_single_job request jobid return Job.from_id jt request.jt jobid jobid
def now return datetime.datetime.now TimeZoneInfo.local
def get_dependencies return config.check_driver_dependencies __virtualname__ {'libcloud' HAS_LIBS}
def jscode expr assign_to None **settings return JavascriptCodePrinter settings .doprint expr assign_to
def number_of_nonisomorphic_trees order return sum 1 for _ in nonisomorphic_trees order
def make_sparse_spd_matrix dim 1 alpha 0.95 norm_diag False smallest_coef 0.1 largest_coef 0.9 random_state None random_state check_random_state random_state chol - np.eye dim aux random_state.rand dim dim aux[ aux < alpha ] 0aux[ aux > alpha ] smallest_coef + largest_coef - smallest_coef * random_state.rand np.sum aux > alpha aux np.tril aux k -1 permutation random_state.permutation dim aux aux[permutation].T[permutation]chol + auxprec np.dot chol.T chol if norm_diag d np.diag prec .reshape 1 prec.shape[0] d 1.0 / np.sqrt d prec * dprec * d.Treturn prec
@inspect_command variadic u'ids' signature u'[id1[id2[...[idN]]]]' def query_task state ids **kwargs return {req.id _state_of_task req req.info for req in _find_requests_by_id maybe_list ids }
def _impute df observations censorship transform_in transform_out uncensored_mask df[censorship] False censored_mask df[censorship] True fit_params stats.linregress df['Zprelim'][uncensored_mask] transform_in df[observations][uncensored_mask] slope intercept fit_params[ 2]df.loc[ 'estimated'] transform_out slope * df['Zprelim'][censored_mask] + intercept df.loc[ 'final'] numpy.where df[censorship] df['estimated'] df[observations] return df
def _settings_closed events params params['fig_options'] None
def config_to_kodi MASTER_SETTINGS config extracted_settings_for_kodi {}for setting protocols in MASTER_SETTINGS.iteritems value general_config_get config **protocols extracted_settings_for_kodi[setting] valuereturn extracted_settings_for_kodi
def _generate_reset_key user return '{0}_reset_key'.format user.name .lower
@deprecated.Callable deprecation u'4.0' removal u'5.0' alternative u'Pleaseusecelery.app.backends.by_url' def get_backend_by_url backend None loader None return _backends.by_url backend backend loader loader
def _NewDocumentFromPb doc_pb lang Noneif doc_pb.has_language lang _DecodeUTF8 doc_pb.language return Document doc_id _DecodeUTF8 doc_pb.id fields _NewFieldsFromPb doc_pb.field_list language lang rank doc_pb.order_id
@register.filter name 'ip_str_to_list' def ip_str_to_list ip_str return ip_str.split ' '
def _immediately_before node try pos node.treeposition tree node.root except AttributeError return []idx len pos - 1 while 0 < idx and pos[idx] 0 idx - 1if idx < 0 return []pos list pos[ idx + 1 ] pos[ -1 ] - 1before tree[pos]return [before] + _rightmost_descendants before
def __float value valid _value False value try _value float value valid Trueexcept ValueError passreturn valid _value 'float'
def searchElementById node Id tagname nodes node.getElementsByTagName tagname for node in nodes an node.getAttributeNode 'id' if an and an.nodeValue Id return node
def rand_url randbits str random.randint 1 2147483647 return 'https //url-' + randbits + '.com'
def set_version_db apps schema_editor db_alias schema_editor.connection.aliasVersion apps.get_model u'reversion' u'Version' content_types Version.objects.using db_alias .order_by .values_list u'content_type_id' u'content_type__app_label' u'content_type__model' .distinct model_dbs defaultdict list for content_type_id app_label model_name in content_types try model live_apps.get_model app_label model_name except LookupError db u'default'else db router.db_for_write model model_dbs[db].append content_type_id if DEFAULT_DB_ALIAS in model_dbs and len model_dbs 1 Version.objects.using db_alias .update db DEFAULT_DB_ALIAS else for db content_type_ids in model_dbs.items Version.objects.using db_alias .filter content_type__in content_type_ids .update db db
def _auth profile None if profile credentials __salt__['config.option'] profile user credentials['keystone.user']password credentials['keystone.password']tenant credentials['keystone.tenant']auth_url credentials['keystone.auth_url']region_name credentials.get 'keystone.region_name' None service_type credentials['keystone.service_type']else user __salt__['config.option'] 'keystone.user' password __salt__['config.option'] 'keystone.password' tenant __salt__['config.option'] 'keystone.tenant' auth_url __salt__['config.option'] 'keystone.auth_url' region_name __salt__['config.option'] 'keystone.region_name' service_type __salt__['config.option'] 'keystone.service_type' kwargs {'username' user 'password' password 'tenant_name' tenant 'auth_url' auth_url 'region_name' region_name 'service_type' service_type}return suoneu.SaltNeutron **kwargs
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def volume_type_extra_specs_delete context volume_type_id key return IMPL.volume_type_extra_specs_delete context volume_type_id key
def test_chelsea data.chelsea
@apply_to_text_filedef typogrify_sans_widont data if typo is None req_missing ['typogrify'] 'usethetypogrify_sans_widontfilter' data _normalize_html data data typo.amp data data typo.smartypants data data typo.initial_quotes data return data
def picknthweekday year month dayofweek hour minute whichweek first datetime.datetime year month 1 hour minute weekdayone first.replace day dayofweek - first.isoweekday % 7 + 1 for n in xrange whichweek dt weekdayone + whichweek - n * ONEWEEK if dt.month month return dt
def resize_image data sz 256 256 img_data str data im Image.open StringIO img_data if im.mode ! 'RGB' im im.convert 'RGB' imr im.resize sz resample Image.BILINEAR fh_im StringIO imr.save fh_im format 'JPEG' fh_im.seek 0 return bytearray fh_im.read
def add_namespace_to_cmd cmd namespace None return ['ip' 'netns' 'exec' namespace] + cmd if namespace else cmd
def app_install app fobj request filename overwrite None did_mkdir Falseif filename[ -4 ] '.w2p' extension 'w2p'elif filename[ -7 ] '.tar.gz' extension 'tar.gz'else extension 'tar'upname apath '../deposit/%s.%s' % app extension request try write_file upname fobj.read 'wb' path apath app request if not overwrite os.mkdir path did_mkdir Truew2p_unpack upname path if extension ! 'tar' os.unlink upname fix_newlines path return upnameexcept Exception if did_mkdir rmtree path return False
def asynchronous function *args **kwargs return AsynchronousRequest function *args **kwargs
def launch_local_console input_stream console_log_path pattern_paths None r w os.pipe local_script_path os.path.join MONITORDIR 'console.py' console_cmd [sys.executable local_script_path]if pattern_paths console_cmd.append '--pattern_paths %s' % ' '.join pattern_paths console_cmd + [console_log_path str w ]warning_stream os.fdopen r 'r' 0 devnull_w open os.devnull 'w' console_proc subprocess.Popen console_cmd stdin input_stream stdout devnull_w stderr devnull_w os.close w return console_proc warning_stream
def select_negation cache selector exclude frozenset cache.iterparsedselector selector.subselector for item in cache.iterparsedselector selector.selector if item not in exclude yield item
def _inv_impl expr op **kw if hasattr expr 'negation_clause' return expr.negation_clauseelse return expr._negate
def getChildElementsByTagName self tagName result []for child in self.childNodes if isinstance child Element if child.tagName tagName result.append child return result
def title_to_url title max_length 50 title _force_unicode title title rx_whitespace.sub '_' title title rx_notsafe.sub '' title title rx_underscore.sub '_' title title title.strip '_' title title.lower if len title > max_length title title[ max_length]last_word title.rfind '_' if last_word > 0 title title[ last_word]return title or '_'
def vm_disk_save name kwargs None call None if call ! 'action' raise SaltCloudSystemExit 'Thevm_disk_saveactionmustbecalledwith-aor--action.' if kwargs is None kwargs {}disk_id kwargs.get 'disk_id' None image_name kwargs.get 'image_name' None image_type kwargs.get 'image_type' '' snapshot_id int kwargs.get 'snapshot_id' '-1' if disk_id is None or image_name is None raise SaltCloudSystemExit "Thevm_disk_savefunctionrequiresa'disk_id'andan'image_name'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] vm_id int get_vm_id kwargs {'name' name} response server.one.vm.disksave auth vm_id int disk_id image_name image_type snapshot_id data {'action' 'vm.disksave' 'saved' response[0] 'image_id' response[1] 'error_code' response[2]}return data
def getRadioPluginsAddPluginGroupFrame directoryPath importantFileNames names repository repository.pluginGroupFrame settings.PluginGroupFrame radioPlugins []for name in names radioPlugin settings.RadioPlugin .getFromRadio name in importantFileNames repository.pluginGroupFrame.latentStringVar name repository name importantFileNames[0] radioPlugin.updateFunction repository.pluginGroupFrame.updateradioPlugins.append radioPlugin defaultRadioButton settings.getSelectedRadioPlugin importantFileNames + [radioPlugins[0].name] radioPlugins repository.pluginGroupFrame.getFromPath defaultRadioButton directoryPath repository return radioPlugins
def _gen_unzip it elem_len elem next it first_elem_len len elem if elem_len is not None and elem_len ! first_elem_len raise ValueError 'elementatindex0waslength%d expected%d' % first_elem_len elem_len else elem_len first_elem_len yield elem for n elem in enumerate it 1 if len elem ! elem_len raise ValueError 'elementatindex%dwaslength%d expected%d' % n len elem elem_len yield elem
def DefaultController name controllers DefaultControllers **kwargs controller findController controllers if not controller raise Exception 'CouldnotfindadefaultOpenFlowcontroller' return controller name **kwargs
def sentiment_comparison statement other_statement from nltk.sentiment.vader import SentimentIntensityAnalyzersentiment_analyzer SentimentIntensityAnalyzer statement_polarity sentiment_analyzer.polarity_scores statement.text.lower statement2_polarity sentiment_analyzer.polarity_scores other_statement.text.lower statement_greatest_polarity 'neu'statement_greatest_score -1 for polarity in sorted statement_polarity if statement_polarity[polarity] > statement_greatest_score statement_greatest_polarity polaritystatement_greatest_score statement_polarity[polarity]statement2_greatest_polarity 'neu'statement2_greatest_score -1 for polarity in sorted statement2_polarity if statement2_polarity[polarity] > statement2_greatest_score statement2_greatest_polarity polaritystatement2_greatest_score statement2_polarity[polarity]if statement_greatest_polarity ! statement2_greatest_polarity return 0values [statement_greatest_score statement2_greatest_score]difference max values - min values return 1.0 - difference
def basename path return os.path.basename path
def get_meta doctype cached True import frappe.model.metareturn frappe.model.meta.get_meta doctype cached cached
def remove_file filename if os.path.exists filename os.remove filename
def InitHttp api_endpoint None page_size None auth None connector http_connector.HttpConnector api_endpoint api_endpoint page_size page_size auth auth return GrrApi connector connector
def describe_nat_gateways nat_gateway_id None subnet_id None subnet_name None vpc_id None vpc_name None states 'pending' 'available' region None key None keyid None profile None return _find_nat_gateways nat_gateway_id nat_gateway_id subnet_id subnet_id subnet_name subnet_name vpc_id vpc_id vpc_name vpc_name states states region region key key keyid keyid profile profile
def attach_issue_custom_attributes queryset as_field 'issue_custom_attributes_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json custom_attributes_issuecustomattribute \nORDERBYcustom_attributes_issuecustomattribute.order\n \nFROMcustom_attributes_issuecustomattribute\nWHEREcustom_attributes_issuecustomattribute.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def load_train_file config_file_path environ None from pylearn2.config import yaml_parsesuffix_to_strip '.yaml'if config_file_path.endswith suffix_to_strip config_file_full_stem config_file_path[0 - len suffix_to_strip ]else config_file_full_stem config_file_pathos.environ['PYLEARN2_TRAIN_FILE_FULL_STEM'] config_file_full_stemdirectory config_file_path.split '/' [ -1 ]directory '/'.join directory if directory ! '' directory + '/'os.environ['PYLEARN2_TRAIN_DIR'] directoryos.environ['PYLEARN2_TRAIN_BASE_NAME'] config_file_path.split '/' [ -1 ]os.environ['PYLEARN2_TRAIN_FILE_STEM'] config_file_full_stem.split '/' [ -1 ]return yaml_parse.load_path config_file_path environ environ
def relink_or_drop_orphan_translationprojects apps schema_editor Project apps.get_model u'pootle_project.Project' TP apps.get_model u'pootle_translationproject.TranslationProject' for proj_key in set TP.objects.values_list u'project_id' flat True if not Project.objects.filter pk proj_key .exists for tp in TP.objects.filter project_id proj_key proj_code tp.pootle_path.split u'/' [2]projects Project.objects.filter code proj_code if projects.exists tp.project projects.first tp.save else tp.delete
@functools.lru_cache def get_default_timezone return pytz.timezone settings.TIME_ZONE
def resize_quota_delta context new_flavor old_flavor sense compare def _quota_delta resource return sense * new_flavor[resource] - old_flavor[resource] deltas {}if compare * _quota_delta 'vcpus' > 0 deltas['cores'] _quota_delta 'vcpus' if compare * _quota_delta 'memory_mb' > 0 deltas['ram'] _quota_delta 'memory_mb' return deltas
def will_it_float s try return float s except ValueError return s
@register.filter name 'display_list' is_safe True def display_list values display_limit if len values 1 display_string '%s' % values[0] elif len values < display_limit display_string ' '.join '%s' % value for value in values[ -1 ] display_string + 'and%s' % values[ -1 ] else display_string ' '.join '%s' % value for value in values[ display_limit] display_string + and_n_others values display_limit return display_string
@skip 'multiple_execute' def test_no_clr_attributes class x passfor stuff in [object int float bool str long complex dict set None NotImplemented Ellipsis type test_no_clr_attributes classmethod staticmethod frozenset property sys BaseException type zip slice buffer enumerate file range xrange type x type x ] for dir_stuff in dir stuff if dir_stuff[ 1].isalpha Assert dir_stuff[ 1].islower '%sshouldnotbeanattributeof%s' % dir_stuff str stuff
def deprecate func old new def f *args **kwargs warn_deprecate_obj old new return func *args **kwargs return f
def standard_b64decode s return b64decode s
def get_next_page_of_all_non_private_commits page_size feconf.COMMIT_LIST_PAGE_SIZE urlsafe_start_cursor None max_age None if max_age is not None and not isinstance max_age datetime.timedelta raise ValueError 'max_agemustbeadatetime.timedeltainstance.orNone.' results new_urlsafe_start_cursor more exp_models.ExplorationCommitLogEntryModel.get_all_non_private_commits page_size urlsafe_start_cursor max_age max_age return [exp_domain.ExplorationCommitLogEntry entry.created_on entry.last_updated entry.user_id entry.username entry.exploration_id entry.commit_type entry.commit_message entry.commit_cmds entry.version entry.post_commit_status entry.post_commit_community_owned entry.post_commit_is_private for entry in results] new_urlsafe_start_cursor more
def parse_reftuple lh_container rh_container refspec if refspec.startswith '+' force Truerefspec refspec[1 ]else force Falserefspec to_bytes refspec if ' ' in refspec lh rh refspec.split ' ' else lh rh refspecif lh '' lh Noneelse lh parse_ref lh_container lh if rh '' rh Noneelse try rh parse_ref rh_container rh except KeyError if not '/' in rh rh 'refs/heads/' + rh return lh rh force
def get_int_or_uuid value try uuid.UUID value return valueexcept ValueError AttributeError return int value
def _delete_users users return __salt__['users.delete_users'] users commit False
@receiver models.signals.post_save sender VerificationStatus @receiver models.signals.post_delete sender VerificationStatus def invalidate_verification_status_cache sender instance **kwargs cache_key VerificationStatus.cache_key_name instance.user.id unicode instance.checkpoint.course_id cache.delete cache_key
def lock hass entity_id None code None data {}if code data[ATTR_CODE] codeif entity_id data[ATTR_ENTITY_ID] entity_idhass.services.call DOMAIN SERVICE_LOCK data
def find_hg_tag path tags {}try client subprocess.Popen ['hg' 'cat' '-r' 'tip' '.hgtags'] stdout subprocess.PIPE cwd path for line in client.communicate [0].splitlines line line.strip if not line continue hash tag line.split tags[hash] tagexcept OSError returnclient subprocess.Popen ['hg' 'parent' '--template' '#node#'] stdout subprocess.PIPE cwd path tip client.communicate [0].strip tag tags.get tip if tag is not None return tagreturn tip
@memoize 'gold-goal' stale True def gold_goal_on date goal GoldRevenueGoalByDate.get date if not goal return 0return float goal
def addMethodNamesToDict classObj dict prefix baseClass None for base in classObj.__bases__ addMethodNamesToDict base dict prefix baseClass if baseClass is None or baseClass in classObj.__bases__ for name method in classObj.__dict__.items optName name[len prefix ]if type method is types.FunctionType and name[ len prefix ] prefix and len optName dict[optName] 1
def reinitLoggingDir if gLoggingInitialized and 'NTA_LOG_DIR' in os.environ makeDirectoryFromAbsolutePath os.path.dirname _genLoggingFilePath
def filter_hidden_settings conf def maybe_censor key value mask u'*' * 8 if isinstance value Mapping return filter_hidden_settings value if isinstance key string_t if HIDDEN_SETTINGS.search key return maskelif u'broker_url' in key.lower from kombu import Connectionreturn Connection value .as_uri mask mask elif u'backend' in key.lower return maybe_sanitize_url value mask mask return valuereturn {k maybe_censor k v for k v in items conf }
def test_nextitem_single hist monkeypatch hist.start 'f' monkeypatch.setattr hist._tmphist 'nextitem' lambda 'item' assert hist.nextitem 'item'
def _KindsListToTuple kinds_list return '' [{'kind_name' kind} for kind in sorted kinds_list ]
def _minpoly_from_dense minpoly ring minpoly_ ring.zerofor monom coeff in minpoly.terms minpoly_[monom] ring.domain coeff return minpoly_
def s_poly cp return lbp_sub lbp_mul_term cp[2] cp[1] lbp_mul_term cp[5] cp[4]
def _AuthFacebookOrGoogleUser tester action user_dict ident_dict device_dict user_cookie if device_dict is None url tester.GetUrl '/%s/%s' % action ident_dict['authority'].lower response _SendAuthRequest tester url 'GET' user_cookie user_cookie assert response.code 302 response.codeurl tester.GetUrl '/%s/%s?code code' % action ident_dict['authority'].lower response _SendAuthRequest tester url 'GET' user_cookie user_cookie assert response.code 302 response.codeassert response.headers['location'].startswith '/view' else if ident_dict['authority'] 'Facebook' url tester.GetUrl '/%s/facebook?access_token access_token' % action else url tester.GetUrl '/%s/google?refresh_token refresh_token' % action request_dict _CreateRegisterRequest device_dict response _SendAuthRequest tester url 'POST' user_cookie user_cookie request_dict request_dict return response
def g return 5
def fix_unicode_dict d new_dict {}for key value in d.items if isinstance value dict new_dict[key] fix_unicode_dict value elif isinstance value tuple new_dict[key] fix_unicode_array list value elif isinstance value list new_dict[key] fix_unicode_array value elif isinstance value str unicode new_dict[key] value.decode 'utf-8' 'ignore' else new_dict[key] valuereturn new_dict
def team return s3_rest_controller
def chunk_list ls items 8 itms []for i v in enumerate ls if i > items and i % items 0 yield itms itms [v]else itms.append v if itms yield itms
def trg_write uid res_type res_id cr return WorkflowService.new cr uid res_type res_id .write
def user_has_resource_api_permission user_db resource_api permission_type if not cfg.CONF.rbac.enable return Trueresolver resolvers.get_resolver_for_permission_type permission_type permission_type result resolver.user_has_resource_api_permission user_db user_db resource_api resource_api permission_type permission_type return result
def command_copy args sources args.sourcesdestpath args.destpathsource_files []for file_ in sources if '*' in file_ selected glob file_ source_files.extend selected elif os.path.isfile file_ source_files.append file_ if destpath.endswith '/' or os.path.isdir destpath or len sources > 1 destdir destpathelse assert len source_files 1 destdir os.path.dirname destpath if not os.path.isdir destdir sys.stdout.write 'copy Createdir%s\n' % destdir os.makedirs destdir for source in source_files destname os.path.join destdir os.path.basename source sys.stdout.write 'copy %s >%s\n' % source destname shutil.copy source destname return 0
@testing.requires_testing_data@requires_mnedef test_other_volume_source_spaces tempdir _TempDir temp_name op.join tempdir 'temp-src.fif' run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name '--mri' fname_mri] src read_source_spaces temp_name src_new setup_volume_source_space None pos 7.0 mri fname_mri subjects_dir subjects_dir _compare_source_spaces src src_new mode 'approx' assert_true 'volume shape' in repr src del srcdel src_newassert_raises ValueError setup_volume_source_space 'sample' temp_name pos 7.0 sphere [1.0 1.0] mri fname_mri subjects_dir subjects_dir run_subprocess ['mne_volume_source_space' '--grid' '7.0' '--src' temp_name] assert_raises ValueError read_source_spaces temp_name
def create_containers_and_parents container_dn import univention.admin.uexceptions as uexcpassert container_dn.startswith 'cn ' try parent ldap_dn_tree_parent container_dn obj umc_module_for_add 'container/cn' parent obj['name'] container_dn.split ' ' [0].split ' ' [1]obj['description'] 'containercreatedbyimport'except uexcp.ldapError create_containers_and_parents parent obj umc_module_for_add 'container/cn' parent obj['name'] container_dn.split ' ' [0].split ' ' [1]obj['description'] 'containercreatedbyimport'
def test_mkt_locale_not_in_django activate 'mn' en trans_real._translations['en-US']mn trans_real._translations['mn']assert en ! mn assert en._catalog ! mn._catalog
def delegates task_that_delegates if not hasattr task_that_delegates 'subtasks' raise AttributeError '%sneedstoimplementthemethod"subtasks"' % task_that_delegates @task._task_wraps task_that_delegates class Wrapped task_that_delegates def deps self return task.flatten self.requires + task.flatten [t.deps for t in task.flatten self.subtasks ] def run self for t in task.flatten self.subtasks t.run task_that_delegates.run self return Wrapped
def _convert_bin_to_numeric_type x dtype infer_dtype x if dtype 'timedelta' or dtype 'timedelta64' x to_timedelta x .view np.int64 elif dtype 'datetime' or dtype 'datetime64' x to_datetime x .view np.int64 return x
def wavefunction n x n x S n S x return exp n * I * x / sqrt 2 * pi
def _yield_all_steps emr_conn cluster_id *args **kwargs for resp in _repeat _patched_list_steps emr_conn cluster_id *args **kwargs for step in getattr resp 'steps' [] yield step
def setdefaultencoding encoding func getattr sys 'setdefaultencoding' None if func is None import gcimport typesfor obj in gc.get_objects if isinstance obj types.BuiltinFunctionType and obj.__name__ 'setdefaultencoding' func objbreakif func is None raise RuntimeError 'Couldnotfindsetdefaultencoding' sys.setdefaultencoding funcreturn func encoding
def margeff_cov_with_se model params exog cov_params at derivative dummy_ind count_ind method J cov_me margeff_cov_params model params exog cov_params at derivative dummy_ind count_ind method J return cov_me np.sqrt np.diag cov_me
def recipr0 X test np.equal np.asarray X 0 return np.where test 0 1.0 / X
def batch_tasks registry xml_parent data pdef XML.SubElement xml_parent 'hudson.plugins.batch__task.BatchTaskProperty' tasks XML.SubElement pdef 'tasks' for task in data batch_task XML.SubElement tasks 'hudson.plugins.batch__task.BatchTask' XML.SubElement batch_task 'name' .text task['name']XML.SubElement batch_task 'script' .text task['script']
def _eval val onts mdb_safe if isinstance val basestring val val.strip if not val return Noneelse return valelif isinstance val dict or isinstance val SamlBase return to_dict val onts mdb_safe elif isinstance val list lv []for v in val if isinstance v dict or isinstance v SamlBase lv.append to_dict v onts mdb_safe else lv.append v return lvreturn val
def _TestSavePhotos tester user_cookie request_dict validator tester.validator user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict actual_dict tester.SendRequest 'save_photos' user_cookie request_dict _ValidateSavePhotos tester user_id device_id request_dict tester._CompareResponseDicts 'save_photos' user_id request_dict {} actual_dict return actual_dict
def compute_signature message secret if not secret return ''if isinstance secret six.text_type secret secret.encode 'utf-8' digest_maker hmac.new secret '' hashlib.sha256 for name value in utils.recursive_keypairs message if name 'message_signature' continuedigest_maker.update six.text_type name .encode 'utf-8' digest_maker.update six.text_type value .encode 'utf-8' return digest_maker.hexdigest
def test_nested_dict_aliasing ad _AliasDict {'bar' False 'biz' True} aliases {'foo' ['bar' 'nested'] 'nested' ['biz']} eq_ ad['bar'] False eq_ ad['biz'] True ad['foo'] Trueeq_ ad['bar'] True eq_ ad['biz'] True
def _parse_return_code_powershell string regex re.search 'ReturnValue\\s* \\d* ' string if not regex return False 'CouldnotparsePowerShellreturncode.' else return int regex.group 1
def upload_pack path '.' inf None outf None if outf is None outf getattr sys.stdout 'buffer' sys.stdout if inf is None inf getattr sys.stdin 'buffer' sys.stdin backend FileSystemBackend path def send_fn data outf.write data outf.flush proto Protocol inf.read send_fn handler UploadPackHandler backend [path] proto handler.handle return 0
def _get_win_folder_from_registry csidl_name import _winregshell_folder_name {'CSIDL_APPDATA' 'AppData' 'CSIDL_COMMON_APPDATA' 'CommonAppData' 'CSIDL_LOCAL_APPDATA' 'LocalAppData'}[csidl_name]key _winreg.OpenKey _winreg.HKEY_CURRENT_USER 'Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ShellFolders' directory _type _winreg.QueryValueEx key shell_folder_name return directory
def get_exploration_metadata_dicts exploration_ids editor_user_id None exploration_summaries exp_services.get_exploration_summaries_matching_ids exploration_ids filtered_exploration_summaries []for exploration_summary in exploration_summaries if exploration_summary is None continueif exploration_summary.status rights_manager.ACTIVITY_STATUS_PRIVATE if editor_user_id is None continueif not rights_manager.Actor editor_user_id .can_edit feconf.ACTIVITY_TYPE_EXPLORATION exploration_summary.id continuefiltered_exploration_summaries.append exploration_summary return [summary.to_metadata_dict for summary in filtered_exploration_summaries]
def shallow_copy in_list return [x for x in in_list]
def libvlc_audio_set_format_callbacks mp setup cleanup f _Cfunctions.get 'libvlc_audio_set_format_callbacks' None or _Cfunction 'libvlc_audio_set_format_callbacks' 1 1 1 None None MediaPlayer AudioSetupCb AudioCleanupCb return f mp setup cleanup
def _escape txt txt txt.replace u'&' u'&amp;' txt txt.replace u'<' u'&lt;' txt txt.replace u'>' u'&gt;' txt txt.replace u'"' u'&quot;' return txt
@depends HAS_PYVMOMI def get_vsan_eligible_disks host username password protocol None port None host_names None service_instance salt.utils.vmware.get_service_instance host host username username password password protocol protocol port port host_names _check_hosts service_instance host host_names response _get_vsan_eligible_disks service_instance host host_names ret {}for host_name value in six.iteritems response error value.get 'Error' if error ret.update {host_name {'Error' error}} continuedisks value.get 'Eligible' if disks and isinstance disks list disk_names []for disk in disks disk_names.append disk.canonicalName ret.update {host_name {'Eligible' disk_names}} else ret.update {host_name {'Eligible' disks}} return ret
def _get_rereview_themes reviewer locks ThemeLock.objects.select_related .no_cache .filter reviewer reviewer theme__rereviewqueuetheme__isnull False .exclude theme__addon__status amo.STATUS_REJECTED num updated_locks _calc_num_themes_checkout locks if updated_locks locks updated_locksthemes RereviewQueueTheme.objects.no_cache .filter theme__addon__isnull False theme__themelock None .exclude theme__addon__status amo.STATUS_REJECTED return num themes locks
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def ensure_dtype func argname arg try return dtype arg except TypeError raise TypeError "{func} couldn'tconvertargument{argname} {arg!r}toanumpydtype.".format func _qualified_name func argname argname arg arg
def channel_indices_by_type info idx dict key list for key in _PICK_TYPES_KEYS if key not in 'meg' 'fnirs' idx.update mag list grad list hbo list hbr list for k ch in enumerate info['chs'] for key in idx.keys if channel_type info k key idx[key].append k return idx
def __cprint *args **kwargs if not kwargs.pop 'verbose' True returncolor kwargs.get 'color' None sep kwargs.get 'sep' '' end kwargs.get 'end' '\n' thread threading.current_thread try file_ thread_output_stream.get thread [ -1 ]except IndexError file_ kwargs.get 'file' sys.stdout if color printer_queue.put PrintResource content '\x1b[{}m'.format colors[color] end '' file file_ sep sep thread thread printer_queue.put PrintResource content args end '' file file_ sep sep thread thread printer_queue.put PrintResource content '\x1b[0m' sep sep end end file file_ thread thread else printer_queue.put PrintResource content args sep sep end end file file_ thread thread
def split_domain_port host host host.lower if not host_validation_re.match host return u'' u'' if host[ -1 ] u']' return host u'' bits host.rsplit u' ' 1 if len bits 2 return tuple bits return bits[0] u''
def start_kernel argv None **kwargs from IPython.kernel.zmq.kernelapp import launch_new_instancereturn launch_new_instance argv argv **kwargs
def orthogonalize *vlist **kwargs orthonormal kwargs.get 'orthonormal' False if not all isinstance vec Vector for vec in vlist raise TypeError 'EachelementmustbeofTypeVector' ortho_vlist []for i term in enumerate vlist for j in range i term - ortho_vlist[j].projection vlist[i] if simplify term .equals Vector.zero raise ValueError 'Vectorsetnotlinearlyindependent' ortho_vlist.append term if orthonormal ortho_vlist [vec.normalize for vec in ortho_vlist]return ortho_vlist
def dissoc d *keys d2 copy.copy d for key in keys if key in d2 del d2[key]return d2
def try_all_threshold image figsize 8 5 verbose True def thresh func '\nAwrapperfunctiontoreturnathresholdedimage.\n'def wrapper im return im > func im try wrapper.__orifunc__ func.__orifunc__except AttributeError wrapper.__orifunc__ func.__module__ + '.' + func.__name__ return wrappermethods OrderedDict {'Isodata' thresh threshold_isodata 'Li' thresh threshold_li 'Mean' thresh threshold_mean 'Minimum' thresh threshold_minimum 'Otsu' thresh threshold_otsu 'Triangle' thresh threshold_triangle 'Yen' thresh threshold_yen } return _try_all image figsize figsize methods methods verbose verbose
def task_pydocstyle yield {'name' os.path.join os.getcwd 'nikola' 'actions' ["pydocstyle--count--match-dir ' ?!^\\. ?!data .*'nikola/"]}
def get_module_imports project pymodule return module_imports.ModuleImports project pymodule
def setcopyright __builtin__.copyright _Printer 'copyright' sys.copyright if sys.platform[ 4] 'java' __builtin__.credits _Printer 'credits' 'JythonismaintainedbytheJythondevelopers www.jython.org .' elif sys.platform 'cli' __builtin__.credits _Printer 'credits' 'IronPythonismaintainedbytheIronPythondevelopers www.ironpython.net .' else __builtin__.credits _Printer 'credits' 'ThankstoCWI CNRI BeOpen.com ZopeCorporationandacastofthousands\nforsupportingPythondevelopment.Seewww.python.orgformoreinformation.' here os.path.dirname os.__file__ __builtin__.license _Printer 'license' 'Seehttp //www.python.org/%.3s/license.html' % sys.version ['LICENSE.txt' 'LICENSE'] [os.path.join here os.pardir here os.curdir]
def requestPdpContextActivationReject a TpPd pd 8 b MessageType mesType 69 c SmCause packet a / b / c return packet
def arg *args **kwargs return {'args' args 'kwargs' kwargs}
def parse_ls_tree rev output []lines git.ls_tree rev r True [STDOUT].splitlines regex re.compile u'^ \\d+ \\W \\w+ \\W \\w+ [\\t]+ .* $' for line in lines match regex.match line if match mode match.group 1 objtype match.group 2 oid match.group 3 filename match.group 4 output.append mode objtype oid filename return output
def reiterate iterable if isinstance iterable list tuple return iterableelse iterator iter iterable try chunk ''while not chunk chunk next iterator return itertools.chain [chunk] iterator except StopIteration return []
def onSpaceData spaceID entryID key value pass
@commands u'settimeformat' u'settf' @example u'.settf%Y-%m-%dT%T%z' def update_user_format bot trigger tformat trigger.group 2 if not tformat bot.reply u'Whatformatdoyouwantmetouse?Tryusinghttp //strftime.nettomakeone.' returntz get_timezone bot.db bot.config None trigger.nick trigger.sender old_format bot.db.get_nick_value trigger.nick u'time_format' bot.db.set_nick_value trigger.nick u'time_format' tformat try timef format_time db bot.db zone tz nick trigger.nick except bot.reply u"Thatformatdoesn'twork.Tryusinghttp //strftime.nettomakeone." bot.db.set_nick_value trigger.nick u'time_format' old_format returnbot.reply u'Gotit.Yourtimewillnowappearas%s. Ifthetimezoneiswrong youmighttrythesettzcommand ' % timef
def _CheckDocumentId doc_id _ValidateString doc_id 'doc_id' MAXIMUM_DOCUMENT_ID_LENGTH _ValidateVisiblePrintableAsciiNotReserved doc_id 'doc_id' return doc_id
def group_pre_delete instance sender **kwargs if instance.name 'anonymous' raise Exception 'Deletionoftheanonymousgroupisnotpermittedaswillbreakthegeonodepermissionssystem'
def _is_number_match_OS numobj1 number2 try numobj2 parse number2 UNKNOWN_REGION return _is_number_match_OO numobj1 numobj2 except NumberParseException _ exc _ sys.exc_info if exc.error_type NumberParseException.INVALID_COUNTRY_CODE region1 region_code_for_country_code numobj1.country_code try if region1 ! UNKNOWN_REGION numobj2 parse number2 region1 match _is_number_match_OO numobj1 numobj2 if match MatchType.EXACT_MATCH return MatchType.NSN_MATCHelse return matchelse numobj2 parse number2 None keep_raw_input False _check_region False numobj None return _is_number_match_OO numobj1 numobj2 except NumberParseException return MatchType.NOT_A_NUMBERreturn MatchType.NOT_A_NUMBER
def test_validate_input report Report items ['a' 'b' 'c']captions ['LetterA' 'LetterB' 'LetterC']section 'ABCs'comments ['Firstletterofthealphabet.' 'Secondletterofthealphabet' 'Thirdletterofthealphabet']assert_raises ValueError report._validate_input items captions[ -1 ] section comments None assert_raises ValueError report._validate_input items captions section comments comments[ -1 ] values report._validate_input items captions section comments None items_new captions_new comments_new valuesassert_equal len comments_new len items
def listCoordinates filename coords line.strip .split '/' for line in open filename 'r' coords map int row column zoom for zoom column row in coords coords [Coordinate *args for args in coords]count len coords for offset coord in enumerate coords yield offset count coord
def get_long_path_name path return _get_long_path_name path
def unquote_unreserved uri try parts uri.split '%' for i in range 1 len parts h parts[i][0 2]if len h 2 and h.isalnum c chr int h 16 if c in UNRESERVED_SET parts[i] c + parts[i][2 ] else parts[i] '%' + parts[i] else parts[i] '%' + parts[i] return ''.join parts except ValueError return uri
def head_splitter headfile remote module None fail_on_error False res Noneif os.path.exists headfile rawdata Nonetry f open headfile 'r' rawdata f.readline f.close except if fail_on_error and module module.fail_json msg 'Unabletoread%s' % headfile if rawdata try rawdata rawdata.replace 'refs/remotes/%s' % remote '' 1 refparts rawdata.split '' newref refparts[ -1 ]nrefparts newref.split '/' 2 res nrefparts[ -1 ].rstrip '\n' except if fail_on_error and module module.fail_json msg "Unabletosplitheadfrom'%s'" % rawdata return res
def test_saving_state_include_domains hass_recorder hass hass_recorder {'include' {'domains' 'test2'}} states _add_entities hass ['test.recorder' 'test2.recorder'] assert len states 1 assert hass.states.get 'test2.recorder' states[0]
def getTokens command if type command unicode try command command.encode wx.GetDefaultPyEncoding except UnicodeEncodeError passf cStringIO.StringIO command tokens []try def eater *args tokens.append args tokenize.tokenize_loop f.readline eater except tokenize.TokenError passreturn tokens
@FileSystem.in_directory current_directory 'django' 'chive' def test_django_admin_media_serving_on_django_13 os.environ['PYTHONPATH'] '%s %s' % FileSystem.join lib_directory 'Django-1.3' OLD_PYTHONPATH status out commands.getstatusoutput 'pythonmanage.pyharvest--verbosity 2./features/' assert_not_equals status 0 lines out.splitlines assert u"Preparingtoservedjango'sadminsitestaticfiles..." in lines assert u"Django'sbuiltinserverisrunningat0.0.0.0 7000" in lines
def _flash_encryption_tweak_key key offset tweak_range key [ord k for k in key]offset_bits [ offset & 1 << x ! 0 for x in range 24 ]for bit in tweak_range if offset_bits[_FLASH_ENCRYPTION_TWEAK_PATTERN[bit]] key[ bit / 8 ] ^ 1 << 7 - bit % 8 return ''.join chr k for k in key
def _register_ogp_service url owner None services Service.objects.filter base_url url if services.count > 0 service services[0]return_dict [{'status' 'ok' 'service_id' service.pk 'service_name' service.name 'service_title' service.title 'msg' 'ThisisanexistingService'}]return return_dictservice Service.objects.create base_url url type 'OGP' method 'H' name 'OpenGeoPortal' title 'OpenGeoPortal' abstract OGP_ABSTRACT owner owner service.set_default_permissions if settings.USE_QUEUE WebServiceHarvestLayersJob.objects.get_or_create service service else _harvest_ogp_layers service owner owner message 'Service%sregistered' % service.name return_dict [{'status' 'ok' 'msg' message 'service_id' service.pk 'service_name' service.name 'service_title' service.title}]return HttpResponse json.dumps return_dict content_type 'application/json' status 200
def do ruby command runas None cwd None try command salt.utils.shlex_split command except AttributeError command salt.utils.shlex_split str command return _rvm_do ruby command runas runas cwd cwd
@pytest.fixture scope 'session' def tmpdir_factory request return request.config._tmpdirhandler
def cube width dtype np.uint8 return np.ones width width width dtype dtype
def _check_roundtrip_fixed dip tempdir _TempDir dip.save op.join tempdir 'test-dip.fif.gz' dip_read read_dipole op.join tempdir 'test-dip.fif.gz' assert_allclose dip_read.data dip_read.data assert_allclose dip_read.times dip.times assert_equal dip_read.info['xplotter_layout'] dip.info['xplotter_layout'] assert_equal dip_read.ch_names dip.ch_names for ch_1 ch_2 in zip dip_read.info['chs'] dip.info['chs'] assert_equal ch_1['ch_name'] ch_2['ch_name'] for key in 'loc' 'kind' 'unit_mul' 'range' 'coord_frame' 'unit' 'cal' 'coil_type' 'scanno' 'logno' assert_allclose ch_1[key] ch_2[key] err_msg key
def wait objects None timeout None count None if objects is None return get_hub .join timeout timeout result []if count is None return list iwait objects timeout for obj in iwait objects objects timeout timeout result.append obj count - 1if count < 0 breakreturn result
def validate_marketing_site_config settings if settings.FEATURES.get 'ENABLE_MKTG_SITE' if not hasattr settings 'MKTG_URLS' raise ValueError "'ENABLE_MKTG_SITE'isTrue but'MKTG_URLS'isnotdefined." if not settings.MKTG_URLS.get 'ROOT' raise ValueError "Thereisno'ROOT'definedin'MKTG_URLS'."
def _get_key_dir if 'config.get' in __salt__ gpg_keydir __salt__['config.get'] 'gpg_keydir' else gpg_keydir __opts__.get 'gpg_keydir' return gpg_keydir or os.path.join __opts__['config_dir'] 'gpgkeys'
def force_rss __SCHED.add_single_task rss.run_method 'RSS' 1 kronos.method.sequential None None
def submit_calculate_students_features_csv request course_key features task_type 'profile_info_csv'task_class calculate_students_features_csvtask_input featurestask_key ''return submit_task request task_type task_class course_key task_input task_key
def evaluation_question return s3_rest_controller
def isbinarytext text assert isinstance text str "textmustbestr got'%s'" % type text .__name__ return any c in _BINARYCHARS for c in text
def document_api_from_discovery_document uri http build_http response content http.request FLAGS.discovery_uri discovery json.loads content service build_from_document discovery name discovery['version']version safe_version discovery['version'] document_collection_recursive service '%s_%s.' % name version discovery discovery
def create_datacenter call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thecreate_addressfunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}if kwargs.get 'name' is None raise SaltCloudExecutionFailure 'The"name"parameterisrequired' if kwargs.get 'location' is None raise SaltCloudExecutionFailure 'The"location"parameterisrequired' conn get_conn datacenter Datacenter name kwargs['name'] location kwargs['location'] description kwargs.get 'description' response conn.create_datacenter datacenter _wait_for_completion conn response 60 'create_datacenter' return response
def term_all_jobs ret []for data in running ret.append signal_job data['jid'] signal.SIGTERM return ret
def predicative adjective w adjective.lower if w in adjective_predicative return adjective_predicative[w]if w.endswith 'ari' return w + 'o' if w.endswith 'ali' 'ili' 'esi' 'nti' 'ori' return w[ -1 ] + 'e' if w.endswith 'isti' return w[ -1 ] + 'a' if w.endswith 'che' 'ghe' return w[ -2 ] + 'a' if w.endswith 'chi' 'ghi' return w[ -2 ] + 'o' if w.endswith 'i' return w[ -1 ] + 'o' if w.endswith 'e' return w[ -1 ] + 'a' return adjective
def combine_labels left right if set left .intersection right left tuple l + u'0' for l in left right tuple r + u'1' for r in right return left + right
def test_iht_sample_wt_fit iht InstanceHardnessThreshold ESTIMATOR random_state RND_SEED assert_raises RuntimeError iht.sample X Y
def hash_item item ephemeral_paths complete hash_config item durable durable_hash item ephemeral_paths return complete durable
def iter_color_groups mapping prefs for key in natsort prefs.keys col_name prefs[key]['column']if 'colors' in prefs[key] if isinstance prefs[key]['colors'] dict colors prefs[key]['colors'].copy else colors prefs[key]['colors'][ ]else colors {}labelname prefs[key]['column']groups group_by_field mapping col_name colors data_colors data_color_order get_group_colors groups colors yield labelname groups colors data_colors data_color_order
def test_write_twoline_no_pad out StringIO ascii.write dat out Writer ascii.FixedWidthTwoLine delimiter_pad '' position_char ' ' assert_equal_splitlines out.getvalue 'Col1Col2Col3Col4\n \n1.2"hello"1a\n2.4\'sworlds22\n'
def test_class_attribute vals [ [1] * u.m [2] * u.m ]texp ['<Tablelength 1>' 'namedtypeunit' '---------------' 'col0float64m' 'col1float64m']qexp ['<QTablelength 1>' 'namedtypeunitclass' '-----------------------' 'col0float64mQuantity' 'col1float64mQuantity']for table_cls exp in table.Table texp table.QTable qexp t table_cls vals out StringIO t.info out out assert out.getvalue .splitlines exp
def _migrate_dashboard_stats_to_latest_schema versioned_dashboard_stats stats_schema_version versioned_dashboard_stats.schema_versionif not 1 < stats_schema_version < feconf.CURRENT_DASHBOARD_STATS_SCHEMA_VERSION raise Exception 'Sorry wecanonlyprocessv1-v%ddashboardstatsschemasatpresent.' % feconf.CURRENT_DASHBOARD_STATS_SCHEMA_VERSION
def stacked_matmul a b if a.shape[1] > 50 out np.empty_like a for i in range a.shape[0] out[i] np.dot a[i] b[i] return outelse return np.einsum '...ij ...jk->...ik' a b
def write_metadata_im file metadata command ['convert' file] + list chain.from_iterable '-set' k v for k v in metadata.items + [file] util.command_output command return True
@task@writedef save_theme header footer addon **kw dst_root os.path.join user_media_path 'addons' str addon.id header os.path.join settings.TMP_PATH 'persona_header' header header_dst os.path.join dst_root 'header.png' if footer footer os.path.join settings.TMP_PATH 'persona_footer' footer footer_dst os.path.join dst_root 'footer.png' try save_persona_image src header full_dst header_dst if footer save_persona_image src footer full_dst footer_dst create_persona_preview_images src header full_dst [os.path.join dst_root 'preview.png' os.path.join dst_root 'icon.png' ] set_modified_on [addon] theme_checksum addon.persona except IOError addon.delete raise
def test_quantity_from_table from ...table import Tablet Table data [np.arange 5 np.arange 5 ] names [u'a' u'b'] t[u'a'].unit u.kpcqa u.Quantity t[u'a'] assert qa.unit u.kpc assert_array_equal qa.value t[u'a'] qb u.Quantity t[u'b'] assert qb.unit u.dimensionless_unscaled assert_array_equal qb.value t[u'b'] qap u.Quantity t[u'a'] u.pc assert qap.unit u.pc assert_array_equal qap.value t[u'a'] * 1000 qbp u.Quantity t[u'b'] u.pc assert qbp.unit u.pc assert_array_equal qbp.value t[u'b']
def _isDefaultHandler return signal.getsignal signal.SIGCHLD signal.SIG_DFL
def open filename flag 'c' protocol None writeback False return DbfilenameShelf filename flag protocol writeback
@gof.local_optimizer [sigmoid] def local_ultra_fast_sigmoid node if isinstance node.op tensor.Elemwise and node.op.scalar_op scalar_sigmoid out ultra_fast_sigmoid node.inputs[0] copy_stack_trace node.outputs[0] out def values_eq_approx_remove_low_prec a b return tensor.TensorType.values_eq_approx a b atol 0.02 out.tag.values_eq_approx values_eq_approx_remove_low_precreturn [out]
def _ParseOptions message string message.ParseFromString string return message
def parse_argstring magic_func argstring return magic_func.parser.parse_argstring argstring
def _assert_is_type name value value_type if not isinstance value value_type if type value_type is tuple types ' '.join t.__name__ for t in value_type raise ValueError '{0}mustbeoneof {1} '.format name types else raise ValueError '{0}mustbe{1}'.format name value_type.__name__
@utils.arg '--limit' dest 'limit' metavar '<limit>' help _ 'Numberofimagestoreturnperrequest.' @deprecated_imagedef do_image_list cs _args limit _args.limitimage_list cs.images.list limit limit def parse_server_name image try return image.server['id']except AttributeError KeyError return ''fmts {'Server' parse_server_name}utils.print_list image_list ['ID' 'Name' 'Status' 'Server'] fmts sortby_index 1
def check_object_support obj return isinstance obj models.Model
def s_get name None if not name return blocks.CURRENTs_switch name if not blocks.REQUESTS.has_key name raise sex.SullyRuntimeError 'blocks.REQUESTSNOTFOUND %s' % name return blocks.REQUESTS[name]
def _read_next_string data str_len struct.unpack '>I' data[ 4] return data[4 4 + str_len ] data[ 4 + str_len ]
def get_lcm_config cmd 'Get-DscLocalConfigurationManager|Select-Object-PropertyConfigurationModeFrequencyMins LCMState RebootNodeIfNeeded ConfigurationMode ActionAfterReboot RefreshMode CertificateID ConfigurationID RefreshFrequencyMins AllowModuleOverwrite DebugMode StatusRetentionTimeInDays'return _pshell cmd
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def validate_space_limit file_size from frappe.utils.file_manager import MaxFileSizeReachedErrorlimits get_limits if not limits.space returnspace_limit flt limits.space * 1024.0 2 usage frappe._dict limits.space_usage or {} if not usage usage frappe._dict update_space_usage file_size file_size / 1024.0 ** 2 if flt flt usage.total + file_size 2 > space_limit frappe.throw _ u'Youhaveexceededthemaxspaceof{0}foryourplan.{1}.' .format u'<b>{0}MB</b>'.format cint space_limit if space_limit < 1024 else u'<b>{0}GB</b>'.format limits.space u'<ahref "#usage-info">{0}</a>'.format _ u'Clickheretocheckyourusageorupgradetoahigherplan' MaxFileSizeReachedError usage.files_size flt usage.files_size + file_size update_limits {u'space_usage' usage}
def default_input_format content_type 'application/json' apply_globally False api None def decorator formatter formatter hug.output_format.content_type content_type formatter if apply_globally hug.defaults.input_format[content_type] formatterelse apply_to_api hug.API api if api else hug.api.from_object formatter apply_to_api.http.set_input_format content_type formatter return formatterreturn decorator
def redirect url code None if code is None code 303 if request.get 'SERVER_PROTOCOL' 'HTTP/1.1' else 302 location urljoin request.url url raise HTTPResponse '' status code header dict Location location
def set_font font section 'main' option 'font' CONF.set section option + '/family' to_text_string font.family CONF.set section option + '/size' float font.pointSize CONF.set section option + '/italic' int font.italic CONF.set section option + '/bold' int font.bold FONT_CACHE[ section option ] font
def dump_tokens s f StringIO s for type token start end line in generate_tokens f.readline if type ENDMARKER breaktype tok_name[type]print '% type -10.10s% token -13.13r% start s% end s' % locals
@receiver comment_endorsed def comment_endorsed_handler sender **kwargs comment kwargs['post']handle_activity kwargs['user'] comment long comment.thread.user_id
def get_error_detail exc_info code getattr exc_info u'code' None or u'invalid' return [ErrorDetail msg code code for msg in exc_info.messages]
def google_list_style style if 'list-style-type' in style list_style style['list-style-type']if list_style in ['disc' 'circle' 'square' 'none'] return 'ul'return 'ol'
def retention_policy_exists database name **client_args if get_retention_policy database name **client_args return Truereturn False
def check_new_version myversion version_url try version to_native urlopen version_url .read pversion parse_version version pmyversion parse_version myversion except IOError import tracebackprint traceback.format_exc return -1 myversion if pversion[ 3] + pversion[ -6 ] > pmyversion[ 3] + pmyversion[ -6 ] return True version else return False version
def test_sigmaclip_negative_axis data np.ones 3 4 sigma_clip data axis -1
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def cxMessyOnePoint ind1 ind2 cxpoint1 random.randint 0 len ind1 cxpoint2 random.randint 0 len ind2 ind1[cxpoint1 ] ind2[cxpoint2 ] ind2[cxpoint2 ] ind1[cxpoint1 ] return ind1 ind2
def request_path request url request.get_full_url path escape_path _rfc3986.urlsplit url [2] if not path.startswith '/' path '/' + path return path
def oid_generated_on_client oid pid_from_doc struct.unpack '>H' oid.binary[7 9] [0]return os.getpid % 65535 pid_from_doc
@manager.option u'-t' u'--load-test-data' action u'store_true' help u'Loadadditionaltestdata' def load_examples load_test_data print u'Loadingexamplesinto{}'.format db data.load_css_templates print u'Loadingenergyrelateddataset' data.load_energy print u"Loading[WorldBank'sHealthNutritionandPopulationStats]" data.load_world_bank_health_n_pop print u'Loading[Birthnames]' data.load_birth_names print u'Loading[Randomtimeseriesdata]' data.load_random_time_series_data print u'Loading[Randomlong/latdata]' data.load_long_lat_data print u'Loading[Multiformattimeseries]' data.load_multiformat_time_series_data print u'Loading[MiscCharts]dashboard' data.load_misc_dashboard if load_test_data print u'Loading[Unicodetestdata]' data.load_unicode_test_data
def get_f_option opts for opt arg in opts if opt '-f' return argelse return None
def _getHgVersion filename dirname os.path.dirnameif not os.path.exists filename or not os.path.isdir os.path.join dirname filename '.hg' return Nonetry hgParentLines err shellCall ['hg' 'parents' filename] stderr True changeset hgParentLines.splitlines [0].split [ -1 ]except Exception changeset ''try hgID err shellCall ['hg' 'id' '-nibt' dirname filename ] stderr True except Exception if err hgID ''if len hgID or len changeset return hgID.strip + '|parent ' + changeset.strip else return None
def SendCGIResponse status headers content outfile cors_handler None if cors_handler cors_handler.UpdateHeaders headers outfile.write 'Status %s\r\n' % status WriteHeaders headers outfile len content if content else None outfile.write '\r\n' if content outfile.write content outfile.seek 0
def read_and_call uhandle method **keywds line safe_readline uhandle errmsg _fails_conditions * line **keywds if errmsg is not None raise ValueError errmsg method line
def is_vcs_repository path return get_vcs_root path is not None
def InstanceActionAPI *args **kwargs compute_api_class_name _get_compute_api_class_name compute_api_class importutils.import_class compute_api_class_name class_name compute_api_class.__module__ + '.InstanceActionAPI' return importutils.import_object class_name *args **kwargs
def convolve in1 in2 mode 'full' method 'auto' volume asarray in1 kernel asarray in2 if volume.ndim kernel.ndim 0 return volume * kernel if _inputs_swap_needed mode volume.shape kernel.shape volume kernel kernel volume if method 'auto' method choose_conv_method volume kernel mode mode if method 'fft' out fftconvolve volume kernel mode mode if volume.dtype.kind in 'ui' out np.around out return out.astype volume.dtype if _np_conv_ok volume kernel mode return np.convolve volume kernel mode return correlate volume _reverse_and_conj kernel mode 'direct'
def should_bypass_proxies url get_proxy lambda k os.environ.get k or os.environ.get k.upper no_proxy get_proxy 'no_proxy' netloc urlparse url .netlocif no_proxy no_proxy host for host in no_proxy.replace '' '' .split ' ' if host ip netloc.split ' ' [0]if is_ipv4_address ip for proxy_ip in no_proxy if is_valid_cidr proxy_ip if address_in_network ip proxy_ip return Trueelse for host in no_proxy if netloc.endswith host or netloc.split ' ' [0].endswith host return Truetry bypass proxy_bypass netloc except TypeError socket.gaierror bypass Falseif bypass return Truereturn False
def _popget d key default None if key in d return d.pop key return default
def harmonic_mean data if iter data is data data list data errmsg 'harmonicmeandoesnotsupportnegativevalues'n len data if n < 1 raise StatisticsError 'harmonic_meanrequiresatleastonedatapoint' elif n 1 x data[0]if isinstance x numbers.Real Decimal if x < 0 raise StatisticsError errmsg return xelse raise TypeError 'unsupportedtype' try T total count _sum 1 / x for x in _fail_neg data errmsg except ZeroDivisionError return 0assert count n return _convert n / total T
def scale_to_unit_interval ndar eps 1e-08 ndar ndar.copy ndar - ndar.min ndar * 1.0 / ndar.max + eps return ndar
def createFactorialTrialList factors tempListOfLists [[]]for key in factors alist factors[key]tempList []for value in alist for iterList in tempListOfLists tempList.append iterList + [key value] tempListOfLists tempListtrialList []for atrial in tempListOfLists keys atrial[0 2]values atrial[1 2]atrialDict {}for i in range len keys atrialDict[keys[i]] values[i]trialList.append atrialDict return trialList
def get_default_theme is_unicode True return u'powerline_terminus' if is_unicode else u'ascii'
def make_kind_check python_types numpy_kind def check value if hasattr value 'dtype' return value.dtype.kind numpy_kind return isinstance value python_types return check
def mesh_surface_area verts faces actual_verts verts[faces]a actual_verts[ 0 ] - actual_verts[ 1 ] b actual_verts[ 0 ] - actual_verts[ 2 ] del actual_vertsreturn np.cross a b ** 2 .sum axis 1 ** 0.5 .sum / 2.0
def _mix_simple a b x x np.clip x 0.0 1.0 return 1.0 - x * a + x * b
def isinstance obj bases try cls obj.__getattr__ '__class__' except AttributeError try cls obj.__class__except AttributeError cls orig_type obj return issubclass cls bases
def test_smooth_bootstrap x rs.randn 15 n_boot 100out_smooth algo.bootstrap x n_boot n_boot smooth True func np.median assert not np.median out_smooth in x
def _load_hbase_list d prefix ret []prefix 'f %s_' % prefix for key in k for k in d if k.startswith prefix ret.append key[len prefix ] return ret
def test_redundant_multiple_bases class Foo list object passclass Bar Foo passAreEqual Bar []
def load_certificate_request type buffer if isinstance buffer _text_type buffer buffer.encode 'ascii' bio _new_mem_buf buffer if type FILETYPE_PEM req _lib.PEM_read_bio_X509_REQ bio _ffi.NULL _ffi.NULL _ffi.NULL elif type FILETYPE_ASN1 req _lib.d2i_X509_REQ_bio bio _ffi.NULL else raise ValueError 'typeargumentmustbeFILETYPE_PEMorFILETYPE_ASN1' if req _ffi.NULL _raise_current_error x509req X509Req.__new__ X509Req x509req._req _ffi.gc req _lib.X509_REQ_free return x509req
def libvlc_media_library_load p_mlib f _Cfunctions.get 'libvlc_media_library_load' None or _Cfunction 'libvlc_media_library_load' 1 None ctypes.c_int MediaLibrary return f p_mlib
def benchmark scale 1 overallResult {}byteCount 1024bufferedDeferred _benchmarkBuffered byteCount * scale def didBuffered bufferedResult overallResult[u'buffered'] bufferedResultunbufferedDeferred _benchmarkUnbuffered byteCount * scale def didUnbuffered unbufferedResult overallResult[u'unbuffered'] unbufferedResultreturn overallResultunbufferedDeferred.addCallback didUnbuffered return unbufferedDeferredbufferedDeferred.addCallback didBuffered return bufferedDeferred
def is_tuple node if isinstance node Node and node.children [LParen RParen ] return Truereturn isinstance node Node and len node.children 3 and isinstance node.children[0] Leaf and isinstance node.children[1] Node and isinstance node.children[2] Leaf and node.children[0].value u' ' and node.children[2].value u' '
def poweron hostname timeout 20 username None password None client __connect hostname timeout username password if isinstance client paramiko.SSHClient stdin stdout stderr client.exec_command 'racadmserveractionpowerup' if 'successful' in stdout.readline log.info 'powerupsuccessful' else log.error 'powerupracadmcommandfailed' return Falseelse log.error 'clientwasnotoftypeparamiko.SSHClient' return Falsereturn True
def say_hello name None if name is None name u'Stranger'return u'Hithere %s!' % name
def constructor_import loader node value loader.construct_scalar node if '.' not in value raise yaml.YAMLError "importtagsuffixcontainsno'.'" return try_to_import value
def _get_c_string data position opts end data.index '\x00' position return _utf_8_decode data[position end] opts.unicode_decode_error_handler True [0] end + 1
def terminal_info return {u'size' terminal_size u'isatty' sys.stdout.isatty }
def has_path G source target try sp nx.shortest_path G source target except nx.NetworkXNoPath return Falsereturn True
def default_tax_handler request order_form set_tax request _ u'Tax' 0
def orthogonalization_matrix lengths angles a b c lengthsangles numpy.radians angles sina sinb _ numpy.sin angles cosa cosb cosg numpy.cos angles co cosa * cosb - cosg / sina * sinb return numpy.array [[ a * sinb * math.sqrt 1.0 - co * co 0.0 0.0 0.0] [ - a * sinb * co b * sina 0.0 0.0] [ a * cosb b * cosa c 0.0] [0.0 0.0 0.0 1.0]]
def _construct_expression coeffs opt domain result EX [] for coeff in coeffs result.append domain.from_sympy coeff return domain result
def setPin pinNumber state global PORTPORT.setPin pinNumber state
def from_string s return cPickle.loads s
def t2b t clean b rws t if len clean % 2 1 raise ValueError 'Evennumberofcharactersexpected' return a2b_hex clean
def connect_ec2_endpoint url aws_access_key_id None aws_secret_access_key None **kwargs from boto.ec2.regioninfo import RegionInfopurl urlparse url kwargs['port'] purl.portkwargs['host'] purl.hostnamekwargs['path'] purl.pathif not 'is_secure' in kwargs kwargs['is_secure'] purl.scheme 'https' kwargs['region'] RegionInfo name purl.hostname endpoint purl.hostname kwargs['aws_access_key_id'] aws_access_key_idkwargs['aws_secret_access_key'] aws_secret_access_keyreturn connect_ec2 **kwargs
def safe_decode_hdr msg None name None hdr None charset None if hdr is None value msg and msg[name] or '' charset charset or msg.get_content_charset or 'utf-8' else value hdrcharset charset or 'utf-8' if not isinstance value unicode value try_decode value charset replace '?' if ' ?' in value and '? ' in value try value value.encode 'utf-8' .replace '"' '' pairs decode_header value value ''.join [try_decode t cs or charset for t cs in pairs] except email.errors.HeaderParseError passreturn value.replace '\r' '' .replace ' DCTB ' '' .replace '\n' ''
def text_filter_formstyle form fields *args **kwargs def render_row row_id label widget comment hidden False controls DIV DIV LABEL 'Search ' _class 'prefix' _class 'large-4columns' _for widget[1].attributes['_name'] DIV widget _class 'large-8columns' _class 'rowcollapseprefix-radius' _id row_id return controlsif args row_id formlabel fields widget comment argshidden kwargs.get 'hidden' False return render_row row_id label widget comment hidden else parent TAG[''] for row_id label widget comment in fields parent.append render_row row_id label widget comment return parent
def build_no_log_generator container log_args yield u"WARNING nologsareavailablewiththe'{}'logdriver\n".format container.log_driver
def bound_function template_key def wrapper method_resolver @functools.wraps method_resolver def attribute_resolver self ty class MethodTemplate AbstractTemplate key template_keydef generic _ args kws sig method_resolver self ty args kws if sig is not None and sig.recvr is None sig.recvr tyreturn sigreturn types.BoundFunction MethodTemplate ty return attribute_resolverreturn wrapper
def is_builtin name if name in builtins return Trueif name in SPECIAL_BUILTINS return Truereturn False
def _GetPercentileList items percentilelist if not items return Nonesortedlist sorted items return [_GetPercentile sortedlist p for p in percentilelist]
def _most_frequent array extra_value n_repeat if array.size > 0 mode stats.mode array most_frequent_value mode[0][0]most_frequent_count mode[1][0]else most_frequent_value 0most_frequent_count 0if most_frequent_count 0 and n_repeat 0 return np.nanelif most_frequent_count < n_repeat return extra_valueelif most_frequent_count > n_repeat return most_frequent_valueelif most_frequent_count n_repeat if most_frequent_value < extra_value return most_frequent_valueelse return extra_value
def bench_R5 def blowup L n for i in range n L.append L[i] + L[ i + 1 ] * L[ i + 2 ] def uniq x v set x return vL [x y z]blowup L 8 L uniq L
def _Offsets *args return dict a None for a in args
def authenticate username password service 'login' @CONV_FUNCdef my_conv n_messages messages p_response app_data 'Simpleconversationfunctionthatrespondstoany\npromptwheretheechoisoffwiththesuppliedpassword'addr CALLOC n_messages sizeof PamResponse p_response[0] cast addr POINTER PamResponse for i in range n_messages if messages[i].contents.msg_style PAM_PROMPT_ECHO_OFF pw_copy STRDUP str password p_response.contents[i].resp cast pw_copy c_char_p p_response.contents[i].resp_retcode 0return 0handle PamHandle conv PamConv my_conv 0 retval PAM_START service username pointer conv pointer handle if retval ! 0 return Falseretval PAM_AUTHENTICATE handle 0 return retval 0
def p_unary_operator t pass
def set_used_ips user_defined_config inventory used_ips user_defined_config.get 'used_ips' if isinstance used_ips list for ip in used_ips split_ip ip.split ' ' if len split_ip > 2 ip_range list netaddr.iter_iprange split_ip[0] split_ip[ -1 ] USED_IPS.update [str i for i in ip_range] else logger.debug 'IP%ssetasused' split_ip[0] USED_IPS.add split_ip[0] for host_entry in inventory['_meta']['hostvars'].values networks host_entry.get 'container_networks' dict for network_entry in networks.values address network_entry.get 'address' if address logger.debug 'IP%ssetasused' address USED_IPS.add address
def printTogetherListsByFileNames fileNames for fileName in fileNames togetherLists getTogetherLists fileName if len togetherLists > 0 for togetherList in togetherLists for together in togetherList function together[0]sorted together[1]return
def abbrev_cwd cwd os.getcwd .replace '\\' '/' drivepart ''tail cwdif sys.platform 'win32' if len cwd < 4 return cwd drivepart tail os.path.splitdrive cwd parts tail.split '/' if len parts > 2 tail '/'.join parts[ -2 ] return drivepart + cwd '/' and '/' or tail
def del_store name store saltenv 'base' ret {'name' name 'result' True 'comment' '' 'changes' {}}cert_file __salt__['cp.cache_file'] name saltenv if cert_file is False ret['result'] Falseret['comment'] + 'Certificatefilenotfound.'else cert_serial __salt__['certutil.get_cert_serial'] cert_file serials __salt__['certutil.get_stored_cert_serials'] store if cert_serial in serials out __salt__['certutil.del_store'] cert_file store if 'successfully' in out ret['changes']['removed'] nameelse ret['result'] Falseret['comment'] + 'Failedtoremovethecertificate{0}'.format name else ret['comment'] + '{0}alreadyremoved.'.format name return ret
def instance_get_all_by_host_and_not_type context host type_id None return IMPL.instance_get_all_by_host_and_not_type context host type_id
def print_elapsed_time module_name elapsed print '%-22s %6.2f' % module_name elapsed
def getmodebase mode return ImageMode.getmode mode .basemode
def GetHelpWidth if not sys.stdout.isatty or termios is None or fcntl is None return _help_widthtry data fcntl.ioctl sys.stdout termios.TIOCGWINSZ '1234' columns struct.unpack 'hh' data [1]if columns > 40 return columnsreturn int os.getenv 'COLUMNS' _help_width except TypeError IOError struct.error return _help_width
def trigamma x return polygamma 1 x
def is_numeric_batch batch def is_numeric batch return isinstance batch np.ndarray or scipy.sparse.issparse batch or str type batch "<type'CudaNdarray'>" return _is_batch_all batch is_numeric
def CDLUNIQUE3RIVER barDs count return call_talib_with_ohlc barDs count talib.CDLUNIQUE3RIVER
def delete_symlink link_path if os.path.exists link_path os.remove link_path
def unpickle_lazyobject wrapped return wrapped
def is_null_datelike_scalar other if other is NaT or other is None return Trueelif is_scalar other if hasattr other 'dtype' return other.view 'i8' iNaT elif is_integer other and other iNaT return Truereturn isnull other return False
def bootstrap_support master_tree trees new_master setup_master_tree master_tree trees for sub_tree in trees tree_support new_master sub_tree num_trees len trees bootstrap_supports {}for node in new_master.iterNontips include_self True node.bootstrap_support node.bootstrap_support / num_trees bootstrap_supports[node.Name] node.bootstrap_supportreturn new_master bootstrap_supports
@protocol.commands.add u'noidle' list_command False def noidle context if not context.subscriptions returncontext.subscriptions set context.events set context.session.prevent_timeout False
def enable_automatic_int_sympification app hasshell hasattr app 'shell' import astif hasshell old_run_cell app.shell.run_cellelse old_run_cell app.run_celldef my_run_cell cell *args **kwargs try ast.parse cell except SyntaxError passelse cell int_to_Integer cell old_run_cell cell *args **kwargs if hasshell app.shell.run_cell my_run_cellelse app.run_cell my_run_cell
def append_path oldpath newpath if oldpath return oldpath + ' ' + newpath else return newpath
def delete_dict match skey get_key __opts__ return skey.delete_key match_dict match
def test_install_from_wheel_gen_uppercase_entrypoint script data result script.pip 'install' 'console-scripts-uppercase 1.0' '--no-index' '--find-links ' + data.find_links expect_error False if os.name 'nt' wrapper_file script.bin / 'cmdName.exe' else wrapper_file script.bin / 'cmdName' assert wrapper_file in result.files_created if os.name ! 'nt' assert bool os.access script.base_path / wrapper_file os.X_OK
def xhtml_to_html xhtml try xhtml xhtml.getroot except AttributeError passprefix '{%s}' % XHTML_NAMESPACE prefix_len len prefix for el in xhtml.iter prefix + '*' el.tag el.tag[prefix_len ]
def name2unicode name if name in glyphname2unicode return glyphname2unicode[name]m STRIP_NAME.search name if not m raise KeyError name return unichr int m.group 0
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def traceroute6 target dport 80 minttl 1 maxttl 30 sport RandShort l4 None timeout 2 verbose None **kargs if verbose is None verbose conf.verbif l4 is None a b sr IPv6 dst target hlim minttl maxttl / TCP seq RandInt sport sport dport dport timeout timeout filter 'icmp6ortcp' verbose verbose **kargs else a b sr IPv6 dst target hlim minttl maxttl / l4 timeout timeout verbose verbose **kargs a TracerouteResult6 a.res if verbose a.display return a b
def retry_before_failing retries NO_RETRIES return retry exception AssertionError timeout None retries retries
def is_like_list model_or_instance relationname if not inspect.isclass model_or_instance model get_model model_or_instance else model model_or_instancemapper sqlalchemy_inspect model relation mapper.all_orm_descriptors[relationname]if isinstance relation AssociationProxy relation relation.local_attrreturn relation.property.uselist
def p_declarator_1 t pass
def bitmap2RRlist bitmap RRlist []while bitmap if len bitmap < 2 warning 'bitmaptooshort %i ' % len bitmap returnwindow_block ord bitmap[0] offset 256 * window_block bitmap_len ord bitmap[1] if bitmap_len < 0 or bitmap_len > 32 warning 'bitmaplengthisnovalid %i ' % bitmap_len returntmp_bitmap bitmap[2 2 + bitmap_len ]for b in xrange len tmp_bitmap v 128for i in xrange 8 if ord tmp_bitmap[b] & v RRlist + [ offset + b * 8 + i ]v v >> 1 bitmap bitmap[ 2 + bitmap_len ]return RRlist
def _add_dnsmasq_accept_rules dev table iptables_manager.ipv4['filter']for port in [67 53] for proto in ['udp' 'tcp'] args {'dev' dev 'port' port 'proto' proto}table.add_rule 'INPUT' '-i% dev s-p% proto s-m% proto s--dport% port s-jACCEPT' % args iptables_manager.apply
def project_pifacc_opts T current.Treturn {1 T 'PIFACC-1 ImplementingTangible On-GroundAdaptationMeasures' 2 T 'PIFACC-2 GovernanceandDecisionMaking' 3 T 'PIFACC-3 Improvingourunderstandingofclimatechange' 4 T 'PIFACC-4 Education TrainingandAwareness' 5 T 'PIFACC-5 MitigationofGlobalGreenhouseGasEmissions' 6 T 'PIFACC-6 PartnershipsandCooperation' }
def differential_evolution func bounds args strategy 'best1bin' maxiter 1000 popsize 15 tol 0.01 mutation 0.5 1 recombination 0.7 seed None callback None disp False polish True init 'latinhypercube' atol 0 solver DifferentialEvolutionSolver func bounds args args strategy strategy maxiter maxiter popsize popsize tol tol mutation mutation recombination recombination seed seed polish polish callback callback disp disp init init atol atol return solver.solve
def symmetric_encrypt encrypt_key plaintext return binascii.hexlify encrypt_key.Encrypt plaintext .upper
def interval_encode seconds include_sign False s ''orig secondsseconds abs seconds for char amount in timeOrdered if seconds > amount i seconds divmod seconds amount s + '%i%s' % i char if orig < 0 s '-' + s elif not orig return '0'elif include_sign s '+' + s return s
def onlyPy2 test @functools.wraps test def wrapper *args **kwargs msg '{name}requiresPython2.xtorun'.format name test.__name__ if six.PY3 raise SkipTest msg return test *args **kwargs return wrapper
def ng_model_options request return {u'EDITCART_NG_MODEL_OPTIONS' app_settings.EDITCART_NG_MODEL_OPTIONS u'ADD2CART_NG_MODEL_OPTIONS' app_settings.ADD2CART_NG_MODEL_OPTIONS}
def clique graph id if isinstance id Node id id.ida [id]for n in graph.nodes try next id for id in a if n.id id or graph.edge n.id id is None except StopIteration a.append n.id return a
def _extract_member self member targetpath pwd if targetpath[ -1 ] in os.path.sep os.path.altsep and len os.path.splitdrive targetpath [1] > 1 targetpath targetpath[ -1 ]if member.filename[0] '/' targetpath os.path.join targetpath member.filename[1 ] else targetpath os.path.join targetpath member.filename targetpath os.path.normpath targetpath upperdirs os.path.dirname targetpath if upperdirs and not os.path.exists upperdirs os.makedirs upperdirs if member.filename[ -1 ] '/' if not os.path.isdir targetpath os.mkdir targetpath return targetpath_extract_from_zip self member.filename targetpath return targetpath
def csv_validator optdict name value return optik_ext.check_csv None name value
def traverse obj opts visitors return traverse_using iterate obj opts obj visitors
def _validateSetting value policy log.debug 'validating{0}forpolicy{1}'.format value policy if 'Settings' in policy if policy['Settings'] if isinstance policy['Settings'] list if value not in policy['Settings'] return Falseelif isinstance policy['Settings'] dict _policydata _policy_info if not getattr _policydata policy['Settings']['Function'] value **policy['Settings']['Args'] return Falseelse return Truereturn True
def one_file_or_folder folder if os.path.exists folder and os.path.isdir folder cont os.listdir folder if len cont 1 folder os.path.join folder cont[0] folder one_file_or_folder folder return folder
def parse_unified_diff_output lines adds []removes []for line in lines if len line > 2 and line[ 3] '+++' or line[ 3] '---' continueelif len line > 1 and line[ 2] '@@' continueelif len line > 0 and line[0] '+' added_line line[1 ].lstrip .rstrip if len added_line 0 continueadds adds + [added_line] elif len line > 0 and line[0] '-' removed_line line[1 ].lstrip .rstrip if len removed_line 0 continueremoves removes + [removed_line] return adds removes
def returner_doc *args returners_ salt.loader.returners __opts__ [] docs {}if not args for fun in returners_ docs[fun] returners_[fun].__doc__return _strip_rst docs for module in args _use_fnmatch Falseif '*' in module target_mod module_use_fnmatch Trueelif module target_mod module + '.' if not module.endswith '.' else module else target_mod ''if _use_fnmatch for fun in returners_ if fun module or fun.startswith target_mod docs[fun] returners_[fun].__doc__else for fun in six.iterkeys returners_ if fun module or fun.startswith target_mod docs[fun] returners_[fun].__doc__return _strip_rst docs
@_restore_ownershipdef create_key key_type 'RSA' key_length 1024 name_real 'AutogeneratedKey' name_comment 'GeneratedbySaltStack' name_email None subkey_type None subkey_length None expire_date None use_passphrase False user None gnupghome None ret {'res' True 'fingerprint' '' 'message' ''}create_params {'key_type' key_type 'key_length' key_length 'name_real' name_real 'name_comment' name_comment}gpg _create_gpg user gnupghome if name_email create_params['name_email'] name_emailif subkey_type create_params['subkey_type'] subkey_typeif subkey_length create_params['subkey_length'] subkey_lengthif expire_date create_params['expire_date'] expire_dateif use_passphrase gpg_passphrase __salt__['pillar.get'] 'gpg_passphrase' if not gpg_passphrase ret['res'] Falseret['message'] 'gpg_passphrasenotavailableinpillar.'return retelse create_params['passphrase'] gpg_passphraseinput_data gpg.gen_key_input **create_params key gpg.gen_key input_data if key.fingerprint ret['fingerprint'] key.fingerprintret['message'] 'GPGkeypairsuccessfullygenerated.'else ret['res'] Falseret['message'] 'UnabletogenerateGPGkeypair.'return ret
def _asFilesystemBytes path encoding None if type path bytes return pathelse if encoding is None encoding sys.getfilesystemencoding return path.encode encoding
def article2draft article draft Draft article._content article.metadata article.settings article.source_path article._context draft.status 'draft'return draft
def _prep_label_split label subject None subjects_dir None if isinstance label BiHemiLabel raise TypeError 'Canonlysplitlabelsrestrictedtoonehemisphere.' elif isinstance label string_types label read_label label subjects_dir get_subjects_dir subjects_dir raise_error True if label.subject is None and subject is None raise ValueError 'Thesubjectneedstobespecified.' elif subject is None subject label.subjectelif label.subject is None passelif subject ! label.subject raise ValueError 'Thelabelspecifiesadifferentsubject %r fromthesubjectparameter %r .' % label.subject subject return label subject subjects_dir
def assert_true expr msg 'FalseisnotTrue' if not expr raise AssertionError msg
def check_increasing x y rho _ spearmanr x y increasing_bool rho > 0 if rho not in [ -1.0 1.0] F 0.5 * math.log 1.0 + rho / 1.0 - rho F_se 1 / math.sqrt len x - 3 rho_0 math.tanh F - 1.96 * F_se rho_1 math.tanh F + 1.96 * F_se if np.sign rho_0 ! np.sign rho_1 warnings.warn 'ConfidenceintervaloftheSpearmancorrelationcoefficientspanszero.Determinationof``increasing``maybesuspect.' return increasing_bool
def get_conn vm_ get_configured_provider driver get_driver Provider.DIMENSIONDATA region config.get_cloud_config_value 'region' vm_ __opts__ user_id config.get_cloud_config_value 'user_id' vm_ __opts__ key config.get_cloud_config_value 'key' vm_ __opts__ if key is not None log.debug 'DimensionDataauthenticatingusingpassword' return driver user_id key region region
def unregister_ui review_ui if not issubclass review_ui FileAttachmentReviewUI raise TypeError u'OnlyFileAttachmentReviewUIsubclassescanbeunregistered' try _file_attachment_review_uis.remove review_ui except ValueError logging.error u'FailedtounregistermissingreviewUI%r' % review_ui raise ValueError u'ThisreviewUIwasnotpreviouslyregistered'
def degree_centrality G centrality {}s 1.0 / len G - 1.0 centrality {n d * s for n d in G.degree }return centrality
def update_collection_summary collection_id contributor_id_to_add create_collection_summary collection_id contributor_id_to_add
def generate_go_library target source env return _generate_go_package target source env
def get_hosts_mapped_with_segments context segment_host_mapping network.SegmentHostMapping.get_objects context return {row.host for row in segment_host_mapping}
def all_config_files user user_config_files if os.path.exists 'setup.cfg' return user + ['setup.cfg'] return user
def strips a b return rstrips lstrips a b b
def set_boot_arch arch 'default' if arch not in ['i386' 'x86_64' 'default'] msg 'Invalidvaluepassedforarch.\nMustbei386 x86_64 ordefault.\nPassed {0}'.format arch raise SaltInvocationError msg cmd 'systemsetup-setkernelbootarchitecture{0}'.format arch salt.utils.mac_utils.execute_return_success cmd return salt.utils.mac_utils.confirm_updated arch get_boot_arch
def modify_host id **data rpc_utils.check_modify_host data host models.Host.smart_get id rpc_utils.check_modify_host_locking host data host.update_object data
def _define_nrt_unresolved_abort ctx module fnty ctx.call_conv.get_function_type types.none fn ir.Function module fnty name 'nrt_unresolved_abort' bb fn.append_basic_block builder ir.IRBuilder bb msg 'numbajittedfunctionabortedduetounresolvedsymbol'ctx.call_conv.return_user_exc builder RuntimeError msg return fn
def preprocess_args fun varnames def wrapper f *a **kw if hasattr f 'func_code' func_code f.func_codeelse func_code f.__code__names func_code.co_varnamesnew_a [ fun arg if name in varnames else arg for arg name in zip a names ]new_kw {k fun v if k in varnames else v for k v in kw.items }return f *new_a **new_kw return decorator.decorator wrapper
@task_postrun.connectdef clear_request_cache **kwargs middleware.RequestCache.clear_request_cache
def _nose_tools_trivial_transform stub _BUILDER.string_build '__all__ []' all_entries ['ok_' 'eq_']for pep8_name method in _nose_tools_functions all_entries.append pep8_name stub[pep8_name] methodall_assign stub['__all__'].parentall_object astroid.List all_entries all_object.parent all_assignall_assign.value all_objectreturn stub
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def _report_lines msgs return '' + '\n'.join str msg for msg in msgs
def print_version option opt value parser parser.print_version sys.exit 0
def create_instance context user_id 'fake' project_id 'fake' params None flavor flavors.get_flavor_by_name 'm1.tiny' net_info model.NetworkInfo [] info_cache objects.InstanceInfoCache network_info net_info inst objects.Instance context context image_ref uuids.fake_image_ref reservation_id 'r-fakeres' user_id user_id project_id project_id instance_type_id flavor.id flavor flavor old_flavor None new_flavor None system_metadata {} ami_launch_index 0 root_gb 0 ephemeral_gb 0 info_cache info_cache if params inst.update params inst.create return inst
def _cov X shrinkage None shrinkage 'empirical' if shrinkage is None else shrinkage if isinstance shrinkage string_types if shrinkage 'auto' sc StandardScaler X sc.fit_transform X s ledoit_wolf X [0]s sc.scale_[ np.newaxis] * s * sc.scale_[np.newaxis ] elif shrinkage 'empirical' s empirical_covariance X else raise ValueError 'unknownshrinkageparameter' elif isinstance shrinkage float or isinstance shrinkage int if shrinkage < 0 or shrinkage > 1 raise ValueError 'shrinkageparametermustbebetween0and1' s shrunk_covariance empirical_covariance X shrinkage else raise TypeError 'shrinkagemustbeofstringorinttype' return s
def local_mean img size 3 structure_element np.ones size size dtype img.dtype l_mean signal.correlate img structure_element mode 'same' l_mean / size ** 2 return l_mean
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def version profile 'default' cmd {'cmd' 'version' 'mime' 'prop'}return _do_http cmd profile ['worker.jk_version'].split '/' [ -1 ]
def __handle_except inst return __standardize_result False 'Docker-composecommand{0}failed'.format inspect.stack [1][3] '{0}'.format inst None
def _spawn script outputFD pyExe FilePath sys.executable .asBytesMode .pathenv bytesEnviron env['PYTHONPATH'] FilePath pathsep.join sys.path .asBytesMode .pathsspp StartStopProcessProtocol reactor.spawnProcess sspp pyExe [pyExe FilePath __file__ .sibling script + '.py' .asBytesMode .path intToBytes outputFD ] env env childFDs {0 'w' 1 'r' 2 'r' outputFD outputFD} return sspp
def locatedExpr expr locator Empty .setParseAction lambda s l t l return Group locator 'locn_start' + expr 'value' + locator.copy .leaveWhitespace 'locn_end'
def update_plex host port token library_name section_key get_music_section host port token library_name api_endpoint 'library/sections/{0}/refresh'.format section_key api_endpoint append_token api_endpoint token url urljoin 'http //{0} {1}'.format host port api_endpoint r requests.get url return r
@utils.arg 'server' metavar '<server>' help _ 'NameorUUIDoftheservertoshowactionsfor.' start_version '2.0' end_version '2.20' @utils.arg 'server' metavar '<server>' help _ 'NameorUUIDoftheservertoshowactionsfor.OnlyUUIDcanbeusedtoshowactionsforadeletedserver.' start_version '2.21' @utils.arg 'request_id' metavar '<request_id>' help _ 'RequestIDoftheactiontoget.' def do_instance_action cs args if cs.api_version < api_versions.APIVersion '2.21' server _find_server cs args.server else server _find_server cs args.server raise_if_notfound False action_resource cs.instance_action.get server args.request_id action action_resource.to_dict if 'events' in action action['events'] pprint.pformat action['events'] utils.print_dict action
def prohibit_output data tables None for char in data for check in tables if check char raise StringPrepError u'Prohibitedcodepoint %s' % char
def setlocal name value global_dict local_dict get_twill_glocals local_dict[name] value
def convert_equals_signs result local_dict global_dict for step in _group_parentheses convert_equals_signs _apply_functions _transform_equals_sign result step result local_dict global_dict result _flatten result return result
def skip_if_ABSTFN_contains_backslash test found_backslash '\\' in ABSTFN msg 'ABSTFNisnotaposixpath-testsfail'return [test unittest.skip msg test ][found_backslash]
def test_project_update_role_points project f.ProjectFactory.create related_role f.RoleFactory.create project project computable True null_points f.PointsFactory.create project project value None user_story f.UserStoryFactory project project new_related_role f.RoleFactory.create project project computable True assert user_story.role_points.count 1 assert user_story.role_points.filter role new_related_role points null_points .count 0 project.update_role_points assert user_story.role_points.count 2 assert user_story.role_points.filter role new_related_role points null_points .count 1
def gf_lshift f n K if not f return felse return f + [K.zero] * n
def pred_probs f_log_probs options worddict prepare_data data iterator verbose False n_samples len data[0] probs numpy.zeros n_samples 1 .astype 'float32' n_done 0for _ valid_index in iterator x mask ctx prepare_data [data[0][t] for t in valid_index] data[1] worddict maxlen None n_words options['n_words'] pred_probs f_log_probs x mask ctx probs[valid_index] pred_probs[ None]n_done + len valid_index if verbose print '%d/%dsamplescomputed' % n_done n_samples return probs
def pretty_hex ip length 8 hexval '%x' % ip.value if len hexval < length hexval '0' * length - len hexval + hexval return hexval.upper
def fake_uname return 'Linux' '' '' '' ''
def test_ast_good_yield can_compile u' yield1 '
def test_backspace_and_delete superConsole.SendKeys 'outputRedirectStart{ }True{ }{ENTER}' testRegex ''superConsole.SendKeys "print'IQ{BACKSPACE}P'{ENTER}" testRegex + 'IP'superConsole.SendKeys "print'FW'{LEFT}{LEFT}{DELETE}X{ENTER}" testRegex + 'FX'superConsole.SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex
def returns model downgrade None upgrade None return attrsetter '_returns' model downgrade upgrade
def _generateEventID global _nextEventID_nextEventID + 1return _nextEventID
def in_main_thread return threading.current_thread .__class__.__name__ u'_MainThread'
def __patch__init__ self edgecolor None facecolor None linewidth None linestyle None antialiased None hatch None fill True **kwargs artist.Artist.__init__ self if linewidth is None linewidth mpl.rcParams['patch.linewidth']if linestyle is None linestyle 'solid'if antialiased is None antialiased mpl.rcParams['patch.antialiased']self.set_edgecolor edgecolor self.set_facecolor facecolor self.set_linewidth linewidth self.set_linestyle linestyle self.set_antialiased antialiased self.set_hatch hatch self.fill fillself._combined_transform transforms.IdentityTransform if len kwargs artist.setp self **kwargs
def blaze_loader alias if alias not in ['DSC' 'DSK'] returnimport pyamf.flex.messagingreturn CLASS_CACHE[alias]
def list_dbs **client_args client _client **client_args return client.get_list_database
def some_function input input np.asarray input output fortran_module.some_function input.ravel return output.reshape input.shape
def create_database if DBDRIVER in ['sqlite3'] global TESTDBif os.path.exists TESTDB try os.remove TESTDB except time.sleep 1 try os.remove TESTDB except Exception print 'Couldnotremove%r' % TESTDB passTESTDB temp_db_filename else _do_db_create server BioSeqDatabase.open_database driver DBDRIVER user DBUSER passwd DBPASSWD host DBHOST db TESTDB try server.load_database_sql SQL_FILE server.commit server.close except server.close raisereturn TESTDB
def copy_parser_result parser_result if type parser_result is list return [ParserTestResult test for test in parser_result]elif isinstance parser_result Exception return ParserException parser_result else raise UnsupportedParserResultError
def is_event_loop_running app None if app is None app init_qtapp if hasattr app '_in_event_loop' return app._in_event_loopelse return False
def commands out []for plugin in find_plugins out + plugin.commands return out
def settings_module module os.environ['DJANGO_SETTINGS_MODULE'] module
def case_activity def prep r resource r.resourcelist_fields ['case_id$reference' 'person_id$first_name' 'person_id$last_name' 'need_id' 'need_details' 'emergency' 'referral_details' 'followup' 'followup_date' 'completed']resource.configure list_fields list_fields insertable False deletable False return Trues3.prep prepreturn s3_rest_controller
def get_real_func obj while hasattr obj '__wrapped__' obj obj.__wrapped__if isinstance obj functools.partial obj obj.funcreturn obj
def test_kmr_matrix print __name__ + '.' + test_kmr_matrix.__name__ matrices Matrices for matrix_dict in matrices.kmr_matrix_dicts x gth_solve matrix_dict['A'] yield StationaryDistSumOne x yield StationaryDistNonnegative x yield StationaryDistLeftEigenVec matrix_dict['A'] x
def verify_expected_problem_visibility test courseware_page expected_problems test.assertEqual len expected_problems courseware_page.num_xblock_components 'Incorrectnumberofvisibleproblems' for index expected_problem in enumerate expected_problems test.assertIn expected_problem courseware_page.xblock_components[index].text
def _check_discrete_args at method if method in ['dyex' 'eyex'] raise ValueError '%snotallowedfordiscretevariables' % method if at in ['median' 'zero'] raise ValueError '%snotallowedfordiscretevariables' % at
def permuteToBlocks arr blockshape if len blockshape < 2 raise ValueError 'Needmorethanonedimension.' elif len blockshape 2 blockheight blockwidth blockshapereturn permuteToBlocks2d arr blockheight blockwidth elif len blockshape 3 blockdepth blockheight blockwidth blockshapereturn permuteToBlocks3d arr blockdepth blockheight blockwidth else raise NotImplementedError 'Onlyfordimensions2and3.'
def _point_cloud_error_balltree src_pts tgt_tree dist _ tgt_tree.query src_pts return dist.ravel
def get_cache_limit if sabnzbd.WIN32 or sabnzbd.DARWIN return DEF_CACHE_LIMITtry mem_bytes os.sysconf 'SC_PAGE_SIZE' * os.sysconf 'SC_PHYS_PAGES' / 4 if mem_bytes > from_units DEF_CACHE_LIMIT return DEF_CACHE_LIMITelif mem_bytes > from_units '32M' return to_units mem_bytes except passreturn ''
def register_and_login client username password register client username password return login client username password
def build_urls base appendages urls [base]for i in range len appendages urls.append base + ''.join appendages[ i + 1 ] return urls
def get_data_file pkg path return io.BytesIO pkgutil.get_data pkg path
def _spectrogram x fs 1.0 window 'tukey' 0.25 nperseg 256 noverlap None nfft None detrend 'constant' return_onesided True scaling 'density' axis -1 mode 'psd' if noverlap is None noverlap nperseg // 8 freqs time Pxy _spectral_helper x x fs window nperseg noverlap nfft detrend return_onesided scaling axis mode mode return freqs time Pxy
def mkrefs *objs allObjs {}for obj in objs if isinstance obj pg.QtCore.QObject obj qObjectTree obj else obj [obj]for o in obj allObjs[id o ] oreturn map weakref.ref allObjs.values
def prep_for_freeze model fields modelsinspector.get_model_fields model m2m True for name field in fields.items fields[name] remove_useless_attributes field fields['Meta'] remove_useless_meta modelsinspector.get_model_meta model fields['Meta']['object_name'] model._meta.object_nameif not getattr model._meta 'managed' True fields['Meta']['managed'] repr model._meta.managed return fields
def current_games year None week None kind 'REG' if year is None or week is None year week current_year_and_week guesses []now _now games _games_in_week year week kind kind for info in games gametime _game_datetime info if gametime > now if gametime - now .total_seconds < 60 * 15 guesses.append info['eid'] elif now - gametime .total_seconds < _MAX_GAME_TIME guesses.append info['eid'] current []for guess in guesses game nflgame.game.Game guess if game is not None and game.playing current.append game return current
def preprocess_release f open 'app.yaml' 'r' content f.read os.remove 'app.yaml' content content.replace 'oppiaserver' APP_NAME d open 'app.yaml' 'w+' d.write content
def list_security_group_rules profile None conn _auth profile return conn.list_security_group_rules
def _symbolic_factor expr opt method if isinstance expr Expr and not expr.is_Relational if hasattr expr '_eval_factor' return expr._eval_factor coeff factors _symbolic_factor_list together expr opt method return _keep_coeff coeff _factors_product factors elif hasattr expr 'args' return expr.func *[_symbolic_factor arg opt method for arg in expr.args] elif hasattr expr '__iter__' return expr.__class__ [_symbolic_factor arg opt method for arg in expr] else return expr
def windowposition folder pos None fsr Carbon.File.FSRef folder folder_alias fsr.FSNewAliasMinimal openwindow fsr if not pos return _getwindowposition folder_alias if type pos InstanceType pos pos.h pos.v return _setwindowposition folder_alias pos
def Xor string key return ''.join [chr c ^ key for c in bytearray string ]
def inplace_allocempty op idx def wrapper maker @local_optimizer [op] inplace True @wraps maker def opt node if type node.op ! op or node.op.inplace returninputs list node.inputs alloc inputs[idx]if alloc.owner and isinstance alloc.owner.op GpuAllocEmpty and len alloc.clients > 1 alloc_op gpu_alloc_empty alloc.owner.op.context_name dtype alloc.owner.op.dtype inputs[idx] alloc_op *alloc.owner.inputs return maker node inputs return optreturn wrapper
def directories_equal directory1 directory2 def compare_dirs dir1 dir2 'Comparedirectoriesforequality.'comparison filecmp.dircmp dir1 dir2 if len comparison.left_only > 0 or len comparison.right_only > 0 return Falseif len comparison.funny_files > 0 or len comparison.diff_files > 0 return Falsefor subdir in comparison.subdirs if not compare_dirs dir1 / subdir dir2 / subdir return Falsereturn Truereturn compare_dirs path directory1 path directory2
def hbox margin spacing *items return box QtWidgets.QHBoxLayout margin spacing *items
def test_commented_csv t ascii.read ['#a b' '1 2' '#3 4'] format 'csv' assert t.colnames ['#a' 'b'] assert len t 2 assert t['#a'][1] '#3'
def _sunos_cpudata grains {}grains['cpu_flags'] []grains['cpuarch'] __salt__['cmd.run'] 'isainfo-k' psrinfo '/usr/sbin/psrinfo2>/dev/null'grains['num_cpus'] len __salt__['cmd.run'] psrinfo python_shell True .splitlines kstat_info 'kstat-pcpu_info * * brand'for line in __salt__['cmd.run'] kstat_info .splitlines match re.match ' \\w+ \\d+ \\w+\\d+ \\w+ \\s+ .+ ' line if match grains['cpu_model'] match.group 2 isainfo 'isainfo-n-v'for line in __salt__['cmd.run'] isainfo .splitlines match re.match '^\\s+ .+ ' line if match cpu_flags match.group 1 .split grains['cpu_flags'].extend cpu_flags return grains
def todate somedate if isinstance somedate datetime return date somedate.year somedate.month somedate.day assert isinstance somedate date DateTimeType repr somedate return somedate
def test_str_repr_call_info monkeypatch monkeypatch.setenv 'AWS_REGION' 'us-east-1' cinfo calling_format.from_store_name 'hello-world' assert repr cinfo str cinfo assert repr cinfo "CallingInfo hello-world <class'boto.s3.connection.SubdomainCallingFormat'> 'us-east-1' None " cinfo calling_format.from_store_name 'hello.world' assert repr cinfo str cinfo assert repr cinfo "CallingInfo hello.world <class'boto.s3.connection.OrdinaryCallingFormat'> 'us-east-1' 's3.amazonaws.com' " cinfo calling_format.from_store_name 'Hello-World' assert repr cinfo str cinfo assert repr cinfo "CallingInfo Hello-World <class'boto.s3.connection.OrdinaryCallingFormat'> 'us-east-1' 's3.amazonaws.com' "
def checkSuhosinPatch injection if injection.place PLACE.GET debugMsg 'checkingforparameterlength'debugMsg + 'constraintingmechanisms'logger.debug debugMsg pushValue kb.injection kb.injection injectionrandInt randomInt if not checkBooleanExpression '%d %s%d' % randInt '' * SUHOSIN_MAX_VALUE_LENGTH randInt warnMsg 'parameterlengthconstrainting'warnMsg + 'mechanismdetected e.g.Suhosinpatch .'warnMsg + 'Potentialproblemsinenumerationphasecanbeexpected'logger.warn warnMsg kb.injection popValue
def app_backup storage full_bucket_name None if not makedirs APP_BACKUP_DIR_LOCATION logging.warning "Dir'{0}'alreadyexists.Skippingdircreation...".format APP_BACKUP_DIR_LOCATION for dir_path _ filenames in os.walk APP_DIR_LOCATION for filename in filenames source '{0}/{1}'.format dir_path filename destination '{0}/{1}'.format APP_BACKUP_DIR_LOCATION filename try shutil.copy source destination except Exception logging.error "Errorwhilebackingup'{0}'.".format source delete_app_tars APP_BACKUP_DIR_LOCATION return Falseif storage StorageTypes.GCS source '{0}/{1}'.format APP_DIR_LOCATION filename destination '{0}/apps/{1}'.format full_bucket_name filename logging.debug 'Destination {0}'.format destination if not gcs_helper.upload_to_bucket destination source logging.error "Errorwhileuploading'{0}'toGCS.".format source delete_app_tars APP_BACKUP_DIR_LOCATION return Falsereturn True
@receiver post_compress def update_angular_template_hash sender **kwargs context kwargs['context']compressed context['compressed']compressed_name compressed['name']if compressed_name 'angular_template_cache_preloads' cache caches['default']theme context['THEME']key make_template_fragment_key 'angular' ['template_cache_preloads' theme] if cache.get key cache.delete key
def isPixelTableIntersecting bigTable littleTable maskTable {} littleTableKeys littleTable.keys for littleTableKey in littleTableKeys if littleTableKey not in maskTable if littleTableKey in bigTable return Truereturn False
def exception_from_error_queue exception_type errors []while True error lib.ERR_get_error if error 0 breakerrors.append text lib.ERR_lib_error_string error text lib.ERR_func_error_string error text lib.ERR_reason_error_string error raise exception_type errors
def test_dirichlet_expectation x np.logspace -100 10 10000 expectation np.empty_like x _dirichlet_expectation_1d x 0 expectation assert_allclose expectation np.exp psi x - psi np.sum x atol 1e-19 x x.reshape 100 100 assert_allclose _dirichlet_expectation_2d x psi x - psi np.sum x axis 1 [ np.newaxis] rtol 1e-11 atol 3e-09
def get_default_locale_callable exec_dir os.path.dirname os.path.realpath __file__ xml_path os.path.join exec_dir 'data' 'FacebookLocales.xml' fb_locales _build_locale_table xml_path def default_locale request "\nGuessanappropiateFBlocalebasedontheactiveDjangolocale.\nIftheactivelocaleisavailable itisreturned.Otherwise \nittriestoreturnanotherlocalewiththesamelanguage.Ifthere\nisn'toneavaible 'en_US'isreturned.\n"chosen 'en_US'language get_language if language locale to_locale language lang _ reg locale.partition '_' lang_map fb_locales.get lang if lang_map is not None if reg in lang_map['regs'] chosen lang + '_' + reg else chosen lang + '_' + lang_map['default'] return chosenreturn default_locale
def test_stacked_line stacked StackedLine stacked.add 'one_two' [1 2] stacked.add 'ten_twelve' [10 12] q stacked.render_pyquery assert set [v.text for v in q 'desc.value' ] set '1' '2' '11 +10 ' '14 +12 '
def test_metaclass_call_override class mytype type def __call__ self *args return argsclass myclass object __metaclass__ mytypeAreEqual myclass 1 2 3 1 2 3
def getRMScontrast matrix matrix matrix.flatRMScontrast sum matrix - numpy.mean matrix ** 2 / len matrix ** 0.5 return RMScontrast
@when u'wedroptable' def step_drop_table context context.cli.sendline u'droptablea;'
def Object theType offset vm name None **kwargs name name or theType offset int offset try if vm.profile.has_type theType result vm.profile.types[theType] offset offset vm vm name name **kwargs return resultexcept InvalidOffsetError return NoneObject 'InvalidAddress0x{0 08X} instantiating{1}'.format offset name strict vm.profile.strict debug.warning 'Cantfindobject{0}inprofile{1}?'.format theType vm.profile
def set_auth_key_from_file user source config '.ssh/authorized_keys' saltenv 'base' lfile __salt__['cp.cache_file'] source saltenv if not os.path.isfile lfile raise CommandExecutionError 'Failedtopullkeyfilefromsaltfileserver' s_keys _validate_keys lfile if not s_keys err 'Nokeysdetectedin{0}.Isfileproperlyformatted?'.format source log.error err __context__['ssh_auth.error'] errreturn 'fail'else rval ''for key in s_keys rval + set_auth_key user key s_keys[key]['enc'] s_keys[key]['comment'] s_keys[key]['options'] config list s_keys.keys if 'fail' in rval return 'fail'elif 'replace' in rval return 'replace'elif 'new' in rval return 'new'else return 'nochange'
def get_command_from_state state command Noneif state 'present' command 'vrouter-ospf-add'if state 'absent' command 'vrouter-ospf-remove'return command
def test_utf8 data jinja.render 'test.html' var '\\u2603' assert data 'Hello\\u2603'
def libvlc_media_list_lock p_ml f _Cfunctions.get 'libvlc_media_list_lock' None or _Cfunction 'libvlc_media_list_lock' 1 None None MediaList return f p_ml
def sparse_categorical_crossentropy y_true y_pred y_true tf.cast y_true tf.int64 y_pred logit tf.cast y_pred tf.float32 return tf.reduce_mean tf.nn.sparse_softmax_cross_entropy_with_logits y_pred y_true
@pytest.mark.parametrize u'poly' [Chebyshev2D 1 2 Polynomial2D 2 Legendre2D 1 2 Chebyshev1D 5 Legendre1D 5 Polynomial1D 5 ] def test_compound_with_polynomials poly poly.parameters [1 2 3 4 1 2]shift Shift 3 model poly | shift x y np.mgrid[ 20 37]result_compound model x y result shift poly x y assert_allclose result result_compound
def parse_actor_and_date line actor epoch offset '' 0 0 m _re_actor_epoch.search line if m actor epoch offset m.groups else m _re_only_actor.search line actor m.group 1 if m else line or '' return Actor._from_string actor int epoch utctz_to_altz offset
def eq name value ret {'name' name 'result' False 'comment' '' 'changes' {}}if name not in __reg__ ret['result'] Falseret['comment'] 'Value{0}notinregister'.format name return retif __reg__[name]['val'] value ret['result'] Truereturn ret
def test_scenarios_parsed_by_feature_has_feature feature Feature.from_string FEATURE2 for scenario in feature.scenarios assert_equals scenario.feature feature
def batch_iterator_valid data_test y_test batchsize valid_fn n_samples_valid data_test.shape[0]loss_valid []acc_valid []for i in range n_samples_valid + batchsize - 1 // batchsize sl slice i * batchsize i + 1 * batchsize X_batch_test data_test[sl]y_batch_test y_test[sl] loss_vv acc_vv valid_fn X_batch_test y_batch_test loss_valid.append loss_vv acc_valid.append acc_vv return np.mean loss_valid np.mean acc_valid
def remHook hook func hook _hooks.get hook [] if func in hook hook.remove func
def _equalsIgnoreCase a b return a b or string.lower a string.lower b
def find_igw vpc_conn vpc_id igw vpc_conn.get_all_internet_gateways filters {'attachment.vpc-id' vpc_id} if not igw raise AnsibleIgwSearchException 'NoIGWfoundforVPC{0}'.format vpc_id elif len igw 1 return igw[0].idelse raise AnsibleIgwSearchException 'MultipleIGWsfoundforVPC{0}'.format vpc_id
def load_cert *names loader _guess_loader names[ -1 ] OpenSSL.crypto.FILETYPE_PEM OpenSSL.crypto.FILETYPE_ASN1 return OpenSSL.crypto.load_certificate loader load_vector *names
def OutRbrace DedentLevel Output '}'
def test_iqr a np.arange 5 iqr utils.iqr a assert_equal iqr 2
def getNormalAverage normals if len normals < 2 return normals[0]return normals[0] + normals[1] .getNormalized
def validate_autoaccept val if val 1 raise ValidationError _ 'Valueof1isnotallowedforautoacceptaseveryusergivesvotetohissuggestion.'
def _volume_field return field type BlockDeviceVolume mandatory True factory lambda x x
def adapt_choice_f choice_f result lambda ids seqs 'ignored' choice_f ids return result
@with_setup step_runner_environ def test_behave_as_step_can_access_the_scenario @step '[^"]accessthescenario' def access_the_scenario step assert_equal step.scenario.name 'TheOriginalScenario' try f Feature.from_string FEATURE9 feature_result f.run assert feature_result.passed 'Thescenariopassedtothebehave_asstepdidnotmatch'finally registry.clear
def f1_score y_real y_pred return fbeta_score y_real y_pred 1
def testtextextraction document opendocx TEST_FILE paratextlist getdocumenttext document assert len paratextlist > 0
@login_requireddef favorite req subject id if subject 'document' obj get_object_or_404 Document pk id elif subject 'map' obj get_object_or_404 Map pk id elif subject 'layer' obj get_object_or_404 Layer pk id elif subject 'user' obj get_object_or_404 settings.AUTH_USER_MODEL pk id favorite models.Favorite.objects.create_favorite obj req.user delete_url reverse 'delete_favorite' args [favorite.pk] response {'has_favorite' 'true' 'delete_url' delete_url}return HttpResponse json.dumps response content_type 'application/json' status 200
def deserialize_key_value value secret False if secret KeyValuePairAPI._setup_crypto value symmetric_decrypt KeyValuePairAPI.crypto_key value return value
def _aggr_mode inList valueCounts dict nonNone 0for elem in inList if elem SENTINEL_VALUE_FOR_MISSING_DATA continuenonNone + 1if elem in valueCounts valueCounts[elem] + 1else valueCounts[elem] 1if nonNone 0 return NonesortedCounts valueCounts.items sortedCounts.sort cmp lambda x y x[1] - y[1] reverse True return sortedCounts[0][0]
def hydrate_sources sources_field source_files_digest excluded_source_files fileset_with_spec _eager_fileset_with_spec sources_field.address.spec_path sources_field.filespecs source_files_digest excluded_source_files return HydratedField sources_field.arg fileset_with_spec
def in6_isaddrTeredo x our inet_pton socket.AF_INET6 x [0 4]teredoPrefix inet_pton socket.AF_INET6 conf.teredoPrefix [0 4]return teredoPrefix our
def _decode_options packet buff start_idx packet['options'] {}idx start_idxwhile idx < len buff option idx _get_string buff idx value idx _get_string buff idx if option '' raise InvalidPacketException u'Emptyoption' if value '' raise InvalidPacketException u'Emptyvalueforoption[%s]' % repr option packet['options'][option] valuefor k v in packet['options'].items if k not in OPTIONS raise InvalidOptionException u'Unknownoption[%s]' % repr k try if k in 'blksize' 'timeout' 'tsize' packet['options'][k] int v else packet['options'][k] vexcept ValueError raise InvalidOptionException u'Invalidvalueforoption%s %s' % repr k repr v
@processor_for Category exact_page True def category_processor request page settings.clear_cache products Product.objects.published for_user request.user .filter page.category.filters .distinct sort_options [ slugify option[0] option[1] for option in settings.SHOP_PRODUCT_SORT_OPTIONS]sort_by request.GET.get u'sort' sort_options[0][1] if sort_options else u'-date_added' products paginate products.order_by sort_by request.GET.get u'page' 1 settings.SHOP_PER_PAGE_CATEGORY settings.MAX_PAGING_LINKS products.sort_by sort_bysub_categories page.category.children.published child_categories Category.objects.filter id__in sub_categories return {u'products' products u'child_categories' child_categories}
def categorical_crossentropy coding_dist true_dist if true_dist.ndim coding_dist.ndim return - tensor.sum true_dist * tensor.log coding_dist axis coding_dist.ndim - 1 elif true_dist.ndim coding_dist.ndim - 1 return crossentropy_categorical_1hot coding_dist true_dist else raise TypeError 'rankmismatchbetweencodingandtruedistributions'
def translate_jobconf_dict jobconf hadoop_version None translated_jobconf jobconf.copy translation_warnings {}for variable value in jobconf.items if hadoop_version variants [translate_jobconf variable hadoop_version ]else variants translate_jobconf_for_all_versions variable for variant in variants if variant in jobconf continuetranslated_jobconf[variant] valueif hadoop_version translation_warnings[variable] variantif translation_warnings log.warning 'Detectedhadoopconfigurationpropertynamesthatdonotmatchhadoopversion%s \nThehavebeentranslatedasfollows\n%s' hadoop_version '\n'.join [ '%s %s' % variable variant for variable variant in sorted translation_warnings.items ] return translated_jobconf
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def randoms count alphabet string.lowercase return ''.join random.choice alphabet for _ in xrange count
def html_body input_string source_path None destination_path None input_encoding 'unicode' output_encoding 'unicode' doctitle 1 initial_header_level 1 parts html_parts input_string input_string source_path source_path destination_path destination_path input_encoding input_encoding doctitle doctitle initial_header_level initial_header_level fragment parts['html_body']if output_encoding ! 'unicode' fragment fragment.encode output_encoding return fragment
def _get_mods evt mods []mods + [keys.CONTROL] if evt.ControlDown else [] mods + [keys.ALT] if evt.AltDown else [] mods + [keys.SHIFT] if evt.ShiftDown else [] mods + [keys.META] if evt.MetaDown else [] return mods
def test_g0 from .. import g0assert g0.value 9.80665 assert g0.si.value 9.80665 assert g0.cgs.value 980.665 assert g0.uncertainty 0 assert g0.nameassert g0.referenceassert g0.unitassert g0.unit.physical_type u'acceleration'
def _url_for_read user_id return '{prefix}/users/{user_id}/read'.format prefix settings.PREFIX user_id user_id
def check_html html parser etree.HTMLParser try etree.fromstring html parser return Trueexcept Exception passreturn False
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def p_identifier_list_1 t pass
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates.get_loc kd overwrite_from_dates ad_series.loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name].iteritems }
def title s *args **kwargs return gca .set_title s *args **kwargs
def addRackHole derivation vector3RackProfiles x xmlElement rackHole euclidean.getComplexPolygon complex x - derivation.rackHoleBelow derivation.rackHoleRadius -13 vector3RackProfiles.append euclidean.getVector3Path rackHole
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def connect_action_bool action fn action.triggered[bool].connect fn
def normalize_path path resolve_symlinks True path expanduser path if resolve_symlinks path os.path.realpath path else path os.path.abspath path return os.path.normcase path
def remove_qos tenant_id qos_id session db.get_session try qos session.query network_models_v2.QoS .filter_by tenant_id tenant_id .filter_by qos_id qos_id .one session.delete qos session.flush return qosexcept exc.NoResultFound pass
def _get_feeds_dir lib dirpath lib.directoryif not os.path.exists syspath dirpath os.makedirs syspath dirpath return dirpath
def generate_age issue_time td datetime.datetime.now - issue_time age td.microseconds + td.seconds + td.days * 24 * 3600 * 10 ** 6 / 10 ** 6 return unicode_type age
def y1_zeros nt complex False if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'Argumentsmustbescalarpositiveinteger.' kf 1kc not complex return specfun.cyzo nt kf kc
def get url conn urlopen url resp conn.read conn.close return resp
def get_other_dvr_serviced_device_owners return [n_const.DEVICE_OWNER_LOADBALANCER n_const.DEVICE_OWNER_LOADBALANCERV2 n_const.DEVICE_OWNER_DHCP]
def _ansi_expand_style cmap for key val in list cmap.items if key 'NO_COLOR' continueelif len val 0 cmap[ 'BOLD_' + key ] '1'cmap[ 'UNDERLINE_' + key ] '4'cmap[ 'BOLD_UNDERLINE_' + key ] '1;4'cmap[ 'BACKGROUND_' + key ] valelse cmap[ 'BOLD_' + key ] '1;' + val cmap[ 'UNDERLINE_' + key ] '4;' + val cmap[ 'BOLD_UNDERLINE_' + key ] '1;4;' + val cmap[ 'BACKGROUND_' + key ] val.replace '38' '48' 1
def _AddPropertiesForNonRepeatedScalarField field cls proto_field_name field.nameproperty_name _PropertyName proto_field_name type_checker type_checkers.GetTypeChecker field default_value field.default_valuevalid_values set def getter self return self._fields.get field default_value getter.__module__ Nonegetter.__doc__ 'Getterfor%s.' % proto_field_name def setter self new_value self._fields[field] type_checker.CheckValue new_value if not self._cached_byte_size_dirty self._Modified setter.__module__ Nonesetter.__doc__ 'Setterfor%s.' % proto_field_name doc 'Magicattributegeneratedfor"%s"protofield.' % proto_field_name setattr cls property_name property getter setter doc doc
def test_grouped_copy T1 for masked in False True t1 Table T1 masked masked tg t1.group_by 'a' tgc tg.copy assert np.all tgc.groups.indices tg.groups.indices assert np.all tgc.groups.keys tg.groups.keys tac tg['a'].copy assert np.all tac.groups.indices tg['a'].groups.indices c1 t1['a'].copy gc1 c1.group_by t1['a'] gc1c gc1.copy assert np.all gc1c.groups.indices np.array [0 1 4 8]
def to_unicode value if not isinstance value six.string_types raise ValueError 'Value"%s"mustbeastring.' % value if not isinstance value six.text_type value six.u value return value
def _realize_padding it padding Nonefor item in it if isinstance item int padding max padding item continueif padding yield '\n' * padding padding None yield item
def filter_capabilities_by_languages bears languages languages set language.lower for language in languages language_bears_capabilities {language set set for language in languages}for section_bears in bears.values for bear in section_bears bear_language {language.lower for language in bear.LANGUAGES} | {'all'} & languages language bear_language.pop if bear_language else '' capabilities language_bears_capabilities[language] if language else tuple language_bears_capabilities.update {language capabilities[0] | bear.can_detect capabilities[1] | bear.CAN_FIX } if language else {} return language_bears_capabilities
def bench_optimizer optimizer param_grid return sum apply_optimizer optimizer func a b for func a b in param_grid
def nolog *allargs pass
@lru_cache def _call_fc_list timer Timer 5 lambda warnings.warn u'Matplotlibisbuildingthefontcacheusingfc-list.Thismaytakeamoment.' timer.start try out subprocess.check_output [str u'fc-list' u'--format %{file}\\n'] except OSError subprocess.CalledProcessError return []finally timer.cancel fnames []for fname in out.split '\n' try fname six.text_type fname sys.getfilesystemencoding except UnicodeDecodeError continuefnames.append fname return fnames
def tags repo_dir None tags {}for n c in list_refs repo_dir repo_dir limit_to_tags True assert n.startswith 'refs/tags/' name n[10 ]if not c in tags tags[c] []tags[c].append name return tags
def get_emboss_version child subprocess.Popen _escape_filename exes['embossversion'] stdout subprocess.PIPE stderr subprocess.STDOUT universal_newlines True shell sys.platform ! 'win32' stdout stderr child.communicate child.stdout.close del childassert stderr is None for line in stdout.split '\n' if line.strip 'ReportthecurrentEMBOSSversionnumber' passelif line.strip 'ReportsthecurrentEMBOSSversionnumber' passelif line.startswith 'WritesthecurrentEMBOSSversionnumber' passelif line.count '.' 2 return tuple int v for v in line.strip .split '.' elif line.count '.' 3 return tuple int v for v in line.strip .split '.' [ 3]else raise MissingExternalDependencyError 'InstallEMBOSSifyouwanttouseBio.Emboss %s .' % line raise MissingExternalDependencyError 'CouldnotgetEMBOSSversion'
def _read_event fid out {'event_name' read_str fid 16 'start_lat' read_float fid 'end_lat' read_float fid 'step_size' read_float fid 'fixed_event' read_int16 fid 'checksum' read_int32 fid }fid.seek 32 1 _correct_offset fid return out
def acls_from_account_info info acl parse_acl version 2 data info.get 'sysmeta' {} .get 'core-access-control' if acl is None return Noneadmin_members acl.get 'admin' [] readwrite_members acl.get 'read-write' [] readonly_members acl.get 'read-only' [] if not any admin_members readwrite_members readonly_members return Nonereturn {'admin' admin_members 'read-write' readwrite_members 'read-only' readonly_members}
@blueprint.route '/view-config/<extension_id>' methods ['GET'] def view_config extension_id extension extensions.view.get_extension extension_id if extension is None raise ValueError "Unknownextension'%s'" % extension_id config_form extension.get_config_form template context extension.get_config_template config_form return flask.render_template_string template **context
def threaded_reactor global _twisted_threadtry from twisted.internet import reactorexcept ImportError return None None if not _twisted_thread from twisted.python import threadablefrom threading import Thread_twisted_thread Thread target lambda reactor.run installSignalHandlers False _twisted_thread.setDaemon True _twisted_thread.start return reactor _twisted_thread
def _listToPhrase things finalDelimiter delimiter ' ' if not isinstance things list tuple raise TypeError 'Thingsmustbealistoratuple' if not things return ''if len things 1 return str things[0] if len things 2 return '%s%s%s' % str things[0] finalDelimiter str things[1] else strThings []for thing in things strThings.append str thing return '%s%s%s%s' % delimiter.join strThings[ -1 ] delimiter finalDelimiter strThings[ -1 ]
def GetContentType filename return mimetypes.guess_type filename [0] or 'application/octet-stream'
def do_title s return soft_unicode s .title
def rename_and_collapse_folder oldpath newpath files orgpath oldpathitems globber oldpath if len items 1 folder items[0]folder_path os.path.join oldpath folder if os.path.isdir folder_path and folder not in 'VIDEO_TS' 'AUDIO_TS' logging.info 'Collapsing%s' os.path.join newpath folder oldpath folder_patholdpath os.path.normpath oldpath newpath os.path.normpath newpath files [os.path.normpath f .replace oldpath newpath for f in files]renamer oldpath newpath try remove_dir orgpath except passreturn files
def E_nl_dirac n l spin_up True Z 1 c Float '137.035999037' if not l > 0 raise ValueError "'l'mustbepositiveorzero" if not n > l raise ValueError "'n'mustbegreaterthan'l'" if l 0 and spin_up is False raise ValueError 'Spinmustbeupforl 0.' if spin_up skappa - l - 1 else skappa - l c S c beta sqrt skappa ** 2 - Z ** 2 / c ** 2 return c ** 2 / sqrt 1 + Z ** 2 / n + skappa + beta ** 2 / c ** 2 - c ** 2
def pappus_graph G LCF_graph 18 [5 7 -7 7 -7 -5 ] 3 G.name 'PappusGraph'return G
def clean_warning_registry warnings.resetwarnings reg '__warningregistry__'for mod_name mod in list sys.modules.items if 'six.moves' in mod_name continueif hasattr mod reg getattr mod reg .clear
def _find_alias FunctionName Name FunctionVersion None region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile args {'FunctionName' FunctionName}if FunctionVersion args['FunctionVersion'] FunctionVersionfor aliases in salt.utils.boto3.paged_call conn.list_aliases **args for alias in aliases.get 'Aliases' if alias['Name'] Name return aliasreturn None
def tree_decode buf ofs 0while ofs < len buf z buf.find '\x00' ofs assert z > ofs spl buf[ofs z].split '' 1 assert len spl 2 mode name splsha buf[ z + 1 z + 1 + 20 ]ofs z + 1 + 20 yield int mode 8 name sha
def is_hidden path if sys.platform 'darwin' return _is_hidden_osx path or _is_hidden_dot path elif sys.platform 'win32' return _is_hidden_win path else return _is_hidden_dot path
def wordlist_to_graph_file wordlist dbfile strip True from whoosh.filedb.structfile import StructFileg GraphCorrector.from_word_list wordlist strip strip if isinstance dbfile string_type dbfile open dbfile 'wb' if not isinstance dbfile StructFile dbfile StructFile dbfile g.to_file dbfile
def json_ser obj if isinstance obj datetime date return obj.isoformat
def freedman_bin_width data return_bins False data np.asarray data if data.ndim ! 1 raise ValueError u'datashouldbeone-dimensional' n data.sizeif n < 4 raise ValueError u'datashouldhavemorethanthreeentries' v25 v75 np.percentile data [25 75] dx 2 * v75 - v25 / n ** 1 / 3 if return_bins dmin dmax data.min data.max Nbins max 1 np.ceil dmax - dmin / dx bins dmin + dx * np.arange Nbins + 1 return dx bins else return dx
def test_breadcrumb c LocalizingClient response c.get reverse 'search' doc pq response.content href doc '.breadcrumbsa' [0]eq_ '/' href.attrib['href'][0]
def testnewdocument_noimagecopy document docbody relationships imagefiledict simpledoc noimagecopy True coreprops coreproperties 'Pythondocxtestnewdocument' 'AshortexampleofmakingdocxfromPython' 'AlanBrooks' ['python' 'OfficeOpenXML' 'Word'] savedocx document coreprops appproperties contenttypes websettings wordrelationships relationships TEST_FILE imagefiledict imagefiledict
def has_tags available required for key value in required.items if key not in available or value ! available[key] return Falsereturn True
def tmp_path *paths return os.path.join os.path.dirname __file__ u'tmp' *paths
@compositedef related_deployments_strategy draw number_of_deployments node_uuid_pool draw node_uuid_pool_strategy deployments set while True deployments.add draw deployment_strategy node_uuid_pool node_uuid_pool if len deployments number_of_deployments return tuple deployments
def get url conn urlopen url resp conn.read conn.close return resp
def latinize value def replace_double_character match search u'\u0398\u03a7\u03a8\u03b8\u03c7\u03c8\u039f\u03a5\u0391\u03a5\u0395\u03a5\u039f\u03c5\u0391\u03c5\u0395\u03c5\u03bf\u03c5\u03b1\u03c5\u03b5\u03c5'.split replace u'THCHPSthchpsOUAUEUOuAuEuouaueu'.split matched match.group 0 if matched in search return replace[search.index matched ]return matchedsearch u'\u0391\u0392\u0393\u0394\u0395\u0396\u0397\u0399\u039a\u039b\u039c\u039d\u039e\u039f\u03a0\u03a1\u03a3\u03a3\u03a4\u03a5\u03a6\u03a9\u03b1\u03b2\u03b3\u03b4\u03b5\u03b6\u03b7\u03b9\u03ba\u03bb\u03bc\u03bd\u03be\u03bf\u03c0\u03c1\u03c3\u03c2\u03c4\u03c5\u03c6\u03c9'replace u'AVGDEZIIKLMNXOPRSSTUFOavgdeziiklmnxoprsstyfo'def replace_greek_character match matched list match.group 0 value map lambda l replace[search.find l ] matched return u''.join value return re.sub u'[{0}]+'.format search replace_greek_character re.sub u' [\u0398\u03a7\u03a8\u03b8\u03c7\u03c8]+|\u039f\u03a5|\u0391\u03a5|\u0395\u03a5|\u039f\u03c5|\u0391\u03c5|\u0395\u03c5|\u03bf\u03c5|\u03b1\u03c5|\u03b5\u03c5 ' replace_double_character remove_accents value
def num_cpus try return psutil.cpu_count except AttributeError return psutil.NUM_CPUS
def assert_armijo s phi c1 0.0001 err_msg '' phi1 phi s phi0 phi 0 msg 's %s;phi 0 %s;phi s %s;%s' % s phi0 phi1 err_msg assert_ phi1 < 1 - c1 * s * phi0 msg
def port_list br cmd 'ovs-vsctllist-ports{0}'.format br result __salt__['cmd.run_all'] cmd retcode result['retcode']stdout result['stdout']return _stdout_list_split retcode stdout
def IsBucket name return ObjectStore.HasInstance name
def get_collection_from_model collection_model run_conversion True versioned_collection {'schema_version' collection_model.schema_version 'nodes' copy.deepcopy collection_model.nodes }if run_conversion and collection_model.schema_version ! feconf.CURRENT_COLLECTION_SCHEMA_VERSION _migrate_collection_to_latest_schema versioned_collection return collection_domain.Collection collection_model.id collection_model.title collection_model.category collection_model.objective collection_model.language_code collection_model.tags versioned_collection['schema_version'] [collection_domain.CollectionNode.from_dict collection_node_dict for collection_node_dict in versioned_collection['nodes']] collection_model.version collection_model.created_on collection_model.last_updated
def skipUnlessDBFeature feature return _deferredSkip lambda not getattr connection.features feature "Databasedoesn'tsupportfeature%s" % feature
def get_paths level 15 wildcards ['/']for i in range level wildcards.append wildcards[ -1 ] + '*/' p [ 'sympy' + x + 'test_*.py' for x in wildcards]return p
def translation_percent translated total if total 0 or total is None return 0.0perc round 1000 * translated / total / 10.0 if perc 0.0 and translated ! 0 return 0.1if perc 100.0 and translated ! total return 99.9return perc
def _create_eeg_el ch t None if ch['kind'] ! FIFF.FIFFV_EEG_CH raise RuntimeError '%sisnotanEEGchannel.Cannotcreateanelectrodedefinition.' % ch['ch_name'] if t is None t Transform 'head' 'head' if t.from_str ! 'head' raise RuntimeError 'Inappropriatecoordinatetransformation' r0ex _loc_to_eeg_loc ch['loc'] if r0ex.shape[1] 1 w np.array [1.0] else w np.array [1.0 -1.0 ] r0ex apply_trans t['trans'] r0ex.T cosmag r0ex.copy _normalize_vectors cosmag res dict chname ch['ch_name'] coil_class FIFF.FWD_COILC_EEG w w accuracy _accuracy_dict['normal'] type ch['coil_type'] coord_frame t['to'] rmag r0ex cosmag cosmag return res
def to_unicode value if not isinstance value six.string_types raise ValueError 'Value"%s"mustbeastring.' % value if not isinstance value six.text_type value six.u value return value
def surface_column_elements clause stack deque [clause] while stack elem stack.popleft yield elem for sub in elem.get_children if isinstance sub FromGrouping continuestack.append sub
def take n iterable return islice iterable n
def test_rgb_to_hsl_part_17 assert rgb_to_hsl 0 0 51 240 100 10 assert rgb_to_hsl 0 0 102 240 100 20 assert rgb_to_hsl 0 0 153 240 100 30 assert rgb_to_hsl 0 0 204 240 100 40 assert rgb_to_hsl 0 0 255 240 100 50 assert rgb_to_hsl 51 51 255 240 100 60 assert rgb_to_hsl 102 102 255 240 100 70 assert rgb_to_hsl 153 153 255 240 100 80 assert rgb_to_hsl 204 204 255 240 100 90
def failure_to_exc_info failure if isinstance failure Failure return failure.type failure.value failure.getTracebackObject
@image_comparison baseline_images [u'legend_expand'] remove_text True def test_legend_expand legend_modes [None u'expand'] fig axes_list plt.subplots len legend_modes 1 x np.arange 100 for ax mode in zip axes_list legend_modes ax.plot x 50 - x u'o' label u'y 1' l1 ax.legend loc 2 mode mode ax.add_artist l1 ax.plot x x - 50 u'o' label u'y -1' l2 ax.legend loc 5 mode mode ax.add_artist l2 ax.legend loc 3 mode mode ncol 2
def genslices_ndim ndim shape iterables [genslices shape[n] for n in range ndim ]return product *iterables
def libvlc_release p_instance f _Cfunctions.get 'libvlc_release' None or _Cfunction 'libvlc_release' 1 None None Instance return f p_instance
@not_implemented_for 'undirected' 'multigraph' def reciprocity G nodes None if nodes is None return overall_reciprocity G if nodes in G reciprocity next _reciprocity_iter G nodes [1]if reciprocity is None raise NetworkXError 'Notdefinedforisolatednodes.' else return reciprocityreturn dict _reciprocity_iter G nodes
def compare_psnr im_true im_test data_range None dynamic_range None _assert_compatible im_true im_test if dynamic_range is not None warn '`dynamic_range`hasbeendeprecatedinfavorof`data_range`.The`dynamic_range`keywordargumentwillberemovedinv0.14' skimage_deprecation data_range dynamic_rangeif data_range is None dmin dmax dtype_range[im_true.dtype.type] true_min true_max np.min im_true np.max im_true if true_max > dmax or true_min < dmin raise ValueError 'im_truehasintensityvaluesoutsidetherangeexpectedforitsdatatype.Pleasemanuallyspecifythedata_range' if true_min > 0 data_range dmaxelse data_range dmax - dmin im_true im_test _as_floats im_true im_test err compare_mse im_true im_test return 10 * np.log10 data_range ** 2 / err
def int64_output func argtypes func.argtypes argtypesfunc.restype c_int64return func
def test_dicts objs tokenize '{foobarbarbaz}' assert objs [HyDict ['foo' 'bar' 'bar' 'baz'] ] objs tokenize ' bar{foobarbarbaz} ' assert objs [HyExpression [HySymbol 'bar' HyDict ['foo' 'bar' 'bar' 'baz'] ] ] objs tokenize '{ foobar bazquux }' assert objs [HyDict [HyExpression [HySymbol 'foo' HySymbol 'bar' ] HyExpression [HySymbol 'baz' HySymbol 'quux' ] ] ]
def _unpickleFunction fullyQualifiedName from twisted.python.reflect import namedAnyreturn namedAny fullyQualifiedName
def getGeometricDifference first second return max first second / min first second
def jenkins_build_results inQueue None builds None strats []if inQueue is None inQueue booleans strats.append just pmap without_builds fixed_dictionaries dict inQueue inQueue if builds is None or builds is NO_BUILDS strats.append without_builds if builds is None builds lists jenkins_builds average_size 1 if builds is not NO_BUILDS with_builds fixed_dictionaries dict inQueue inQueue builds builds property dictionaries text max_size 2 text max_size 2 average_size 1 max_size 2 strats.append with_builds return one_of *strats
def compare_files self result_file ref_file self.assertEqual result_file.src ref_file.src self.assertEqual result_file.dest ref_file.dest self.assertEqual result_file.compare_key ref_file.compare_key self.assertEqual result_file.size ref_file.size self.assertEqual result_file.last_update ref_file.last_update self.assertEqual result_file.src_type ref_file.src_type self.assertEqual result_file.dest_type ref_file.dest_type self.assertEqual result_file.operation_name ref_file.operation_name
def dmp_inject f u K front False f h dmp_to_dict f u {} v K.ngens - 1 for f_monom g in f.items g g.to_dict for g_monom c in g.items if front h[ g_monom + f_monom ] celse h[ f_monom + g_monom ] cw u + v + 1 return dmp_from_dict h w K.dom w
def combine_values *values for v in reversed values if v is not None return velse return None
def _usage_unallocated raw ret {}for line in raw.split '\n' [1 ] keyset re.sub '\\s+' '' line.strip .split '' if len keyset 2 ret[keyset[0]] keyset[1]return ret
def test_default_conv img theano.tensor.ftensor4 fil theano.tensor.ftensor4 c theano.tensor.nnet.conv2d img fil f theano.function [img fil] c mode theano_mode if cuda.dnn.dnn_available assert any [isinstance a.op GpuDnnConv for a in f.maker.fgraph.apply_nodes] else assert any [isinstance a.op cuda.blas.GpuCorrMM for a in f.maker.fgraph.apply_nodes]
def estrada_index G return sum subgraph_centrality G .values
def immunohistochemistry return load 'ihc.png'
def parse_create_or_delete message return {'type' message['type'] 'event' message['action'] 'values' {'user' get_owner_name message 'subject' get_subject message }}
def _get_quote_state token quote_char prev_char Nonefor idx cur_char in enumerate token if idx > 0 prev_char token[ idx - 1 ]if cur_char in '"\'' and prev_char ! '\\' if quote_char if cur_char quote_char quote_char Noneelse quote_char cur_charreturn quote_char
def tokenize readline from itertools import chain repeat encoding consumed detect_encoding readline rl_gen iter readline '' empty repeat '' return _tokenize chain consumed rl_gen empty .__next__ encoding
def debug_option if g['debug'] g['traceback'].append traceback.format_exc
def DECLARE_key_flag flag_name flag_values FLAGS if flag_name in _SPECIAL_FLAGS _InternalDeclareKeyFlags [flag_name] flag_values _SPECIAL_FLAGS key_flag_values flag_values return_InternalDeclareKeyFlags [flag_name] flag_values flag_values
def zdt4 individual g 1 + 10 * len individual - 1 + sum xi ** 2 - 10 * cos 4 * pi * xi for xi in individual[1 ] f1 individual[0]f2 g * 1 - sqrt f1 / g return f1 f2
def backward_migrate_group_curators apps schema_editor pass
def model_query context model *args **kwargs session kwargs.get 'session' or get_session read_deleted kwargs.get 'read_deleted' or context.read_deleted project_only kwargs.get 'project_only' query session.query model *args if read_deleted 'no' query query.filter_by deleted False elif read_deleted 'yes' passelif read_deleted 'only' query query.filter_by deleted True elif read_deleted 'int_no' query query.filter_by deleted 0 else raise Exception _ "Unrecognizedread_deletedvalue'%s'" % read_deleted if project_only and is_user_context context if model models.VolumeAttachment query query.filter models.Volume.project_id context.project_id else query query.filter_by project_id context.project_id return query
def find_sink_node digr node digr.nodes [0]while digr.neighbors node node digr.neighbors node [0]return node
def _api_shutdown name output kwargs sabnzbd.halt cherrypy.engine.exit sabnzbd.SABSTOP Truereturn report output
def update_contact doc method contact_name frappe.db.get_value u'Contact' {u'email_id' doc.name} if contact_name contact frappe.get_doc u'Contact' contact_name for key in u'first_name' u'last_name' u'phone' if doc.get key contact.set key doc.get key contact.flags.ignore_mandatory Truecontact.save ignore_permissions True
def gpu_safe_new x tag '' if hasattr x 'name' and x.name is not None nw_name x.name + tag else nw_name Noneif isinstance x theano.Constant return x.clone nw_x x.type nw_x.name nw_namereturn nw_x
def html_format value if not value return ''elif MARKUP_LANGUAGE 'markdown' return markdown value elif MARKUP_LANGUAGE 'textile' return textile value elif MARKUP_LANGUAGE 'restructuredtext' return restructuredtext value elif '</p>' not in value return linebreaks value return value
def dataset_cov n dim 300 2 np.random.seed 0 C np.array [[0.0 -1.0 ] [2.5 0.7]] * 2.0 X np.r_[ np.dot np.random.randn n dim C np.dot np.random.randn n dim C.T + np.array [1 4] ]y np.hstack np.zeros n np.ones n return X y
def resolve_uri s namespaces cdao_namespaces cdao_to_obo True xml_style False if cdao_to_obo and s.startswith 'cdao ' return resolve_uri 'obo %s' % cdao_elements[s[5 ]] namespaces cdao_to_obo for prefix in namespaces if xml_style s s.replace prefix + ' ' '{%s}' % namespaces[prefix] else s s.replace prefix + ' ' namespaces[prefix] return s
def set_by_cli var detector set_by_cli.detectorif detector is None plugins plugins_disco.PluginsRegistry.find_all reconstructed_args helpful_parser.args + [helpful_parser.verb] detector set_by_cli.detector prepare_and_parse_args plugins reconstructed_args detect_defaults True detector.authenticator detector.installer plugin_selection.cli_plugin_requests detector logger.debug 'DefaultDetectoris%r' detector if not isinstance getattr detector var _Default return Truefor modifier in VAR_MODIFIERS.get var [] if set_by_cli modifier return Truereturn False
def retry jenkins_session url params print 'Retrying{}'.format url if params jenkins_session.post url + '/buildWithParameters' data params else jenkins_session.post url + '/build'
def test_pooling_with_anon_variable X_sym tensor.ftensor4 shp 3 3 strd 1 1 im_shp 6 6 pool_0 max_pool X_sym pool_shape shp pool_stride strd image_shape im_shp try_dnn False pool_1 mean_pool X_sym pool_shape shp pool_stride strd image_shape im_shp
def get_repository name cmd u'Get-PSRepository"{0}"'.format name no_ret _pshell cmd return name not in list_modules
def test_hash_vs_typeinfo_2 x Symbol 'x' x1 Symbol 'x' even True assert x ! x1 assert hash x ! hash x1
def ct_to_rgb temp colorlist list color_temperature_to_rgb color_temperature_mired_to_kelvin temp return [int val for val in colorlist]
def unescape_xml text def fixup m txt m.group 0 if txt[ 2] '&#' try if txt[ 3] '&#x' return chr int txt[3 -1 ] 16 else return chr int txt[2 -1 ] except ValueError passelse try txt chr entities.name2codepoint[txt[1 -1 ]] except KeyError passreturn txtreturn re.sub '&#?\\w+;' fixup text
def in6_xor a1 a2 return _in6_bitops a1 a2 2
def interface_addresses attrs None where None return _osquery_cmd table 'interface_addresses' attrs attrs where where
@pytest.fixture scope 'module' params ['cpu'] def backend_cpu request be get_backend request datatype np.float32 def cleanup be request.getfuncargvalue 'backend_cpu' del berequest.addfinalizer cleanup return be
def effectively_exploit_all w3af enabled_plugins stopOnFirst dlg TextDialogConsumer 'MultipleExploit!' exploit_task _launch_exploit_all dlg w3af enabled_plugins stopOnFirst gobject.idle_add exploit_task.next
def open_with_encoding filename encoding None mode u'r' if not encoding encoding detect_encoding filename return io.open filename mode mode encoding encoding newline u''
def nova_docstring_multiline_end physical_line previous_logical tokens ops [t for t _ _ _ _ in tokens if t tokenize.OP ]if is_docstring physical_line previous_logical and len tokens > 0 and len ops 0 pos max physical_line.find i for i in END_DOCSTRING_TRIPLE if physical_line.strip not in START_DOCSTRING_TRIPLE return pos 'N403 multilinedocstringendonnewline'
@pytest.fixturedef install_egg modules_tmpdir monkeypatch def inner name base modules_tmpdir if not isinstance name str raise ValueError name base.join name .ensure_dir base.join name .join '__init__.py' .ensure egg_setup base.join 'setup.py' egg_setup.write textwrap.dedent "\nfromsetuptoolsimportsetup\nsetup name '{0}' \nversion '1.0' \npackages ['site_egg'] \nzip_safe True \n".format name import subprocesssubprocess.check_call [sys.executable 'setup.py' 'bdist_egg'] cwd str modules_tmpdir egg_path modules_tmpdir.join 'dist/' .listdir monkeypatch.syspath_prepend str egg_path return egg_pathreturn inner
def tax_add price tax_percentage 21 if price is None return Noneresult price * 100 + tax_percentage / D 100 return result.quantize D '0.01' ROUND_HALF_UP
def __WrapDispatch dispatch userName None resultCLSID None typeinfo None UnicodeToString None clsctx pythoncom.CLSCTX_SERVER WrapperClass None assert UnicodeToString is None 'thisisdeprecatedandwillgoaway'if resultCLSID is None try typeinfo dispatch.GetTypeInfo if typeinfo is not None resultCLSID str typeinfo.GetTypeAttr [0] except pythoncom.com_error AttributeError passif resultCLSID is not None import gencacheklass gencache.GetClassForCLSID resultCLSID if klass is not None return klass dispatch if WrapperClass is None WrapperClass CDispatchreturn dynamic.Dispatch dispatch userName WrapperClass typeinfo clsctx clsctx
def matrix_to_zero e if isinstance e Matrix if zeros *e.shape e e Integer 0 elif isinstance e numpy_ndarray e _numpy_matrix_to_zero e elif isinstance e scipy_sparse_matrix e _scipy_sparse_matrix_to_zero e return e
@_built_in_directivedef session context_name 'session' request None **kwargs return request and request.context.get context_name None
def idd_sfrmi l m return _id.idd_sfrmi l m
def cross_from_above x threshold x np.asarray x ind np.nonzero x[ -1 ] > threshold & x[1 ] < threshold [0]if len ind return ind + 1 else return ind
def orphans i o return variables_and_orphans i o [1]
def _div_gf2 a b if a < b return 0 a deg number.sizeq 0r ad deg b while deg r > d s 1 << deg r - d q ^ sr ^ _mult_gf2 b s return q r
def s3_unicode s encoding 'utf-8' if type s is unicode return stry if not isinstance s basestring if hasattr s '__unicode__' s unicode s else try s unicode str s encoding 'strict' except UnicodeEncodeError if not isinstance s Exception raises ''.join [s3_unicode arg encoding for arg in s] else s s.decode encoding except UnicodeDecodeError if not isinstance s Exception raiseelse s ''.join [s3_unicode arg encoding for arg in s] return s
def dup_sqf_part f K if K.is_FiniteField return dup_gf_sqf_part f K if not f return fif K.is_negative dup_LC f K f dup_neg f K gcd dup_gcd f dup_diff f 1 K K sqf dup_quo f gcd K if K.has_Field return dup_monic sqf K else return dup_primitive sqf K [1]
def _get_classes classes {}for class_name class_dict in _BACKWARDS_COMPAT_CLASS_NAMES.items object_name class_dict['object_name']base_type class_dict['base_type']if object_name in OBJECTS or object_name in ARRAYS classes[class_name] {'object_name' object_name 'base_type' base_type}else classes[class_name] {'object_name' None 'base_type' base_type}for object_name in TRACE_NAMES class_name string_to_class_name object_name classes[class_name] {'object_name' object_name 'base_type' dict}return classes
def getTranslatorFileTypeTuples importPluginFileNames getImportPluginFileNames fileTypeTuples []for importPluginFileName in importPluginFileNames fileTypeTitle importPluginFileName.upper + 'files' fileType fileTypeTitle '*.' + importPluginFileName fileTypeTuples.append fileType fileTypeTuples.sort return fileTypeTuples
def setup_python_path collector_dir mydir os.path.dirname collector_dir libdir os.path.join mydir 'collectors' 'lib' if not os.path.isdir libdir returnpythonpath os.environ.get 'PYTHONPATH' '' if pythonpath pythonpath + ' 'pythonpath + mydiros.environ['PYTHONPATH'] pythonpathLOG.debug 'SetPYTHONPATHto%r' pythonpath
def instance_create context values return IMPL.instance_create context values
def sortLogNondominated individuals k first_front_only False if k 0 return []unique_fits defaultdict list for i ind in enumerate individuals unique_fits[ind.fitness.wvalues].append ind obj len individuals[0].fitness.wvalues - 1 fitnesses unique_fits.keys front dict.fromkeys fitnesses 0 fitnesses.sort reverse True sortNDHelperA fitnesses obj front nbfronts max front.values + 1 pareto_fronts [[] for i in range nbfronts ]for fit in fitnesses index front[fit]pareto_fronts[index].extend unique_fits[fit] if not first_front_only count 0for i front in enumerate pareto_fronts count + len front if count > k return pareto_fronts[ i + 1 ]return pareto_frontselse return pareto_fronts[0]
def avoid_outliers y x np.mgrid[ -4 2 200j -4 2 200j]z 10 * np.cos x ** 2 + y ** 2 z[ 100 105 ] 2000z[ 120 110 ] -9000 ls LightSource 315 45 fig ax1 ax2 plt.subplots ncols 2 figsize 8 4.5 rgb ls.shade z plt.cm.copper ax1.imshow rgb interpolation 'bilinear' ax1.set_title 'Fullrangeofdata' rgb ls.shade z plt.cm.copper vmin -10 vmax 10 ax2.imshow rgb interpolation 'bilinear' ax2.set_title 'Manuallysetrange' fig.suptitle 'AvoidingOutliersinShadedPlots' size 'x-large'
def couple expr jcoupling_list None a expr.atoms TensorProduct for tp in a if not all [isinstance state SpinState for state in tp.args] continueif not all [ state.__class__ is tp.args[0].__class__ for state in tp.args] raise TypeError 'Allstatesmustbethesamebasis' expr expr.subs tp _couple tp jcoupling_list return expr
def date_range start end if getattr start 'date' None is not None start start.date if getattr end 'date' None is not None end end.date days end - start .days + 1 return start + datetime.timedelta days d for d in xrange days
def restart_httpd request notifier .restart 'http' return HttpResponse 'OK'
def extract_host host level 'backend' default_pool_name False if host is None msg _ 'volumeisnotassignedtoahost' raise exception.InvalidVolume reason msg if level 'host' hst host.split '#' [0]return hst.split '@' [0]elif level 'backend' return host.split '#' [0]elif level 'pool' lst host.split '#' if len lst 2 return lst[1]elif default_pool_name is True return DEFAULT_POOL_NAMEelse return None
def func_namespace func kls Noneif hasattr func 'im_func' kls func.im_classfunc func.im_funcif kls return '%s.%s' % kls.__module__ kls.__name__ else return '%s.%s' % func.__module__ func.__name__
def _par_indices names unique {}for idx name in enumerate names name name.upper if name in unique unique[name].append idx else unique[name] [idx]return unique
def copyfileobj src dst length None if length 0 returnif length is None shutil.copyfileobj src dst returnBUFSIZE 16 * 1024 blocks remainder divmod length BUFSIZE for b in xrange blocks buf src.read BUFSIZE if len buf < BUFSIZE raise IOError 'endoffilereached' dst.write buf if remainder ! 0 buf src.read remainder if len buf < remainder raise IOError 'endoffilereached' dst.write buf return
def flattened_iterator l types list tuple if not isinstance l types yield l returnfor element in l for sub_element in flattened_iterator element types yield sub_element
def project_create name domain description None enabled True profile None **connection_args kstone auth profile **connection_args new getattr kstone _TENANTS None .create name name domain domain description description enabled enabled return tenant_get new.id profile profile **connection_args
def firefox_addons attrs None where None if salt.utils.is_darwin return _osquery_cmd table 'firefox_addons' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonmacOSsystems.'}
def _check_and_uninstall_ruby ret ruby user None ret _ruby_installed ret ruby user user if ret['result'] if ret['default'] __salt__['rbenv.default'] 'system' runas user if __salt__['rbenv.uninstall_ruby'] ruby runas user ret['result'] Trueret['changes'][ruby] 'Uninstalled'ret['comment'] 'Successfullyremovedruby'return retelse ret['result'] Falseret['comment'] 'Failedtouninstallruby'return retelse ret['result'] Trueret['comment'] 'Ruby{0}isalreadyabsent'.format ruby return ret
def c_creates_button client objname TOBJ_TEMPLATE % client.counter client.objs.append objname cmds '@create%s %s' % objname TOBJ_TYPECLASS '@desc%s testredbutton!' % objname return cmds
def yogafire_minifest request if not settings.YOGAFIRE_GUID return HttpResponseNotFound return mini_manifest request settings.YOGAFIRE_GUID
def _apply_random func state_data size args kwargs state np.random.RandomState state_data func getattr state func return func size size *args **kwargs
def get_swift_info admin False disallowed_sections None disallowed_sections disallowed_sections or [] info dict _swift_info for section in disallowed_sections key_to_pop Nonesub_section_dict infofor sub_section in section.split '.' if key_to_pop sub_section_dict sub_section_dict.get key_to_pop {} if not isinstance sub_section_dict dict sub_section_dict {}breakkey_to_pop sub_sectionsub_section_dict.pop key_to_pop None if admin info['admin'] dict _swift_admin_info info['admin']['disallowed_sections'] list disallowed_sections return info
def remote_file_exists file_url try handler urllib2.urlopen file_url handler.close return Trueexcept urllib2.HTTPError return False
def is_namespace_mutable context namespace if context.is_admin return Trueif context.owner is None return Falsereturn namespace.owner context.owner
def _compute_sph_harm order az pol sph_harm _get_sph_harm out np.empty len az _get_n_moments order + 1 for degree in range order + 1 for order_ in range degree + 1 sph sph_harm order_ degree az pol out[ _deg_ord_idx degree order_ ] _sh_complex_to_real sph order_ if order_ > 0 out[ _deg_ord_idx degree - order_ ] _sh_complex_to_real _sh_negate sph order_ - order_ return out
def test_classification_report_imbalanced_multiclass_with_unicode_label y_true y_pred _ make_prediction binary False labels np.array [u'blue\xa2' u'green\xa2' u'red\xa2'] y_true labels[y_true]y_pred labels[y_pred]expected_report u'prerecspef1geoibasupblue\xa20.830.790.920.810.860.7424green\xa20.330.100.860.150.440.1931red\xa20.420.900.550.570.630.3720avg/total0.510.530.800.470.620.4175'if np_version[ 3] < 1 7 0 expected_message 'NumPy<1.7.0doesnotimplementsearchsortedonunicodedatacorrectly.'assert_raise_message RuntimeError expected_message classification_report_imbalanced y_true y_pred else report classification_report_imbalanced y_true y_pred assert_equal _format_report report expected_report
def _AddHasExtensionMethod cls def HasExtension self extension_handle _VerifyExtensionHandle self extension_handle if extension_handle.label _FieldDescriptor.LABEL_REPEATED raise KeyError '"%s"isrepeated.' % extension_handle.full_name if extension_handle.cpp_type _FieldDescriptor.CPPTYPE_MESSAGE value self._fields.get extension_handle return value is not None and value._is_present_in_parent else return extension_handle in self._fields cls.HasExtension HasExtension
def request_methods_view request return HttpResponse 'requestmethod %s' % request.method
def parsed_version version return tuple map int version.split '.' [ 3]
def extract_record_set records filters sorting pagination_rules None limit None id_field DEFAULT_ID_FIELD deleted_field DEFAULT_DELETED_FIELD filtered list apply_filters records filters or [] total_records len filtered paginated {}for rule in pagination_rules or [] values list apply_filters filtered rule paginated.update dict x[id_field] x for x in values if paginated paginated paginated.values else paginated filteredsorted_ apply_sorting paginated sorting or [] filtered_deleted len [r for r in sorted_ if r.get deleted_field is True ] if limit sorted_ list sorted_ [ limit]return sorted_ total_records - filtered_deleted
def methods_of obj result []for i in dir obj if callable getattr obj i and not i.startswith '_' result.append i getattr obj i return result
def to_unserialized_json obj return _cached_dfs_serialize obj
def get_processor_config config settings.CC_PROCESSOR.get settings.CC_PROCESSOR_NAME {} config_key configuration_helpers.get_value 'cybersource_config_key' if config_key config config['microsites'][config_key]return config
def accept_quality accept default 1 quality defaultif accept and ';' in accept accept rest accept.split ';' 1 accept_quality RE_ACCEPT_QUALITY.search rest if accept_quality quality float accept_quality.groupdict .get 'quality' quality .strip return quality accept.strip
def get_bdms_to_connect bdms exclude_root_mapping False return bdm for bdm in bdms if bdm.get 'boot_index' -1 ! 0 or not exclude_root_mapping
def educateQuotesLatex s dquotes '``' "''" s single_quote_start_re.sub '\x04' s s double_quote_start_re.sub '\x02' s s double_quote_sets_re.sub '\x01\x03' s s single_quote_sets_re.sub '\x03\x01' s s decade_abbr_re.sub '\x04' s s opening_single_quotes_regex.sub '\\1\x03' s s closing_single_quotes_regex.sub '\\1\x04' s s closing_single_quotes_regex_2.sub '\\1\x04\\2' s s s.replace "'" '\x03' s opening_double_quotes_regex.sub '\\1\x01' s s closing_double_quotes_regex.sub '\x02' s s closing_double_quotes_regex_2.sub '\\1\x02' s s s.replace '"' '\x01' return s.replace '\x01' dquotes[0] .replace '\x02' dquotes[1] .replace '\x03' '`' .replace '\x04' "'"
@pytest.fixture scope 'session' def log_counter return itertools.count
def shortPythonVersion return '%s.%s.%s' % sys.version_info[ 3]
def define_average name description manager counters counter _AverageCounter name description manager.register counter return counter
def debugerror return web._InternalError djangoerror
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_last_doc doctype d get_all doctype [u'name'] order_by u'creationdesc' limit_page_length 1 if d return get_doc doctype d[0].name else raise DoesNotExistError
def _write_kegg item info indent KEGG_ITEM_LENGTH s ''for line in info partial_lines line.splitlines for l in partial_lines s s + item.ljust indent + l + '\n' if item is not '' item ''return s
def fetch_lyricscom artist title url LYRICSCOM_URL_PATTERN % _lc_encode title _lc_encode artist html fetch_url url if not html returnlyrics extract_text_between html '<divid "lyrics"class "SCREENONLY"itemprop "description">' '</div>' if not lyrics returnfor not_found_str in LYRICSCOM_NOT_FOUND if not_found_str in lyrics returnparts lyrics.split '\n---\nLyricspoweredby' 1 if parts return parts[0]
def get_hosting_service name try return _hosting_service_registry.get u'hosting_service_id' name except ItemLookupError return None
def _scal_inplace symbol symbolname symbol.__name__inplace symbolname.endswith '_inplace' if inplace scalar_op getattr scal symbolname[ - len '_inplace' ] inplace_scalar_op scalar_op.__class__ scal.transfer_type 0 rval elemwise.Elemwise inplace_scalar_op {0 0} name symbolname else scalar_op getattr scal symbolname rval elemwise.Elemwise scalar_op name symbolname if getattr symbol '__doc__' False rval.__doc__ symbol.__doc__ + '\n' + rval.__doc__ rval.__epydoc_asRoutine symbolrval.__module__ 'theano.tensor.inplace'pprint.assign rval printing.FunctionPrinter symbolname.replace '_inplace' ' ' return rval
def is_ascii word def onlyascii char if ord char > 127 return ''else return charfor c in word if not onlyascii c return Falsereturn True
def concatenate tensor_list axis 0 concat_size sum tt.shape[axis] for tt in tensor_list output_shape for k in range axis output_shape + tensor_list[0].shape[k] output_shape + concat_size for k in range axis + 1 tensor_list[0].ndim output_shape + tensor_list[0].shape[k] out tensor.zeros output_shape offset 0for tt in tensor_list indices for k in range axis indices + slice None indices + slice offset offset + tt.shape[axis] for k in range axis + 1 tensor_list[0].ndim indices + slice None out tensor.set_subtensor out[indices] tt offset + tt.shape[axis]return out
@synchronized CONFIG_LOCK def add_to_database section keyword obj global databaseif section not in database database[section] {}database[section][keyword] obj
@pytest.mark.parametrize 'sect' configdata.DATA.keys def test_section_desc sect desc configdata.SECTION_DESC[sect]assert isinstance desc str
def mangle_compatibility_messages validation compat validation['compatibility_summary']for k in 'errors' 'warnings' 'notices' validation[k] compat[k]for msg in validation['messages'] if msg['compatibility_type'] msg['type'] msg['compatibility_type']
def isactiveprocess processname all processes ok 0for n c in all if n processname return 1return 0
def format_proxy proxy_config auth True if not proxy_config.get u'hostname' return Noneport proxy_config.get u'port' if not port or port < 0 port 80if proxy_config.get u'username' and proxy_config.get u'password' and auth template u'{scheme} //{username} {password}@{hostname} {port}'else template u'{scheme} //{hostname} {port}'return template.format scheme proxy_config.get u'scheme' or u'http' username proxy_config.get u'username' password proxy_config.get u'password' hostname proxy_config[u'hostname'] port port
def adjust_start_date user days_early_for_beta start course_key if days_early_for_beta is None return startif CourseBetaTesterRole course_key .has_user user debug 'Adjuststarttime userinbetarolefor%s' course_key delta timedelta days_early_for_beta effective start - delta return effectivereturn start
def open_file_dialog filename QtGui.QFileDialog.getOpenFileName filename _format_filename filename return filename
def get_prog try if os.path.basename sys.argv[0] in '__main__.py' '-c' return '%s-msentry' % sys.executable except AttributeError TypeError IndexError passreturn 'sentry'
def _load_credentials_file credentials_file try credentials_file.seek 0 data json.load credentials_file except Exception logger.warning 'Credentialsfilecouldnotbeloaded willignoreandoverwrite.' return {}if data.get 'file_version' ! 2 logger.warning 'Credentialsfileisnotversion2 willignoreandoverwrite.' return {}credentials {}for key encoded_credential in iteritems data.get 'credentials' {} try credential_json base64.b64decode encoded_credential credential client.Credentials.new_from_json credential_json credentials[key] credentialexcept logger.warning 'Invalidcredential{0}infile ignoring.'.format key return credentials
def get_bill_type bill_id prefix re.match ' [a-z]* ' bill_id.lower .group if prefix in bill_types return bill_types[prefix]else return 'bill'
@bp.route '/signin' methods ['GET' 'POST'] def signin next_url request.args.get 'next' '/' if g.user return redirect next_url form SigninForm if form.validate_on_submit login_user form.user form.permanent.data return redirect next_url return render_template 'account/signin.html' form form
def keypair_add name pubfile None pubkey None profile None conn _auth profile return conn.keypair_add name pubfile pubkey
def getValidator schema schema_store resolver LocalRefResolver base_uri '' referrer schema store schema_store return validator_for schema schema resolver resolver format_checker draft4_format_checker
def FormatFile filename style_config None lines None print_diff False verify False in_place False logger None _CheckPythonVersion if in_place and print_diff raise ValueError 'Cannotpassbothin_placeandprint_diff.' original_source newline encoding ReadFile filename logger reformatted_source changed FormatCode original_source style_config style_config filename filename lines lines print_diff print_diff verify verify if reformatted_source.rstrip '\n' lines reformatted_source.rstrip '\n' .split '\n' reformatted_source newline.join line for line in lines + newline if in_place if original_source and original_source ! reformatted_source file_resources.WriteReformattedCode filename reformatted_source in_place encoding return None encoding changed return reformatted_source encoding changed
def p_translation_unit_2 t pass
def html_and_illegal_unicode_replace atom_element if atom_element new_element RE_XML_ILLEGAL_COMPILED.sub '' atom_element return strip_html new_element return atom_element
def drop_privileges user USER try ent pwd.getpwnam user except KeyError returnif os.getuid ! 0 returnos.setgid ent.pw_gid os.setuid ent.pw_uid
def try_to_eval value try return eval value except NameError SyntaxError ImportError return value
def user_query kind user_id sort time q kind._query kind.c.author_id user_id kind.c._spam True False sort db_sort sort if time ! 'all' q._filter db_times[time] return make_results q
def rpr s if s is None return 'None'seen_unicode Falseresults []for cc in s ccn ord cc if ccn > 32 and ccn < 127 if cc "'" results.append '\\' results.append cc elif cc '\\' results.append '\\' results.append cc else results.append cc else seen_unicode Trueif ccn < 65535 results.append '\\u' results.append '%04x' % ccn else results.append '\\U' results.append '%08x' % ccn result "'" + ''.join results + "'" if seen_unicode return 'u ' + result + ' ' else return result
def join_locale comps loc comps['language']if comps.get 'territory' loc + '_' + comps['territory'] if comps.get 'codeset' loc + '.' + comps['codeset'] if comps.get 'modifier' loc + '@' + comps['modifier'] if comps.get 'charmap' loc + '' + comps['charmap'] return loc
def to_rabbitmq_queue_arguments arguments **options prepared dictfilter dict _to_rabbitmq_queue_argument key value for key value in items options return dict arguments **prepared if prepared else arguments
def consume_queue queue get queue.get_nowaitwhile 1 try yield get except Empty break
def register_identifier data_format data_class identifier force False if not data_format data_class in _identifiers or force _identifiers[ data_format data_class ] identifierelse raise IORegistryError u"Identifierforformat'{0}'andclass'{1}'isalreadydefined".format data_format data_class.__name__
def run_cmd cmd shell False args shlex.split cmd try sp subprocess.Popen args shell shell stdout subprocess.PIPE stderr subprocess.PIPE close_fds True except OSError raise Exception 'OSerrorrunningcommand%s' % cmd output err sp.communicate rc sp.returncodeif rc ! 0 raise Exception 'Commandreturnreturncode%s error %s' % rc err return output
def add_device device None device_class None collector 'localhost' prod_state 1000 if not device device __salt__['grains.get'] 'fqdn' if not device_class device_class _determine_device_class log.info 'Addingdevice%stozenoss' device data dict deviceName device deviceClass device_class model True collector collector productionState prod_state response _router_request 'DeviceRouter' 'addDevice' data [data] return response
def _get_child_branches trie return trie[1 ]
def _VarintSize value if value < 127 return 1if value < 16383 return 2if value < 2097151 return 3if value < 268435455 return 4if value < 34359738367 return 5if value < 4398046511103 return 6if value < 562949953421311 return 7if value < 72057594037927935 return 8if value < 9223372036854775807 return 9return 10
def Exponential name rate return rv name ExponentialDistribution rate
def filename_task task session items task.items if task.is_album else [task.item] missing_titles sum bad_title i.title for i in items if missing_titles names {}for item in items path displayable_path item.path name _ os.path.splitext os.path.basename path names[item] namefor pattern in PATTERNS d all_matches names pattern if d apply_matches d
def _subject_from_inverse inverse_operator return inverse_operator['src'][0].get 'subject_his_id' None
def _log_key match return tuple k v for k v in sorted match.items if k not in 'log_type' 'path'
def enable_request_namespace warnings.warn 'namespace_manager.enable_request_namespace isdeprecated uselib_configinstead.' DeprecationWarning stacklevel 2 if _ENV_CURRENT_NAMESPACE not in os.environ if _ENV_DEFAULT_NAMESPACE in os.environ os.environ[_ENV_CURRENT_NAMESPACE] os.environ[_ENV_DEFAULT_NAMESPACE]
def hermitenorm n monic False if n < 0 raise ValueError 'nmustbenonnegative.' if n 0 n1 n + 1 else n1 n x w mu0 roots_hermitenorm n1 mu True wfunc lambda x exp - x * x / 2.0 if n 0 x w [] [] hn sqrt 2 * pi * _gam n + 1 kn 1.0p orthopoly1d x w hn kn wfunc wfunc limits - inf inf monic monic eval_func lambda x eval_hermitenorm n x return p
@app.route '/headers' def view_headers return jsonify get_dict 'headers'
def _bool_fallback a b if a is None assert isinstance b bool return belse assert isinstance a bool return a
def _chrcls allowed_chars return u'^' + UNSAFE_CHAR_STRING + str.join u'' VALID_CHARS - allowed_chars .replace u'%' u'%%' .replace u']' u'\\]' .replace u'-' u'\\-'
def prewitt_h image mask None assert_nD image 2 image img_as_float image result convolve image HPREWITT_WEIGHTS return _mask_filter_result result mask
def test_SAMPClientError SAMPClientError 'test'
def is_nan builder val return builder.fcmp_unordered 'uno' val val
def default_test_processes if not hasattr os 'fork' return 1try return int os.environ['DJANGO_TEST_PROCESSES'] except KeyError return multiprocessing.cpu_count
def _find_tcl_tk hook_api bins selectImports hook_api.__file__ if is_darwin if not bins bins getImports hook_api.__file__ mapping {}for l in bins mapping[os.path.basename l ] lbins [ 'Tcl' mapping['Tcl'] 'Tk' mapping['Tk'] ]path_to_tcl bins[0][1]if 'Library/Frameworks' in path_to_tcl tcl_tk _find_tcl_tk_darwin_frameworks bins else tcl_tk _find_tcl_tk_dir else tcl_tk _find_tcl_tk_dir return tcl_tk
def _get_incron_cmdstr path return 'incrontab{0}'.format path
def _format_info data return {'gid' data.pw_gid 'groups' list_groups data.pw_name 'home' data.pw_dir 'name' data.pw_name 'shell' data.pw_shell 'uid' data.pw_uid 'fullname' data.pw_gecos}
def template_allocate call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thetemplate_allocatefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}path kwargs.get 'path' None data kwargs.get 'data' None if data if path log.warning "Boththe'data'and'path'argumentswereprovided.'data'willtakeprecedence." elif path data salt.utils.fopen path mode 'r' .read else raise SaltCloudSystemExit "Thetemplate_allocatefunctionrequireseither'data'orafile'path'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] response server.one.template.allocate auth data ret {'action' 'template.allocate' 'allocated' response[0] 'template_id' response[1] 'error_code' response[2]}return ret
def require_not_initialized exception def decorator method @wraps method def wrapped_method self *args **kwargs if self.initialized raise exceptionreturn method self *args **kwargs return wrapped_methodreturn decorator
def in6_chksum nh u p ph6 PseudoIPv6 ph6.nh nhrthdr 0hahdr 0final_dest_addr_found 0while u ! None and not isinstance u IPv6 if isinstance u IPv6ExtHdrRouting and u.segleft ! 0 and len u.addresses ! 0 and final_dest_addr_found 0 rthdr u.addresses[ -1 ]final_dest_addr_found 1elif isinstance u IPv6ExtHdrDestOpt and len u.options 1 and isinstance u.options[0] HAO hahdr u.options[0].hoau u.underlayerif u is None warning 'NoIPv6underlayertocomputechecksum.Leavingnull.' return 0if hahdr ph6.src hahdrelse ph6.src u.srcif rthdr ph6.dst rthdrelse ph6.dst u.dstph6.uplen len p ph6s str ph6 return checksum ph6s + p
def _edge_func G if G.is_multigraph def get_edges nbunch None return G.edges nbunch keys True else def get_edges nbunch None return G.edges nbunch return get_edges
def increase_stream_retention_period stream_name retention_hours region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r _execute_with_retries conn 'increase_stream_retention_period' StreamName stream_name RetentionPeriodHours retention_hours if 'error' not in r r['result'] Truereturn r
def contains_whitespace text return any x.isspace for x in text
def proto2methodprotofunc proto return proto.replace '' '' .replace ' ' '' .replace '[' '' .replace ' ' '' .replace '/' '_' .replace ';' ''
def test_repr_latex scangle Angle 2.1 u.deg rlscangle scangle._repr_latex_ arrangle Angle [1 2.1] u.deg rlarrangle arrangle._repr_latex_ assert rlscangle u'$2^\\circ06{}^\\prime00{}^{\\prime\\prime}$' assert rlscangle.split u'$' [1] in rlarrangle bigarrangle Angle np.ones 50000 / 50000.0 u.deg assert u'...' in bigarrangle._repr_latex_
def CheckOutputFile filename full_path os.path.abspath filename if os.path.exists full_path raise FileExistsError '%s outputfileexists' % filename elif not os.access os.path.dirname full_path os.W_OK raise FileNotWritableError '%s notwritable' % os.path.dirname full_path
def DoubleToStringAddress number number int number address '%i.%i.%i.%i' % number >> 8 * 3 & 255 number >> 8 * 2 & 255 number >> 8 & 255 number & 255 return address
def fix_xml_ampersands xml_str return re.sub u'& ?!amp;|lt;|gt;|apos;|quot;|#x[0-9a-fA-F]{ 4};|#[0-9]{ 4}; ' u'&amp;' xml_str
def get_n_primes_near_x number target if target 1 and number 1 return [1]primes []i target - 1 if i % 2 0 i - 1while len primes ! number and i > 0 if is_prime i primes.append int i i - 2if len primes ! number raise RuntimeError 'unabletofind%dprimenumbers<%d' % number target return primes
def close *args if len args 0 figManager _pylab_helpers.Gcf.get_active if figManager is None returnelse _pylab_helpers.Gcf.destroy figManager.num elif len args 1 arg args[0]if arg u'all' _pylab_helpers.Gcf.destroy_all elif isinstance arg six.integer_types _pylab_helpers.Gcf.destroy arg elif hasattr arg u'int' _pylab_helpers.Gcf.destroy arg.int elif is_string_like arg allLabels get_figlabels if arg in allLabels num get_fignums [allLabels.index arg ]_pylab_helpers.Gcf.destroy num elif isinstance arg Figure _pylab_helpers.Gcf.destroy_fig arg else raise TypeError u'Unrecognizedargumenttype%stoclose' % type arg else raise TypeError u'closetakes0or1arguments'
@ndb.taskletdef _make_token_async scopes service_account_id rpc app_identity.create_rpc app_identity.make_get_access_token_call rpc scopes service_account_id token expires_at yield rpc raise ndb.Return token expires_at
def _connect_secureish *args **kwargs if tuple int x for x in boto.__version__.split '.' > 2 6 0 kwargs['validate_certs'] Truekwargs['is_secure'] Trueauth_region_name kwargs.pop 'auth_region_name' None conn connection.S3Connection *args **kwargs if auth_region_name conn.auth_region_name auth_region_namereturn conn
def glyph_role name rawtext text lineno inliner options {} content [] target options.get 'target' None glyph_name 'glyphicon-{}'.format text if target target utils.unescape target new_element nodes.reference rawtext '' refuri target else new_element nodes.container classes options.setdefault 'class' [] classes + ['glyphicon' glyph_name]for custom_class in classes new_element.set_class custom_class return [new_element] []
@abortsdef test_require_noniterable_provided_by_key def fake_providing_function passrequire 'foo' provided_by fake_providing_function
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def _compute_reprs net_in net layers_style layers_content gram_scale 1 repr_s repr_c {} {} net.blobs['data'].data[0] net_innet.forward for layer in set layers_style | set layers_content F net.blobs[layer].data[0].copy F.shape F.shape[0] -1 repr_c[layer] Fif layer in layers_style repr_s[layer] sgemm gram_scale F F.T return repr_s repr_c
def load_data_file fname directory None force_download False _url_root 'http //github.com/vispy/demo-data/raw/master/'url _url_root + fname if directory is None directory config['data_path']if directory is None raise ValueError 'config["data_path"]isnotdefined sodirectorymustbesupplied' fname op.join directory op.normcase fname if op.isfile fname if not force_download return fnameif isinstance force_download string_types ntime time.strptime force_download '%Y-%m-%d' ftime time.gmtime op.getctime fname if ftime > ntime return fnameelse print 'Fileolderthan%s updating...' % force_download if not op.isdir op.dirname fname os.makedirs op.abspath op.dirname fname _fetch_file url fname return fname
def unpack_unicode data pos lenlen 2 nchars unpack '<' + 'BH'[ lenlen - 1 ] data[pos pos + lenlen ] [0]if not nchars return UNICODE_LITERAL '' pos + lenlenoptions BYTES_ORD data[pos] pos + 1if options & 8 pos + 2if options & 4 pos + 4if options & 1 rawstrg data[pos pos + 2 * nchars ]strg unicode rawstrg 'utf_16_le' else strg unicode data[pos pos + nchars ] 'latin_1' return strg
def url_validator key data errors context import urlparseimport stringmodel context['model']session context['session']url data.get key None if not url returnpieces urlparse.urlparse url if all [pieces.scheme pieces.netloc] and set pieces.netloc < set string.letters + string.digits + '-.' and pieces.scheme in ['http' 'https'] returnerrors[key].append _ 'PleaseprovideavalidURL'
def no_assert_true_false_is_not logical_line _re re.compile 'assert True|False \\ .+\\s+is\\s+ not\\s+ ?.+\\ $' if _re.search logical_line yield 0 'N356 assertTrue Ais|isnotB orassertFalse Ais|isnotB sentencesmustnotbeused.UseassertIs A B orassertIsNot A B instead'
def convert_string_to_number value if value is None return 1if isinstance value int return valueif value.isdigit return int value num_list map lambda s hashnum s re.findall numbers + '+' value re.IGNORECASE return sum num_list
@pytest.mark.parametrize u'model_class' [cls for cls in list linear1d + list linear2d if isinstance cls PolynomialBase ] def test_polynomial_init_with_constraints model_class if u'1D' in model_class.__name__ param u'c0'else param u'c0_0'if issubclass model_class OrthoPolynomialBase degree 2 2 else degree 2 m model_class fixed {param True} *degree assert m.fixed[param] is True assert getattr m param .fixed is True
def _imshow_tfr_unified bn ch_idx tmin tmax vmin vmax onselect ylim None tfr None freq None vline None x_label None y_label None colorbar False picker True cmap 'RdBu_r' title None hline None _compute_scalings bn tmin tmax freq[0] freq[ -1 ] ax bn.axdata_lines bn.data_linesextent bn.x_t + bn.x_s * tmin bn.x_t + bn.x_s * tmax bn.y_t + bn.y_s * freq[0] bn.y_t + bn.y_s * freq[ -1 ] data_lines.append ax.imshow tfr[ch_idx] clip_on True clip_box bn.pos extent extent aspect 'auto' origin 'lower' vmin vmin vmax vmax cmap cmap
def splititer pattern string maxsplit 0 flags 0 concurrent None **kwargs return _compile pattern flags kwargs .splititer string maxsplit concurrent
def _make_graph_edges_3d n_x n_y n_z vertices np.arange n_x * n_y * n_z .reshape n_x n_y n_z edges_deep np.vstack vertices[ -1 ].ravel vertices[ 1 ].ravel edges_right np.vstack vertices[ -1 ].ravel vertices[ 1 ].ravel edges_down np.vstack vertices[ -1 ].ravel vertices[1 ].ravel edges np.hstack edges_deep edges_right edges_down return edges
def block_until_http_ready urlstring wait_time 10 timeout 240 server_ready Falset_elapsed 0while not server_ready and t_elapsed < timeout try sys.stdout.write '.' sys.stdout.flush req urllib2.Request urlstring response urllib2.urlopen req server_ready Trueexcept urllib2.URLError passtime.sleep wait_time t_elapsed + wait_time
def build_http if socket.getdefaulttimeout is not None http_timeout socket.getdefaulttimeout else http_timeout DEFAULT_HTTP_TIMEOUT_SECreturn httplib2.Http timeout http_timeout
def _getRandomNumber random bits if bits % 8 raise ValueError 'bits %d mustbeamultipleof8' % bits bytes random bits / 8 result Util.number.bytes_to_long bytes return result
def opener some_file command print '\nOpening%s\n' % some_file.strip '../' os.system '%s%s' % command some_file
def DNSServiceBrowse flags 0 interfaceIndex kDNSServiceInterfaceIndexAny regtype _NO_DEFAULT domain None callBack None _NO_DEFAULT.check regtype @_DNSServiceBrowseReplydef _callback sdRef flags interfaceIndex errorCode serviceName regtype replyDomain context if callBack is not None callBack sdRef flags interfaceIndex errorCode serviceName.decode regtype.decode replyDomain.decode _global_lock.acquire try sdRef _DNSServiceBrowse flags interfaceIndex regtype domain _callback None finally _global_lock.release sdRef._add_callback _callback return sdRef
def curl_head_command ip port device part target policy_index if is_valid_ipv6 ip formatted_ip '[%s]' % ip else formatted_ip ipcmd 'curl-g-I-XHEAD"http //%s %s/%s/%s/%s"' % formatted_ip port device part urllib.parse.quote target if policy_index is not None cmd + '-H"%s %s"' % 'X-Backend-Storage-Policy-Index' policy_index return cmd
def call_switch *args **kwargs out dict devices _get_lights for dev_id in 'id' not in kwargs and sorted devices.keys or _get_devices kwargs if 'on' in kwargs state kwargs['on'] and Const.LAMP_ON or Const.LAMP_OFF else state devices[str dev_id ]['state']['on'] and Const.LAMP_OFF or Const.LAMP_ON out[dev_id] _set dev_id state return out
def test_relu x K.placeholder ndim 2 f K.function [x] [activations.relu x ] test_values get_standard_values result f [test_values] [0]assert_allclose result test_values rtol 1e-05
def make_url filename path abspath filename last_modified os.stat path .st_mtimeif settings.ASSETS_EXPIRE 'querystring' result '%s?%d' % filename last_modified elif settings.ASSETS_EXPIRE 'filename' name filename.rsplit '.' 1 if len name > 1 result '%s.%d.%s' % name[0] last_modified name[1] else result '%s.%d' % name last_modified elif not settings.ASSETS_EXPIRE result filenameelse raise ValueError 'UnknownvalueforASSETS_EXPIREoption %s' % settings.ASSETS_EXPIRE return absurl result
def getManipulatedGeometryOutput geometryOutput xmlElement scalePoints matrix.getConnectionVertexes geometryOutput 'scale.' xmlElement return geometryOutput
def pow_neg p max_denom 1024 assert p < 0 p Fraction p p Fraction p / p - 1 .limit_denominator max_denom return p / p - 1 p 1 - p
def fidelity state1 state2 state1 represent state1 if isinstance state1 Density else state1 state2 represent state2 if isinstance state2 Density else state2 if not isinstance state1 Matrix or not isinstance state2 Matrix raise ValueError 'state1andstate2mustbeoftypeDensityorMatrixreceivedtype %sforstate1andtype %sforstate2' % type state1 type state2 if state1.shape ! state2.shape and state1.is_square raise ValueError 'Thedimensionsofbothargsshouldbeequalandthematrixobtainedshouldbeasquarematrix' sqrt_state1 state1 ** Rational 1 2 return Tr sqrt_state1 * state2 * sqrt_state1 ** Rational 1 2 .doit
def Application_EndRequest app e pass
def get_files_recursive src fmt for root dirnames filenames in os.walk src for filename in fnmatch.filter filenames '*' + fmt yield os.path.join root filename
def eigenhproblem_standard desc dim dtype overwrite lower turbo eigenvalues if iscomplex empty 1 dtype dtype a _complex_symrand dim dtype else a symrand dim .astype dtype if overwrite a_c a.copy else a_c a w z eigh a overwrite_a overwrite lower lower eigvals eigenvalues assert_dtype_equal z.dtype dtype w w.astype dtype diag_ diag dot z.T.conj dot a_c z .realassert_array_almost_equal diag_ w DIGITS[dtype]
def action_allowed_user user app action allowed any match_rules group.rules app action for group in user.groups.all return allowed
def urlencode query if isinstance query dict query query.items return u'&'.join [u' '.join [escape k escape v ] for k v in query]
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def iterator_impl iterable_type iterator_type def wrapper cls iternext cls.iternext@iternext_impldef iternext_wrapper context builder sig args result value argsiterobj cls context builder value return iternext iterobj context builder result lower_builtin 'iternext' iterator_type iternext_wrapper return clsreturn wrapper
def __VersionIsSupported desiredVersion serviceVersionDescription root serviceVersionDescriptionif root.tag 'namespaces' if root.get 'version' ! '1.0' raise RuntimeError 'vimServiceVersions.xmlhasversion%s whichisnotunderstood' % root.get 'version' desiredVersionId versionIdMap[desiredVersion]supportedVersion Nonefor namespace in root.findall 'namespace' versionId namespace.findtext 'version' if versionId desiredVersionId return Trueelse for versionId in namespace.findall 'priorVersions/version' if versionId.text desiredVersionId return Trueelse wsdlNS 'http //schemas.xmlsoap.org/wsdl/'importElement serviceVersionDescription.find './/{%s}import' % wsdlNS supportedVersion versionMap[importElement.get 'namespace' [4 ]]if IsChildVersion supportedVersion desiredVersion return Truereturn False
def _ExecuteQuery results query filters orders index_list orders _GuessOrders filters orders dsquery _MakeQuery query filters orders if query.property_name_size results _CreateIndexOnlyQueryResults results set order.property for order in orders return ListCursor query dsquery orders index_list datastore_query.apply_query dsquery results
def datetime_to_iso timestamp return datetime.strptime timestamp '%Y-%m-%d%H %M %S' .isoformat
def check_old_queue old Falseif not os.path.exists os.path.join cfg.admin_dir.get_path QUEUE_FILE_NAME for ver in QUEUE_VERSION - 1 QUEUE_VERSION - 2 QUEUE_VERSION - 3 data load_admin QUEUE_FILE_TMPL % str ver if data breaktry old bool data and isinstance data tuple and len data[1] except TypeError IndexError passif old and sabnzbd.WIN32 and ver < 10 and sabnzbd.DIR_LCLDATA ! sabnzbd.DIR_HOME and misc.is_relative_path cfg.download_dir cfg.download_dir.set 'Documents/' + cfg.download_dir return old
def cc_test name srcs [] deps [] warning 'yes' defs [] incs [] embed_version False optimize [] dynamic_link None testdata [] extra_cppflags [] extra_linkflags [] export_dynamic False always_run False exclusive False heap_check None heap_check_debug False **kwargs cc_test_target CcTest name srcs deps warning defs incs embed_version optimize dynamic_link testdata extra_cppflags extra_linkflags export_dynamic always_run exclusive heap_check heap_check_debug blade.blade kwargs blade.blade.register_target cc_test_target
def get_entity_kind key_path if isinstance key_path entity_pb.EntityProto key_path key_path.key return key_path.path .element_list [ -1 ].type
def fake_get_value name default None return FAKE_SITE.get name default
def consistencygroup_create context values cg_snap_id None cg_id None return IMPL.consistencygroup_create context values cg_snap_id cg_id
def record_affiliate_registration_attribution request user affiliate_id request.COOKIES.get settings.AFFILIATE_COOKIE_NAME if user and affiliate_id UserAttribute.set_user_attribute user REGISTRATION_AFFILIATE_ID affiliate_id
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def _escapify qstring text ''for c in qstring if c in __escaped text + '\\' + c elif ord c > 32 and ord c < 127 text + celse text + '\\%03d' % ord c return text
def is_object_patched modname objname return is_module_patched modname and objname in saved[modname]
def import_aes module_name return __import__ module_name fromlist [module_name.split '.' [ -1 ]]
def rangename3d book ref3d coords ref3d.coordsreturn '%s!%s' % sheetrange book *coords[ 2] rangename2d *coords[2 6]
def _ll_nbp y X beta alph Q mu np.exp np.dot X beta size 1 / alph * mu ** Q prob size / size + mu ll nbinom.logpmf y size prob return ll
def getGeometryOutputByFunction manipulationFunction xmlElement geometryOutput []target evaluate.getPathsByKey 'target' xmlElement for path in target geometryOutput + getGeometryOutputByLoopFunction manipulationFunction SideLoop path xmlElement return getUnpackedLoops geometryOutput
def _filter_plans attr name plans return [plan for plan in plans if plan[attr] name ]
def get_session_count global HOUSEcnt 0if len HOUSE.keys > 0 for key in HOUSE.keys for entry in HOUSE[key] if HOUSE[key][entry].running cnt + 1return cnt
def test_prewitt_v_horizontal i j np.mgrid[ -5 6 -5 6]image i > 0 .astype float result filters.prewitt_v image assert_allclose result 0
def do_unblock move_entry blocked_list blocked unblocked_list unblocked
def fix_lib64 lib_dir symlink True if [p for p in distutils.sysconfig.get_config_vars .values if isinstance p basestring and 'lib64' in p ] if is_pypy logger.debug 'PyPydetected skippinglib64symlinking' returnlogger.debug 'Thissystemuseslib64;symlinkinglib64tolib' assert os.path.basename lib_dir 'python%s' % sys.version[ 3] 'Unexpectedpythonlibdir %r' % lib_dir lib_parent os.path.dirname lib_dir top_level os.path.dirname lib_parent lib_dir os.path.join top_level 'lib' lib64_link os.path.join top_level 'lib64' assert os.path.basename lib_parent 'lib' 'Unexpectedparentdir %r' % lib_parent if os.path.lexists lib64_link returncp_or_ln os.symlink if symlink else copyfile cp_or_ln 'lib' lib64_link
def load_parser path p_time os.path.getmtime path if path else None try parser_cache_item parser_cache[path]if not path or p_time < parser_cache_item.change_time return parser_cache_item.parserexcept KeyError if settings.use_filesystem_cache return ParserPickling.load_parser path p_time
def hashPassword password digestMod hashlib.sha512 iterations 10000 saltSize 32 digestname iterations salt hash hashPasswordTuple password digestMod iterations saltSize return Delimiter.join [digestname str iterations base64.b64encode salt .decode u'ascii' base64.b64encode hash .decode u'ascii' ]
def test_io_layout_lay tempdir _TempDir layout read_layout 'CTF151' scale False layout.save op.join tempdir 'foobar.lay' layout_read read_layout op.join tempdir 'foobar.lay' path './' scale False assert_array_almost_equal layout.pos layout_read.pos decimal 2 assert_true layout.names layout_read.names
def test_read_detect_col_starts_or_ends table '\n#1919< Columnstartindexes\n#|||< Columnstartpositions\n#<------><--------><------------->< Inferredcolumnpositions\nJohn555-1234192.168.1.10\nMary555-2134192.168.1.123\nBob555-4527192.168.1.9\nBill555-9875192.255.255.255\n'for kwargs in {'col_starts' 1 9 19 } {'col_ends' 8 18 33 } dat ascii.read table Reader ascii.FixedWidthNoHeader names 'Name' 'Phone' 'TCP' **kwargs assert_equal tuple dat.dtype.names 'Name' 'Phone' 'TCP' assert_equal dat[0][1] '555-1234' assert_equal dat[1][0] 'Mary' assert_equal dat[1][2] '192.168.1.123' assert_equal dat[3][2] '192.255.255.255'
def addNoise input noise 0.1 doForeground True doBackground True if doForeground and doBackground return numpy.abs input - numpy.random.random input.shape < noise else if doForeground return numpy.logical_and input numpy.random.random input.shape > noise if doBackground return numpy.logical_or input numpy.random.random input.shape < noise return input
def validate_not_part_of_system_pack resource_db pack getattr resource_db 'pack' None if pack SYSTEM_PACK_NAME msg "Resourcesbelongingtosystemlevelpackscan'tbemanipulated"raise ValueValidationException msg return resource_db
def create_order_source prices_include_tax line_data tax_rates lines [Line.from_text x for x in line_data]shop get_shop prices_include_tax currency u'USD' tax_classes create_assigned_tax_classes tax_rates products create_products shop lines tax_classes services create_services shop lines tax_classes source OrderSource shop fill_order_source source lines products services return source
def p_throws p p[0] p[3]
def _user_is_admin object_list bundle if settings.CENTRAL_SERVER and _is_central_object_admin object_list bundle return Trueif getattr bundle.request 'is_admin' False return True
def get_previous_url request referer_url request.META.get 'HTTP_REFERER' '' if referer_url parsed_referer urlparse.urlparse referer_url referer_host parsed_referer.netlocreferer_path parsed_referer.pathreferer_query parsed_referer.queryserver_host request.get_host if referer_host server_host and '/translate/' not in referer_path if referer_query referer_url referer_url[ referer_url.index '?' ]if 'details' in referer_query referer_url '%s?details' % referer_url return referer_urlreturn reverse 'pootle-home'
def temporaryApplyOverrides repository global globalTemporaryOverridesif repository.baseName in globalTemporaryOverrides settingTable {}for setting in repository.preferences settingTable[setting.name] settingfor name value in overrides[repository.baseName].items if name in settingTable settingTable[name].setValueToString value else print 'Overridenotappliedfor %s %s' % name value
def test_object_size assert_true object_size np.ones 10 np.float32 < object_size np.ones 10 np.float64 for lower upper obj in 0 60 '' 0 30 1 0 30 1.0 0 60 'foo' 0 150 np.ones 0 0 150 np.int32 1 150 500 np.ones 20 100 400 dict 400 1000 dict a np.ones 50 200 900 sparse.eye 20 format 'csc' 200 900 sparse.eye 20 format 'csr' size object_size obj assert_true lower < size < upper msg '%s<%s<%s \n%s' % lower size upper obj
def name_servers nameservers for_item True if isinstance nameservers basestring nameservers nameservers.strip if for_item is True if nameservers in ['<<inherit>>' ''] return nameserversnameservers shlex.split nameservers if isinstance nameservers list for ns in nameservers ip_version netaddr.IPAddress ns .versionif ip_version 4 ipv4_address ns elif ip_version 6 ipv6_address ns else raise CX 'InvalidIPaddressformat' else raise CX 'Invalidinputtype%s expectedstrorlist' % type nameservers return nameservers
def p_logical_or_expression_2 t pass
def _debuginit self exc_value None exc_type None exc_tb None Failure__init__ Failure.__init__.im_func if exc_value exc_type exc_tb None None None exc sys.exc_info if not exc[0] self.__class__ and DO_POST_MORTEM try strrepr str exc[1] except strrepr 'brokenstr'print "Jumpingintodebuggerforpost-mortemofexception'%s' " % strrepr import pdbpdb.post_mortem exc[2] Failure__init__ self exc_value exc_type exc_tb
def start_user_as_anon return {'user' ANON}
def process_open_files attrs None where None return _osquery_cmd table 'process_open_files' attrs attrs where where
def ticketdb if len request.args ! 2 session.flash T 'invalidticket' redirect URL 'site' app get_app myversion request.env.web2py_versionticket request.args[1]e RestrictedError request.tickets_db get_ticket_storage app [0]e.load request app ticket response.view 'default/ticket.html'return dict app app ticket ticket output e.output traceback e.traceback and TRACEBACK e.traceback snapshot e.snapshot code e.code layer e.layer myversion myversion
def test_io_stc tempdir _TempDir stc _fake_stc stc.save op.join tempdir 'tmp.stc' stc2 read_source_estimate op.join tempdir 'tmp.stc' assert_array_almost_equal stc.data stc2.data assert_array_almost_equal stc.tmin stc2.tmin assert_equal len stc.vertices len stc2.vertices for v1 v2 in zip stc.vertices stc2.vertices assert_array_almost_equal v1 v2 assert_array_almost_equal stc.tstep stc2.tstep
def data_sharing_consent_requested request if not enterprise_enabled return Falsereturn active_provider_requests_data_sharing request
def test_keypoints_censure_mode_validity_error assert_raises ValueError CENSURE mode 'dummy'
def serial proxy if proxy return {'serial' _get_grain proxy 'serial_number' }
def system commandline logging.info commandline return os.system commandline
def _last_post_from posts exclude_post None if exclude_post posts posts.exclude id exclude_post.id posts posts.order_by '-created' try return posts[0]except IndexError return None
def getSplitDictionary global globalSplitDictionaryOperatorsplitDictionary globalSplitDictionaryOperator.copy global globalDictionaryOperatorBeginsplitDictionary.update globalDictionaryOperatorBegin splitDictionary['and'] EvaluatorAndsplitDictionary['false'] EvaluatorFalsesplitDictionary['False'] EvaluatorFalsesplitDictionary['or'] EvaluatorOrsplitDictionary['not'] EvaluatorNotsplitDictionary['true'] EvaluatorTruesplitDictionary['True'] EvaluatorTruesplitDictionary['none'] EvaluatorNonesplitDictionary['None'] EvaluatorNonereturn splitDictionary
def hankel_transform f r k nu **hints return HankelTransform f r k nu .doit **hints
def cycle_by_name name return symbol_by_name name CYCLE_ALIASES
def enable_term_protect name call None if call ! 'action' raise SaltCloudSystemExit 'Theenable_term_protectactionmustbecalledwith-aor--action.' return _toggle_term_protect name 'true'
def _make_dipoles times poss oris sol gof amplitude sol * 1000000000.0 oris np.array oris dipoles []for i_dip in range poss.shape[0] i_pos poss[i_dip][np.newaxis ].repeat len times axis 0 i_ori oris[i_dip][np.newaxis ].repeat len times axis 0 dipoles.append Dipole times i_pos amplitude[i_dip] i_ori gof return dipoles
def fake_function *args **kwargs if 'callable' not in kwargs and 'expect_call' not in kwargs kwargs['callable'] Truereturn Fake *args **kwargs .has_attr __name__ 'fake'
def separatevars expr symbols [] dict False force False expr sympify expr if dict return _separatevars_dict _separatevars expr force symbols else return _separatevars expr force
def _AnnotateIndents tree if tree.parent is None pytree_utils.SetNodeAnnotation tree pytree_utils.Annotation.CHILD_INDENT '' for child in tree.children if child.type token.INDENT child_indent pytree_utils.GetNodeAnnotation tree pytree_utils.Annotation.CHILD_INDENT if child_indent is not None and child_indent ! child.value raise RuntimeError 'inconsistentindentationforchild' tree child pytree_utils.SetNodeAnnotation tree pytree_utils.Annotation.CHILD_INDENT child.value _AnnotateIndents child
def parse_trees filename data open 'test_file' 'r' .read for tree_str in data.split ';\n' if tree_str yield Trees.Tree tree_str + ';'
def send_email_to_qualified_users query_id email_subject email_body email_intent max_recipients query_model user_models.UserQueryModel.get query_id query_model.query_status feconf.USER_QUERY_STATUS_ARCHIVEDrecipient_ids query_model.user_idsif max_recipients recipient_ids recipient_ids[ max_recipients]bulk_email_model_id email_manager.send_user_query_email query_model.submitter_id recipient_ids email_subject email_body email_intent query_model.sent_email_model_id bulk_email_model_idquery_model.put for recipient_id in recipient_ids recipient_bulk_email_model user_models.UserBulkEmailsModel.get recipient_id strict False if recipient_bulk_email_model is None recipient_bulk_email_model user_models.UserBulkEmailsModel id recipient_id sent_email_model_ids [] recipient_bulk_email_model.sent_email_model_ids.append bulk_email_model_id recipient_bulk_email_model.put
def job name jobs _jobs if name in jobs return {'job' jobs[name]}return None
def tokenize_grant grant return _grant_to_tokens grant
def generate_zipfiles gallery_dir listdir list_downloadable_sources gallery_dir for directory in sorted os.listdir gallery_dir if os.path.isdir os.path.join gallery_dir directory target_dir os.path.join gallery_dir directory listdir.extend list_downloadable_sources target_dir py_zipfile python_zip listdir gallery_dir jy_zipfile python_zip listdir gallery_dir '.ipynb' dw_rst CODE_ZIP_DOWNLOAD.format os.path.basename py_zipfile py_zipfile os.path.basename jy_zipfile jy_zipfile return dw_rst
@when u'wedropdatabase' def step_db_drop context context.cli.sendline u'dropdatabase{0};'.format context.conf[u'dbname_tmp']
def mangle_type_c typ if typ in C2CODE return C2CODE[typ]else return 'u' + mangle_identifier typ
def systemInformationType3 a L2PseudoLength l2pLength 18 b TpPd pd 6 c MessageType mesType 27 d CellIdentity e LocalAreaId f ControlChannelDescription g CellOptionsBCCH h CellSelectionParameters i RachControlParameters j Si3RestOctets packet a / b / c / d / e / f / g / h / i / j return packet
def get_data_home data_home None if data_home is None data_home os.environ.get 'SEABORN_DATA' os.path.join '~' 'seaborn-data' data_home os.path.expanduser data_home if not os.path.exists data_home os.makedirs data_home return data_home
def getNewRepository return FillRepository
def merge_lookup A B lookup_table np.array A.lookup_table mask np.isfinite lookup_table indices np.array lookup_table[mask] dtype int lookup_table[mask] B.lookup_table[indices]return Lookup A.variable lookup_table
def set_custom sld tld nameservers opts salt.utils.namecheap.get_opts 'namecheap.domains.dns.setCustom' opts['SLD'] sldopts['TLD'] tldopts['Nameservers'] ' '.join nameservers response_xml salt.utils.namecheap.post_request opts if response_xml is None return Falsednsresult response_xml.getElementsByTagName 'DomainDNSSetCustomResult' [0]return salt.utils.namecheap.string_to_value dnsresult.getAttribute 'Update'
def killed manager containers count name containers.refresh manager.kill_containers containers.running containers.notice_changed manager.get_inspect_containers containers.running
def get_context_from_function_and_args function args kwargs for arg in itertools.chain kwargs.values args if isinstance arg RequestContext return argreturn None
def generate_random_numeric length return ''.join random.choice string.digits for _x in range length
def exclude_paths root patterns dockerfile None if dockerfile is None dockerfile 'Dockerfile'exceptions [p for p in patterns if p.startswith '!' ]include_patterns [p[1 ] for p in exceptions]include_patterns + [dockerfile '.dockerignore']exclude_patterns list set patterns - set exceptions paths get_paths root exclude_patterns include_patterns has_exceptions len exceptions > 0 return set paths .union set [dockerfile] if os.path.exists os.path.join root dockerfile else set
def Assign target source if not isinstance target list target [target]if not isinstance source list source.prefix u''source [source]return Node syms.atom target + [Leaf token.EQUAL u' ' prefix u'' ] + source
def CollectionItemToAff4Path item if isinstance item rdf_flows.GrrMessage item item.payloadif isinstance item rdf_client.StatEntry return item.aff4pathelif isinstance item rdf_file_finder.FileFinderResult return item.stat_entry.aff4pathelif isinstance item collectors.ArtifactFilesDownloaderResult if item.HasField 'downloaded_file' return item.downloaded_file.aff4pathraise ItemNotExportableError
def getdefaultlocale envvars 'LC_ALL' 'LC_CTYPE' 'LANG' 'LANGUAGE' try import _locale code encoding _locale._getdefaultlocale except ImportError AttributeError passelse if sys.platform 'win32' and code and code[ 2] '0x' code windows_locale.get int code 0 return code encoding import oslookup os.environ.getfor variable in envvars localename lookup variable None if localename if variable 'LANGUAGE' localename localename.split ' ' [0]breakelse localename 'C'return _parse_localename localename
def replace name repl full_match False ret {'name' name 'result' False 'changes' {} 'comment' ''}if full_match is False search '^.*{0}.*$'.format name else search namematches __salt__['nxos.cmd'] 'find' search if not matches ret['result'] Trueret['comment'] 'Nothingfoundtoreplace'return retif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configswillbechanged'ret['changes']['old'] matchesret['changes']['new'] [re.sub name repl match for match in matches]return retret['changes'] __salt__['nxos.cmd'] 'replace' name repl full_match full_match matches __salt__['nxos.cmd'] 'find' search if matches ret['result'] Falseret['comment'] 'Failedtoreplaceallinstancesof"{0}"'.format name else ret['result'] Trueret['comment'] 'Successfullyreplacedallinstancesof"{0}"with"{1}"'.format name repl return ret
def basic_auth realm users encrypt None debug False if check_auth users encrypt if debug cherrypy.log 'Authsuccessful' 'TOOLS.BASIC_AUTH' returncherrypy.serving.response.headers['www-authenticate'] httpauth.basicAuth realm raise cherrypy.HTTPError 401 'Youarenotauthorizedtoaccessthatresource'
def reserve_quota_delta context deltas instance quotas objects.Quotas context context if deltas project_id user_id objects.quotas.ids_from_instance context instance quotas.reserve project_id project_id user_id user_id **deltas return quotas
def get_merged_prs start_ref end_ref ensure_pr_fetch start_unmerged_branches set branch.strip for branch in git.branch all True no_merged start_ref .splitlines end_merged_branches set branch.strip for branch in git.branch all True merged end_ref .splitlines merged_between_refs start_unmerged_branches & end_merged_branches merged_prs set for branch in merged_between_refs match PR_BRANCH_RE.search branch if match merged_prs.add int match.group 1 return merged_prs
def is_booted_from_volume session vm_ref vbd_ref find_vbd_by_number session vm_ref 0 vbd_other_config session.VBD.get_other_config vbd_ref if vbd_other_config.get 'osvol' False return Truereturn False
def set_region region _local.region region
def make_filename name for _ in FILENAME_EXCLUDE name name.replace _ '' return ''.join s.title for s in name.split if s
def _find_smart_path challbs preferences combinations chall_cost {}max_cost 1for i chall_cls in enumerate preferences chall_cost[chall_cls] imax_cost + ibest_combo []best_combo_cost max_costcombo_total 0for combo in combinations for challenge_index in combo combo_total + chall_cost.get challbs[challenge_index].chall.__class__ max_cost if combo_total < best_combo_cost best_combo combobest_combo_cost combo_totalcombo_total 0if not best_combo _report_no_chall_path return best_combo
def event_return events opts _get_options {} opts['skip'] Truefor event in events log.trace 'Carbonreturnerreceivedevent {0}'.format event metric_base event['tag']saltdata event['data'].get 'data' _send saltdata metric_base opts
def is_okay pkt if int pkt[0] 16 7 if set pkt set ['07' '00' '00' '01' '00' '00' '00' '02' '00' '00' '00'] return Truereturn False
def foldl fn elems initializer None name None if initializer is None initializer elems[0]elems elems[1 ]fn2 lambda x acc fn acc x return theano.foldl fn2 elems initializer name name [0]
def _make_fragment_list pp length frag_list []for i in range 0 len pp - length + 1 f Fragment length -1 for j in range 0 length residue pp[ i + j ]resname residue.get_resname if residue.has_id 'CA' ca residue['CA']else raise PDBException 'CHAINBREAK' if ca.is_disordered raise PDBException 'CHAINBREAK' ca_coord ca.get_coord f.add_residue resname ca_coord frag_list.append f return frag_list
def requeue queue index -1 x queue.pop index queue.insert 0 x return x
def _update_query_params uri params parts urllib.parse.urlparse uri query_params dict urllib.parse.parse_qsl parts.query query_params.update params new_parts parts._replace query urllib.parse.urlencode query_params return urllib.parse.urlunparse new_parts
def get_environ_proxies proxy_keys ['all' 'http' 'https' 'ftp' 'socks' 'no']get_proxy lambda k os.environ.get k or os.environ.get k.upper proxies [ key get_proxy key + '_proxy' for key in proxy_keys]return dict [ key val for key val in proxies if val]
def get_random_mac mac [254 22 62 random.randint 0 255 random.randint 0 255 random.randint 0 255 ]return ' '.join map lambda x '%02x' % x mac
def getFloatFromValue value try return float value except passreturn None
def _save_rev_and_notify rev_form creator document based_on_id None base_rev None new_rev rev_form.save creator document based_on_id base_rev statsd.incr 'wiki.revision' ReviewableRevisionInLocaleEvent new_rev .fire exclude new_rev.creator EditDocumentEvent new_rev .fire exclude new_rev.creator
def expand_init init typ type init if typ NamedInitializer des [expand_init dp for dp in init.name]return des expand_init init.expr elif typ in InitList ExprList return [expand_init expr for expr in init.exprs]elif typ Constant return ['Constant' init.type init.value]elif typ ID return ['ID' init.name]
def vm_profiles_config path providers env_var 'SALT_CLOUDVM_CONFIG' defaults None if defaults is None defaults VM_CONFIG_DEFAULTSoverrides salt.config.load_config path env_var os.path.join salt.syspaths.CONFIG_DIR 'cloud.profiles' default_include overrides.get 'default_include' defaults['default_include'] include overrides.get 'include' [] overrides.update salt.config.include_config default_include path verbose False overrides.update salt.config.include_config include path verbose True return apply_vm_profiles_config providers overrides defaults
def ask_for_it_by_name name if name not in ask_for_it_by_name.cache ask_for_it_by_name.cache[name] _ask_for_it_by_name name return ask_for_it_by_name.cache[name]
def multiplexer conditions def multiplexer_rl expr for key rule in conditions.items if key expr return rule expr return multiplexer_rl
def totime somedate if not isinstance somedate time return time somedate.hour somedate.minute somedate.second assert isinstance somedate time repr somedate return somedate
def gis_update_location_tree feature user_id None if user_id auth.s3_impersonate user_id feature json.loads feature path gis.update_location_tree feature db.commit return path
def getIsPointCloseInline close loop point pointIndex afterCenterComplex loop[pointIndex]if abs afterCenterComplex - point > close return FalseafterEndComplex loop[ pointIndex + 1 % len loop ]if not isInline point afterCenterComplex afterEndComplex return FalsebeforeCenterComplex loop[ pointIndex + len loop - 1 % len loop ]if abs beforeCenterComplex - point > close return FalsebeforeEndComplex loop[ pointIndex + len loop - 2 % len loop ]return isInline point beforeCenterComplex beforeEndComplex
def cache_global name generate try result read_global name except CacheMiss result generate write_global name result return result
def startLogging file *a **kw if isinstance file LoggingFile returnflo FileLogObserver file startLoggingWithObserver flo.emit *a **kw return flo
def alias aliasPath sourcePath sourcePath sourcePath.split '/' aliasPath aliasPath.split '/' def rewriter request if request.postpath[ len aliasPath ] aliasPath after request.postpath[len aliasPath ]request.postpath sourcePath + after request.path '/' + '/'.join request.prepath + request.postpath return rewriter
def load_yaml_config version checkout_path version.project.checkout_path version.slug try config load_config path checkout_path env_config {'output_base' '' 'type' 'sphinx' 'name' version.slug} [0]except InvalidConfig raiseexcept ConfigError config BuildConfig env_config {} raw_config {} source_file 'empty' source_position 0 return ConfigWrapper version version yaml_config config
def selected_row view if view.selectionMode in [QAbstractItemView.MultiSelection QAbstractItemView.ExtendedSelection] raise ValueError "invalid'selectionMode'" sel_model view.selectionModel indexes sel_model.selectedRows if indexes assert len indexes 1 return indexes[0].row else return None
def gen_jid return '{0 %Y%m%d%H%M%S%f}'.format datetime.datetime.now
def find predicate seq for element in seq if predicate element return elementreturn None
def _gf_trace_map f n g b p K f gf_rem f g p K h fr ffor i in range 1 n h gf_frobenius_map h g b p K r gf_add r h p K r gf_rem r g p K return r
def get_new_file_id secs usecs divmod time.time 1.0 secs usecs int secs int usecs * 1000000.0 return {'machid' get_machid 'version' FIFF.FIFFC_VERSION 'secs' secs 'usecs' usecs}
def test_magic_parse_options ip get_ipython path 'c \\x'm DummyMagics ip opts m.parse_options '-f%s' % path 'f ' [0]if os.name 'posix' expected 'c x'else expected pathnt.assert_equal opts['f'] expected
def already_tapped module brew_path tap rc out err module.run_command [brew_path 'tap'] taps [tap_.strip .lower for tap_ in out.split '\n' if tap_]tap_name re.sub 'homebrew-' '' tap.lower return tap_name in taps
def is_sphinx_markup docstring return '`' in docstring or ' ' in docstring
def parse_ini_file config_file parser ConfigParser.RawConfigParser parser.optionxform strparser.readfp config_file return parser
def _mask_non_positives a mask a < 0.0 if mask.any return ma.MaskedArray a mask mask return a
def replacement_fields s repl_fields_re re.compile '\\{[^\\}]*\\}' return sorted repl_fields_re.findall s
def _joint_probabilities distances desired_perplexity verbose distances astype distances np.float32 copy False conditional_P _utils._binary_search_perplexity distances None desired_perplexity verbose P conditional_P + conditional_P.T sum_P np.maximum np.sum P MACHINE_EPSILON P np.maximum squareform P / sum_P MACHINE_EPSILON return P
def _api_change_script name output kwargs value kwargs.get 'value' value2 kwargs.get 'value2' if value and value2 nzo_id valuescript value2if script.lower 'none' script Noneresult NzbQueue.do.change_script nzo_id script return report output keyword 'status' data bool result > 0 else return report output _MSG_NO_VALUE
def list_common_lookups kwargs None call None if kwargs is None kwargs {}args {}if 'lookup' in kwargs args['lookup'] kwargs['lookup']response _query 'common' 'lookup/list' args args return response
def bind_port sock host HOST if sock.family socket.AF_INET and sock.type socket.SOCK_STREAM if hasattr socket 'SO_REUSEADDR' if sock.getsockopt socket.SOL_SOCKET socket.SO_REUSEADDR 1 raise ValueError 'testsshouldneversettheSO_REUSEADDRsocketoptiononTCP/IPsockets!' if hasattr socket 'SO_REUSEPORT' if sock.getsockopt socket.SOL_SOCKET socket.SO_REUSEPORT 1 raise ValueError 'testsshouldneversettheSO_REUSEPORTsocketoptiononTCP/IPsockets!' if hasattr socket 'SO_EXCLUSIVEADDRUSE' sock.setsockopt socket.SOL_SOCKET socket.SO_EXCLUSIVEADDRUSE 1 sock.bind host 0 port sock.getsockname [1]return port
@Profiler.profiledef test_orm_query_cols_only n session Session bind engine for id_ in random.sample ids n session.query Customer.id Customer.name Customer.description .filter Customer.id id_ .one
def get_configuration options agent_config options[u'agent-config']configuration yaml.safe_load agent_config.getContent validate_configuration configuration configuration configuration['control-service'].setdefault 'port' 4524 path agent_config.parent configuration['ca-certificate'] Certificate.loadPEM path.child 'cluster.crt' .getContent configuration['node-credential'] NodeCredential.from_path path 'node' return configuration
def sdm_monomial_deg M return monomial_deg M[1 ]
def _string_dist_basic str1 str2 assert isinstance str1 six.text_type assert isinstance str2 six.text_type str1 as_string unidecode str1 str2 as_string unidecode str2 str1 re.sub '[^a-z0-9]' '' str1.lower str2 re.sub '[^a-z0-9]' '' str2.lower if not str1 and not str2 return 0.0return levenshtein_distance str1 str2 / float max len str1 len str2
def claModelControlEnableSPLearningCb claModel assert isinstance claModel CLAModel claModel._getSPRegion .setParameter 'learningMode' True return
@register.inclusion_tag 'inclusion.html' def inclusion_unlimited_args_kwargs one two 'hi' *args **kwargs sorted_kwarg sorted six.iteritems kwargs key operator.itemgetter 0 return {'result' 'inclusion_unlimited_args_kwargs-Expectedresult %s/%s' % ' '.join [six.text_type arg for arg in [one two] + list args ] ' '.join [ '%s %s' % k v for k v in sorted_kwarg] }
def sum_shapes shapes rows max [shape[0] for shape in shapes] cols max [shape[1] for shape in shapes] for shape in shapes if not shape 1 1 and shape ! rows cols raise ValueError 'Incompatibledimensions' + len shapes * '%s' % tuple shapes return rows cols
def getEmptyZ shape z zoneIndex round z / shape.zoneInterval if zoneIndex not in shape.zZoneTable return zzoneAround 1while 1 zoneDown zoneIndex - zoneAround if zoneDown not in shape.zZoneTable return zoneDown * shape.zoneInterval zoneUp zoneIndex + zoneAround if zoneUp not in shape.zZoneTable return zoneUp * shape.zoneInterval zoneAround + 1
@cronjobs.registerdef reindex_users_that_contributed_yesterday if settings.STAGE returntoday datetime.now yesterday today - timedelta days 1 user_ids list Answer.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter created__gte yesterday created__lt today .values_list 'creator_id' flat True user_ids + list Revision.objects.filter reviewed__gte yesterday reviewed__lt today .values_list 'reviewer_id' flat True index_task.delay UserMappingType list set user_ids
def get_site_domain return Site.objects.get_current .domain
def test_input_estimator_unchanged est RandomForestClassifier transformer SelectFromModel estimator est transformer.fit data y assert_true transformer.estimator is est
@contextfunctiondef modules_header_block context request context['request'] modules active _get_modules request for module in modules module.title _ module.title response_format 'html'if 'response_format' in context response_format context['response_format']return Markup render_to_string 'core/tags/modules_header_block' {'modules' modules 'active' active 'request' request} response_format response_format
def millisecond_to_clocktime value return value * Gst.MSECOND
def greet name print 'Hello%s!' % name
def make_half_violin x y fillcolor '#1f77b4' linecolor 'rgb 0 0 0 ' text [ ' pdf y y ' + '{ 0.2f}'.format x[i] + ' ' + '{ 0.2f}'.format y[i] + ' ' for i in range len x ]return graph_objs.Scatter x x y y mode 'lines' name '' text text fill 'tonextx' fillcolor fillcolor line graph_objs.Line width 0.5 color linecolor shape 'spline' hoverinfo 'text' opacity 0.5
def PCO_protocol_dispatcher s proto_num ord s[0] * 256 + ord s[1] cls PCO_PROTOCOL_CLASSES.get proto_num Raw return cls s
def pwd_from_name name global _uid_to_pwd_cache _name_to_pwd_cache entry cached _cache_key_value pwd.getpwnam name _name_to_pwd_cache if entry and not cached _uid_to_pwd_cache[entry.pw_uid] entryreturn entry
def get_tile_set chunks tile_set defaultdict int for chunkx chunkz chunkmtime in chunks.iteritems col row tileset.convert_coords chunkx chunkz for tilec tiler in tileset.get_tiles_by_chunk col row tile tileset.RenderTile.compute_path tilec tiler 5 tile_set[tile.path] max tile_set[tile.path] chunkmtime for tile tile_mtime in tile_set.copy .iteritems for i in reversed xrange 5 tile_set[tile[ i]] max tile_set[tile[ i]] tile_mtime return dict tile_set
def PermissionMod field permissions class Modded field @classmethoddef many_init cls *args **kwargs kwargs['child'] field return PermissionMod serializers.ListSerializer permissions *args **kwargs def get_attribute self instance if self.check_permissions instance return super Modded self .get_attribute instance else raise fields.SkipField def check_permissions self obj request self.context.get 'request' for Perm in permissions perm Perm if not perm.has_permission request self return Falseif not perm.has_object_permission request self obj return Falsereturn Truereturn Modded
def flip image return image.transpose Image.FLIP_TOP_BOTTOM
def utctz_to_altz utctz return -1 * int float utctz / 100 * 3600
def _get_national_number_groups numobj formatting_pattern None if formatting_pattern is None rfc3966_format format_number numobj PhoneNumberFormat.RFC3966 end_index rfc3966_format.find U_SEMICOLON if end_index < 0 end_index len rfc3966_format start_index rfc3966_format.find U_DASH + 1 return rfc3966_format[start_index end_index].split U_DASH else nsn national_significant_number numobj return _format_nsn_using_pattern nsn formatting_pattern PhoneNumberFormat.RFC3966 .split U_DASH
def iter_shortcuts for option in CONF.options 'shortcuts' context name option.split '/' 1 yield context name get_shortcut context name
def selfupdate composer None php None runas None quiet False composer_home '/root' result _run_composer 'selfupdate' extra_flags '--no-progress' composer composer php php runas runas quiet quiet composer_home composer_home return result
def _convert_hs_points points t points apply_trans t['trans'] points points _flip_fiducials points .astype np.float32 return points
def _cart2polar_2pi x y r t np.hypot x y np.arctan2 y x t + np.where t < 0.0 2 * np.pi 0 return r t
def _process_and_sort s force_ascii full_process True ts utils.full_process s force_ascii force_ascii if full_process else s tokens ts.split sorted_string u''.join sorted tokens return sorted_string.strip
def build_tool_panel_section_select_field app options []for section_id section_name in app.toolbox.get_sections options.append section_name section_id select_field SelectField name 'tool_panel_section_id' field_id 'tool_panel_section_select' for option_tup in options select_field.add_option option_tup[0] option_tup[1] return select_field
def object_upload_fileobj self Fileobj ExtraArgs None Callback None Config None return self.meta.client.upload_fileobj Fileobj Fileobj Bucket self.bucket_name Key self.key ExtraArgs ExtraArgs Callback Callback Config Config
def get_ladder_capture state feature np.zeros 1 state.size state.size for x y in state.get_legal_moves feature[ 0 x y ] state.is_ladder_capture x y return feature
def select_function cache function fname function.name.replace u'-' u'_' try func cache.dispatch_map[fname]except KeyError raise ExpressionError u'Thepseudo-class %s isunknown' % function.name if fname u'lang' items frozenset func cache function for item in cache.iterparsedselector function.selector if item in items yield item else for item in cache.iterparsedselector function.selector if func cache function item yield item
def fisher probs try return chi2prob -2 * sum log probs 2 * len probs direction 'high' except OverflowError return 0.0
def check_user user if user.is_disabled raise DeactivatedAccountErrorelif not user.is_confirmed raise UnconfirmedAccountError
def groupfinder userid request backend getattr request.registry 'permission' None if not backend return []if request.prefixed_userid userid request.prefixed_useridreify_key userid + '_principals' if reify_key not in request.bound_data principals backend.get_user_principals userid request.bound_data[reify_key] principalsreturn request.bound_data[reify_key]
def IsURLErrorFatal error assert isinstance error urllib2.URLError if not hasattr error 'reason' return Trueif not isinstance error.reason[0] int return Truereturn error.reason[0] not in non_fatal_error_codes
def GetResultS Handle pIOType Channel if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pv ctypes.c_double ec staticLib.GetResultS Handle pIOType Channel ctypes.byref pv if ec ! 0 raise LabJackException ec return pv.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def format_stack_outputs outputs resolve_value False return [format_stack_output outputs[key] resolve_value resolve_value for key in outputs]
@post '/scan/<taskid>/start' def scan_start taskid if taskid not in DataStore.tasks logger.warning '[%s]InvalidtaskIDprovidedtoscan_start ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} for option value in request.json.items DataStore.tasks[taskid].set_option option value DataStore.tasks[taskid].engine_start logger.debug '[%s]Startedscan' % taskid return jsonize {'success' True 'engineid' DataStore.tasks[taskid].engine_get_id }
def zalpha colors zs colors get_colors colors len zs if len zs norm Normalize min zs max zs sats 1 - norm zs * 0.7 colors [ c[0] c[1] c[2] c[3] * s for c s in zip colors sats ]return colors
def initlog *allargs global logfp logif logfile and not logfp try logfp open logfile 'a' except IOError passif not logfp log nologelse log dologlog *allargs
def dmp_negative_p f u K return K.is_negative dmp_ground_LC f u K
def with_rw_repo working_tree_ref bare False assert isinstance working_tree_ref string_types 'Decoratorrequiresrefnameforworkingtreecheckout'def argument_passer func @wraps func def repo_creator self prefix 'non_'if bare prefix ''repo_dir tempfile.mktemp prefix '%sbare_%s' % prefix func.__name__ rw_repo self.rorepo.clone repo_dir shared True bare bare n True rw_repo.head.commit rw_repo.commit working_tree_ref if not bare rw_repo.head.reference.checkout prev_cwd os.getcwd os.chdir rw_repo.working_dir try return func self rw_repo except log.info 'Keepingrepoafterfailure %s' repo_dir repo_dir Noneraisefinally os.chdir prev_cwd rw_repo.git.clear_cache rw_repo Noneimport gcgc.collect if repo_dir is not None rmtree repo_dir return repo_creatorreturn argument_passer
def _openssl_pbkdf2 data salt iterations digest keylen c_hashfunc ctypes.c_void_p _openssl_hashlib_to_crypto_map_get digest c_pass ctypes.c_char_p data c_passlen ctypes.c_int len data c_salt ctypes.c_char_p salt c_saltlen ctypes.c_int len salt c_iter ctypes.c_int iterations c_keylen ctypes.c_int keylen c_buff ctypes.create_string_buffer keylen crypto.PKCS5_PBKDF2_HMAC.argtypes [ctypes.c_char_p ctypes.c_int ctypes.c_char_p ctypes.c_int ctypes.c_int ctypes.c_void_p ctypes.c_int ctypes.c_char_p]crypto.PKCS5_PBKDF2_HMAC.restype ctypes.c_interr crypto.PKCS5_PBKDF2_HMAC c_pass c_passlen c_salt c_saltlen c_iter c_hashfunc c_keylen c_buff return err c_buff
def topk k seq key None if key is not None and not callable key key getter key return tuple heapq.nlargest k seq key key
def _is_na_compat arr fill_value np.nan dtype arr.dtypeif isnull fill_value return not is_bool_dtype dtype or is_integer_dtype dtype return True
def single_client_test host cycles logger log_to_stderr logger.setLevel logging.DEBUG logger.debug 'startingworker %d' % os.getpid try count 0client ModbusTcpClient host while count < cycles result client.read_holding_registers 10 1 .getRegister 0 count + 1except logger.exception 'failedtoruntestsuccessfully' logger.debug 'finishedworker %d' % os.getpid
def compatibility_fix cf for item in _FIXES old new itemtry cf[new]except KeyError try cf[new] cf[old]del cf[old]except KeyError pass
def send_udp data host port sock socket.socket socket.AF_INET socket.SOCK_DGRAM sock.sendto data host port response server sock.recvfrom 8192 sock.close return response
def salt_syndic import salt.utils.processsalt.utils.process.notify_systemd import salt.cli.daemonspid os.getpid try syndic salt.cli.daemons.Syndic syndic.start except KeyboardInterrupt os.kill pid 15
def get_detection_type detect_num detect_num int detect_num if 0 < detect_num < len DETECTION_TYPES return DETECTION_TYPES[detect_num]else return DETECTION_TYPES[0]
def inline_functions dsk output fast_functions None inline_constants False dependencies None if not fast_functions return dskoutput set output fast_functions set fast_functions if dependencies is None dependencies {k get_dependencies dsk k for k in dsk}dependents reverse_dict dependencies keys [k for k v in dsk.items if istask v and functions_of v .issubset fast_functions and dependents[k] and k not in output ]if keys dsk inline dsk keys inline_constants inline_constants dependencies dependencies for k in keys del dsk[k]return dsk
def _get_cron_cmdstr path user None if user cmd 'crontab-u{0}'.format user else cmd 'crontab'return '{0}{1}'.format cmd path
def loads s encoding None cls None object_hook None parse_float None parse_int None parse_constant None object_pairs_hook None **kw if cls is None and encoding is None and object_hook is None and parse_int is None and parse_float is None and parse_constant is None and object_pairs_hook is None and not kw return _default_decoder.decode s if cls is None cls JSONDecoderif object_hook is not None kw['object_hook'] object_hookif object_pairs_hook is not None kw['object_pairs_hook'] object_pairs_hookif parse_float is not None kw['parse_float'] parse_floatif parse_int is not None kw['parse_int'] parse_intif parse_constant is not None kw['parse_constant'] parse_constantreturn cls encoding encoding **kw .decode s
def removeChildNodesFromElementObject elementNode elementNode.removeChildNodesFromIDNameParent if elementNode.xmlObject ! None if elementNode.parentNode.xmlObject ! None if elementNode.xmlObject in elementNode.parentNode.xmlObject.archivableObjects elementNode.parentNode.xmlObject.archivableObjects.remove elementNode.xmlObject
def binskim sample signature _check_challenge signature if len re.findall ' [a-f\\d]{32} ' sample 0 return 'WrongInput!'binskim_path config['binskim']['file_x64']command 'analyze'path config['MobSF']['samples'] + sample output_p '-o'output_d config['MobSF']['samples'] + sample + '_binskim' policy_p '--config'policy_d 'default'params [binskim_path command path output_p output_d policy_p policy_d]pipe subprocess.Popen subprocess.list2cmdline params pipe.wait out_file open output_d return out_file.read
def set_tags name tags region None key None keyid None profile None if exists name region key keyid profile conn _get_conn region region key key keyid keyid profile profile ret _add_tags conn name tags return retelse return False
def collect_log_file host log_path dest_path logging.info 'Collecting%s...' log_path try host.get_file log_path dest_path preserve_perm False except Exception logging.warning 'Collectionof%sfailed' log_path
def make_decorator func def decorate newfunc if hasattr func 'compat_func_name' name func.compat_func_nameelse name func.__name__newfunc.__dict__ func.__dict__newfunc.__doc__ func.__doc__newfunc.__module__ func.__module__if not hasattr newfunc 'compat_co_firstlineno' newfunc.compat_co_firstlineno func.func_code.co_firstlinenotry newfunc.__name__ nameexcept TypeError newfunc.compat_func_name namereturn newfuncreturn decorate
def _pos_match pos_tuple if pos_tuple[0] 's' pos_tuple 'a' pos_tuple[1] pos_tuple[2] for n x in enumerate pos_tuple if x is not None breakfor pt in _pos_tuples if pt[n] pos_tuple[n] return ptreturn None
def clean s lines [l.rstrip for l in s.split '\n' ]return '\n'.join lines
def libvlc_audio_output_list_get p_instance f _Cfunctions.get 'libvlc_audio_output_list_get' None or _Cfunction 'libvlc_audio_output_list_get' 1 None ctypes.POINTER AudioOutput Instance return f p_instance
def _get_info_from_infocache env account container None cache_key get_cache_key account container if 'swift.infocache' in env and cache_key in env['swift.infocache'] return env['swift.infocache'][cache_key]return None
def test_input_discard mlp MLP layers [FlattenerLayer CompositeLayer 'composite' [Linear 10 'h0' 0.1 ] {0 [0] 1 []} Softmax 5 'softmax' 0.1 ] input_space CompositeSpace [VectorSpace 15 VectorSpace 20 ] input_source 'features0' 'features1' dataset VectorSpacesDataset np.random.rand 20 20 .astype theano.config.floatX np.random.rand 20 15 .astype theano.config.floatX np.random.rand 20 5 .astype theano.config.floatX CompositeSpace [VectorSpace 20 VectorSpace 15 VectorSpace 5 ] 'features1' 'features0' 'targets' train Train dataset mlp SGD 0.1 batch_size 5 train.algorithm.termination_criterion EpochCounter 1 train.main_loop
def domains_for_certname config certname def update_domains_for_name_match candidate_lineage rv 'Returndomainsifcertnamematches elsereturnrv\n'matching_domains rvif candidate_lineage.lineagename certname matching_domains candidate_lineage.names return matching_domainsreturn _search_lineages config update_domains_for_name_match None
def responsive res space_compress None if space_compress is None space_compress not g.template_debug if is_api res res or u'' if not c.allowed_callback and request.environ.get 'WANT_RAW_JSON' res scriptsafe_dumps res else res websafe_json simplejson.dumps res if c.allowed_callback res '/**/%s %s ' % websafe_json c.allowed_callback res elif space_compress res spaceCompress res return res
def subtract_mean image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._subtract_mean image selem out out mask mask shift_x shift_x shift_y shift_y
def _words_group input strlen words []nblanks input.count '' nmax max nblanks len input // strlen + 1 arr np.fromstring input + '' dtype binary_type 1 blank_loc np.nonzero arr '' [0]offset 0xoffset 0for idx in range nmax try loc np.nonzero blank_loc > strlen + offset [0][0]offset blank_loc[ loc - 1 ] + 1 if loc 0 offset -1 except Exception offset len input if offset < xoffset offset xoffset + strlen words.append input[xoffset offset] if len input offset breakxoffset offsetreturn words
def get_phrases_from_module module return module.WORDS if hasattr module 'WORDS' else []
def pid sig cmd __grains__['ps']output __salt__['cmd.run_stdout'] cmd pids ''for line in output.splitlines if 'status.pid' in line continueif re.search sig line if pids pids + '\n'pids + line.split [1]return pids
def irc_prefix var if isinstance var basestring return u'irc_%s' % var.lower
def create_cn hostname password username dbname if password cn connect host hostname user username database dbname password password else cn connect user username database dbname print u'Createdconnection {0}.'.format cn.dsn return cn
def matplotlib_rgb_color rgb_color return tuple [ i / 255.0 for i in rgb_color]
def task_cli_pip_install venv_name 'flocker-client' package_source PackageSource url 'https //{bucket}.s3.amazonaws.com/{key}/Flocker-{version}-py2-none-any.whl'.format bucket ARCHIVE_BUCKET key 'python' version _get_wheel_version package_source return sequence [run_from_args ['virtualenv' '--python /usr/bin/python2.7' venv_name] run_from_args ['source' '{}/bin/activate'.format venv_name ] run_from_args ['pip' 'install' '--upgrade' 'pip'] run_from_args ['pip' 'install' url] ]
def get_valid_name layer_name name _clean_string layer_name proposed_name namecount 1while Layer.objects.filter name proposed_name .exists proposed_name '%s_%d' % name count count count + 1 logger.info 'Requestednamealreadyused;adjustingname[%s] >[%s]' layer_name proposed_name else logger.info 'Usingnameasrequested' return proposed_name
@click.command 'supervisor' @click.option '--user' @click.option '--yes' help 'Yestoregenerationofsupervisorconfig' is_flag True default False def setup_supervisor user None yes False from bench.config.supervisor import generate_supervisor_configgenerate_supervisor_config bench_path '.' user user yes yes
def is_neg var apply var.ownerif not apply return Noneif apply.op tensor.neg return apply.inputs[0]if apply.op tensor.mul and len apply.inputs > 2 for idx mul_input in enumerate apply.inputs try constant opt.get_scalar_constant_value mul_input is_minus_1 numpy.allclose constant -1 except NotScalarConstantError is_minus_1 Falseif is_minus_1 if len apply.inputs 2 return apply.inputs[ 1 - idx ]else return tensor.mul * apply.inputs[0 idx] + apply.inputs[ idx + 1 ] return None
def _get_dash_pattern style if is_string_like style and is_hashable style style ls_mapper.get style style if style in [u'solid' u'None'] offset dashes None None elif style in [u'dashed' u'dashdot' u'dotted'] offset 0dashes tuple rcParams[u'lines.{}_pattern'.format style ] elif isinstance style tuple offset dashes styleelse raise ValueError u'Unrecognizedlinestyle %s' % str style if dashes is not None and offset is not None dsum sum dashes if dsum offset % dsumreturn offset dashes
@given 'abehavemodelwith' def step_given_a_behave_model_with_table context assert context.table 'REQUIRE context.table'context.table.require_columns BehaveModelBuilder.REQUIRED_COLUMNS model_builder BehaveModelBuilder context.behave_model model_builder.build_model_from_table context.table
def b str_or_bytes if not isinstance str_or_bytes bytes return str_or_bytes.encode 'ascii' else return str_or_bytes
def serve request path document_root None insecure False **kwargs if not settings.DEBUG and not insecure raise ImproperlyConfigured "Thestaticfilesviewcanonlybeusedindebugmodeorifthethe--insecureoptionof'runserver'isused" normalized_path posixpath.normpath urllib.unquote path .lstrip '/' absolute_path finders.find normalized_path if not absolute_path raise Http404 "'%s'couldnotbefound" % path document_root path os.path.split absolute_path return static.serve request path document_root document_root **kwargs
def encode_ros_handshake_header header fields [ '%s %s' % k v for k v in header.items ]if python3 0 s ''.join [ '%s%s' % struct.pack '<I' len f f for f in fields] return struct.pack '<I' len s + s else s ''.join [ struct.pack '<I' len f + f.encode 'utf-8' for f in fields] return struct.pack '<I' len s + s
def fib num num int num if num < 0 raise ValueError 'Negativenumberisnotallowed!' start time.time if num < 2 return num time.time - start return _fib num - 1 + _fib num - 2 time.time - start
def bode system w None n 100 w y freqresp system w w n n mag 20.0 * numpy.log10 abs y phase numpy.unwrap numpy.arctan2 y.imag y.real * 180.0 / numpy.pi return w mag phase
def date_and_notes s s s.strip if not s return u'' u'' notes u''if s[0].isdigit or s.split [0].lower in 'c.' 'january' 'february' 'march' 'april' 'may' 'june' 'july' 'august' 'september' 'october' 'november' 'december' 'ca.' 'circa' '???? ' i s.find ' ' if i ! -1 notes s[ i + 1 ].strip s s[ i]else notes ss u''if s '????' s u''return s notes
def parse_raw_obj obj_info raw_obj_name obj_info['name'].encode 'utf-8' policy_index obj_name raw_obj_name.split ' ' 1 q_policy_index int policy_index account container obj split_path obj_name 3 3 rest_with_last True try q_op {'application/x-put' 'PUT' 'application/x-delete' 'DELETE'}[obj_info['content_type']]except KeyError raise ValueError 'invalidoperationtype%r' % obj_info.get 'content_type' None return {'q_policy_index' q_policy_index 'account' account 'container' container 'obj' obj 'q_op' q_op 'q_ts' decode_timestamps obj_info['hash'] [0] 'q_record' last_modified_date_to_timestamp obj_info['last_modified'] 'path' '/%s/%s/%s' % account container obj }
def is_ipv6_pd_enabled subnet return subnet.get 'subnetpool_id' const.IPV6_PD_POOL_ID
def validate_request_data_and_get_certificate certificate_invalidation course_key user certificate_invalidation.get 'user' if not user raise ValueError _ 'Studentusername/emailfieldisrequiredandcannotbeempty.Kindlyfillinusername/emailandthenpress"InvalidateCertificate"button.' student get_student user course_key certificate GeneratedCertificate.certificate_for_student student course_key if not certificate raise ValueError _ 'Thestudent{student}doesnothavecertificateforthecourse{course}.Kindlyverifystudentusername/emailandtheselectedcoursearecorrectandtryagain.' .format student student.username course course_key.course return certificate
def spawn_main pipe_handle parent_pid None tracker_fd None assert is_forking sys.argv if sys.platform 'win32' import msvcrtfrom .reduction import steal_handlenew_handle steal_handle parent_pid pipe_handle fd msvcrt.open_osfhandle new_handle os.O_RDONLY else from . import semaphore_trackersemaphore_tracker._semaphore_tracker._fd tracker_fdfd pipe_handleexitcode _main fd sys.exit exitcode
def transpose matlist K return [list a for a in zip *matlist ]
def index_along_axis index ndim axis indices [slice None ] * ndim indices[axis] indexreturn tuple indices
def association_rules dataset freqsets support minlift nr_transactions float len dataset freqsets [f for f in freqsets if len f > 1 ]for fset in freqsets for f in fset consequent frozenset [f] antecendent fset - consequent py_x support[fset] / support[antecendent] base support[consequent] / nr_transactions lift py_x / base if lift > minlift yield AssociationRule antecendent consequent base py_x lift
def group_type_destroy context id return IMPL.group_type_destroy context id
def multiplicative_epsilon front **kargs wobj numpy.array [ind.fitness.wvalues for ind in front] * -1 def contribution i mwobj numpy.ma.array wobj mwobj[i] numpy.ma.maskedreturn numpy.min numpy.max wobj[i] / mwobj axis 1 contrib_values map contribution range len front return numpy.argmin contrib_values
def measure_all_oneshot qubit format 'sympy' import randomm qubit_to_matrix qubit if format 'sympy' m m.normalized random_number random.random total 0result 0for i in m total + i * i.conjugate if total > random_number breakresult + 1return Qubit IntQubit result int math.log max m.shape 2 + 0.1 else raise NotImplementedError "Thisfunctioncan'thandlenon-sympymatrixformatsyet"
def test_tokenizer raw '<em>test<x></x></em>'eq_ '<em>test&lt;x&gt;&lt;/x&gt;</em>' linkify raw eq_ raw linkify raw tokenizer HTMLTokenizer
def laplacian_spectrum G weight 'weight' from scipy.linalg import eigvalshreturn eigvalsh nx.laplacian_matrix G weight weight .todense
def escapeForIRI xri xri xri.replace '%' '%25' xri _xref_re.sub _escape_xref xri return xri
def authorize_quota_class_context context class_name if is_user_context context if not context.quota_class raise exception.Forbidden elif context.quota_class ! class_name raise exception.Forbidden
def reduce_order_meijer func nan nbq ops1 _reduce_order func.an func.bq ReduceOrder.meijer_plus lambda x default_sort_key - x nbm nap ops2 _reduce_order func.bm func.ap ReduceOrder.meijer_minus default_sort_key return G_Function nan nap nbm nbq ops1 + ops2
def heading headingtext headinglevel lang 'en' lmap {'en' 'Heading' 'it' 'Titolo'}paragraph makeelement 'p' pr makeelement 'pPr' pStyle makeelement 'pStyle' attributes {'val' lmap[lang] + str headinglevel } run makeelement 'r' text makeelement 't' tagtext headingtext pr.append pStyle run.append text paragraph.append pr paragraph.append run return paragraph
def add_rich_rule zone rule permanent True cmd "--zone {0}--add-rich-rule '{1}'".format zone rule if permanent cmd + '--permanent'return __firewall_cmd cmd
def put_str content path share 'C$' conn None host None username None password None if conn is None conn get_conn host username password if conn is False return Falsefh_ StrHandle content conn.putFile share path fh_.string
def get_numeric val try return float val except passreturn val
def test_read_no_header_autocolumn_NoHeader table '\n|John|555-1234|192.168.1.10|\n|Mary|555-2134|192.168.1.12|\n|Bob|555-4527|192.168.1.9|\n'dat ascii.read table Reader ascii.FixedWidthNoHeader assert_equal tuple dat.dtype.names 'col1' 'col2' 'col3' assert_equal dat[1][0] 'Mary' assert_equal dat[0][1] '555-1234' assert_equal dat[2][2] '192.168.1.9'
@with_setup prepare_stdout def test_output_level_2_error runner Runner feature_name 'error_traceback' verbosity 2 runner.run assert_stdout_lines_with_traceback 'Itshouldpass...OK\nItshouldraiseanexceptiondifferentofAssertionError...ERROR\n\n\n<Step "Givenmystepthatblowsaexception">\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line% call_line d in__call__\nret self.function self.step *args **kw \nFile"% step_file s" line10 ingiven_my_step_that_blows_a_exception\nraiseRuntimeError\nRuntimeError\n\n1feature 0passed \n2scenarios 1passed \n2steps 1failed 1passed \n\nListoffailedscenarios \nScenario ItshouldraiseanexceptiondifferentofAssertionError#tests/functional/output_features/error_traceback/error_traceback.feature 5\n\n' % {'lettuce_core_file' lettuce_path 'core.py' 'step_file' abspath lettuce_path '..' 'tests' 'functional' 'output_features' 'error_traceback' 'error_traceback_steps.py' 'call_line' call_line}
def export_set dataset **kwargs stream StringIO kwargs.setdefault 'delimiter' DEFAULT_DELIMITER if not is_py3 kwargs.setdefault 'encoding' DEFAULT_ENCODING _csv csv.writer stream **kwargs for row in dataset._package dicts False _csv.writerow row return stream.getvalue
def require_snapshot_exists f @functools.wraps f def wrapper context snapshot_id *args **kwargs if not resource_exists context models.Snapshot snapshot_id raise exception.SnapshotNotFound snapshot_id snapshot_id return f context snapshot_id *args **kwargs return wrapper
def AddModuleToCache typelibclsid lcid major minor verbose 1 bFlushNow not is_readonly fname GetGeneratedFileName typelibclsid lcid major minor mod _GetModule fname mod._in_gencache_ 1dict mod.CLSIDToClassMapinfo str typelibclsid lcid major minor for clsid cls in dict.iteritems clsidToTypelib[clsid] infodict mod.CLSIDToPackageMapfor clsid name in dict.iteritems clsidToTypelib[clsid] infodict mod.VTablesToClassMapfor clsid cls in dict.iteritems clsidToTypelib[clsid] infodict mod.VTablesToPackageMapfor clsid cls in dict.iteritems clsidToTypelib[clsid] infoif info in versionRedirectMap del versionRedirectMap[info]if bFlushNow _SaveDicts
def running_config version os.uname [2]for config in '/proc/config.gz' '/boot/config-%s' % version '/lib/modules/%s/build/.config' % version if os.path.isfile config return configreturn None
def gray rc u'image' cmap u'gray' im gci if im is not None im.set_cmap cm.gray
def force_escape value from google.appengine._internal.django.utils.html import escapereturn mark_safe escape value
def form_for_fields field_list fields SortedDict [ f.name f.formfield for f in field_list if f.editable] return type 'FormForFields' BaseForm {'base_fields' fields}
def PropertyValueFromString type_ value_string _auth_domain None if type_ datetime.datetime value_string value_string.strip if value_string[ -6 ] in '+' '-' if value_string[ -5 ] '00 00' value_string value_string[ -6 ]else raise ValueError 'Non-UTCoffsetsindatetimesarenotsupported.' split value_string.split '.' iso_date split[0]microseconds 0if len split > 1 microseconds int split[1] time_struct time.strptime iso_date '%Y-%m-%d%H %M %S' [0 6]value datetime.datetime * time_struct + microseconds return valueelif type_ Rating return Rating int value_string elif type_ bool return value_string 'True' elif type_ users.User return users.User value_string _auth_domain elif type_ type None return Nonereturn type_ value_string
def test_stratified_dataset_shuffle_split skip_if_no_sklearn mapping {'dataset_iterator' 'StratifiedDatasetShuffleSplit'}test_yaml test_yaml_dataset_iterator % mapping trainer yaml_parse.load test_yaml trainer.main_loop
def diff before after assert after.eid before.eid plays []after_plays list after.drives.plays before_plays list before.drives.plays for play in after_plays if play not in before_plays plays.append play _players OrderedDict after_players list after.max_player_stats before_players list before.max_player_stats for aplayer in after_players has_before Falsefor bplayer in before_players if aplayer.playerid bplayer.playerid has_before Truepdiff aplayer - bplayer if pdiff is not None _players[aplayer.playerid] pdiffif not has_before _players[aplayer.playerid] aplayerplayers nflgame.seq.GenPlayerStats _players return GameDiff before before after after plays plays players players
def wrap_filters filters def combined_filter x for filt in filters if not filt x return Falsereturn Truereturn combined_filter
def init mpstate return CmdlongModule mpstate
def test_cache cp compilerop.CachingCompiler ncache len linecache.cache cp.cache 'x 1' nt.assert_true len linecache.cache > ncache
def _getTestList suiteNames ['OneNodeTests' 'MultiNodeTests' 'ModelMaturityTests' 'SwarmTerminatorTests']testNames []for suite in suiteNames for f in dir eval suite if f.startswith 'test' testNames.append '%s.%s' % suite f return testNames
def mock_responses resps def wrapper func @responses.activate@functools.wraps func def wrapped *args **kwargs for resp in resps responses.add *resp.args **resp.kwargs return func *args **kwargs return wrappedreturn wrapper
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def remove cwd targets msg None user None username None password None *opts if msg opts + '-m' msg if targets opts + tuple salt.utils.shlex_split targets return _run_svn 'remove' cwd user username password opts
def vocabulary_show context data_dict _check_access 'vocabulary_show' context data_dict model context['model']vocab_id data_dict.get 'id' if not vocab_id raise ValidationError {'id' _ 'idnotindata' } vocabulary model.vocabulary.Vocabulary.get vocab_id if vocabulary is None raise NotFound _ 'Couldnotfindvocabulary"%s"' % vocab_id vocabulary_dict model_dictize.vocabulary_dictize vocabulary context return vocabulary_dict
def _getTPClass temporalImp if temporalImp 'py' return TP.TPelif temporalImp 'cpp' return TP10X2.TP10X2elif temporalImp 'tm_py' return TP_shim.TPShimelif temporalImp 'tm_cpp' return TP_shim.TPCPPShimelif temporalImp 'tm_py_fast' return TP_shim.FastTPShimelif temporalImp 'monitored_tm_py' return TP_shim.MonitoredTPShimelse raise RuntimeError "InvalidtemporalImp'%s'.Legalvaluesare 'py' 'cpp' 'tm_py' 'monitored_tm_py'" % temporalImp
def _make_writeable filename import statif sys.platform.startswith 'java' returnif not os.access filename os.W_OK st os.stat filename new_permissions stat.S_IMODE st.st_mode | stat.S_IWUSR os.chmod filename new_permissions
def _task_is_running course_id task_type task_key running_tasks InstructorTask.objects.filter course_id course_id task_type task_type task_key task_key for state in READY_STATES running_tasks running_tasks.exclude task_state state return len running_tasks > 0
def get_group_dataset_counts query search.PackageSearchQuery q {'q' '+capacity public' 'fl' 'groups' 'facet.field' ['groups' 'owner_org'] 'facet.limit' -1 'rows' 1}query.run q return query.facets
def _makeRPMs tapfile None maintainer None protocol None description None longDescription None setVersion None rpmfile None type_ None args []if not tapfile tapfile 'dummy-tap-file'handle open tapfile 'w' handle.write '#DummyTAPfile\n' handle.close args.extend ['--quiet' '--tapfile' tapfile] if maintainer args.extend ['--maintainer' maintainer] if protocol args.extend ['--protocol' protocol] if description args.extend ['--description' description] if longDescription args.extend ['--long_description' longDescription] if setVersion args.extend ['--set-version' setVersion] if rpmfile args.extend ['--rpmfile' rpmfile] if type_ args.extend ['--type' type_] return tap2rpm.run args
def process_email streams MessageStream.objects.filter trash False incoming_server_username__isnull False for stream in streams stream.process_email
@open_file 0 mode 'rb' def read_multiline_adjlist path comments '#' delimiter None create_using None nodetype None edgetype None encoding 'utf-8' lines line.decode encoding for line in path return parse_multiline_adjlist lines comments comments delimiter delimiter create_using create_using nodetype nodetype edgetype edgetype
def create_queue name region opts None user None create {'queue-name' name}out _run_aws 'create-queue' region region opts opts user user **create ret {'retcode' 0 'stdout' out['QueueUrl'] 'stderr' ''}return ret
def consume_queue queue get queue.get_nowaitwhile 1 try yield get except Empty break
def modClearCharacterRefs s titlesRefs namesRefs charactersRefs return re_characterRef.sub '\\1' s
def _fetch_profile_opts cfg virtualname __salt__ _options profile_attr profile_attrs if not profile_attr or profile_attr not in _options return {}creds {}profile _options[profile_attr]if profile log.info 'Usingprofile%s' profile if 'config.option' in __salt__ creds cfg profile else creds cfg.get profile if not creds return {}return dict pattr creds.get '{0}.{1}'.format virtualname profile_attrs[pattr] for pattr in profile_attrs
def add_created_exploration_id user_id exploration_id user_contributions get_user_contributions user_id strict False if not user_contributions create_user_contributions user_id [exploration_id] [] elif exploration_id not in user_contributions.created_exploration_ids user_contributions.created_exploration_ids.append exploration_id user_contributions.created_exploration_ids.sort _save_user_contributions user_contributions
def TEMA ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.TEMA timeperiod
def get_cache_key request key_prefix None method 'GET' cache None if key_prefix is None key_prefix settings.CACHE_MIDDLEWARE_KEY_PREFIXcache_key _generate_cache_header_key key_prefix request if cache is None cache caches[settings.CACHE_MIDDLEWARE_ALIAS]headerlist cache.get cache_key if headerlist is not None return _generate_cache_key request method headerlist key_prefix else return None
@raises ValueError def test_conditional_rejects_invalid_output_layer mlp MLP layers [Linear layer_name 'h' dim 5 irange 0.01 Linear layer_name 'mu' dim 5 irange 0.01 ] conditional DummyConditional mlp mlp name 'conditional' output_layer_required False vae DummyVAE conditional.set_vae vae conditional.initialize_parameters input_space VectorSpace dim 5 ndim 5
def update_credit_request_status request_uuid provider_id status if status not in [CreditRequest.REQUEST_STATUS_APPROVED CreditRequest.REQUEST_STATUS_REJECTED] raise InvalidCreditStatustry request CreditRequest.objects.get uuid request_uuid provider__provider_id provider_id old_status request.statusrequest.status statusrequest.save log.info u'UpdatedrequestwithUUID"%s"fromstatus"%s"to"%s"forproviderwithID"%s".' request_uuid old_status status provider_id except CreditRequest.DoesNotExist msg u'CreditproviderwithID"{provider_id}"attemptedtoupdaterequestwithUUID"{request_uuid}" butnorequestwiththisUUIDisassociatedwiththeprovider.'.format provider_id provider_id request_uuid request_uuid log.warning msg raise CreditRequestNotFound msg
def extra_padding_y original_size padding return _resize original_size 1 padding padding
@register u'backward-word' def backward_word event buff event.current_bufferpos buff.document.find_previous_word_beginning count event.arg if pos buff.cursor_position + pos
def shutting_down globals globals v globals .get '_shutting_down' return v is True or v is None
def default_slugifier value if settings.OSCAR_SLUG_ALLOW_UNICODE return django_slugify value allow_unicode True return django_slugify value
def run_parallel commands timeout None ignore_status False stdout_tee None stderr_tee None bg_jobs []for command in commands bg_jobs.append BgJob command stdout_tee stderr_tee stderr_level get_stderr_level ignore_status join_bg_jobs bg_jobs timeout for bg_job in bg_jobs if not ignore_status and bg_job.result.exit_status raise error.CmdError command bg_job.result 'Commandreturnednon-zeroexitstatus' return [bg_job.result for bg_job in bg_jobs]
def wanmen_download_by_course json_api_content output_dir '.' merge True info_only False **kwargs for tIndex in range len json_api_content[0]['Topics'] for pIndex in range len json_api_content[0]['Topics'][tIndex]['Parts'] wanmen_download_by_course_topic_part json_api_content tIndex pIndex output_dir output_dir merge merge info_only info_only **kwargs
def _WriteErrorToOutput status message outfile logging.error message outfile.write 'Status %s\r\n\r\n%s' % status message
def pkcs1Digest data messageLength digest sha1 data .digest return pkcs1Pad ID_SHA1 + digest messageLength
def _prepare_rgba_array arr arr np.asanyarray arr if arr.ndim not in [3 4] or arr.shape[ -1 ] ! 4 msg 'theinputarraymusthaveashape .. .. [.. ]4 got{0}'.format arr.shape raise ValueError msg return dtype.img_as_float arr
@receiver pre_save sender User def user_pre_save_callback sender **kwargs user kwargs['instance']user._changed_fields get_changed_fields_dict user sender
def _service_is_chkconfig name cmdline '/sbin/chkconfig--list{0}'.format name return __salt__['cmd.retcode'] cmdline python_shell False ignore_retcode True 0
def right_align_return_tracks_track_assigner song tracks_provider offset tracks_provider.track_offsettracks tracks_provider.tracks_to_use return_tracks list song.return_tracks size tracks_provider.num_tracksnum_empty_tracks max 0 size + offset - len tracks track_list size * [None] for i in xrange size track_index i + offset if len tracks > track_index track tracks[track_index]empty_offset 0 if tracks[track_index] not in return_tracks else num_empty_tracks track_list[ i + empty_offset ] trackreturn track_list
def import_attached_events db_session account message assert account is not None for part in message.attached_event_files part_data ''try part_data part.block.dataif part_data '' continuenew_events events_from_ics account.namespace account.emailed_events_calendar part_data except MalformedEventError log.error 'Attachedeventparsingerror' account_id account.id message_id message.id logstash_tag 'icalendar_autoimport' event_part_id part.id continueexcept AssertionError TypeError RuntimeError AttributeError ValueError UnboundLocalError LookupError ImportError NameError log.error 'Unhandledexceptionduringmessageparsing' message_id message.id event_part_id part.id logstash_tag 'icalendar_autoimport' traceback traceback.format_exception sys.exc_info [0] sys.exc_info [1] sys.exc_info [2] continueprocess_invites db_session message account new_events['invites'] if account.provider ! 'gmail' process_nylas_rsvps db_session message account new_events['rsvps']
def unpack_zeroterm_array ptr assert ptrindex 0current ptr[index]while current yield current free ffi.cast 'gpointer' current index + 1current ptr[index]free ffi.cast 'gpointer' ptr
def decode_as_string text encoding None if encoding is None encoding _console_encodingif not isinstance text unicode text text.decode encoding text unicodedata.normalize 'NFC' text return text
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def get_plays files git_dir playbooks_dirs plays set for play_dir in playbooks_dirs play_dir_path pathlib2.Path git_dir play_dir candidate_files {f for f in play_dir_path.glob '*.yml' }for f in files file_path pathlib2.Path git_dir f if file_path in candidate_files plays.add _get_playbok_name_from_file file_path return plays
def tenant_create name description None enabled True profile None **connection_args kstone auth profile **connection_args new getattr kstone _TENANTS None .create name description enabled return tenant_get new.id profile profile **connection_args
def IsEncodingsModule module_name if module_name in 'codecs' 'encodings' or module_name.startswith 'encodings.' return Truereturn False
def mds_destroy **kwargs return ceph_cfg.mds_destroy **kwargs
def make_default_headers n return tuple agate.utils.letter_name i for i in range n
def path_filter_patterns paths patterns root None from headphones import loggerignored 0for path in paths[ ] if path_match_patterns path patterns logger.debug 'Pathignoredbypattern %s' os.path.join root or '' path ignored + 1paths.remove path return ignored
def get_move_page_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'move_page' check_global check_global use_cache use_cache return page_ids
def send_message module client_id client_secret topic msg try access_token get_access_token module client_id client_secret url 'https //typetalk.in/api/v1/topics/%d' % topic headers {'Authorization' 'Bearer%s' % access_token }do_request module url {'message' msg} headers return True {'access_token' access_token} except ConnectionError e get_exception return False e
def bgrewriteaof host None port None db None password None server _connect host port db password return server.bgrewriteaof
def check_domain domain return domain not in DEFAULT_DOMAINS and not domain.startswith u'http ' and not domain.startswith u'https ' and not domain.endswith u'/'
def serialize_tar_info tar_info is_deleted Falsefilename tar_info.nameif filename '.' filename '/'if filename.startswith './' filename '/' + filename[2 ] if filename.startswith '/.wh.' filename '/' + filename[5 ] is_deleted Trueif filename.startswith '/.wh.' return Nonereturn filename FILE_TYPES.get tar_info.type 'u' is_deleted tar_info.size tar_info.mtime tar_info.mode tar_info.uid tar_info.gid
def dedent_initial s n 4 return s[n ] if s[ n] u'' * n else s
def conditional_escape text if isinstance text SafeData return textelse return escape text
def is_void at if isinstance at datetime return Falsereturn all getattr at attr is None for attr in adatetime.units
def check_email_valid email_address field reason invalid_email_reason email_address field if reason is not None raise InvalidEmailError reason
def user_follower_list context data_dict _check_access 'user_follower_list' context data_dict return _follower_list context data_dict ckan.logic.schema.default_follow_user_schema context['model'].UserFollowingUser
def sample_ppc trace samples None model None vars None size None random_seed None progressbar True if samples is None samples len trace if model is None model modelcontext model if vars is None vars model.observed_RVsseed random_seed if progressbar indices tqdm randint 0 len trace samples total samples else indices randint 0 len trace samples ppc defaultdict list for idx in indices param trace[idx]for var in vars ppc[var.name].append var.distribution.random point param size size return {k np.asarray v for k v in ppc.items }
def rms_flat a return np.sqrt np.mean np.abs a ** 2
def get_active_website_users return frappe.db.sql u"selectcount * from`tabUser`\n DCTB DCTB whereenabled 1anduser_type 'WebsiteUser'\n DCTB DCTB andhour timediff now last_active <72" [0][0]
def cov_hac_simple results nlags None weights_func weights_bartlett use_correction True xu hessian_inv _get_sandwich_arrays results sigma S_hac_simple xu nlags nlags weights_func weights_func cov_hac _HCCM2 hessian_inv sigma if use_correction nobs k_params xu.shapecov_hac * nobs / float nobs - k_params return cov_hac
def kit_item return s3_rest_controller
def getName obj def sanitize name return name.replace '.' '/' if isinstance obj _BuildStepFactory klass obj.factoryelse klass type obj name ''klasses klass + inspect.getmro klass for klass in klasses if hasattr klass '__module__' and klass.__module__.startswith 'buildbot.' return sanitize name + klass.__module__ + '.' + klass.__name__ else name + '>'return sanitize type obj .__name__
@collect_authdef auth_login auth campaign request.args.get 'campaign' next_url request.args.get 'next' data login_and_register_handler auth login True campaign campaign next_url next_url if data['status_code'] http.FOUND return redirect data['next_url']
def get_next_page_of_all_non_private_commits page_size feconf.COMMIT_LIST_PAGE_SIZE urlsafe_start_cursor None max_age None if max_age is not None and not isinstance max_age datetime.timedelta raise ValueError 'max_agemustbeadatetime.timedeltainstance.orNone.' results new_urlsafe_start_cursor more exp_models.ExplorationCommitLogEntryModel.get_all_non_private_commits page_size urlsafe_start_cursor max_age max_age return [exp_domain.ExplorationCommitLogEntry entry.created_on entry.last_updated entry.user_id entry.username entry.exploration_id entry.commit_type entry.commit_message entry.commit_cmds entry.version entry.post_commit_status entry.post_commit_community_owned entry.post_commit_is_private for entry in results] new_urlsafe_start_cursor more
def item_field_getters funcs {}for plugin in find_plugins if plugin.template_fields funcs.update plugin.template_fields return funcs
def scrub_headers headers if isinstance headers dict headers headers.items headers [ parse_header_string key parse_header_string val for key val in headers]if not logger_settings.get 'redact_sensitive_headers' True return dict headers if logger_settings.get 'reveal_sensitive_prefix' 16 < 0 logger_settings['reveal_sensitive_prefix'] 16return {key safe_value key val for key val in headers}
def partition_node node host nodeport 27017idx node.rfind ' ' if idx ! -1 host port node[ idx] int node[ idx + 1 ] if host.startswith '[' host host[1 -1 ]return host port
def convert_search search if not search search ''else search search.replace '*' '%' .replace '' '%' if search and search.startswith '^' search search.replace '^' '' search + '%'elif search and search.endswith '$' search search.replace '$' '' search '%' + search else search '%' + search + '%' return search
def get_interface_type interface if interface.upper .startswith 'ET' return 'ethernet'elif interface.upper .startswith 'VL' return 'svi'elif interface.upper .startswith 'LO' return 'loopback'elif interface.upper .startswith 'MG' return 'management'elif interface.upper .startswith 'MA' return 'management'elif interface.upper .startswith 'PO' return 'portchannel'else return 'unknown'
def _find_head_bem subject subjects_dir high_res False fnames _high_res_head_fnames if high_res else _head_fnames for fname in fnames path fname.format subjects_dir subjects_dir subject subject if os.path.exists path return path
def _generate_totp_passcode secret if isinstance secret six.text_type secret secret.encode 'utf-8' while len secret % 8 ! 0 secret secret + ' ' decoded base64.b32decode secret totp crypto_totp.TOTP decoded 6 hashes.SHA1 30 backend default_backend return totp.generate timeutils.utcnow_ts microsecond True .decode 'utf-8'
def get_python_lib plat_specific 0 standard_lib 0 prefix None if prefix is None if standard_lib prefix plat_specific and BASE_EXEC_PREFIX or BASE_PREFIX else prefix plat_specific and EXEC_PREFIX or PREFIX if os.name 'posix' libpython os.path.join prefix 'lib' 'python' + get_python_version if standard_lib return libpythonelse return os.path.join libpython 'site-packages' elif os.name 'nt' if standard_lib return os.path.join prefix 'Lib' else return os.path.join prefix 'Lib' 'site-packages' else raise DistutilsPlatformError "Idon'tknowwherePythoninstallsitslibraryonplatform'%s'" % os.name
def link src dst if platform.system u'Windows' if ctypes.windll.kernel32.CreateHardLinkW ctypes.c_wchar_p unicode dst ctypes.c_wchar_p unicode src None 0 raise ctypes.WinError else ek os.link src dst
def datetime_from_timestamp timestamp content return set_date_tzinfo datetime.fromtimestamp timestamp tz_name content.settings.get 'TIMEZONE' None
def upload_problem_responses_csv _xmodule_instance_args _entry_id course_id task_input action_name start_time time start_date datetime.now UTC num_reports 1task_progress TaskProgress action_name num_reports start_time current_step {'step' 'Calculatingstudentsanswerstoproblem'}task_progress.update_task_state extra_meta current_step problem_location task_input.get 'problem_location' student_data list_problem_responses course_id problem_location features ['username' 'state'] header rows format_dictlist student_data features task_progress.attempted task_progress.succeeded len rows task_progress.skipped task_progress.total - task_progress.attempted rows.insert 0 header current_step {'step' 'UploadingCSV'}task_progress.update_task_state extra_meta current_step problem_location re.sub '[ /]' '_' problem_location csv_name 'student_state_from_{}'.format problem_location upload_csv_to_report_store rows csv_name course_id start_date return task_progress.update_task_state extra_meta current_step
def resnet_v1_101 inputs num_classes None is_training True global_pool True output_stride None reuse None scope 'resnet_v1_101' blocks [resnet_utils.Block 'block1' bottleneck [ 256 64 1 ] * 2 + [ 256 64 2 ] resnet_utils.Block 'block2' bottleneck [ 512 128 1 ] * 3 + [ 512 128 2 ] resnet_utils.Block 'block3' bottleneck [ 1024 256 1 ] * 22 + [ 1024 256 2 ] resnet_utils.Block 'block4' bottleneck [ 2048 512 1 ] * 3 ]return resnet_v1 inputs blocks num_classes is_training global_pool global_pool output_stride output_stride include_root_block True reuse reuse scope scope
def splitStringWithNumbers string rawParts re.split ' \\d+ ' string nonEmptyParts filter None rawParts def splitHelper nonEmptyParts for part in nonEmptyParts if re.match '\\d+' part yield int part else yield part return list splitHelper nonEmptyParts
@register_canonicalize@register_stabilize@gof.local_optimizer [T.Reshape] def local_reshape_lift node if isinstance node.op T.Reshape and node.inputs[0].owner and isinstance node.inputs[0].owner.op T.Elemwise and len node.inputs[0].owner.inputs 1 r node.op node.inputs[0].owner.inputs[0] node.inputs[1] copy_stack_trace node.outputs r e node.inputs[0].owner.op r copy_stack_trace node.outputs + node.inputs e if e.type ! node.outputs[0].type re T.patternbroadcast e node.outputs[0].broadcastable copy_stack_trace e re else re ereturn [re]
def get_time_zone_abbr time_zone date_time None date_time datetime.now utc if date_time is None else date_time return _format_time_zone_string time_zone date_time '%Z'
def p_if_stmt p p[0] ast.If [ p[2] p[4] ] None
def ridge_penalty_gradient beta alpha return [0] + [ 2 * alpha * beta_j for beta_j in beta[1 ]]
def name_servers_search search for_item True if isinstance search basestring search search.strip if for_item is True if search in ['<<inherit>>' ''] return searchsearch shlex.split search if isinstance search list for sl in search hostname sl else raise CX 'Invalidinputtype%s expectedstrorlist' % type search return search
def register_file name member path digest '' conn None if conn is None conn init conn.execute 'INSERTINTOfilesVALUES ? ? ? ? ? ? ? ? ? ? ? ? ' name '{0}/{1}'.format path member.path member.size member.mode digest member.devmajor member.devminor member.linkname member.linkpath member.uname member.gname member.mtime
def get_image vm_ vm_image config.get_cloud_config_value 'image' vm_ __opts__ .encode 'ascii' 'salt-cloud-force-ascii' images avail_images for key value in images.iteritems if vm_image and vm_image in images[key]['id'] images[key]['name'] return images[key]raise SaltCloudNotFound "Thespecifiedimage '{0}' couldnotbefound.".format vm_image
def addbroadcast x *axes rval Rebroadcast *[ axis True for axis in axes] x return theano.tensor.opt.apply_rebroadcast_opt rval
def syspath path prefix True if os.path.__name__ ! 'ntpath' return pathif not isinstance path unicode try path path.decode 'utf8' except UnicodeError encoding sys.getfilesystemencoding or sys.getdefaultencoding path path.decode encoding 'replace' if prefix and not path.startswith WINDOWS_MAGIC_PREFIX if path.startswith u'\\\\' path u'UNC' + path[1 ] path WINDOWS_MAGIC_PREFIX + path return path
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def sorting_score start advertised_start announcement announcement start now sorting_dates start advertised_start announcement scale 300.0if announcement days now - announcement .daysscore - exp - days / scale else days now - start .daysscore exp days / scale return score
def badges_enabled return settings.FEATURES.get 'ENABLE_OPENBADGES' False
def late_versioning_catch document resource resource_def app.config['DOMAIN'][resource]version app.config['VERSION']if resource_def['versioning'] is True if version not in document resolve_document_version document resource 'POST' insert_versioning_documents resource document
def ensure_timezone func argname arg if isinstance arg tzinfo return argif isinstance arg string_types return timezone arg raise TypeError "{func} couldn'tconvertargument{argname} {arg!r}toatimezone.".format func _qualified_name func argname argname arg arg
@utils.arg '--tenant' metavar '<tenant-id>' default None help _ 'IDoftenanttolistthedefaultquotasfor.' def do_quota_defaults cs args if args.tenant project_id args.tenantelif isinstance cs.client client.SessionClient auth cs.client.authproject_id auth.get_auth_ref cs.client.session .project_idelse project_id cs.client.tenant_id_quota_show cs.quotas.defaults project_id
def parse_with_bindops sentence grammar None trace 0 if not grammar grammar 'grammars/book_grammars/storage.fcfg'parser load_parser grammar trace trace chart_class InstantiateVarsChart tokens sentence.split return list parser.parse tokens
@open_file 1 mode 'wt' def write_sparse6 G path nodes None header True path.write generate_sparse6 G nodes nodes header header path.write '\n'
@core_helperdef url_for_static *args **kw if args url urlparse.urlparse args[0] url_is_external url.scheme ! '' or url.netloc ! '' if url_is_external CkanUrlException ckan.exceptions.CkanUrlExceptionraise CkanUrlException 'ExternalURLpassedtourl_for_static ' return url_for_static_or_external *args **kw
def fix_reference_name name blacklist None import rename ''.join re.split '[^0-9a-zA-Z_]' name while name and not re.match ' [a-zA-Z]+[0-9a-zA-Z_]* $' name if not re.match '[a-zA-Z]' name[0] name name[1 ]continuename str name if not name name 'data'if blacklist is not None and name in blacklist get_new_name lambda index name + '%03d' % index index 0while get_new_name index in blacklist index + 1name get_new_name index return name
def glob_tildes_at_end path result glob path with_tildes [f for f in result if f.endswith '~' ]no_tildes [f for f in result if not f.endswith '~' ]return no_tildes + with_tildes
def xorg name ret {'name' name 'changes' {} 'result' None 'comment' ''}if __salt__['keyboard.get_x'] name ret['result'] Trueret['comment'] 'XOrglayout{0}alreadyset'.format name return retif __opts__['test'] ret['comment'] 'XOrglayout{0}needstobeset'.format name return retif __salt__['keyboard.set_x'] name ret['changes'] {'layout' name}ret['result'] Trueret['comment'] 'SetXOrgkeyboardlayout{0}'.format name return retelse ret['result'] Falseret['comment'] 'FailedtosetXOrgkeyboardlayout'return ret
def delete_resource resource_name key identifier_fields profile 'pagerduty' subdomain None api_key None resource get_resource resource_name key identifier_fields profile subdomain api_key if resource if __opts__['test'] return 'woulddelete'del __context__['pagerduty_util.resource_cache'][resource_name]resource_id _get_resource_id resource return _query method 'DELETE' action '{0}/{1}'.format resource_name resource_id profile profile subdomain subdomain api_key api_key else return True
def _unique_parnames names upper_names set unique_names []for name in names name_upper name.upper while name_upper in upper_names name '_' + name name_upper '_' + name_upper unique_names.append name upper_names.add name_upper return unique_names
def add_label name kernel_config None platform None only_if_needed None return models.Label.add_object name name kernel_config kernel_config platform platform only_if_needed only_if_needed .id
def ParseTaskAgeLimit age_limit age_limit age_limit.strip if not age_limit raise MalformedQueueConfiguration 'TaskAgeLimitmustnotbeempty.' unit age_limit[ -1 ]if unit not in 'smhd' raise MalformedQueueConfiguration 'TaskAge_Limitmustbeins seconds m minutes h hours ord days ' try number float age_limit[0 -1 ] if unit 's' return int number if unit 'm' return int number * 60 if unit 'h' return int number * 3600 if unit 'd' return int number * 86400 except ValueError raise MalformedQueueConfiguration 'TaskAge_Limit"%s"isinvalid.' % age_limit
def test_existing_path_FileLinks_repr_alt_formatter td mkdtemp tf1 NamedTemporaryFile dir td tf2 NamedTemporaryFile dir td def fake_formatter dirname fnames included_suffixes return ['hello' 'world']fl display.FileLinks td terminal_display_formatter fake_formatter actual repr fl actual actual.split '\n' actual.sort expected ['hello' 'world']expected.sort nt.assert_equal actual expected
def test_equalize_channels evoked1 read_evokeds fname condition 0 proj True evoked2 evoked1.copy ch_names evoked1.ch_names[2 ]evoked1.drop_channels evoked1.ch_names[ 1] evoked2.drop_channels evoked2.ch_names[1 2] my_comparison [evoked1 evoked2]equalize_channels my_comparison for e in my_comparison assert_equal ch_names e.ch_names
def idzr_aidi m n k return _id.idzr_aidi m n k
def getEvaluatedDictionaryByEvaluationKeys elementNode evaluationKeys evaluatedDictionary {}for key in elementNode.attributes.keys if key in evaluationKeys addValueToEvaluatedDictionary elementNode evaluatedDictionary key return evaluatedDictionary
def rename_file source dest os.rename source dest __remove_pyc_pyo source
def _prepare_unit unit return {'id' unit.id 'url' unit.get_translate_url 'isfuzzy' unit.isfuzzy 'source' [source[1] for source in pluralize_source unit ] 'target' [target[1] for target in pluralize_target unit ]}
def test_plane vertices filled outline create_plane assert_array_equal np.arange len vertices np.unique filled assert_array_equal np.arange len vertices np.unique outline
def untokenize_without_newlines tokens text u''last_row 0last_column -1 for t in tokens token_string t[1] start_row start_column t[2] end_row end_column t[3]if start_row > last_row last_column 0if start_column > last_column or token_string u'\n' and not text.endswith u'' text + u''if token_string ! u'\n' text + token_stringlast_row end_rowlast_column end_columnreturn text.rstrip
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def get_instance_vdis_for_sr session vm_ref sr_ref for vbd_ref in session.call_xenapi 'VM.get_VBDs' vm_ref try vdi_ref session.call_xenapi 'VBD.get_VDI' vbd_ref if sr_ref session.call_xenapi 'VDI.get_SR' vdi_ref yield vdi_ref except session.XenAPI.Failure continue
@csrf_exempt@social.apps.django_app.utils.psa '{0} complete'.format URL_NAMESPACE def lti_login_and_complete_view request backend *args **kwargs if request.method ! 'POST' return HttpResponseNotAllowed 'POST' request.backend.start return complete request backend *args **kwargs
def getFlippedLoop elementNode loop prefix flipPoints elementNode loop prefix if getShouldReverse elementNode prefix loop.reverse return loop
def log_dependency_not_found label_name if label_name in DEPENDENCIES_NOT_FOUND returnlogging.info 'Dependency%snotfound' label_name DEPENDENCIES_NOT_FOUND.add label_name
def _clean_blocks tmp_seq_blocks seq_blocks []for seq_block in tmp_seq_blocks for line_name in seq_block seq_block[line_name] seq_block[line_name].replace '{' '' .replace '}' '' seq_blocks.append seq_block return seq_blocks
def get_network_interface_fields fields item_system.NETWORK_INTERFACE_FIELDSfields_ui []for field in fields field_ui {'name' field[0] 'dname' field[0] 'value' '?' 'caption' field[3] 'editable' field[4] 'tooltip' field[5] 'choices' field[6] 'css_class' 'generic' 'html_element' 'generic'}if not field_ui['editable'] continuefield_ui['value'] ''field_ui['value_raw'] field_ui['value']name field[0]field_ui['html_element'] _get_field_html_element name fields_ui.append field_ui return fields_ui
def test_make_imbalance_4 X_ y_ make_imbalance X Y ratio 0.01 min_c_ 1 counter Counter y_ assert_equal counter[0] 500 assert_equal counter[1] 5 assert_true np.all [ X_i in X for X_i in X_]
def get_chunks_in_range chunks first_line num_lines for i chunk in enumerate chunks lines chunk[u'lines']if lines[ -1 ][0] > first_line > lines[0][0] start_index first_line - lines[0][0] if first_line + num_lines < lines[ -1 ][0] last_index start_index + num_lines else last_index len lines new_chunk {u'index' i u'lines' chunk[u'lines'][start_index last_index] u'numlines' last_index - start_index u'change' chunk[u'change'] u'meta' chunk.get u'meta' {} } yield new_chunk first_line + new_chunk[u'numlines']num_lines - new_chunk[u'numlines']assert num_lines > 0 if num_lines 0 break
@profiler.tracedef vpnservice_create request **kwargs body {'vpnservice' {'admin_state_up' kwargs['admin_state_up'] 'name' kwargs['name'] 'description' kwargs['description'] 'router_id' kwargs['router_id'] 'subnet_id' kwargs['subnet_id']}}vpnservice neutronclient request .create_vpnservice body .get 'vpnservice' return VPNService vpnservice
def remove_master_course_staff_from_ccx_for_existing_ccx apps schema_editor CustomCourseForEdX apps.get_model u'ccx' u'CustomCourseForEdX' list_ccx CustomCourseForEdX.objects.all for ccx in list_ccx if not ccx.course_id or ccx.course_id.deprecated continueccx_locator CCXLocator.from_course_locator ccx.course_id unicode ccx.id try course get_course_by_id ccx.course_id remove_master_course_staff_from_ccx course ccx_locator ccx.display_name send_email False except Http404 log.warning u'Unabletoremoveinstructorsandstaffofmastercourse%sfromccx%s.' ccx.course_id ccx_locator
def kb object return sys.getsizeof object * 0.01
def test_maxfilter_get_rank mf read_info raw_fname ['proc_history'][0]['max_info']rank1 mf['sss_info']['nfree']rank2 _get_sss_rank mf assert_equal rank1 rank2
def get_gid_list user None include_default True if HAS_GRP is False or HAS_PWD is False return []gid_list [gid for group gid in six.iteritems salt.utils.get_group_dict user include_default include_default ]return sorted set gid_list
def init_quickmark_completions log.completion.debug 'Initializingquickmarkcompletion.' try _instances[usertypes.Completion.quickmark_by_name].deleteLater except KeyError passmodel miscmodels.QuickmarkCompletionModel _instances[usertypes.Completion.quickmark_by_name] model
def _allow_donation course_modes course_id enrollment if course_id not in course_modes flat_unexpired_modes {unicode course_id [mode for mode in modes] for course_id modes in course_modes.iteritems }flat_all_modes {unicode course_id [mode.slug for mode in modes] for course_id modes in CourseMode.all_modes_for_courses [course_id] .iteritems }log.error u'Cannotfind`%s`incoursemodes.`%s`.Allmodes `%s`' course_id flat_unexpired_modes flat_all_modes donations_enabled DonationConfiguration.current .enabledreturn donations_enabled and enrollment.mode in course_modes[course_id] and course_modes[course_id][enrollment.mode].min_price 0
def replaceEnt mo return replacements.get mo.group 1 mo.group
def transplant_class cls module class C cls passC.__module__ moduleC.__name__ cls.__name__C.__qualname__ cls.__name__return C
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def update_python_path paths old_sys_path_items list sys.path for path in paths if path.find 'site-packages' ! -1 site.addsitedir path else sys.path.insert 0 path new_sys_path_items set sys.path - set old_sys_path_items sys.path list new_sys_path_items + old_sys_path_items
def get_image_service return ImageService
def to_local_timezone datetime return get_i18n .to_local_timezone datetime
def makeTodo value if isinstance value str return Todo reason value if isinstance value tuple errors reason valuetry errors list errors except TypeError errors [errors]return Todo reason reason errors errors
def remove_acl path if platform.system constants.PLATFORM_DARWIN and os.path.isfile '/bin/chmod' subprocess.call ['/bin/chmod' '-R' '-N' path] elif platform.system constants.PLATFORM_LINUX and os.path.isfile '/bin/setfacl' subprocess.call ['/bin/setfacl' '-R' '-b' path]
def compile_metrics start_time stop_time None start_time int start_time xml _get_rrd_updates _get_rrd_server start_time if xml doc minidom.parseString xml return _parse_rrd_update doc start_time stop_time raise exception.CouldNotFetchMetrics
def subreddit_sitemaps subreddits for subreddit_chunks in in_chunks subreddits LINKS_PER_SITEMAP yield _subreddit_sitemap subreddit_chunks
def process_bc_freqs bc_freqs bcs_list []for curr_key in bc_freqs.keys bcs_list.append curr_key int bc_freqs[curr_key] bcs_list sorted bcs_list key itemgetter 1 reverse True sorted_bcs []for curr_bc in bcs_list sorted_bcs.append '%s DCTB %d' % curr_bc[0] curr_bc[1] return sorted_bcs
def lens_makers_formula n_lens n_surr r1 r2 if isinstance n_lens Medium n_lens n_lens.refractive_indexelse n_lens sympify n_lens if isinstance n_surr Medium n_surr n_surr.refractive_indexelse n_surr sympify n_surr r1 sympify r1 r2 sympify r2 return 1 / n_lens - n_surr / n_surr * 1 / r1 - 1 / r2
def getCentersFromIntersectionLoop circleIntersectionLoop radius loop []for circleIntersection in circleIntersectionLoop loop.append circleIntersection.circleNodeAhead.circle * radius return loop
def find_latex_line lines latex re_string re.compile latex.replace '\\' '\\\\' for i line in enumerate lines if re_string.match line return ielse return None
def shuffle_array X y idx np.argsort [random.random for i in xrange len y ] X [X[i] for i in idx]y [y[i] for i in idx]return X y
def arg_to_softmax prob if not isinstance prob Variable raise TypeError if prob.owner is None raise TypeError owner prob.ownerif not isinstance owner.op T.nnet.Softmax raise TypeError rval owner.inputsreturn rval
def _fixencoding input encoding final False prefix u'@charset"'if len input > len prefix if input.startswith prefix pos input.find u'"' len prefix if pos > 0 if encoding.replace '_' '-' .lower 'utf-8-sig' encoding u'utf-8'return prefix + encoding + input[pos ] else return inputelif not prefix.startswith input or final return inputif final return inputreturn None
def perform_cleanup scratch_image_name scratch_text_name_root for name in scratch_image_name scratch_text_name_root + '.txt' 'tesseract.log' try os.remove name except OSError pass
def iter_first sequence it iter sequence try if PY3 return next it else return it.next except StopIteration raise ValueError
def test_operator_export export_string TPOTSelectKBest .export 5 assert export_string 'SelectKBest k 5 score_func f_classif '
def _update_orf_afi_safi afi safi global _orf_entry_afiglobal _orf_entry_safi_orf_entry_afi afi_orf_entry_safi safi
def _if_str_then_list listing if type listing is str return [listing]elif type listing is not list raise TypeErrorreturn listing
@redis_connection 'unique' def get_expected conn key today return conn EXPECTED[key]
def parse_distmat lines header Noneresult []for line in lines if line[0] ' DCTB ' header map strip line.split ' DCTB ' [1 ] else result.append map float line.split ' DCTB ' [1 ] return header asarray result
def plot_posterior_predictive trace eval None lm None samples 30 **kwargs import matplotlib.pyplot as pltif lm is None lm lambda x sample sample['Intercept'] + sample['x'] * x if eval is None eval np.linspace 0 1 100 if 'lw' not in kwargs and 'linewidth' not in kwargs kwargs['lw'] 0.2if 'c' not in kwargs and 'color' not in kwargs kwargs['c'] 'k'for rand_loc in np.random.randint 0 len trace samples rand_sample trace[rand_loc]plt.plot eval lm eval rand_sample **kwargs kwargs.pop 'label' None plt.title 'Posteriorpredictive'
def write_contents f opcode find_module 'opcode' targets ['_unknown_opcode'] * 256 for opname op in opcode.opmap.items targets[op] 'TARGET_%s' % opname f.write 'staticvoid*opcode_targets[256] {\n' f.write ' \n'.join [ '&&%s' % s for s in targets] f.write '\n};\n'
def boto_supports_param_in_spot_request ec2 param method getattr ec2 'request_spot_instances' return param in get_function_code method .co_varnames
def _all_branches repo return repo.branches
def assert_not_equal_comparison case a b equal a b unequal a ! b messages []if equal messages.append 'a bevaluatedtoTrue' if not unequal messages.append 'a! bevaluatedtoFalse' if messages case.fail 'Expectedaandbtobenot-equal ' + ';'.join messages
def code_challenge verifier digest hashlib.sha256 verifier .digest return base64.urlsafe_b64encode digest .rstrip ' '
def get_repo alias repos list_repos if repos for source in six.itervalues repos for sub in source if sub['name'] alias return subreturn {}
def get_warnings_state warnings.warn warn_txt DeprecationWarning stacklevel 2 return warnings.filters[ ]
def get_course course_id depth 0 course modulestore .get_course course_id depth depth if course is None raise ValueError u'Coursenotfound {0}'.format course_id return course
def attributeEscapingDoneOutside data if isinstance data unicode return data.encode 'utf-8' return data
def avail_images call None if call 'action' raise SaltCloudSystemExit 'Theavail_imagesfunctionmustbecalledwith-for--function orwiththe--list-imagesoption' server user password _get_xml_rpc auth ' '.join [user password] image_pool server.one.imagepool.info auth -2 -1 -1 [1]images {}for image in _get_xml image_pool images[image.find 'NAME' .text] _xml_to_dict image return images
def _getNotification serialPort return snap.getPacket
def _nested_changes changes global __opts__opts __opts__.copy if __opts__['color'] __opts__['color'] u'CYAN'ret u'\n'ret + salt.output.out_format changes 'nested' __opts__ nested_indent 14 __opts__ optsreturn ret
def debian_package_install packages cmds [] reg_packages url_packages [] [] for package in packages if package.startswith 'http' url_packages.append package else reg_packages.append package if reg_packages cmds.append 'apt-get-yinstall--no-install-recommends{}'.format ''.join reg_packages cmds.append 'apt-getclean' for url in url_packages name url[ url.rfind '/' + 1 ]cmds.extend ['curl--location{}-o{}'.format url name 'dpkg-i{}'.format name 'rm-rf{}'.format name ] return '&&'.join cmds
def checkTimestamp nonce_string allowed_skew SKEW now None try stamp _ split nonce_string except ValueError return Falseelse if now is None now time past now - allowed_skew future now + allowed_skew return past < stamp < future
def get_best_language accept_lang LUM settings.LANGUAGE_URL_MAPNSL settings.NON_SUPPORTED_LOCALESLC settings.LANGUAGE_CODElangs dict LUM langs.update k.lower v if v else LC for k v in NSL.items if k.lower not in langs langs.update k.split '-' [0] v for k v in LUM.items if k.split '-' [0] not in langs ranked parse_accept_lang_header accept_lang for lang _ in ranked lang lang.lower if lang in langs return langs[lang]pre lang.split '-' [0]if pre in langs return langs[pre]return False
def restart name return __salt__['service.run'] name 'restart'
def setBasicLogger setLoggerClass BasicLogger BasicLogger.setLevel 0
def robust_wraps wrapper def _ wrapped wrapped.__doc__ wrapper.__doc__return wrappedreturn _
def show_usage pass
def CreateAdsWithCustomizations client adgroup_ids feed_name adgroup_ad_service client.GetService 'AdGroupAdService' text_ad {'xsi_type' 'TextAd' 'headline' 'LuxuryCruiseto{ %s.Name}' % feed_name 'description1' 'Only{ %s.Price}' % feed_name 'description2' 'Offerendsin{ countdown %s.Date }!' % feed_name 'finalUrls' ['http //www.example.com'] 'displayUrl' 'www.example.com'}operations [{'operator' 'ADD' 'operand' {'adGroupId' adgroup 'ad' text_ad}} for adgroup in adgroup_ids]response adgroup_ad_service.mutate operations if response and 'value' in response for ad in response['value'] print "CreatedanadwithID'%s' type'%s' andstatus'%s'." % ad['ad']['id'] ad['ad']['Ad.Type'] ad['status'] else raise errors.GoogleAdsError 'Noadswereadded.'
def tag_search context data_dict tags count _tag_search context data_dict return {'count' count 'results' [_table_dictize tag context for tag in tags]}
def lookup_object spec parts target spec.split ' ' if ' ' in spec else spec None module __import__ parts for part in parts.split '.' [1 ] + [target] if target else [] module getattr module part return module
def _AddPrivateHelperMethods cls def Modified self 'Setsthe_cached_byte_size_dirtybittotrue \nandpropagatesthistoourlisteneriffthiswasastatechange.\n'if not self._cached_byte_size_dirty self._cached_byte_size_dirty Trueself._listener_for_children.dirty Trueself._is_present_in_parent Trueself._listener.Modified cls._Modified Modifiedcls.SetInParent Modified
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def simplify_section_result section_result section_yielded_result section_result[0]results_for_section []for value in chain section_result[1].values section_result[2].values if value is None continuefor result in value results_for_section.append result section_yielded_unfixed_results len results_for_section > 0 return section_yielded_result section_yielded_unfixed_results results_for_section
def plot_colored_circles ax prng nb_samples 15 for sty_dict j in zip plt.rcParams['axes.prop_cycle'] range nb_samples ax.add_patch plt.Circle prng.normal scale 3 size 2 radius 1.0 color sty_dict['color'] ax.set_xlim [ -4 8] ax.set_ylim [ -5 6] ax.set_aspect 'equal' adjustable 'box' return ax
def get_os_sslcertfile_searchpath OS get_os_name l Noneif OS in __DEF_OS_LOCATIONS l __DEF_OS_LOCATIONS[OS]if not hasattr l '__iter__' l l return l
def prefix_decode_all ls last u '' for w in ls i ord w[0] decoded last[ i] + w[1 ].decode 'utf8' yield decoded last decoded
def run _task
def FillUser property if property.value .has_uservalue uid SynthesizeUserId property.value .uservalue .email if uid property.mutable_value .mutable_uservalue .set_obfuscated_gaiaid uid
def fns return {'details' 'Networkdevicegrains.'}
def CloseInteractiveWindow global editif edit is not None and edit.currentView is not None if edit.currentView.GetParentFrame win32ui.GetMainFrame frame win32ui.GetMainFrame cb frame.GetControlBar ID_DOCKED_INTERACTIVE_CONTROLBAR frame.ShowControlBar cb 0 1 else edit.currentView.GetParentFrame .DestroyWindow
def akaike_info_criterion_lsq ssr n_params n_samples return akaike_info_criterion -0.5 * n_samples * np.log ssr / n_samples n_params n_samples
def combine_lists *seqs result []for seq in seqs if seq is None continueif isinstance seq bytes string_types dict result.append seq else try result.extend seq except result.append seq return result
def initCycle container seq_func n 1 return container func for _ in xrange n for func in seq_func
def copy_if_out_of_date original derived if not os.path.exists derived or os.stat derived .st_mtime < os.stat original .st_mtime try shutil.copyfile original derived except IOError if os.path.basename original 'matplotlibrc' msg "'%s'notfound." % original + 'Didyourun`pythonsetup.pybuild`?' raise IOError msg else raise
def get_distinct_translations units targets {}result []for unit in units if unit.target in targets continuetargets[unit.target] 1result.append unit return result
def as_page return render frappe.response[u'route'] http_status_code frappe.response.get u'http_status_code'
def remove_file_failed failed_file try os.remove failed_file except Exception pass
def terminate_threads func def wrapper *args **kwargs cur_threads set threading.enumerate try return func *args **kwargs finally do_terminate_threads set threading.enumerate - cur_threads wrapper.__name__ func.__name__return wrapper
def EqualVersions version baseline baseline_tuple baseline.versiontruncated_tuple version.version[ len baseline_tuple ]if truncated_tuple baseline_tuple return Trueelse return False
def stable_unique seq seen set seen_add seen.addreturn [x for x in seq if not x in seen or seen_add x ]
def compute_min_dist digr n nodes_explored dist min float 'inf' for v in nodes_explored if digr.has_edge v n d dist[v] + digr.get_edge_weight v n if d < min min dreturn min
def jet rc 'image' cmap 'jet' im gci if im is not None im.set_cmap cm.jet draw_if_interactive
def reapAllProcesses for process in list reapProcessHandlers.values process.reapProcess
def test_passing_request_to_constructor request build_request '/?page 1&sort abc' class SimpleTable Table abc Column table SimpleTable [{'abc' 'bar'} {'abc' 'rab'}] request request assert table.columns['abc'].is_ordered
def forecast location params None url '{}/{}'.format api location headers {'Accept-Encoding' 'gzip'}r requests.get url params params headers headers if r.status_code ! 200 raise WeatherException 'Yourkeyisinvalidorforecast.ioisdown' r r.json if 'error' in r raise WeatherException 'Errorgettingweather {}'.format r['error'] r['error'] return r
def swapList elements indexBegin indexEnd elements[indexBegin] elements[indexEnd] elements[indexEnd] elements[indexBegin]
def no_change return NoOp sleep NOOP_SLEEP_TIME
def version_cmp a b if a b 'TP' return 0if a 'TP' return -1 elif b 'TP' return 1d version2float b - version2float a return 1 if d > 0 else -1 if d < 0 else 0
def start_with_prefix prefix trie branch _retrive_branch prefix trie if not branch return []prefix_list []q branch[1 ]while q curr_branch q.pop 0 if _is_trie_bucket curr_branch prefix_list.append _get_bucket_key curr_branch else q.extend curr_branch[1 ] return prefix_list
def _check_parser parser if parser not in _parsers raise KeyError 'Invalidparser{0!r}passed validparsersare{1}'.format parser _parsers.keys
def pearson_log_likelihood_ratio observed [] expected [] df None tail UPPER o list observed e list expected or _expected o n len o m len o[0] if o else 0 df df or n - 1 * m - 1 df df or m 1 and n - 1 or m - 1 g 0.0for i in xrange n for j in xrange m if o[i][j] ! 0 and e[i][j] ! 0 g + o[i][j] * log o[i][j] / e[i][j] g g * 2 p gammai df * 0.5 g * 0.5 tail return g p
def print_dots current total start False end False if SHUTDOWN_EVENT.isSet returnsys.stdout.write '.' if current + 1 total and end is True sys.stdout.write '\n' sys.stdout.flush
def get_site_url url '' return '{0} //{1}{2}'.format 'https' if ENABLE_HTTPS else 'http' get_site_domain url
def addXIntersectionIndexesFromLoopListsY loopLists xIntersectionIndexList y for loopListIndex in xrange len loopLists loopList loopLists[loopListIndex]addXIntersectionIndexesFromLoopsY loopList loopListIndex xIntersectionIndexList y
def compose *funcs **kfuncs return reduce lambda f g lambda *args **kaargs f g *args **kaargs funcs
def ensure_cwltool_available if main is None or workflow is None or shellescape is None message 'Thisfeaturerequirescwltoolanddependenciestobeavailable theyarenot.'if main is None message + 'cwltoolisnotunavailable.'elif load_tool is None message + 'cwltool.load_toolisunavailable-cwltoolversionistooold.'if requests is None message + "Library'requests'unavailable."if shellescape is None message + "Library'shellescape'unavailable."if schema_salad is None message + "Library'schema_salad'unavailable."raise ImportError message
def _sph_harm order degree az pol from scipy.special import lpmvfrom .preprocessing.maxwell import _sph_harm_normif np.abs order > degree raise ValueError 'Absolutevalueofordermustbe< degree' az np.asarray az pol np.asarray pol if np.abs az > 2 * np.pi .any raise ValueError 'Azimuthcoordsmustliein[-2*pi 2*pi]' if pol < 0 .any or pol > np.pi .any raise ValueError 'Polarcoordsmustliein[0 pi]' sph lpmv order degree np.cos pol * np.exp 1j * order * az sph * _sph_harm_norm order degree return sph
def SelectTlb title 'SelectLibrary' excludeFlags 0 import pywin.dialogs.listitems EnumTlbs excludeFlags for i in items i.major int i.major 16 i.minor int i.minor 16 items.sort rc pywin.dialogs.list.SelectFromLists title items ['TypeLibrary'] if rc is None return Nonereturn items[rc]
def avg list return float _sum list / len list or 1
def _max_stat X X2 perms dof_scaling n_samples len X mus np.dot perms X / float n_samples stds np.sqrt X2[None ] - mus ** 2 * dof_scaling max_abs np.max np.abs mus / stds / sqrt n_samples axis 1 return max_abs
def _class_type klass ancestors None if klass._type is not None return klass._typeif _is_metaclass klass klass._type 'metaclass'elif klass.name.endswith 'Interface' klass._type 'interface'elif klass.name.endswith 'Exception' klass._type 'exception'else if ancestors is None ancestors set if klass in ancestors klass._type 'class'return 'class'ancestors.add klass for base in klass.ancestors recurs False name _class_type base ancestors if name ! 'class' if name 'metaclass' and not _is_metaclass klass continueklass._type base.typebreakif klass._type is None klass._type 'class'return klass._type
def write_id fid kind id_ None id_ _generate_meas_id if id_ is None else id_ data_size 5 * 4 fid.write np.array kind dtype '>i4' .tostring fid.write np.array FIFF.FIFFT_ID_STRUCT dtype '>i4' .tostring fid.write np.array data_size dtype '>i4' .tostring fid.write np.array FIFF.FIFFV_NEXT_SEQ dtype '>i4' .tostring arr np.array [id_['version'] id_['machid'][0] id_['machid'][1] id_['secs'] id_['usecs']] dtype '>i4' fid.write arr.tostring
def run _task
def should_be_approved pending_registration return timezone.now - pending_registration.initiation_date > settings.REGISTRATION_APPROVAL_TIME
def volume_get_active_by_window context begin end None project_id None return IMPL.volume_get_active_by_window context begin end project_id
def esearch db term **keywds cgi 'https //eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'variables {'db' db 'term' term}variables.update keywds return _open cgi variables
def get_images name None quiet False all True client _get_client status base_status.copy try infos client.images name name quiet quiet all all for i in range len infos inf infos[i]try inf['Human_Size'] _sizeof_fmt int inf['Size'] except ValueError passtry ts int inf['Created'] dts datetime.datetime.fromtimestamp ts inf['Human_IsoCreated'] dts.isoformat inf['Human_Created'] dts.strftime '%Y-%m-%d%H %M %S' except Exception passtry inf['Human_VirtualSize'] _sizeof_fmt int inf['VirtualSize'] except ValueError pass_valid status out infos except Exception _invalid status out traceback.format_exc return status
def _get_bookmark repo name try return [x for x in _all_bookmarks repo if x[0] name ][0]except IndexError return False
def test_another_sparktext chart Line chart.add '_' [0 30 55 80 33 150] assert chart.render_sparktext u '\xe2\x96\x81\xe2\x96\x82\xe2\x96\x83\xe2\x96\x84\xe2\x96\x82\xe2\x96\x88' assert chart.render_sparktext chart.render_sparktext chart2 Bar chart2.add '_' [0 30 55 80 33 150] assert chart2.render_sparktext chart.render_sparktext
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def hstack tables join_type u'outer' uniq_col_name u'{col_name}_{table_name}' table_names None metadata_conflicts u'warn' tables _get_list_of_tables tables if len tables 1 return tables[0]col_name_map OrderedDict out _hstack tables join_type uniq_col_name table_names col_name_map _merge_col_meta out tables col_name_map metadata_conflicts metadata_conflicts _merge_table_meta out tables metadata_conflicts metadata_conflicts return out
def upgrade_response response wrapper_class get_seek_wrapper_class response if hasattr response 'closeable_response' if not hasattr response 'seek' response wrapper_class response assert hasattr response 'get_data' return copy.copy response try code response.codeexcept AttributeError code Nonetry msg response.msgexcept AttributeError msg Nonedata Noneget_data getattr response 'get_data' None if get_data data get_data response closeable_response response.fp response.info response.geturl code msg response wrapper_class response if data response.set_data data return response
def get_app_modules for app in apps.get_app_configs yield app.name app.module
def human_number number return {1 'one' 2 'two' 3 'three' 4 'four' 5 'five' 6 'six' 7 'seven' 8 'eight' 9 'nine' 10 'ten'}[number]
def _format_field_name attr parts attr.rsplit ' ' 1 name parts[ -1 ].replace '_' '' if name.isupper or name.islower name name.title parts[ -1 ] namereturn ' '.join parts
def group_get context group_id return IMPL.group_get context group_id
def newest_slice iterable count if count < -1 raise ValueError "countcan'tbesmallerthan-1!" elif count 0 return []elif count -1 or len iterable < count return iterableelse return itertools.islice iterable len iterable - count len iterable
def render_form_errors form type u'all' **kwargs renderer_cls get_form_renderer **kwargs return renderer_cls form **kwargs .render_errors type
def getUID global _uid_uid + 1return str _uid
def _parse_ssl_options options use_ssl options.get 'ssl' if use_ssl is not None validate_boolean 'ssl' use_ssl certfile options.get 'ssl_certfile' keyfile options.get 'ssl_keyfile' passphrase options.get 'ssl_pem_passphrase' ca_certs options.get 'ssl_ca_certs' cert_reqs options.get 'ssl_cert_reqs' match_hostname options.get 'ssl_match_hostname' True crlfile options.get 'ssl_crlfile' ssl_kwarg_keys [k for k in options if k.startswith 'ssl_' and options[k] ]if use_ssl False and ssl_kwarg_keys raise ConfigurationError 'sslhasnotbeenenabledbutthefollowingsslparametershavebeenset %s.Pleaseset`ssl True`orremove.' % ' '.join ssl_kwarg_keys if ssl_kwarg_keys and use_ssl is None use_ssl Trueif use_ssl is True ctx get_ssl_context certfile keyfile passphrase ca_certs cert_reqs crlfile return ctx match_hostname return None match_hostname
def _parse_currency value if not isinstance value dict value currency.match value .groupdict value['amount'] Decimal value['amount'] return value
def _CreateKeyset name purpose key_type meta keydata.KeyMetadata name purpose key_type writer keyczar_dict.DictWriter writer.WriteMetadata meta czar keyczar.GenericKeyczar keyczar_dict.DictReader writer.dict czar.AddVersion keyinfo.PRIMARY czar.Write writer return writer.dict
def get_first_mapbox_geocode_result query map_id settings.MAPBOX_MAP_IDurl 'http //api.tiles.mapbox.com/v3/%s/geocode/%s.json' % map_id query r requests.get url r.raise_for_status data r.json if data.get 'results' result data['results'][0]result dict [ item['type'] item for item in result] return resultreturn {}
def test_precision_epoch t_utc Time range 1980 2001 format 'jyear' scale 'utc' t_tai Time range 1980 2001 format 'jyear' scale 'tai' dt t_utc - t_tai assert allclose_sec dt.sec np.round dt.sec
def serializeObject object_ return base64pickle object_
def hostname global __FQDN__grains {}if salt.utils.is_proxy return grainsgrains['localhost'] socket.gethostname if __FQDN__ is None __FQDN__ salt.utils.network.get_fqhostname if __FQDN__ is None log.error 'Havingtroublegettingahostname.Doesthismachinehaveitshostnameanddomainsetproperly?' __FQDN__ 'localhost.localdomain'grains['fqdn'] __FQDN__ grains['host'] grains['domain'] grains['fqdn'].partition '.' [ 2]return grains
def _normalize_basedir basedir None if isinstance basedir six.string_types basedir [x.strip for x in basedir.split ' ' ]if basedir is None basedir []if not basedir basedir _get_yum_config_value 'reposdir' if not isinstance basedir list or not basedir raise SaltInvocationError 'Couldnotdetermineanyrepodirectories' return basedir
def _postprocess_for_cut fac bins retbins x_is_series series_index name if x_is_series fac Series fac index series_index name name if not retbins return facreturn fac bins
def change_cwd cwd os.getcwd if os.path.split cwd [1] 'scripts' os.chdir os.path.join cwd os.pardir
def updateInstance self try self.__class__ latestClass self.__class__ except TypeError if hasattr self.__class__ '__slots__' raise RebuildError "Can'trebuildclasswith__slots__onPython<2.6" else raise
def cap_expirydate return current.request.utcnow + datetime.timedelta days current.deployment_settings.get_cap_expire_offset
def lwta p block_size batch_size p.shape[0]num_filters p.shape[1]num_blocks num_filters // block_size w p.reshape batch_size num_blocks block_size block_max w.max axis 2 .dimshuffle 0 1 'x' * T.ones_like w max_mask T.cast w > block_max 'float32' indices numpy.array range 1 block_size + 1 max_mask2 max_mask * indices block_max2 max_mask2.max axis 2 .dimshuffle 0 1 'x' * T.ones_like w max_mask3 T.cast max_mask2 > block_max2 'float32' w2 w * max_mask3 w3 w2.reshape p.shape[0] p.shape[1] return w3
def local_tz func @functools.wraps func def wrapper *args **kwargs tz os.environ.get 'TZ' '' try os.environ['TZ'] 'EST+05EDT M4.1.0 M10.5.0'time.tzset return func *args **kwargs finally os.environ['TZ'] tztime.tzset return wrapper
def _encode_ocsp_nocheck backend ext return _encode_asn1_str_gc backend '\x05\x00' 2
def modules modulePath try mod sys.modules[modulePath]if mod is None raise KeyError except KeyError mod __import__ modulePath globals locals [''] return mod
def has_dataset name endswith {'brainstorm' 'MNE_brainstorm-data' 'fake' 'foo' 'misc' 'MNE-misc-data' 'sample' 'MNE-sample-data' 'somato' 'MNE-somato-data' 'spm' 'MNE-spm-face' 'testing' 'MNE-testing-data' 'visual_92_categories' 'visual_92_categories-data'}[name]archive_name Noneif name 'brainstorm' archive_name dict brainstorm 'bst_raw' dp _data_path download False name name check_version False archive_name archive_name return dp.endswith endswith
def sms_outbox if not auth.s3_logged_in session.error T 'RequiresLogin!' redirect URL c 'default' f 'user' args 'login' tablename 'msg_sms'table s3db.msg_smss3.filter table.inbound False table.inbound.readable Falses3.crud_strings[tablename] Storage title_display T 'SMSDetails' title_list T 'SentSMS' label_list_button T 'ViewSentSMS' label_delete_button T 'DeleteSMS' msg_record_deleted T 'SMSdeleted' msg_list_empty T 'NoSMScurrentlyinOutbox' def postp r output if isinstance output dict add_btn A T 'Compose' _class 'action-btn' _href URL f 'compose' output['rheader'] add_btnreturn outputs3.postp postps3db.configure tablename editable False insertable False listadd False list_fields ['id' 'date' 'to_address' 'body'] return s3_rest_controller module 'sms'
def within_range_list num range_list return any num > min_ and num < max_ for min_ max_ in range_list
def oracle_old_passwd password username uppercase True IV pad '\x00' * 8 '\x00' if isinstance username unicode username unicode.encode username UNICODE_ENCODING unistr ''.join '\x00%s' % c for c in username + password .upper cipher des hexdecode '0123456789ABCDEF' CBC IV pad encrypted cipher.encrypt unistr cipher des encrypted[ -8 ] CBC IV pad encrypted cipher.encrypt unistr retVal hexencode encrypted[ -8 ] return retVal.upper if uppercase else retVal.lower
def test_process_warning capsys query ' 'choices [' ']_ process.extractOne query choices out err capsys.readouterr outstr "WARNING root Appliedprocessorreducesinputquerytoemptystring allcomparisonswillhavescore0.[Query ' ']\n"assert err outstr
def DNSServiceUpdateRecord sdRef RecordRef None flags 0 rdata _NO_DEFAULT ttl 0 _NO_DEFAULT.check rdata rdlen rdata _string_to_length_and_void_p rdata _global_lock.acquire try _DNSServiceUpdateRecord sdRef RecordRef flags rdlen rdata ttl finally _global_lock.release
def asint value if value is None return valuereturn int value
def f_measure reference test alpha 0.5 p precision reference test r recall reference test if p is None or r is None return Noneif p 0 or r 0 return 0return 1.0 / alpha / p + 1 - alpha / r
def load_url url model_dir None if model_dir is None torch_home os.path.expanduser os.getenv 'TORCH_HOME' '~/.torch' model_dir os.getenv 'TORCH_MODEL_ZOO' os.path.join torch_home 'models' if not os.path.exists model_dir os.makedirs model_dir parts urlparse url filename os.path.basename parts.path cached_file os.path.join model_dir filename if not os.path.exists cached_file sys.stderr.write 'Downloading "{}"to{}\n'.format url cached_file hash_prefix HASH_REGEX.search filename .group 1 _download_url_to_file url cached_file hash_prefix return torch.load cached_file
def get_ccx_for_coach course coach ccxs CustomCourseForEdX.objects.filter course_id course.id coach coach if ccxs.exists return ccxs[0]return None
def LogExceptionCallback type value tb logging.error 'unexpectederror' exc_info type value tb
def monkeypatch_render import django.shortcutsdef more_info fun "Django'srendershortcut butcapturesinformationfortesting\nWhenusingDjango'srendershortcutwithJinja2templates noneof\ntheinformationiscapturedandthusyoucan'tuseitfortesting.\nThisalleviatesthatsomewhatbycapturingsomeoftheinformation\nallowingyoutotestit.\nCaveats \n*itdoes*not*capturealltheJinja2templatesusedtorender.\nOnlythetopmostonerequestedbytherender function.\n"@wraps fun def _more_info request template_name *args **kwargs resp fun request template_name *args **kwargs resp.jinja_templates [template_name]if args resp.jinja_context args[0]elif 'context' in kwargs resp.jinja_context kwargs['context']else resp.jinja_context {}return respreturn _more_infodjango.shortcuts.render more_info django.shortcuts.render
def assert_rpm_requires test_case expected_requirements rpm_path output check_output ['rpm' '--query' '--requires' '--package' rpm_path.path] actual_requirements set line.strip for line in output.splitlines expected_requirements set expected_requirements missing_requirements expected_requirements - actual_requirements if missing_requirements test_case.fail 'Missingrequirements {}in{}'.format missing_requirements rpm_path.path
def test_rgb_yuv rng np.random.RandomState [1 2 3] X as_floatX rng.randn 5 32 * 32 * 3 axes ['b' 0 1 'c']view_converter dense_design_matrix.DefaultViewConverter 32 32 3 axes dataset DenseDesignMatrix X X view_converter view_converter dataset.axes axespreprocessor RGB_YUV dataset.apply_preprocessor preprocessor result dataset.get_design_matrix assert isfinite result
def batch_l2_norm_squared x return BatchL2NormSquared x
def complex_semver_match version version_specifier split_version_specifier version_specifier.split ' ' if len split_version_specifier 1 return semver.match version version_specifier else for version_specifier_part in split_version_specifier version_specifier_part version_specifier_part.strip if not version_specifier_part continueif not semver.match version version_specifier_part return Falsereturn True
@mock_streams 'stderr' def test_require_mixed_state_keys_prints_missing_only try require 'foo' 'version' except SystemExit err sys.stderr.getvalue assert 'version' not in err assert 'foo' in err
def test_hepatitis skip_if_no_data data hepatitis.Hepatitis assert data.X is not None assert np.all data.X ! np.inf assert np.all data.X ! np.nan
@env.catch_exceptionsdef reload_changes changes resources changes.get_changed_resources moved _get_moved_resources changes current env.curbuf.numberfor f in resources bufnr env.var 'bufnr "%s" ' % f.real_path env.goto_buffer bufnr path env.curbuf.nameif f in moved path moved[f].real_pathenv.debug 'Reload' f.real_path path bufnr env.goto_file path 'e!' force True env.message '%shasbeenchanged.' % f.real_path history True env.goto_buffer current
def sub_miller segments fracts [segment_to_fraction segment for segment in segments]common_denominator reduce lcm [fract.denominator for fract in fracts] miller_indices [ fract.numerator * math.fabs common_denominator / fract.denominator for fract in fracts]return ' ' + ' '.join map str map decimal.Decimal miller_indices + ' '
def site_config_dirs appname if WINDOWS path os.path.normpath _get_win_folder 'CSIDL_COMMON_APPDATA' pathlist [os.path.join path appname ]elif sys.platform 'darwin' pathlist [os.path.join '/Library/ApplicationSupport' appname ]else xdg_config_dirs os.getenv 'XDG_CONFIG_DIRS' '/etc/xdg' if xdg_config_dirs pathlist [os.path.join expanduser x appname for x in xdg_config_dirs.split os.pathsep ]else pathlist []pathlist.append '/etc' return pathlist
def validate_required value required if required and not value raise ValueError u'mustbeset.'
def translation_allowed_language select_language if settings.FEINCMS_FRONTEND_LANGUAGES l select_language[ 2]if l not in settings.FEINCMS_FRONTEND_LANGUAGES select_language django_settings.LANGUAGES[0][0]return select_language
def parse_servers result from version import PROTOCOL_VERSIONservers {}for item in result host item[1]out {}version Nonepruning_level '-'if len item > 2 for v in item[2] if re.match '[st]\\d*' v protocol port v[0] v[1 ] if port '' port DEFAULT_PORTS[protocol]out[protocol] portelif re.match 'v .? +' v version v[1 ]elif re.match 'p\\d*' v pruning_level v[1 ]if pruning_level '' pruning_level '0'try is_recent cmp util.normalize_version version util.normalize_version PROTOCOL_VERSION > 0 except Exception is_recent Falseif out and is_recent out['pruning'] pruning_levelservers[host] outreturn servers
def buildAlternatingTrainingSet numOnes 5 numPatterns 14p getSimplePatterns numOnes numPatterns s1 [p[0] p[1] p[0] p[1] p[0] p[2]]s2 [p[0] p[1] p[0] p[1] p[3] p[4]]s3 [p[0] p[1] p[5] p[6] p[7] p[8]]s4 [p[0] p[9] p[10] p[11] p[12] p[13]]trainingSequences [s1 s2 s3 s4]return trainingSequences 5
def foldl fn elems initializer None name None if initializer is None initializer elems[0]elems elems[1 ]fn2 lambda x acc fn acc x return theano.foldl fn2 elems initializer name name [0]
def resolve_dotted_attribute obj attr allow_dotted_names True if allow_dotted_names attrs attr.split '.' else attrs [attr]for i in attrs if i.startswith '_' raise AttributeError 'attempttoaccessprivateattribute"%s"' % i else obj getattr obj i return obj
def upscale image ratio if not isinstance image np.ndarray raise ValueError 'Expectedndarray' if ratio < 1 raise ValueError 'Ratiomustbegreaterthan1 ratio %f ' % ratio width int math.floor image.shape[1] * ratio height int math.floor image.shape[0] * ratio channels image.shape[2]out np.ndarray height width channels dtype np.uint8 for x y in np.ndindex width height out[ y x ] image[ int math.floor y / ratio int math.floor x / ratio ]return out
def test_gnb_prior_large_bias clf GaussianNB priors np.array [0.01 0.99] clf.fit X y assert_equal clf.predict [[ -0.1 -0.1 ]] np.array [2]
def test_add_array_even_shape large_test_array np.zeros 11 11 small_test_array np.ones 4 4 large_test_array_ref large_test_array.copy large_test_array_ref[0 2 0 2] + small_test_array[2 4 2 4]added_array add_array large_test_array small_test_array 0 0 assert np.all added_array large_test_array_ref
def test_find_best_app test_apps class Module app Flask 'appname' assert find_best_app Module Module.app class Module application Flask 'appname' assert find_best_app Module Module.application class Module myapp Flask 'appname' assert find_best_app Module Module.myapp class Module passpytest.raises NoAppException find_best_app Module class Module myapp1 Flask 'appname1' myapp2 Flask 'appname2' pytest.raises NoAppException find_best_app Module
def parse_args parser argparse.ArgumentParser parser.add_argument '--profile-tool' metavar 'TOOL' action 'store' choices ['kcachegrind' 'snakeviz' 'gprof2dot' 'none'] default 'snakeviz' help 'Thetooltousetoviewtheprofilingdata' parser.add_argument '--profile-file' metavar 'FILE' action 'store' help 'Thefilenametousewith--profile-tool none' return parser.parse_known_args
def reset noGamma True OK init if noGamma and OK setVideoMode NOGAMMACORRECT
def ansible_local_init ansible_inv ansible_inv['local'] {}ansible_inv['local']['hosts'] ['localhost']ansible_inv['local']['vars'] {'ansible_connection' 'local'}
def UQRatio s1 s2 return QRatio s1 s2 force_ascii False
def generate s limit 20 return _gen parse s limit
def add_cycle G nodes **attr G.add_edges_from pairwise nodes cyclic True **attr
def NewLogfileMonitorMixin follow_paths pattern_paths None if not follow_paths or pattern_paths and not follow_paths raise InvalidConfigurationErrorreturn type 'LogfileMonitorMixin%d' % id follow_paths LogfileMonitorMixin {'follow_paths' follow_paths 'pattern_paths' pattern_paths or }
def p_map_type p p[0] TType.MAP p[3] p[5]
def course_has_entrance_exam course if not is_entrance_exams_enabled return Falseif not course.entrance_exam_enabled return Falseif not course.entrance_exam_id return Falsereturn True
def get_migration_data try from django.contrib.auth import get_user_modelexcept ImportError from django.contrib.auth.models import Userelse User get_user_model user_orm_label '%s.%s' % User._meta.app_label User._meta.object_name user_model_label '%s.%s' % User._meta.app_label User._meta.module_name return User user_orm_label user_model_label
def tree_from_cix_path cix_path tree ET.parse cix_path .getroot version tree.get 'version' if version CIX_VERSION return treeelif version '0.1' return tree_2_0_from_tree_0_1 tree else raise CodeIntelError 'unknownCIXversion %r' % version
def set_resp_defaults req resp resource params if resource._default_status is not None resp.status resource._default_statusif resource._default_body is not None resp.body resource._default_bodyif resource._default_headers is not None resp.set_headers resource._default_headers
def parse_spec text tokens text.split ' ' specs []for token in tokens if ' ' not in token token + ' 1' sizespec weight token.split ' ' weight float weight units {'m' 1 'g' 1 << 10 't' 1 << 20 'p' 1 << 30 }unit units.get sizespec[ -1 ].lower None if not unit size float sizespec unit 1else size float sizespec[ -1 ] spec PartitionSpec int size * unit weight specs.append spec return specs
def build_whitespace_split_regex text def __build_parts text lexer shlex.shlex text lexer.whitespace_split Truelexer.commenters ''if "'" in text lexer.quotes '"'elif '"' in text lexer.quotes "'"return list lexer regex ''for line in text.splitlines parts [re.escape s for s in __build_parts line ]regex + ' ? [\\s]+ ?{0} ? [\\s]+ ?'.format ' ? [\\s]+ ?'.join parts return ' ?m ^{0}$'.format regex
@open_file 1 mode 'wb' def write_gexf G path encoding 'utf-8' prettyprint True version '1.1draft' writer GEXFWriter encoding encoding prettyprint prettyprint version version writer.add_graph G writer.write path
@socketio.on 'leave' namespace '/jobs' def on_leave_jobs if 'room' in flask.session room flask.session['room']del flask.session['room']leave_room room
def test_continuous_error y np.linspace 0 1 15 nm NearMiss random_state RND_SEED version VERSION_NEARMISS assert_warns UserWarning nm.fit X y
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def path_to_cache_dir path d p os.path.splitdrive os.path.abspath path if d d d.replace ' ' '---' p p.replace os.sep '--' return d + p + '.cache'
def latex expr **settings return LatexPrinter settings .doprint expr
def c_object return dict c g
def load_opts_from_mrjob_conf runner_alias conf_path None already_loaded None if already_loaded is None already_loaded []conf_path _expanded_mrjob_conf_path conf_path return _load_opts_from_mrjob_conf runner_alias conf_path already_loaded
def reset_builtins_dir set_builtins_dir DEFAULT_DIR
def create_url hostname port None isSecure False if port is not None netloc '%s %d' % hostname port elif isSecure netloc u'{} 443'.format hostname else netloc u'{} 80'.format hostname if isSecure scheme u'rss'else scheme u'rs'return u'{} //{}'.format scheme netloc
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def transfer_user from_session to_session if auth.BACKEND_SESSION_KEY in from_session and auth.SESSION_KEY in from_session and auth.HASH_SESSION_KEY in from_session to_session[auth.BACKEND_SESSION_KEY] from_session[auth.BACKEND_SESSION_KEY]to_session[auth.SESSION_KEY] from_session[auth.SESSION_KEY]to_session[auth.HASH_SESSION_KEY] from_session[auth.HASH_SESSION_KEY]
def processElementNode elementNode elementNode.parentNode.xmlObject.vertexes + getCubicPath elementNode
def run_tidy html global _tidy_cmd _tidy_existsfrom commands import _optionsrequire_tidy _options.get 'require_tidy' if not _tidy_exists if require_tidy raise TwillException 'tidydoesnotexistandrequire_tidyisset' return None None clean_html Noneif _tidy_exists try process subprocess.Popen _tidy_cmd stdin subprocess.PIPE stdout subprocess.PIPE stderr subprocess.PIPE bufsize 0 shell False stdout stderr process.communicate html clean_html stdouterrors stderrexcept OSError _tidy_exists Falseerrors Noneif require_tidy and clean_html is None raise TwillException 'tidydoesnotexistandrequire_tidyisset' return clean_html errors
def _getargs func import typesif sys.version_info > 3 0 if isinstance func types.MethodType func func.__func__co func.__code__else if isinstance func types.MethodType func func.im_funcco func.func_codereturn co.co_varnames[ co.co_argcount]
def find_urls string unique True string u string string string.replace u'\u2024' '.' string string.replace '' '' matches []for p in RE_URL1 RE_URL2 RE_URL3 for m in p.finditer '%s' % string s m.group 1 s s.split '">' [0].split "'>" [0]if not unique or s not in matches matches.append s return matches
def alertingNetToMs Facility_presence 0 ProgressIndicator_presence 0 UserUser_presence 0 a TpPd pd 3 b MessageType mesType 1 packet a / b if Facility_presence is 1 c FacilityHdr ieiF 28 packet packet / c if ProgressIndicator_presence is 1 d ProgressIndicatorHdr ieiPI 30 packet packet / d if UserUser_presence is 1 e UserUserHdr ieiUU 126 packet packet / e return packet
def getwinsize if 'TIOCGWINSZ' in dir termios TIOCGWINSZ termios.TIOCGWINSZelse TIOCGWINSZ 1074295912s struct.pack 'HHHH' 0 0 0 0 x fcntl.ioctl sys.stdout.fileno TIOCGWINSZ s return struct.unpack 'HHHH' x [0 2]
def ParsePropertyQuery query filters orders Check not query.has_transaction 'transactionalquerieson__property__notallowed' key_range ParseKeyFilteredQuery filters orders key_range.Remap lambda x _PropertyKeyToString x '' if query.has_ancestor ancestor datastore_types.Key._FromPb query.ancestor ancestor_kind ancestor_property _PropertyKeyToString ancestor None if ancestor_property is not None key_range.Update datastore_pb.Query_Filter.EQUAL ancestor_kind ancestor_property else key_range.Update datastore_pb.Query_Filter.GREATER_THAN_OR_EQUAL ancestor_kind '' key_range.Update datastore_pb.Query_Filter.LESS_THAN_OR_EQUAL ancestor_kind + '\x00' '' query.clear_ancestor return key_range
def fix_lib64 lib_dir symlink True if [p for p in distutils.sysconfig.get_config_vars .values if isinstance p basestring and 'lib64' in p ] if is_pypy logger.debug 'PyPydetected skippinglib64symlinking' returnlogger.debug 'Thissystemuseslib64;symlinkinglib64tolib' assert os.path.basename lib_dir 'python%s' % sys.version[ 3] 'Unexpectedpythonlibdir %r' % lib_dir lib_parent os.path.dirname lib_dir top_level os.path.dirname lib_parent lib_dir os.path.join top_level 'lib' lib64_link os.path.join top_level 'lib64' assert os.path.basename lib_parent 'lib' 'Unexpectedparentdir %r' % lib_parent if os.path.lexists lib64_link returncp_or_ln os.symlink if symlink else copyfile cp_or_ln 'lib' lib64_link
def handle_copy_source_param params **kwargs source params.get 'CopySource' if source is None returnif isinstance source six.string_types params['CopySource'] _quote_source_header source elif isinstance source dict params['CopySource'] _quote_source_header_from_dict source
def to_spacecase string string re.sub ' _ ' '' string string re.sub '^ \\s* . ' lambda match match.group 2 .upper string string re.sub ' \\s* $' '' string string re.sub ' ?< [^\\s] \\s+ [^\\s] ' lambda match '' + match.group 1 .upper string return re.sub ' ?< [^\\s] [A-Z] ' lambda match '' + match.group 1 string
def _json_drives game home_team data drive_nums []for drive_num in data try drive_nums.append int drive_num except passdrives []for i drive_num in enumerate sorted drive_nums 1 d Drive game i home_team data[str drive_num ] if not hasattr d 'game' continuedrives.append d return drives
def source_estimate_quantification stc1 stc2 metric 'rms' known_metrics ['rms' 'cosine']if metric not in known_metrics raise ValueError 'metricmustbeastrfromtheknownmetrics "rms"or"cosine"' _check_stc stc1 stc2 data1 data2 stc1.data stc2.data if metric 'rms' score np.sqrt np.mean data1 - data2 ** 2 elif metric 'cosine' score 1.0 - np.dot data1.flatten data2.flatten / norm data1 * norm data2 return score
def PathHasDriveLetter path return path[1 2] ' '
def genops pickle import cStringIO as StringIOif isinstance pickle str pickle StringIO.StringIO pickle if hasattr pickle 'tell' getpos pickle.tellelse getpos lambda None while True pos getpos code pickle.read 1 opcode code2op.get code if opcode is None if code '' raise ValueError 'pickleexhaustedbeforeseeingSTOP' else raise ValueError 'atposition%s opcode%runknown' % pos is None and '<unknown>' or pos code if opcode.arg is None arg Noneelse arg opcode.arg.reader pickle yield opcode arg pos if code '.' assert opcode.name 'STOP' break
def make_carousel_thumbs app exception if exception is not None returnprint 'Preparingcarouselimages' image_dir os.path.join app.builder.outdir '_images' for glr_plot max_width in carousel_thumbs.items image os.path.join image_dir glr_plot if os.path.exists image c_thumb os.path.join image_dir glr_plot[ -4 ] + '_carousel.png' sphinx_gallery.gen_rst.scale_image image c_thumb max_width 190
def validate_document_class option value if not issubclass value collections.MutableMapping RawBSONDocument raise TypeError '%smustbedict bson.son.SON bson.raw_bson.RawBSONDocument orasublassofcollections.MutableMapping' % option return value
def page_name app None if app return _ u'Add-onsfor{0}' .format app.pretty else return _ 'Add-ons'
def sort_seqs_by_clustersize seqs mapping ids []seqs_cache {}for header seq in seqs id header.split '|' [0]id id.rstrip '' ids.append id seqs_cache[id] header seq for id in sort_ids ids mapping yield seqs_cache[id]
def get_dhcp_leases context network_ref hosts []host Noneif network_ref['multi_host'] host CONF.hostfor data in db.network_get_associated_fixed_ips context network_ref['id'] host host if data['allocated'] and data['leased'] hosts.append _host_lease data return '\n'.join hosts
@utils.arg 'backup' metavar '<backup>' help 'IDofthebackuptodelete.' @utils.service_type 'monitor' def do_backup_delete cs args backup _find_backup cs args.backup backup.delete
def predictNOE peaklist originNuc detectedNuc originResNum toResNum returnLine ''datamap _data_map peaklist.datalabels originAssCol datamap[ originNuc + '.L' ] + 1 originPPMCol datamap[ originNuc + '.P' ] + 1 detectedPPMCol datamap[ detectedNuc + '.P' ] + 1 if str toResNum in peaklist.residue_dict detectedNuc and str originResNum in peaklist.residue_dict detectedNuc detectedList peaklist.residue_dict detectedNuc [str toResNum ]originList peaklist.residue_dict detectedNuc [str originResNum ]returnLine detectedList[0]for line in detectedList aveDetectedPPM _col_ave detectedList detectedPPMCol aveOriginPPM _col_ave originList originPPMCol originAss originList[0].split [originAssCol]returnLine xpktools.replace_entry returnLine originAssCol + 1 originAss returnLine xpktools.replace_entry returnLine originPPMCol + 1 aveOriginPPM return returnLine
def mounts cmd 'mount'ret {}out __salt__['cmd.run_all'] cmd output out['stdout'].splitlines for line in output if not line continueif 'fuse.mfs' in line comps line.split '' info1 comps[0].split ' ' info2 info1[1].split '/' ret[comps[2]] {'remote' {'master' info1[0] 'port' info2[0] 'subfolder' '/' + info2[1] } 'local' comps[2] 'options' comps[5].replace ' ' '' .replace ' ' '' .split ' ' }return ret
def addLoop infillWidth infillPaths loop rotationPlaneAngle simplifiedLoop euclidean.getSimplifiedLoop loop infillWidth if len simplifiedLoop < 2 returnsimplifiedLoop.append simplifiedLoop[0] planeRotated euclidean.getPointsRoundZAxis rotationPlaneAngle simplifiedLoop infillPaths.append planeRotated
def _compare_to_remote remote local_branch remote_branch None remote_branch remote_branch if remote_branch else local_branch git_remote '%s/%s' % remote remote_branch return _git_diff_name_status git_remote local_branch
def where cond a b raise_on_error False use_numexpr True if use_numexpr return _where cond a b raise_on_error raise_on_error return _where_standard cond a b raise_on_error raise_on_error
def _cast_y_axis_extrema y_axis_extrema try y_axis_extrema float y_axis_extrema except ValueError if y_axis_extrema 'auto' y_axis_extrema Noneelse raise ValueError "Theminandmaxy-axisvaluesmustbenumbersor'auto'.Couldn'thandlethevalue%r." % y_axis_extrema return y_axis_extrema
def combine_local_envs *envs return _combine_envs_helper envs local True
def add_blank_choice choices return None '---------' + tuple choices
def sanitize_release_group string if string is None returnstring re.sub '\\[\\w+\\]' '' string return string.strip .upper
def wrapper ruby_string wrapper_prefix runas None *binaries cmd ['wrapper' ruby_string wrapper_prefix]cmd.extend binaries return _rvm cmd runas runas
def TimestampFromTicks ticks return Timestamp *time.localtime ticks [ 6]
def sites_for_org try org request.args[0]except result current.xml.json_message False 400 'NoOrgprovided!' else try org int org except result current.xml.json_message False 400 'InvalidOrgprovided!' else stable s3db.org_siteif settings.get_org_branches btable s3db.org_organisation_branchquery btable.organisation_id org & btable.deleted ! True rows db query .select btable.branch_id org_ids [row.branch_id for row in rows] + [org] query stable.organisation_id.belongs org_ids & stable.deleted ! True else query stable.organisation_id org & stable.deleted ! True rows db query .select stable.site_id stable.name orderby stable.name result rows.json finally response.headers['Content-Type'] 'application/json'return result
def _get_info_from_memcache app env account container None cache_key get_cache_key account container memcache getattr app 'memcache' None or env.get 'swift.cache' if memcache info memcache.get cache_key if info for key in info if isinstance info[key] six.text_type info[key] info[key].encode 'utf-8' elif isinstance info[key] dict for subkey value in info[key].items if isinstance value six.text_type info[key][subkey] value.encode 'utf-8' env.setdefault 'swift.infocache' {} [cache_key] inforeturn inforeturn None
def core_helper f name None def _get_name func_or_class try return func_or_class.__name__except AttributeError return func_or_class.__class__.__name___builtin_functions[ name or _get_name f ] freturn f
def validate_num_values vals default None cast_to int based_on min num_values len vals if num_values 0 return defaultif num_values > 1 if based_on min LOG.info _LI '% num_values dvaluesfound ofwhichtheminimumvaluewillbeused.' {'num_values' num_values} else LOG.info _LI '% num_values dvaluesfound ofwhichthemaximumvaluewillbeused.' {'num_values' num_values} return based_on [cast_to val for val in vals]
def streq_const_time s1 s2 if len s1 ! len s2 return Falseresult 0for a b in zip s1 s2 result | ord a ^ ord b return result 0
def get_primary_key model mapper model._sa_class_manager.mapperpks [mapper.get_property_by_column c .key for c in mapper.primary_key]if len pks 1 return pks[0]elif len pks > 1 return tuple pks else return None
def get_cashflow_data year quarter if ct._check_input year quarter is True ct._write_head df _get_cashflow_data year quarter 1 pd.DataFrame if df is not None df['code'] df['code'].map lambda x str x .zfill 6 return df
def _comment_directive block location next_entry block[ location + 1 ] if location + 1 < len block else None if isinstance next_entry list and next_entry if len next_entry > 2 and next_entry[ -2 ] '#' and COMMENT in next_entry[ -1 ] returnelif isinstance next_entry nginxparser.UnspacedList next_entry next_entry.spaced[0]else next_entry next_entry[0]block.insert location + 1 COMMENT_BLOCK[ ] if next_entry is not None and '\n' not in next_entry block.insert location + 2 '\n'
def test_creds_not_found assert_equal find_credentials {'foo' 'bar'} None None
def mkdir_p dir if not dir returnif dir.endswith '/' or dir.endswith '\\' mkdir_p dir[ -1 ] returnif os.path.isdir dir returnmkdir_p os.path.dirname dir try os.mkdir dir except Exception pass
def load_inventory preferred_path None default_inv None inventory file_loaded load_from_json INVENTORY_FILENAME preferred_path raise_if_missing False if file_loaded is not False load_path os.path.dirname file_loaded else load_path dir_find preferred_path if inventory is not False logger.debug 'Loadedexistinginventoryfrom{}'.format file_loaded _make_backup load_path file_loaded else logger.debug 'Noexistinginventory createdfreshskeleton.' inventory copy.deepcopy default_inv return inventory load_path
def swapon name priority None ret {}on_ swaps if name in on_ ret['stats'] on_[name]ret['new'] Falsereturn retif __grains__['kernel'] 'SunOS' if __grains__['virtual'] ! 'zone' __salt__['cmd.run'] 'swap-a{0}'.format name python_shell False else return Falseelse cmd 'swapon{0}'.format name if priority cmd + '-p{0}'.format priority __salt__['cmd.run'] cmd python_shell False on_ swaps if name in on_ ret['stats'] on_[name]ret['new'] Truereturn retreturn ret
def convDown hidSums filters targets numModulesX paddingStart moduleStride filterSizeX imSizeX numImgColors numGroups 1numFilters filters.shape[0]numImages hidSums.shape[0]numModules numModulesX ** 2 assert paddingStart > 0 assert targets.shape numImages numImgColors * imSizeX * imSizeX _ConvNet.convDown hidSums.p_mat filters.p_mat targets.p_mat imSizeX - paddingStart moduleStride numImgColors numGroups
def _rollout env timestep_limit None count 0episode_state 'resetting'while True obs reward done info env.step [] count + 1if episode_state 'resetting' if done is None assert obs is None continueelif done is False episode_state 'running'if episode_state 'running' assert done is False assert isinstance reward float assert isinstance done bool 'Receiveddone Nonebeforedone True'if obs is not None assert obs['vision'].shape 768 1024 3 breakif timestep_limit is not None and count > timestep_limit assert episode_state 'running' 'Failedtofinishresettingintimesteplimit'break
def PrepareSpecialPropertiesForStore entity_proto _PrepareSpecialProperties entity_proto False
def xypic_draw_diagram diagram masked None diagram_format '' groups None **hints grid DiagramGrid diagram groups **hints drawer XypicDiagramDrawer return drawer.draw diagram grid masked diagram_format
def formstyle_ul form fields table UL for id label controls help in fields _help DIV help _class 'w2p_fc' _controls DIV controls _class 'w2p_fw' _label DIV label _class 'w2p_fl' table.append LI _label _controls _help _id id return table
def _has_value tagtype value if tagtype in tagtype_list.TAGTYPE_LIST return bool value return True
def get_lms_link_for_about_page course_key assert isinstance course_key CourseKey if settings.FEATURES.get 'ENABLE_MKTG_SITE' about_base settings.MKTG_URLS['ROOT']else about_base settings.LMS_ROOT_URLreturn u'{about_base_url}/courses/{course_key}/about'.format about_base_url about_base course_key course_key.to_deprecated_string
def is_tag_mutable context tag if context.is_admin return Trueif context.owner is None return Falsereturn tag.namespace.owner context.owner
def ImportStateName state return {STATE_READ 'READ' STATE_GETTING 'SENDING' STATE_GOT 'SENT' STATE_NOT_SENT 'NOT_SENT'}[state]
def calcResponse HA1 HA2 algo pszNonce pszNonceCount pszCNonce pszQop m algorithms[algo] m.update HA1 m.update ' ' m.update pszNonce m.update ' ' if pszNonceCount and pszCNonce m.update pszNonceCount m.update ' ' m.update pszCNonce m.update ' ' m.update pszQop m.update ' ' m.update HA2 respHash hexlify m.digest return respHash
def _yum_pkginfo output cur {}keys itertools.cycle 'name' 'version' 'repoid' values salt.utils.itertools.split _strip_headers output osarch __grains__['osarch']for key value in zip keys values if key 'name' try cur['name'] cur['arch'] value.rsplit '.' 1 except ValueError cur['name'] valuecur['arch'] osarchcur['name'] salt.utils.pkg.rpm.resolve_name cur['name'] cur['arch'] osarch else if key 'version' value value.rstrip '-' elif key 'repoid' value value.lstrip '@' cur[key] valueif key 'repoid' pkginfo salt.utils.pkg.rpm.pkginfo **cur cur {}if pkginfo is not None yield pkginfo
def test_dnn_tag x T.ftensor4 old theano.config.on_opt_errortheano.config.on_opt_error 'raise'sio StringIO handler logging.StreamHandler sio logging.getLogger 'theano.compile.tests.test_dnn' .addHandler handler logging.getLogger 'theano' .removeHandler theano.logging_default_handler raised Falsetry f theano.function [x] pool_2d x ws 2 2 ignore_border True mode mode_with_gpu.including 'cudnn' except AssertionError RuntimeError assert not cuda.dnn.dnn_available raised Truefinally theano.config.on_opt_error oldlogging.getLogger 'theano.compile.tests.test_dnn' .removeHandler handler logging.getLogger 'theano' .addHandler theano.logging_default_handler if not raised assert cuda.dnn.dnn_available assert any [isinstance n.op cuda.dnn.GpuDnnPool for n in f.maker.fgraph.toposort ]
@_uniquedef uninstallation_paths dist r csv.reader FakeFile dist.get_metadata_lines 'RECORD' for row in r path os.path.join dist.location row[0] yield path if path.endswith '.py' dn fn os.path.split path base fn[ -3 ]path os.path.join dn base + '.pyc' yield path
@api_wrapperdef update_export module export filesystem system changed Falsename module.params['name']client_list module.params['client_list']if export is None if not module.check_mode export system.exports.create export_path name filesystem filesystem if client_list export.update_permissions client_list changed Trueelif client_list if set map transform unmunchify export.get_permissions ! set map transform client_list if not module.check_mode export.update_permissions client_list changed Truemodule.exit_json changed changed
@receiver USER_FIELD_CHANGED def email_marketing_user_field_changed sender user None table None setting None old_value None new_value None **kwargs if user.is_anonymous returnif table ! 'auth_user' and table ! 'auth_userprofile' returnif setting in CHANGED_FIELDNAMES email_config EmailMarketingConfiguration.current if not email_config.enabled returnupdate_user.delay _create_sailthru_user_vars user user.profile user.email site _get_current_site new_user False activation setting 'is_active' and new_value is True elif setting 'email' email_config EmailMarketingConfiguration.current if not email_config.enabled returnupdate_user_email.delay user.email old_value
def volume_list provider client _get_client info client.extra_action action 'volume_list' provider provider names 'name' return info['name']
def clean_args args for arg in args.keys if not args[arg] del args[arg]return args
def _qemu_image_info path ret {}out __salt__['cmd.run'] 'qemu-imginfo{0}'.format path match_map {'size' 'virtualsize \\w+\\ \\d+ byte[s]?\\ ' 'format' 'fileformat \\w+ '}for info search in six.iteritems match_map try ret[info] re.search search out .group 1 except AttributeError continuereturn ret
@with_setup state.setup state.teardown def test_subunit_output_with_tags state.expect [Includes {'status' 'success' 'tags' set ['slow-ish'] } Includes {'status' 'success' 'tags' set ['fast-ish'] } Includes {'status' 'success' 'tags' set } Includes {'status' 'success' 'tags' set } ]runner Runner feature_name 'tagged_features' enable_subunit True runner.run
def get_recipients doc fetched_from_email_account False recipients split_emails doc.recipients if recipients recipients filter_email_list doc recipients [] return recipients
def reset_defaults mpl.rcParams.update mpl.rcParamsDefault
def _has_access_string user action perm def check_staff '\nChecksforstaffaccess\n'if perm ! 'global' debug "Deny invalidpermission'%s'" perm return ACCESS_DENIEDreturn ACCESS_GRANTED if GlobalStaff .has_user user else ACCESS_DENIED def check_support 'CheckthattheuserhasaccesstothesupportUI.'if perm ! 'global' return ACCESS_DENIEDreturn ACCESS_GRANTED if GlobalStaff .has_user user or SupportStaffRole .has_user user else ACCESS_DENIED checkers {'staff' check_staff 'support' check_support 'certificates' check_support}return _dispatch checkers action user perm
def _stringify_args args new_args []for item in args if isinstance item int long new_args.append '%#lx' % item else new_args.append str item return new_args
def nearest_workday dt if dt.weekday 5 return dt - timedelta 1 elif dt.weekday 6 return dt + timedelta 1 return dt
def build_config_from_file module data []module frappe.scrub module for app in frappe.get_installed_apps try data + get_config app module except ImportError passreturn data
@receiver post_delete sender Suggestion @receiver post_save sender Suggestion def update_suggestion_flag sender instance **kwargs for unit in get_related_units instance unit.update_has_suggestion
def test_multiple assert hug.types.multiple 'value' ['value'] assert hug.types.multiple ['value1' 'value2'] ['value1' 'value2']
def filter_nonzero data combine None nz_feats nonzero_features data combine return [set[ nz_feats] for set in data]
def Degree degrees return math.pi * degrees / 180.0
def _create_email_user_param sailthru_vars sailthru_client email new_user email_config site None sailthru_user {'id' email 'key' 'email'}sailthru_user['vars'] dict sailthru_vars last_changed_time int time.time if new_user list_name _get_or_create_user_list_for_site sailthru_client site site default_list_name email_config.sailthru_new_user_list sailthru_user['lists'] {list_name 1} if list_name else {email_config.sailthru_new_user_list 1} return sailthru_user
@handle_response_format@treeio_login_required@_process_mass_formdef index request response_format 'html' if request.GET query _get_filter_query request.GET contacts Object.filter_by_request request Contact.objects.filter query .order_by 'name' else contacts Object.filter_by_request request Contact.objects.order_by 'name' filters FilterForm request.user.profile 'name' request.GET context _get_default_context request context.update {'contacts' contacts 'filters' filters} return render_to_response 'identities/index' context context_instance RequestContext request response_format response_format
@register u'menu-complete' def menu_complete event generate_completions event
def service_highstate requires True ret {}running running_service_owners for service in running ret[service] {'service' ['running']}if requires ret[service]['service'].append {'require' {'pkg' running[service]}} enabled enabled_service_owners for service in enabled if service in ret ret[service]['service'].append {'enabled' True} else ret[service] {'service' [{'enabled' True}]}if requires exists Falsefor item in ret[service]['service'] if isinstance item dict and next six.iterkeys item 'require' exists Trueif not exists ret[service]['service'].append {'require' {'pkg' enabled[service]}} return ret
def check_segments coll positions linelength lineoffset orientation segments coll.get_segments if orientation.lower u'horizontal' or orientation.lower u'none' or orientation is None pos1 1pos2 0elif orientation.lower u'vertical' pos1 0pos2 1else raise ValueError u"orientationmustbe'horizontal'or'vertical'" for i segment in enumerate segments assert_equal segment[ 0 pos1 ] lineoffset + linelength / 2.0 assert_equal segment[ 1 pos1 ] lineoffset - linelength / 2.0 assert_equal segment[ 0 pos2 ] positions[i] assert_equal segment[ 1 pos2 ] positions[i]
@njitdef _repeat_1d x K out N x.shape[0]L out.shape[0] // K * N for n in range N val x[n]for k in range K for l in range L ind k * N * L + n * L + l out[ind] val
@pytest.mark.parametrize 'store_cookies empty' [ True False False True ] def test_cookies_changed config_stub fake_save_manager monkeypatch qtbot store_cookies empty config_stub.data CONFIG_COOKIES_ENABLEDmonkeypatch.setattr lineparser 'LineParser' LineparserSaveStub jar cookies.CookieJar jar._lineparser.data [COOKIE1 COOKIE2]jar.parse_cookies config_stub.set 'content' 'cookies-store' store_cookies if empty assert not jar._lineparser.data assert not jar._lineparser.saved else assert jar._lineparser.data
def anonymous_id_for_user user course_id save True if user.is_anonymous return Nonecached_id getattr user '_anonymous_id' {} .get course_id if cached_id is not None return cached_idhasher hashlib.md5 hasher.update settings.SECRET_KEY hasher.update unicode user.id if course_id hasher.update unicode course_id .encode 'utf-8' digest hasher.hexdigest if not hasattr user '_anonymous_id' user._anonymous_id {}user._anonymous_id[course_id] digestif save is False return digesttry AnonymousUserId.objects.get_or_create user user course_id course_id anonymous_user_id digest except IntegrityError passreturn digest
def strip_xmlns element xmlns element.tag element.tag.replace '{' + xmlns + '}' '' for cur_child in element.getchildren strip_xmlns cur_child xmlns return element
def _GetOutputTargetExt spec target_extension spec.get 'product_extension' if target_extension return '.' + target_extension return None
def print_ccode expr **settings print ccode expr **settings
def replace_prefix path p1 p2 common_prefix os.path.commonprefix [path p1] if common_prefix assert path.find common_prefix 0 path path[ len common_prefix + 1 ]return os.path.join p2 path
def _element_to_dict data position obj_end opts element_type data[position position + 1 ]position + 1 element_name position _get_c_string data position opts try value position _ELEMENT_GETTER[element_type] data position obj_end opts element_name except KeyError _raise_unknown_type element_type element_name return element_name value position
def encode_as_multipart multipart_container boundary v_vars v_files _split_vars_files multipart_container _ data multipart_encode v_vars v_files boundary boundary return data
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def translate_mixed_exceptions method def wrapper self ctx res_id *args **kwargs try res method self ctx res_id *args **kwargs except keystone_exception.NotFound cinder_exception.NotFound _reraise exception.VolumeNotFound volume_id res_id except cinder_exception.OverLimit _reraise exception.OverQuota overs 'snapshots' return resreturn translate_cinder_exception wrapper
def _sorted_edge u v return u v if u < v else v u
def cc_stats x1 x2 demean True nobs1 k1 x1.shape nobs2 k2 x2.shapecc cancorr x1 x2 demean demean cc2 cc ** 2 lam cc2 / 1 - cc2 df_model k1 * k2 df_resid k1 * nobs1 - k2 - demean s min df_model k1 m 0.5 * df_model - k1 n 0.5 * df_resid - k1 - 1 df1 k1 * df_model df2 k2pt_value cc2.sum wl_value np.product 1 / 1 + lam ht_value lam.sum rm_value lam.max res {}res['canonicalcorrelationcoefficient'] ccres['eigenvalues'] lamres["Pillai'sTrace"] pt_valueres["Wilk'sLambda"] wl_valueres["Hotelling'sTrace"] ht_valueres["Roy'sLargestRoot"] rm_valueres['df_resid'] df_residres['df_m'] mreturn res
@partial.partialdef login_analytics strategy auth_entry *args **kwargs event_name Noneif auth_entry AUTH_ENTRY_LOGIN event_name 'edx.bi.user.account.authenticated'elif auth_entry in [AUTH_ENTRY_ACCOUNT_SETTINGS] event_name 'edx.bi.user.account.linked'if event_name is not None and hasattr settings 'LMS_SEGMENT_KEY' and settings.LMS_SEGMENT_KEY tracking_context tracker.get_tracker .resolve_context analytics.track kwargs['user'].id event_name {'category' 'conversion' 'label' None 'provider' kwargs['backend'].name} context {'ip' tracking_context.get 'ip' 'GoogleAnalytics' {'clientId' tracking_context.get 'client_id' }}
def create_game_directory dirname global GAMEDIRGAMEDIR os.path.abspath os.path.join CURRENT_DIR dirname if os.path.exists GAMEDIR print "CannotcreatenewEvenniagamedir '%s'alreadyexists." % dirname sys.exit shutil.copytree EVENNIA_TEMPLATE GAMEDIR create_settings_file
@deprecated 'relabel_sequential' def relabel_from_one label_field return relabel_sequential label_field offset 1
def _nssplit qualifiedName fields qualifiedName.split ' ' 1 if len fields 2 return fieldselse return None fields[0]
def _flatten_code code flat_code []for c in code flat_code.extend c return flat_code
def create_new_user server email password secret appscale_info.get_secret ret server.commit_new_user email password 'user' secret return not ret.startswith 'Error '
@_ConfigurableFilter executable 'OPTIPNG_EXECUTABLE' def optipng infile executable 'optiong' return runinplace '{}-preserve-o2-quiet%1'.format executable infile
def matchTypes accept_types have_types if not accept_types default 1else default 0match_main {}match_sub {}for main sub q in accept_types if main '*' default max default q continueelif sub '*' match_main[main] max match_main.get main 0 q else match_sub[ main sub ] max match_sub.get main sub 0 q accepted_list []order_maintainer 0for mtype in have_types main sub mtype.split '/' if main sub in match_sub q match_sub[ main sub ]else q match_main.get main default if q accepted_list.append 1 - q order_maintainer q mtype order_maintainer + 1accepted_list.sort return [ mtype q for _ _ q mtype in accepted_list]
def access_log request msg None level None if level is None level logging.INFOai AccessInfo request ai.log level msg
def walkQObjectTree obj counts None verbose False depth 0 if verbose print '' * depth + typeStr obj report Falseif counts is None counts {}report Truetyp str type obj try counts[typ] + 1except KeyError counts[typ] 1for child in obj.children walkQObjectTree child counts verbose depth + 1 return counts
def get_available_slug title new_slug None slug new_slug or title.slug title.slug slugtitle.update_path path title.pathif not is_valid_page_slug title.page title.page.parent title.language slug title.page.site path match COPY_SLUG_REGEX.match slug if match try next_id int match.groups [0] + 1 slug '-'.join slug.split '-' [ -1 ] + '-%d' % next_id except TypeError slug + '-2'else slug + APPEND_TO_SLUGreturn get_available_slug title slug else return slug
@ioflo.base.deeding.deedify 'SaltRaetReactorFork' ioinits {'opts' '.salt.opts' 'proc_mgr' '.salt.usr.proc_mgr'} def reactor_fork self self.proc_mgr.value.add_process salt.utils.reactor.Reactor args self.opts.value
def getSceneSeasons indexer_id cache_db_con db.DBConnection 'cache.db' seasons cache_db_con.select 'SELECTDISTINCTseasonFROMscene_exceptionsWHEREindexer_id ?' [indexer_id] return [cur_exception['season'] for cur_exception in seasons]
def mapcat func seqs return concat map func seqs
def comports return list iterate_comports
@jitdef simulate_linear_model A x0 v ts_length A np.asarray A n A.shape[0]x np.empty n ts_length x[ 0] x0for t in range ts_length - 1 for i in range n x[ i t + 1 ] v[ i t ]for j in range n x[ i t + 1 ] + A[ i j ] * x[ j t ] return x
def find_end_of_attribute block offset block boundary next_attr_boundary block offset if block is None or boundary is None return None None if boundary.type is not ATTR_VALUE or boundary.data is not ATTR_END return None None return block boundary.offset
def task_enable_flocker_agent distribution action 'start' validate_start_action action if is_systemd_distribution distribution return sequence [run_from_args ['systemctl' 'enable' 'flocker-dataset-agent'] run_from_args ['systemctl' action.lower 'flocker-dataset-agent'] ] elif is_ubuntu distribution return sequence [run_from_args ['service' 'flocker-dataset-agent' action.lower ] ] else raise DistributionNotSupported distribution distribution
def TRANS p global gTABLE_850_LATINif sabnzbd.WIN32 return p.translate gTABLE_850_LATIN .decode 'cp1252' 'replace' else return unicoder p
def order_history user **kwargs course_org_filter kwargs['course_org_filter'] if 'course_org_filter' in kwargs else None org_filter_out_set kwargs['org_filter_out_set'] if 'org_filter_out_set' in kwargs else [] order_history_list []purchased_order_items OrderItem.objects.filter user user status 'purchased' .select_subclasses .order_by '-fulfilled_time' for order_item in purchased_order_items if order_item.order.id not in [item['order_id'] for item in order_history_list] order_item_course_id getattr order_item 'course_id' None if order_item_course_id if course_org_filter and course_org_filter order_item_course_id.org or course_org_filter is None and order_item_course_id.org not in org_filter_out_set order_history_list.append {'order_id' order_item.order.id 'receipt_url' reverse 'shoppingcart.views.show_receipt' kwargs {'ordernum' order_item.order.id} 'order_date' ModuleI18nService .strftime order_item.order.purchase_time 'SHORT_DATE' } return order_history_list
def subs_filename subs_id lang 'en' if lang 'en' return u'subs_{0}.srt.sjson'.format subs_id else return u'{0}_subs_{1}.srt.sjson'.format lang subs_id
def trainRandomForest features n_estimators [X Y] listOfFeatures2Matrix features rf sklearn.ensemble.RandomForestClassifier n_estimators n_estimators rf.fit X Y return rf
def handle text mic profile messages ["I'msorry couldyourepeatthat?" 'Myapologies couldyoutrysayingthatagain?' 'Saythatagain?' 'Ibegyourpardon?']message random.choice messages mic.say message
def media_next_track hass hass.services.call DOMAIN SERVICE_MEDIA_NEXT_TRACK
def xen_cpu name global connglobal conn_inforeturn conn_info[2]
def test_stockwell_st_no_zero_pad data np.zeros 20 128 start_f 1stop_f 10sfreq 30width 2W _precompute_st_windows data.shape[ -1 ] start_f stop_f sfreq width _st_power_itc data 10 True 0 1 W
def get_sha256_str base_str if isinstance base_str six.text_type base_str base_str.encode 'utf-8' return hashlib.sha256 base_str .hexdigest
def _reserve_task course_id task_type task_key task_input requester if _task_is_running course_id task_type task_key log.warning 'Duplicatetaskfoundfortask_type%sandtask_key%s' task_type task_key raise AlreadyRunningError 'requestedtaskisalreadyrunning' try most_recent_id InstructorTask.objects.latest 'id' .idexcept InstructorTask.DoesNotExist most_recent_id 'Nonefound'finally log.warning 'Noduplicatetasksfound task_type%s task_key%s andmostrecenttask_id %s' task_type task_key most_recent_id return InstructorTask.create course_id task_type task_key task_input requester
def create_basic_xml_info readname fname to_print ['<trace>\n']to_print.append '<trace_name>' to_print.append readname to_print.append '</trace_name>\n' info Noneif config['xml_info'] if fname in config['xml_info'] info config['xml_info'][fname]else try info config['xml_info'][fake_sff_name]except KeyError passif info for key in info to_print.append '<' + key + '>' + info[key] + '</' + key + '>\n' return ''.join to_print
def get_registered_canvas_class format if format not in _default_backends return Nonebackend_class _default_backends[format]if cbook.is_string_like backend_class backend_class importlib.import_module backend_class .FigureCanvas_default_backends[format] backend_classreturn backend_class
def scroll_half_page_down event scroll_forward event half True
def get_collection_sample collection_type datatype if collection_type 'list' return [get_sample datatype get_sample datatype ]elif collection_type 'set' return sortedset [get_sample datatype ] elif collection_type 'map' return OrderedMap [ get_sample datatype get_sample datatype ] elif collection_type 'tuple' return get_sample datatype else raise Exception 'Missinghandlingofnon-primitivetype{0}.'.format collection_type
def fresnelc_zeros nt if floor nt ! nt or nt < 0 or not isscalar nt raise ValueError 'Argumentmustbepositivescalarinteger.' return specfun.fcszo 1 nt
def show_account account_id None email None directory_id None application_id None group_id None **kwargs if account_id status result _query action 'accounts' command account_id return resultif email if not directory_id and not application_id and not group_id return {'Error' 'Eitheradirectory_id application_id orgroup_idmustbespecifiedwithanemailaddress'}if directory_id status result _query action 'directories' command '{0}/accounts'.format directory_id args {'email' email} elif application_id status result _query action 'applications' command '{0}/accounts'.format application_id args {'email' email} elif group_id status result _query action 'groups' command '{0}/accounts'.format group_id args {'email' email} return result
@login_required@require_http_methods ['GET' 'POST'] def remove_contributor request document_slug user_id document get_object_or_404 Document locale request.LANGUAGE_CODE slug document_slug if not document.allows request.user 'edit' raise PermissionDenieduser get_object_or_404 User id user_id if request.method 'POST' document.contributors.remove user msg _ '{user}removedfromthecontributorssuccessfully!' .format user user.username messages.add_message request messages.SUCCESS msg return HttpResponseRedirect reverse 'wiki.document_revisions' args [document_slug] return render request 'wiki/confirm_remove_contributor.html' {'document' document 'contributor' user}
def group seq multiple True if not seq return [] current groups [seq[0]] [] for elem in seq[1 ] if elem current[ -1 ] current.append elem else groups.append current current [elem]groups.append current if multiple return groupsfor i current in enumerate groups groups[i] current[0] len current return groups
def pstats2entries data entries dict allcallers dict for code_info call_info in data.stats.items code Code code.co_filename code.co_firstlineno code.co_name code_info cc nc tt ct callers call_infoentry Entry entry.code codeentry.callcount ccentry.reccallcount nc - cc entry.inlinetime ttentry.totaltime ctentry.calls list entries[code_info] entryallcallers[code_info] callers.items for entry in entries.itervalues entry_label cProfile.label entry.code entry_callers allcallers.get entry_label [] for entry_caller call_info in entry_callers entries[entry_caller].calls.append entry call_info return entries.values
def shortest_path_length creation_sequence i first creation_sequence[0]if isinstance first str if isinstance creation_sequence list cs creation_sequence[ ]else cs list creation_sequence elif isinstance first tuple cs [v[1] for v in creation_sequence]i [v[0] for v in creation_sequence].index i elif isinstance first int cs uncompact creation_sequence else raise TypeError 'Notavalidcreationsequencetype' N len cs spl [2] * N spl[i] 0for j in range i + 1 N if cs[j] 'd' spl[j] 1if cs[i] 'd' for j in range i spl[j] 1for j in range N - 1 0 -1 if cs[j] 'd' breakspl[j] -1 return spl
def test_grouping_identifier_list_subquery p sqlparse.parse 'select*from selecta b+casdfromtable sub' [0]subquery p.tokens[ -1 ].tokens[0] idx iden_list subquery.token_next_by i sql.IdentifierList assert iden_list is not None _ ilist subquery.token_next_by i sql.Identifier idx idx assert ilist is None
@register_opt 'low_memory' @local_optimizer [GpuCAReduceCuda] def local_gpu_elemwise_careduce node if isinstance node.op GpuCAReduceCuda and node.op.pre_scalar_op is None and node.inputs[0].owner and isinstance node.inputs[0].owner.op GpuElemwise and isinstance node.inputs[0].owner.op.scalar_op scalar.basic.Sqr op node.opinp node.inputs[0].owner.inputs[0]return [gpu_ca_reduce_cuda scalar_op op.scalar_op axis op.axis reduce_mask op.reduce_mask pre_scalar_op scalar.basic.sqr inp ]
def _ReadUrlContents url req urllib2.Request url return urllib2.urlopen req .read
def selRandom individuals k return [random.choice individuals for i in xrange k ]
def set_session_view request request.session['session_var'] 'YES'return HttpResponse 'set_session'
def num2strg num s str num if s.endswith '.0' s s[ -2 ]return s
def get_resource_uploader data_dict upload Nonefor plugin in plugins.PluginImplementations plugins.IUploader upload plugin.get_resource_uploader data_dict if upload is None upload ResourceUpload data_dict return upload
def define_message message_descriptor module_name class_dict {'__module__' module_name}for enum in message_descriptor.enum_types or [] enum_instance define_enum enum module_name class_dict[enum.name] enum_instancefor field in message_descriptor.fields or [] field_instance define_field field class_dict[field.name] field_instanceclass_name message_descriptor.name.encode 'utf-8' return type class_name messages.Message class_dict
def vif_details_bridge_name_handler resource event set_br_name **kwargs port kwargs['port']if 'trunk_details' in port set_br_name utils.gen_trunk_br_name port['trunk_details']['trunk_id']
@_docstring 'release-groups' browse True def browse_release_groups artist None release None release_type [] includes [] limit None offset None valid_includes VALID_BROWSE_INCLUDES['release-groups']params {'artist' artist 'release' release}return _browse_impl 'release-group' includes valid_includes limit offset params [] release_type
def get_file_logger filename level logging.INFO filepath os.path.join settings.LOG_ROOT filename handler logging.FileHandler filepath handler.setLevel level logger logging.getLogger filepath logger.addHandler handler logger.setLevel level return logger
def mnc2mc mnc wmean True n len mnc mean mnc[0]mnc [1] + list mnc mu []for n m in enumerate mnc mu.append 0 for k in range n + 1 mu[n] + -1 ** n - k * comb n k exact 1 * mnc[k] * mean ** n - k if wmean mu[1] meanreturn mu[1 ]
def parseAsPublicKey s try return parsePEMKey s public True except return parseXMLKey s public True
def addGridRow diameter gridPath loopsComplex maximumComplex rowIndex x y zigzag row []while x < maximumComplex.real point complex x y if euclidean.getIsInFilledRegion loopsComplex point row.append point x + diameter.realif zigzag and rowIndex % 2 1 row.reverse gridPath + row
def unpackage package_ return msgpack.loads package_ use_list True
def createAndStartSwarm client clientInfo '' clientKey '' params '' minimumWorkers None maximumWorkers None alreadyRunning False if minimumWorkers is None minimumWorkers Configuration.getInt 'nupic.hypersearch.minWorkersPerSwarm' if maximumWorkers is None maximumWorkers Configuration.getInt 'nupic.hypersearch.maxWorkersPerSwarm' return ClientJobsDAO.get .jobInsert client client cmdLine '$HYPERSEARCH' clientInfo clientInfo clientKey clientKey alreadyRunning alreadyRunning params params minimumWorkers minimumWorkers maximumWorkers maximumWorkers jobType ClientJobsDAO.JOB_TYPE_HS
def oo_get_hosts_from_hostvars hostvars hosts retval []for host in hosts try retval.append hostvars[host] except errors.AnsibleError passreturn retval
def imrotate arr angle interp 'bilinear' arr asarray arr func {'nearest' 0 'lanczos' 1 'bilinear' 2 'bicubic' 3 'cubic' 3}im toimage arr im im.rotate angle resample func[interp] return fromimage im
def is_complete_v1_key v1_key assert len v1_key.path > 1 last_element v1_key.path[ len v1_key.path - 1 ]return last_element.WhichOneof 'id_type' is not None
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def _cmp_by_asn local_asn path1 path2 def get_path_source_asn path asn Noneif path.source is None asn local_asnelse asn path.source.remote_asreturn asnp1_asn get_path_source_asn path1 p2_asn get_path_source_asn path2 if p1_asn local_asn and p2_asn ! local_asn return path2if p2_asn local_asn and p1_asn ! local_asn return path1return None
@click.command u'use' @click.argument u'site' def _use site sites_path u'.' use site sites_path sites_path
def _region region return '--region{r}'.format r region
def filter_none **kwargs return dict k v for k v in six.iteritems kwargs if v is not None
def test_userdata objects userdata_items [item.user_data for item in ITEMS]assert userdata_items objects.user_data
def is_owner_user id user conferences get_memcached get_key 'conferences' if conferences[id]['info']['creator'] user return Truereturn False
def get_new_and_noteworthy_nodes from osf.models import Node NodeLogtoday timezone.now last_month today - dateutil.relativedelta.relativedelta months 1 data Node.objects.filter date_created__gte last_month is_public True is_deleted False parent_nodes__isnull True nodes []for node in data unique_actions NodeLog.objects.filter node node.pk .order_by 'action' .distinct 'action' .count n {}n['unique_actions'] unique_actionsn['contributors'] [c._id for c in node.contributors]n['_id'] node._idn['title'] node.titlenodes.append n noteworthy_nodes sorted nodes key lambda node node.get 'unique_actions' reverse True [ 25]filtered_new_and_noteworthy filter_nodes noteworthy_nodes return [each['_id'] for each in filtered_new_and_noteworthy]
def _training_mode_application_calls application_calls from ..bricks import BatchNormalizationout []for app_call in application_calls assert isinstance app_call.application.brick BatchNormalization assert app_call.application.application BatchNormalization.apply if app_call.metadata.get 'training_mode' False out.append app_call return out
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def build_preprocessors md_instance **kwargs preprocessors odict.OrderedDict preprocessors[u'normalize_whitespace'] NormalizeWhitespace md_instance if md_instance.safeMode ! u'escape' preprocessors[u'html_block'] HtmlBlockPreprocessor md_instance preprocessors[u'reference'] ReferencePreprocessor md_instance return preprocessors
def brick_attach_volume_encryptor context attach_info encryption connection_info attach_info['conn']connection_info['data']['device_path'] attach_info['device']['path']encryptor brick_get_encryptor connection_info **encryption encryptor.attach_volume context **encryption
def itn n digits 8 format DEFAULT_FORMAT if 0 < n < 8 ** digits - 1 s '%0*o' % digits - 1 n + NUL else if format ! GNU_FORMAT or n > 256 ** digits - 1 raise ValueError 'overflowinnumberfield' if n < 0 n struct.unpack 'L' struct.pack 'l' n [0]s ''for i in xrange digits - 1 s chr n & 255 + s n >> 8s chr 128 + s return s
def crop x wrg hrg is_random False row_index 0 col_index 1 channel_index 2 h w x.shape[row_index] x.shape[col_index] assert h > hrg and w > wrg 'Thesizeofcroppingshouldsmallerthantheoriginalimage'if is_random h_offset int np.random.uniform 0 h - hrg - 1 w_offset int np.random.uniform 0 w - wrg - 1 return x[h_offset hrg + h_offset w_offset wrg + w_offset ]else h_offset int np.floor h - hrg / 2.0 w_offset int np.floor w - wrg / 2.0 h_end h_offset + hrg w_end w_offset + wrg return x[h_offset h_end w_offset w_end]
def GetAllResourcesSample client CreateClient for resource in client.GetAllResources PrintResource resource
def getVector3Path complexPath z 0.0 vector3Path []for complexPoint in complexPath vector3Path.append Vector3 complexPoint.real complexPoint.imag z return vector3Path
def unescapeHTMLEntities text def fixup m text m.group 0 if text[ 2] '&#' try if text[ 3] '&#x' return unichr int text[3 -1 ] 16 else return unichr int text[2 -1 ] except ValueError passelse try text unichr htmlentitydefs.name2codepoint[text[1 -1 ]] except KeyError passreturn textreturn re.sub '&#?\\w+;' fixup text
def submit_row context opts context['opts']change context['change']is_popup context['is_popup']save_as context['save_as']return {'onclick_attrib' opts.get_ordered_objects and change and 'onclick "submitOrderForm ;"' or '' 'show_delete_link' not is_popup and context['has_delete_permission'] and change or context['show_delete'] 'show_save_as_new' not is_popup and change and save_as 'show_save_and_add_another' context['has_add_permission'] and not is_popup and not save_as or context['add'] 'show_save_and_continue' not is_popup and context['has_change_permission'] 'is_popup' is_popup 'show_save' True}
def se_cov cov return np.sqrt np.diag cov
def trigger_server_restart **kwargs mark_urlconf_as_changed
def order_at a p t if a.is_zero return ooif p Poly t t return a.as_poly t .ET [0][0]power_list []p1 pr a.rem p1 tracks_power 1while r.is_zero power_list.append p1 tracks_power p1 p1 * p1 tracks_power * 2r a.rem p1 n 0product Poly 1 t while len power_list ! 0 final power_list.pop productf product * final[0] r a.rem productf if r.is_zero n + final[1]product productfreturn n
def discover_extensions version only_contrib False if not isinstance version api_versions.APIVersion version api_versions.get_api_version version if only_contrib chain _discover_via_contrib_path version else chain itertools.chain _discover_via_python_path _discover_via_contrib_path version _discover_via_entry_points return [ext.Extension name module for name module in chain]
def __parse_request_range range_header_text left Noneright Noneif not range_header_text return left right range_header_text range_header_text.strip if not range_header_text.startswith 'bytes' return left right components range_header_text.split ' ' if len components ! 2 return left right components components[1].split '-' try right int components[1] except passtry left int components[0] except passreturn left right
def get_has_cache_stats return get_memcached_hosts is not None
def get_servers req servers_service_pb.GetServersRequest resp servers_service_pb.GetServersResponse apiproxy_stub_map.MakeSyncCall 'servers' 'GetServers' req resp return list resp.server_list
def restart_with_reloader while 1 _log 'info' '*Restartingwithreloader' args [sys.executable] + sys.argv new_environ os.environ.copy new_environ['WERKZEUG_RUN_MAIN'] 'true'if os.name 'nt' for key value in new_environ.iteritems if isinstance value unicode new_environ[key] value.encode 'iso-8859-1' exit_code subprocess.call args env new_environ if exit_code ! 3 return exit_code
def test_get_words_r expected_words ['Hello' 'function' 'hello' 'name' 's' 'sprintf']assert sorted expected_words sorted get_words_by_filename 'example.R' assert sorted expected_words sorted get_words_by_content 'example.R'
def uirfftn inarray dim None shape None if dim is None dim inarray.ndimoutarray np.fft.irfftn inarray shape axes range - dim 0 return outarray * np.sqrt np.prod outarray.shape[ - dim ]
def job_get_idx_by_tag tag job job_get_by_tag tag if job is None return Nonereturn job.job_idx
def test_array_input line_builder_array assert len line_builder_array.comp_glyphs 2
def get_gs_object bucket_name path scope 'https //www.googleapis.com/auth/devstorage.read_only'url 'https //%s.commondatastorage.googleapis.com/%s' % bucket_name path auth_token _ app_identity.get_access_token scope result urlfetch.fetch url method urlfetch.GET headers {'Authorization' 'OAuth%s' % auth_token 'x-goog-api-version' '2'} if result and result.status_code 200 return result.contentraise BackupValidationException 'Requestedpathwasnotfound'
def embed_image_html image if image is None return Noneelif isinstance image PIL.Image.Image passelif isinstance image np.ndarray image PIL.Image.fromarray image else raise ValueError 'imagemustbeaPIL.Imageoranp.ndarray' fmt image.formatif not fmt fmt 'png'else fmt fmt.lower string_buf StringIO image.save string_buf format fmt data string_buf.getvalue .encode 'base64' .replace '\n' '' return 'data image/%s;base64 %s' % fmt data
def transcode text input PREFERRED_ENCODING output PREFERRED_ENCODING try return text.decode 'cp437' .encode 'cp1252' except UnicodeError try return text.decode 'cp437' .encode output except UnicodeError return text
def max_partition table schema 'default' field None filter None metastore_conn_id 'metastore_default' from airflow.hooks.hive_hooks import HiveMetastoreHookif '.' in table schema table table.split '.' hh HiveMetastoreHook metastore_conn_id metastore_conn_id return hh.max_partition schema schema table_name table field field filter filter
@click.command 'dns_multitenant' @click.argument 'state' type click.Choice ['on' 'off'] def config_dns_multitenant state state True if state 'on' else False update_config {'dns_multitenant' state}
def dynamic_loader argument **kw kw['lazy'] 'dynamic'return relationship argument **kw
def get_ha1_file_htdigest filename def get_ha1 realm username result Nonef open filename 'r' for line in f u r ha1 line.rstrip .split ' ' if u username and r realm result ha1breakf.close return resultreturn get_ha1
def _set_placeholder_cache_version placeholder lang site_id version vary_on_list None duration None from django.core.cache import cachekey _get_placeholder_cache_version_key placeholder lang site_id if not version or version < 1 version int time.time * 1000000 if vary_on_list is None vary_on_list []cache.set key version vary_on_list duration
def submit_row context opts context['opts']change context['change']is_popup context['is_popup']save_as context['save_as']return {'onclick_attrib' opts.get_ordered_objects and change and 'onclick "submitOrderForm ;"' or '' 'show_delete_link' not is_popup and context['has_delete_permission'] and change or context['show_delete'] 'show_save_as_new' not is_popup and change and save_as 'show_save_and_add_another' context['has_add_permission'] and not is_popup and not save_as or context['add'] 'show_save_and_continue' not is_popup and context['has_change_permission'] 'is_popup' is_popup 'show_save' True}
def decode_args args stdin_encoding return [ arg.decode stdin_encoding if type arg bytes else arg for arg in args]
def exp_server_version return odoo.release.version
def show_instance name call None if call ! 'action' raise SaltCloudException 'Theshow_instanceactionmustbecalledwith-aor--action.' node_id get_linode_id_from_name name node_data get_linode kwargs {'linode_id' node_id} ips get_ips node_id state int node_data['STATUS'] ret {'id' node_data['LINODEID'] 'image' node_data['DISTRIBUTIONVENDOR'] 'name' node_data['LABEL'] 'size' node_data['TOTALRAM'] 'state' _get_status_descr_by_id state 'private_ips' ips['private_ips'] 'public_ips' ips['public_ips']}return ret
def get_total_users return frappe.db.sql u'selectsum simultaneous_sessions from`tabUser`\n DCTB DCTB whereenabled 1anduser_type "SystemUser"\n DCTB DCTB andnamenotin {} '.format u' '.join [u'%s'] * len STANDARD_USERS STANDARD_USERS [0][0]
def WILLR barDs count timeperiod - 2 ** 31 return call_talib_with_hlc barDs count talib.WILLR timeperiod
def retweets string return [b for a b in TWITTER_RETWEET.findall string ]
def get_remote_branch pass
def _parse_routes iface opts opts dict k.lower v for k v in six.iteritems opts result {}if 'routes' not in opts _raise_error_routes iface 'routes' 'Listofroutes' for opt in opts result[opt] opts[opt]return result
def _drv2_moment self n *args def fun x return np.power x n * self._pmf x *args return _expect fun self.a self.b self.ppf 0.5 *args self.inc
def get_fullname user None if not user user frappe.session.userif not hasattr frappe.local u'fullnames' frappe.local.fullnames {}if not frappe.local.fullnames.get user p frappe.db.get_value u'User' user [u'first_name' u'last_name'] as_dict True if p frappe.local.fullnames[user] u''.join filter None [p.get u'first_name' p.get u'last_name' ] or user else frappe.local.fullnames[user] userreturn frappe.local.fullnames.get user
def get_flag_url comment if get_comment_app_name ! DEFAULT_COMMENTS_APP and hasattr get_comment_app 'get_flag_url' return get_comment_app .get_flag_url comment else return urlresolvers.reverse 'django.contrib.comments.views.moderation.flag' args comment.id
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def correlation_sum indicators embedding_dim if not indicators.ndim 2 raise ValueError 'Indicatorsmustbeamatrix' if not indicators.shape[0] indicators.shape[1] raise ValueError 'Indicatormatrixmustbesymmetric square ' if embedding_dim 1 indicators_joint indicatorselse corrsum indicators correlation_sum indicators embedding_dim - 1 indicators_joint indicators[1 1 ] * indicators[ -1 -1 ] nobs len indicators_joint corrsum np.mean indicators_joint[np.triu_indices nobs 1 ] return corrsum indicators_joint
def _get_vsan_eligible_disks service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_system host_ref.configManager.vsanSystemif vsan_system is None msg "VSANSystemConfigManagerisunsetforhost'{0}'.VSANconfigurationcannotbechangedwithoutaconfiguredVSANSystem.".format host_name log.debug msg ret.update {host_name {'Error' msg}} continuesuitable_disks []query vsan_system.QueryDisksForVsan for item in query if item.state 'eligible' suitable_disks.append item if not suitable_disks msg "Thehost'{0}'doesnothaveanyVSANeligibledisks.".format host_name log.warning msg ret.update {host_name {'Eligible' msg}} continuedisks _get_host_ssds host_ref + _get_host_non_ssds host_ref matching []for disk in disks for suitable_disk in suitable_disks if disk.canonicalName suitable_disk.disk.canonicalName matching.append disk ret.update {host_name {'Eligible' matching}} return ret
def to_units val spaces 0 dec_limit 2 postfix '' decimals 0if val < 0 sign '-'else sign ''val str abs val .strip n 0try val float val except return ''while val > 1023.0 and n < 5 val val / 1024.0 n n + 1 unit TAB_UNITS[n]if not unit unit '' * spaces if n > dec_limit decimals 1else decimals 0fmt '%%s%%.%sf%%s%%s' % decimals return fmt % sign val unit postfix
def get_scanner hass config info config[DOMAIN]host info.get CONF_HOST username info.get CONF_USERNAME password info.get CONF_PASSWORD port info.get CONF_PORT scanner NetgearDeviceScanner host username password port return scanner if scanner.success_init else None
def get_displayable_collection_summary_dicts_matching_ids collection_ids collection_summaries collection_services.get_collection_summaries_matching_ids collection_ids return _get_displayable_collection_summary_dicts collection_summaries
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def _removeBackrefs senderkey try signals connections[senderkey]except KeyError signals Noneelse items signals.items def allReceivers for signal set in items for item in set yield item for receiver in allReceivers _killBackref receiver senderkey
def in_train_phase x alt if learning_phase is 1 return xelif learning_phase is 0 return altx switch learning_phase x alt x._uses_learning_phase Truereturn x
@facebook_requireddef decorator_example request graph if graph return HttpResponse 'authorized' else return HttpResponse 'userdeniedorerror'
def get_messages_from_include_files app_name None messages []for file in frappe.get_hooks u'app_include_js' app_name app_name or [] + frappe.get_hooks u'web_include_js' app_name app_name or [] messages.extend get_messages_from_file os.path.join frappe.local.sites_path file return messages
def change_BACKLOG_FREQUENCY freq sickbeard.BACKLOG_FREQUENCY try_int freq sickbeard.DEFAULT_BACKLOG_FREQUENCY sickbeard.MIN_BACKLOG_FREQUENCY sickbeard.get_backlog_cycle_time if sickbeard.BACKLOG_FREQUENCY < sickbeard.MIN_BACKLOG_FREQUENCY sickbeard.BACKLOG_FREQUENCY sickbeard.MIN_BACKLOG_FREQUENCYsickbeard.backlogSearchScheduler.cycleTime datetime.timedelta minutes sickbeard.BACKLOG_FREQUENCY
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def construct **kwargs point_x kwargs.pop 'point_x' None point_y kwargs.pop 'point_y' None if 'point' in kwargs raise TypeError 'Unknownkeyword point' if None not in point_x point_y kwargs['point'] EccPoint point_x point_y eq1 pow Integer point_y 2 _curve.p x Integer point_x eq2 pow x 3 _curve.p x * -3 eq2 + xeq2 + _curve.beq2 % _curve.pif eq1 ! eq2 raise ValueError 'Thepointisnotonthecurve' d kwargs.get 'd' None if d is not None and 'point' in kwargs pub_key _curve.G * d if pub_key.x ! point_x or pub_key.y ! point_y raise ValueError 'PrivateandpublicECCkeysdonotmatch' return EccKey **kwargs
def get_markdown_element_tree markdown_html warnings.warn u'reviewboard.reviews.markdown_utils.get_markdown_element_treeisdeprecated.Pleaseusedjblets.markdown.get_markdown_element_tree.' DeprecationWarning return djblets_markdown.get_markdown_element_tree markdown_html
def xhash arr import hashlibreturn hashlib.sha1 arr .hexdigest
def hours h return h / HOURS_PER_DAY
def random_markov_chain n k None sparse False random_state None P random_stochastic_matrix n k sparse format 'csr' random_state random_state mc MarkovChain P return mc
def relative_position pos global absolute_path_lengthif absolute_path_length 0 absolute_path_length len os.path.abspath os.getcwd return pos[0].get_filenametable_entry [ absolute_path_length + 1 ] pos[1]
def isLoopIntersectingLoop loop otherLoop for pointIndex in xrange len loop pointBegin loop[pointIndex]pointEnd loop[ pointIndex + 1 % len loop ]if isLineIntersectingLoop otherLoop pointBegin pointEnd return Truereturn False
def test_cannot_start_with_multiline lines strings.get_stripped_lines INVALID_MULTI_LINE try step Step.many_from_lines lines except LettuceSyntaxError returnassert False 'LettuceSyntaxErrornotraised'
def _kernel_versions_debian kernel_get_selections __salt__['cmd.run'] 'dpkg--get-selectionslinux-image-*' kernels []kernel_versions []for line in kernel_get_selections.splitlines kernels.append line try kernel kernels[ -2 ]except IndexError kernel kernels[0]kernel kernel.rstrip ' DCTB DCTB install' kernel_get_version __salt__['cmd.run'] 'apt-cachepolicy' + kernel for line in kernel_get_version.splitlines if line.startswith 'Installed ' kernel_v line.strip 'Installed ' kernel_versions.append kernel_v breakif __grains__['os'] 'Ubuntu' kernel_v kernel_versions[0].rsplit '.' 1 kernel_ubuntu_generic kernel_v[0] + '-generic#' + kernel_v[1] kernel_ubuntu_lowlatency kernel_v[0] + '-lowlatency#' + kernel_v[1] kernel_versions.extend [kernel_ubuntu_generic kernel_ubuntu_lowlatency] return kernel_versions
@require_POST@login_requireddef watch_locale request product None kwargs {'locale' request.LANGUAGE_CODE}if product is not None kwargs['product'] productReviewableRevisionInLocaleEvent.notify request.user **kwargs statsd.incr 'wiki.watches.locale' return HttpResponse
def csv_append csv_string item if csv_string return ' '.join csv_string item else return item
def parse_service_definition_opt results []svc_def_opt cfg.CONF.DEFAULT_SERVICETYPE.service_definitiontry for svc_def_str in svc_def_opt split svc_def_str.split ' ' svc_def {'service_class' split[0] 'plugin' split[1]}try svc_def['driver'] split[2]except IndexError LOG.debug _ 'Defaultservicetype-nodriverforservice% service_class sandplugin% plugin s' svc_def results.append svc_def return resultsexcept TypeError IndexError raise q_exc.InvalidConfigurationOption opt_name 'service_definition' opt_value svc_def_opt
def policy_decorator scope def outer func @functools.wraps func def wrapped self context target *args **kwargs check_policy context func.__name__ target scope return func self context target *args **kwargs return wrappedreturn outer
def _make_with_custom_variables func variables variables collections.deque variables def custom_getter getter name **kwargs if kwargs['trainable'] return variables.popleft else kwargs['reuse'] Truereturn getter name **kwargs return _wrap_variable_creation func custom_getter
def _parse_read_concern options concern options.get 'readconcernlevel' return ReadConcern concern
def within_length flowgram minlength 0 maxlength 400 seq flowgram.toSeq l len seq return l > minlength and l < maxlength
def _parse_fmdump output result []output output.split '\n' header [field for field in output[0].lower .split '' if field]del output[0]for entry in output entry [item for item in entry.split '' if item]entry ['{0}{1}{2}'.format entry[0] entry[1] entry[2] ] + entry[3 ] fault OrderedDict for field in header fault[field] entry[header.index field ]result.append fault return result
def update_credential tenant_id credential_id new_user_name None new_password None session db.get_session try cred session.query network_models_v2.Credential .filter_by tenant_id tenant_id .filter_by credential_id credential_id .one if new_user_name cred['user_name'] new_user_nameif new_password cred['password'] new_passwordsession.merge cred session.flush return credexcept exc.NoResultFound raise c_exc.CredentialNotFound credential_id credential_id tenant_id tenant_id
def truncate_microsecond dt measure d datetime dt.year dt.month dt.day tzinfo dt.tzinfo seconds total_seconds dt - d * 1000000 // measure * measure / 1000000 return dt.utcfromtimestamp seconds + utctotimestamp d
def check_cuda_available if not available msg 'CUDAenvironmentisnotcorrectlysetup\n seehttps //github.com/pfnet/chainer#installation .'msg + str _resolution_error raise RuntimeError msg if not cudnn_enabled and not _cudnn_disabled_by_user and not getattr check_cuda_available '_already_warned' False warnings.warn 'cuDNNisnotenabled.\nPleasereinstallchainerafteryouinstallcudnn\n seehttps //github.com/pfnet/chainer#installation .' check_cuda_available._already_warned True
def test_ncr_fit_sample_nn_obj nn NearestNeighbors n_neighbors 3 ncr NeighbourhoodCleaningRule return_indices True random_state RND_SEED n_neighbors nn X_resampled y_resampled idx_under ncr.fit_sample X Y X_gt np.array [[ -1.20809175 -1.49917302 ] [ -0.60497017 -0.66630228 ] [ -0.91735824 0.93110278] [ -0.20413357 0.64628718] [0.35967591 2.61186964] [ -1.55581933 1.09609604] [1.55157493 -1.6981518 ]] y_gt np.array [0 0 1 1 2 1 2] idx_gt np.array [10 11 3 5 7 13 14] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt assert_array_equal idx_under idx_gt
def buildSomeConnections modules res []for i in range len modules // 3 - 1 res.append FullConnection modules[ i * 2 ] modules[ i * 3 + 1 ] return res
def _layout_to_matrix layout result [ [0] * len layout for i in range len layout ]stack []for i in range len layout i_level layout[i]if stack j stack[ -1 ]j_level layout[j]while j_level > i_level stack.pop j stack[ -1 ]j_level layout[j]result[i][j] result[j][i] 1stack.append i return result
def removeComments element global numCommentBytesif isinstance element xml.dom.minidom.Document for subelement in element.childNodes if isinstance element xml.dom.minidom.Comment numCommentBytes + len element.data element.documentElement.removeChild subelement else removeComments subelement elif isinstance element xml.dom.minidom.Comment numCommentBytes + len element.data element.parentNode.removeChild element else for subelement in element.childNodes removeComments subelement
def addSparseEndpointsFromSegment doubleExtrusionWidth endpoints fillLine horizontalSegmentLists infillSolidity removedEndpoints segment solidSurfaceThickness surroundingXIntersections endpointFirstPoint segment[0].pointendpointSecondPoint segment[1].pointif surroundingXIntersections None endpoints + segmentreturnif infillSolidity > 0.0 if fillLine < 1 or fillLine > len horizontalSegmentLists - 1 endpoints + segmentreturnif int round round fillLine * infillSolidity / infillSolidity fillLine endpoints + segmentreturnif abs endpointFirstPoint - endpointSecondPoint < doubleExtrusionWidth endpoints + segmentreturnif not isSegmentAround horizontalSegmentLists[ fillLine - 1 ] segment endpoints + segmentreturnif not isSegmentAround horizontalSegmentLists[ fillLine + 1 ] segment endpoints + segmentreturnif solidSurfaceThickness 0 removedEndpoints + segmentreturnif isSegmentCompletelyInAnIntersection segment surroundingXIntersections removedEndpoints + segmentreturnendpoints + segment
def process_arguments if len sys.argv > 1 if sys.argv[1] 'list' show_packages elif sys.argv[1] 'update' atomic_update os.path.join dataset_web dataset_sources os.path.join dataset_conf_path dataset_sources hook progress_bar elif sys.argv[1] 'upgrade' upgrade_packages sys.argv[2 ] hook progress_bar elif sys.argv[1] 'install' install_packages sys.argv[2 ] hook progress_bar elif sys.argv[1] 'install-from-file' install_packages_from_file sys.argv[2 ] elif sys.argv[1] 'force-install' install_packages sys.argv[2 ] force_install True hook progress_bar elif sys.argv[1] 'remove' remove_packages sys.argv[2 ] elif sys.argv[1] 'clean' passelif sys.argv[1] 'version' logger.info __version__ else raise RuntimeError "[cl]unknowncommand'%s'" % sys.argv[1] else raise RuntimeError '[cl]missingcommand'
def have_graph name for g in mestate.graphs if g.name name return Truereturn False
@command name 'hash' usage 'computehashes' def print_hash args import lixian_hashlixian_hash.main expand_command_line args
def authorize_quota_class_context context class_name if is_user_context context if not context.quota_class raise exception.Forbidden elif context.quota_class ! class_name raise exception.Forbidden
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def test_logarithmic line Line logarithmic True line.add '_' [1 10 ** 10 1] q line.render_pyquery assert len q '.axis.x' 0 assert len q '.axis.y' 1 assert len q '.plot.seriespath' 1 assert len q '.legend' 1 assert len q '.x.axis.guides' 0 assert len q '.y.axis.guides' 21 assert len q '.dots' 3
def currentThread try return _active[_get_ident ]except KeyError return _DummyThread
def get_user_cart user cart_queryset Cart.objects.all return cart_queryset.open .filter user user .first
def getNewRepository return FillRepository
def _factoriesShouldConnect clientInfo serverInfo clientHost clientPort clientFactory clientTimeout clientBindAddress clientInfo serverPort serverFactory serverBacklog serverInterface serverInfoif serverPort clientPort return clientFactory serverFactory else return None
def MakeControlInstance controlClass name None return MakeControlClass controlClass name
def parse_options parser cli_args if not cli_args cli_args.append '-h' options args parser.parse_args cli_args options.__parser parserif not args parser.print_usage sys.exit 0 command_name args.pop 0 command lookup_command parser command_name return options command args
def function_population new_genome num_organisms fitness_calculator all_orgs []for org_num in range num_organisms cur_genome new_genome all_orgs.append Organism cur_genome fitness_calculator return all_orgs
def hash_file filename return u'ed2k //|file|%s|%d|%s|/' % os.path.basename filename os.path.getsize filename hash_filehash filename .upper
def print_label_patch result return make_instancemethod TextTestResult.printLabel result
def describe_apis name None description None region None key None keyid None profile None if name return _find_apis_by_name name description description region region key key keyid keyid profile profile else return _find_apis_by_name '' description description region region key key keyid keyid profile profile
def greedy_color G strategy 'largest_first' interchange False if len G 0 return {}strategy STRATEGIES.get strategy strategy if not callable strategy raise nx.NetworkXError 'strategymustbecallableoravalidstring.{0}notvalid.'.format strategy if interchange if strategy is strategy_independent_set msg 'interchangecannotbeusedwithstrategy_independent_set'raise nx.NetworkXPointlessConcept msg if strategy is strategy_saturation_largest_first msg 'interchangecannotbeusedwithstrategy_saturation_largest_first'raise nx.NetworkXPointlessConcept msg colors {}nodes strategy G colors if interchange return _interchange.greedy_coloring_with_interchange G nodes for u in nodes neighbour_colors {colors[v] for v in G[u] if v in colors }for color in itertools.count if color not in neighbour_colors breakcolors[u] colorreturn colors
def _TestShareExisting tester user_cookie request_dict validator tester.validator user_id device_id tester.GetIdsFromCookie user_cookie request_dict deepcopy request_dict actual_dict tester.SendRequest 'share_existing' user_cookie request_dict op_dict tester._DeriveNotificationOpDict user_id device_id request_dict validator.ValidateCopyEpisodes op_dict request_dict['viewpoint_id'] request_dict['episodes'] viewpoint_changed validator.ValidateCoverPhoto request_dict['viewpoint_id'] activity_dict {'name' 'share_existing' 'activity_id' request_dict['activity']['activity_id'] 'timestamp' request_dict['activity']['timestamp'] 'episodes' [{'episode_id' ep_dict['new_episode_id'] 'photo_ids' ep_dict['photo_ids']} for ep_dict in request_dict['episodes']]}invalidate {'episodes' [{'episode_id' ep_dict['new_episode_id'] 'get_attributes' True 'get_photos' True} for ep_dict in request_dict['episodes']]}if viewpoint_changed invalidate['viewpoints'] [{'viewpoint_id' request_dict['viewpoint_id'] 'get_attributes' True}]validator.ValidateFollowerNotifications request_dict['viewpoint_id'] activity_dict op_dict invalidate sends_alert True validator.ValidateViewpointAccounting request_dict['viewpoint_id'] tester._CompareResponseDicts 'share_existing' user_id request_dict {} actual_dict _ValidateAutoSave tester user_id device_id request_dict return actual_dict
def seed range 10 hash None if hash is None hash __grains__['id']random.seed hash return random.randrange range
def ProfileFeedFromString xml_string return atom.CreateClassFromXMLString ProfileFeed xml_string
def salt_cp import salt.cli.cpclient salt.cli.cp.SaltCPCli _install_signal_handlers client client.run
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def tearDown_test_db if os.path.exists os.path.join TESTDIR TESTDBNAME os.remove os.path.join TESTDIR TESTDBNAME if os.path.exists os.path.join TESTDIR TESTCACHEDBNAME os.remove os.path.join TESTDIR TESTCACHEDBNAME
def collect_system_data_files path destdir None include_py_files False if not isinstance path string_types raise ValueErrordatas []for dirpath dirnames files in os.walk path for f in files extension os.path.splitext f [1]if include_py_files or extension not in PY_IGNORE_EXTENSIONS source os.path.join dirpath f dest remove_prefix dirpath os.path.dirname path + os.sep if destdir is not None dest os.path.join destdir dest datas.append source dest return datas
def _python_shell_default python_shell __pub_jid try if __pub_jid and python_shell is None return Trueelif __opts__.get 'cmd_safe' True is False and python_shell is None return Trueexcept NameError passreturn python_shell
def complete_xontrib prefix line start end ctx args line.split '' if len args 0 or args[0] ! 'xontrib' return Nonecurix args.index prefix if curix 1 possible {'list' 'load'}elif curix 2 if args[1] 'load' possible _list_installed_xontribs else raise StopIterationreturn {i for i in possible if i.startswith prefix }
def get_service_instance_from_managed_object mo_ref name '<unnamed>' if not name name mo_ref.namelog.trace '[{0}]Retrievingserviceinstancefrommanagedobject'.format name si vim.ServiceInstance 'ServiceInstance' si._stub mo_ref._stubreturn si
def expand_args args flist expanded args[ ]if flist try if flist '-' fd sys.stdinelse fd open flist while 1 line fd.readline if not line breakexpanded.append line[ -1 ] except IOError print 'Errorreadingfilelist%s' % flist raisereturn expanded
def served_by_nginx url r requests.get url allow_redirects False status r.status_code 200 nginx 'x-served' in r.headers and r.headers['x-served'] 'Nginx' return all [status nginx]
def related_search vitem query generate_search_qs vitem.ytid match 'related' if query.get 'videoCategoryId' del query['videoCategoryId']t vitem.titlettitle t[ 48].strip + '..' if len t > 49 else t msg 'Videosrelatedto%s%s%s' % c.y ttitle c.w failmsg 'Relatedto%s%s%snotfound' % c.y vitem.ytid c.w _search ttitle query msg failmsg
def _randrat return S randrange 25 + 10 / 50
def encrypt data iv Random.new .read AES.block_size cipher _create_cipher iv return iv + cipher.encrypt data
def EMSA_PKCS1_V1_5_ENCODE hash emLen with_hash_parameters True if with_hash_parameters digestAlgo DerSequence [DerObjectId _HASH_OIDS[hash.name] .encode DerNull .encode ] else digestAlgo DerSequence [DerObjectId _HASH_OIDS[hash.name] .encode ] digest DerOctetString hash.digest digestInfo DerSequence [digestAlgo.encode digest.encode ] .encode if emLen < len digestInfo + 11 raise TypeError 'Selectedhashalgorithhasatoolongdigest %dbytes .' % len digest PS bchr 255 * emLen - len digestInfo - 3 return b '\x00\x01' + PS + bchr 0 + digestInfo
def mock_ssh_dir host path dest rel_posix_to_abs_local host path if not os.path.exists dest os.makedirs dest
def delete_ipsec_site_connection ipsec_site_connection profile None conn _auth profile return conn.delete_ipsec_site_connection ipsec_site_connection
def get_config_var name return get_config_vars .get name
def _api_test_prowl name output kwargs logging.info 'SendingProwlnotification' res sabnzbd.notifier.send_prowl 'SABnzbd' T 'TestNotification' 'other' force True test kwargs return report output error res
def clear_search_index search_services.clear_index SEARCH_INDEX_EXPLORATIONS
def getstatus file import warningswarnings.warn 'commands.getstatus isdeprecated' DeprecationWarning 2 return getoutput 'ls-ld' + mkarg file
def is_prefix_subset orig_prefixes new_prefixes orig_set netaddr.IPSet orig_prefixes new_set netaddr.IPSet new_prefixes return orig_set.issubset new_set
def matshow A fignum None **kw A np.asanyarray A if fignum is False or fignum is 0 ax gca else fig figure fignum figsize figaspect A ax fig.add_axes [0.15 0.09 0.775 0.775] im ax.matshow A **kw sci im return im
def contains_inf arr return np.isinf np.nanmax arr or np.isinf np.nanmin arr
def nova_to_osvif_vif vif LOG.debug 'ConvertingVIF%s' vif funcname '_nova_to_osvif_vif_' + vif['type'].replace '.' '_' func getattr sys.modules[__name__] funcname None if not func raise exception.NovaException "UnsupportedVIFtype% type sconvert'% func s'" % {'type' vif['type'] 'func' funcname} try vifobj func vif LOG.debug 'Convertedobject%s' vifobj return vifobjexcept NotImplementedError LOG.debug 'NoconversionforVIFtype%syet' vif['type'] return None
def err_func err_func.counter + 1if err_func.counter 3 return Trueelif err_func.counter 2 raise TypeErrorelse raise errors.ConnectionFailure
def custom cls **params def customized *args **kwargs 'Customizedconstructor'kwargs kwargs.copy kwargs.update params return cls *args **kwargs customized.__name__ 'custom %s %s ' % cls params return customized
def FillBetween xs y1 y2 None where None **options options _UnderrideColor options options _Underride options linewidth 0 alpha 0.5 pyplot.fill_between xs y1 y2 where **options
def structure_function f index 0 def structured_function *args pattern args[index]evaluated f *args evaluated[ pattern 0 ] 0return evaluatedreturn structured_function
def make_general_rowkey_scan rts_start None rts_end None some_id None if some_id is None return None None if not rts_start rts_start chr 122 end_row prepare_key some_id rts_start start_row prepare_key some_id rts_end return start_row end_row
def ustr what if isinstance what unicode return whattry r what.__str__ except AttributeError r str what if not isinstance r unicode return unicode r ENCODING return r
@nodes_or_number 0 def star_graph n create_using None n_name nodes nif isinstance n_name int nodes nodes + [n_name] first nodes[0]G empty_graph nodes create_using if G.is_directed raise nx.NetworkXError 'DirectedGraphnotsupported' G.add_edges_from first v for v in nodes[1 ] G.name 'star_graph %s ' % n_name return G
def activateAaPdpContextAccept ProtocolConfigurationOptions_presence 0 GprsTimer_presence 0 a TpPd pd 8 b MessageType mesType 81 c LlcServiceAccessPointIdentifier d QualityOfService e MobileId f PacketDataProtocolAddress g RadioPriorityAndSpareHalfOctets packet a / b / c / d / e / f / g if ProtocolConfigurationOptions_presence is 1 i ProtocolConfigurationOptions ieiPCO 39 packet packet / i if GprsTimer_presence is 1 j GprsTimer ieiGT 41 packet packet / j return packet
def test_chordal_cycle_graph if not is_scipy_available raise SkipTest 'SciPyisnotavailable' primes [3 5 7 11]for p in primes G chordal_cycle_graph p assert_equal len G p
def _nullpager stream text color if not color text strip_ansi text stream.write text
def _format_return_as_json rval jsonp_callback None pretty False dumps_kwargs dict indent 4 sort_keys True if pretty else {} json safe_dumps rval **dumps_kwargs if jsonp_callback json '{} {} ;'.format jsonp_callback json return json
def UploadRaw file_path aff4_path token None full_path rdfvalue.RDFURN aff4_path .Add os.path.basename file_path fd aff4.FACTORY.Create full_path 'AFF4Image' mode 'w' token token fd.Write open file_path 'rb' .read 1024 * 1024 * 30 fd.Close return str fd.urn
def import_stages stages []for plugin in find_plugins stages + plugin.get_import_stages return stages
def filter_skiplines code errors if not errors return errorsenums set er.lnum for er in errors removed set [num for num l in enumerate code.split '\n' 1 if num in enums and SKIP_PATTERN l ] if removed errors [er for er in errors if er.lnum not in removed ]return errors
def write_unpaired_read data sff_fh seq_fh qual_fh xml_fh seq qual get_read_data data if len seq 0 returnwrite_sequence data['name'] seq qual seq_fh qual_fh anci create_xml_for_unpaired_read data sff_fh.name if anci is not None xml_fh.write anci return
def org_organisation_logo id if not id return Nones3db current.s3dbif isinstance id Row record idelse table s3db.org_organisationrecord current.db table.id id .select table.name table.acronym table.logo limitby 0 1 .first if record and record.logo size None 60 image s3db.pr_image_represent record.logo size size url_small URL c 'default' f 'download' args image if record.acronym is None or record.acronym '' alt '%slogo' % record.name else alt '%slogo' % record.acronym logo IMG _src url_small _alt alt _height 60 return logoreturn ''
def simpleflake timestamp None random_bits None epoch SIMPLEFLAKE_EPOCH second_time timestamp if timestamp is not None else time.time second_time - epochmillisecond_time int second_time * 1000 randomness random.SystemRandom .getrandbits SIMPLEFLAKE_RANDOM_LENGTH randomness random_bits if random_bits is not None else randomness flake millisecond_time << SIMPLEFLAKE_TIMESTAMP_SHIFT + randomness return flake
def __parse_word value for word_list in [english_word_numeral_list french_word_numeral_list french_alt_word_numeral_list] try return word_list.index value.lower except ValueError passraise ValueError
def generate_timestamp return int time.time
def switch_host_s3_accelerate request operation_name **kwargs parts urlsplit request.url .netloc.split '.' parts [p for p in parts if p in S3_ACCELERATE_WHITELIST ]endpoint 'https //s3-accelerate.'if len parts > 0 endpoint + '.'.join parts + '.' endpoint + 'amazonaws.com'if operation_name in ['ListBuckets' 'CreateBucket' 'DeleteBucket'] return_switch_hosts request endpoint use_new_scheme False
def redirect url code None if code is None code 303 if request.get 'SERVER_PROTOCOL' 'HTTP/1.1' else 302 location urljoin request.url url raise HTTPResponse '' status code header dict Location location
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def disallowed_in_before_trading_start exception def decorator method @wraps method def wrapped_method self *args **kwargs if self._in_before_trading_start raise exceptionreturn method self *args **kwargs return wrapped_methodreturn decorator
def truncate_path path length MAX_FILENAME_LENGTH comps components path out [c[ length] for c in comps] base ext os.path.splitext comps[ -1 ] if ext base base[ length - len ext ]out[ -1 ] base + ext return os.path.join *out
def register_hook handler name handler.__name__.split '_' [0]HOOK_HANDLERS[name] handlerreturn handler
def get_peer_user_ids_for_stream_change stream altered_users subscribed_users altered_user_ids [user.id for user in altered_users]if stream.invite_only all_subscribed_ids [user.id for user in subscribed_users]return set all_subscribed_ids - set altered_user_ids else return set active_user_ids stream.realm - set altered_user_ids
def ackley individual N len individual return 20 - 20 * exp -0.2 * sqrt 1.0 / N * sum x ** 2 for x in individual + e - exp 1.0 / N * sum cos 2 * pi * x for x in individual
def language_dir language_code RTL_LANGS ['ar' 'arc' 'bcc' 'bqi' 'ckb' 'dv' 'fa' 'glk' 'he' 'ks' 'lrc' 'mzn' 'pnb' 'ps' 'sd' 'ug' 'ur' 'yi' 'nqo' 'shu' 'sqr' 'ssh' 'xaa' 'yhd' 'yud' 'aao' 'abh' 'abv' 'acm' 'acq' 'acw' 'acx' 'acy' 'adf' 'ads' 'aeb' 'aec' 'afb' 'ajp' 'apc' 'apd' 'arb' 'arq' 'ars' 'ary' 'arz' 'auz' 'avl' 'ayh' 'ayl' 'ayn' 'ayp' 'bbz' 'pga' 'iw' 'pbt' 'pbu' 'pst' 'prp' 'prd' 'ydd' 'yds' 'yih' 'ji' 'hbo' 'men' 'xmn' 'jpr' 'peo' 'pes' 'prs' 'sam']shortcode language_code[ 3]if not shortcode.isalpha shortcode language_code[ 2]if shortcode in RTL_LANGS return 'rtl'return 'ltr'
def watcher while True _process_message
def variations iterable optional lambda x False iterable tuple iterable o [optional x for x in iterable]a set for p in product [False True] repeat sum o p list p v [ b and b and p.pop 0 for b in o]v tuple iterable[i] for i in range len v if not v[i] a.add v return sorted a cmp lambda x y len y - len x
def app_is_deployed app_id if not os.path.exists '{0}{1}/'.format _APPS_LOCATION app_id logging.error 'Seemsthat"{0}"isnotdeployed.'.format app_id logging.info 'Pleasedeploy"{0}"andtryagain.'.format app_id return Falsereturn True
def principals_allowed_by_permission context permission reg get_current_registry policy reg.queryUtility IAuthorizationPolicy if policy is None return [Everyone]return policy.principals_allowed_by_permission context permission
def brick_detach_volume_encryptor attach_info encryption connection_info attach_info['conn']connection_info['data']['device_path'] attach_info['device']['path']encryptor brick_get_encryptor connection_info **encryption encryptor.detach_volume **encryption
def configure_errorhandlers app @app.errorhandler 403 def forbidden_page error return render_template 'errors/forbidden_page.html' 403 @app.errorhandler 404 def page_not_found error return render_template 'errors/page_not_found.html' 404 @app.errorhandler 500 def server_error_page error return render_template 'errors/server_error.html' 500
def registered_tasks request return JsonResponse {u'regular' list keys tasks u'periodic' u''}
def _is_pid_running_on_windows pid pid str pid startupinfo subprocess.STARTUPINFO startupinfo.dwFlags | subprocess.STARTF_USESHOWWINDOWprocess subprocess.Popen 'tasklist/fi"PIDeq{0}"'.format pid stdout subprocess.PIPE stderr subprocess.STDOUT startupinfo startupinfo stdoutdata stderrdata process.communicate stdoutdata to_text_string stdoutdata process.kill check pid in stdoutdata return check
def splitpasswd user global _passwdprogif _passwdprog is None import re_passwdprog re.compile '^ [^ ]* .* $' re.S match _passwdprog.match user if match return match.group 1 2 return user None
def gather_symptoms symptoms []for module in SYMPTOM_MODULES for name in dir module if name.startswith SYMPTOM_PREFIX symptoms.append getattr module name return symptoms
def run_saved_post_hooks for cmd in post_hook.eventually logger.info 'Runningpost-hookcommand %s' cmd _run_hook cmd
def p_pointer_4 t pass
def log_level level_string return getattr logging level_string.upper
def _should_profile_development_default return True
def text_len length fs return length * 0.6 * fs
def matrix_combinations_param registry xml_parent data element_name 'hudson.plugins.matrix__configuration__parameter.MatrixCombinationsParameterDefinition'pdef XML.SubElement xml_parent element_name if 'name' not in data raise JenkinsJobsException 'matrix-combinationsmusthaveanameparameter.' XML.SubElement pdef 'name' .text data['name']XML.SubElement pdef 'description' .text data.get 'description' '' combination_filter data.get 'filter' if combination_filter XML.SubElement pdef 'defaultCombinationFilter' .text combination_filterreturn pdef
def _build_localename localetuple language encoding localetupleif language is None language 'C'if encoding is None return languageelse return language + '.' + encoding
def _normalize_key value if ndb is not None and isinstance value ndb.Model ndb.Key return Noneif getattr value 'key' None return value.key elif isinstance value basestring return datastore.Key value else return value
def _IsFinite value if isinstance value float and -1e309 < value < 1e309 return Trueelif isinstance value int long return Trueelse return False
def apply_discount line discount quantity line.discount discount quantity incl_tax False
def getFileInAlterationsOrGivenDirectory directory fileName settingsAlterationsDirectory archive.getSettingsPath 'alterations' archive.makeDirectory settingsAlterationsDirectory fileInSettingsAlterationsDirectory getFileInGivenDirectory settingsAlterationsDirectory fileName if fileInSettingsAlterationsDirectory ! '' return fileInSettingsAlterationsDirectoryalterationsDirectory archive.getSkeinforgePath 'alterations' fileInAlterationsDirectory getFileInGivenDirectory alterationsDirectory fileName if fileInAlterationsDirectory ! '' return fileInAlterationsDirectoryif directory '' directory os.getcwd return getFileInGivenDirectory directory fileName
def _format_info data return {'gid' data.pw_gid 'groups' list_groups data.pw_name 'home' data.pw_dir 'name' data.pw_name 'shell' data.pw_shell 'uid' data.pw_uid 'fullname' data.pw_gecos}
def validate_dpi s if s u'figure' return stry return float s except ValueError raise ValueError u'"%s"isnotstring"figure"orcouldnotconvert"%s"tofloat' % s s
def _kr3 y alpha 5.0 beta 50.0 perc alpha 100.0 - alpha beta 100.0 - beta lower_alpha upper_alpha lower_beta upper_beta np.percentile y perc l_alpha np.mean y[ y < lower_alpha ] u_alpha np.mean y[ y > upper_alpha ] l_beta np.mean y[ y < lower_beta ] u_beta np.mean y[ y > upper_beta ] return u_alpha - l_alpha / u_beta - l_beta
def do_dialog my_dlg Dlg.GetNewDialog ID_MAIN -1 while 1 n Dlg.ModalDialog None if n ITEM_LOOKUP_BUTTON tp h rect my_dlg.GetDialogItem ITEM_LOOKUP_ENTRY txt Dlg.GetDialogItemText h tp h rect my_dlg.GetDialogItem ITEM_RESULT Dlg.SetDialogItemText h dnslookup txt elif n ITEM_QUIT_BUTTON break
def N_equals a b return comp a.n b.n 1e-06
def git_handling orig_dir os.getcwd os.chdir global_params.CFGS_DIR current_dir os.getcwd + '/' if current_dir global_params.CFGS_DIR proc subprocess.Popen [GIT 'add' '*.txt'] stdout subprocess.PIPE stderr subprocess.PIPE std_out std_err proc.communicate commit_message 'Networkconfigchanges auto 'proc subprocess.Popen [GIT 'commit' '-m' commit_message] stdout subprocess.PIPE stderr subprocess.PIPE std_out std_err proc.communicate os.chdir orig_dir
def remove_entrance_exam_milestone_reference request course_key course_children modulestore .get_items course_key qualifiers {'category' 'chapter'} for course_child in course_children if course_child.is_entrance_exam delete_item request course_child.scope_ids.usage_id milestones_helpers.remove_content_references unicode course_child.scope_ids.usage_id
def _translate_raw_sort sort sort_dir ''if sort.startswith '-' sort sort[1 ]sort_dir 'desc'sort SORTS_DICT.get sort sort return '%s%s' % sort sort_dir
def pre_safe_import_module api real_to_six_module_name eval_statement '\nimportsix\nprint \'{\' \n\n#Iterateoverthe"six._moved_attributes"listratherthanthe\n#"six._importer.known_modules"dictionary as"urllib"-specificmovedmodules\n#areoverwritteninthelatterwithunhelpful"LazyModule"objects.\nformoved_moduleinsix._moved_attributes \n#Ifthisisamovedmoduleorattribute mapthecorrespondingmodule.In\n#thecaseofmovedattributes theattribute\'smoduleismappedwhilethe\n#attributeitselfismappedatruntimeandhenceignoredhere.\nifisinstance moved_module six.MovedModule six.MovedAttribute \nprint \'%r %r \'% \nmoved_module.mod \'six.moves.\'+moved_module.name \n\nprint \'}\' \n' api.add_runtime_package api.module_name for real_module_name six_module_name in real_to_six_module_name.items api.add_alias_module real_module_name six_module_name
def set_pixel x y color _sensehat.set_pixel x y color return {'color' color}
def test_consensus_score_issue2445 a_rows np.array [[True True False False] [False False True True] [False False False True]] a_cols np.array [[True True False False] [False False True True] [False False False True]] idx [0 2]s consensus_score a_rows a_cols a_rows[idx] a_cols[idx] assert_almost_equal s 2.0 / 3.0
@app.template_filter 'fees_by_currency' def fees_by_currency currency fees DataGetter.get_fee_settings_by_currency currency return fees
def submit request if not request.user.is_authenticated return proceed request user UserProfile.objects.get pk request.user.id if not user.read_dev_agreement return redirect 'submit.app.terms' return manifest request
def issorted seq if not seq return Truex seq[0]for elem in seq[1 ] if elem < x return Falsex elemreturn True
def _make_queryset_readonly queryset db_query_methods ['count' 'get' 'get_or_create' 'latest' 'in_bulk' 'delete']for method_name in db_query_methods method getattr queryset method_name wrapped_method _wrap_with_readonly method setattr queryset method_name wrapped_method queryset.iterator _wrap_generator_with_readonly queryset.iterator
def test_iht_fit_invalid_ratio ratio 1.0 / 10000.0 iht InstanceHardnessThreshold ESTIMATOR ratio ratio random_state RND_SEED assert_raises RuntimeError iht.fit X Y
def EI_gaussian mean var thresh sigma np.sqrt var score old_div mean - thresh sigma n scipy.stats.normreturn sigma * score * n.cdf score + n.pdf score
def rational_polynomial data return 30.0 * data[0] - 1 * data[2] - 1 / data[1] ** 2 * data[0] - 10
def _mean values return sum values / float max len values 1
def bytestobits bytesource for b in bytesource value unpackbyte b for bitplusone in range 8 0 -1 bitindex bitplusone - 1 nextbit 1 & value >> bitindex yield nextbit
def OpenFileInPreviewWindow filename vim.command u'silent!pedit!' + filename
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _get_overrides_for_user user block query StudentFieldOverride.objects.filter course_id block.runtime.course_id location block.location student_id user.id overrides {}for override in query field block.fields[override.field]value field.from_json json.loads override.value overrides[override.field] valuereturn overrides
def _pad_length stringlen return BLOCK_SIZE - stringlen % BLOCK_SIZE % BLOCK_SIZE
def test_command_chain_dispatcher_fofo fail1 Fail u'fail1' fail2 Fail u'fail2' okay1 Okay u'okay1' okay2 Okay u'okay2' dp CommandChainDispatcher [ 0 fail1 10 fail2 15 okay2 ] dp.add okay1 5 nt.assert_equal dp u'okay1' nt.assert_true fail1.called nt.assert_true okay1.called nt.assert_false fail2.called nt.assert_false okay2.called
def override_field_for_user user block name value override _ StudentFieldOverride.objects.get_or_create course_id block.runtime.course_id location block.location student_id user.id field name field block.fields[name]override.value json.dumps field.to_json value override.save
def attach_epic_order queryset epic_id as_field 'epic_order' model queryset.modelsql 'SELECT"epics_relateduserstory"."order"AS"epic_order"\nFROM"epics_relateduserstory"\nWHERE"epics_relateduserstory"."user_story_id" {tbl}.idand\n"epics_relateduserstory"."epic_id" {epic_id}'sql sql.format tbl model._meta.db_table epic_id epic_id queryset queryset.extra select {as_field sql} return queryset
def makeAtom line return filter lambda x not x in map chr range 33 + [34 39 92] line
def ignore_message_warning warnings.resetwarnings warnings.filterwarnings 'ignore' 'BaseException.message' DeprecationWarning
def str2bytes string if isinstance string type '' and PY_MAJOR_VERSION > 2 return bytes string 'latin1' else return string
def get_ninja_editor_skins_files path extension '.color'return get_ninja_file path extension
def BOP barDs count return call_talib_with_ohlc barDs count talib.BOP
def add_app_ctx ctx app_slug try app Webapp.objects.get app_slug app_slug ctx['app'] appexcept Webapp.DoesNotExist passreturn ctx
def monitor_get_global sock name return communicate sock '__get_global__ "%s" ' % name
def site_needs def prep r if r.interactive and r.method 'create' site_id get_vars.get '~. site ' None if site_id field s3db.req_site_needs.site_idfield.default site_idfield.readable Falsefield.writable Falsereturn Trues3.prep prepreturn s3_rest_controller
def configure_eliot_logging_for_acceptance eliot_to_stdout MESSAGE_FORMATS ACTION_START_FORMATS
def is_lval t if not t return Falsei iter t if i.next not in IDENTIFIER_START return Falsereturn all e in IDENTIFIER_PART for e in i
def _manual_join_columns columns_to_join manual_joins []columns_to_join_new copy.copy columns_to_join for column in 'metadata' 'system_metadata' 'pci_devices' if column in columns_to_join_new columns_to_join_new.remove column manual_joins.append column return manual_joins columns_to_join_new
def _read_dir_entry_struct fid tag shape rlims return [_read_tag_header fid for _ in range tag.size // 16 - 1 ]
def schema request_body_schema min_version None max_version None def add_validator func @functools.wraps func def wrapper *args **kwargs _schema_validation_helper request_body_schema kwargs['body'] min_version max_version args kwargs return func *args **kwargs return wrapperreturn add_validator
def _FileToModuleName filename _ lib suffix filename.partition '$PYTHON_LIB/' if lib module suffixelse module filenamemodule os.path.normpath module if '.py' in module module module.rpartition '.py' [0]module module.replace os.sep '.' module module.strip '.' if module.endswith '.__init__' module module.rpartition '.__init__' [0]return module
def canonicalize app pagename templatename context doctree if not app.config.canonical_root returncontext['canonical'] _build_url app.config.canonical_root app.config.canonical_branch pagename
def _get_boolean_param request param_name return request.POST.get param_name False in ['true' 'True' True]
def deprecated_redirect request url **kwargs dest reverse url kwargs kwargs proto 'https //' if request.is_secure else 'http //' host Site.objects.get_current .domainreturn render request 'sumo/deprecated.html' {'dest' dest 'proto' proto 'host' host}
def _associate_eip_with_interface eni_id eip_id private_ip None vm_ None retries 5while retries > 0 params {'Action' 'AssociateAddress' 'NetworkInterfaceId' eni_id 'AllocationId' eip_id}if private_ip params['PrivateIpAddress'] private_ipretries retries - 1 result aws.query params return_root True location get_location vm_ provider get_provider opts __opts__ sigver '4' if isinstance result dict and result.get 'error' time.sleep 1 continueif not result[2].get 'associationId' breaklog.debug 'AssociatedElasticIPaddress{0}withinterface{1}'.format eip_id eni_id return result[2].get 'associationId' raise SaltCloudException 'Couldnotassociateelasticipaddress<{0}>withnetworkinterface<{1}>'.format eip_id eni_id
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def is_tool_load_error obj return obj is TOOL_LOAD_ERROR
def _get_response_factory registry response_factory registry.queryUtility IResponseFactory default lambda r Response return response_factory
def MINUS_DI barDs count timeperiod - 2 ** 31 return call_talib_with_hlc barDs count talib.MINUS_DI timeperiod
def grains if not GRAINS_CACHE return _grains DETAILS['host'] DETAILS['protocol'] DETAILS['port'] return GRAINS_CACHE
def collocation_fun fun y p x h f fun x y p y_middle 0.5 * y[ 1 ] + y[ -1 ] - 0.125 * h * f[ 1 ] - f[ -1 ] f_middle fun x[ -1 ] + 0.5 * h y_middle p col_res y[ 1 ] - y[ -1 ] - h / 6 * f[ -1 ] + f[ 1 ] + 4 * f_middle return col_res y_middle f f_middle
def UWRatio s1 s2 return WRatio s1 s2 force_ascii False
def _generate_random_string length 6 return ''.join random.sample string.ascii_lowercase length
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def getCraftTypeName subName '' profileSettings getReadProfileRepository craftTypeName settings.getSelectedPluginName profileSettings.craftRadios if subName '' return craftTypeNamereturn os.path.join craftTypeName subName
def sign_plaintext client_secret resource_owner_secret signature utils.escape client_secret or u'' signature + u'&'signature + utils.escape resource_owner_secret or u'' return signature
def concepts items items if isinstance items string_types items items rels [item_metadata[r] for r in items]concept_map process_bundle rels return concept_map.values
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def num_mock_patch_args function patchings getattr function 'patchings' None if not patchings return 0mock sys.modules.get 'mock' sys.modules.get 'unittest.mock' None if mock is not None return len [p for p in patchings if not p.attribute_name and p.new is mock.DEFAULT ] return len patchings
def get_files_from_folder folder ext try filesExt os.listdir folder except filesExt []filesExt [f for f in filesExt if f.endswith ext ]return filesExt
def gen_keys nbits p q find_p_q nbits e d calculate_keys p q nbits return p q e d
def returnValue val raise _DefGen_Return val
def rehash runas None _pyenv_exec 'rehash' runas runas return True
@checker '.py' '.rst' def check_whitespace fn lines for lno line in enumerate lines if '\r' in line yield lno + 1 '\\rinline' if ' DCTB ' in line yield lno + 1 'OMGTABS!!!1' if line[ -1 ].rstrip ' DCTB ' ! line[ -1 ] yield lno + 1 'trailingwhitespace'
def get_fontspec latex_fontspec []texcommand get_texcommand if texcommand ! u'pdflatex' latex_fontspec.append u'\\usepackage{fontspec}' if texcommand ! u'pdflatex' and rcParams.get u'pgf.rcfonts' True families [u'serif' u'sans-serif' u'monospace']fontspecs [u'\\setmainfont{%s}' u'\\setsansfont{%s}' u'\\setmonofont{%s}']for family fontspec in zip families fontspecs matches [f for f in rcParams[ u'font.' + family ] if f in system_fonts ]if matches latex_fontspec.append fontspec % matches[0] else passreturn u'\n'.join latex_fontspec
def __remove_queue_logging_handler global LOGGING_STORE_HANDLERif LOGGING_STORE_HANDLER is None returnroot_logger logging.getLogger for handler in root_logger.handlers if handler is LOGGING_STORE_HANDLER root_logger.removeHandler LOGGING_STORE_HANDLER LOGGING_STORE_HANDLER Nonebreak
def poll_tail_pipes pipes lastlines_dirpath None waitsecs 5 lines []bad_pipes [] ready _ _ select.select pipes.keys waitsecs for fi in ready path pipes[fi]data fi.read if len data 0 bad_pipes.append fi continueif lastlines_dirpath write_lastlines_file lastlines_dirpath path data for line in data.splitlines lines.append '[%s] DCTB %s\n' % path line return lines bad_pipes
def superuser *args **kwargs return False
def _run_finalizers minpriority None if _finalizer_registry is None returnif minpriority is None f lambda p p[0][0] is not None else f lambda p p[0][0] is not None and p[0][0] > minpriority items [x for x in _finalizer_registry.items if f x ]items.sort reverse True for key finalizer in items sub_debug 'calling%s' finalizer try finalizer except Exception import tracebacktraceback.print_exc if minpriority is None _finalizer_registry.clear
def QuotedFileName fname import regutil stringtry fname.index '' return '"%s"' % fname except ValueError return fname
def _get_env_activate bin_env if not bin_env raise CommandNotFoundError 'Couldnotfinda`activate`binary' if os.path.isdir bin_env if salt.utils.is_windows activate_bin os.path.join bin_env 'Scripts' 'activate.bat' else activate_bin os.path.join bin_env 'bin' 'activate' if os.path.isfile activate_bin return activate_binraise CommandNotFoundError 'Couldnotfinda`activate`binary'
def get_subpackages name splist []for dirpath _dirnames _filenames in os.walk name if osp.isfile osp.join dirpath '__init__.py' splist.append '.'.join dirpath.split os.sep return splist
def GetBytes mem_str unit mem_str[ -1 ]val float mem_str[ -1 ] if unit 'G' val * 1024 * 1024 * 1024 elif unit 'M' val * 1024 * 1024 elif unit 'K' val * 1024else try val int mem_str except Exception print '%sisnotavalidwayofwritingmemorysize.' % mem_str return int val
def getDescendingAreaOrientedLoops allPoints corners importRadius return getOrientedLoops getDescendingAreaLoops allPoints corners importRadius
def nodes_or_number which_args @decoratordef _nodes_or_number f *args **kw try iter_wa iter which_args except TypeError iter_wa which_args new_args list args for i in iter_wa n args[i]try nodes list range n except TypeError nodes tuple n else if n < 0 msg 'Negativenumberofnodesnotvalid %i' % n raise nx.NetworkXError msg new_args[i] n nodes return f *new_args **kw return _nodes_or_number
def impl_ret_new_ref ctx builder retty ret return ret
def _get_constant_term p x R p.ringzm R.zero_monomi R.gens.index x zm R.zero_monoma [0] * R.ngens a[i] 1miv tuple a c 0for expv in p if monomial_min expv miv zm c + R {expv p[expv]} return c
def robots request template render request 'site/robots.txt' return HttpResponse template content_type 'text/plain'
def run_on_ui_thread f def f2 *args **kwargs Runnable f *args **kwargs return f2
def _extend_nodelist extend_node if is_variable_extend_node extend_node return []blocks dict extend_node.blocks _extend_blocks extend_node blocks placeholders []for block in blocks.values placeholders + _scan_placeholders _get_nodelist block block blocks.keys parent_template _find_topmost_template extend_node placeholders + _scan_placeholders _get_nodelist parent_template None blocks.keys return placeholders
def data_table fn_list datalabel keyatom outlist [][dict_list label_line_list] _read_dicts fn_list keyatom minr dict_list[0]['minres']maxr dict_list[0]['maxres']for dictionary in dict_list if maxr < dictionary['maxres'] maxr dictionary['maxres']if minr > dictionary['minres'] minr dictionary['minres']res minrwhile res < maxr count 0line str res for dictionary in dict_list label label_line_list[count]if str res in dictionary line line + ' DCTB ' + XpkEntry dictionary[str res ][0] label .fields[datalabel] else line line + ' DCTB ' + '*' count count + 1 line line + '\n' outlist.append line res res + 1 return outlist
def get_selection text try first text.index 'sel.first' last text.index 'sel.last' except TclError first last Noneif not first first text.index 'insert' if not last last firstreturn first last
def calculate_torrent_hash link data None if link.startswith 'magnet ' torrent_hash re.findall 'urn btih [\\w]{32 40} ' link [0]if len torrent_hash 32 torrent_hash b16encode b32decode torrent_hash .lower elif data info bdecode data ['info']torrent_hash sha1 bencode info .hexdigest else raise ValueError 'Cannotcalculatetorrenthashwithoutmagnetlinkordata' return torrent_hash.upper
def replaceHTMLEntity t return _htmlEntityMap.get t.entity
def move_from_center coord centers deltas axmask True True True coord copy.copy coord for i in range 3 if not axmask[i] continueif coord[i] < centers[i] coord[i] - deltas[i]else coord[i] + deltas[i]return coord
@register.inclusion_tag 'zinnia/tags/dummy.html' def get_recent_linkbacks number 5 template 'zinnia/tags/linkbacks_recent.html' entry_published_pks map smart_text Entry.published.values_list 'id' flat True content_type ContentType.objects.get_for_model Entry linkbacks get_comment_model .objects.filter content_type content_type object_pk__in entry_published_pks flags__flag__in [PINGBACK TRACKBACK] is_public True .order_by '-pk' [ number]linkbacks linkbacks.prefetch_related 'content_object' return {'template' template 'linkbacks' linkbacks}
def libvlc_log_set_file p_instance stream f _Cfunctions.get 'libvlc_log_set_file' None or _Cfunction 'libvlc_log_set_file' 1 1 None None Instance FILE_ptr return f p_instance stream
def plot_evoked_white evoked noise_cov show True return _plot_evoked_white evoked evoked noise_cov noise_cov scalings None rank None show show
def render_xml data if isinstance data list data {config.ITEMS data}xml ''if data xml + xml_root_open data xml + xml_add_links data xml + xml_add_meta data xml + xml_add_items data xml + xml_root_close return xml
def idd_estrank eps A A np.asfortranarray A m n A.shape n2 w idd_frmi m ra np.empty n * n2 + n + 1 * n2 + 1 order 'F' k ra _id.idd_estrank eps A w ra return k
def calculate_compile_sources targets is_thrift_target basedirs set sources set def collect_sources target basedirs.add target.target_base sources.update target.sources_relative_to_buildroot for target in targets target.walk collect_sources predicate is_thrift_target return basedirs sources
def trim_silence audio threshold energy librosa.feature.rmse audio frames np.nonzero energy > threshold indices librosa.core.frames_to_samples frames [1]return audio[indices[0] indices[ -1 ]] if indices.size else audio[0 0]
def _convert_exception e args 'exceptioninldapbackend {0}'.format repr e e if six.PY2 six.reraise LDAPError args sys.exc_info [2] else six.raise_from LDAPError *args e
def full_strip string string _stripper_double_spaces.sub '' string string _stripper_double_ellipsis.sub consts.CHAR_ELLIPSIS string string _stripper_space_ellipsis.sub consts.CHAR_ELLIPSIS string return string.strip ''
def prde_linear_constraints a b G DE m len G Gns Gds list zip *G d reduce lambda i j i.lcm j Gds d Poly d field True Q [ ga * d.quo gd .div d for ga gd in G]if not all [ri.is_zero for _ ri in Q] N max [ri.degree DE.t for _ ri in Q] M Matrix N + 1 m lambda i j Q[j][1].nth i else M Matrix qs _ list zip *Q return qs M
def get_essid_from_cap bssid capfile if not program_exists 'tshark' return ''cmd ['tshark' '-r' capfile '-R' 'wlan.fc.type_subtype 0x05&&wlan.sa %s' % bssid '-n']proc Popen cmd stdout PIPE stderr DN proc.wait for line in proc.communicate [0].split '\n' if line.find 'SSID ' ! -1 essid line[ line.find 'SSID ' + 5 ]print GR + '[+]' + W + 'guessedessid %s' % G + essid + W return essidprint R + '[!]' + O + 'unabletoguessessid!' + W return ''
def splitZip path components os.path.normpath path .split os.sep for index component in enumerate components if component.endswith '.zip' zipPath os.sep.join components[0 index + 1 ] archivePath ''.join [ x + '/' for x in components[ index + 1 ]] return zipPath archivePath else return path None
@with_devicedef which name which_cmd '\nIFS \nBINARY %s\nP $PATH \nforpathin"${P[@]}";doif[-e"$path/$BINARY"];thenecho"$path/$BINARY";\nbreak\nfi\ndone\n' % name which_cmd which_cmd.strip return process ['sh' '-c' which_cmd] .recvall .strip
def iter_symbols code for name in code.co_names yield name for const in code.co_consts if isinstance const basestring yield const elif isinstance const CodeType for name in iter_symbols const yield name
def get_memcached_client expiration_time 0 if CONF.cache.enabled and CONF.cache.memcache_servers _warn_if_null_backend return CacheClient _get_default_cache_region expiration_time expiration_time
def write_data text options outputname module if options.output_dir is not None fname os.path.join options.output_dir outputname % module fname fname.replace '.py' '' f open fname 'w' f.write text.encode 'utf-8' f.close else print text
def find_mrjob_conf def candidates if 'MRJOB_CONF' in os.environ yield expand_path os.environ['MRJOB_CONF'] yield expand_path os.path.join '~' '.mrjob.conf' yield '/etc/mrjob.conf' for path in candidates log.debug 'Lookingforconfigsin%s' % path if os.path.exists path log.info 'Usingconfigsin%s' % path return pathelse log.info 'Noconfigsfound;fallingbackonauto-configuration' return None
def test_sequence value try len value value.__getitem__except return Falsereturn True
def _point_cloud_error src_pts tgt_pts from scipy.spatial.distance import cdistY cdist src_pts tgt_pts 'euclidean' dist Y.min axis 1 return dist
def first predicate it return next v for v in evaluate_promises it if predicate v if predicate is not None else v is not None None
def _execute q table context model context['model']session model.Sessionreturn session.execute q
def fama_macbeth **kwargs window_type kwargs.get 'window_type' if window_type is None klass FamaMacBethelse klass MovingFamaMacBethreturn klass **kwargs
def remove_cert_binding name site hostheader '' ipaddress '*' port 443 ret {'name' name 'changes' {} 'comment' str 'result' None}binding_info _get_binding_info hostheader ipaddress port current_cert_bindings __salt__['win_iis.list_cert_bindings'] site if binding_info not in current_cert_bindings ret['comment'] 'Certificatebindinghasalreadybeenremoved {0}'.format name ret['result'] Trueelif __opts__['test'] ret['comment'] 'Certificatebindingwillberemoved {0}'.format name ret['changes'] {'old' name 'new' None}else current_name current_cert_bindings[binding_info]['certificatehash']if name current_name ret['comment'] 'Removedcertificatebinding {0}'.format name ret['changes'] {'old' name 'new' None}ret['result'] __salt__['win_iis.remove_cert_binding'] name site hostheader ipaddress port return ret
def valid_hook hook_file hook_name filename os.path.basename hook_file basename os.path.splitext filename [0]matching_hook basename hook_name supported_hook basename in _HOOKS backup_file filename.endswith '~' return matching_hook and supported_hook and not backup_file
def dist_is_local dist return is_local dist_location dist
def ldd_deps filename ret None if not os.path.exists filename filename salt.utils.which filename if ret is None ret []out __salt__['cmd.run'] 'ldd' filename python_shell False for line in out.splitlines if not line.strip continuedep_path ''if ' >' in line comps line.split ' >' dep_comps comps[1].strip .split if os.path.exists dep_comps[0] dep_path dep_comps[0]else dep_comps line.strip .split if os.path.exists dep_comps[0] dep_path dep_comps[0]if dep_path if dep_path not in ret ret.append dep_path new_deps ldd_deps dep_path ret for dep in new_deps if dep not in ret ret.append dep return ret
def delete_service name restart True out __mgmt name 'service' 'delete' if restart if out 'success' return __firewall_cmd '--reload' return out
def _retry_on_deadlock f @functools.wraps f def wrapped *args **kwargs while True try return f *args **kwargs except db_exc.DBDeadlock LOG.warn _ "Deadlockdetectedwhenrunning'% func_name s' Retrying..." dict func_name f.__name__ time.sleep 0.5 continuefunctools.update_wrapper wrapped f return wrapped
def mysql_timestamp_converter s if s[4] '-' return DateTime_or_None s s s + '0' * 14 - len s parts map int filter None s[ 4] s[4 6] s[6 8] s[8 10] s[10 12] s[12 14] try return Timestamp *parts except SystemExit KeyboardInterrupt raiseexcept return None
def argmin seq func return min seq key func
def test_install_folder_using_dot_slash script script.scratch_path.join 'mock' .mkdir pkg_path script.scratch_path / 'mock' pkg_path.join 'setup.py' .write mock100_setup_py result script.pip 'install' './mock' egg_folder script.site_packages / 'mock-100.1-py%s.egg-info' % pyversion assert egg_folder in result.files_created str result
def get_unicode_writer stream sys.stdout encoding None errors u'replace' encoding encoding or get_preferred_output_encoding if sys.version_info < 3 or not hasattr stream u'buffer' return lambda s stream.write s.encode encoding errors else return lambda s stream.buffer.write s.encode encoding errors
def test_multilabel X y make_multilabel_classification n_classes 2 n_labels 1 allow_unlabeled False random_state 123 clf OneVsRestClassifier SVC kernel 'linear' eclf VotingClassifier estimators [ 'ovr' clf ] voting 'hard' try eclf.fit X y except NotImplementedError return
def get_minion_data minion opts grains Nonepillar Noneif opts.get 'minion_data_cache' False cache salt.cache.Cache opts if minion is None for id_ in cache.list 'minions' data cache.fetch 'minions/{0}'.format id_ 'data' if data is None continueelse data cache.fetch 'minions/{0}'.format minion 'data' if data is not None grains data['grains']pillar data['pillar']return minion if minion else None grains pillar
def speedx clip factor None final_duration None if final_duration factor 1.0 * clip.duration / final_duration newclip clip.fl_time lambda t factor * t apply_to ['mask' 'audio'] if clip.duration is not None newclip newclip.set_duration 1.0 * clip.duration / factor return newclip
def get_doctype_stats index stats {}from kitsune.search.models import get_mapping_typesfor cls in get_mapping_types if cls.get_index index s S cls .indexes index stats[cls.get_mapping_type_name ] s.count return stats
def _normal_order_terms expr recursive_limit 10 _recursive_depth 0 new_terms []for term in expr.args if isinstance term Mul new_term _normal_order_factor term recursive_limit recursive_limit _recursive_depth _recursive_depth new_terms.append new_term else new_terms.append term return Add *new_terms
def assembleFormattedText formatted return _textattributes.flatten formatted _FormattingState 'toMIRCControlCodes'
def _get_head_file_path config return os.path.join _get_root_versions_dir config HEAD_FILENAME
def vagrant_settings name '' *args **kwargs name _name_or_host_string name config ssh_config name extra_args _settings_dict config kwargs.update extra_args return settings *args **kwargs
def memoize_important_follower_config dict_ dict_['memoized_config'] {'include_tags' include_tags 'exclude_tags' exclude_tags}
def _get_status_id_by_name status_name return LINODE_STATUS.get status_name {} .get 'code' None
def find predicate seq for element in seq if predicate element return elementreturn None
def net_device_verification net_device print_attr ['hostname' 'ip' 'username' 'password' 'device_type' 'vendor' 'model' 'os_version' 'uptime' 'serial_number']for field in print_attr val getattr net_device field print '%15s %-40s' % field val print
def setup_wizard_complete if getattr settings 'SHUUP_ENABLE_MULTIPLE_SHOPS' False return Trueshop Shop.objects.first complete configuration.get shop 'setup_wizard_complete' if complete is None return not setup_wizard_visible_panes shop return complete
def test_ipy_dash_S ipi IronPythonInstance executable exec_prefix extraArgs + '-S' AreEqual ipi.Start True response ipi.ExecuteLine 'importsys' response ipi.ExecuteLine 'printsys.path' Assert response.find 'Lib' ! -1
def _table_columns first_table_row positions []start 1while start < len first_table_row end first_table_row.find '+' start if end -1 breakpositions.append start end start end + 1 return positions
def add_implicit_resolver tag regexp first None Loader Loader Dumper Dumper Loader.add_implicit_resolver tag regexp first Dumper.add_implicit_resolver tag regexp first
def compress_dhist dh head tail dh[ -10 ] dh[ -10 ] newhead []done set for h in head if h in done continuenewhead.append h done.add h return newhead + tail
def iframe_close request response_format 'html' return render_to_response 'core/iframe_close' {} context_instance RequestContext request response_format response_format
def solow_analytic_solution t k0 g n s alpha delta lmbda n + g + delta * 1 - alpha k_t s / n + g + delta * 1 - np.exp - lmbda * t + k0 ** 1 - alpha * np.exp - lmbda * t ** 1 / 1 - alpha analytic_traj np.hstack t[ np.newaxis] k_t[ np.newaxis] return analytic_traj
def get_dc_info session ds_ref dc_info _DS_DC_MAPPING.get ds_ref.value if not dc_info dcs session._call_method vim_util 'get_objects' 'Datacenter' ['name' 'datastore' 'vmFolder'] _update_datacenter_cache_from_objects session dcs dc_info _DS_DC_MAPPING.get ds_ref.value return dc_info
def req_missing names purpose python True optional False if not isinstance names tuple or isinstance names list or isinstance names set names names if not names return Falseif python whatarethey_s u'Pythonpackage'whatarethey_p u'Pythonpackages'else whatarethey_s whatarethey_p u'software'if len names 1 msg u'Inorderto{0} youmustinstallthe"{1}"{2}.'.format purpose names[0] whatarethey_s else most u'" "'.join names[ -1 ] pnames most + u'"and"' + names[ -1 ] msg u'Inorderto{0} youmustinstallthe"{1}"{2}.'.format purpose pnames whatarethey_p if optional LOGGER.warn msg else LOGGER.error msg LOGGER.error u'Exitingduetomissingdependencies.' sys.exit 5 return msg
def compile_extra typingctx targetctx func args return_type flags locals library None pipeline Pipeline typingctx targetctx library args return_type flags locals return pipeline.compile_extra func
def GeekNoneDBConnectOnly func def wrapper *args **kwargs GeekNote.skipInitConnection Truereturn func *args **kwargs return wrapper
def are_similar e1 e2 from .exceptions import GeometryErrorif e1 e2 return Truetry return e1.is_similar e2 except AttributeError try return e2.is_similar e1 except AttributeError n1 e1.__class__.__name__n2 e2.__class__.__name__raise GeometryError 'Cannottestsimilaritybetween%sand%s' % n1 n2
def ipv6_to_int ip return type_desc.Int16.to_user addrconv.ipv6.text_to_bin ip
def get_init_anonymous_user User kwargs {User.USERNAME_FIELD guardian_settings.ANONYMOUS_USER_NAME}user User **kwargs user.set_unusable_password return user
def get_environment return settings.environment
def py_encode_basestring_ascii s if isinstance s str and HAS_UTF8.search s is not None s s.decode 'utf-8' def replace match s match.group 0 try return ESCAPE_DCT[s]except KeyError n ord s if n < 65536 return '\\u{0 04x}'.format n else n - 65536s1 55296 | n >> 10 & 1023 s2 56320 | n & 1023 return '\\u{0 04x}\\u{1 04x}'.format s1 s2 return '"' + str ESCAPE_ASCII.sub replace s + '"'
def find_backref_chain obj predicate max_depth 20 extra_ignore return _find_chain obj predicate gc.get_referrers max_depth max_depth extra_ignore extra_ignore
def _hash data algorithm if algorithm 'SHA-256' return sha256 data .hexdigest else return md5 data .hexdigest
def draw_text im position text color 0 0 255 cv2.putText im text position cv2.FONT_HERSHEY_SIMPLEX 1.5 color 1 return im
def get_resource_uri_template resource include_child if resource.name 'root' path '/api/'else if resource._parent_resource path get_resource_uri_template resource._parent_resource True path + '%s/' % resource.uri_name if not resource.singleton and include_child and resource.model path + '{%s}/' % resource.uri_object_key return path
def text_value value if value is None return u''return force_text value
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def create_process progname sensor return subprocess.Popen CMDLINE % {'progname' progname 'sensor' SENSORS.get sensor sensor } shell True stdin subprocess.PIPE
def dbl_from_geom func num_geom 1 argtypes [GEOM_PTR for i in xrange num_geom ]argtypes + [POINTER c_double ]func.argtypes argtypesfunc.restype c_intfunc.errcheck check_dblreturn func
def escapeForContent data if isinstance data unicode data data.encode 'utf-8' data data.replace '&' '&amp;' .replace '<' '&lt;' .replace '>' '&gt;' return data
def get_webapp_global_conf global_conf dict global_conf.update _get_static_settings return global_conf
def unquote_unreserved uri try parts uri.split '%' for i in range 1 len parts h parts[i][0 2]if len h 2 and h.isalnum c chr int h 16 if c in UNRESERVED_SET parts[i] c + parts[i][2 ] else parts[i] '%' + parts[i] else parts[i] '%' + parts[i] return ''.join parts except ValueError return uri
def shb response if py3k h response.getheaders else h [] key value None None for line in response.msg.headers if line if line[0] in ' DCTB ' value + line.strip else if key and value h.append key value key value line.split ' ' 1 key key.strip value value.strip if key and value h.append key value return '%s%s' % response.status response.reason h response.read
def fill_price_worse_than_limit_price fill_price order if order.limit if order.direction > 0 and fill_price > order.limit or order.direction < 0 and fill_price < order.limit return Truereturn False
def int2hexstr num intsize 4 if intsize 8 if num < 0 result struct.pack '<q' num else result struct.pack '<Q' num elif num < 0 result struct.pack '<l' num else result struct.pack '<L' num return result
def to_xml items msg [u'<?xmlversion "1.0"?>' u'<items>']for item in items msg.append item.to_xml msg.append u'</items>' return u''.join msg
def windowed_histogram image selem out None mask None shift_x False shift_y False n_bins None if n_bins is None n_bins int image.max + 1 return _apply_vector_per_pixel generic_cy._windowed_hist image selem out out mask mask shift_x shift_x shift_y shift_y out_dtype np.double pixel_size n_bins
def StyledWidget_paintEvent self event opt QStyleOption opt.initFrom self painter QPainter self self.style .drawPrimitive QStyle.PE_Widget opt painter self
def category category return {'0' '0' '1' 'phishing' '2' 'webattack' '3' 'infectious' '4' 'payloads' '5' 'mailer' '6' 'arduino' '7' 'sms' '8' 'wireless' '9' 'modules' '10' 'cloner' '11' 'harvester' '12' 'tabnapping' '13' 'teensy' '14' 'binary2teensy' '15' 'dll_hijacking' '16' 'multiattack' '17' 'java_applet' '18' 'encoding' '19' 'fasttrack' '20' 'autopwn' '21' 'mssql' '22' 'scan' '23' 'direct' '24' 'exploits' '25' 'active_target' '26' 'shell' '27' 'set' '28' 'teensy2powershell' '29' 'powershell' '30' 'delldrac' '31' 'ridenum' '32' 'psexec' '33' 'fsattack'}.get category 'ERROR'
def RemoveDuplicateDependencies targets for target_name target_dict in targets.iteritems for dependency_key in dependency_sections dependencies target_dict.get dependency_key [] if dependencies target_dict[dependency_key] Unify dependencies
def circulant c c np.asarray c .ravel a b np.ogrid[0 len c 0 - len c -1 ]indx a + b return c[indx]
def calc_entropy string import mathalphabet 0other set seen set lastset Nonestring to_unicode string for c in string inset othersetfor cset in lowerset upperset numberset sym1set sym2set if c in cset inset csetbreakif inset not in seen seen.add inset alphabet + len inset elif c not in other alphabet + 1other.add c if inset is not lastset alphabet + 1lastset csetentropy len string * math.log alphabet / 0.6931471805599453 return round entropy 2
def plot_gallery images titles h w n_row 3 n_col 4 plt.figure figsize 1.8 * n_col 2.4 * n_row plt.subplots_adjust bottom 0 left 0.01 right 0.99 top 0.9 hspace 0.35 for i in range n_row * n_col plt.subplot n_row n_col i + 1 plt.imshow images[i].reshape h w cmap plt.cm.gray plt.title titles[i] size 12 plt.xticks plt.yticks
def resnet_v2_50 inputs num_classes None is_training True global_pool True output_stride None reuse None scope 'resnet_v2_50' blocks [resnet_utils.Block 'block1' bottleneck [ 256 64 1 ] * 2 + [ 256 64 2 ] resnet_utils.Block 'block2' bottleneck [ 512 128 1 ] * 3 + [ 512 128 2 ] resnet_utils.Block 'block3' bottleneck [ 1024 256 1 ] * 5 + [ 1024 256 2 ] resnet_utils.Block 'block4' bottleneck [ 2048 512 1 ] * 3 ]return resnet_v2 inputs blocks num_classes is_training is_training global_pool global_pool output_stride output_stride include_root_block True reuse reuse scope scope
def _availables_plugins url try descriptor urlopen url plugins json_manager.read_json_from_stream descriptor return pluginsexcept URLError return {}
def gci return gci._current
def automodule name attributes []obj importlib.import_module name for attrname in dir obj value getattr obj attrname if getattr value u'__module__' None ! name continueif inspect.isclass value attributes.append get_class_info value name if inspect.isfunction value attributes.append get_function_info value return {u'members' filter None attributes u'docs' get_obj_doc obj }
def valid_ip ip_address octets ip_address.split '.' if len octets ! 4 return Falsefor i octet in enumerate octets try octets[i] int octet except ValueError return False first_octet second_octet third_octet fourth_octet octetsif first_octet < 1 return Falseelif first_octet > 223 return Falseelif first_octet 127 return Falseif first_octet 169 and second_octet 254 return Falsefor octet in second_octet third_octet fourth_octet if octet < 0 or octet > 255 return Falsereturn True
def clean_html html if html is None return htmlhtml html.replace u'\n' u'' html re.sub u'\\s*<\\s*br\\s*/?\\s*>\\s*' u'\n' html html re.sub u'<\\s*/\\s*p\\s*>\\s*<\\s*p[^>]*>' u'\n' html html re.sub u'<.*?>' u'' html html unescapeHTML html return html.strip
def auth_disallow_anonymous_access action @functools.wraps action def wrapper context data_dict return action context data_dict wrapper.auth_allow_anonymous_access Falsereturn wrapper
def lookup_package_plugin package_type None if package_type is None return _default_package_pluginreturn _package_plugins.get package_type _default_package_plugin
@decorators.memoizedef _check_mkfile return salt.utils.which 'mkfile'
def parsestream stream encoding None stack engine.FilterStack stack.full_analyze return stack.run stream encoding
def test_description_on_big_sentenced_steps feature Feature.from_string FEATURE4 assert_equals feature.description 'Asacleverguy\nIwanttodescribethisFeature\nSothatIcantakecareofmyScenario'
def _dict_with_children_specs specs result {}for spec in specs if not spec['deleted'] result.update {spec['key'] spec['value']} return result
def fakeTargetFunction pass
def small_ego_G edges [ 'a' 'b' 'a' 'c' 'b' 'c' 'b' 'd' 'b' 'e' 'b' 'f' 'c' 'd' 'c' 'f' 'c' 'h' 'd' 'f' 'e' 'f' 'f' 'h' 'h' 'j' 'h' 'k' 'i' 'j' 'i' 'k' 'j' 'k' 'u' 'a' 'u' 'b' 'u' 'c' 'u' 'd' 'u' 'e' 'u' 'f' 'u' 'g' 'u' 'h' 'u' 'i' 'u' 'j' 'u' 'k' ]G nx.Graph G.add_edges_from edges return G
def db_null_instance_uuid_scan delete False engine get_engine meta sqlalchemy.MetaData bind engine meta.reflect engine processed {}for table in reversed meta.sorted_tables if table.name not in 'fixed_ips' 'shadow_fixed_ips' processed[table.name] _process_null_records table 'instance_uuid' check_fkeys True delete delete for table_name in 'instances' 'shadow_instances' table db_utils.get_table engine table_name processed[table.name] _process_null_records table 'uuid' check_fkeys False delete delete return processed
def _crawl_attribute this_data this_attr if isinstance this_data list t_list []for d in this_data t_list.append _crawl_attribute d this_attr return t_listelif isinstance this_attr dict t_dict {}for k in this_attr.keys if hasattr this_data k t_dict[k] _crawl_attribute getattr this_data k None this_attr[k] return t_dictelif isinstance this_attr list this_dict {}for l in this_attr this_dict dictupdate.update this_dict _crawl_attribute this_data l return this_dictelse return {this_attr _recurse_config_to_dict getattr this_data this_attr None }
def get_precision currency global _cacheif _cache is None _cache _generate_cache return _cache[currency]
def index_field_from_django_field f default CharField result defaultif f.get_internal_type in u'DateField' u'DateTimeField' result DateTimeFieldelif f.get_internal_type in u'BooleanField' u'NullBooleanField' result BooleanFieldelif f.get_internal_type in u'CommaSeparatedIntegerField' result MultiValueFieldelif f.get_internal_type in u'DecimalField' u'FloatField' result FloatFieldelif f.get_internal_type in u'IntegerField' u'PositiveIntegerField' u'PositiveSmallIntegerField' u'SmallIntegerField' result IntegerFieldreturn result
def test_ast_invalid_unary_op cant_compile u' not234 ' cant_compile u' not ' cant_compile u' not234 ' cant_compile u' ~2234 ' cant_compile u' ~ '
def test_ascii_dash o nikola.utils.slugify u'hello-world' lang u'en' assert o u'hello-world' assert isinstance o nikola.utils.unicode_str
def _fill inst_class frequencies ctype_info inst_class.get_flat_type_info inst_class cfreq_key inst_class 0 for k v in ctype_info.items if v.Attributes.min_occurs > 0 frequencies[cfreq_key][k] 0
def validate_dictionary_string_length specs if not isinstance specs dict msg _ 'specsmustbeadictionary.' raise exception.InvalidInput reason msg for key value in specs.items if key is not None check_string_length key 'Key"%s"' % key min_length 1 max_length 255 if value is not None check_string_length value 'Valueforkey"%s"' % key min_length 0 max_length 255
@RegisterWithArgChecks name 'neighbor.out_filter.set' req_args [neighbors.IP_ADDRESS neighbors.OUT_FILTER] def set_neighbor_out_filter neigh_ip_address filters core CORE_MANAGER.get_core_service peer core.peer_manager.get_by_addr neigh_ip_address peer.out_filters filtersreturn True
def enumerate_plugins dirpath module_prefix namespace class_ attributes {} if os.path.isfile dirpath dirpath os.path.dirname dirpath for fname in os.listdir dirpath if fname.endswith '.py' and not fname.startswith '__init__' module_name _ os.path.splitext fname importlib.import_module '%s.%s' % module_prefix module_name plugins []for subclass in class_.__subclasses__ if module_prefix ! '.'.join subclass.__module__.split '.' [ -1 ] continuenamespace[subclass.__name__] subclassfor key value in attributes.items setattr subclass key value plugins.append subclass return plugins
def get_dashboard slug orgname None profile 'grafana' if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.get '{0}/api/dashboards/db/{1}'.format profile['grafana_url'] slug auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 data response.json if response.status_code 404 return Noneif response.status_code > 400 response.raise_for_status return data.get 'dashboard'
def get_memcached_hosts if not memcache return Nonecache_info settings.CACHES[DEFAULT_FORWARD_CACHE_ALIAS]backend cache_info[u'BACKEND']locations cache_info.get u'LOCATION' [] if not backend.startswith u'django.core.cache.backends.memcached' or not locations return []if not isinstance locations list locations [locations]return locations
def hidden path return os.path.split path [1].startswith '.'
def chart_popup return {}
def GetResourceLimits logging_context error_fh sys.stderr resource_limits DEFAULT_RESOURCE_LIMITS.copy StatusUpdate 'Gettingcurrentresourcelimits.' error_fh resource_limits.update _GetRemoteResourceLimits logging_context logging.debug 'Usingresourcelimits %s' resource_limits return resource_limits
def __mgmt name _type action cmd '--{0}-{1} {2}--permanent'.format action _type name return __firewall_cmd cmd
def modify_test id **data models.Test.smart_get id .update_object data
def checks_existence model def decorated func '\nDecoratorfortheexistencefunction.\n'_MODEL_EXISTS[model] funcreturn funcreturn decorated
def _load_preview_module request descriptor student_data KvsFieldData SessionKeyValueStore request if has_author_view descriptor wrapper partial CmsFieldData student_data student_data else wrapper partial LmsFieldData student_data student_data wrapped_field_data wrapper descriptor._field_data preview_runtime _preview_module_system request descriptor wrapped_field_data descriptor.bind_for_student preview_runtime request.user.id [wrapper] return descriptor
def normalize_signature sig if isinstance sig str parsed _parse_signature_string sig else parsed sigif isinstance parsed tuple args return_type parsed None elif isinstance parsed typing.Signature args return_type parsed.args parsed.return_type else raise TypeError 'invalidsignature %rinstancenotallowed' % sig.__class__.__name__ def check_type ty if not isinstance ty types.Type raise TypeError 'invalidsignature expectedatypeinstance got%r' % ty if return_type is not None check_type return_type for ty in args check_type ty return args return_type
@frappe.whitelist def get_backup delete_temp_backups odb BackupGenerator frappe.conf.db_name frappe.conf.db_name frappe.conf.db_password db_host frappe.db.host odb.get_backup recipient_list odb.send_email frappe.msgprint _ u'Downloadlinkforyourbackupwillbeemailedonthefollowingemailaddress {0}' .format u' '.join recipient_list
def label_present name value node None apiserver None ret __salt__['k8s.label_present'] name value node apiserver return ret
def assertVolumesEqual test first second first first.get_filesystem .get_path second second.get_filesystem .get_path def get_contents path result {}for child in path.children if child.isdir value get_contents child else value child.getContent result[child.basename ] valuereturn resulttest.assertEqual get_contents first get_contents second
def dontListen thread_id None global oscThreadsif thread_id and thread_id in oscThreads ids [thread_id]else ids list oscThreads.keys for thread_id in ids Logger.debug 'OSC Stopthread<%s>' % thread_id oscThreads[thread_id].isRunning FalseoscThreads[thread_id].join Logger.debug 'OSC Stopthread<%s>finished' % thread_id del oscThreads[thread_id]
def build_dependency_list deps version_prefix u'' return sorted [ u'%s%s%s' % dep_name version_prefix dep_version for dep_name dep_version in deps.items ] key lambda s s.lower
def media_endpoint _id file_ app.media.get _id if file_ is None return abort 404 if_modified_since weak_date request.headers.get 'If-Modified-Since' if if_modified_since is not None if if_modified_since.tzinfo is None if_modified_since if_modified_since.replace tzinfo tz_util.utc if if_modified_since > file_.upload_date return Response status 304 headers {'Last-Modified' date_to_rfc1123 file_.upload_date 'Content-Length' file_.length}response Response file_ headers headers mimetype file_.content_type direct_passthrough True return response
def limited_epoch_train file_path max_epochs 1 train load_train_file file_path train.algorithm.termination_criterion EpochCounter max_epochs max_epochs train.main_loop
@step 'Icreatealogrecordwith' def step_I_create_logrecord_with_table context assert context.table 'REQUIRE context.table'assert len context.table.rows 1 'REQUIRE table.row.size 1'step_I_create_logrecords_with_table context
def check_cs_op result func cargs if result 0 raise GEOSException 'Couldnotsetvalueoncoordinatesequence' else return result
@bp.route '/<urlname>' def view urlname node Node.query.filter_by urlname urlname .first_or_404 page force_int request.args.get 'page' 1 0 if not page return abort 404 paginator Topic.query.filter_by node_id node.id .order_by Topic.id.desc .paginate page paginator.items fill_topics paginator.items status Noneif g.user status NodeStatus.query.filter_by account_id g.user.id node_id node.id .first return render_template 'node/view.html' node node paginator paginator status status
def agent_self consul_url None ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retfunction 'agent/self'ret _query consul_url consul_url function function method 'GET' query_params query_params return ret
def activity_create context activity_dict **kw _check_access 'activity_create' context activity_dict if 'ignore_auth' in kw raise Exception 'ActivityStreamcallingparametershavechangedignore_authmustbepassedinthecontextnotasaparam' if not paste.deploy.converters.asbool config.get 'ckan.activity_streams_enabled' 'true' returnmodel context['model']if getattr model.Session 'revision' None activity_dict['revision_id'] model.Session.revision.idelse activity_dict['revision_id'] Noneschema context.get 'schema' or ckan.logic.schema.default_create_activity_schema data errors _validate activity_dict schema context if errors raise ValidationError errors activity model_save.activity_dict_save data context if not context.get 'defer_commit' model.repo.commit log.debug "Created'%s'activity" % activity.activity_type return model_dictize.activity_dictize activity context
def libvlc_media_player_get_xwindow p_mi f _Cfunctions.get 'libvlc_media_player_get_xwindow' None or _Cfunction 'libvlc_media_player_get_xwindow' 1 None ctypes.c_uint32 MediaPlayer return f p_mi
def check_package_data_first command class DecoratedCommand command def run self check_package_data self.package_data command.run self return DecoratedCommand
def word_features table features numpy.zeros len table 620 dtype 'float32' keys table.keys for i in range len table f table[keys[i]]features[i] f / norm f return features
@superuser_requireddef site_settings request form_class template_name u'admin/settings.html' return djblets_site_settings request form_class template_name {u'root_path' settings.SITE_ROOT + u'admin/db/' }
def stop_cover hass entity_id None data {ATTR_ENTITY_ID entity_id} if entity_id else None hass.services.call DOMAIN SERVICE_STOP_COVER data
def download_package_dict package_name global download_count not_found_countdownload_count + 1if download_count % 1000 0 logger.info 'Downloaded%spackages %snotfound ' download_count not_found_count response session.get 'https //pypi.python.org/pypi/%s/json' % package_name if response.status_code requests.codes.ok return response.json elif response.status_code requests.codes.not_found not_found_count + 1else logger.warning 'Unexpectederrorcodeforpackage%s %s' package_name response.status_code
def read_from_matrix matrix str1 str2 result '' i j len str1 len str2 while i ! 0 and j ! 0 if matrix[i][j] matrix[ i - 1 ][j] i - 1elif matrix[i][j] matrix[i][ j - 1 ] j - 1else result + str1[ i - 1 ]i - 1j - 1return result[ -1 ]
def virtual_interface_get context vif_id return IMPL.virtual_interface_get context vif_id
def test_undefined_step_represent_string feature_file ojoin 'runner_features' 'first.feature' feature Feature.from_file feature_file step feature.scenarios[0].steps[0]assert_equals step.represent_string step.sentence 'GivenIdonothing#tests/functional/output_features/runner_features/first.feature 7\n' assert_equals step.represent_string 'foobar' 'foobar#tests/functional/output_features/runner_features/first.feature 7\n'
def create_membership **kwargs project kwargs.pop 'project' ProjectFactory project.points.add PointsFactory.create project project value None defaults {'project' project 'user' UserFactory.create 'role' RoleFactory.create project project permissions list map lambda x x[0] MEMBERS_PERMISSIONS }defaults.update kwargs return MembershipFactory.create **defaults
def get_user_id username rv query_db 'selectuser_idfromuserwhereusername ?' [username] one True return rv[0] if rv else None
def find_existing_anchors soup existing_anchors set for tag in soup.find_all True for attr in [u'id' u'name'] if tag.has_attr attr existing_anchors.add tag.get attr return existing_anchors
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def wrap_message message width MAX_LINE_LENGTH lines message.split '\n' wrapped_lines [textwrap.fill line width expand_tabs False replace_whitespace False drop_whitespace False break_on_hyphens False for line in lines]wrapped_message '\n'.join wrapped_lines return wrapped_message
def _ImportDeployTemplate deploy_template 'viewfinder.backend.prod.deploy.{0}'.format sys.argv[1] __import__ deploy_template servers sys.modules[deploy_template].__dict__['servers'][0]setup_script sys.modules[deploy_template].__dict__['setup_script'][0]return servers setup_script
def _translate_output output sensors_data_dict {}sensors_data_array output.split '\n\n' for sensor_data in sensors_data_array sensor_data_dict _process_sensor sensor_data if not sensor_data_dict continuesensor_type _get_sensor_type sensor_data_dict sensor_id sensor_data_dict['SensorID']if 'SensorReading' in sensor_data_dict sensors_data_dict.setdefault sensor_type {} [sensor_id] sensor_data_dictif not sensors_data_dict raise ipmiexcept.IPMIException _ 'parseIPMIsensordatafailed Nodataretrievedfromgiveninput' return sensors_data_dict
def InterruptibleQueueJoin queue thread_local thread_pool queue_join_thread_factory QueueJoinThread check_workers True thread queue_join_thread_factory queue thread.start while True thread.join timeout 0.5 if not thread.isAlive return Trueif thread_local.shut_down logger.debug 'Queuejoininterrupted' return Falseif check_workers for worker_thread in thread_pool.Threads if not worker_thread.isAlive return False
def c_moves client cmds client.exitsreturn 'look' if not cmds else cmds
def check_classification_toy name ForestClassifier FOREST_CLASSIFIERS[name]clf ForestClassifier n_estimators 10 random_state 1 clf.fit X y assert_array_equal clf.predict T true_result assert_equal 10 len clf clf ForestClassifier n_estimators 10 max_features 1 random_state 1 clf.fit X y assert_array_equal clf.predict T true_result assert_equal 10 len clf leaf_indices clf.apply X assert_equal leaf_indices.shape len X clf.n_estimators
@block_user_agents@login_required@permission_required 'wiki.delete_document' @check_readonly@process_document_pathdef delete_document request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug prevent document.children.exists first_revision document.revisions.all [0]if request.method 'POST' form DocumentDeletionForm data request.POST if form.is_valid DocumentDeletionLog.objects.create locale document.locale slug document.slug user request.user reason form.cleaned_data['reason'] document.delete return redirect document else form DocumentDeletionForm context {'document' document 'form' form 'request' request 'revision' first_revision 'prevent' prevent}return render request 'wiki/confirm_document_delete.html' context
def property_mock request cls prop_name **kwargs _patch patch.object cls prop_name new_callable PropertyMock **kwargs request.addfinalizer _patch.stop return _patch.start
def GetFieldValue field if not field return Nonevalue field.value .string_value value_type field.value .type if value_type in TEXT_DOCUMENT_FIELD_TYPES return valueif value_type document_pb.FieldValue.DATE return DeserializeDate value if value_type document_pb.FieldValue.NUMBER return float value raise TypeError 'Noconversiondefinedfortype%s' % value_type
def load_certificate_from_path path key_filename cert_filename cert_path path.child cert_filename key_path path.child key_filename certificate load_certificate_file cert_path keypair load_key_file key_path return keypair certificate
def set_file name source template None context None defaults None **kwargs ret {'name' name 'changes' {} 'result' True 'comment' ''}if context is None context {}elif not isinstance context dict ret['result'] Falseret['comment'] 'Contextmustbeformedasadict'return retif defaults is None defaults {}elif not isinstance defaults dict ret['result'] Falseret['comment'] 'Defaultsmustbeformedasadict'return retif __opts__['test'] ret['result'] Noneret['comment'] 'Debconfselectionswouldhavebeenset.'return retif template result __salt__['debconf.set_template'] source template context defaults **kwargs else result __salt__['debconf.set_file'] source **kwargs if result ret['comment'] 'Debconfselectionswereset.'else ret['result'] Falseret['comment'] 'Unabletosetdebconfselectionsfromfile.'return ret
def pre_scm_buildstep registry xml_parent data bsp XML.SubElement xml_parent 'org.jenkinsci.plugins.preSCMbuildstep.PreSCMBuildStepsWrapper' bs XML.SubElement bsp 'buildSteps' for step in data for edited_node in create_builders registry step bs.append edited_node
def snippet func func._snippet Truereturn func
def CodesearchEntryFromString xml_string return atom.CreateClassFromXMLString CodesearchEntry xml_string
def parse_egg_info path info {}for line in open path encoding u'utf-8' line line.strip m pat.match line if m key m.group 1 .lower info[key] m.group 2 try return u'% name s-% version s-<pip>' % info except KeyError passreturn None
def isorted to_sort return sorted to_sort key lambda x x.lower
def is_list_like value return isinstance value Iterable and not isinstance value base dict
def string_from_path path if not path return ''path [_path_part_escape compat.to_unicode s for s in path]if not all map RE_ELEMENT.match path get_logger .warn "Cannotconvertpathtostring keyscontaininvalidcharacters shouldbealpha-numericorunderscore '%s'" % path string PATH_STRING_SEPARATOR_CHAR.join path return string
def set_format fmt 'xml' global ws_formatif fmt 'xml' ws_format fmtset_parser elif fmt 'json' ws_format fmtwarn 'Thejsonformatisnon-officialandmaychangeatanytime' set_parser json.loads else raise ValueError 'invalidformat %s' % fmt
def cmd_action parent cmd fn *hotkeys return qtutils.add_action parent cmd.name lambda cmds.do cmd fn *hotkeys
def benjamini_hochberg_step_down pvals tmp fdr_correction pvals corrected_vals empty len pvals max_pval 1.0for i in argsort pvals [ -1 ] if tmp[i] < max_pval corrected_vals[i] tmp[i]max_pval tmp[i]else corrected_vals[i] max_pvalreturn corrected_vals
def queens_solved organisms for org in organisms if org.fitness len org.genome return 1return 0
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def atleast_3d *arys res []for a in arys if not isinstance a cupy.ndarray raise TypeError 'Onlycupyarrayscanbeatleast_3d' if a.ndim 0 a a.reshape 1 1 1 elif a.ndim 1 a a[None None]elif a.ndim 2 a a[ None]res.append a if len res 1 res res[0]return res
def isValid text return any word in text.upper for word in WORDS
def _get_full_output node for_output False ret {}for item in six.iterkeys node value node[item]if value is not None and for_output value str value ret[item] valuereturn ret
def insert_system_roles system_roles SystemRole.get_valid_values for role_name in system_roles description role_namerole_db RoleDB name role_name description description system True try Role.insert role_db log_not_unique_error_as_debug True except StackStormDBObjectConflictError NotUniqueError pass
def get_locales_by_visit start_date end_date cache_key 'locales_sorted_by_visits {start} {end}'.format start start_date end end_date sorted_locales cache.get cache_key if sorted_locales is None try results visitors_by_locale start_date end_date locales_and_visits results.items sorted_locales list reversed sorted locales_and_visits key lambda x x[1] cache.add cache_key sorted_locales CACHE_TIMEOUT except GoogleAPIError Oauth2Error OpenSSLError log.exception 'SomethingwentwronggettingvisitorsbylocalefromGoogleAnalytics.Nobodygota500though.' sorted_locales [ l 0 for l in settings.SUMO_LANGUAGES]return sorted_locales
def last_update_time STAMP '/var/lib/apt/periodic/fabtools-update-success-stamp'if not is_file STAMP return -1 return getmtime STAMP
def _output_to_list cmdoutput return [item for line in cmdoutput.splitlines if _safe_output line for item in line.split ]
def _purge _cache.clear
def assert_application_calculated_changes case node_state node_config nonmanifest_datasets expected_changes additional_node_states frozenset additional_node_config frozenset deployer ApplicationNodeDeployer hostname node_state.hostname node_uuid node_state.uuid docker_client FakeDockerClient return assert_calculated_changes_for_deployer case deployer node_state node_config nonmanifest_datasets additional_node_states additional_node_config expected_changes NodeLocalState node_state node_state
def delete_ref refname oldvalue None assert refname.startswith 'refs/' oldvalue [] if not oldvalue else [oldvalue] p subprocess.Popen ['git' 'update-ref' '-d' refname] + oldvalue preexec_fn _gitenv _git_wait 'gitupdate-ref' p
def isErrorNode node return node and node.getType 'error'
def bulk_update_delete context data_dict _check_access 'bulk_update_delete' context data_dict _bulk_update_dataset context data_dict {'state' 'deleted'}
def get_price_info context product quantity 1 mod ctx _get_module_and_context context price_info mod.get_price_info ctx product quantity for module in get_discount_modules price_info module.discount_price ctx product price_info return price_info
def _wrap_with_before action responder if 'resource' in get_argnames action shim actionelse def shim req resp resource kwargs action req resp kwargs @wraps responder def do_before self req resp **kwargs shim req resp self kwargs responder self req resp **kwargs return do_before
def is_task_successful request task_id response_data {'task' {'id' task_id 'executed' AsyncResult task_id .successful }}return HttpResponse serialize response_data mimetype 'application/json'
def leaves_list Z Z np.asarray Z order 'c' is_valid_linkage Z throw True name 'Z' n Z.shape[0] + 1 ML np.zeros n dtype 'i' [Z] _copy_arrays_if_base_present [Z] _hierarchy.prelist Z ML int n return ML
def _mac_ver_gestalt try import gestaltimport MacOSexcept ImportError return None sysv sysa _mac_ver_lookup 'sysv' 'sysa' if sysv major sysv & 65280 >> 8 minor sysv & 240 >> 4 patch sysv & 15 if major minor > 10 4 major minor patch _mac_ver_lookup 'sys1' 'sys2' 'sys3' release '%i.%i.%i' % major minor patch else release '%s.%i.%i' % _bcd2str major minor patch if sysa machine {1 '68k' 2 'PowerPC' 10 'i386'}.get sysa '' return release versioninfo machine
def get_attrs str return _scanner.scan str [0]
def map32 id pos NOUN global _map32_cacheif not _map32_cache _map32_cache open os.path.join MODULE 'dict' 'index.32' .readlines _map32_cache x for x in _map32_cache if x[0] ! ';' _map32_cache dict x.strip .split '' for x in _map32_cache k pos in _map32_pos2 and pos or _map32_pos1.get pos 'x' k + str id .lstrip '0' k _map32_cache.get k None if k is not None return int k[1 ] _map32_pos2[k[0]] return None
def download_daily_bars sourceCode tableCode year csvFile authToken None bars download_csv sourceCode tableCode datetime.date year 1 1 datetime.date year 12 31 'daily' authToken f open csvFile 'w' f.write bars f.close
def archiver typename archiver _ARCHIVER_BY_TYPE.get typename if not archiver raise ValueError u'Noarchiverregisteredfor{!r}'.format typename return archiver
def split_at_corner_index contour index segments []index [ i + 1 for i in index]for s e in zip [0] + index index + [10000000] segments.append contour[s e + 1 ] return segments
@task help {'args' 'Commandlineargsforbehave' 'format' 'Formattertouse'} def behave_test ctx args '' format '' format format or ctx.behave_test.format options ctx.behave_test.options or '' args args or ctx.behave_test.args behave '{python}bin/behave'.format python sys.executable ctx.run '{behave}-f{format}{options}{args}'.format behave behave format format options options args args pty USE_PTY
def select_bracket_style option minimap style 0if not minimap style | sublime.HIDE_ON_MINIMAPif option 'outline' style | sublime.DRAW_NO_FILLelif option 'none' style | sublime.HIDDENelif option 'underline' style | sublime.DRAW_EMPTY_AS_OVERWRITEelif option 'thin_underline' style | sublime.DRAW_NO_FILLstyle | sublime.DRAW_NO_OUTLINEstyle | sublime.DRAW_SOLID_UNDERLINEelif option 'squiggly' style | sublime.DRAW_NO_FILLstyle | sublime.DRAW_NO_OUTLINEstyle | sublime.DRAW_SQUIGGLY_UNDERLINEelif option 'stippled' style | sublime.DRAW_NO_FILLstyle | sublime.DRAW_NO_OUTLINEstyle | sublime.DRAW_STIPPLED_UNDERLINEreturn style
def search pattern string flags 0 pos None endpos None partial False concurrent None **kwargs return _compile pattern flags kwargs .search string pos endpos concurrent partial
def _callback_argspec callback if not callable callback raise ValueError 'Callbacksmustbecallables' if isfunction callback or ismethod callback return getargspec callback elif isinstance callback partial return getargspec callback.func else return getargspec callback.__call__
def print_fcode expr **settings print fcode expr **settings
def _get_toplevel path user None password None return _git_run ['git' 'rev-parse' '--show-toplevel'] cwd path user user password password ['stdout']
def get_or_create_user_cart user cart_queryset Cart.objects.all return cart_queryset.open .get_or_create user user [0]
def make_temp_path path new_ext None root ext os.path.splitext path if new_ext is None new_ext exttemp_path root + TEMP_EXTENSION + new_ext return temp_path
def TaskMessage1 name id None args kwargs {} callbacks None errbacks None chain None **options from celery import uuidfrom kombu.serialization import dumpsid id or uuid message Mock name u'TaskMessage-{0}'.format id message.headers {}message.payload {u'task' name u'id' id u'args' args u'kwargs' kwargs u'callbacks' callbacks u'errbacks' errbacks}message.payload.update options message.content_type message.content_encoding message.body dumps message.payload return message
def reactivate domain_name opts salt.utils.namecheap.get_opts 'namecheap.domains.reactivate' opts['DomainName'] domain_nameresponse_xml salt.utils.namecheap.post_request opts if response_xml is None return {}domainreactivateresult response_xml.getElementsByTagName 'DomainReactivateResult' [0]return salt.utils.namecheap.xml_to_dict domainreactivateresult
def get_plural_form word if word not in _PLURAL_FORMS plural prompt_user 'Whatisthepluralformof"%s"[%ss] ' % word word default word + 's' _PLURAL_FORMS[word] pluralreturn _PLURAL_FORMS[word]
def getLang if getattr threadLocal 'currentLang' None return threadLocal.currentLangelse return currentLang
def rgb2lab rgb illuminant 'D65' observer '2' return xyz2lab rgb2xyz rgb illuminant observer
def GetModuleName return gflags._GetCallingModule
def batched_tensordot x y axes 2 return _tensordot_as_dot x y axes dot batched_dot batched True
def test_fairy registry xml_parent data platform data.get 'platform' valid_platforms ['android' 'ios']if 'platform' not in data raise MissingAttributeError 'platform' if platform 'android' root XML.SubElement xml_parent 'org.jenkinsci.plugins.testfairy.TestFairyAndroidRecorder' helpers.test_fairy_common root data mappings [ 'proguard-file' 'mappingFile' '' 'keystorepath' 'keystorePath' None 'storepass' 'storepass' 'android' 'alias' 'alias' 'androiddebugkey' 'keypass' 'keypass' '' ]helpers.convert_mapping_to_xml root data mappings fail_required True elif platform 'ios' root XML.SubElement xml_parent 'org.jenkinsci.plugins.testfairy.TestFairyIosRecorder' helpers.test_fairy_common root data mappings [ 'dSYM-file' 'mappingFile' '' ]helpers.convert_mapping_to_xml root data mappings fail_required True else raise InvalidAttributeError 'platform' platform valid_platforms
def config_true_value value return value is True or isinstance value basestring and value.lower in TRUE_VALUES
@pytest.yield_fixture autouse True def application app create_app Config ctx app.app_context ctx.push yield app ctx.pop
def hash_combination combination bits []for variable value in six.iteritems combination if isinstance variable six.integer_types and isinstance value six.integer_types bits.append u'%d %d' % variable value else bits.append u'%d %d' % variable.pk value.pk bits.sort raw_combination u' '.join bits hashed_combination hashlib.sha1 force_bytes raw_combination .hexdigest return hashed_combination
def _step3 state marked state.marked 1 state.col_uncovered[np.any marked axis 0 ] Falseif marked.sum < state.C.shape[0] return _step4
def rindex s *args return s.rindex *args
def _prune_array array if array.base is not None and array.size < array.base.size // 2 return array.copy return array
def fake_support_backend_values name default None config_dict {'CONTACT_FORM_SUBMISSION_BACKEND' 'email' 'email_from_address' TEST_SUPPORT_EMAIL}return config_dict[name]
def log_exceptions logger def decorator func @wraps func def wrapper *args **kwargs try result func *args **kwargs except Exception logger.exception u'Uncaughtexceptionwhilerunning{0}'.format func.__name__ raisereturn resultreturn wrapperreturn decorator
def acl_list consul_url None **kwargs ret {}data {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif 'id' not in kwargs ret['message'] 'Requiredparameter"id"ismissing.'ret['res'] Falsereturn retfunction 'acl/list'ret _query consul_url consul_url data data method 'PUT' function function return ret
def git_info path command ['git' 'log' '-1' '--format %H\n%s\n%cD'] sha msg date check_output command cwd path .decode 'utf8' .splitlines return dict sha sha date date msg msg
def do_endpoints cs args catalog cs.client.service_catalog.catalogfor e in catalog['access']['serviceCatalog'] utils.print_dict e['endpoints'][0] e['name']
def no_loops_in_hierarchy key data errors context if not 'id' in data returngroup context['model'].Group.get data['id'] allowable_parents group.groups_allowed_to_be_its_parent type group.type for parent in data['groups'] parent_name parent['name']if parent_name and context['model'].Group.get parent_name not in allowable_parents raise Invalid _ 'Thisparentwouldcreatealoopinthehierarchy'
def test_get_event_data raw mne.io.read_raw_fif raw_fname preload True verbose False picks mne.pick_types raw.info meg 'grad' eeg False eog True stim True exclude raw.info['bads'] event_id tmin tmax 2 -0.1 0.3 epochs Epochs raw events event_id event_id tmin tmin tmax tmax picks picks baseline None preload True proj False data epochs.get_data [0 ]rt_client MockRtClient raw rt_data rt_client.get_event_data event_id event_id tmin tmin tmax tmax picks picks stim_channel 'STI014' assert_array_equal rt_data data
def _select_block str_in start_tag end_tag start_pos str_in.find start_tag if start_pos < 0 raise ValueError 'start_tagnotfound' depth 0for pos in range start_pos len str_in if str_in[pos] start_tag depth + 1elif str_in[pos] end_tag depth - 1if depth 0 breaksel str_in[ start_pos + 1 pos]return sel
def thumbgen_filename filename name ext op.splitext filename return '%s_thumb%s' % name ext
def _margeff_cov_params_count model cov_margins params exog count_ind method J for i in count_ind exog0 exog.copy exog0[ i] - 1dfdb0 model._derivative_predict params exog0 method exog0[ i] + 2dfdb1 model._derivative_predict params exog0 method dfdb dfdb1 - dfdb0 if dfdb.ndim > 2 dfdb dfdb.mean 0 / 2 if J > 1 K dfdb.shape[1] / J - 1 cov_margins[i K ] dfdbelse cov_margins[i ] dfdbreturn cov_margins
def variations iterable optional lambda x False iterable tuple iterable o [optional x for x in iterable]a set for p in product [False True] repeat sum o p list p v [ b and b and p.pop 0 for b in o]v tuple iterable[i] for i in range len v if not v[i] a.add v return sorted a cmp lambda x y len y - len x
def set_cookie_data storage messages invalid False encode_empty False encoded_data storage._encode messages encode_empty encode_empty if invalid encoded_data encoded_data[1 ]storage.request.COOKIES {CookieStorage.cookie_name encoded_data}if hasattr storage '_loaded_data' del storage._loaded_data
def iswritable f if not six.PY2 and hasattr f 'writable' return f.writable if hasattr f 'closed' and f.closed raise ValueError 'I/Ooperationonclosedfile' if not hasattr f 'write' return Falseif hasattr f 'mode' and not any c in f.mode for c in 'wa+' return Falsereturn True
def assertIsNot first second msg '' a b first second assert a is not b '%s %ris%r' % msg.format a b a b
def _to_db_dict namespace_id resource_type_id model_dict db_dict {'namespace_id' namespace_id 'resource_type_id' resource_type_id 'properties_target' model_dict['properties_target'] 'prefix' model_dict['prefix']}return db_dict
def rax_argument_spec return dict api_key dict type 'str' aliases ['password'] no_log True auth_endpoint dict type 'str' credentials dict type 'str' aliases ['creds_file'] env dict type 'str' identity_type dict type 'str' default 'rackspace' region dict type 'str' tenant_id dict type 'str' tenant_name dict type 'str' username dict type 'str' verify_ssl dict choices BOOLEANS type 'bool'
def mean_of_targets dataset return dataset.y.mean axis 0
def listen target identifier fn *args **kw _event_key target identifier fn .listen *args **kw
def compose *funcs **kfuncs return reduce lambda f g lambda *args **kaargs f g *args **kaargs funcs
def _get_node_change_list exploration_id property_name new_value return [{'cmd' collection_domain.CMD_EDIT_COLLECTION_NODE_PROPERTY 'exploration_id' exploration_id 'property_name' property_name 'new_value' new_value}]
def _merge_extraconfig existing changes existing existing or [] if changes for c in changes if len [x for x in existing if x.key c.key ] > 0 extraConf [x for x in existing if x.key c.key ][0]extraConf.value c.valueelse existing.append c return existing
def convert_to_ascii chatbot statement import unicodedataimport sysif sys.version_info[0] < 3 statement.text unicode statement.text text unicodedata.normalize 'NFKD' statement.text text text.encode 'ascii' 'ignore' .decode 'utf-8' statement.text str text return statement
def is_mongo_running output os.popen 'mongo--eval"print \'running\' "' .read return output and 'running' in output
def _filter_transactions qs data filter_mapping {'app' 'addon_id' 'transaction_type' 'type' 'transaction_id' 'uuid' 'date_from' 'created__gte' 'date_to' 'created__lte'}for form_field db_field in filter_mapping.iteritems if data.get form_field try qs qs.filter **{db_field data[form_field]} except ValueError continuereturn qs
def computeUserPass userPassString dictO fileID pElement keyLength 128 revision 3 encryptMetadata False userPass ''dictU ''dictOE ''dictUE ''ret computeEncryptionKey userPassString dictO dictU dictOE dictUE fileID pElement keyLength revision encryptMetadata if ret[0] ! -1 rc4Key ret[1]else return retif revision 2 userPass RC4 paddingString rc4Key elif revision > 2 counter 1md5Input paddingString + fileID hashResult hashlib.md5 md5Input .digest userPass RC4 hashResult rc4Key while counter < 19 newKey ''for i in range len rc4Key newKey + chr ord rc4Key[i] ^ counter userPass RC4 userPass newKey counter + 1counter 0while counter < 16 userPass + chr random.randint 32 255 counter + 1return 0 userPass
def fourier_uniform input size n -1 axis -1 output None input numpy.asarray input output return_value _get_output_fourier output input axis _ni_support._check_axis axis input.ndim sizes _ni_support._normalize_sequence size input.ndim sizes numpy.asarray sizes dtype numpy.float64 if not sizes.flags.contiguous sizes sizes.copy _nd_image.fourier_filter input sizes n axis output 1 return return_value
def group_type_create context values projects None return IMPL.group_type_create context values projects
def import_course_from_xml *args **kwargs manager CourseImportManager *args **kwargs return list manager.run_imports
def iirnotch w0 Q return _design_notch_peak_filter w0 Q 'notch'
@auth_signals.unconfirmed_user_created.connectdef queue_no_addon_email user mails.queue_mail to_addr user.username mail mails.NO_ADDON send_at timezone.now + settings.NO_ADDON_WAIT_TIME user user fullname user.fullname
def _cycle_permute l if len l 1 return lmin_item min l key default_sort_key indices [i for i x in enumerate l if x min_item ]le list l le.extend l indices.append len l + indices[0] sublist [[le[indices[i] indices[ i + 1 ]]] for i in range len indices - 1 ]idx sublist.index min sublist ordered_l le[indices[idx] indices[idx] + len l ]return ordered_l
def _check_start_stop raw start stop return [ c if isinstance c int or c is None else raw.time_as_index c [0] for c in start stop ]
def update_nested original_dict updates dict_to_update copy.deepcopy original_dict for key value in six.iteritems updates if isinstance value dict sub_dict update_nested dict_to_update.get key {} value dict_to_update[key] sub_dictelse dict_to_update[key] updates[key]return dict_to_update
def reorder_suite suite classes reverse False class_count len classes suite_class type suite bins [OrderedSet for i in range class_count + 1 ]partition_suite_by_type suite classes bins reverse reverse reordered_suite suite_class for i in range class_count + 1 reordered_suite.addTests bins[i] return reordered_suite
def TR22 rv max 4 pow False def f rv if not isinstance rv Pow and rv.base.func in cot tan return rvrv _TR56 rv tan sec lambda x x - 1 max max pow pow rv _TR56 rv cot csc lambda x x - 1 max max pow pow return rvreturn bottom_up rv f
def hash_seed seed None max_bytes 8 if seed is None seed _seed max_bytes max_bytes hash hashlib.sha512 str seed .encode 'utf8' .digest return _bigint_from_bytes hash[ max_bytes]
def set_gpu_from_theano if config.device.startswith 'gpu' and len config.device > 3 os.environ['CUDA_DEVICE'] theano.config.device[3 ]elif config.init_gpu_device.startswith 'gpu' and len config.init_gpu_device > 3 os.environ['CUDA_DEVICE'] theano.config.init_gpu_device[3 ]
def _get_runner classpath main jvm_options args executor cwd distribution create_synthetic_jar synthetic_jar_dir executor executor or SubprocessExecutor distribution safe_cp classpathif create_synthetic_jar safe_cp safe_classpath classpath synthetic_jar_dir logger.debug u'Bundlingclasspath{}into{}'.format u' '.join classpath safe_cp return executor.runner safe_cp main args args jvm_options jvm_options cwd cwd
def DocFileSuite *paths **kw suite unittest.TestSuite if kw.get 'module_relative' True kw['package'] _normalize_module kw.get 'package' for path in paths suite.addTest DocFileTest path **kw return suite
def send_approved_mail request user context {u'request' request u'user' user}subject subject_template u'email/account_approved_subject.txt' context send_mail_template subject u'email/account_approved' settings.DEFAULT_FROM_EMAIL user.email context context
def _copy_number_format other copy NumberFormat pattern other.pattern format other.format leading_digits_pattern list other.leading_digits_pattern national_prefix_formatting_rule other.national_prefix_formatting_rule national_prefix_optional_when_formatting other.national_prefix_optional_when_formatting domestic_carrier_code_formatting_rule other.domestic_carrier_code_formatting_rule copy._mutable Truereturn copy
def stts2penntreebank token tag return token stts.get tag tag
def get_translations languages None translations get_builtin_gnu_translations languages if hasattr translations 'ugettext' return DefaultTranslations translations else return translations
def _func_on_containers logger conf concurrency_key func bench Bench logger conf [] pool eventlet.GreenPool int getattr conf concurrency_key for container in conf.containers pool.spawn_n func bench.url bench.token container pool.waitall
def getPublicTypeMembers type_ onlyValues False for name value in inspect.getmembers type_ if not name.startswith '__' if not onlyValues yield name value else yield value
def _parse_content content password contentsalt Nonesalt_slug u'salt 'try sep content.rindex salt_slug except ValueError passelse salt password[ sep + len salt_slug ]password content[ sep]return password salt
def localcontext ctx None if ctx is None ctx getcontext return _ContextManager ctx
def prepare annotations def expand_annotation annotation if isinstance annotation dict return MapAnnotation annotation elif isinstance annotation string_t return mlazy instantiate annotation return annotationif annotations is None return elif not isinstance annotations list tuple annotations annotations return [expand_annotation anno for anno in annotations]
def build_name_function max_int max_int + 1e-08pad_length int math.ceil math.log10 max_int def name_function i return str i .zfill pad_length return name_function
def basic_search request template u'search/search.html' load_all True form_class ModelSearchForm searchqueryset None extra_context None results_per_page None query u''results EmptySearchQuerySet if request.GET.get u'q' form form_class request.GET searchqueryset searchqueryset load_all load_all if form.is_valid query form.cleaned_data[u'q']results form.search else form form_class searchqueryset searchqueryset load_all load_all paginator Paginator results results_per_page or RESULTS_PER_PAGE try page paginator.page int request.GET.get u'page' 1 except InvalidPage raise Http404 u'Nosuchpageofresults!' context {u'form' form u'page' page u'paginator' paginator u'query' query u'suggestion' None}if results.query.backend.include_spelling context[u'suggestion'] form.get_suggestion if extra_context context.update extra_context return render request template context
def split_code_at_show text parts []is_doctest contains_doctest text part []for line in text.split '\n' if not is_doctest and line.strip 'plt.show ' or is_doctest and line.strip '>>>plt.show ' part.append line parts.append '\n'.join part part []else part.append line if '\n'.join part .strip parts.append '\n'.join part return parts
def timestampMac32 value if not isinstance value float int long raise TypeError 'anintegerorfloatisrequired' if not 0 < value < 4294967295 return _ 'invalidMactimestamp %s ' % value return MAC_TIMESTAMP_T0 + timedelta seconds value
def _get_metadata field expr metadata_expr no_metadata_rule if isinstance metadata_expr bz.Expr or metadata_expr is None return metadata_exprtry return expr._child['_'.join expr._name or '' field ]except ValueError AttributeError if no_metadata_rule 'raise' raise ValueError 'no%stablecouldbereflectedfor%s' % field expr elif no_metadata_rule 'warn' warnings.warn NoMetaDataWarning expr field stacklevel 4 return None
def captured_stdin return captured_output 'stdin'
def play_complicated paths my_paths copy.copy paths def next_song my_paths.pop 0 p.play_file my_paths[0] p GstPlayer next_song p.run p.play_file my_paths[0] while my_paths time.sleep 1
def calc_baseline_error_to_observed_error baseline_error est_error return float baseline_error / float est_error
@handle_response_format@treeio_login_required@module_admin_required def index_modules request response_format 'html' modules Module.objects.all .order_by 'title' return render_to_response 'core/administration/index_modules' {'modules' modules} context_instance RequestContext request response_format response_format
def setsebool boolean value persist False if persist cmd 'setsebool-P{0}{1}'.format boolean value else cmd 'setsebool{0}{1}'.format boolean value return not __salt__['cmd.retcode'] cmd python_shell False
def getBaseObject object if inspect.isbuiltin object dropSelf 0elif inspect.ismethod object try if object.im_self is None dropSelf 0else dropSelf 1object object.im_funcexcept AttributeError dropSelf 0elif inspect.isclass object constructor getConstructor object if constructor is not None object constructordropSelf 1else dropSelf 0elif callable object try object object.__call__.im_funcdropSelf 1except AttributeError dropSelf 0else dropSelf 0return object dropSelf
def _selfOfMethod methodObject if _PY3 return methodObject.__self__return methodObject.im_self
def _set_gps_from_zone kwargs location zone if zone is not None kwargs['gps'] zone.attributes['latitude'] zone.attributes['longitude'] kwargs['gps_accuracy'] zone.attributes['radius']kwargs['location_name'] locationreturn kwargs
def _PytreeNodeRepr node if isinstance node pytree.Node return '%s %s %r ' % node.__class__.__name__ NodeName node [_PytreeNodeRepr c for c in node.children] if isinstance node pytree.Leaf return '%s %s %r ' % node.__class__.__name__ NodeName node node.value
def _queryRPMTags rpmfile taglist queryFormat RECORD_SEPARATOR.join [ '[%%{%s}%s]' % tag UNIT_SEPARATOR for tag in taglist] def parseTagValues output res {}for tag values in zip taglist output.split RECORD_SEPARATOR values values.strip UNIT_SEPARATOR .split UNIT_SEPARATOR res[tag] valuesreturn resdef checkErrorResult failure failure.trap IOError if str failure.value .startswith "gotstderr 'error " newFailure Failure SkipTest "rpmismissingitspackagedatabase.Run'sudorpm-qa>/dev/null'tocreateone." else newFailure failured failure.value.processEndedd.addBoth lambda _ newFailure return dd utils.getProcessOutput 'rpm' '-q' '--queryformat' queryFormat '-p' rpmfile d.addCallbacks parseTagValues checkErrorResult return d
def bounding_box bw bh w h new_width new_height w h if bw and new_width > bw new_width bwnew_height new_width / float w / h if bh and new_height > bh new_height bhnew_width new_height * float w / h return new_width new_height
def CDLLADDERBOTTOM barDs count return call_talib_with_ohlc barDs count talib.CDLLADDERBOTTOM
def survey_updateMetaData record qtype metadata metatable current.s3db.survey_question_metadataquestion_id record.idif isinstance metadata str metadata_list json2py metadata else metadata_list metadatafor desc value in metadata_list.items desc desc.strip if not isinstance value str value json.dumps value value value.strip metatable.insert question_id question_id descriptor desc value value if qtype 'Grid' widget_obj survey_question_type['Grid'] widget_obj.insertChildren record metadata_list
def VaryRate start end saturate_epochs epoch if saturate_epochs < 0 return startstep start - end / saturate_epochs - 1 if epoch < saturate_epochs return start - step * epoch else return end
def index if mode_task s3_redirect_default URL f 'project' vars {'tasks' 1} else s3_redirect_default URL f 'project'
def vb_machinestate_to_str machinestate return vb_machinestate_to_tuple machinestate [0]
def update_featured_activity_references featured_activity_references for activity_reference in featured_activity_references activity_reference.validate activity_hashes [reference.get_hash for reference in featured_activity_references]if len activity_hashes ! len set activity_hashes raise Exception 'Theactivityreferencelistshouldnothaveduplicates.' featured_model_instance activity_models.ActivityReferencesModel.get_or_create activity_models.ACTIVITY_REFERENCE_LIST_FEATURED featured_model_instance.activity_references [reference.to_dict for reference in featured_activity_references]featured_model_instance.put
def CheckReference request_trusted request_app_id key require_id_or_name True assert isinstance key entity_pb.Reference CheckAppId request_trusted request_app_id key.app Check key.path .element_size > 0 "key'spathcannotbeempty" if require_id_or_name last_element key.path .element_list [ -1 ]has_id_or_name last_element.has_id and last_element.id ! 0 or last_element.has_name and last_element.name ! '' if not has_id_or_name raise datastore_errors.BadRequestError 'missingkeyid/name' for elem in key.path .element_list Check not elem.has_id or not elem.has_name 'eachkeypathelementshouldhaveidornamebutnotboth %r' % key
@register u'capitalize-word' def capitalize_word event buff event.current_bufferfor i in range event.arg pos buff.document.find_next_word_ending words buff.document.text_after_cursor[ pos]buff.insert_text words.title overwrite True
def getRAM totalRAM available psutil.virtual_memory [0 2]return totalRAM / 1048576.0 available / 1048576.0
def default_path default_sheets_dir os.environ.get 'DEFAULT_CHEAT_DIR' or os.path.join '~' '.cheat' default_sheets_dir os.path.expanduser os.path.expandvars default_sheets_dir if not os.path.isdir default_sheets_dir try os.umask 0 os.mkdir default_sheets_dir except OSError die 'CouldnotcreateDEFAULT_CHEAT_DIR' if not os.access default_sheets_dir os.R_OK die 'TheDEFAULT_CHEAT_DIR ' + default_sheets_dir + ' isnotreadable.' if not os.access default_sheets_dir os.W_OK die 'TheDEFAULT_CHEAT_DIR ' + default_sheets_dir + ' isnotwritable.' return default_sheets_dir
def make_plot source xname yname line_color xdr None ydr None if xdr is None xdr DataRange1d if ydr is None ydr DataRange1d plot Plot x_range xdr y_range ydr min_border 50 plot.add_layout LinearAxis 'below' plot.add_layout LinearAxis 'left' plot.add_glyph source Line x xname y yname line_color line_color plot.add_tools PanTool WheelZoomTool return plot
def getCraftedTextFromText gcodeText repository None if gcodec.isProcedureDoneOrFileIsEmpty gcodeText 'chamber' return gcodeTextif repository None repository settings.getReadRepository ChamberRepository if not repository.activateChamber.value return gcodeTextreturn ChamberSkein .getCraftedGcode gcodeText repository
def decodeIntToUnicode value retVal valueif isinstance value int try if value > 255 _ '%x' % value if len _ % 2 1 _ '0%s' % _ retVal getUnicode hexdecode _ encoding 'UTF-16' if Backend.isDbms DBMS.MSSQL else None else retVal getUnicode chr value except retVal INFERENCE_UNKNOWN_CHARreturn retVal
def display_pygraphviz graph path format None prog None args '' if format is None filename path.nameformat os.path.splitext filename [1].lower [1 ]if not format format Nonegraph.draw path format prog args path.close nx.utils.default_opener filename
def _dummy name token expr **kwargs d _dummy_ name token **kwargs if d in expr.free_symbols return Dummy name **kwargs return d
def forecast location params None url '{}/{}'.format api location headers {'Accept-Encoding' 'gzip'}r requests.get url params params headers headers if r.status_code ! 200 raise WeatherException 'Yourkeyisinvalidorforecast.ioisdown' r r.json if 'error' in r raise WeatherException 'Errorgettingweather {}'.format r['error'] r['error'] return r
def fast_queue bytes_left NzbQueue.do.remaining paused Downloader.do.pausedbpsnow BPSMeter.do.get_bps time_left calc_timeleft bytes_left bpsnow return paused bytes_left bpsnow time_left
def messageid uniq None N idGenerator .next datetime time.strftime '%Y%m%d%H%M%S' time.gmtime pid os.getpid rand random.randrange 2 ** 31 - 1 if uniq is None uniq ''else uniq '.' + uniq return '<%s.%s.%s%s.%s@%s>' % datetime pid rand uniq N DNSNAME
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def buildgraph cursor include_last_hop False include_target False only_connected True graph {}entry_nodes set for host in cursor if 'traces' not in host continuefor trace in host['traces'] hops trace['hops']hops.sort key lambda hop hop['ttl'] if not hops continueentry_nodes.add hops[0]['ipaddr'] if not include_last_hop and not include_target if hops[ -1 ]['ipaddr'] host['addr'] hops.pop if not include_last_hop hops.pop for i hop in enumerate hops[1 ] if not only_connected or hop['ttl'] - hops[i]['ttl'] 1 graph.setdefault hops[i]['ipaddr'] set .update [hop['ipaddr']] return graph entry_nodes
def _bashcomplete cmd prog_name complete_var None if complete_var is None complete_var '_%s_COMPLETE' % prog_name.replace '-' '_' .upper complete_instr os.environ.get complete_var if not complete_instr returnfrom ._bashcomplete import bashcompleteif bashcomplete cmd prog_name complete_var complete_instr sys.exit 1
def remove_metadata module_data start_line start_col end_line end_col lines module_data.split '\n' new_lines lines[ start_line]if start_col ! 0 new_lines.append lines[start_line][ start_col] next_line lines[end_line]if len next_line - 1 ! end_col new_lines.append next_line[end_col ] if len lines > end_line new_lines.extend lines[ end_line + 1 ] return '\n'.join new_lines
def ion matplotlib.interactive True install_repl_displayhook
def test_lambda_list_keywords_mixed can_compile u' fn x&restxs&kwargskw listxxskw ' cant_compile u' fn x&restxs&fasfkey{bar"baz"} ' if PY3 can_compile u' fn[x&restxs&kwargskwxs&kwonlykwoxs] listxxskwxskwoxs '
def variance_scaling factor 2.0 mode 'FAN_IN' uniform False seed None dtype tf.float32 if variance_scaling_initializer is None raise NotImplementedError "'variance_scaling_initializer'notsupported pleaseupdateTensorFlow." return variance_scaling_initializer factor factor mode mode uniform uniform seed seed dtype dtype
def argparse_type variable for action in helpful_parser.parser._actions if action.type is not None and action.dest variable return action.typereturn str
def _count_leading line ch i n 0 len line while i < n and line[i] ch i + 1return i
def select_best_encoding outstream None outstream outstream or sys.stdout encoding getattr outstream 'encoding' None or sys.getdefaultencoding if is_ascii_encoding encoding return 'utf-8'return encoding
def MonkeyPatchThreadingLocal _threading_local @staticmethoddef New cls *args **kw self object.__new__ cls key '_local__key' 'thread.local.' + str id self object.__setattr__ self '_local__key' key object.__setattr__ self '_local__args' args kw object.__setattr__ self '_local__lock' _threading_local.RLock if args or kw and cls.__init__ is object.__init__ raise TypeError 'Initializationargumentsarenotsupported' dict object.__getattribute__ self '__dict__' _threading_local.current_thread .__dict__[key] dictreturn self_threading_local._localbase.__new__ New
def cartesian_product X msg 'Inputmustbealist-likeoflist-likes'if not is_list_like X raise TypeError msg for x in X if not is_list_like x raise TypeError msg if len X 0 return []lenX np.fromiter len x for x in X dtype int cumprodX np.cumproduct lenX a np.roll cumprodX 1 a[0] 1if cumprodX[ -1 ] ! 0 b cumprodX[ -1 ] / cumprodX else b np.zeros_like cumprodX return [np.tile np.repeat np.asarray com._values_from_object x b[i] np.product a[i] for i x in enumerate X ]
def network_get_associated_fixed_ips context network_id host None return IMPL.network_get_associated_fixed_ips context network_id host
@treeio_login_required@handle_response_formatdef source_add request response_format 'html' if not request.user.profile.is_admin 'treeio.sales' return user_denied request message "Youdon'thaveadministratoraccesstotheSalesmodule" if request.POST if 'cancel' not in request.POST source SaleSource form SaleSourceForm request.user.profile request.POST instance source if form.is_valid source form.save source.set_user_from_request request return HttpResponseRedirect reverse 'sales_source_view' args [source.id] else return HttpResponseRedirect reverse 'sales_settings_view' else form SaleSourceForm request.user.profile all_products Object.filter_by_request request Product.objects.filter parent__isnull True all_sources Object.filter_by_request request SaleSource.objects return render_to_response 'sales/source_add' {'form' form 'sources' all_sources 'products' all_products} context_instance RequestContext request response_format response_format
def _openstack_verify_from_config verify_peer True verify_ca_path None **config if verify_peer if verify_ca_path verify verify_ca_pathelse verify Trueelse verify Falsereturn verify
@register_specialize@register_stabilize@gof.local_optimizer [T.fill] def local_fill_to_alloc node if node.op T.fill r v node.inputsif v.type node.outputs[0].type rval [v]elif v.type.broadcastable node.outputs[0].type.broadcastable rval [T.cast v node.outputs[0].type.dtype ]elif r.type.broadcastable node.outputs[0].type.broadcastable o broadcast_like v r node.fgraph dtype v.dtype copy_stack_trace node.outputs[0] o rval [o]else returnassert rval[0].type node.outputs[0].type 'rval' rval[0].type 'orig' node.outputs[0].type 'node' node return rval
def check_file_output filename force console.logger.debug 'Checkingfileoutput' if os.path.isfile filename and not force answer console.ask 'File{0}alreadyexists!Overwriteit?[y/N]' filename if answer.lower ! 'y' sys.exit return FileOutput filename
def DifferentialOperators base generator ring DifferentialOperatorAlgebra base generator return ring ring.derivative_operator
@receiver post_save sender CourseEnrollment def assign_default_role_on_enrollment sender instance **kwargs assign_default_role instance.course_id instance.user
def _topo_to_sph topo assert topo.ndim 2 and topo.shape[1] 2 sph np.ones len topo 3 sph[ 1] - np.deg2rad topo[ 0] sph[ 2] np.pi * topo[ 1] return sph
def _extractReturnURL endpoint if endpoint.matchTypes [RP_RETURN_TO_URL_TYPE] return endpoint.urielse return None
def whichmodule func funcname mod getattr func '__module__' None if mod is not None return modif func in classmap return classmap[func]for name module in sys.modules.items if module is None continueif name ! '__main__' and getattr module funcname None is func breakelse name '__main__'classmap[func] namereturn name
def query_series api_key user_token member_name None params {}if member_name member_id query_member_id api_key user_token member_name if member_id params {u'id' member_id}else log.error u'member%rnotfound' % member_name return []r requests.get API_URL_PREFIX + u'members/infos' params params headers {u'Accept' u'application/json' u'X-BetaSeries-Version' u'2.1' u'X-BetaSeries-Key' api_key u'X-BetaSeries-Token' user_token} assert r.status_code 200 u'BadHTTPstatuscode %s' % r.status_code j r.json error_list j[u'errors']for err in error_list log.error str err if not error_list return [x[u'title'] for x in j[u'member'][u'shows'] if x[u'user'][u'archived'] is False ]else return []
def extract_from_dir dirname None method_map DEFAULT_MAPPING options_map None keywords DEFAULT_KEYWORDS comment_tags callback None strip_comment_tags False if dirname is None dirname os.getcwd if options_map is None options_map {}absname os.path.abspath dirname for root dirnames filenames in os.walk absname for subdir in dirnames if subdir.startswith '.' or subdir.startswith '_' dirnames.remove subdir dirnames.sort filenames.sort for filename in filenames filepath os.path.join root filename .replace os.sep '/' for message_tuple in check_and_call_extract_file filepath method_map options_map callback keywords comment_tags strip_comment_tags dirpath absname yield message_tuple
def urivalue uri uri uri[ uri.find ' ' + 1 -1 ].strip if uri and uri[0] in '\'"' and uri[0] uri[ -1 ] return stringvalue uri else return uri
def rev_list_range start end revrange u'%s..%s' % start end out git.rev_list revrange pretty u'oneline' [STDOUT]return parse_rev_list out
def timestampWin64 value try return WIN64_TIMESTAMP_T0 + durationWin64 value except OverflowError raise ValueError _ 'datenewerthanyear%s value %s ' % MAXYEAR value
def is_conservative field if field Vector 0 return Trueframe list field.separate [0]return curl field frame .simplify Vector 0
def GetCleanEnvironment env os.environ.copy old_virtual_prompt env.pop '_OLD_VIRTUAL_PROMPT' None if old_virtual_prompt env['PROMPT'] old_virtual_promptold_virtual_path env.pop '_OLD_VIRTUAL_PATH' None if old_virtual_path env['PATH'] old_virtual_pathreturn env
def yesno value arg None if arg is None arg gettext 'yes no maybe' bits arg.split ' ' if len bits < 2 return valuetry yes no maybe bitsexcept ValueError yes no maybe bits[0] bits[1] bits[1] if value is None return maybeif value return yesreturn no
def mainProjectionsLinesAndCircles params None if not params params {'testlength' 400}win Window monitor 'LightCrafter4500' screen 1 fullscr True color 'gray' useFBO True autoLog False warper Warper win warp 'spherical' warpfile '' warpGridsize 128 eyepoint [0.5 0.5] flipHorizontal False flipVertical False g ProjectionsLinesAndCircles win warper for i in range int params['testlength'] * 60 g.update_sweep i win.close
def eval_args f f._pox_eval_args Truereturn f
def get_cli_body_ssh_vrrp command response module if 'xml' in response[0] body []elif 'showrun' in command body responseelse try response response[0].replace command + '\n\n' '' .strip body [json.loads response ]except ValueError module.fail_json msg 'CommanddoesnotsupportJSONoutput' command command return body
def open_firewalld service return sequence [run_from_args ['firewall-cmd' '--reload'] ] + [run_from_args command + [service] for command in [['firewall-cmd' '--permanent' '--add-service'] ['firewall-cmd' '--add-service']]]
def qc_results params alpha score qc_tol qc_verbose False assert not np.isnan params .max assert params params.ravel 'F' .min 'paramsshouldhavealreadybeen1-d'fprime score params k_params len params passed_array np.array [True] * k_params for i in range k_params if alpha[i] > 0 if abs fprime[i] - alpha[i] / alpha[i] > qc_tol passed_array[i] Falseqc_dict dict fprime fprime alpha alpha params params passed_array passed_array passed passed_array.min if not passed num_failed passed_array False .sum message 'QCcheckdidnotpassfor%doutof%dparameters' % num_failed k_params message + '\nTryincreasingsolveraccuracyornumberofiterations decreasingalpha orswitchsolvers'if qc_verbose message + _get_verbose_addon qc_dict print message return passed
def request_httprepr request parsed urlparse_cached request path urlunparse '' '' parsed.path or '/' parsed.params parsed.query '' s '%s%sHTTP/1.1\r\n' % request.method path s + 'Host %s\r\n' % parsed.hostname if request.headers s + request.headers.to_string + '\r\n' s + '\r\n's + request.bodyreturn s
def migrate_common_facts facts params {'node' 'portal_net' 'master' 'portal_net'}if 'common' not in facts facts['common'] {}for role in params.keys if role in facts for param in params[role] if param in facts[role] facts['common'][param] facts[role].pop param return facts
def is_last_random_cohort user_group random_cohorts CourseUserGroup.objects.filter course_id user_group.course_id group_type CourseUserGroup.COHORT cohort__assignment_type CourseCohort.RANDOM return len random_cohorts 1 and random_cohorts[0].name user_group.name
def specificity_score y_true y_pred labels None pos_label 1 average 'binary' sample_weight None _ s _ sensitivity_specificity_support y_true y_pred labels labels pos_label pos_label average average warn_for 'specificity' sample_weight sample_weight return s
def inverse_mod a m if a < 0 or m < a a a % m c d a m uc vc ud vd 1 0 0 1 while c ! 0 q c d divmod d c + c uc vc ud vd ud - q * uc vd - q * vc uc vc assert d 1 if ud > 0 return udelse return ud + m
def get_operation_data year quarter if ct._check_input year quarter is True ct._write_head data _get_operation_data year quarter 1 pd.DataFrame if data is not None data['code'] data['code'].map lambda x str x .zfill 6 return data
def bogosort collection def isSorted collection if len collection < 2 return Truefor i in range len collection - 1 if collection[i] > collection[ i + 1 ] return Falsereturn Truewhile not isSorted collection random.shuffle collection return collection
def get_registry return _registry
def feed_parser_initialization generator generator.plugin_instance GitHubActivity generator
def assert_studio_view block fragment try html lxml.html.fragment_fromstring fragment.content except lxml.etree.ParserError assert_studio_view_invalid_html block fragment.content else assert_studio_view_valid_html block html
def _run_finalizers minpriority None if _finalizer_registry is None returnif minpriority is None f lambda p p[0][0] is not None else f lambda p p[0][0] is not None and p[0][0] > minpriority items [x for x in _finalizer_registry.items if f x ]items.sort reverse True for key finalizer in items sub_debug 'calling%s' finalizer try finalizer except Exception import tracebacktraceback.print_exc if minpriority is None _finalizer_registry.clear
def trima a limits None inclusive True True a ma.asarray a a.unshare_mask if limits is None or limits None None return a lower_lim upper_lim limits lower_in upper_in inclusivecondition Falseif lower_lim is not None if lower_in condition | a < lower_lim else condition | a < lower_lim if upper_lim is not None if upper_in condition | a > upper_lim else condition | a > upper_lim a[condition.filled True ] maskedreturn a
def require_snapshot_exists f @functools.wraps f def wrapper context snapshot_id *args **kwargs if not resource_exists context models.Snapshot snapshot_id raise exception.SnapshotNotFound snapshot_id snapshot_id return f context snapshot_id *args **kwargs return wrapper
def ohdave_rsa_encrypt data exponent modulus payload int binascii.hexlify data[ -1 ] 16 encrypted pow payload exponent modulus return u'%x' % encrypted
def cmd_watch args if len args 0 mpstate.status.watch Nonereturnmpstate.status.watch args[0]print 'Watching%s' % mpstate.status.watch
@deprecated 'l1_cross_distanceswasdeprecatedinversion0.18andwillberemovedin0.20.' def l1_cross_distances X X check_array X n_samples n_features X.shapen_nonzero_cross_dist n_samples * n_samples - 1 // 2 ij np.zeros n_nonzero_cross_dist 2 dtype np.int D np.zeros n_nonzero_cross_dist n_features ll_1 0for k in range n_samples - 1 ll_0 ll_1ll_1 ll_0 + n_samples - k - 1 ij[ll_0 ll_1 0] kij[ll_0 ll_1 1] np.arange k + 1 n_samples D[ll_0 ll_1] np.abs X[k] - X[ k + 1 n_samples] return D ij
def extrudeFile filename print 'File' + filename + 'isbeingextruded.' fileText archive.getFileText filename gcodec.writeFileMessageSuffix filename extrudeText fileText 'Thegcodelogfileissavedas' '_log'
def make_service options def make_stub 'Helperfunctionformakingastubtotalktoservice.'credentials_path options.get 'credentials_path' None http httplib2.Http http apiclient.http.set_user_agent http 'SpinnakerStackdriverAgent/0.001' if credentials_path logging.info 'UsingStackdriverCredentialsfrom"%s"' credentials_path credentials ServiceAccountCredentials.from_json_keyfile_name credentials_path scopes StackdriverMetricsService.WRITE_SCOPE else logging.info 'UsingStackdriverCredentialsfromapplicationdefault.' credentials GoogleCredentials.get_application_default http credentials.authorize http return apiclient.discovery.build 'monitoring' 'v3' http http return StackdriverMetricsService make_stub options
def image_type image_type if image_type 'kernel' return 'aki'if image_type 'ramdisk' return 'ari'if image_type not in ['aki' 'ari'] return 'ami'return image_type
def resource_type return s3_rest_controller
def matdims arr oned_as 'column' shape arr.shapeif shape return 1 1 if reduce operator.mul shape 0 return 0 * np.max [arr.ndim 2] if len shape 1 if oned_as 'column' return shape + 1 elif oned_as 'row' return 1 + shape else raise ValueError '1Doption"%s"isstrange' % oned_as return shape
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
@assert_equal.register datetime.datetime np.datetime64 datetime.datetime np.datetime64 def assert_timestamp_and_datetime_equal result expected path msg '' allow_datetime_coercions False compare_nat_equal True **kwargs assert allow_datetime_coercions or type result type expected "%sdatetimetypes %s %s don'tmatchandallow_datetime_coercionswasnotset.\n%s" % _fmt_msg msg type result type expected _fmt_path path result pd.Timestamp result expected pd.Timestamp result if compare_nat_equal and pd.isnull result and pd.isnull expected returnassert_equal.dispatch object object result expected path path **kwargs
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofaserverforwhichthenetworkcacheshouldberefreshedfromneutron Adminonly .' def do_refresh_network cs args server _find_server cs args.server cs.server_external_events.create [{'server_uuid' server.id 'name' 'network-changed'}]
def colors pass
def select_query query_type 'list_nodes_select' client _get_client info client.select_query query_type return info
def _get_regex data position dummy0 opts dummy1 pattern position _get_c_string data position opts bson_flags position _get_c_string data position opts bson_re Regex pattern bson_flags return bson_re position
def find_credentials usernames []usernames.append __pillar__['proxy'].get 'admin_username' 'root' if 'fallback_admin_username' in __pillar__.get 'proxy' usernames.append __pillar__['proxy'].get 'fallback_admin_username' for user in usernames for pwd in __pillar__['proxy']['passwords'] r __salt__['dracr.get_chassis_name'] host __pillar__['proxy']['host'] admin_username user admin_password pwd try if r.get 'retcode' None is None DETAILS['admin_username'] userDETAILS['admin_password'] pwd__opts__['proxy']['admin_username'] user__opts__['proxy']['admin_password'] pwdreturn user pwd except AttributeError DETAILS['admin_username'] userDETAILS['admin_password'] pwd__opts__['proxy']['admin_username'] user__opts__['proxy']['admin_password'] pwdreturn user pwd log.debug 'proxyfx2.find_credentialsfoundnovalidcredentials usingDelldefault' return 'root' 'calvin'
def get_profit_statement code if code.isdigit request Request ct.SINA_PROFITSTATEMENT_URL % code text urlopen request timeout 10 .read text text.decode 'GBK' text text.replace ' DCTB \n' '\r\n' text text.replace ' DCTB ' ' ' df pd.read_csv StringIO text dtype {'code' 'object'} return df
def do_SpnCreate po if g_createdSCP is None _option_error po 'ScpCreatemusthavebeenspecifiedbeforeSpnCreate' spns win32security.DsGetSpn dscon.DS_SPN_SERVICE _get_option po 'service_class' g_createdSCP.distinguishedName _get_option po 'port' 0 None None spn spns[0]log 2 'CreatedSPN %s' spn global g_createdSPNLastg_createdSPNLast spng_createdSPNs.append spn return spn
def emptyNet net Mininet controller Controller info '***Addingcontroller\n' net.addController 'c0' info '***Addinghosts\n' h1 net.addHost 'h1' ip '10.0.0.1' h2 net.addHost 'h2' ip '10.0.0.2' info '***Addingswitch\n' s3 net.addSwitch 's3' info '***Creatinglinks\n' net.addLink h1 s3 net.addLink h2 s3 info '***Startingnetwork\n' net.start info '***RunningCLI\n' CLI net info '***Stoppingnetwork' net.stop
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def connectableEndpoint debug False reactor MemoryReactorClock clientEndpoint TCP4ClientEndpoint reactor '0.0.0.0' 4321 serverEndpoint TCP4ServerEndpoint reactor 4321 serverEndpoint.listen Factory.forProtocol Protocol return clientEndpoint ConnectionCompleter reactor
def scale s dtype None assert len s 3 return np.array np.diag np.concatenate [s 1.0 ] dtype
def _get_course_and_check_access course_key user depth 0 if not has_studio_write_access user course_key raise PermissionDenied course_module modulestore .get_course course_key depth depth return course_module
def read handle debug 0 iterator parse handle debug try first next iterator except StopIteration first Noneif first is None raise ValueError 'Nopathwaysfoundinhandle' try second next iterator except StopIteration second Noneif second is not None raise ValueError 'Morethanonepathwayfoundinhandle' return first
@webob.dec.wsgify@util.check_accept 'application/json' def list_for_consumer req context req.environ['placement.context']consumer_id util.wsgi_path_item req.environ 'consumer_uuid' allocations objects.AllocationList.get_all_by_consumer_id context consumer_id allocations_json jsonutils.dumps _serialize_allocations_for_consumer allocations req.response.status 200req.response.body encodeutils.to_utf8 allocations_json req.response.content_type 'application/json'return req.response
def fetch url 'https //techblog.willshouse.com/2012/01/03/most-common-user-agents/'page requests.get url page html.fromstring page.text path '//*[@id "post-2229"]/div[2]/table/tbody'return page.xpath path [0]
def make_dev_path dev partition None base '/dev' path os.path.join base dev if partition path + str partition return path
def billed_ops_to_str billed_ops_list ops_as_strs []for op in billed_ops_list op_name datamodel_pb.BilledOpProto.BilledOp_Name op.op ops_as_strs.append '%s %s' % op_name op.num_ops return ' '.join ops_as_strs
def get_demo_driver provider_name 'RACKSPACE' *args **kwargs provider_name provider_name.upper DriverClass get_driver getattr Provider provider_name if not args args getattr secrets provider_name + '_PARAMS' if not kwargs kwargs getattr secrets provider_name + '_KEYWORD_PARAMS' {} try return DriverClass *args **kwargs except InvalidCredsError raise InvalidCredsError 'validvaluesshouldbeputinsecrets.py'
def unmap_url srcdir src destdir '.' if is_url src url_parts urlparse.urlparse src filename os.path.basename url_parts[2] dest os.path.join destdir filename return get_file src dest else return os.path.join srcdir src
def document_custom_signature section name method include None exclude None args varargs keywords defaults inspect.getargspec method args args[1 ]signature_params inspect.formatargspec args varargs keywords defaults signature_params signature_params.lstrip ' ' signature_params signature_params.rstrip ' ' section.style.start_sphinx_py_method name signature_params
def catalogue_pre_delete instance sender **kwargs catalogue get_catalogue catalogue.remove_record instance.uuid
def attach_priorities queryset as_field 'priorities_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json projects_priority \nORDERBYprojects_priority.order\n \nFROMprojects_priority\nWHEREprojects_priority.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def getHeuristicCharEncoding page retVal detect page ['encoding']if retVal infoMsg "heuristicsdetectedwebpagecharset'%s'" % retVal singleTimeLogMessage infoMsg logging.INFO retVal return retVal
def Benini name alpha beta sigma return rv name BeniniDistribution alpha beta sigma
def libvlc_video_set_marquee_string p_mi option psz_text f _Cfunctions.get 'libvlc_video_set_marquee_string' None or _Cfunction 'libvlc_video_set_marquee_string' 1 1 1 None None MediaPlayer ctypes.c_uint ctypes.c_char_p return f p_mi option psz_text
def _has_eeg_average_ref_proj projs check_active False for proj in projs if proj['desc'] 'AverageEEGreference' or proj['kind'] FIFF.FIFFV_MNE_PROJ_ITEM_EEG_AVREF if not check_active or proj['active'] return Truereturn False
@access_log_level logging.DEBUG def status_bar request resp ''for view in _status_bar_views try r view request if r.status_code 200 resp + r.contentelse LOG.warning 'Failedtoexecutestatus_barview%s' % view except LOG.exception 'Failedtoexecutestatus_barview%s' % view return HttpResponse resp
def loads s encoding None cls None object_hook None parse_float None parse_int None parse_constant None object_pairs_hook None **kw if cls is None and encoding is None and object_hook is None and parse_int is None and parse_float is None and parse_constant is None and object_pairs_hook is None and not kw return _default_decoder.decode s if cls is None cls JSONDecoderif object_hook is not None kw['object_hook'] object_hookif object_pairs_hook is not None kw['object_pairs_hook'] object_pairs_hookif parse_float is not None kw['parse_float'] parse_floatif parse_int is not None kw['parse_int'] parse_intif parse_constant is not None kw['parse_constant'] parse_constantreturn cls encoding encoding **kw .decode s
def get_init_flt user get_user if user in INIT_QUERIES return INIT_QUERIES[user]if isinstance user basestring and '@' in user realm user[user.index '@' ]if realm in INIT_QUERIES return INIT_QUERIES[realm]if config.WEB_PUBLIC_SRV return db.nmap.searchcategory ['Shared' get_anonymized_user ] return DEFAULT_INIT_QUERY
def _item_to_topic iterator resource return Topic.from_api_repr resource iterator.client
def profile_preload mod base used_memory t0 time.time jedi.preload_module mod elapsed time.time - t0 used used_memory - base return elapsed used
def test_spatial_batch_normalization def check *input_dim sbn SpatialBatchNormalization input_dim sbn.initialize x theano.tensor.TensorType theano.config.floatX [False] * len input_dim + 1 y sbn.apply x rng numpy.random.RandomState 2015 12 17 input_ random_unif rng 11 + input_dim assert_equal y.eval {x input_} input_ yield check 2 3 5 yield check 5 3 2 3 yield check 1 11
def test_category_delete category category.delete category Category.query.filter_by id category.id .first assert category is None
def write_complex128 fid kind data data_size 16data np.array data dtype '>c16' .T_write fid data kind data_size FIFF.FIFFT_COMPLEX_FLOAT '>c16'
def test_exclude_should_work_on_sequence_too class PersonTable tables.Table first_name tables.Column last_name tables.Column occupation tables.Column class Meta sequence u'first_name' u'last_name' u'occupation' class AnotherPersonTable PersonTable class Meta PersonTable.Meta exclude u'first_name' u'last_name' tableA PersonTable [] assert tableA.columns.names [u'first_name' u'last_name' u'occupation'] tableB AnotherPersonTable [] assert tableB.columns.names [u'occupation'] tableC PersonTable [] exclude u'first_name' assert tableC.columns.names [u'last_name' u'occupation']
def albumart_metadata release common_tags date year _date_year release artist release['ArtistName']album release['AlbumTitle']override_values {Vars.ARTIST artist Vars.ALBUM album Vars.YEAR year Vars.DATE date Vars.ARTIST_LOWER _lower artist Vars.ALBUM_LOWER _lower album }res MetadataDict common_tags res.add_items override_values.iteritems return res
def LoadEntity entity keys_only False property_names None if entity clone entity_pb.EntityProto if property_names clone.mutable_key .CopyFrom entity.key clone.mutable_entity_group seen set for prop in entity.property_list if prop.name in property_names Check prop.name not in seen 'datastoredevstubproducedbadresult' datastore_pb.Error.INTERNAL_ERROR seen.add prop.name new_prop clone.add_property new_prop.set_name prop.name new_prop.set_meaning entity_pb.Property.INDEX_VALUE new_prop.mutable_value .CopyFrom prop.value new_prop.set_multiple False elif keys_only clone.mutable_key .CopyFrom entity.key clone.mutable_entity_group else clone.CopyFrom entity PrepareSpecialPropertiesForLoad clone return clone
def test_simple_uninstall_distutils script script.scratch_path.join 'distutils_install' .mkdir pkg_path script.scratch_path / 'distutils_install' pkg_path.join 'setup.py' .write textwrap.dedent "\nfromdistutils.coreimportsetup\nsetup \nname 'distutils-install' \nversion '0.1' \n \n" result script.run 'python' pkg_path / 'setup.py' 'install' result script.pip 'list' '--format legacy' assert 'distutils-install 0.1 ' in result.stdout script.pip 'uninstall' 'distutils_install' '-y' expect_stderr True result2 script.pip 'list' '--format legacy' assert 'distutils-install 0.1 ' not in result2.stdout
def _lucas_extrastrong_params n from sympy.core import igcdfrom sympy.ntheory.residue_ntheory import jacobi_symbol P Q D 3 1 5 while True g igcd D n if g > 1 and g ! n return 0 0 0 if jacobi_symbol D n -1 breakP + 1D P * P - 4 return _int_tuple D P Q
def GetPlatformRestrictions campaign_feed platform_restrictions Noneif campaign_feed['matchingFunction']['operator'] 'AND' for argument in campaign_feed['matchingFunction']['lhsOperand'] if argument['value']['operator'] 'EQUALS' request_context_operand argument['value']['lhsOperand'][0]if request_context_operand and request_context_operand 'DEVICE_PLATFORM' platform_restrictions argument['value']['rhsOperand'][0].upper return platform_restrictions
def p_command_data p p[0] 'DATA' p[2]
def _build_dependency_manager_no_config kwargs configure_logging kwargs root find_root kwargs dependency_resolvers_config_file find_path kwargs 'dependency_resolvers_config_file' root use_dependencies tool_dependency_dir use_cached_dependency_manager tool_dependency_cache_dir precache_dependencies parse_dependency_options kwargs root dependency_resolvers_config_file if not use_dependencies dependency_manager NullDependencyManager else dependency_manager_kwds {'default_base_path' tool_dependency_dir 'conf_file' dependency_resolvers_config_file 'app_config' kwargs}if use_cached_dependency_manager dependency_manager_kwds['tool_dependency_cache_dir'] tool_dependency_cache_dirdependency_manager CachedDependencyManager **dependency_manager_kwds else dependency_manager DependencyManager **dependency_manager_kwds return dependency_manager
def disease_rheader r tabs None T current.Tif r.representation ! 'html' return Noneresourcename r.nameif resourcename 'disease' tabs T 'BasicDetails' None T 'Symptoms' 'symptom' T 'Documents' 'document' rheader_fields ['name'] ['code'] rheader S3ResourceHeader rheader_fields tabs r elif resourcename 'case' tabs T 'BasicDetails' None T 'Exposure' 'exposure' T 'Monitoring' 'case_monitoring' T 'Diagnostics' 'case_diagnostics' T 'Contacts' 'contact' T 'Tracing' 'tracing' rheader_fields ['person_id'] rheader S3ResourceHeader rheader_fields tabs r elif resourcename 'tracing' tabs T 'BasicDetails' None T 'ContactPersons' 'exposure' rheader_fields ['case_id'] rheader S3ResourceHeader rheader_fields tabs r else rheader ''return rheader
@nottestdef slow_test f f.slow_test Truereturn f
def per_cpu_times ret []for cpu_t in cext.per_cpu_times user nice system idle cpu_titem scputimes user nice system idle ret.append item return ret
def _rfc_transform msg msgstring msg.to_string start msgstring.find 'References ' if start -1 return msgstringend msgstring.find '\r\n' start + len 'References ' substring msgstring[start end]separator '\n DCTB 'rfcmsg msgstring[ start] + substring.replace ' DCTB ' separator + msgstring[end ] return rfcmsg
def get_table_headings choices return filter lambda x x['id'] in choices HEADING_CHOICES
def isPower2 num return num & num - 1 0 and num > 0
def _cookie_parse_impl b i 0n len b while i < n match _cookie_re.search b + ';' i if not match breakkey match.group 'key' .strip value match.group 'val' i match.end 0 if key.lower not in _cookie_params yield _cookie_unquote key _cookie_unquote value
def fort_details bot fort_id latitude longitude if fort_id not in FORT_CACHE '\nLookupthefortdetailsandcachetheresponseforfutureuse.\n'request bot.api.create_request request.fort_details fort_id fort_id latitude latitude longitude longitude try response_dict request.call FORT_CACHE[fort_id] response_dict['responses']['FORT_DETAILS']except Exception passreturn FORT_CACHE.get fort_id {}
def _safe_rep obj short False try result repr obj except Exception result object.__repr__ obj if not short or len result < 80 return resultreturn result[ 80] + '[truncated]...'
def get_plural_type code pluralequation if pluralequation[ -1 ] u';' pluralequation pluralequation[ -1 ]if pluralequation[0] u' ' and pluralequation[ -1 ] u' ' pluralequation pluralequation[1 -1 ]base_code code.replace u'_' u'-' .split u'-' [0]if pluralequation u'0' return data.PLURAL_NONEfor mapping in data.PLURAL_MAPPINGS if pluralequation in mapping[0] return mapping[1]if base_code in u'ar' return data.PLURAL_ARABICLOGGER.error u'Cannotguesstypeofpluralfor%s %s' code pluralequation return data.PLURAL_UNKNOWN
def _rcconf_status name service_status rcconf '/etc/rc.conf'rxname '^{0} .*'.format name newstatus '{0} {1}'.format name service_status ret __salt__['cmd.retcode'] "grep'{0}'{1}".format rxname rcconf if ret 0 __salt__['file.replace'] rcconf rxname newstatus else ret __salt__['file.append'] rcconf newstatus return ret
def _debuginit self exc_value None exc_type None exc_tb None Failure__init__ Failure.__init__.im_func if exc_value exc_type exc_tb None None None exc sys.exc_info if not exc[0] self.__class__ and DO_POST_MORTEM try strrepr str exc[1] except strrepr 'brokenstr'print "Jumpingintodebuggerforpost-mortemofexception'%s' " % strrepr import pdbpdb.post_mortem exc[2] Failure__init__ self exc_value exc_type exc_tb
def ham_dist e1 e2 ne operator.nereturn sum imap ne e1 e2
def marker_weight matches marker return len set match.name for match in matches.range predicate marker_comparator_predicate *marker.span
def softplus x return tf.nn.softplus x
def list_locations provider 'all' client _get_client locations client.list_locations provider return locations
def get_destination_path path to keep_dirs filename os.path.basename path if keep_dirs path_suffix pathelse path_suffix filenamereturn os.path.join to path_suffix
def test_regularize_cov raw read_raw_fif raw_fname raw.info['bads'].append raw.ch_names[0] noise_cov read_cov cov_fname reg_noise_cov regularize noise_cov raw.info mag 0.1 grad 0.1 eeg 0.1 proj True exclude 'bads' assert_true noise_cov['dim'] reg_noise_cov['dim'] assert_true noise_cov['data'].shape reg_noise_cov['data'].shape assert_true np.mean noise_cov['data'] < reg_noise_cov['data'] < 0.08
def test_edit data title '' parent None app qapplication dlg DataFrameEditor parent parent if dlg.setup_and_check data title title dlg.exec_ return dlg.get_value else import syssys.exit 1
def get_pathext default_pathext None if default_pathext is None default_pathext os.pathsep.join ['.COM' '.EXE' '.BAT' '.CMD'] pathext os.environ.get 'PATHEXT' default_pathext return pathext
def bind_context gr role account_id *args gr.context ' '.join [role str account_id ] + [str arg for arg in args]
def trunk_can_be_managed context trunk if not trunk.admin_state_up raise trunk_exc.TrunkDisabled trunk_id trunk.id
def dist_in_site_packages dist return normalize_path dist_location dist .startswith normalize_path site_packages
def attach_roles queryset as_field 'roles_attr' model queryset.modelsql '\nSELECTjson_agg \nrow_to_json users_role \nORDERBYusers_role.order\n \nFROMusers_role\nWHEREusers_role.project_id {tbl}.id\n'sql sql.format tbl model._meta.db_table queryset queryset.extra select {as_field sql} return queryset
def ends_in_file path _RE_ENDEXT re.compile '\\.%ext[{}]*$' re.I _RE_ENDFN re.compile '%fn[{}]*$' re.I return bool _RE_ENDEXT.search path or _RE_ENDFN.search path
def stream_to_file stream suffix '' prefix '' dir None text False **kwd fd temp_name tempfile.mkstemp suffix suffix prefix prefix dir dir text text return stream_to_open_named_file stream fd temp_name **kwd
def get_docker_plays roles graph coverage dict.fromkeys roles False items set docker_plays {node.name for node in graph.nodes if node.type 'docker_playbook' }for play in docker_plays roles_nodes nx.all_neighbors graph play 'docker_playbook' docker_roles {role.name for role in roles_nodes}common_roles roles & docker_roles if common_roles items.add play for role in common_roles coverage[role] Truefor role in coverage if not coverage[role] LOGGER.warning "role'%s'isnotcovered." % role return items
def verify_assertions data assertion_description_list for assertion_description in assertion_description_list verify_assertion data assertion_description
def install p PollReactor from twisted.internet.main import installReactorinstallReactor p
def calc_hash type content header '%s%d\x00' % type len content sum Sha1 header sum.update content return sum.digest
def feed_forward neural_network input_vector outputs []for layer in neural_network input_with_bias input_vector + [1] output [neuron_output neuron input_with_bias for neuron in layer]outputs.append output input_vector outputreturn outputs
def rm_fetched dist raise NotImplementedError
def refresh_db if 'eix.sync' in __salt__ return __salt__['eix.sync'] if 'makeconf.features_contains' in __salt__ and __salt__['makeconf.features_contains'] 'webrsync-gpg' cmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0 else if __salt__['cmd.retcode'] 'emerge--askn--quiet--sync' python_shell False 0 return Truecmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0
def set_options source options.set_source source
def smart_fill variable_name db PARAM_NAME_KNOWLEDGE default '56' variable_name variable_name.lower possible_results []for filled_value variable_name_list in db.items for variable_name_db in variable_name_list if variable_name_db variable_name return filled_valueif variable_name in variable_name_db match_rate get_match_rate variable_name variable_name_db possible_results.append filled_value match_rate elif variable_name_db in variable_name match_rate get_match_rate variable_name variable_name_db possible_results.append filled_value match_rate if possible_results possible_results.sort sortfunc return possible_results[0][0]else msg '[smart_fill]Failedtofindavalueforparameterwithname"%s"'om.out.debug msg % variable_name return default
def AllocateIds model_key size None **kwargs return AllocateIdsAsync model_key size **kwargs .get_result
def test_no_units_for_char_columns t1 Table [['A']] names 'B' out StringIO ascii.write t1 out format 'ipac' t2 ascii.read out.getvalue format 'ipac' guess False assert t2['B'].unit is None
def directive apply_globally False api None def decorator directive_method if apply_globally hug.defaults.directives[underscore directive_method.__name__ ] directive_methodelse apply_to_api hug.API api if api else hug.api.from_object directive_method apply_to_api.add_directive directive_method directive_method.directive Truereturn directive_methodreturn decorator
def getOpenIDStore return util.getOpenIDStore '/tmp/djopenid_c_store' 'c_'
def copy_plugins_to_language page source_language target_language only_empty True copied 0placeholders page.get_placeholders for placeholder in placeholders if not only_empty or not placeholder.get_plugins language target_language .exists plugins list placeholder.get_plugins language source_language .order_by 'path' copied_plugins copy_plugins.copy_plugins_to plugins placeholder target_language copied + len copied_plugins return copied
def test_import_empty completion jedi.Script 'import' .completions [0]definition completion.follow_definition [0]assert definition
def _update_version_in_install_rdf content new_version_number tree lxml.etree.fromstring content namespace 'http //www.mozilla.org/2004/em-rdf#'version_uri '{{{0}}}version'.format namespace for node in tree.xpath '//em version|//*[@em version]' namespaces {'em' namespace} if node.tag version_uri node.text new_version_numberelse node.set version_uri new_version_number return lxml.etree.tostring tree xml_declaration True encoding 'utf-8'
def tophat image selem out None mask None shift_x False shift_y False return _apply_scalar_per_pixel generic_cy._tophat image selem out out mask mask shift_x shift_x shift_y shift_y
def intword value try value int value except TypeError ValueError return valueif value < 1000000 return valueif value < 1000000000 new_value value / 1000000.0 return ungettext '% value .1fmillion' '% value .1fmillion' new_value % {'value' new_value} if value < 1000000000000 new_value value / 1000000000.0 return ungettext '% value .1fbillion' '% value .1fbillion' new_value % {'value' new_value} if value < 1000000000000000 new_value value / 1000000000000.0 return ungettext '% value .1ftrillion' '% value .1ftrillion' new_value % {'value' new_value} return value
def _goUnion expression unpack True dump False output unionUse expression unpack unpack dump dump if isinstance output basestring output parseUnionPage output return output
def resize device minor start end _validate_device device try int minor except Exception raise CommandExecutionError 'Invalidminornumberpassedtopartition.resize' _validate_partition_boundary start _validate_partition_boundary end out __salt__['cmd.run'] 'parted-m-s--{0}resize{1}{2}{3}'.format device minor start end return out.splitlines
@pytest.fixture params True False def limit_loader request monkeypatch if not request.param returnclass LimitedLoader object def __init__ self loader self.loader loaderdef __getattr__ self name if name in 'archive' 'get_filename' msg 'Mockingaloaderwhichdoesnothave`%s.`' % name raise AttributeError msg return getattr self.loader name old_get_loader pkgutil.get_loaderdef get_loader *args **kwargs return LimitedLoader old_get_loader *args **kwargs monkeypatch.setattr pkgutil 'get_loader' get_loader
def add_extension module name code code int code if not 1 < code < 2147483647 raise ValueError 'codeoutofrange' key module name if _extension_registry.get key code and _inverted_registry.get code key returnif key in _extension_registry raise ValueError 'key%sisalreadyregisteredwithcode%s' % key _extension_registry[key] if code in _inverted_registry raise ValueError 'code%sisalreadyinuseforkey%s' % code _inverted_registry[code] _extension_registry[key] code_inverted_registry[code] key
def allow_cross_site_request f @functools.wraps f def wrapper request *args **kw response f request *args **kw "IfAccess-Control-Allow-Credentialsisn'tset thebrowserwon't\nreturndatarequiredcookiestosee.Thisisagoodthing let'skeep\nitthatway."response['Access-Control-Allow-Origin'] '*'response['Access-Control-Allow-Methods'] 'GET OPTIONS'return responsereturn wrapper
@receiver send_admin_notification sender CourseCreator def send_admin_notification_callback sender **kwargs user kwargs['user']studio_request_email settings.FEATURES.get 'STUDIO_REQUEST_EMAIL' '' context {'user_name' user.username 'user_email' user.email}subject render_to_string 'emails/course_creator_admin_subject.txt' context subject ''.join subject.splitlines message render_to_string 'emails/course_creator_admin_user_pending.txt' context try send_mail subject message studio_request_email [studio_request_email] fail_silently False except SMTPException log.warning "Failuresending'pendingstate'e-mailfor%sto%s" user.email studio_request_email
def set_flags obj flag_field flags for flag in flags if flag[1] & flag_field obj.__dict__[flag[0]] Trueelse obj.__dict__[flag[0]] False
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def tablespace_remove name user None host None port None maintenance_db None password None runas None query 'DROPTABLESPACE"{0}"'.format name ret _psql_prepare_and_run ['-c' query] user user host host port port runas runas maintenance_db maintenance_db password password return ret['retcode'] 0
def get_package_name data return data.get 'name' or data.get 'details' .strip '/' .rsplit '/' 1 [ -1 ]
def S_hac_groupsum x time nlags None weights_func weights_bartlett x_group_sums group_sums x time .Treturn S_hac_simple x_group_sums nlags nlags weights_func weights_func
def generate_request_for_access_token request_token auth_server_url ACCESS_TOKEN_URL http_request atom.http_core.HttpRequest auth_server_url 'POST' http_request.headers['Content-Length'] '0'return request_token.modify_request http_request
def _format_time when if when is None return Nonereturn datetime.isoformat when
def source_indexes indexes view model view.model if isinstance model QSortFilterProxyModel return list map model.mapToSource indexes else return indexes
def read_and_call_while uhandle method **keywds nlines 0while True line safe_readline uhandle if _fails_conditions * line **keywds uhandle.saveline line breakmethod line nlines nlines + 1 return nlines
def createBundle b OSC.OSCMessage b.address ''b.append '#bundle' b.append 0 b.append 0 return b
def yule u v u _validate_vector u v _validate_vector v nff nft ntf ntt _nbool_correspond_all u v return float 2.0 * ntf * nft / float ntt * nff + ntf * nft
def get_cross_validation_datasets_random dataset n_fold seed None order numpy.random.RandomState seed .permutation len dataset return get_cross_validation_datasets dataset n_fold order
def default_expire_time expire_delta datetime.timedelta seconds CONF.token.expiration expires_at timeutils.utcnow + expire_delta return expires_at.replace microsecond 0
def group_follower_count context data_dict return _follower_count context data_dict ckan.logic.schema.default_follow_group_schema context['model'].UserFollowingGroup
def set_installed_variant_rpm_facts facts installed_rpms []for base_rpm in ['openshift' 'atomic-openshift' 'origin'] optional_rpms ['master' 'node' 'clients' 'sdn-ovs']variant_rpms [base_rpm] + ['{0}-{1}'.format base_rpm r for r in optional_rpms] + [ 'tuned-profiles-%s-node' % base_rpm ] for rpm in variant_rpms exit_code _ _ module.run_command ['rpm' '-q' rpm] if exit_code 0 installed_rpms.append rpm facts['common']['installed_variant_rpms'] installed_rpmsreturn facts
def test_exit_on_collection_with_maxfail_smaller_than_n_errors testdir testdir.makepyfile **COLLECTION_ERROR_PY_FILES res testdir.runpytest '--maxfail 1' assert res.ret 2 res.stdout.fnmatch_lines ['*ERRORcollectingtest_02_import_error.py*' '*Nomodulenamed*asdfa*' '*Interrupted stoppingafter1failures*'] assert 'test_03' not in res.stdout.str
def BoxPlot data label None values None color None group None xscale 'categorical' yscale 'linear' xgrid False ygrid True continuous_range None **kw if continuous_range and not isinstance continuous_range Range1d raise ValueError 'continuous_rangemustbeaninstanceofbokeh.models.ranges.Range1d' y_range continuous_rangekw['label'] labelkw['values'] valueskw['color'] colorkw['group'] groupkw['xscale'] xscalekw['yscale'] yscalekw['xgrid'] xgridkw['ygrid'] ygridkw['y_range'] y_rangereturn create_and_build BoxPlotBuilder data **kw
def split_host_and_port netloc match re.match '^ .+ \\d+ $' netloc if match host match.group 1 port int match.group 2 else host netlocport Nonereturn host port
def make_capture_protocol d Deferred captured_data []class Recorder Protocol def dataReceived self data captured_data.append data def connectionLost self reason if reason.check ConnectionDone d.callback ''.join captured_data else d.errback reason return d Recorder
def chown path owner execute 'chown' owner path run_as_root True
def CompareStat tup1 tup2 if tup1.st_ino ! tup2.st_ino return Falseif tup1.st_size ! tup2.st_size return Falseif tup1.st_mtime ! tup2.st_mtime return Falseif tup1.st_ctime ! tup2.st_ctime return Falsereturn True
def ls path load_path None def _match path 'Internalmatchfunction'try matches aug.match path except RuntimeError return {}ret {}for _ma in matches ret[_ma] aug.get _ma return retload_path _check_load_paths load_path aug _Augeas loadpath load_path path path.rstrip '/' + '/' match_path path + '*' matches _match match_path ret {}for key value in six.iteritems matches name _lstrip_word key path if _match key + '/*' ret[ name + '/' ] valueelse ret[name] valuereturn ret
def vm_resize name kwargs None call None if call ! 'action' raise SaltCloudSystemExit 'Thevm_resizeactionmustbecalledwith-aor--action.' if kwargs is None kwargs {}path kwargs.get 'path' None data kwargs.get 'data' None capacity_maintained kwargs.get 'capacity_maintained' True if data if path log.warning "Boththe'data'and'path'argumentswereprovided.'data'willtakeprecedence." elif path data salt.utils.fopen path mode 'r' .read else raise SaltCloudSystemExit "Thevm_resizefunctionrequireseither'data'orafile'path'tobeprovided." server user password _get_xml_rpc auth ' '.join [user password] vm_id int get_vm_id kwargs {'name' name} response server.one.vm.resize auth vm_id data salt.utils.is_true capacity_maintained ret {'action' 'vm.resize' 'resized' response[0] 'vm_id' response[1] 'error_code' response[2]}return ret
def str_slice arr start None stop None step None obj slice start stop step f lambda x x[obj] return _na_map f arr
def merge_sort collection length len collection if length > 1 midpoint length // 2 left_half merge_sort collection[ midpoint] right_half merge_sort collection[midpoint ] i 0j 0k 0left_length len left_half right_length len right_half while i < left_length and j < right_length if left_half[i] < right_half[j] collection[k] left_half[i]i + 1else collection[k] right_half[j]j + 1k + 1while i < left_length collection[k] left_half[i]i + 1k + 1while j < right_length collection[k] right_half[j]j + 1k + 1return collection
def generate_master_key return os.urandom 32
def cast_to_a1_notation method @wraps method def wrapper self *args **kwargs try if len args int args[0] range_start rowcol_to_a1 *args[ 2] range_end rowcol_to_a1 *args[ -2 ] range_name ' '.join range_start range_end args range_name + args[4 ] except ValueError passreturn method self *args **kwargs return wrapper
def get_dasharray obj i None if obj.__dict__.get '_dashSeq' None is not None return ' '.join map str obj._dashSeq else ls obj.get_linestyle if i is not None ls ls[i]dasharray LINESTYLES.get ls None if dasharray is None warnings.warn "dashstyle'{0}'notunderstood defaultingtosolid.".format ls dasharray LINESTYLES['-']return dasharray
def extract_tarfile upload_file extension '.shp' tempdir None absolute_base_file Noneif tempdir is None tempdir tempfile.mkdtemp the_tar tarfile.open upload_file the_tar.extractall tempdir for item in the_tar.getnames if item.endswith extension absolute_base_file os.path.join tempdir item return absolute_base_file
def map requests stream False size None exception_handler None gtimeout None requests list requests pool Pool size if size else None jobs [send r pool stream stream for r in requests]gevent.joinall jobs timeout gtimeout ret []for request in requests if request.response is not None ret.append request.response elif exception_handler and hasattr request 'exception' ret.append exception_handler request request.exception else ret.append None return ret
def psturng q r v if all map _isfloat [q r v] return _psturng q r v return _vpsturng q r v
@command 'play\\s+ %s|\\d+ ' % WORD def play_pl name if name.isdigit name int name name sorted g.userpl [ name - 1 ]saved g.userpl.get name if not saved name util.get_near_name name g.userpl saved g.userpl.get name if saved g.model.songs list saved.songs play_all '' '' '' else g.message util.F 'plnotfound' % name g.content content.playlists_display
def features out __salt__['cmd.run_all'] 'mkfs.btrfs-Olist-all' salt.utils.fsutils._verify_run out ret {}for line in [re.sub '\\s+' '' line for line in out['stderr'].split '\n' if '-' in line ] option description line.split '-' 1 ret[option] descriptionreturn ret
def preserve_whitespace v quote True if quote v html_quote v v v.replace '\n' '<br>\n' v re.sub ' + ' _repl_nbsp v v re.sub ' \\n + ' _repl_nbsp v v re.sub '^ + ' _repl_nbsp v return '<code>%s</code>' % v
def test_filter_merge b Bundle 's1' Bundle 's2' Bundle 's3' filters [css sass] filters [js] output 'foo' jl bundle_to_joblist b assert jl['foo'][0][0] [] assert jl['foo'][0][1] ['s1'] assert jl['foo'][1][0] [js] assert jl['foo'][1][1] ['s2'] assert jl['foo'][2][0] [css sass js] assert jl['foo'][2][1] ['s3']
def _add_inset_axes parent_axes inset_axes parent_axes.figure.add_axes inset_axes inset_axes.set_navigate False
def get_locales prefix None normalize True locale_getter _default_locale_getter try raw_locales locale_getter except return Nonetry raw_locales raw_locales.split '\n' out_locales []for x in raw_locales if PY3 out_locales.append str x encoding pd.options.display.encoding else out_locales.append str x except TypeError passif prefix is None return _valid_locales out_locales normalize found re.compile '%s.*' % prefix .findall '\n'.join out_locales return _valid_locales found normalize
def get_page_queryset_from_path path preview False draft False site None if is_installed 'django.contrib.admin' admin_base admin_reverse 'index' if path.startswith admin_base match ADMIN_PAGE_RE.search path if match return Page.objects.filter pk match.group 1 else return Page.objects.none if not site site Site.objects.get_current if draft pages Page.objects.drafts .filter site site elif preview pages Page.objects.public .filter site site else pages Page.objects.public .published site site if not path return pages.filter is_home True site site [ 1]return pages.filter title_set__path path .distinct
def BuildSingleObject default_class stream loader yaml.loader.SafeLoader definitions BuildObjects default_class stream loader if len definitions < 1 raise yaml_errors.EmptyConfigurationFile if len definitions > 1 raise yaml_errors.MultipleConfigurationFile return definitions[0]
def setUpModule global ENGINEglobal SESSIONENGINE create_engine 'sqlite //' Base.metadata.create_all ENGINE session_factory sessionmaker bind ENGINE SESSION scoped_session session_factory
def check_response method @functools.wraps method def wrapped self *args **kwargs response method self *args **kwargs status response.status_codeif status > 400 if response.status_code 429 self.handle_429 resp *args **kwargs return method self *args **kwargs .json msg_args response response.text response.headers msg 'Badapiresponse %r%r%r' % msg_args raise BadAPIResponse response msg return response.json return wrapped
def ResampleRows df return SampleRows df len df replace True
def pandas_wrapper_freq func trim_head None trim_tail None freq_kw 'freq' columns None *args **kwargs @wraps func def new_func X *args **kwargs if not _is_using_pandas X None return func X *args **kwargs wrapper_func _get_pandas_wrapper X trim_head trim_tail columns index X.indexfreq index.inferred_freqkwargs.update {freq_kw freq_to_period freq } ret func X *args **kwargs ret wrapper_func ret return retreturn new_func
def _compute_derivatives image mode 'constant' cval 0 imy ndi.sobel image axis 0 mode mode cval cval imx ndi.sobel image axis 1 mode mode cval cval return imx imy
def get_target alias aliases list_aliases if alias in aliases return aliases[alias]return ''
def datetime2timestamp dt default_timezone None epoch datetime.datetime 1970 1 1 if dt.tzinfo is None if default_timezone is None default_timezone tzutc dt dt.replace tzinfo default_timezone d dt.replace tzinfo None - dt.utcoffset - epoch if hasattr d 'total_seconds' return d.total_seconds return d.microseconds + d.seconds + d.days * 24 * 3600 * 10 ** 6 / 10 ** 6
def onerror function path excinfo if not os.access path os.W_OK os.chmod path stat.S_IWUSR function path else raise
def update_headers headers api_version if not api_version.is_null version_string api_version.get_string if api_version.ver_minor ! 0 headers[LEGACY_HEADER_NAME] version_stringif api_version.ver_minor > 27 headers[HEADER_NAME] '%s%s' % SERVICE_TYPE version_string
def log_sink_factory om_queue global outout LogSink om_queue return out
def validate_type_strict object_ object_types if not isinstance object_types tuple object_types object_types exact_type_match any [ type object_ t for t in object_types] if not exact_type_match error_format 'Pleasepassobject_oftype%sastheargument encounteredtype%s'message error_format % object_types type object_ raise ValueError message
def ProbMaxPool images rnd targets numChannels subsX startX strideX outputsX numImages images.shape[0]assert targets.shape numImages numChannels * outputsX * outputsX assert rnd.shape images.shape _ConvNet.ProbMaxPool images.p_mat rnd.p_mat targets.p_mat numChannels subsX startX strideX outputsX
def shortstr s l 53 if len s > l return s[ l - 3 ] + '...' return s
def starttime pid return psutil.Process pid .create_time - psutil.boot_time
def _parseSchema schema schema_store result {}schema resolveSchema schema schema_store def fill_in_result object_schema result['properties'] {}for prop propSchema in object_schema[u'properties'].iteritems attr result['properties'][prop] {}attr['title'] propSchema['title']attr['description'] prepare_docstring propSchema['description'] attr['required'] prop in object_schema.get 'required' [] attr['type'] propSchema['type']if schema[u'type'] u'object' result['type'] 'object'fill_in_result schema elif schema[u'type'] u'array' result['type'] 'array'child_schema schema[u'items']if child_schema.get 'type' 'object' fill_in_result child_schema else raise Exception 'Onlysingleobjecttypeallowedinanarray.' else raise Exception 'Non-object/arraytop-leveldefinitionsnotsupported.' return result
def service_get_all_servicemanage_sorted context return IMPL.service_get_all_servicemanage_sorted context
def safe_no_dnn_workmem workmem if workmem raise RuntimeError 'Theoption`dnn.conv.workmem`hasbeenremovedandshouldnotbeusedanymore.Pleaseusetheoption`dnn.conv.algo_fwd`instead.' return True
def drk_default_shelter s3 current.response.s3shelter_id s3.drk_default_shelterif not shelter_id default_site current.deployment_settings.get_org_default_site if default_site stable current.s3db.cr_shelterquery stable.site_id default_site shelter current.db query .select stable.id limitby 0 1 .first if shelter shelter_id shelter.ids3.drk_default_shelter shelter_idreturn shelter_id
def runReactorWithLogging config oldstdout oldstderr profiler None reactor None if reactor is None from twisted.internet import reactortry if config['profile'] if profiler is not None profiler.run reactor elif config['debug'] sys.stdout oldstdoutsys.stderr oldstderrif runtime.platformType 'posix' signal.signal signal.SIGUSR2 lambda *args pdb.set_trace signal.signal signal.SIGINT lambda *args pdb.set_trace fixPdb pdb.runcall reactor.run else reactor.run except close Falseif config['nodaemon'] file oldstdoutelse file open 'TWISTD-CRASH.log' 'a' close Truetry traceback.print_exc file file file.flush finally if close file.close
def aggregate_filename files new_suffix path os.path.split files[0] [0]names [os.path.splitext os.path.split x [1] [0] for x in files]common_prefix os.path.commonprefix names path os.getcwd if common_prefix u'' return os.path.abspath os.path.join path os.path.splitext files[0] [0] + u'_' + new_suffix + u'.mnc' else return os.path.abspath os.path.join path common_prefix + u'_' + new_suffix + u'.mnc'
def find_countries string context None ret []for word_match in iter_words string.strip .lower word word_match.valueif word.lower in COMMON_WORDS continuetry country_object babelfish.Country.fromguessit word if is_allowed_country country_object context ret.append word_match.span[0] word_match.span[1] {'value' country_object} except babelfish.Error continuereturn ret
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def get_cookies environ header environ.get 'HTTP_COOKIE' '' if 'paste.cookies' in environ cookies check_header environ['paste.cookies']if check_header header return cookiescookies SimpleCookie try cookies.load header except CookieError passenviron['paste.cookies'] cookies header return cookies
def get_errant_logs_for_tree root_node return log for node in root_node.node_and_primary_descendants for log in get_errant_logs node
def parse_color_string css_string tokens list tokenize_grouped css_string.strip if len tokens 1 return parse_color tokens[0]
def _TruncateAlert alert max_bytes alert_json escape.utf8 json.dumps escape.recursive_unicode alert ensure_ascii False alert_json alert_json[1 -1 ]if len alert_json < max_bytes return escape.utf8 alert assert max_bytes > len _ELLIPSIS_BYTES 'max_bytesmustbeatleast%d' % len _ELLIPSIS_BYTES max_bytes - len _ELLIPSIS_BYTES truncated alert_json[ max_bytes].decode 'utf-8' errors 'ignore' while True try alert json.loads u'"%s"' % truncated breakexcept Exception truncated truncated[ -1 ]return escape.utf8 alert + _ELLIPSIS_BYTES
def grab_cpu_scalar v nd if v.owner is not None n v.ownerif isinstance n.op GpuDimShuffle DimShuffle and n.op.new_order 'x' * nd return grab_cpu_scalar n.inputs[0] n.inputs[0].ndim elif isinstance n.op GpuFromHost HostFromGpu return grab_cpu_scalar n.inputs[0] nd else return Noneelif isinstance v Constant and v.broadcastable True * nd return v.dimshuffle
def find_position string index leading string[ index].splitlines return len leading len leading[ -1 ] + 1
def conll_demo dg DependencyGraph conll_data1 tree dg.tree tree.pprint print dg print dg.to_conll 4
def trie_add values trie None terminus 0 if trie is None trie {}for value in values this triew_len len value - 1 for i c in enumerate value try this this[c]except KeyError this[c] {}this this[c]if i w_len this[terminus] valuereturn trie
def SlashSlugCheck slug return SlugCheck slug allow '/'
def merge_infos info1 info2 for key value in six.iteritems info2 if key in info1 and key.startswith 'stats' if key.startswith 'stats.timers' info1[key] + valueelif key.startswith 'stats.gauges' info1[key] valueelse info1[key] + valueelse info1[key] value
def encode_images model IM images model['f_ienc'] IM return images
def module_enabled module enable_module module reload_service 'apache2'
def readSegmentGT gtFile f open gtFile 'rb' reader csv.reader f delimiter ' ' segStart []segEnd []segLabel []for row in reader if len row 3 segStart.append float row[0] segEnd.append float row[1] segLabel.append row[2] return numpy.array segStart numpy.array segEnd segLabel
def structure_copy structure if hasattr structure 'copy' return structure.copy return iter_copy structure
def get_user return os.getenv 'REMOTE_USER'
def lpol_fiar d n 20 from scipy.special import gammalnj np.arange n ar - np.exp gammaln - d + j - gammaln j + 1 - gammaln - d ar[0] 1return ar
def parse_hook_payload request if request.META['CONTENT_TYPE'] 'application/json' return json.loads request.body.decode 'utf-8' else return json.loads request.POST['payload']
def directlyProvidedBy object provides getattr object '__provides__' None if provides is None or isinstance provides Implements return _emptyreturn Declaration provides.__bases__[ -1 ]
def _order_totals context fields [u'shipping_type' u'shipping_total' u'discount_total' u'tax_type' u'tax_total']template_vars {}if u'order' in context for field in fields + [u'item_total'] template_vars[field] getattr context[u'order'] field else template_vars[u'item_total'] context[u'request'].cart.total_price if template_vars[u'item_total'] 0 template_vars[u'tax_total'] 0template_vars[u'discount_total'] 0template_vars[u'shipping_total'] 0else for field in fields template_vars[field] context[u'request'].session.get field None template_vars[u'order_total'] template_vars.get u'item_total' None if template_vars.get u'shipping_total' None is not None template_vars[u'order_total'] + Decimal str template_vars[u'shipping_total'] if template_vars.get u'discount_total' None is not None template_vars[u'order_total'] - Decimal str template_vars[u'discount_total'] if template_vars.get u'tax_total' None is not None template_vars[u'order_total'] + Decimal str template_vars[u'tax_total'] return template_vars
def handle_calendar_deletes namespace_id deleted_calendar_uids log db_session deleted_count 0for uid in deleted_calendar_uids local_calendar db_session.query Calendar .filter Calendar.namespace_id namespace_id Calendar.uid uid .first if local_calendar is not None _delete_calendar db_session local_calendar deleted_count + 1log.info 'deletedcalendars' deleted deleted_count
def parse_file_upload header_dict post_data import email email.Messagefrom cgi import parse_headerraw_message '\r\n'.join [ '%s %s' % pair for pair in header_dict.items ] raw_message + '\r\n\r\n' + post_data msg email.message_from_string raw_message POST MultiValueDict FILES MultiValueDict for submessage in msg.get_payload if submessage and isinstance submessage email.Message.Message name_dict parse_header submessage['Content-Disposition'] [1]if name_dict.has_key 'filename' assert type [] ! type submessage.get_payload 'NestedMIMEmessagesarenotsupported'if not name_dict['filename'].strip continuefilename name_dict['filename'][ name_dict['filename'].rfind '\\' + 1 ]FILES.appendlist name_dict['name'] {'filename' filename 'content-type' submessage.has_key 'Content-Type' and submessage['Content-Type'] or None 'content' submessage.get_payload } else POST.appendlist name_dict['name'] submessage.get_payload return POST FILES
def getinfos spec function _GETINFOS_FUNCTIONS.get spec.get 'recontype' if type function is dict function function.get spec.get 'source' if function is None return {}if hasattr function '__call__' return function spec
def Uniform name left right return rv name UniformDistribution left right
def _drop_sequences cr seq_names names ' '.join seq_names cr.execute 'DROPSEQUENCEIFEXISTS%sRESTRICT' % names
def gen_with_app *args **kwargs def generator func @wraps func def deco *args2 **kwargs2 app TestApp *args **kwargs for item in func app *args2 **kwargs2 yield item app.cleanup return decoreturn generator
def run_pydoc module_name *args cmd [sys.executable pydoc.__file__ ''.join args module_name]output subprocess.Popen cmd stdout subprocess.PIPE .stdout.read return output.strip
def binary_str data return ''.join '\\x%02x' % byte for byte in bytearray data
def urlencode query if isinstance query dict query query.items return u'&'.join [u' '.join [escape k escape v ] for k v in query]
@receiver SignalHandler.course_deleted def _listen_for_course_delete sender course_key **kwargs CourseOverview.objects.filter id course_key .delete from cms.djangoapps.contentstore.courseware_index import CourseAboutSearchIndexerCourseAboutSearchIndexer.remove_deleted_items course_key
def mean_absolute_error y_true y_pred return tf.reduce_mean tf.abs y_pred - y_true
def _api_pause name output kwargs scheduler.plan_resume 0 Downloader.do.pause return report output
def get_employees_who_are_born_today return frappe.db.sql u"selectname personal_email company_email user_id employee_name\n DCTB DCTB fromtabEmployeewhereday date_of_birth day % date s \n DCTB DCTB andmonth date_of_birth month % date s \n DCTB DCTB andstatus 'Active'" {u'date' today } as_dict True
def parse_search_values_from_opts opts search_values {}for key in 'id' 'region' 'zone' 'ip' 'port' 'replication_ip' 'replication_port' 'device' 'weight' 'meta' value getattr opts key None if value if key 'ip' or key 'replication_ip' value validate_and_normalize_address value search_values[key] valuereturn search_values
def mock_stdout_or_stderr if PY2 return StringIO buf BytesIO writer codecs.getwriter 'utf_8' buf writer.buffer bufwriter.getvalue lambda buf.getvalue return writer
def get_library library_name lib libraries.get library_name None if not lib templatetags_modules get_templatetags_modules tried_modules []for module in templatetags_modules taglib_module u'%s.%s' % module library_name tried_modules.append taglib_module lib import_library taglib_module if lib libraries[library_name] libbreakif not lib raise InvalidTemplateLibrary u'Templatelibrary%snotfound tried%s' % library_name u' '.join tried_modules return lib
def addToZoneTable point shape zoneIndexFloat point.z / shape.zoneInterval shape.zZoneTable[math.floor zoneIndexFloat ] Noneshape.zZoneTable[math.ceil zoneIndexFloat ] None
def get_attr_info return {'distributed' {'default' cfg.CONF.router_distributed} 'ha' {'default' cfg.CONF.l3_ha} 'ha_vr_id' {'default' 0} 'availability_zone_hints' {'default' '[]' 'transform_to_db' az.convert_az_list_to_string 'transform_from_db' az.convert_az_string_to_list}}
def setscientific infos ''if __has_numpy infos + '\nThisisastandardPythoninterpreterwithpreloadedtoolsforscientific\ncomputingandvisualization.Ittriestoimportthefollowingmodules \n\n>>>importnumpyasnp#NumPy multidimensionalarrays linearalgebra ... 'if __has_scipy infos + '\n>>>importscipyassp#SciPy signalandimageprocessinglibrary 'if __has_matplotlib infos + "\n>>>importmatplotlibasmpl#Matplotlib 2D/3Dplottinglibrary \n>>>importmatplotlib.pyplotasplt#Matplotlib'spyplot MATLAB-likesyntax\n>>>frompylabimport*#Matplotlib'spylabinterface\n>>>ion #TurnedonMatplotlib'sinteractivemode"if __has_guiqwt infos + "\n>>>importguidata#GUIgenerationforeasydataseteditinganddisplay\n\n>>>importguiqwt#Efficient2Ddata-plottingfeatures\n>>>importguiqwt.pyplotasplt_#guiqwt'spyplot MATLAB-likesyntax\n>>>plt_.ion #Turnedonguiqwt'sinteractivemode"if __imports infos + '\n'infos + '\nWithinSpyder thisinterpreteralsoprovides \n*specialcommands e.g.%ls %cd %pwd %clear \n-%ls Listfilesinthecurrentdirectory\n-%cddir Changetodirectorydir\n-%pwd Showcurrentdirectory\n-%clearx Removevariablexfromnamespace\n'try import __builtin__ as builtinsexcept ImportError import builtinstry from site import _Printerexcept ImportError from _sitebuiltins import _Printerbuiltins.scientific _Printer 'scientific' infos
@csrf_exempt@gzip_page@require_sync_session@api_handle_error_with_jsondef device_download data session zone session.client_device.get_zone devicezones list DeviceZone.all_objects.filter zone zone device__in data['devices'] devices [devicezone.device for devicezone in devicezones]session.models_downloaded + len devices + len devicezones return JsonResponse {'devices' serialize devices + devicezones dest_version session.client_version ensure_ascii False }
def action_peek_json body try decoded jsonutils.loads body except ValueError msg _ 'cannotunderstandJSON' raise exception.MalformedRequestBody reason msg if len decoded ! 1 msg _ 'toomanybodykeys' raise exception.MalformedRequestBody reason msg return list decoded.keys [0]
def maven_deploy registry xml_parent data p XML.SubElement xml_parent 'hudson.maven.RedeployPublisher' if 'id' in data XML.SubElement p 'id' .text data['id']if 'url' in data XML.SubElement p 'url' .text data['url']XML.SubElement p 'uniqueVersion' .text str data.get 'unique-version' True .lower XML.SubElement p 'evenIfUnstable' .text str data.get 'deploy-unstable' False .lower if 'release-env-var' in data XML.SubElement p 'releaseEnvVar' .text data['release-env-var']
def tree_entries_from_data data ord_zero ord '0' space_ord ord '' len_data len data i 0out list while i < len_data mode 0while byte_ord data[i] ! space_ord mode mode << 3 + byte_ord data[i] - ord_zero i + 1i + 1ns iwhile byte_ord data[i] ! 0 i + 1name data[ns i]name safe_decode name i + 1sha data[i i + 20 ]i i + 20 out.append sha mode name return out
def _make_rowkey_scan meter rts_start None rts_end None if not rts_start rts_start chr 127 end_row '%s_%s' % meter rts_start start_row '%s_%s' % meter rts_end return start_row end_row
def ServiceRequest opener host method request_dict req _MakeRequest host '/service/%s' % method request_dict return _HandleResponse method opener.open req
def make_utf8_env global _CACHED_ENVif not _CACHED_ENV lang_re re.compile '\\. [^@]* ' env os.environ.copy lang env.get 'LANG' DEFAULT_LANG if lang_re.search lang lang lang_re.sub '.UTF-8' lang else lang DEFAULT_LANGenv['LANG'] lang_CACHED_ENV envreturn _CACHED_ENV
def move_tables manager src_manager tables check_exists src_manager tables TABLE_TYPE for table in tables manager.execute 'RENAMETABLE`% db s`.`% table s`TO`% table s`' % dict db src_manager.get_db_name table table
def siParse s regex FLOAT_REGEX s asUnicode s m regex.match s if m is None raise ValueError 'Cannotparsenumber"%s"' % s try sip m.group 'siPrefix' except IndexError sip ''try suf m.group 'suffix' except IndexError suf ''return m.group 'number' '' if sip is None else sip '' if suf is None else suf
def peek seq iterator iter seq item next iterator return item itertools.chain [item] iterator
def decompress data results []while data decomp BZ2Decompressor try res decomp.decompress data except OSError if results breakelse raiseresults.append res if not decomp.eof raise ValueError 'Compresseddataendedbeforetheend-of-streammarkerwasreached' data decomp.unused_datareturn ''.join results
def send_mass_mail datatuple fail_silently False auth_user None auth_password None connection None connection connection or get_connection username auth_user password auth_password fail_silently fail_silently messages [EmailMessage subject message sender recipient for subject message sender recipient in datatuple]return connection.send_messages messages
def _ad_as_ts expr return None if expr is None else bz.transform expr **{TS_FIELD_NAME expr[AD_FIELD_NAME]}
def set_process_title progname info None proctitle '[%s]' % progname proctitle '%s%s' % proctitle info if info else proctitle if _setproctitle _setproctitle.setproctitle proctitle return proctitle
def test_fit tpot_obj TPOTClassifier random_state 42 population_size 1 generations 1 verbosity 0 tpot_obj.fit training_features training_classes assert isinstance tpot_obj._optimized_pipeline creator.Individual assert tpot_obj._gp_generation 0 assert not tpot_obj._start_datetime is None
def make_list_unique sequence marker_function None seen {}result []for item in sequence marker itemif marker_function is not None marker marker_function item if marker in seen continueseen[marker] Trueresult.append item return result
def setUniformVariables programObj texture texw texh step gl.glUseProgram programObj location_texture gl.glGetUniformLocation programObj 'texture' if location_texture ! -1 gl.glUniform1i location_texture texture location_texw gl.glGetUniformLocation programObj 'texw' if location_texw ! -1 gl.glUniform1f location_texw texw location_texh gl.glGetUniformLocation programObj 'texh' if location_texh ! -1 gl.glUniform1f location_texh texh location_step gl.glGetUniformLocation programObj 'step' if location_step ! -1 gl.glUniform1f location_step step gl.glUseProgram 0 checkGLError
def fanout_cast conf context topic msg check_serialize msg method msg.get 'method' if not method returnargs msg.get 'args' {} version msg.get 'version' None namespace msg.get 'namespace' None for consumer in CONSUMERS.get topic [] try consumer.call context version method namespace args None except Exception pass
def upcast *args t _upcast_memo.get hash args if t is not None return tupcast np.find_common_type args [] for t in supported_dtypes if np.can_cast upcast t _upcast_memo[hash args ] treturn traise TypeError 'nosupportedconversionfortypes %r' % args
def package_in_frozen package_name frozen_output pattern ' ?mi ^{pkg} |#egg {pkg_under}-'.format pkg re.escape package_name pkg_under re.escape package_name.replace '-' '_' return bool re.search pattern frozen_output
def make_frac a denom a np.array a dtype float / sum a b [float v * denom for v in a]b np.array b dtype int err b / float denom - a inds np.argsort err [ denom - sum b ]b[inds] + 1denom int denom b b.tolist return tuple Fraction v denom for v in b
def _clamp_norm_point pos return min 100 max -100 pos[0] min 100 max -100 pos[1]
def _create_file_if_needed filename if os.path.exists filename return Falseelse open filename 'a+b' .close logger.info 'Credentialfile{0}created'.format filename return True
def cosm A A _asarray_square A if np.iscomplexobj A return 0.5 * expm 1j * A + expm -1j * A else return expm 1j * A .real
def validate_cms_config settings validate_common_config settings validate_marketing_site_config settings
def anonymous_id_from_user_id user_id user User.objects.get id user_id return anonymous_id_for_user user None
def find_prompt ssh_conn ssh_conn.send '\n' time.sleep 1 ssh_conn.expect '#' prompt ssh_conn.before + ssh_conn.after return prompt.strip
def create_vlanids LOG.debug _ 'create_vlanids called' session db.get_session try vlanid session.query l2network_models.VlanID .one except exc.MultipleResultsFound passexcept exc.NoResultFound start int conf.VLAN_START end int conf.VLAN_END while start < end vlanid l2network_models.VlanID start session.add vlanid start + 1session.flush return
def getCraftedText fileName text '' liftRepository None return getCraftedTextFromText archive.getTextIfEmpty fileName text liftRepository
def xor aa bb result bytearray for a b in zip bytearray aa bytearray bb result.append a ^ b return result
def ask_full_inference proposition assumptions known_facts_cnf if not satisfiable And known_facts_cnf assumptions proposition return Falseif not satisfiable And known_facts_cnf assumptions Not proposition return Truereturn None
def scheduler_task site event handler now False frappe.logger __name__ .info u'running{handler}for{site}forevent {event}'.format handler handler site site event event try if not now frappe.connect site site frappe.flags.in_scheduler Truefrappe.get_attr handler except Exception frappe.db.rollback traceback log handler u'Method {event} Handler {handler}'.format event event handler handler frappe.logger __name__ .error traceback raiseelse frappe.db.commit frappe.logger __name__ .info u'ran{handler}for{site}forevent {event}'.format handler handler site site event event
def order_filter a domain rank domain asarray domain size domain.shapefor k in range len size if size[k] % 2 ! 1 raise ValueError 'Eachdimensionofdomainargumentshouldhaveanoddnumberofelements.' return sigtools._order_filterND a domain rank
def simulate_post app path **kwargs return simulate_request app 'POST' path **kwargs
def unique_name entry name path typecode entryif typecode in 'BINARY' 'DATA' name os.path.normcase name return name
def get_data name if name in editors return editors[name].get_raw_data return current_container .raw_data name
def get_search_scores query choices ignore_case True template '{}' valid_only False sort False query query.replace '' '' pattern get_search_regex query ignore_case results []for choice in choices r re.search pattern choice if query and r result get_search_score query choice ignore_case ignore_case apply_regex False template template elif query result choice choice NOT_FOUND_SCORE else result choice choice NO_SCORE if valid_only if result[ -1 ] ! NOT_FOUND_SCORE results.append result else results.append result if sort results sorted results key lambda row row[ -1 ] return results
def _find_aggregate cs aggregate return utils.find_resource cs.aggregates aggregate
def _get_valid_pathstr pathstr if not isinstance pathstr str bytes pathstr to_str pathstr pathstr pathstr.replace os.sep u'..' pathstr re.sub u'[][ {}? <>#!|"\';]' u'' pathstr pathstr pathstr.replace u' ' u'.' return pathstr
def test_invalid_list_comprehension cant_compile u' genexprx[] ' cant_compile u' genexpr[x[1234]]x ' cant_compile u' list-compNone[] ' cant_compile u' list-comp[x[123]]x '
def complete_filename text list glob.glob text + '*' for idx val in enumerate list if os.path.isdir val list[idx] val + os.path.sep return list
def ansible_dict_to_boto3_tag_list tags_dict tags_list []for k v in tags_dict.items tags_list.append {'Key' k 'Value' v} return tags_list
def getLoopsIntersectionByPair importRadius loopsFirst loopsLast radiusSide 0.01 * importRadius corners getLoopsListsIntersections [loopsFirst loopsLast] corners + getInsetPointsByInsetLoops loopsFirst True loopsLast radiusSide corners + getInsetPointsByInsetLoops loopsLast True loopsFirst radiusSide allPoints corners[ ]allPoints + getInsetPointsByInsetLoops getInBetweenLoopsFromLoops importRadius loopsFirst True loopsLast radiusSide allPoints + getInsetPointsByInsetLoops getInBetweenLoopsFromLoops importRadius loopsLast True loopsFirst radiusSide return trianglemesh.getDescendingAreaLoops allPoints corners importRadius
def validateSVGfiles svgFilePathsList validatedPaths []for filePath in svgFilePathsList fileName os.path.basename filePath if fileName[0] '.' continuedata readFile filePath svg reSVGelement.search data if not svg print 'WARNING Couldnotfind<svg>elementinthefile.Skiping%s' % filePath continuevalidatedPaths.append filePath return validatedPaths
@deprecated 'Thefunctionwishart_logzisdeprecatedin0.18andwillberemovedin0.20.' def wishart_logz v s dets n_features z 0.0z + 0.5 * v * n_features * np.log 2 z + 0.25 * n_features * n_features - 1 * np.log np.pi z + 0.5 * v * np.log dets z + np.sum gammaln 0.5 * v - np.arange n_features + 1 return z
def bucket_upload_file self Filename Key ExtraArgs None Callback None Config None return self.meta.client.upload_file Filename Filename Bucket self.name Key Key ExtraArgs ExtraArgs Callback Callback Config Config
def namedtmp name rm True path os.path.join tmpdir name if rm try os.unlink path except OSError IOError passreturn path
def toposort_flatten data sort True result []for d in toposort data result.extend sorted if sort else list d return result
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
def map_wmc request mapid template 'maps/wmc.xml' map_obj _resolve_map request mapid 'base.view_resourcebase' _PERMISSION_MSG_VIEW return render_to_response template RequestContext request {'map' map_obj 'siteurl' settings.SITEURL} content_type 'text/xml'
def jenkins_info_from_response project if project.get 'inQueue' False return JenkinsResults.RUNNING {} if 'builds' not in project return JenkinsResults.UNKNOWN {} if len project['builds'] < 1 return JenkinsResults.NOTRUN {} result jenkins_result_from_api project['builds'][0]['result'] return result properties_to_params project['property']
def _strong_gens_from_distr strong_gens_distr if len strong_gens_distr 1 return strong_gens_distr[0][ ]else result strong_gens_distr[0]for gen in strong_gens_distr[1] if gen not in result result.append gen return result
def module_is_loaded module_name module_name module_name.replace '-' '_' return bool loaded_module_info module_name
def authentication_method_generator request auth if auth is None raise exception.ValidationError attribute 'auth' target 'requestbody' if request.environ.get 'REMOTE_USER' method ExternalAuthenticationMethod elif 'token' in auth method TokenAuthenticationMethod elif 'passwordCredentials' in auth method LocalAuthenticationMethod else raise exception.ValidationError attribute 'auth' target 'requestbody' return method
def get_trace_component_for_rule rule_db trigger_instance_db trace_component {}trace_component {'id' str rule_db.id 'ref' rule_db.ref}caused_by {}if trigger_instance_db caused_by['type'] 'trigger_instance'caused_by['id'] str trigger_instance_db.id trace_component['caused_by'] caused_byreturn trace_component
def from_2D_to_1D constant if isinstance constant np.ndarray return np.asarray constant [ 0]else return constant
def sig2 method endpoint params provider aws_api_version timenow datetime.utcnow timestamp timenow.strftime '%Y-%m-%dT%H %M %SZ' access_key_id secret_access_key token creds provider params_with_headers params.copy params_with_headers['AWSAccessKeyId'] access_key_idparams_with_headers['SignatureVersion'] '2'params_with_headers['SignatureMethod'] 'HmacSHA256'params_with_headers['Timestamp'] '{0}'.format timestamp params_with_headers['Version'] aws_api_versionkeys sorted params_with_headers.keys values list list map params_with_headers.get keys querystring urlencode list zip keys values canonical '{0}\n{1}\n/\n{2}'.format method.encode 'utf-8' endpoint.encode 'utf-8' querystring.encode 'utf-8' hashed hmac.new secret_access_key canonical hashlib.sha256 sig binascii.b2a_base64 hashed.digest params_with_headers['Signature'] sig.strip if token ! '' params_with_headers['SecurityToken'] tokenreturn params_with_headers
def chown path owner execute 'chown' owner path run_as_root True
def test_cert thumbprint context _DEFAULT_CONTEXT store _DEFAULT_STORE untrusted_root False dns_name '' eku '' cmd list thumbprint thumbprint.upper cert_path 'Cert \\{0}\\{1}\\{2}'.format context store thumbprint cmd.append "Test-Certificate-Cert'{0}'".format cert_path _validate_cert_path name cert_path if untrusted_root cmd.append '-AllowUntrustedRoot' if dns_name cmd.append "-DnsName'{0}'".format dns_name if eku cmd.append "-EKU'{0}'".format eku cmd.append '-ErrorActionSilentlyContinue' return ast.literal_eval _cmd_run cmd str .join cmd
def get_column_letter col_idx if not 1 < col_idx < 18278 msg 'Columnindexoutofbounds %s' % col_idx raise ColumnStringIndexException msg ordinals []temp col_idxwhile temp quotient remainder divmod temp 26 if remainder 0 quotient - 1remainder 26ordinals.append remainder + 64 temp quotientordinals.reverse return ''.join [chr ordinal for ordinal in ordinals]
def variable_device device name if callable device var_name tf.get_variable_scope .name + '/' + name var_def tf.NodeDef name var_name op 'Variable' device device var_def if device is None device ''return device
def port_allocator registry xml_parent data pa XML.SubElement xml_parent 'org.jvnet.hudson.plugins.port__allocator.PortAllocator' ports XML.SubElement pa 'ports' names data.get 'names' if not names logger logging.getLogger __name__ logger.warning 'port_allocatornameisdeprecated useanameslistinstead' names [data['name']]for name in names dpt XML.SubElement ports 'org.jvnet.hudson.plugins.port__allocator.DefaultPortType' XML.SubElement dpt 'name' .text name
def get_sort_func is_float is_argsort False key is_float is_argsort try return _sorts[key]except KeyError sort quicksort.make_jit_quicksort lt lt_floats if is_float else None is_argsort is_argsort func _sorts[key] sort.run_quicksortreturn func
def _url_val val obj serializer request **kwargs url Noneif isinstance val Link url val.resolve_url obj request elif isinstance val basestring if getattr serializer 'field' None serializer serializer.parenturl getattr serializer val obj if obj is not None else None else url valif not url and url ! 0 raise SkipFieldelse return url
def agent_build_destroy context agent_update_id IMPL.agent_build_destroy context agent_update_id
def is_self_paced course return course and course.self_paced and SelfPacedConfiguration.current .enabled
@on_valid 'file/dynamic' def file data response **kwargs if hasattr data 'read' name data getattr data 'name' '' data elif os.path.isfile data name data data open data 'rb' else response.content_type 'text/plain'response.status HTTP_NOT_FOUNDreturn 'Filenotfound!'response.content_type mimetypes.guess_type name None [0] or 'application/octet-stream' return data
def dup_decompose f K F []while True result _dup_decompose f K if result is not None f h resultF [h] + F else breakreturn [f] + F
def QueryFollowed device logger callback def _OnResponse response response_dict www_util.ParseJSONResponse response viewpoints response_dict.get 'viewpoints' if len viewpoints < 1 logger.error 'query_followedreturned0viewpoints shouldalwaysreturnatleastone.' else logger.info 'QueryFollowedscenariopassed.' callback device.SendRequest 'service/query_followed' _OnResponse 'POST' limit 5 headers {'version' message.MAX_SUPPORTED_MESSAGE_VERSION}
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def _bessel_poly n reverse False if abs int n ! n raise ValueError 'Polynomialordermustbeanonnegativeinteger' else n int n out []for k in range n + 1 num _falling_factorial 2 * n - k n den 2 ** n - k * factorial k exact True out.append num // den if reverse return out[ -1 ]else return out
def check_password password encoded setter None preferred u'default' if not password or not is_password_usable encoded return Falsepreferred get_hasher preferred hasher identify_hasher encoded must_update hasher.algorithm ! preferred.algorithm is_correct hasher.verify password encoded if setter and is_correct and must_update setter password return is_correct
def result_extractor train_obj import numpychannels train_obj.model.monitor.channelstrain_cost channels['sgd_cost ExhaustiveSGD[X] ']best_epoch numpy.argmin train_cost.val_record best_rec_error train_cost.val_record[best_epoch]batch_num train_cost.batch_record[best_epoch]return dict best_epoch best_epoch train_rec_error best_rec_error batch_num batch_num
def _mapper_or_none entity insp inspection.inspect entity False if insp is not None return insp.mapperelse return None
def test_iforest_error X iris.dataassert_raises ValueError IsolationForest max_samples -1 .fit X assert_raises ValueError IsolationForest max_samples 0.0 .fit X assert_raises ValueError IsolationForest max_samples 2.0 .fit X assert_warns_message UserWarning 'max_sampleswillbesetton_samplesforestimation' IsolationForest max_samples 1000 .fit X assert_no_warnings IsolationForest max_samples 'auto' .fit X assert_no_warnings IsolationForest max_samples np.int64 2 .fit X assert_raises ValueError IsolationForest max_samples 'foobar' .fit X assert_raises ValueError IsolationForest max_samples 1.5 .fit X
def spearman_correlation ranks1 ranks2 n 0res 0for k d in _rank_dists ranks1 ranks2 res + d * d n + 1try return 1 - 6 * res / n * n * n - 1 except ZeroDivisionError return 0.0
def submit request if not request.user.is_authenticated return proceed request user UserProfile.objects.get pk request.user.id if not user.read_dev_agreement return redirect 'submit.app.terms' return manifest request
def create_multiple_choice_xml correct_choice 2 num_choices 4 choices [False for _ in range num_choices ]choices[correct_choice] Truechoice_names ['choice_{}'.format index for index in range num_choices ]question_text 'ThecorrectanswerisChoice{}'.format correct_choice return MultipleChoiceResponseXMLFactory .build_xml question_text question_text choices choices choice_names choice_names
def validate_archive_keys info keys ['snapshotfile' 'framework' 'name']for key in keys if key not in info return False key return True 0
def error_response status 400 cause None **kw if cause is not None current_app.logger.exception str cause kw['status'] statusreturn errors_response status [error **kw ]
def load_testsuite loader dir suite unittest.TestSuite files []for f in os.listdir dir path join dir f if isfile path and fnmatch f 'test_*.py' files.append f elif isfile join path '__init__.py' suite.addTests loader.discover path for f in files f relpath join dir f loader._top_level_dir f splitext normpath f.replace os.path.sep '.' [0]suite.addTests loader.loadTestsFromName f return suite
def file_upload_view request form_data request.POST.copy form_data.update request.FILES if isinstance form_data.get u'file_field' UploadedFile and isinstance form_data[u'name'] six.text_type if os.path.dirname form_data[u'file_field'].name ! u'' return HttpResponseServerError return HttpResponse u'' else return HttpResponseServerError
def confidenceIntervalSize stdev nbsamples return 2 * 1.98 * stdev / sqrt nbsamples
def split32 data all_pieces []for position in range 0 len data 32 piece data[position position + 32 ]all_pieces.append piece return all_pieces
def FakeAccess path mode if not os.path.exists path or mode ! os.R_OK return Falseelse return True
def get_models app_mod None app_list get_apps if app_mod return _app_models.get app_mod.__name__.split '.' [ -2 ] {} .values else model_list []for app_mod in app_list model_list.extend get_models app_mod return model_list
def parse xml_string target_class None version 1 encoding None if target_class is None target_class XmlElementif isinstance xml_string unicode if encoding is None xml_string xml_string.encode STRING_ENCODING else xml_string xml_string.encode encoding tree ElementTree.fromstring xml_string return _xml_element_from_tree tree target_class version
def getPixmap name key name + '.png' data pixmapData.pixmapData[key]if isinstance data basestring or isinstance data bytes pixmapData.pixmapData[key] pickle.loads data arr pixmapData.pixmapData[key]return QtGui.QPixmap makeQImage arr alpha True
def lookup_connections backend identities if isinstance backend string_types backend _ Backend.objects.get_or_create name backend connections []for identity in identities connection _ backend.connection_set.get_or_create identity identity connections.append connection return connections
def onearg x return 2 * x
def get_console_screen_buffer_info fd 1 hcon STDHANDLES[fd]csbi CONSOLE_SCREEN_BUFFER_INFO GetConsoleScreenBufferInfo hcon byref csbi return csbi
def _byte_string s return s.encode 'US-ASCII'
def validate_row app_id row zookeeper db_access row_key row.keys [0]entity row.values [0]if APP_ENTITY_SCHEMA[1] not in entity return rowrow_txn long entity[APP_ENTITY_SCHEMA[1]] valid_txn zookeeper.get_valid_transaction_id app_id row_txn row_key if row_txn valid_txn return rowif valid_txn 0 return Nonepadded_version str valid_txn .zfill ID_KEY_LENGTH journal_key dbconstants.KEY_DELIMITER.join [row_key padded_version] journal_results db_access.batch_get_entity dbconstants.JOURNAL_TABLE [journal_key] dbconstants.JOURNAL_SCHEMA journal_row journal_results[journal_key]if dbconstants.JOURNAL_SCHEMA[0] not in journal_row return Nonevalid_entity journal_row[dbconstants.JOURNAL_SCHEMA[0]]return {row_key {APP_ENTITY_SCHEMA[0] valid_entity APP_ENTITY_SCHEMA[1] str valid_txn }}
def dict_to_keyval value key_base None val_iter key_func None None if isinstance value dict val_iter six.iteritems value key_func lambda k key_base + '.' + k if key_base else k elif isinstance value tuple list val_iter enumerate value key_func lambda k key_base + '[%d]' % k if val_iter for k v in val_iter key_gen key_func k if isinstance v dict or isinstance v tuple list for key_gen v in dict_to_keyval v key_gen yield key_gen v else yield key_gen v
def test_solve_discrete_lyapunov_B A np.ones 2 2 * 0.5 B np.array [[0.5 -0.5 ] [ -0.5 0.5]] X qme.solve_discrete_lyapunov A B assert_allclose B X
def set_item_user_text item text item.setData 0 Qt.UserRole to_qvariant text
def get_repo_latest_revision_hash repo_path try exit_code stdout _ run_command cmd ['git' 'rev-parse' 'HEAD'] cwd repo_path except Exception revision_hash 'unknown'else if exit_code 0 revision_hash stdout.strip else revision_hash 'unknown'return revision_hash
@bdd.then bdd.parsers.parse '{path}shouldbeloaded' def path_should_be_loaded quteproc path quteproc.wait_for_load_finished path
def handle_merge translation request next_unit_url if not can_translate request.user translation messages.error request _ u"Youdon'thaveprivilegestosavetranslations!" returnmergeform MergeForm translation request.GET if not mergeform.is_valid messages.error request _ u'Invalidmergerequest!' returnunit mergeform.cleaned_data[u'unit']merged Unit.objects.get pk mergeform.cleaned_data[u'merge'] if unit.checksum ! merged.checksum messages.error request _ u'Cannotmergedifferentmessages!' else unit.target merged.targetunit.fuzzy merged.fuzzysaved unit.save_backend request if saved request.user.profile.translated + 1request.user.profile.save return HttpResponseRedirect next_unit_url
def get_md5 *args **kwargs if MD5_AVAILABLE return hashlib.md5 *args **kwargs else raise MD5UnavailableError
def _compare_keys key_record1 key_record2 return cmp key_record1[0] key_record2[0]
def all_editable_exts exts []for language extensions in sourcecode.ALL_LANGUAGES.items exts.extend list extensions return [ '.' + ext for ext in exts]
def build_dev_from_opts opts for attribute shortopt longopt in ['region' '-r' '--region'] ['zone' '-z' '--zone'] ['ip' '-i' '--ip'] ['port' '-p' '--port'] ['device' '-d' '--device'] ['weight' '-w' '--weight'] if getattr opts attribute None is None raise ValueError 'Requiredargument%s/%snotspecified.' % shortopt longopt ip validate_and_normalize_address opts.ip replication_ip validate_and_normalize_address opts.replication_ip or opts.ip replication_port opts.replication_port or opts.port if not validate_device_name opts.device raise ValueError 'Invaliddevicename' return {'region' opts.region 'zone' opts.zone 'ip' ip 'port' opts.port 'device' opts.device 'meta' opts.meta 'replication_ip' replication_ip 'replication_port' replication_port 'weight' opts.weight}
def get_build_id_offsets return {'i386' [372] 'arm' [372] 'thumb' [372] 'aarch64' [568] 'amd64' [624 372] 'powerpc' [372] 'powerpc64' [568] 'sparc' [372] 'sparc64' [624]}.get context.arch []
def Distribution pos size counts dtype x numpy.zeros size dtype dtype if hasattr pos '__iter__' total 0for i in pos total + counts[i]total float total for i in pos x[i] counts[i] / total else x[pos] 1return x
def collection_creation_options return CREATION_ONLY_OPTION
def check_threshold birch_instance threshold current_leaf birch_instance.dummy_leaf_.next_leaf_while current_leaf subclusters current_leaf.subclusters_for sc in subclusters assert_greater_equal threshold sc.radius current_leaf current_leaf.next_leaf_
def construct **kwargs point_x kwargs.pop 'point_x' None point_y kwargs.pop 'point_y' None if 'point' in kwargs raise TypeError 'Unknownkeyword point' if None not in point_x point_y kwargs['point'] EccPoint point_x point_y eq1 pow Integer point_y 2 _curve.p x Integer point_x eq2 pow x 3 _curve.p x * -3 eq2 + xeq2 + _curve.beq2 % _curve.pif eq1 ! eq2 raise ValueError 'Thepointisnotonthecurve' d kwargs.get 'd' None if d is not None and 'point' in kwargs pub_key _curve.G * d if pub_key.x ! point_x or pub_key.y ! point_y raise ValueError 'PrivateandpublicECCkeysdonotmatch' return EccKey **kwargs
def choice argument values try value argument.lower .strip except AttributeError raise ValueError 'mustsupplyanargument;choosefrom%s' % format_values values if value in values return valueelse raise ValueError '"%s"unknown;choosefrom%s' % argument format_values values
def v_str v_tuple return '.'.join str x for x in v_tuple
def find_notifier obj name prop_meta find_meta_property obj name if not prop_meta.hasNotifySignal raise TypeError '%sdoesnothaveanotifiersignal.' % name notifier prop_meta.notifySignal if QT_VERSION < 327680 name notifier.signature .split ' ' [0]else name bytes notifier.methodSignature .decode 'utf-8' .split ' ' [0]return name
def ioType fileIshObject default unicode if isinstance fileIshObject TextIOBase return unicodeif isinstance fileIshObject IOBase return bytesencoding getattr fileIshObject 'encoding' None import codecsif isinstance fileIshObject codecs.StreamReader codecs.StreamWriter if encoding return unicodeelse return bytesif not _PY3 if isinstance fileIshObject file if encoding is not None return basestringelse return bytesfrom cStringIO import InputType OutputTypefrom StringIO import StringIOif isinstance fileIshObject StringIO InputType OutputType return bytesreturn default
def getOverhangDirection belowOutsetLoops segmentBegin segmentEnd segment segmentEnd - segmentBegin normalizedSegment euclidean.getNormalized complex segment.real segment.imag segmentYMirror complex normalizedSegment.real - normalizedSegment.imag segmentBegin segmentYMirror * segmentBegin segmentEnd segmentYMirror * segmentEnd solidXIntersectionList []y segmentBegin.imagsolidXIntersectionList.append euclidean.XIntersectionIndex -1.0 segmentBegin.real solidXIntersectionList.append euclidean.XIntersectionIndex -1.0 segmentEnd.real for belowLoopIndex in xrange len belowOutsetLoops belowLoop belowOutsetLoops[belowLoopIndex]rotatedOutset euclidean.getRotatedComplexes segmentYMirror belowLoop euclidean.addXIntersectionIndexesFromLoopY rotatedOutset belowLoopIndex solidXIntersectionList y overhangingSegments euclidean.getSegmentsFromXIntersectionIndexes solidXIntersectionList y overhangDirection complex for overhangingSegment in overhangingSegments overhangDirection + getDoubledRoundZ overhangingSegment normalizedSegment return overhangDirection
def getTopOverBottom angle endZ inradiusComplex startZ return max 1.0 - abs endZ - startZ * math.tan angle / lineation.getRadiusAverage inradiusComplex 0.0
def in_travis return os.getenv IN_TRAVIS_ENV 'true'
def get_tm_session session_factory transaction_manager dbsession session_factory zope.sqlalchemy.register dbsession transaction_manager transaction_manager return dbsession
def guess_digit image avgs darkness sum image distances {k abs v - darkness for k v in avgs.iteritems }return min distances key distances.get
def _distribute_gens_by_base base gens base_len len base degree gens[0].sizestabs [[] for _ in range base_len ]max_stab_index 0for gen in gens j 0while j < base_len - 1 and gen._array_form[base[j]] base[j] j + 1if j > max_stab_index max_stab_index jfor k in range j + 1 stabs[k].append gen for i in range max_stab_index + 1 base_len stabs[i].append _af_new list range degree return stabs
def get_cached_row klass row index_start max_depth 0 cur_depth 0 if max_depth and cur_depth > max_depth return Noneindex_end index_start + len klass._meta.fields obj klass *row[index_start index_end] for f in klass._meta.fields if f.rel and not f.null cached_row get_cached_row f.rel.to row index_end max_depth cur_depth + 1 if cached_row rel_obj index_end cached_rowsetattr obj f.get_cache_name rel_obj return obj index_end
def remove_credential tenant_id credential_id session db.get_session try cred session.query l2network_models.Credential .filter_by tenant_id tenant_id .filter_by credential_id credential_id .one session.delete cred session.flush return credexcept exc.NoResultFound pass
def PackBlob name value pbvalue pbvalue.set_stringvalue value
def setup_config test control_address u'10.0.0.1' control_port 1234 name None log_config None if name is None name random_name test ca_set get_credential_sets [0]scratch_directory test.make_temporary_directory contents {u'control-service' {u'hostname' control_address u'port' control_port} u'dataset' {u'backend' u'zfs' u'name' name u'mount_root' scratch_directory.child 'mount_root' .path u'volume_config_path' scratch_directory.child 'volume_config.json' .path} u'version' 1}if log_config is not None contents[u'logging'] log_configtest.config scratch_directory.child 'dataset-config.yml' test.config.setContent yaml.safe_dump contents ca_set.copy_to scratch_directory node True test.ca_set ca_set
def _setup_appengine_sdk session session.env['GAE_SDK_PATH'] os.path.join _GAE_ROOT 'google_appengine' session.run 'gcprepotools' 'download-appengine-sdk' _GAE_ROOT
def apphook_post_delete_page_checker instance **kwargs if instance.application_urls request_finished.connect trigger_restart dispatch_uid DISPATCH_UID
def supports_selection return QApplication.clipboard .supportsSelection
def dict_option s return DictValueComponent.create s
def test_tricky_confparse cp_data confparse.ConfParse file os.path.join os.path.dirname __file__ 'test_data' 'sample_conf.xml' assert_equal 'org.apache.hadoop.examples.SleepJob' cp_data['mapred.mapper.class']
def expm_frechet A E method None compute_expm True check_finite True if check_finite A np.asarray_chkfinite A E np.asarray_chkfinite E else A np.asarray A E np.asarray E if A.ndim ! 2 or A.shape[0] ! A.shape[1] raise ValueError 'expectedAtobeasquarematrix' if E.ndim ! 2 or E.shape[0] ! E.shape[1] raise ValueError 'expectedEtobeasquarematrix' if A.shape ! E.shape raise ValueError 'expectedAandEtobethesameshape' if method is None method 'SPS'if method 'SPS' expm_A expm_frechet_AE expm_frechet_algo_64 A E elif method 'blockEnlarge' expm_A expm_frechet_AE expm_frechet_block_enlarge A E else raise ValueError 'Unknownimplementation%s' % method if compute_expm return expm_A expm_frechet_AE else return expm_frechet_AE
@jingo.register.functiondef showing query pager format_opts pager.start_index pager.end_index pager.paginator.count query escape query if query showing _ u'Showing{0}-{1}of{2}resultsfor<strong>{3}</strong>' .format * format_opts + query else showing _ u'Showing{0}-{1}of{2}results' .format *format_opts return jinja2.Markup showing
def get_inputfuncs session *args **kwargs inputfuncsdict dict key func.__doc__ for key func in session.sessionhandler.get_inputfuncs .iteritems session.msg get_inputfuncs inputfuncsdict
def init mpstate return CmdlongModule mpstate
def clues_pay text text text.lower for clue in 'credits' 'paym' 'expired' if clue in text return Truereturn False
def DataChunker receiver x _DataChunker receiver x.next return x.send
def edf_normal_inverse_transformed x alpha 3.0 / 8 beta 3.0 / 8 axis 0 from scipy import statsranks plotting_positions data alpha alpha beta alpha axis 0 masknan False ranks_transf stats.norm.ppf ranks return ranks_transf
def change_keys recs key 'uuid' filter_func None new_recs {}for ref rec in recs.iteritems if filter_func is not None and not filter_func rec continuenew_recs[rec[key]] recnew_recs[rec[key]]['ref'] refreturn new_recs
def string_to_datetime model fieldname value if value is None return valuefield_type get_field_type model fieldname if isinstance field_type Date Time DateTime if value.strip '' return Noneif value in CURRENT_TIME_MARKERS return getattr func value.lower value_as_datetime parse_datetime value if isinstance field_type Date return value_as_datetime.date if isinstance field_type Time return value_as_datetime.timetz return value_as_datetimeif isinstance field_type Interval and isinstance value int return datetime.timedelta seconds value return value
def _format_final_exc_line etype value valuestr _some_str value if value is None or not valuestr line '%s\n' % etype else line '%s %s\n' % etype valuestr return line
def downtime_steps data_gb downtime CONF.libvirt.live_migration_downtimesteps CONF.libvirt.live_migration_downtime_stepsdelay CONF.libvirt.live_migration_downtime_delaydowntime_min nova.conf.libvirt.LIVE_MIGRATION_DOWNTIME_MINsteps_min nova.conf.libvirt.LIVE_MIGRATION_DOWNTIME_STEPS_MINdelay_min nova.conf.libvirt.LIVE_MIGRATION_DOWNTIME_DELAY_MINif downtime < downtime_min LOG.warning _LW "Configoptionlive_migration_downtime'svalueislessthanminimumvalue%dms roundeduptotheminimumvalueandwillraiseValueErrorinthefuturerelease." downtime_min downtime downtime_minif steps < steps_min LOG.warning _LW "Configoptionlive_migration_downtime_steps'svalueislessthanminimumvalue%dms roundeduptotheminimumvalueandwillraiseValueErrorinthefuturerelease." steps_min steps steps_minif delay < delay_min LOG.warning _LW "Configoptionlive_migration_downtime_delay'svalueislessthanminimumvalue%dms roundeduptotheminimumvalueandwillraiseValueErrorinthefuturerelease." delay_min delay delay_mindelay int delay * data_gb offset downtime / float steps + 1 base downtime - offset ** 1 / float steps for i in range steps + 1 yield int delay * i int offset + base ** i
@app.route '/hidden-basic-auth/<user>/<passwd>' def hidden_basic_auth user 'user' passwd 'passwd' if not check_basic_auth user passwd return status_code 404 return jsonify authenticated True user user
def task_enable_root_logins distribution commands [sudo_from_args ['sed' '-i' '1iPermitRootLoginyes' '/etc/ssh/sshd_config'] ]if is_systemd_distribution distribution commands.append sudo_from_args ['systemctl' 'restart' 'sshd'] else commands.append sudo_from_args ['service' 'ssh' 'restart'] return sequence commands
def find_master_dns session parsed_globals cluster_id client get_client session parsed_globals data client.describe_cluster ClusterId cluster_id return data['Cluster']['MasterPublicDnsName']
@validatordef truthy value return value and not isinstance value six.string_types or value.strip
def _get_default_profile_image_urls return _get_profile_image_urls configuration_helpers.get_value 'PROFILE_IMAGE_DEFAULT_FILENAME' settings.PROFILE_IMAGE_DEFAULT_FILENAME staticfiles_storage file_extension settings.PROFILE_IMAGE_DEFAULT_FILE_EXTENSION
@mock_streams 'stderr' @with_patched_object output 'aborts' True def test_abort_message try abort 'Test' except SystemExit passresult sys.stderr.getvalue eq_ '\nFatalerror Test\n\nAborting.\n' result
def floyd_warshall_numpy G nodelist None weight 'weight' try import numpy as npexcept ImportError raise ImportError 'to_numpy_matrix requiresnumpy http //scipy.org/' A nx.to_numpy_matrix G nodelist nodelist multigraph_weight min weight weight nonedge np.inf n m A.shapeI np.identity n A[ I 1 ] 0for i in range n A np.minimum A A[i ] + A[ i] return A
def get_user_headers user credentials '%s secret' % user authorization 'Basic{0}'.format encode64 credentials return {'Authorization' authorization}
def show_toolbar request if request.META.get u'REMOTE_ADDR' None not in settings.INTERNAL_IPS return Falseif request.is_ajax return Falsereturn bool settings.DEBUG
def get_top_state_rule_answers_multi exploration_state_list rule_str_list answer_log_list stats_domain.StateRuleAnswerLog.get_multi_by_multi_explorations exploration_state_list rule_str_list return [[{'value' top_answer[0] 'count' top_answer[1]} for top_answer in answer_log.get_all_top_answers ] for answer_log in answer_log_list]
def test_ast_bad_except cant_compile u' except1 ' cant_compile u' try1 except1 ' cant_compile u' try1 except[13] ' cant_compile u' try1 except[x[FooBar]BarBar] '
def add_lease mac ip_address api network_rpcapi.NetworkAPI api.lease_fixed_ip context.get_admin_context ip_address CONF.host
def elu x alpha 1.0 res tf.nn.elu x if alpha 1 return reselse return tf.where x > 0 res alpha * res
def _has_catalog_visibility course visibility_type return ACCESS_GRANTED if course.catalog_visibility visibility_type else ACCESS_DENIED
def _process_caps caps return [x.strip .split for x in caps.strip .split '\n' ]
@open_file 0 mode 'rb' def read_adjlist path comments '#' delimiter None create_using None nodetype None encoding 'utf-8' lines line.decode encoding for line in path return parse_adjlist lines comments comments delimiter delimiter create_using create_using nodetype nodetype
def getall return _load .copy
def date value arg None from django.utils.dateformat import formatif not value return ''if arg is None arg settings.DATE_FORMATreturn format value arg
def list_backends return _ACTIVE_BACKENDS
def _should_set_tablename bases d if '__tablename__' in d or '__table__' in d or '__abstract__' in d return Falseif any v.primary_key for v in itervalues d if isinstance v sqlalchemy.Column return Truefor base in bases if hasattr base '__tablename__' or hasattr base '__table__' return Falsefor name in dir base attr getattr base name if isinstance attr sqlalchemy.Column and attr.primary_key return True
def _time_from_iso8601_time_naive value return datetime.datetime.strptime value '%H %M %S' .time
def normalize_keystr keystr keystr keystr.lower replacements 'control' 'ctrl' 'windows' 'meta' 'mod1' 'alt' 'mod4' 'meta' for orig repl in replacements keystr keystr.replace orig repl for mod in ['ctrl' 'meta' 'alt' 'shift'] keystr keystr.replace mod + '-' mod + '+' return keystr
def collapse_cell_addresses cells input_ranges keyfunc lambda x x[0] raw_coords [coordinate_from_string cell for cell in cells]grouped_coords OrderedDict k [c[1] for c in g] for k g in groupby sorted raw_coords key keyfunc keyfunc ranges list input_ranges for column in grouped_coords rows sorted grouped_coords[column] grouped_rows [[r[1] for r in list g ] for k g in groupby enumerate rows lambda x x[0] - x[1] ]for rows in grouped_rows if len rows 0 passelif len rows 1 ranges.append '%s%d' % column rows[0] else ranges.append '%s%d %s%d' % column rows[0] column rows[ -1 ] return ''.join ranges
def parse_port_range_list range_list_str log.warning 'parse_key_value_list isdeprecatedandwillberemovedinv0.6.0' return _parse_port_range_list range_list_str
def add_available_prefixes parent prefix_list available_prefixes netaddr.IPSet parent ^ netaddr.IPSet [p.prefix for p in prefix_list] available_prefixes [Prefix prefix p for p in available_prefixes.iter_cidrs ]prefix_list list prefix_list + available_prefixes prefix_list.sort key lambda p p.prefix return prefix_list
def get_language_code language_code site_id None if not language_code return Nonelanguages get_language_list site_id if language_code in languages return language_codefor lang in languages if language_code.split '-' [0] lang return langif lang.split '-' [0] language_code return langreturn language_code
def get_linode kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theget_linodefunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None linode_id kwargs.get 'linode_id' None if name is None and linode_id is None raise SaltCloudSystemExit "Theget_linodefunctionrequireseithera'name'ora'linode_id'." if linode_id is None linode_id get_linode_id_from_name name result _query 'linode' 'list' args {'LinodeID' linode_id} return result['DATA'][0]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_jid jid ret {}for returner_ in __opts__[CONFIG_KEY] ret.update _mminion .returners['{0}.get_jid'.format returner_ ] jid return ret
def ssh_agent_credentials registry xml_parent data logger logging.getLogger __name__ entry_xml XML.SubElement xml_parent 'com.cloudbees.jenkins.plugins.sshagent.SSHAgentBuildWrapper' xml_key 'user'user_list list if 'users' in data user_list + data['users']if len user_list > 1 entry_xml XML.SubElement entry_xml 'credentialIds' xml_key 'string'if 'user' in data logger.warning "Both'users'and'user'parametersspecifiedforssh-agent-credentials.'users'isused 'user'isignored." elif 'user' in data logger.warning "The'user'paramhasbeendeprecated usethe'users'paraminstead." user_list.append data['user'] else raise JenkinsJobsException "Missing'user'or'users'parameterforssh-agent-credentials" for user in user_list XML.SubElement entry_xml xml_key .text user
def convert_to_bytes string factors {'K' 1024 'M' 1024 * 1024 'G' 1024 * 1024 * 1024 'T' 1024 * 1024 * 1024 * 1024 'P' 1024 * 1024 * 1024 * 1024 * 1024 'E' 1024 * 1024 * 1024 * 1024 * 1024 * 1024 }for f fm in factors.items if string.endswith f number float string[ -1 ] number number * fm return long number return long string
@depends 'cx_Oracle' fallback_function _cx_oracle_req def client_version return '.'.join str x for x in cx_Oracle.clientversion
def _as_float_array x check_finite False x np.ascontiguousarray x if not np.issubdtype x.dtype np.inexact x x.astype float if check_finite and not np.isfinite x .all raise ValueError 'Arraymustnotcontaininfsornans.' return x
def disable_animations page disable_jquery_animations page disable_css_animations page
def PackTag field_number wire_type if not 0 < wire_type < _WIRETYPE_MAX raise message.EncodeError 'Unknownwiretype %d' % wire_type return field_number << TAG_TYPE_BITS | wire_type
def dimensionless_angles return [ si.radian None ]
def privileges_get cursor user host output {}cursor.execute 'SHOWGRANTSFOR%s@%s' user host grants cursor.fetchall def pick x if x 'ALLPRIVILEGES' return 'ALL'else return xfor grant in grants res re.match "GRANT .+ ON .+ TO'.*'@'.+' IDENTIFIEDBYPASSWORD'.+' ?? .* " grant[0] if res is None raise InvalidPrivsError 'unabletoparsetheMySQLgrantstring %s' % grant[0] privileges res.group 1 .split ' ' privileges [pick x for x in privileges]if 'WITHGRANTOPTION' in res.group 4 privileges.append 'GRANT' if 'REQUIRESSL' in res.group 4 privileges.append 'REQUIRESSL' db res.group 2 output[db] privilegesreturn output
def FIRST fragment return fragment.startchar
def _svn_revision filename p subprocess.Popen [u'svn' u'status' u'-v' filename] stdout subprocess.PIPE stderr subprocess.PIPE stdout stderr p.communicate if p.returncode ! 0 or stderr or not stdout raise ValueError u'Errordeterminingsvn_revisionfor%s %s' % os.path.split filename [1] textwrap.fill stderr return stdout.split [2]
def _json_convert obj json_options DEFAULT_JSON_OPTIONS if hasattr obj 'iteritems' or hasattr obj 'items' return SON k _json_convert v json_options for k v in iteritems obj elif hasattr obj '__iter__' and not isinstance obj text_type bytes return list _json_convert v json_options for v in obj try return default obj json_options except TypeError return obj
def p_abstract_declarator_1 t pass
def triang M sym True if _len_guards M return np.ones M M needs_trunc _extend M sym n np.arange 1 M + 1 // 2 + 1 if M % 2 0 w 2 * n - 1.0 / M w np.r_[ w w[ -1 ] ]else w 2 * n / M + 1.0 w np.r_[ w w[ -2 -1 ] ]return _truncate w needs_trunc
def get_ranges headervalue content_length if not headervalue return Noneresult [] bytesunit byteranges headervalue.split ' ' 1 for brange in byteranges.split ' ' start stop [x.strip for x in brange.split '-' 1 ]if start if not stop stop content_length - 1 start stop int start int stop if start > content_length continueif stop < start return Noneresult.append start stop + 1 else if not stop return Noneif int stop > content_length result.append 0 content_length else result.append content_length - int stop content_length return result
def vcpus_realtime_topology flavor image mask _get_realtime_mask flavor image if not mask raise exception.RealtimeMaskNotFoundOrInvalid vcpus_rt parse_cpu_spec '0-%d %s' % flavor.vcpus - 1 mask if len vcpus_rt < 1 raise exception.RealtimeMaskNotFoundOrInvalid return vcpus_rt
def maven_target registry xml_parent data maven XML.SubElement xml_parent 'hudson.tasks.Maven' XML.SubElement maven 'targets' .text data['goals']prop_string '\n'.join data.get 'properties' [] XML.SubElement maven 'properties' .text prop_stringif 'maven-version' in data XML.SubElement maven 'mavenName' .text str data['maven-version'] if 'pom' in data XML.SubElement maven 'pom' .text str data['pom'] use_private str data.get 'private-repository' False .lower XML.SubElement maven 'usePrivateRepository' .text use_privateif 'java-opts' in data javaoptions ''.join data.get 'java-opts' [] XML.SubElement maven 'jvmOptions' .text javaoptionsconfig_file_provider_settings maven data
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def fix_broken_encoding value if isinstance value six.text_type value value.encode 'utf8' errors 'replace' if isinstance value six.binary_type value value.decode 'utf8' errors 'replace' return value
def MINUS_DM barDs count timeperiod - 2 ** 31 return call_talib_with_hl barDs count talib.MINUS_DM timeperiod
def sort_fields elem field_orders order_dicts dict for field order in field_orders.items order_dicts[field] order_key dict for i subfield in enumerate order order_key[subfield] i_sort_fields elem order_dicts
def convertXMLElement geometryOutput xmlElement xmlElement.getXMLProcessor .createChildren geometryOutput['shapes'] xmlElement
def diff_test i syms i.free_symbolsfor s in syms assert i.diff s .doit - i.doit .diff s .expand 0 return syms
def _estimate_gaussian_covariances_spherical resp X nk means reg_covar return _estimate_gaussian_covariances_diag resp X nk means reg_covar .mean 1
def test_install_from_wheel_gui_entrypoint script data result script.pip 'install' 'script.wheel3 0.1' '--no-index' '--find-links ' + data.find_links expect_error False if os.name 'nt' wrapper_file script.bin / 't1.exe' else wrapper_file script.bin / 't1' assert wrapper_file in result.files_created
def get_mapnikMap mapfile mmap mapnik.Map 0 0 if exists mapfile mapnik.load_map mmap str mapfile else handle filename mkstemp os.write handle urlopen mapfile .read os.close handle mapnik.load_map mmap filename os.unlink filename return mmap
def verify_numerically f g z None tol 1e-06 a 2 b -1 c 3 d 1 f g z Tuple f g z z [z] if isinstance z Symbol else f.free_symbols | g.free_symbols reps list zip z [random_complex_number a b c d for zi in z] z1 f.subs reps .n z2 g.subs reps .n return comp z1 z2 tol
def _normalizeOptions inputOptions types_ {}for group in optDict.keys types_.update optDict[group] for key in inputOptions if key in types_ value inputOptions[key]if value is None continuetype_ types_[key]if type_ and isinstance type_ tuple type_ type_[0]if type_ OPTION_TYPE.BOOLEAN try value bool value except TypeError ValueError value Falseelif type_ OPTION_TYPE.INTEGER try value int value except TypeError ValueError value 0elif type_ OPTION_TYPE.FLOAT try value float value except TypeError ValueError value 0.0inputOptions[key] value
def convert_DateTimeProperty model prop kwargs if prop.auto_now or prop.auto_now_add return Nonereturn f.DateTimeField format '%Y-%m-%d%H %M %S' **kwargs
def GetAllClientLabels token include_catchall False labels_index aff4.FACTORY.Create standard.LabelSet.CLIENT_LABELS_URN standard.LabelSet mode 'r' token token labels set labels_index.ListLabels if include_catchall labels.add ALL_CLIENTS_LABEL return labels
def get_system_path _bpath []try import win32apisys_dir win32api.GetSystemDirectory except ImportError sys_dir os.path.normpath os.path.join get_windows_dir 'system32' _bpath [sys_dir get_windows_dir ]_bpath.extend compat.getenv 'PATH' '' .split os.pathsep return _bpath
def is_markdown_file path ext os.path.splitext path [1].lower return ext in [u'.markdown' u'.mdown' u'.mkdn' u'.mkd' u'.md']
def _process_path_prefix path_prefix _validate_path path_prefix if not _GCS_PATH_PREFIX_REGEX.match path_prefix raise ValueError 'Pathprefixshouldhaveformat/bucket /bucket/ or/bucket/prefixbutgot%s.' % path_prefix bucket_name_end path_prefix.find '/' 1 bucket path_prefixprefix Noneif bucket_name_end ! -1 bucket path_prefix[ bucket_name_end]prefix path_prefix[ bucket_name_end + 1 ] or None return bucket prefix
def test_install_option_in_requirements_file script data virtualenv script.scratch_path.join 'home1' .mkdir script.scratch_path.join 'home2' .mkdir script.scratch_path.join 'reqs.txt' .write textwrap.dedent "simple--install-option '--home %s'" % script.scratch_path.join 'home1' result script.pip 'install' '--no-index' '-f' data.find_links '-r' script.scratch_path / 'reqs.txt' '--install-option --home %s' % script.scratch_path.join 'home2' expect_stderr True package_dir script.scratch / 'home1' / 'lib' / 'python' / 'simple' assert package_dir in result.files_created
def binary_dilation input structure None iterations 1 mask None output None border_value 0 origin 0 brute_force False input numpy.asarray input if structure is None structure generate_binary_structure input.ndim 1 origin _ni_support._normalize_sequence origin input.ndim structure numpy.asarray structure structure structure[tuple [slice None None -1 ] * structure.ndim ]for ii in range len origin origin[ii] - origin[ii] if not structure.shape[ii] & 1 origin[ii] - 1return _binary_erosion input structure iterations mask output border_value origin 1 brute_force
def _format_opts opts if opts is None return []elif isinstance opts list new_opts []for item in opts if isinstance item six.string_types new_opts.append item else new_opts.append str item return new_optselif not isinstance opts six.string_types opts [str opts ]else opts salt.utils.shlex_split opts try if opts[ -1 ] '--' return opts[ -1 ]except IndexError passreturn opts
@monkeypatch_method pdb.Pdb 'Pdb' def user_return self frame return_value if self._wait_for_mainpyfile if self.mainpyfile ! self.canonic frame.f_code.co_filename or frame.f_lineno < 0 returnself._wait_for_mainpyfile 0self._old_Pdb_user_return frame return_value
def reset noGamma True OK init if noGamma and OK setVideoMode NOGAMMACORRECT
def sigma_exp p q q1 q[0]q2 q[1]return C_exp - delta p q1 - delta p q2 - V p - max V q1 V q2
def message title T 'AccountRegistered-PleaseCheckYourEmail' message T '% system_name shassentanemailto% email stoverifyyouremailaddress.\nPleasecheckyouremailtoverifythisaddress.Ifyoudonotreceivethisemailpleasecheckyoujunkemailorspamfilters.' % {'system_name' settings.get_system_name 'email' request.vars.email} image 'email_icon.png'return dict title title message message image_src '/%s/static/img/%s' % appname image
def _yum contextkey 'yum_bin'if contextkey not in __context__ if 'fedora' in __grains__['os'].lower and int __grains__['osrelease'] > 22 __context__[contextkey] 'dnf'else __context__[contextkey] 'yum'return __context__[contextkey]
def _insert_axis_in_strides context builder orig_strides ndim axis assert len orig_strides ndim - 1 ll_shty ir.ArrayType cgutils.intp_t ndim strides cgutils.alloca_once builder ll_shty one cgutils.intp_t 1 zero cgutils.intp_t 0 for dim in range ndim - 1 ll_dim cgutils.intp_t dim after_axis builder.icmp_signed '> ' ll_dim axis idx builder.select after_axis builder.add ll_dim one ll_dim builder.store orig_strides[dim] cgutils.gep_inbounds builder strides 0 idx builder.store zero cgutils.gep_inbounds builder strides 0 axis return cgutils.unpack_tuple builder builder.load strides
def direct_get_container node part account container marker None limit None prefix None delimiter None conn_timeout 5 response_timeout 15 end_marker None reverse None path '/%s/%s' % account container return _get_direct_account_container path 'Container' node part marker marker limit limit prefix prefix delimiter delimiter end_marker end_marker reverse reverse conn_timeout conn_timeout response_timeout response_timeout
def get_pack_metadata pack_dir manifest_path os.path.join pack_dir MANIFEST_FILE_NAME if not os.path.isfile manifest_path raise ValueError 'Pack"%s"ismissing%sfile' % pack_dir MANIFEST_FILE_NAME meta_loader MetaLoader content meta_loader.load manifest_path if not content raise ValueError 'Pack"%s"metadatafileisempty' % pack_dir return content
def bucketcat series cats if not isinstance series Series series Series series index np.arange len series cats np.asarray cats unique_labels np.unique cats unique_labels unique_labels[com.notnull unique_labels ]data {}for label in unique_labels data[label] series[ cats label ]return DataFrame data columns unique_labels
def _screenshot viewport None alpha True return read_pixels viewport alpha
def iterator_content_items_by_youtube_id ids None channel 'khan' language 'en' **kwargs if ids items Item.select .where Item.youtube_id.in_ ids .dicts .iterator else items Item.select .dicts .iterator mapped_items itertools.imap unparse_model_data items updated_mapped_items update_content_availability mapped_items channel channel language language for path update in updated_mapped_items yield path update
def create_thriftpy_context server_side False ciphers None if MODERN_SSL if server_side context ssl.create_default_context ssl.Purpose.CLIENT_AUTH else context ssl.create_default_context ssl.Purpose.SERVER_AUTH if ciphers context.set_ciphers ciphers else context SSLContext ssl.PROTOCOL_SSLv23 context.options | OP_NO_SSLv2context.options | OP_NO_SSLv3context.options | OP_NO_COMPRESSIONif server_side context.options | OP_CIPHER_SERVER_PREFERENCEcontext.options | OP_SINGLE_DH_USEcontext.options | OP_SINGLE_ECDH_USEelse context.verify_mode ssl.CERT_REQUIREDwarnings.warn 'sslcheckhostnamesupportdisabled upgradeyourpython' InsecurePlatformWarning if getattr context 'supports_set_ciphers' True if ciphers context.set_ciphers ciphers else warnings.warn 'sslcipherssupportdisabled upgradeyourpython' InsecurePlatformWarning return context
def is_reducible circuit nqubits begin end current_circuit for ndx in reversed range begin end next_gate circuit[ndx]current_circuit next_gate + current_circuit if is_scalar_matrix current_circuit nqubits False return Truereturn False
def asyn_lpa_communities G weight None labels {n i for i n in enumerate G }cont Truewhile cont cont Falsenodes list G random.shuffle nodes for node in nodes if len G[node] < 1 continuelabel_freq Counter for v in G[node] label_freq.update {labels[v] G.edge[v][node][weight] if weight else 1 } max_freq max label_freq.values best_labels [label for label freq in label_freq.items if freq max_freq ]new_label random.choice best_labels labels[node] new_labelcont cont or len best_labels > 1 return iter groups labels .values
@register.tag 'timezone' def timezone_tag parser token bits token.split_contents if len bits ! 2 raise TemplateSyntaxError "'%s'takesoneargument timezone " % bits[0] tz parser.compile_filter bits[1] nodelist parser.parse 'endtimezone' parser.delete_first_token return TimezoneNode nodelist tz
def _htmlentity_transform entity_with_semicolon entity entity_with_semicolon[ -1 ]if entity in compat_html_entities.name2codepoint return compat_chr compat_html_entities.name2codepoint[entity] if entity_with_semicolon in compat_html_entities_html5 return compat_html_entities_html5[entity_with_semicolon]mobj re.match u'# x[0-9a-fA-F]+|[0-9]+ ' entity if mobj is not None numstr mobj.group 1 if numstr.startswith u'x' base 16numstr u'0%s' % numstr else base 10try return compat_chr int numstr base except ValueError passreturn u'&%s;' % entity
def get_config_drive_type if CONF.config_drive_format 'iso9660' config_drive_type 'cdrom'elif CONF.config_drive_format 'vfat' config_drive_type 'disk'else raise exception.ConfigDriveUnknownFormat format CONF.config_drive_format return config_drive_type
def datastore_make_private context data_dict if 'id' in data_dict data_dict['resource_id'] data_dict['id']res_id _get_or_bust data_dict 'resource_id' data_dict['connection_url'] config['ckan.datastore.write_url']if not _resource_exists context data_dict raise p.toolkit.ObjectNotFound p.toolkit._ u'Resource"{0}"wasnotfound.'.format res_id p.toolkit.check_access 'datastore_change_permissions' context data_dict db.make_private context data_dict
def fastfn outs mode None model None model modelcontext model return model.fastfn outs mode
def set_cached_value key value timeout None cache.set key value timeout timeout
def _process_key evt key evt.GetKeyCode if key in KEYMAP return KEYMAP[key] '' if 97 < key < 122 key - 32if key > 32 and key < 127 return keys.Key chr key chr key else return None None
def frender path **keywords return Template open path .read filename path **keywords
def assertNotIsInstance obj cls msg '' if isinstance obj cls err_msg '{0}Inputmustnotbetype{1}'raise AssertionError err_msg.format msg cls
def crop x wrg hrg is_random False row_index 0 col_index 1 channel_index 2 h w x.shape[row_index] x.shape[col_index] assert h > hrg and w > wrg 'Thesizeofcroppingshouldsmallerthantheoriginalimage'if is_random h_offset int np.random.uniform 0 h - hrg - 1 w_offset int np.random.uniform 0 w - wrg - 1 return x[h_offset hrg + h_offset w_offset wrg + w_offset ]else h_offset int np.floor h - hrg / 2.0 w_offset int np.floor w - wrg / 2.0 h_end h_offset + hrg w_end w_offset + wrg return x[h_offset h_end w_offset w_end]
def _get_next_open_shard stream_details shard_id found Falsefor shard in stream_details['OpenShards'] current_shard_id shard['ShardId']if current_shard_id shard_id found Truecontinueif found return current_shard_id
def pack_array builder values ty None n len values if ty is None ty values[0].typeary ir.ArrayType ty n ir.Undefined for i v in enumerate values ary builder.insert_value ary v i return ary
def unmonitor session *args **kwargs kwargs['stop'] Truemonitor session *args **kwargs
def toNorm raw return np.power MAX_NORM raw * NORM_RATIO
def copy_files_source_to_target source target print 'Processing%s' % os.path.join os.getcwd source print 'Copyinginto%s' % os.path.join os.getcwd target ensure_directory_exists target shutil.rmtree target for root dirs files in os.walk os.path.join os.getcwd source for directory in dirs print 'Processing%s' % os.path.join root directory for filename in files source_path os.path.join root filename if target in source_path continueif source not in source_path continuetarget_path source_path.replace source target ensure_directory_exists target_path shutil.copyfile source_path target_path
def make_sorted_frequencies counts absolute False c sort counts c c[c.nonzero ]c c[ -1 ]if absolute return celse f c / float c.sum return f
def is_rate_limit_error_message message return isinstance message list and len message > 0 and 'code' in message[0] and message[0]['code'] 88
def _run_map_jobs job_operation_key backup_info_key kinds job_name backup_handler input_reader output_writer mapper_params mapreduce_params queue backup_info BackupInformation.get backup_info_key if not backup_info return []jobs utils.RunMapForKinds job_operation_key kinds job_name backup_handler input_reader output_writer mapper_params mapreduce_params queue_name queue backup_info.active_jobs jobsbackup_info.put force_writes True return jobs
def module_load_tests loader found_tests pattern result testresources.OptimisingTestSuite found_tests testscenarios.load_tests_apply_scenarios loader found_tests pattern result.addTest found_tests return result
def stream_lines stream comments None try readlines stream.xreadlinesexcept AttributeError readlines stream.readlinesresult []for line in readlines line line.strip if line and comments is None or not line.startswith comments result.append line return result
def get_images_table meta images Table 'images' meta Column 'id' Integer primary_key True nullable False Column 'name' String 255 Column 'disk_format' String 20 Column 'container_format' String 20 Column 'size' BigInteger Column 'status' String 30 nullable False Column 'is_public' Boolean nullable False default False index True Column 'location' Text Column 'created_at' DateTime nullable False Column 'updated_at' DateTime Column 'deleted_at' DateTime Column 'deleted' Boolean nullable False default False index True mysql_engine 'InnoDB' extend_existing True return images
def _from_json encoded return [str x for x in jsonutils.loads encoded ]
def graph_number_of_cliques G cliques None if cliques is None cliques list find_cliques G return len cliques
def clone_into parent elem clone parent.makeelement elem.tag parent.append clone if elem.text and not elem.text.isspace clone.text elem.textif elem.tail and not elem.tail.isspace clone.tail elem.tailclone.attrib.update elem.attrib for child in elem.iterchildren etree.Element clone_into clone child
def chop_traceback tb exclude_prefix _UNITTEST_RE exclude_suffix _SQLA_RE start 0end len tb - 1 while start < end and exclude_prefix.search tb[start] start + 1while start < end and exclude_suffix.search tb[end] end - 1return tb[start end + 1 ]
def hy_compile tree module_name root ast.Module get_expr False body []expr Noneif tree compiler HyASTCompiler module_name result compiler.compile tree expr result.force_exprif not get_expr result + result.expr_as_stmt if isinstance tree list spoof_tree tree[0]else spoof_tree treebody compiler.imports_as_stmts spoof_tree + result.stmts ret root body body if get_expr expr ast.Expression body expr ret ret expr return ret
def ndeepmap n func seq if n 1 return [func item for item in seq]elif n > 1 return [ndeepmap n - 1 func item for item in seq]else return func seq
def AllowInstalledLibrary name desired CallSetAllowedModule name desired dependencies PACKAGES[name][1][desired]if dependencies for dep_name dep_version in dependencies AllowInstalledLibrary dep_name dep_version installed[name] desired False
def make_safe data return salt.utils.simple_types_filter object_to_dict data
def _compute_csd_params n_times sfreq mode mt_bandwidth mt_low_bias mt_adaptive ret_mt_adaptive mt_adaptiveif mode 'multitaper' if mt_bandwidth is not None half_nbw float mt_bandwidth * n_times / 2.0 * sfreq else half_nbw 2.0n_tapers_max int 2 * half_nbw window_fun eigvals dpss_windows n_times half_nbw n_tapers_max low_bias mt_low_bias n_tapers len eigvals logger.info 'usingmultitaperspectrumestimationwith%dDPSSwindows' % n_tapers if mt_adaptive and len eigvals < 3 warn 'Notadaptivelycombiningthespectralestimatorsduetoalownumberoftapers.' ret_mt_adaptive Falseelif mode 'fourier' logger.info 'usingFFTwithaHanningwindowtoestimatespectra' window_fun np.hanning n_times ret_mt_adaptive Falseeigvals 1.0n_tapers Noneelse raise ValueError 'Modehasaninvalidvalue.' return window_fun eigvals n_tapers ret_mt_adaptive
def _lstrip_str in_s lstr if in_s.startswith lstr res in_s[len lstr ]else res in_sreturn res
def _assert_occurrence src probe target amount 1 occ src.count probe if occ > amount msg 'morethan'elif occ < amount msg 'lessthan'elif not occ msg 'no'else msg Noneif msg raise CommandExecutionError 'Found{0}expectedoccurrencesin"{1}"expression'.format msg target
def find_package_data packages package_data {}for package in packages package_data[package] []for subdir in find_subdirectories package if '.'.join package subdir in packages logging.debug 'skippingsubmodule%s/%s' % package subdir continueif skip_tests and subdir 'tests' logging.debug 'skippingtests%s/%s' % package subdir continuepackage_data[package] + subdir_findall package_to_path package subdir return package_data
def flasher msg severity None try flash msg severity except RuntimeError if severity u'danger' logging.error msg else logging.info msg
def _get_valid_file_types return ' '.join [' '.join IMAGE_TYPES[ft].extensions for ft in IMAGE_TYPES.keys ]
def decode_dict_keys_to_str src if not six.PY3 or not isinstance src dict return srcoutput {}for key val in six.iteritems src if isinstance key bytes try key key.decode except UnicodeError passoutput[key] valreturn output
def _projectPoly poly normal pMin numpy.dot normal poly[0] pMax pMinfor n in xrange 1 len poly p numpy.dot normal poly[n] pMin min pMin p pMax max pMax p return pMin pMax
def CDLRICKSHAWMAN barDs count return call_talib_with_ohlc barDs count talib.CDLRICKSHAWMAN
def calculate_wait_for_retry retry_attempt wait_time 2 ** retry_attempt max_jitter wait_time / 4.0 wait_time + random.uniform - max_jitter max_jitter return max 1 min wait_time _MAX_RETRY_WAIT
def patched_path path if not path.endswith '/' path + '/'if path.startswith '/RPC2/' path path[5 ]return path
def _makeLongitude value return base.Coordinate value Angles.LONGITUDE
def open_ufw service return sequence [run_from_args ['ufw' 'allow' service] ]
def genGrow pset min_ max_ type_ None def condition height depth 'Expressiongenerationstopswhenthedepthisequaltoheight\norwhenitisrandomlydeterminedthataanodeshouldbeaterminal.\n'return depth height or depth > min_ and random.random < pset.terminalRatio return generate pset min_ max_ condition type_
def _makeRunner config cls runner.TrialRunnerargs {'reporterFactory' config['reporter'] 'tracebackFormat' config['tbformat'] 'realTimeErrors' config['rterrors'] 'uncleanWarnings' config['unclean-warnings'] 'logfile' config['logfile'] 'workingDirectory' config['temp-directory']}if config['dry-run'] args['mode'] runner.TrialRunner.DRY_RUNelif config['jobs'] from twisted.trial._dist.disttrial import DistTrialRunnercls DistTrialRunnerargs['workerNumber'] config['jobs']args['workerArguments'] config._getWorkerArguments else if config['debug'] args['mode'] runner.TrialRunner.DEBUGdebugger config['debugger']if debugger ! 'pdb' try args['debugger'] reflect.namedAny debugger except reflect.ModuleNotFound raise _DebuggerNotFound '%rdebuggercouldnotbefound.' % debugger else args['debugger'] _wrappedPdb args['exitFirst'] config['exitfirst']args['profile'] config['profile']args['forceGarbageCollection'] config['force-gc']return cls **args
def prt_bytes num_bytes human_flag if not human_flag return '%12s' % num_bytes num float num_bytes suffixes [None] + list 'KMGTPEZY' for suffix in suffixes[ -1 ] if num < 1023 breaknum / 1024.0else suffix suffixes[ -1 ]if not suffix return '%4s' % num_bytes elif num > 10 return '%3d%s' % num suffix else return '%.1f%s' % num suffix
def identifies id ref return id ref.alias or id ref.name or ref.schema and id ref.schema + '.' + ref.name
def degree_assortativity_coefficient G x 'out' y 'in' weight None nodes None M degree_mixing_matrix G x x y y nodes nodes weight weight return numeric_ac M
def fixup_ff4 p name []num 0start amp Falsefor ch in p if start if ch.isdigit num + chelif ch ';' name.append unichr int num .encode 'utf8' start Falseelse name.append '&#%s%s' % num ch start Falseelif ch '&' amp Trueelif amp amp Falseif ch '#' start Truenum ''else name.append '&' + ch else name.append ch return ''.join name
def p_arglist p if len p 4 p[0] p[1] + [p[3]] else p[0] [p[1]]
def run_post_update_script component previous_head run_hook component None component.post_update_script env {'WL_PREVIOUS_HEAD' previous_head}
def skipIf condition reason if condition return skip reason return lambda obj obj
def find_containing_network ip_ranges address addr ipaddress.ip_address address for network in ip_ranges if addr in network return networkreturn None
def check_clusterings labels_true labels_pred labels_true np.asarray labels_true labels_pred np.asarray labels_pred if labels_true.ndim ! 1 raise ValueError 'labels_truemustbe1D shapeis%r' % labels_true.shape if labels_pred.ndim ! 1 raise ValueError 'labels_predmustbe1D shapeis%r' % labels_pred.shape if labels_true.shape ! labels_pred.shape raise ValueError 'labels_trueandlabels_predmusthavesamesize got%dand%d' % labels_true.shape[0] labels_pred.shape[0] return labels_true labels_pred
def compute_recall y tp recall tp / T.maximum 1.0 y.sum return recall
def _find_executable executable path None if path is None path os.environ['PATH']paths path.split os.pathsep base ext os.path.splitext executable if sys.platform 'win32' and ext ! '.exe' executable executable + '.exe' if not os.path.isfile executable for p in paths f os.path.join p executable if os.path.isfile f return freturn Noneelse return executable
def process mtree for c in mtree.children groups find_first_level_groups c.value group_delimiters[0] for delimiters in group_delimiters flatten lambda l x l + find_first_level_groups x delimiters groups functools.reduce flatten groups [] c.split_on_components groups
def split_host srv mark srv.rfind ' ' if mark < 0 host srvelse host srv[0 mark]port srv[ mark + 1 ]try port int port except port Nonereturn host port
def _groups_or_na_fun regex if regex.groups 0 raise ValueError 'patterncontainsnocapturegroups' empty_row [np.nan] * regex.groups def f x if not isinstance x compat.string_types return empty_rowm regex.search x if m return [ np.nan if item is None else item for item in m.groups ]else return empty_rowreturn f
def tf2sos b a pairing 'nearest' return zpk2sos pairing pairing *tf2zpk b a
def stupefyEntities text language 'en' smart smartchars language text re.sub smart.endash '-' text text re.sub smart.emdash '--' text text re.sub smart.osquote "'" text text re.sub smart.csquote "'" text text re.sub smart.opquote '"' text text re.sub smart.cpquote '"' text text re.sub smart.ellipsis '...' text return text
def hazard return s3_rest_controller
def ParseFile file base_uri *args **kwds return _ParseFileEx file base_uri *args **kwds [1 ]
def workers_init global DB_SUPPORTS_SUBSECOND_RESOLUTIONsession get_session query session.query models.Worker .filter_by resource_type 'SENTINEL' worker query.first DB_SUPPORTS_SUBSECOND_RESOLUTION bool worker.updated_at.microsecond
def setup_blocks_complete request for module in get_modules if len [block for block in module.get_help_blocks request request kind 'setup' if not block.done ] > 0 return Falsereturn True
def _sift_read f mode 'SIFT' if not hasattr f 'readline' f open f 'r' if mode 'SIFT' nr_features feature_len map int f.readline .split datatype np.dtype [ 'row' float 'column' float 'scale' float 'orientation' float 'data' float feature_len ] else mode 'SURF'feature_len int f.readline - 1 nr_features int f.readline datatype np.dtype [ 'column' float 'row' float 'second_moment' float 3 'sign' float 'data' float feature_len ] data np.fromfile f sep '' if data.size ! nr_features * datatype.itemsize / np.dtype float .itemsize raise IOError 'Invalid%sfeaturefile.' % mode f.close return data.view datatype
def equality_preds names [u'equality' u'inequality']for pair in zip names [Tokens.EQ Tokens.NEQ] print u'%-15s DCTB %s' % pair
def match_consecutive needles haystack ignore_case False regex_no_sep '[^' + os.sep + ']*' regex_no_sep_end regex_no_sep + '$' regex_one_sep regex_no_sep + os.sep + regex_no_sep regex_needle regex_one_sep.join imap re.escape needles + regex_no_sep_end regex_flags re.IGNORECASE | re.UNICODE if ignore_case else re.UNICODE found lambda entry re.search regex_needle entry.path flags regex_flags return ifilter found haystack
def get_network_detach_config_spec client_factory device port_index config_spec client_factory.create 'ns0 VirtualMachineConfigSpec' virtual_device_config client_factory.create 'ns0 VirtualDeviceConfigSpec' virtual_device_config.operation 'remove'virtual_device_config.device deviceconfig_spec.deviceChange [virtual_device_config]config_spec.extraConfig [_iface_id_option_value client_factory 'free' port_index ]return config_spec
def quota_get context project_id resource user_id None return IMPL.quota_get context project_id resource user_id user_id
def assert_side_bar_help_link test page href help_text as_list_item False index -1 expected_link {'href' href 'text' help_text}actual_link page.get_side_bar_help_element_and_click_help as_list_item as_list_item index index assert_link test expected_link actual_link assert_opened_help_link_is_correct test href
def _get_tweets locale settings.LANGUAGE_CODE limit MAX_TWEETS max_id None reply_to None filter None https False locale settings.LOCALES[locale].iso639_1created_limit datetime.now - timedelta days settings.CC_TWEETS_DAYS q Tweet.objects.filter locale locale reply_to reply_to created__gt created_limit if max_id q q.filter pk__lt max_id if filter ! 'all' q q.filter hidden False if filter 'unanswered' q q.filter replies__pk__isnull True elif filter 'answered' q q.filter replies__pk__isnull False if limit q q[ limit]return [_tweet_for_template tweet https for tweet in q]
def deprecated_attr namespace attr replacement _deprecated_attrs.setdefault namespace [] .append attr replacement
def _read_float64 f return np.float64 struct.unpack '>d' f.read 8 [0]
def compute_accuracy predictions labels return labels[ predictions.ravel < 0.5 ].mean
def _get_rerun_link_for_item course_key return reverse_course_url 'course_rerun_handler' course_key
def get_day_names width 'wide' context 'format' locale LC_TIME return Locale.parse locale .days[context][width]
def isLoopListIntersectingInsideXSegment loopList segmentFirstX segmentSecondX segmentYMirror y for alreadyFilledLoop in loopList if isLoopIntersectingInsideXSegment alreadyFilledLoop segmentFirstX segmentSecondX segmentYMirror y return Truereturn False
def _sph_to_cart_partials az pol g_rad g_az g_pol sph_grads np.c_[ g_rad g_az g_pol ]cart_grads np.zeros_like sph_grads c_as s_as np.cos az np.sin az c_ps s_ps np.cos pol np.sin pol trans np.array [[ c_as * s_ps - s_as c_as * c_ps ] [ s_as * s_ps c_as c_ps * s_as ] [c_ps np.zeros_like c_as - s_ps ]] cart_grads np.einsum 'ijk kj->ki' trans sph_grads return cart_grads
def get_path_formats subview None path_formats []subview subview or config['paths'] for query view in subview.items query PF_KEY_QUERIES.get query query path_formats.append query Template view.as_str return path_formats
def _parse_proxy proxy scheme r_scheme splittype proxy if not r_scheme.startswith '/' scheme Noneauthority proxyelse if not r_scheme.startswith '//' raise ValueError 'proxyURLwithnoauthority %r' % proxy end r_scheme.find '/' 2 if end -1 end Noneauthority r_scheme[2 end] userinfo hostport splituser authority if userinfo is not None user password splitpasswd userinfo else user password Nonereturn scheme user password hostport
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def _node_redundancy G v n len G[v] overlap sum 1 for u w in combinations G[v] 2 if set G[u] & set G[w] - {v} return 2 * overlap / n * n - 1
def pportD2 state global dataRegif state 0 dataReg dataReg & ~ 4 else dataReg dataReg | 4 port.DlPortWritePortUchar baseAddress dataReg
def request_wants_json request best request.accept_mimetypes.best_match ['application/json' 'text/html'] return best 'application/json' and request.accept_mimetypes[best] > request.accept_mimetypes['text/html']
def _update_counter model field_name filter_kwargs increment 1 try record model.objects.filter **filter_kwargs affected record.update **{field_name F field_name + increment } if not affected filter_kwargs[field_name] incrementmodel.objects.create **filter_kwargs except IntegrityError logger.error 'IntegrityErrorwhenupdatinganalyticscounterfor%s' model
def set_roi location msg vehicle.message_factory.command_long_encode 0 0 mavutil.mavlink.MAV_CMD_DO_SET_ROI 0 0 0 0 0 location.lat location.lon location.alt vehicle.send_mavlink msg
def _get_location vm_ None locations avail_locations vm_location str config.get_cloud_config_value 'zone' vm_ __opts__ search_global False if not vm_location raise SaltCloudNotFound 'NolocationspecifiedforthisVM.' if vm_location in locations return vm_locationraise SaltCloudNotFound "Thespecifiedlocation '{0}' couldnotbefound.".format vm_location
def run _task
def _update_config template_name template_source None template_path None template_hash None template_hash_name None template_user 'root' template_group 'root' template_mode '755' saltenv None template_engine 'jinja' skip_verify True defaults None test False commit True debug False replace False **template_vars return __salt__['net.load_template'] template_name template_source template_source template_path template_path template_hash template_hash template_hash_name template_hash_name template_user template_user template_group template_group template_mode template_mode saltenv saltenv template_engine template_engine skip_verify skip_verify defaults defaults test test commit commit debug debug replace replace **template_vars
def delete name root None cmd 'groupdel' name if root is not None cmd.extend '-R' root ret __salt__['cmd.run_all'] cmd python_shell False return not ret['retcode']
def separate_list_input input_ no_commas input_.replace ' ' '' return [str string for string in no_commas.split ]
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def quaternion_rotation_matrix quaternion return quaternion_matrix quaternion [ 3 3]
def iter_field_objects fields if isinstance fields dict i six.iteritems fields else i iter fields for field in i if isinstance field RequestField yield field else yield RequestField.from_tuples *field
def is_form_media_type media_type base_media_type params parse_header media_type.encode HTTP_HEADER_ENCODING return base_media_type u'application/x-www-form-urlencoded' or base_media_type u'multipart/form-data'
def new data None return SHA224Hash .new data
def build_filter class_name *args if not hasattr filters class_name return Nonefilterclass getattr filters class_name return filterclass *args
def _default_feature_extractor words return dict word True for word in words
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def iseq_to_qseq_fields line barcode_in_header barcode_length barcode_qual_c 'b' record line.strip .split ' ' rec_0_1 rec_0_2 record[0].split '_' rec_4_1 rec_4_23 record[4].split '#' rec_4_2 rec_4_3 rec_4_23.split '/' if barcode_in_header barcode rec_4_2[ barcode_length]sequence record[5]barcode_qual barcode_qual_c * barcode_length sequence_qual record[6]else barcode record[5][ barcode_length]sequence record[5][barcode_length ]barcode_qual record[6][ barcode_length]sequence_qual record[6][barcode_length ]return rec_0_1 rec_0_2 record[1] record[2] record[3] rec_4_1 rec_4_2 rec_4_3 sequence sequence_qual barcode barcode_qual
def underscores_to_camelcase argument result u''previous_was_underscore Falsefor char in argument if char ! u'_' if previous_was_underscore result + char.upper else result + charprevious_was_underscore char u'_' return result
def process_signature request max_age 60 * 60 * 24 * 10 sig request.GET.get '_' or request.POST.get '_sentry_request_signature' if not sig or sig.count ' ' < 2 return Nonesigned_data '%s|%s|%s' % request.build_absolute_uri '/' .rstrip '/' request.path sig try data get_signer .unsign signed_data max_age max_age except signing.BadSignature return None _ signed_path user_id data.rsplit '|' 2 if signed_path ! request.path return Nonetry return User.objects.get pk base36_decode user_id except ValueError User.DoesNotExist return None
def recursive_update_dict root changes ignores if isinstance changes dict for k v in changes.items if isinstance v dict if k not in root root[k] {}recursive_update_dict root[k] v ignores elif v in ignores if k in root root.pop k else root[k] v
def bing phenny input query input.group 2 if query.startswith ' ' lang query query.split '' 1 lang lang[1 ]else lang 'en-GB'if not query return phenny.reply '.bingwhat?' query query.encode 'utf-8' uri bing_search query lang if uri phenny.reply uri if not hasattr phenny.bot 'last_seen_uri' phenny.bot.last_seen_uri {}phenny.bot.last_seen_uri[input.sender] urielse phenny.reply "Noresultsfoundfor'%s'." % query
def list_public_repos profile 'github' repos []for repo in _get_repos profile if repo.private is False repos.append repo.name return repos
def migrate_registrations_metadata_key schema registrations Node.find Q 'is_registration' 'eq' True & Q 'registered_schema' 'eq' schema total_reg registrations.count logger.info 'Examining{}registrationsforimproperkey'.format total_reg reg_count 0for reg in registrations reg_count + 1if reg.registered_meta.get schema._id {} .get 'recommended-methods' {} .get 'value' {} .get 'undefined' {} reg.registered_meta[schema._id]['recommended-methods']['value']['procedure'] reg.registered_meta[schema._id]['recommended-methods']['value'].pop 'undefined' reg.save logger.info '{}/{}Migratedkeyfor{}'.format reg_count total_reg reg._id else logger.info '{}/{}Keyalreadycorrectfor{}.Nochange.'.format reg_count total_reg reg._id
@compositedef related_deployments_strategy draw number_of_deployments node_uuid_pool draw node_uuid_pool_strategy deployments set while True deployments.add draw deployment_strategy node_uuid_pool node_uuid_pool if len deployments number_of_deployments return tuple deployments
def random_password length 10 chars string.ascii_uppercase + string.digits + string.ascii_lowercase password ''for i in range length password + chars[ ord M2Crypto.m2.rand_bytes 1 % len chars ]return password
def httpconnection_patched_endheaders self message_body None if self._HTTPConnection__state _CS_REQ_STARTED self._HTTPConnection__state _CS_REQ_SENTelse raise CannotSendHeader self._send_output message_body
def set_term_title title if ignore_termtitle return_set_term_title title
def getDecimalPlacesCarried extraDecimalPlaces value return max 0 1 + int math.ceil extraDecimalPlaces - math.log10 value
def registration email return Registration.objects.get user__email email
def getTopdir topfile start None if not start start os.getcwd here starttoomany 20while toomany > 0 if os.path.exists os.path.join here topfile return herenext os.path.dirname here if next here breakhere nexttoomany - 1output "Unabletofindtopfile'%s'anywherefrom%supwards" % topfile start sys.exit 1
def enable_sigusr2_handler enable_sig_handler 'SIGUSR2' _handle_sigusr2
def getGeometryOutput derivation xmlElement if derivation None derivation ShaftDerivation derivation.setToXMLElement xmlElement shaftPath getShaftPath derivation.depthBottom derivation.depthTop derivation.radius derivation.sides return lineation.getGeometryOutputByLoop lineation.SideLoop shaftPath xmlElement
def LoadBackendInfo backend_info open_fn None builder yaml_object.ObjectBuilder BackendInfoExternal handler yaml_builder.BuilderHandler builder listener yaml_listener.EventListener handler listener.Parse backend_info backend_info handler.GetResults if len backend_info < 1 return BackendInfoExternal backends [] if len backend_info > 1 raise BadConfig "Onlyone'backends'clauseisallowed." info backend_info[0]if not info.backends return BackendInfoExternal backends [] for backend in info.backends backend.Init return info
def shared_like variable name None **kwargs variable tensor.as_tensor_variable variable if name is None name 'shared_{}'.format variable.name return theano.shared numpy.zeros 0 * variable.ndim dtype variable.dtype name name **kwargs
@command 'registry' required ['host'] optional ['service-name' 'registry-path'] def registry_command options host service_name None registry_path '/protorpc' dest_dir os.path.expanduser options.dest_dir url 'http //%s%s' % host registry_path reg registry.RegistryService.Stub transport.HttpTransport url if service_name is None service_names [service.name for service in reg.services .services]else service_names [service_name]file_set reg.get_file_set names service_names .file_setfor file_descriptor in file_set.files generate_file_descriptor dest_dir file_descriptor file_descriptor force_overwrite options.force
def delete_label id models.Label.smart_get id .delete
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def dup_scale f a K f n b list f len f - 1 a for i in range n - 1 -1 -1 f[i] b b * f[i] b * a return f
def _gf_gcdex f g p ring f.ring s t h gf_gcdex f.to_dense g.to_dense p ring.domain return ring.from_dense s ring.from_dense t ring.from_dense h
def link_archive_provider node user addon node.get_or_add_addon settings.ARCHIVE_PROVIDER auth Auth user log False if hasattr addon 'on_add' addon.on_add node.save
def default_mappings machines mappings {}failures []mach machines[0]mappings['ident'] [mach]if len machines > 1 machines machines[1 ]for machine in machines mappings['ident'].append machine return mappings failures
def get_user_db_from_request request auth_context request.context.get 'auth' {} if not auth_context return Noneuser_db auth_context.get 'user' None return user_db
def applies_to_all_images fileobject return fileobject.filetype 'Image'
def softmax_cross_entropy x t use_cudnn True normalize True cache_score True class_weight None return SoftmaxCrossEntropy use_cudnn normalize cache_score class_weight x t
def iter_format_modules lang if check_for_language lang format_locations ['django.conf.locale.%s']if settings.FORMAT_MODULE_PATH format_locations.append settings.FORMAT_MODULE_PATH + '.%s' format_locations.reverse locale to_locale lang locales [locale]if '_' in locale locales.append locale.split '_' [0] for location in format_locations for loc in locales try yield import_module '.formats' location % loc except ImportError pass
def get_current_time_in_millisecs return get_time_in_millisecs datetime.datetime.utcnow
def _pick_bad_channels event params bads params['raw'].info['bads']params['info']['bads'] _select_bads event params bads _plot_update_raw_proj params None
def setLevel level level level.lower .strip imdbpyLogger.setLevel LEVELS.get level logging.NOTSET imdbpyLogger.log imdbpyLogger.level 'setloggingthresholdto"%s"' logging.getLevelName imdbpyLogger.level
def SPF domain record 'SPF' nameserver None if _has_dig return __salt__['dig.SPF'] domain record nameserver return 'Thisfunctionrequiresdig whichisnotcurrentlyavailable'
def range_to_tuple range_string m SHEETRANGE_RE.match range_string if m is None raise ValueError 'Valuemustbeoftheformsheetname!A1 E4' sheetname m.group 'quoted' or m.group 'notquoted' cells m.group 'cells' boundaries range_boundaries cells return sheetname boundaries
def set_query_params url param_dict scheme netloc path query_string fragment urlsplit url query_params parse_qs query_string keep_blank_values True for param_name param_value in param_dict.items if param_value is None del query_params[param_name]else query_params[param_name] [param_value]new_query_string urlencode query_params doseq True return urlunsplit scheme netloc path new_query_string fragment
def systemInformationType5ter a L2PseudoLength l2pLength 18 b TpPd pd 6 c MessageType mesType 6 d NeighbourCellsDescription2 packet a / b / c / d return packet
def _parse_cisco_mac_address cisco_hardware_addr cisco_hardware_addr cisco_hardware_addr.replace '.' '' blocks [cisco_hardware_addr[x x + 2 ] for x in range 0 len cisco_hardware_addr 2 ]return ' '.join blocks .upper
def check_credentials request other_application 'admin' expiration 60 * 60 gae_login True if request.env.web2py_runtime_gae from google.appengine.api import usersif users.is_current_user_admin return Trueelif gae_login login_html '<ahref "%s">Signinwithyourgoogleaccount</a>.' % users.create_login_url request.env.path_info raise HTTP 200 '<html><body>%s</body></html>' % login_html else return Falseelse t0 time.time dt t0 - expiration s get_session request other_application r s.authorized and s.last_time and s.last_time > dt if r s.last_time t0set_session request s other_application return r
def main if len sys.argv > 1 writeOutput ''.join sys.argv[1 ] else settings.startMainLoopFromConstructor getNewRepository
def _get_fullname cls if orig_isinstance cls NetProxy modules _get_conn cls .modules.sys.moduleselse modules sys.modulestry filename modules[cls.__module__].__file__except KeyError AttributeError filename cls.__module__return filename cls.__name__
def is_archive_file name archives '.zip' '.tar.gz' '.tar.bz2' '.tgz' '.tar' '.pybundle' '.whl' ext splitext name [1].lower if ext in archives return Truereturn False
def _add_boolean_cli_param params key value if value is True params.append '--{0}'.format key
def _update_rs_no_primary_from_member sds replica_set_name server_description topology_type TOPOLOGY_TYPE.ReplicaSetNoPrimaryif replica_set_name is None replica_set_name server_description.replica_set_nameelif replica_set_name ! server_description.replica_set_name sds.pop server_description.address return topology_type replica_set_name for address in server_description.all_hosts if address not in sds sds[address] ServerDescription address if server_description.me and server_description.address ! server_description.me sds.pop server_description.address return topology_type replica_set_name
def get_mappings return {idxr.get_doctype_name idxr.get_mapping for idxr in indexers}
def chworkphone name workphone return _update_gecos name 'workphone' workphone
def _turn_iterable_to_mapping_from_attribute attribute obj optional False if optional if obj is None return Noneif isinstance obj Mapping return objreturn {getattr a attribute a for a in obj}
def unimplemented_abstract_methods node is_abstract_cb decorated_with_abc visited {}try mro reversed node.mro except NotImplementedError return {}except astroid.ResolveError return {}for ancestor in mro for obj in ancestor.values infered objif isinstance obj astroid.AssName infered safe_infer obj if not infered continueif not isinstance infered astroid.Function if obj.name in visited del visited[obj.name]if isinstance infered astroid.Function abstract is_abstract_cb infered if abstract visited[obj.name] inferedelif not abstract and obj.name in visited del visited[obj.name]return visited
def sentence_gleu reference hypothesis min_len 1 max_len 4 ref_ngrams Counter everygrams reference min_len max_len hyp_ngrams Counter everygrams hypothesis min_len max_len overlap_ngrams ref_ngrams & hyp_ngrams tp sum overlap_ngrams.values tpfp sum hyp_ngrams.values tffn sum ref_ngrams.values precision tp / tpfp recall tp / tffn return min precision recall
def blog_structure site return {'blogid' settings.SITE_ID 'blogName' site.name 'url' '%s //%s%s' % PROTOCOL site.domain reverse 'zinnia entry_archive_index' }
def supported_challenges_validator data if cli.set_by_cli 'standalone_supported_challenges' sys.stderr.write 'WARNING Thestandalonespecificsupportedchallengesflagisdeprecated.\nPleaseusethe--preferred-challengesflaginstead.\n' challs data.split ' ' if 'dvsni' in challs logger.info 'Updatinglegacystandalone_supported_challengesvalue' challs [ challenges.TLSSNI01.typ if chall 'dvsni' else chall for chall in challs]data ' '.join challs unrecognized [name for name in challs if name not in challenges.Challenge.TYPES ]if unrecognized raise argparse.ArgumentTypeError 'Unrecognizedchallenges {0}'.format ' '.join unrecognized choices set chall.typ for chall in SUPPORTED_CHALLENGES if not set challs .issubset choices raise argparse.ArgumentTypeError 'Plugindoesnotsupportthefollowing valid challenges {0}'.format ' '.join set challs - choices return data
@needs 'pavelib.prereqs.install_prereqs' 'pavelib.utils.test.utils.clean_reports_dir' @cmdopts [ 'failed' 'f' 'Runonlyfailedtests' 'fail-fast' 'x' 'Runonlyfailedtests' make_option '-c' '--cov-args' default '' help 'addsasargstocoverageforthetestrun' make_option '--verbose' action 'store_const' const 2 dest 'verbosity' make_option '-q' '--quiet' action 'store_const' const 0 dest 'verbosity' make_option '-v' '--verbosity' action 'count' dest 'verbosity' default 1 make_option '--disable-migrations' action 'store_true' dest 'disable_migrations' help "Createtablesdirectlyfromapps'models.CanalsobeusedbyexportingDISABLE_MIGRATIONS 1." 'cov_args ' None 'deprecatedinfavorofcov-args' make_option '-e' '--extra_args' default '' help 'deprecated passextraoptionsdirectlyinthepavercommandline' 'fail_fast' None 'deprecatedinfavoroffail-fast' ] @PassthroughTask@timeddef test_python options passthrough_options python_suite suites.PythonTestSuite 'PythonTests' passthrough_options passthrough_options **options.test_python python_suite.run
def rand_item_from_iters iter return rand_base 1 '' iter
def xen_vms name global connvm_count conn.numOfDomains return vm_count
def _mac_ver_gestalt try import gestaltimport MacOSexcept ImportError return None sysv sysa _mac_ver_lookup 'sysv' 'sysa' if sysv major sysv & 65280 >> 8 minor sysv & 240 >> 4 patch sysv & 15 if major minor > 10 4 major minor patch _mac_ver_lookup 'sys1' 'sys2' 'sys3' release '%i.%i.%i' % major minor patch else release '%s.%i.%i' % _bcd2str major minor patch if sysa machine {1 '68k' 2 'PowerPC' 10 'i386'}.get sysa '' return release versioninfo machine
def img_as_float image force_copy False return convert image np.float64 force_copy
def accumulateClassList classObj attr listObj baseClass None for base in classObj.__bases__ accumulateClassList base attr listObj if baseClass is None or baseClass in classObj.__bases__ listObj.extend classObj.__dict__.get attr []
def covariance X Y condition None **kwargs return expectation X - expectation X condition **kwargs * Y - expectation Y condition **kwargs condition **kwargs
def url_match condition data_format data_type inds np.logical_and conditions condition data_formats data_format inds np.logical_and inds data_types data_type inds np.logical_and inds data_formats data_format good_urls list urls[inds] for gi g in enumerate good_urls good_urls[gi] url_root + g if len good_urls 0 raise ValueError 'NoMEGSIMdatasetfoundwithcondition "%s" \ndata_format "%s" data_type "%s"' % condition data_format data_type return good_urls
def answer_problem course request problem score 1 max_value 1 user request.usergrade_dict {'value' score 'max_value' max_value 'user_id' user.id}field_data_cache FieldDataCache.cache_for_descriptor_descendents course.id user course depth 2 module get_module user request problem.scope_ids.usage_id field_data_cache ._xmodulemodule.system.publish problem 'grade' grade_dict
def update_user_permissions userid profile 'grafana' **kwargs if isinstance profile string_types profile __salt__['config.option'] profile response requests.put '{0}/api/admin/users/{1}/permissions'.format profile['grafana_url'] userid json kwargs auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def default_entry_point dist pkg_resources.get_distribution 'Orange3' ep pkg_resources.EntryPoint 'OrangeWidgets' 'Orange.widgets' dist dist return ep
def matplotlib_fname if six.PY2 cwd os.getcwdu else cwd os.getcwd fname os.path.join cwd u'matplotlibrc' if os.path.exists fname return fnameif u'MATPLOTLIBRC' in os.environ path os.environ[u'MATPLOTLIBRC']if os.path.exists path if os.path.isfile path return pathfname os.path.join path u'matplotlibrc' if os.path.exists fname return fnameconfigdir _get_configdir if os.path.exists configdir fname os.path.join configdir u'matplotlibrc' if os.path.exists fname return fnamepath get_data_path fname os.path.join path u'matplotlibrc' if not os.path.exists fname warnings.warn u'Couldnotfindmatplotlibrc;usingdefaults' return fname
@utils.arg 'hostname' metavar '<hostname>' help _ 'Thehypervisorhostname orpattern tosearchfor.' def do_hypervisor_servers cs args hypers cs.hypervisors.search args.hostname servers True class InstanceOnHyper object def __init__ self **kwargs self.__dict__.update kwargs instances []for hyper in hypers hyper_host hyper.hypervisor_hostnamehyper_id hyper.idif hasattr hyper 'servers' instances.extend [InstanceOnHyper id serv['uuid'] name serv['name'] hypervisor_hostname hyper_host hypervisor_id hyper_id for serv in hyper.servers] utils.print_list instances ['ID' 'Name' 'HypervisorID' 'HypervisorHostname']
@builtin u'Upper-casetext ignoretags ' upper apply_func_to_html_text def replace_uppercase_ignore_tags match number file_name metadata dictionaries data functions *args **kwargs return apply_func_to_html_text match upper
def __sympifyit func arg retval None if not get_function_code func .co_argcount raise LookupError 'funcnotfound' assert get_function_code func .co_varnames[1] arg if retval is None @wraps func def __sympifyit_wrapper a b return func a sympify b strict True else @wraps func def __sympifyit_wrapper a b try if not hasattr b '_op_priority' b sympify b strict True return func a b except SympifyError return retvalreturn __sympifyit_wrapper
def make_sampling_table size sampling_factor 1e-05 gamma 0.577rank np.array list range size rank[0] 1inv_fq rank * np.log rank + gamma + 0.5 - 1.0 / 12.0 * rank f sampling_factor * inv_fq return np.minimum 1.0 f / np.sqrt f
def GetAnglesPolyline polyline closed False points polyline[ 0]if closed a np.roll points 1 axis 0 b pointsc np.roll points -1 axis 0 else a points[0 -2 ]b points[1 -1 ]c points[2 ]ab b - a cb b - c dot np.sum ab * cb axis 1 cros np.cross ab cb alpha np.arctan2 cros dot return alpha * 180.0 / np.pi
def p_rules p if len p 2 rule p[1]else rule p[2]embedded []embed_count 0rulename rule[0]rulecount 1for r in rule[1] print 'defp_%s_%d p ' % rulename rulecount prod []prodcode ''for i in range len r item r[i]if item[0] '{' if i len r - 1 prodcode itembreakelse embed_name '_embed%d_%s' % embed_count rulename prod.append embed_name embedded.append embed_name item embed_count + 1else prod.append item print "'''%s %s'''" % rulename ''.join prod print_code prodcode 4 printrulecount + 1for e code in embedded print 'defp_%s p ' % e print "'''%s '''" % e print_code code 4 print
def _remove_dots src output {}for key val in six.iteritems src if isinstance val dict val _remove_dots val output[key.replace '.' '-' ] valreturn output
def del_quote db nick msg query qtable.update .where qtable.c.chan 1 .where qtable.c.nick nick.lower .where qtable.c.msg msg .values deleted 1 db.execute query db.commit
def modulePath try _ sys.executable if weAreFrozen else __file__ except NameError _ inspect.getsourcefile modulePath return getUnicode os.path.dirname os.path.realpath _ encoding sys.getfilesystemencoding or UNICODE_ENCODING
def string_values node cstruct are_strings [isinstance v six.string_types for v in cstruct.values ]if not all are_strings error_msg '%scontainsnonstringvalue' % cstruct raise colander.Invalid node error_msg
def job_log_logger registry xml_parent data top XML.SubElement xml_parent 'org.jenkins.ci.plugins.jobloglogger.JobLogLoggerBuildWrapper' XML.SubElement top 'suppressEmpty' .text str data.get 'suppress-empty' True .lower
def update_org_prefs orgname None profile 'grafana' **kwargs if isinstance profile string_types profile __salt__['config.option'] profile if orgname switch_org orgname profile response requests.put '{0}/api/org/preferences'.format profile['grafana_url'] json kwargs auth _get_auth profile headers _get_headers profile timeout profile.get 'grafana_timeout' 3 if response.status_code > 400 response.raise_for_status return response.json
def render_to_pdf template_src context_dict template get_template template_src context Context context_dict html template.render context result StringIO.StringIO pdf pisaDocument StringIO.StringIO html.encode 'ISO-8859-1' result if not pdf.err return HttpResponse result.getvalue mimetype 'application/pdf' return HttpResponse 'Wehadsomeerrors<pre>%s</pre>' % cgi.escape html
def ref_hist inp nbins 64 offset -48 bins np.arange nbins + 1 + float offset bins[0] - float 'Inf' np_inp_log_abs np.rint np.log2 np.abs inp.astype np.float32 np_hist edges np.histogram np_inp_log_abs density False bins bins if np_hist.ndim < 2 np_hist np_hist.reshape 1 np_hist.size return np_hist
def _nose_tools_functions module _BUILDER.string_build textwrap.dedent '\nimportunittest\n\nclassTest unittest.TestCase \npass\na Test \n' try case next module['a'].infer except astroid.InferenceError returnfor method in case.methods if method.name.startswith 'assert' and '_' not in method.name pep8_name _pep8 method.name yield pep8_name astroid.BoundMethod method case
def destroy_cached_images session sr_ref all_cached False dry_run False cached_images _find_cached_images session sr_ref destroyed set def destroy_cached_vdi vdi_uuid vdi_ref LOG.debug "DestroyingcachedVDI'% vdi_uuid s'" if not dry_run destroy_vdi session vdi_ref destroyed.add vdi_uuid for vdi_ref in cached_images.values vdi_uuid session.call_xenapi 'VDI.get_uuid' vdi_ref if all_cached destroy_cached_vdi vdi_uuid vdi_ref continuechain list _walk_vdi_chain session vdi_uuid if len chain > 2 continueelif len chain 2 root_vdi_rec chain[ -1 ]children _child_vhds session sr_ref [root_vdi_rec['uuid']] if len children > 1 continuedestroy_cached_vdi vdi_uuid vdi_ref return destroyed
@gen.coroutinedef wait_for_server ip port timeout 10 loop ioloop.IOLoop.current tic loop.time while loop.time - tic < timeout if can_connect ip port returnelse yield gen.sleep 0.1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds".format **locals
def dbode system w None n 100 w y dfreqresp system w w n n if isinstance system dlti dt system.dtelse dt system[ -1 ]mag 20.0 * numpy.log10 abs y phase numpy.rad2deg numpy.unwrap numpy.angle y return w / dt mag phase
def plot_acf x ax None lags None alpha 0.05 use_vlines True unbiased False fft False title 'Autocorrelation' zero True **kwargs fig ax utils.create_mpl_ax ax lags nlags irregular _prepare_data_corr_plot x lags zero confint Noneif alpha is None acf_x acf x nlags nlags alpha alpha fft fft unbiased unbiased else acf_x confint acf x nlags nlags alpha alpha fft fft unbiased unbiased _plot_corr ax title acf_x confint lags irregular use_vlines **kwargs return fig
def status name sig None runas None if sig return __salt__['status.pid'] sig output list_ runas runas pids ''for line in output.splitlines if 'PID' in line continueif re.search name line if line.split [0].isdigit if pids pids + '\n'pids + line.split [0]return pids
def independent a b return not dependent a b
def test_operator_type assert TPOTSelectKBest .type 'Selector'
def load_data path 'mnist.pkl.gz' path get_file path origin 'https //s3.amazonaws.com/img-datasets/mnist.pkl.gz' if path.endswith '.gz' f gzip.open path 'rb' else f open path 'rb' if sys.version_info < 3 data cPickle.load f else data cPickle.load f encoding 'bytes' f.close return data
def test_geometric_mean_support_binary y_true y_pred _ make_prediction binary True geo_mean geometric_mean_score y_true y_pred assert_allclose geo_mean 0.77 rtol R_TOL
def glr_path_static return os.path.abspath os.path.join os.path.dirname __file__ '_static'
def canonicalize_email email if not email return ''email _force_utf8 email.lower localpart at domain email.partition '@' if not at or '@' in domain return ''localpart localpart.replace '.' '' localpart localpart.partition '+' [0]return localpart + '@' + domain
def table_column_to_votable_datatype column if column.dtype.char u'O' if isinstance column[0] bytes if _all_bytes column[1 ] return {u'datatype' u'char' u'arraysize' u'*'}elif isinstance column[0] six.text_type if _all_unicode column[1 ] return {u'datatype' u'unicodeChar' u'arraysize' u'*'}elif isinstance column[0] np.ndarray dtype shape _all_matching_dtype column if dtype is not False result numpy_to_votable_dtype dtype shape if u'arraysize' not in result result[u'arraysize'] u'*'else result[u'arraysize'] + u'*'return resultreturn {u'datatype' u'unicodeChar' u'arraysize' u'*'}return numpy_to_votable_dtype column.dtype column.shape[1 ]
def get_semver_version version main u'.'.join str x for x in version[ 3] sub u''if version[3] ! u'final' sub u'-{}.{}'.format *version[3 ] return main + sub
def getmodebandnames mode return ImageMode.getmode mode .bands
def hex2str hexnum intsize 4 if not isinstance hexnum six.string_types nbits intsize * 8 hexnum '0x%x' % hexnum + 1 << nbits % 1 << nbits s hexnum[2 ]if len s % 2 ! 0 s '0' + s result codecs.decode s 'hex' [ -1 ]return result
def _GetMSBuildExternalBuilderTargets spec build_cmd _BuildCommandLineForRuleRaw spec spec['msvs_external_builder_build_cmd'] False False False False build_target ['Target' {'Name' 'Build'}]build_target.append ['Exec' {'Command' build_cmd}] clean_cmd _BuildCommandLineForRuleRaw spec spec['msvs_external_builder_clean_cmd'] False False False False clean_target ['Target' {'Name' 'Clean'}]clean_target.append ['Exec' {'Command' clean_cmd}] targets [build_target clean_target]if spec.get 'msvs_external_builder_clcompile_cmd' clcompile_cmd _BuildCommandLineForRuleRaw spec spec['msvs_external_builder_clcompile_cmd'] False False False False clcompile_target ['Target' {'Name' 'ClCompile'}]clcompile_target.append ['Exec' {'Command' clcompile_cmd}] targets.append clcompile_target return targets
def gis_layer_onaccept form enable current.request.post_vars.enableif enable db current.dbs3db current.s3dbctable s3db.gis_configquery ctable.uuid 'SITE_DEFAULT' config db query .select ctable.id limitby 0 1 .first if not config returnconfig_id config.idlayer_id form.vars.layer_idltable s3db.gis_layer_configquery ltable.config_id config_id & ltable.layer_id layer_id record db query .select ltable.id limitby 0 1 .first if record db query .update enabled True else ltable.insert config_id config_id layer_id layer_id enabled True
def make_percent_align_filter min_percent min_percent float min_percent * 100 def align_filter blast_result if float blast_result['%IDENTITY'] < min_percent return Falseelse return Truereturn align_filter
def parse_boolean value if value in [u'true' u'1'] return Trueelif value in [u'false' u'0'] return Falseelse raise ValueError u"expected'true'or'false' got'%s'" % value
def trackers request trackers get_tasktrackers request return render 'tasktrackers.mako' request {'trackers' trackers}
def gen_not_started gen return gen.gi_frame and gen.gi_frame.f_lasti -1
def about request context {'title' 'About'}template 'general/about.html'return render request template context
def all_control_queues_for_declare config possible_uwsgi_queues []if process_is_uwsgi import uwsgipossible_uwsgi_queues [Queue 'control.%s.%s' % config.server_name.split '.' [0] wkr['id'] galaxy_exchange routing_key 'control' for wkr in uwsgi.workers ]return possible_uwsgi_queues + [Queue 'control.%s' % q galaxy_exchange routing_key 'control' for q in config.server_names]
def is_stable coefs verbose False A_var1 util.comp_matrix coefs eigs np.linalg.eigvals A_var1 if verbose print 'EigenvaluesofVAR 1 rep' for val in np.abs eigs print val return np.abs eigs < 1 .all
def axes *args **kwargs nargs len args if len args 0 return subplot 111 **kwargs if nargs > 1 raise TypeError u'Onlyonenonkeywordargtoaxesallowed' arg args[0]if isinstance arg Axes a gcf .sca arg else rect arga gcf .add_axes rect **kwargs return a
def accel_decel clip new_duration None abruptness 1.0 soonness 1.0 if new_duration is None new_duration clip.durationfl lambda t f_accel_decel t clip.duration new_duration abruptness soonness return clip.fl_time fl .set_duration new_duration
def generate_html attrs api_key flickr_data get_info attrs['photo_id'] api_key if 'size' not in attrs.keys attrs['size'] 'large'if 'alt' not in attrs.keys attrs['alt'] flickr_data['photo']['title']['_content']return '<ahref "{}"><imgsrc "{}"alt "{}"></a>'.format flickr_data['photo']['urls']['url'][0]['_content'] source_url flickr_data['photo']['farm'] flickr_data['photo']['server'] attrs['photo_id'] flickr_data['photo']['secret'] attrs['size'] attrs['alt']
@shared_task bind True def add_to_all self nums val subtasks [add.s num val for num in nums]raise self.replace group *subtasks
def assert_policy_shape policy errors []if policy['Version'] ! '2012-10-17' errors.append 'Unknownversion/date {} ofpolicy.Thingsareprobablydifferentthanweassumedtheywere.'.format policy['Version'] found_statement_type {}for statement in policy['Statement'] for label sidlabel in statement_label.items if statement['Sid'] sidlabel found_statement_type[label] Truefor statementtype in statement_label.keys if not found_statement_type.get statementtype errors.append 'Policyismissing{}.'.format statementtype if len errors raise Exception 'Problemsassertingpolicyshape.Cowardlyrefusingtomodifyit {}'.format ''.join errors return None
def round x return tf.round x
def _places client url_part query None location None radius None keyword None language None min_price 0 max_price 4 name None open_now False rank_by None type None page_token None params {'minprice' min_price 'maxprice' max_price}if query params['query'] queryif location params['location'] convert.latlng location if radius params['radius'] radiusif keyword params['keyword'] keywordif language params['language'] languageif name params['name'] convert.join_list '' name if open_now params['opennow'] 'true'if rank_by params['rankby'] rank_byif type params['type'] typeif page_token params['pagetoken'] page_tokenurl '/maps/api/place/%ssearch/json' % url_part return client._get url params
def RawValue typecode_or_type *args type_ typecode_to_type.get typecode_or_type typecode_or_type obj _new_value type_ ctypes.memset ctypes.addressof obj 0 ctypes.sizeof obj obj.__init__ *args return obj
def handle_extensions extensions 'html' ignored 'py' ext_list []for ext in extensions ext_list.extend ext.replace '' '' .split ' ' for i ext in enumerate ext_list if not ext.startswith '.' ext_list[i] '.%s' % ext_list[i] return set [x for x in ext_list if x.strip '.' not in ignored ]
@not_implemented_for 'directed' def connected_components G seen set for v in G if v not in seen c set _plain_bfs G v yield c seen.update c
def _classOfMethod methodObject if _PY3 return methodObject.__self__.__class__return methodObject.im_class
def _resize_part_and_fs dev start old_sectors new_sectors size new_sectors - start end new_sectors - 1 dev_path utils.make_dev_path dev partition_path utils.make_dev_path dev partition 1 utils.execute 'e2fsck' '-f' '-y' partition_path run_as_root True check_exit_code [0 1 2] utils.execute 'tune2fs' '-O^has_journal' partition_path run_as_root True if new_sectors < old_sectors utils.execute 'resize2fs' partition_path '%ds' % size run_as_root True utils.execute 'parted' '--script' dev_path 'rm' '1' run_as_root True utils.execute 'parted' '--script' dev_path 'mkpart' 'primary' '%ds' % start '%ds' % end run_as_root True if new_sectors > old_sectors utils.execute 'resize2fs' partition_path run_as_root True utils.execute 'tune2fs' '-j' partition_path run_as_root True
def get_course_organizations course_id if not organizations_enabled return []from organizations import api as organizations_apireturn organizations_api.get_course_organizations course_id
@FileSystem.in_directory current_directory 'django' 'couves' def test_django_agains_couves status out run_scenario expect 'Couvesbeforeall' .to.be.within out expect 'Couvesafterall' .to.be.within out
def get_homebrew_path formula '' import subprocessbrewcmd ['brew' '--prefix']path Noneif formula brewcmd.append formula dbgstr 'homebrewformula"%s"' % formula else dbgstr 'homebrewprefix'try path subprocess.check_output brewcmd .strip logger.debug 'Found%sat"%s"' % dbgstr path except OSError logger.debug 'Detectedhomebrewnotinstalled' except subprocess.CalledProcessError logger.debug 'homebrewformula"%s"notinstalled' % formula if path if is_py3 path path.decode 'utf8' return pathelse return None
def is_disabled iface return not is_enabled iface
def _deferGenerator g deferred result Nonewaiting [True None]while 1 try result g.next except StopIteration deferred.callback result return deferredexcept deferred.errback return deferredif isinstance result Deferred return fail TypeError 'YieldwaitForDeferred d notd!' if isinstance result waitForDeferred def gotResult r result result result.result rif waiting[0] waiting[0] Falsewaiting[1] relse _deferGenerator g deferred result.d.addBoth gotResult if waiting[0] waiting[0] Falsereturn deferredwaiting[0] Truewaiting[1] Noneresult None
def escape_quotes text return ''.join escape_table.get c c for c in text
@verbosedef tfr_stockwell inst fmin None fmax None n_fft None width 1.0 decim 1 return_itc False n_jobs 1 verbose None data _get_data inst return_itc picks pick_types inst.info meg True eeg True info pick_info inst.info picks data data[ picks ]n_jobs check_n_jobs n_jobs power itc freqs _induced_power_stockwell data sfreq info['sfreq'] fmin fmin fmax fmax n_fft n_fft width width decim decim return_itc return_itc n_jobs n_jobs times inst.times[ decim].copy nave len data out AverageTFR info power times freqs nave method 'stockwell-power' if return_itc out out AverageTFR deepcopy info itc times.copy freqs.copy nave method 'stockwell-itc' return out
@pytest.mark.django_dbdef test_get_children project0 language0 def _all_children_are_directories_or_stores item for child in item.children if isinstance child Directory _all_children_are_directories_or_stores child else assert isinstance child Store for tp in project0.children assert isinstance tp TranslationProject _all_children_are_directories_or_stores tp for tp in language0.children assert isinstance tp TranslationProject _all_children_are_directories_or_stores tp
def indent element level 0 indent ' DCTB ' def empty text return not text or not text.strip def indent_ element level last child_count len element if child_count if empty element.text element.text '\n' + indent * level + 1 if empty element.tail element.tail '\n' + indent * level + -1 if last else 0 for i child in enumerate element indent_ child level + 1 i child_count - 1 elif empty element.tail element.tail '\n' + indent * level + -1 if last else 0 return indent_ element level True
def libvlc_vlm_get_media_instance_time p_instance psz_name i_instance f _Cfunctions.get 'libvlc_vlm_get_media_instance_time' None or _Cfunction 'libvlc_vlm_get_media_instance_time' 1 1 1 None ctypes.c_int Instance ctypes.c_char_p ctypes.c_int return f p_instance psz_name i_instance
def string_span_tokenize s sep if len sep 0 raise ValueError 'Tokendelimitermustnotbeempty' left 0while True try right s.index sep left if right ! 0 yield left right except ValueError if left ! len s yield left len s breakleft right + len sep
def volume_type_create context values projects None return IMPL.volume_type_create context values projects
def monitor_todo_format physical_line pos physical_line.find 'TODO' pos1 physical_line.find 'TODO ' pos2 physical_line.find '#' if pos ! pos1 and pos2 > 0 and pos2 < pos return pos 'ENERGYN101 UseTODO NAME '
def parse_path value value strip_spaces_and_quotes value assert valid_path value return value
def test_callable_args func args assert isinstance args list tuple signature getattr inspect u'signature' None if signature is not None try sig _signatures_cache[func]except KeyError sig signature func _signatures_cache[func] sigtry sig.bind *args except TypeError return Falseelse return Trueelse spec inspect.getargspec func def drop_self spec args varargs varkw defaults specif args[0 1] [u'self'] args args[1 ]return inspect.ArgSpec args varargs varkw defaults spec drop_self spec if spec.varargs is not None return Truereturn len spec.args - len spec.defaults or [] < len args < len spec.args
def uniq seq return [x for i x in enumerate seq if seq.index x i ]
def dmp_rr_prs_gcd f g u K if not u return dup_rr_prs_gcd f g K result _dmp_rr_trivial_gcd f g u K if result is not None return result fc F dmp_primitive f u K gc G dmp_primitive g u K h dmp_subresultants F G u K [ -1 ] c _ _ dmp_rr_prs_gcd fc gc u - 1 K if K.is_negative dmp_ground_LC h u K h dmp_neg h u K _ h dmp_primitive h u K h dmp_mul_term h c 0 u K cff dmp_quo f h u K cfg dmp_quo g h u K return h cff cfg
def wns_send_bulk_message uri_list message None xml_data None raw_data None **kwargs if uri_list for uri in uri_list wns_send_message uri uri message message xml_data xml_data raw_data raw_data **kwargs
def iter_unique_scheme_hostname urls scheme_hostname set for x in urls p urlparse x scheme_hostname.add p.scheme p.hostname return list scheme_hostname
def enf_type field _type val try return _type val except ValueError raise TwitterError {u'message' u'"{0}"mustbetype{1}'.format field _type.__name__ }
def _space_prefix pref full sep None indent None include_sep True if sep is None sep os.path.seppref pref.split sep full full.split sep padding []while pref and full and pref[0] full[0] if indent is None padding.append '' * len full[0] + len sep else padding.append '' * indent full.pop 0 pref.pop 0 if padding if include_sep return ''.join padding + sep + sep.join full else return ''.join padding + sep.join full else return sep.join full
def test_copy label read_label label_fname label_2 label.copy label_2.pos + 1assert_array_equal label.pos label_2.pos - 1
def get_retention_policy database name **client_args client _client **client_args try return next p for p in client.get_list_retention_policies database if p.get 'name' name except StopIteration return {}
def _add_tracking_summary_to_resource_dict resource_dict model tracking_summary model.TrackingSummary.get_for_resource resource_dict['url'] resource_dict['tracking_summary'] tracking_summary
def get_new_files dire return read_in os.path.join dire 'NEW_FILES' .splitlines
def createTripleDES key IV implList None if implList None implList ['cryptlib' 'openssl' 'pycrypto']for impl in implList if impl 'cryptlib' and cryptomath.cryptlibpyLoaded return Cryptlib_TripleDES.new key 2 IV elif impl 'openssl' and cryptomath.m2cryptoLoaded return OpenSSL_TripleDES.new key 2 IV elif impl 'pycrypto' and cryptomath.pycryptoLoaded return PyCrypto_TripleDES.new key 2 IV raise NotImplementedError
def updateProfileSaveListeners for globalProfileSaveListener in euclidean.getListTableElements settings.globalProfileSaveListenerListTable globalProfileSaveListener.save cancelAll
def test_emacs_arguments_for_all_commands for key in ANSI_SEQUENCES if key ! u'\x1b[200~' try result cli _feed_cli_with_input u'hello\x1b4' + key + u'X\n\n' result cli _feed_cli_with_input u'hello\x1b-' + key + u'X\n\n' except KeyboardInterrupt assert key u'\x03'
def sorted_unique series return list pd.Series series.unique .sort_values
def distfitbootstrap sample distr nrepl 100 nobs len sample res np.zeros nrepl for ii in range nrepl rvsind np.random.randint nobs size nobs x sample[rvsind]res[ii] distr.fit_fr x frozen [np.nan 0.0 1.0] return res
def combined_cuboids dimensions required None required tuple required if required else for dim in required if dim not in dimensions raise ArgumentError "Requireddimension'%s'isnotinlistofdimensionstobecombined." % str dim cuboids []to_combine [dim for dim in dimensions if not dim in required ]for i in range len to_combine 0 -1 combos itertools.combinations to_combine i combos [ required + combo for combo in combos]cuboids + tuple combos if required cuboids [required] + cuboids return cuboids
def check_session_view request return HttpResponse request.session.get 'session_var' 'NO'
def equateRectangularDotZ point returnValue point.z returnValue
def crypto_login request if 'client_nonce' in request.GET client_nonce request.GET['client_nonce']try session SyncSession.objects.get client_nonce client_nonce except SyncSession.DoesNotExist return HttpResponseServerError 'Sessionnotfound.' if session.server_device.is_trusted user get_object_or_None User username 'centraladmin' if not user user User username 'centraladmin' is_superuser True is_staff True is_active True user.set_unusable_password user.save user.backend 'django.contrib.auth.backends.ModelBackend'auth_login request user session.delete return HttpResponseRedirect reverse 'homepage'
def broadcasted_add a b raise NotImplementedError 'TODO implementthisfunction.'
def _easteregg app gyver '\n'.join [ x + 77 - len x * '' for x in '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\n7f2zLkGNv8b191cD/3vs9Q833z8t'.decode 'base64' .decode 'zlib' .splitlines ] def easteregged environ start_response def injecting_start_response status headers exc_info None headers.append 'X-Powered-By' 'Werkzeug' return start_response status headers exc_info if environ.get 'QUERY_STRING' ! 'macgybarchakku' return app environ injecting_start_response injecting_start_response '200OK' [ 'Content-Type' 'text/html' ] return [ '\n<!DOCTYPEhtml>\n<html>\n<head>\n<title>AboutWerkzeug</title>\n<styletype "text/css">\nbody{font 15pxGeorgia serif;text-align center;}\na{color #333;text-decoration none;}\nh1{font-size 30px;margin 20px010px0;}\np{margin 0030px0;}\npre{font 11px\'Consolas\' \'Monaco\' monospace;line-height 0.95;}\n</style>\n</head>\n<body>\n<h1><ahref "http //werkzeug.pocoo.org/">Werkzeug</a></h1>\n<p>theSwissArmyknifeofPythonwebdevelopment.</p>\n<pre>%s\n\n\n</pre>\n</body>\n</html>' % gyver ]return easteregged
def DeleteCampaignFeed client campaign_feed campaign_feed_service client.GetService 'CampaignFeedService' 'v201605' operation {'operand' campaign_feed 'operator' 'REMOVE'}campaign_feed_service.mutate [operation]
def test_help_command_should_exit_status_ok_when_no_cmd_is_specified script result script.pip 'help' assert result.returncode SUCCESS
def _coordinateType hemisphere return Angles.LATITUDE if hemisphere in 'NS' else Angles.LONGITUDE
def ds_format ds input_format output_format return datetime.strptime ds input_format .strftime output_format
def _centered arr newsize newsize np.asarray newsize currsize np.array arr.shape startind currsize - newsize // 2 endind startind + newsize myslice [slice startind[k] endind[k] for k in range len endind ]return arr[tuple myslice ]
def sin_cos data 6 * sin data[0] * cos data[1]
def dmp_inner_gcd f g u K if not u return dup_inner_gcd f g K J f g dmp_multi_deflate f g u K h cff cfg _dmp_inner_gcd f g u K return dmp_inflate h J u K dmp_inflate cff J u K dmp_inflate cfg J u K
def seasonal_plot grouped_x xticklabels ylabel None ax None fig ax utils.create_mpl_ax ax start 0ticks []for season df in grouped_x df df.copy df.sort_index nobs len df x_plot np.arange start start + nobs ticks.append x_plot.mean ax.plot x_plot df.values 'k' ax.hlines df.values.mean x_plot[0] x_plot[ -1 ] colors 'r' linewidth 3 start + nobsax.set_xticks ticks ax.set_xticklabels xticklabels ax.set_ylabel ylabel ax.margins 0.1 0.05 return fig
def scp_remote_escape filename escape_chars '!"$&\' * ;< >?[\\]^`{|}'new_name []for char in filename if char in escape_chars new_name.append '\\%s' % char else new_name.append char return utils.sh_escape ''.join new_name
def hashPasswordTuple password digestMod hashlib.sha512 iterations 10000 saltSize 32 salt os.urandom saltSize password password.encode u'utf-8' hash pbkdf2 password salt iterations digestMod digestname digestMod.__name__.replace u'openssl_' u'' return digestname iterations salt hash
def not_zero x if x 0 returnreturn x
def add_share_key_to_url plot_url urlsplit six.moves.urllib.parse.urlparse plot_url username urlsplit.path.split '/' [1].split '~' [1]idlocal urlsplit.path.split '/' [2]fid '{} {}'.format username idlocal body {'share_key_enabled' True 'world_readable' False}response v2.files.update fid body return plot_url + '?share_key ' + response.json ['share_key']
def corpus_iterator corpus_file with_logprob False l corpus_file.readline tagfield with_logprob and -2 or -1 try while l line l.strip if line fields line.split '' ne_tag fields[tagfield]word ''.join fields[ tagfield] yield word ne_tag else yield None None l corpus_file.readline except IndexError sys.stderr.write 'Couldnotreadline \n' sys.stderr.write '\n%s' % line if with_logprob sys.stderr.write 'Didyouforgettooutputlogprobabilitiesinthepredictionfile?\n' sys.exit 1
def rpm_packages attrs None where None if __grains__['os_family'] 'RedHat' return _osquery_cmd table 'rpm_packages' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonRedHatbasedsystems.'}
def mplfig_to_npimage fig from matplotlib.backends.backend_agg import FigureCanvasAggcanvas FigureCanvasAgg fig canvas.draw l b w h canvas.figure.bbox.bounds w h int w int h buf canvas.tostring_rgb image np.fromstring buf dtype np.uint8 return image.reshape h w 3
def manhattan_distances X Y None sum_over_features True size_threshold 500000000.0 X Y check_pairwise_arrays X Y if issparse X or issparse Y if not sum_over_features raise TypeError 'sum_over_features %rnotsupportedforsparsematrices' % sum_over_features X csr_matrix X copy False Y csr_matrix Y copy False D np.zeros X.shape[0] Y.shape[0] _sparse_manhattan X.data X.indices X.indptr Y.data Y.indices Y.indptr X.shape[1] D return Dif sum_over_features return distance.cdist X Y 'cityblock' D X[ np.newaxis ] - Y[np.newaxis ] D np.abs D D return D.reshape -1 X.shape[1]
def _inject_imread_collection_if_needed module if not hasattr module 'imread_collection' and hasattr module 'imread' imread getattr module 'imread' func imread_collection_wrapper imread setattr module 'imread_collection' func
def _fswalk_no_symlinks path for dirpath dirnames filenames in _os_walk_unicode path yield dirpath dirnames filenames
def addVertexes geometryOutput vertexes if geometryOutput.__class__ list for element in geometryOutput addVertexes element vertexes returnif geometryOutput.__class__ dict for geometryOutputKey in geometryOutput.keys if geometryOutputKey 'vertex' vertexes + geometryOutput[geometryOutputKey]else addVertexes geometryOutput[geometryOutputKey] vertexes
def install_candidate candidate version None java_version None install java_version if version is None cmd 'gvminstall%s' % candidate else cmd 'gvminstall%s%s' % candidate version run cmd
def test_iht_fit_sample_knn est 'knn'iht InstanceHardnessThreshold est random_state RND_SEED X_resampled y_resampled iht.fit_sample X Y X_gt np.array [[ -0.3879569 0.6894251] [ -0.09322739 1.28177189] [ -0.77740357 0.74097941] [0.91542919 -0.65453327 ] [ -0.43877303 1.07366684] [ -0.85795321 0.82980738] [ -0.30126957 -0.66268378 ] [ -0.65571327 0.42412021] [0.20246714 -0.34727125 ] [1.06446472 -1.09279772 ] [0.30543283 -0.02589502 ] [ -0.00717161 0.00318087]] y_gt np.array [0 1 1 0 1 1 1 0 1 0 0 0] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def join_url_dir url *args for path in args url url.rstrip '/' + '/' url urljoin url path.lstrip '/' return url
def array_to_xy_origin image return rgb_transpose image[ -1 ]
def is_valid_number numobj region_code region_code_for_number numobj return is_valid_number_for_region numobj region_code
def test_gen tpot_obj TPOTClassifier pipeline tpot_obj._gen_grow_safe tpot_obj._pset 1 3 assert len pipeline > 1 assert pipeline[0].ret Output_DF
@pytest.fixture scope 'session' def user_config_data user_dir cookiecutters_dir user_dir.mkdir 'cookiecutters' replay_dir user_dir.mkdir 'cookiecutter_replay' return {'cookiecutters_dir' str cookiecutters_dir 'replay_dir' str replay_dir }
def get_string_sort_order s for i size in enumerate GARMENT_SIZES if size in s return 10 + i s try return 5 parse_decimal_string s except return 1 s
def getServer request return Server getOpenIDStore getViewURL request endpoint
def libvlc_audio_set_mute p_mi status f _Cfunctions.get 'libvlc_audio_set_mute' None or _Cfunction 'libvlc_audio_set_mute' 1 1 None None MediaPlayer ctypes.c_int return f p_mi status
def trainSVM features Cparam [X Y] listOfFeatures2Matrix features svm sklearn.svm.SVC C Cparam kernel 'linear' probability True svm.fit X Y return svm
def polynomial_exp_mod base exponent polymod p assert exponent < p if exponent 0 return [1]G basek exponentif k % 2 1 s Gelse s [1]while k > 1 k k // 2 G polynomial_multiply_mod G G polymod p if k % 2 1 s polynomial_multiply_mod G s polymod p return s
def bootstrap_consensus msa times tree_constructor consensus trees bootstrap_trees msa times tree_constructor tree consensus list trees return tree
def exception_response status_code **kw exc status_map[status_code] **kw return exc
def _systemctl_cmd action name None systemd_scope False ret []if systemd_scope and salt.utils.systemd.has_scope __context__ and __salt__['config.get'] 'systemd.scope' True ret.extend ['systemd-run' '--scope'] ret.append 'systemctl' if isinstance action six.string_types action shlex.split action ret.extend action if name is not None ret.append _canonical_unit_name name if 'status' in ret ret.extend ['-n' '0'] return ret
def SerializeError Exception pass
def fetch_aws uuid fetch_url constants.UrlfetchTestIdentifiers.AWS_URLreturn fetch fetch_url
def get_mirrors config git_name log logging.getLogger 'gitosis.mirror.get_mirrors' try mirrors config.get 'repo%s' % git_name 'mirrors' for mirror in mirrors.split yield mirror except NoSectionError NoOptionError passmirror_sections s for s in config.sections if s.startswith 'mirror' for section in mirror_sections try repos config.get section 'repos' if repos '@all' or git_name in repos.split yield config.get section 'uri' .strip % git_name except NoOptionError log.error '%ssectionislackingthe"repos"or"uri"settings.' section
def test_set_params tpot_obj TPOTClassifier assert tpot_obj.set_params is tpot_obj
def fully_normalize_name name return ''.join name.lower .split
def email_to_group_id address address address.split '@' 1 [0]signed_data address.replace '+' ' ' return int force_bytes signer.unsign signed_data
def glGetStringSize s width 0for c in s width + glutBitmapWidth OpenGL.GLUT.GLUT_BITMAP_HELVETICA_18 ord c height 18return width height
def remap_static_url original_url course input_url "'" + original_url + "'" output_url replace_static_urls input_url getattr course 'data_dir' None course_id course.id static_asset_path course.static_asset_path return output_url[1 -1 ]
def instance_type_extra_specs_update_or_create context flavor_id extra_specs IMPL.instance_type_extra_specs_update_or_create context flavor_id extra_specs
def _MakeRequest host path request_dict from viewfinder.backend.www.basic_auth import BasicAuthHandlerif BasicAuthHandler._HTTP_TEST_CASE url 'http //%s/admin%s' % host path else url 'https //%s/admin%s' % host path req urllib2.Request url req.add_data json.dumps request_dict req.add_header 'Content-Type' 'application/json' return req
def getCharacterIntegerString character offset splitLine stepLength floatValue getFloatFromCharacterSplitLine character splitLine if floatValue is None return ''floatValue + offsetintegerValue int round float floatValue / stepLength return character + str integerValue
def make_eval_exception app global_conf xmlhttp_key None if xmlhttp_key is None xmlhttp_key global_conf.get 'xmlhttp_key' '_' return EvalException app xmlhttp_key xmlhttp_key
@cache_page 60 * 60 * 168 def opensearch_plugin request host u'%s //%s' % 'https' if request.is_secure else 'http' request.get_host return render_to_response 'search/plugin.html' {'host' host 'locale' request.LANGUAGE_CODE} content_type 'application/opensearchdescription+xml'
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def bandpass data low 80 high 1200 rate 44100 order 6 b a _butter order low high rate return lfilter b a data
def icons icons [ 'image/jpeg' 'jpeg' 'image/png' 'png' '' 'default' ] dirs files storage.listdir settings.ADDON_ICONS_DEFAULT_PATH for fname in files if '32' in fname and 'default' not in fname icon_name fname.split '-' [0]icons.append 'icon/%s' % icon_name icon_name return icons
def s3_image_get context image_id return IMPL.s3_image_get context image_id
@must_be_valid_project@must_have_permission WRITE @must_not_be_registrationdef remove_pointer_from_folder auth node pointer_id **kwargs if pointer_id is None raise HTTPError http.BAD_REQUEST pointer_id node.pointing_at pointer_id pointer Pointer.load pointer_id if pointer is None raise HTTPError http.BAD_REQUEST try node.rm_pointer pointer auth auth except ValueError raise HTTPError http.BAD_REQUEST node.save
def _sanitize_ipv4_mapping ip_str if not ip_str.lower .startswith '0000 0000 0000 0000 0000 ffff ' return ip_strhextets ip_str.split ' ' if '.' in hextets[ -1 ] return ip_stripv4_address '%d.%d.%d.%d' % int hextets[6][0 2] 16 int hextets[6][2 4] 16 int hextets[7][0 2] 16 int hextets[7][2 4] 16 result ' '.join hextets[0 6] result + ' ' + ipv4_address return result
def to_filename name return name.replace '-' '_'
def BuildAndDisplayAdUnitTree root_ad_unit all_ad_units tree {}for ad_unit in all_ad_units if 'parentId' in ad_unit if ad_unit['parentId'] not in tree tree[ad_unit['parentId']] []tree[ad_unit['parentId']].append ad_unit DisplayAdUnitTree root_ad_unit tree
def rgb2ycbcr rgb arr _convert ycbcr_from_rgb rgb arr[... 0] + 16arr[... 1] + 128arr[... 2] + 128return arr
def model_to_ctype val if isinstance val Model val {'pk' val.pk 'ctype' ContentType.objects.get_for_model val .pk}return val
def render_form_field field context None form_field u'form.%s' % field return render_template_with_form u'{%bootstrap_field' + form_field + u'%}' context
def dropname ss li newli li[ ]for item in ss.split newli.remove item return newli
def shutdown delay 0 message None cmd ['shutdown' '-i' '5' '-g' delay '-y']if message cmd.append message ret __salt__['cmd.run'] cmd python_shell False return ret
def report_tests output flaky_tests tests list test.id for test _ in flaky_tests for test in sorted tests output.write '{}\n'.format test
def duplicate_identical_ops ops for i in range len ops for j in range i + 1 len ops if ops[i] ops[j] ops[j] ops[i].duplicate
def getIntFromValue value try return int value except passreturn None
def test_rechunk_4d old 5 5 * 4 a np.random.uniform 0 1 10000 .reshape 10 * 4 x da.from_array a chunks old new 10 * 4 x2 rechunk x chunks new assert x2.chunks new assert np.all x2.compute a
def dropout_locations incoming *args **kwargs kwargs['shared_axes'] 1 return DropoutLayer incoming *args **kwargs
def load_emacs_open_in_editor_bindings registry Registry registry.add_binding Keys.ControlX Keys.ControlE filter EmacsMode & ~ HasSelection get_by_name u'edit-and-execute-command' return registry
def _get_request_body request_body if request_body is None return ''if isinstance request_body WindowsAzureData request_body _convert_class_to_xml request_body if isinstance request_body bytes return request_bodyif isinstance request_body _unicode_type return request_body.encode 'utf-8' request_body str request_body if isinstance request_body _unicode_type return request_body.encode 'utf-8' return request_body
def _fontValidator font if u' ' in font font1 families2 font.split u' ' 1 else font1 families2 font None if not _fontRegexReplacements['__FONT_WITH_1_FAMILY'] font1.strip return Falseif families2 and not _fontFamilyValidator families2 return Falsereturn True
def test_config _ip.magic 'config'
def test_env_vars_available_during_preload gunicorn.arbiter.Arbiter PreloadedAppWithEnvSettings
def test_att_double_space header_checker header_checker.check_filename 'attachment;filename "foobar.html"' 'foobar.html'
def get_graphics vm_ out {'autoport' 'None' 'keymap' 'None' 'listen' 'None' 'port' 'None' 'type' 'None'}xml get_xml vm_ ssock _StringIO xml doc minidom.parse ssock for node in doc.getElementsByTagName 'domain' g_nodes node.getElementsByTagName 'graphics' for g_node in g_nodes for key value in g_node.attributes.items out[key] valuereturn out
def create_leq lh_op rh_op None constr_id None if constr_id is None constr_id get_id expr get_constr_expr lh_op rh_op return LinLeqConstr expr constr_id lh_op.size
def _random_stochastic_matrix m n k None sparse False format 'csr' random_state None if k is None k nprobvecs probvec m k random_state random_state if k n P probvecsif sparse return scipy.sparse.coo_matrix P .asformat format else return Prows np.repeat np.arange m k cols sample_without_replacement n k num_trials m random_state random_state .ravel data probvecs.ravel if sparse P scipy.sparse.coo_matrix data rows cols shape m n return P.asformat format else P np.zeros m n P[ rows cols ] datareturn P
@deprecated 'useargs.pop 0 ' def main_run args doc None copyright None version None _COMMANDS.doc doc_COMMANDS.copyright copyright_COMMANDS.version version_COMMANDS.run args
def writePlistToResource rootObject path restype 'plst' resid 0 warnings.warnpy3k 'In3.x writePlistToResourceisremoved.' from Carbon.File import FSRef FSGetResourceForkNamefrom Carbon.Files import fsRdWrPermfrom Carbon import ResplistData writePlistToString rootObject fsRef FSRef path resNum Res.FSOpenResourceFile fsRef FSGetResourceForkName fsRdWrPerm Res.UseResFile resNum try Res.Get1Resource restype resid .RemoveResource except Res.Error passres Res.Resource plistData res.AddResource restype resid '' res.WriteResource Res.CloseResFile resNum
def init_tparams params tparams OrderedDict for kk pp in params.iteritems tparams[kk] theano.shared params[kk] name kk return tparams
def _patchFileLogObserver patch logFiles []oldFileLobObserver log.FileLogObserverdef FileLogObserver logFile logFiles.append logFile return oldFileLobObserver logFile patch log 'FileLogObserver' FileLogObserver return logFiles
def getNumJoysticks if backend 'pyglet' return len pyglet_input.get_joysticks else pygame.joystick.init return pygame.joystick.get_count
def publish_template hass topic payload_template qos None retain None data _build_publish_data topic qos retain data[ATTR_PAYLOAD_TEMPLATE] payload_templatehass.services.call DOMAIN SERVICE_PUBLISH data
def _convert_to_datetime unix_timestamp try unix_timestamp float unix_timestamp return datetime.fromtimestamp unix_timestamp .strftime '%Y-%m-%d%H %M %S' except ValueError TypeError return 'InvalidTimestamp'
def p_enum_item p if len p 4 p[0] [p[1] p[3]]elif len p 2 p[0] [p[1] None]
def cleanup_extra_indexes model_class extra_indexes model_class.compare_indexes .get 'extra' None if not extra_indexes return 0removed_count 0c model_class._get_collection for extra_index in extra_indexes try c.drop_index extra_index LOG.debug 'Droppedindex%sformodel%s.' extra_index model_class.__name__ removed_count + 1except OperationFailure LOG.warning 'Attempttocleanupindex%sfailed.' extra_index exc_info True return removed_count
def iri2uri uri if isinstance uri str scheme authority path query fragment urllib.parse.urlsplit uri authority authority.encode 'idna' .decode 'utf-8' uri urllib.parse.urlunsplit scheme authority path query fragment uri ''.join [encode c for c in uri] return uri
def configure loglevel logging.INFO verbose False simple False logger logging.getLogger outstream sys.stdoutif simple formatter DumbFormatter verbose elif platform.system 'Windows' outstream WindowsOutputStream outstream formatter ANSIColorFormatter verbose elif outstream.isatty formatter ANSIColorFormatter verbose else formatter DumbFormatter verbose if hasattr logger 'overviewerHandler' logger.overviewerHandler.setFormatter formatter logger.setLevel loglevel else logger.overviewerHandler logging.StreamHandler outstream logger.overviewerHandler.setFormatter formatter logger.addHandler logger.overviewerHandler logger.setLevel loglevel
def mad_std data axis None return median_absolute_deviation data axis axis * 1.482602218505602
def random_weighted_sample mapping k if k > len mapping raise ValueError 'samplelargerthanpopulation' sample set while len sample < k sample.add weighted_choice mapping return list sample
def sed filename change_dict f open filename 'r' data f.read f.close for key val in change_dict.items data data.replace key val f open filename 'w' f.write data f.close
def parse_netntlm_resp_msg headers resp_header seq try header_val3 headers[resp_header]except KeyError returnheader_val3 header_val3.split '' 1 if header_val3[0] 'NTLM' or header_val3[0] 'Negotiate' try msg3 base64.decodestring header_val3[1] except binascii.Error returnreturn parse_ntlm_resp msg3 seq
def decompose_power expr base exp expr.as_base_exp if exp.is_Number if exp.is_Rational if not exp.is_Integer base Pow base Rational 1 exp.q exp exp.pelse base exp expr 1 else exp tail exp.as_coeff_Mul rational True if exp is S.NegativeOne base exp Pow base tail -1 elif exp is not S.One tail _keep_coeff Rational 1 exp.q tail base exp Pow base tail exp.p else base exp expr 1 return base exp
def get_user_for_token token scope max_age None try data signing.loads token max_age max_age except signing.BadSignature raise exc.NotAuthenticated _ 'Invalidtoken' model_cls get_user_model try user model_cls.objects.get pk data[ 'user_%s_id' % scope ] except model_cls.DoesNotExist KeyError raise exc.NotAuthenticated _ 'Invalidtoken' else return user
def post_dns_record **kwargs if 'kwargs' in kwargs f_kwargs kwargs['kwargs']del kwargs['kwargs']kwargs.update f_kwargs mandatory_kwargs 'dns_domain' 'name' 'record_type' 'record_data' for i in mandatory_kwargs if kwargs[i] passelse error '{0} "{1}"##allmandatoryargsmustbeprovided {2}'.format i kwargs[i] str mandatory_kwargs raise SaltInvocationError error domain query method 'domains' droplet_id kwargs['dns_domain'] if domain result query method 'domains' droplet_id kwargs['dns_domain'] command 'records' args {'type' kwargs['record_type'] 'name' kwargs['name'] 'data' kwargs['record_data']} http_method 'post' return resultreturn False
def _AddClearFieldMethod message_descriptor cls def ClearField self field_name try field message_descriptor.fields_by_name[field_name]except KeyError raise ValueError 'Protocolmessagehasno"%s"field.' % field_name if field in self._fields del self._fields[field]self._Modified cls.ClearField ClearField
def get_all_by_namespace context namespace_name session namespace namespace_api.get context namespace_name session db_recs session.query models.MetadefResourceType .join models.MetadefResourceType.associations .filter_by namespace_id namespace['id'] .values models.MetadefResourceType.name models.MetadefNamespaceResourceType.properties_target models.MetadefNamespaceResourceType.prefix models.MetadefNamespaceResourceType.created_at models.MetadefNamespaceResourceType.updated_at model_dict_list []for name properties_target prefix created_at updated_at in db_recs model_dict_list.append _set_model_dict name properties_target prefix created_at updated_at return model_dict_list
def _get_mask X value_to_mask if value_to_mask 'NaN' or np.isnan value_to_mask return np.isnan X else return X value_to_mask
def _strip_clear_tag v if isinstance v ClearedValue return v.valueelse return v
def test_sigma_clip_scalar_mask data np.arange 5 result sigma_clip data sigma 100.0 iters 1 assert result.mask.shape !
def prefix handlers default None error 'Therequestedprefixdoesnotmatchanyofthoseallowed' def output_type data request response path request.pathhandler defaultfor prefix_test prefix_handler in handlers.items if path.startswith prefix_test handler prefix_handlerbreakif not handler raise falcon.HTTPNotAcceptable error response.content_type handler.content_typereturn handler data request request response response output_type.__doc__ 'Supportsanyofthefollowingformats {0}'.format ' '.join function.__doc__ for function in handlers.values output_type.content_type ' '.join handlers.keys return output_type
def activate_minion_cachedir minion_id base None if base is None base __opts__['cachedir']fname '{0}.p'.format minion_id src os.path.join base 'requested' fname dst os.path.join base 'active' shutil.move src dst
def is_backend_frozen context host cluster_name return IMPL.is_backend_frozen context host cluster_name
def test_bootstrap_length out algo.bootstrap a_norm assert_equal len out 10000 n_boot 100out algo.bootstrap a_norm n_boot n_boot assert_equal len out n_boot
def pytest_generate_tests metafunc test_indices [0]test_funcs [TestFuncs.func_dot_reduction_mix TestFuncs.func_dot_reduction_transpose_mix]test_tensor_flags ['pos_rand' 'neg_rand' 'rand']test_tensor_dims [ 2 2 ]if 'custom_args' in metafunc.fixturenames fargs itertools.product test_indices test_funcs test_tensor_flags test_tensor_dims metafunc.parametrize 'custom_args' fargs
def collapse_linebreaks string threshold 1 n '\n' * threshold p [s.rstrip for s in string.splitlines ]string '\n'.join p string re.sub n + '+' n string return string
def node return uname .node
def add_cinder for name function in globals .items if not inspect.isfunction function continueargs inspect.getargspec function [0]if args and name.startswith 'cinder' exec 'pep8.%s %s' % name name
def isbinarytext text assert isinstance text str "textmustbestr got'%s'" % type text .__name__ return any c in _BINARYCHARS for c in text
def GetNotifications user None token None if not user user getpass.getuser user_obj aff4.FACTORY.Open aff4.ROOT_URN.Add 'users' .Add user token token return list user_obj.Get user_obj.Schema.PENDING_NOTIFICATIONS
def _equal_topology tree1 tree2 term_names1 set term.name for term in tree1.find_clades terminal True term_names2 set term.name for term in tree2.find_clades terminal True return term_names1 term_names2 and _bitstring_topology tree1 _bitstring_topology tree2
def getLeftPointIndex points if len points < 1 return NoneleftPointIndex 0for pointIndex in xrange len points if points[pointIndex].real < points[leftPointIndex].real leftPointIndex pointIndexreturn leftPointIndex
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def patch_dns from gevent import socketpatch_module 'socket' items socket.__dns__
def get_model_location session service_definition service_name None service_model ServiceModel service_definition if service_name is None endpoint_prefix service_model.endpoint_prefixservice_name _get_service_name session endpoint_prefix api_version service_model.api_versiondata_path session.get_component 'data_loader' .CUSTOMER_DATA_PATHservice_model_name 'service-%d.json' % int float service_definition.get 'version' '2.0' return os.path.join data_path service_name api_version service_model_name
def _image_entropy img hist img.histogram hist_size sum hist hist [ float h / hist_size for h in hist]return - sum p * math.log p 2 for p in hist if p ! 0
def calc_accuracy X queries n_queries n_neighbors exact_neighbors average_time_exact **lshf_params print 'BuildingLSHForestfor%dsamplesin%ddimensions' % X.shape[0] X.shape[1] lshf LSHForest **lshf_params t0 time lshf.fit X lshf_build_time time - t0 print 'Donein%0.3fs' % lshf_build_time accuracy 0t0 time approx_neighbors lshf.kneighbors queries n_neighbors n_neighbors return_distance False average_time_approx time - t0 / n_queries for i in range len queries accuracy + np.in1d approx_neighbors[i] exact_neighbors[i] .mean accuracy / n_queriesspeed_up average_time_exact / average_time_approx print 'Averagetimeforlshfneighborqueries %0.3fs' % average_time_approx print 'Averagetimeforexactneighborqueries %0.3fs' % average_time_exact print 'AverageAccuracy %0.2f' % accuracy print 'Speedup %0.1fx' % speed_up return speed_up accuracy
def parse_decimal string return get_i18n .parse_decimal string
def bei_zeros nt if not isscalar nt or floor nt ! nt or nt < 0 raise ValueError 'ntmustbepositiveintegerscalar.' return specfun.klvnzo nt 2
def hadamard_product *matrices if not matrices raise TypeError 'EmptyHadamardproductisundefined' validate *matrices if len matrices 1 return matrices[0]else return HadamardProduct *matrices .doit
@taskdef linkcheck ctx build ctx builder 'linkcheck'
def selection_sort collection length len collection for i in range length least ifor k in range i + 1 length if collection[k] < collection[least] least k collection[least] collection[i] collection[i] collection[least] return collection
def _normalized_levenshtein_distance s1 s2 acceptable_differences if len s1 > len s2 s1 s2 s2 s1 acceptable_differences set - i for i in acceptable_differences distances range len s1 + 1 for index2 num2 in enumerate s2 new_distances [ index2 + 1 ]for index1 num1 in enumerate s1 if num2 - num1 in acceptable_differences new_distances.append distances[index1] else new_distances.append 1 + min distances[index1] distances[ index1 + 1 ] new_distances[ -1 ] distances new_distancesreturn distances[ -1 ]
def make_random_form identification uuid.uuid4 .hex[ 8]return AccountCreationForm data {'username' 'user_{id}'.format id identification 'email' 'email_{id}@example.com'.format id identification 'password' '12345' 'name' 'User{id}'.format id identification } tos_required False
def _client_type app_id return '1' if app_id[0] '/' else '0'
def _prf_divide numerator denominator metric modifier average warn_for result numerator / denominator mask denominator 0.0 if not np.any mask return resultresult[mask] 0.0axis0 'sample'axis1 'label'if average 'samples' axis0 axis1 axis1 axis0 if metric in warn_for and 'f-score' in warn_for msg_start '{0}andF-scoreare'.format metric.title elif metric in warn_for msg_start '{0}is'.format metric.title elif 'f-score' in warn_for msg_start 'F-scoreis'else return resultmsg '{0}ill-definedandbeingsetto0.0{{0}}no{1}{2}s.'.format msg_start modifier axis0 if len mask 1 msg msg.format 'dueto' else msg msg.format 'in{0}swith'.format axis1 warnings.warn msg UndefinedMetricWarning stacklevel 2 return result
def cache_subnet_group_absent name region None key None keyid None profile None **args ret {'name' name 'result' True 'comment' '' 'changes' {}}args dict [ k v for k v in args.items if not k.startswith '_' ] exists __salt__['boto3_elasticache.cache_subnet_group_exists'] name region region key key keyid keyid profile profile if exists if __opts__['test'] ret['comment'] 'Cachesubnetgroup{0}wouldberemoved.'.format name ret['result'] Nonereturn retdeleted __salt__['boto3_elasticache.delete_cache_subnet_group'] name region region key key keyid keyid profile profile **args if deleted ret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodelete{0}cache_subnetgroup.'.format name else ret['comment'] 'Cachesubnetgroup{0}alreadyabsent.'.format name return ret
def test_pdbbreakpoint_op b tensor.fmatrix condition tensor.gt b.sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano.function [b] output mode mode_with_gpu topo f.maker.fgraph.toposort assert isinstance topo[ -2 ].op cuda.GpuElemwise assert topo[ -1 ].op cuda.host_from_gpu
def check_valid_profile option _opt_str value parser profs registry.get_plugin_classes obj.Profile if profs try profs[value]except KeyError debug.error 'Invalidprofile' + value + 'selected' setattr parser.values option.dest value
def test_run_json_dump mocker mock_ensure_success mock_user_config template_name context replay_test_dir replay_file spy_get_replay_file mocker.spy replay 'get_file_name' mock_json_dump mocker.patch 'json.dump' side_effect json.dump replay.dump replay_test_dir template_name context assert not mock_user_config.called mock_ensure_success.assert_called_once_with replay_test_dir spy_get_replay_file.assert_called_once_with replay_test_dir template_name assert mock_json_dump.call_count 1 dumped_context outfile_handler kwargs mock_json_dump.call_argsassert outfile_handler.name replay_file assert dumped_context context
def test_marked_class_run_twice testdir request py_file testdir.makepyfile "\nimportpytest\n@pytest.mark.parametrize 'abc' [1 2 3] \nclassTest1 object \ndeftest_1 self abc \nassertabcin[1 2 3]\n" file_name os.path.basename py_file.strpath rec testdir.inline_run file_name file_name rec.assertoutcome passed 6
def stop_trace logger.info 'DEBUG stop_trace!' pipe_out.write 'debugfinished!' pipe_out.write None
def _escape_tex_reserved_symbols input def replace match return TEX_RESERVED_SYMBOLS_MAP[match.group ]return TEX_RESERVED_SYMBOLS_RE.sub replace input
def varmats_from_mat file_obj rdr MatFile5Reader file_obj file_obj.seek 0 hdr_len MDTYPES[native_code]['dtypes']['file_header'].itemsizeraw_hdr file_obj.read hdr_len file_obj.seek 0 rdr.initialize_read mdict rdr.read_file_header next_position file_obj.tell named_mats []while not rdr.end_of_stream start_position next_position hdr next_position rdr.read_var_header name asstr hdr.name file_obj.seek start_position byte_count next_position - start_position var_str file_obj.read byte_count out_obj BytesIO out_obj.write raw_hdr out_obj.write var_str out_obj.seek 0 named_mats.append name out_obj return named_mats
def eGet Handle IOType Channel pValue x1 if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pv ctypes.c_double pValue ec staticLib.eGet Handle IOType Channel ctypes.byref pv x1 if ec ! 0 raise LabJackException ec return pv.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def get_public_keys vm_ key_filename config.get_cloud_config_value 'ssh_public_key' vm_ __opts__ search_global False default None if key_filename is not None key_filename os.path.expanduser key_filename if not os.path.isfile key_filename raise SaltCloudConfigError "Thedefinedssh_public_key'{0}'doesnotexist".format key_filename ssh_keys []for key in open key_filename .readlines ssh_keys.append key return ssh_keys
def append_to_flowgram_file identifier flowgram fh trim False if trim flowgram flowgram.getQualityTrimmedFlowgram if not hasattr flowgram 'spaced_flowgram' spaced_flowgram_seq ''.join map str flowgram.flowgram flowgram.spaced_flowgram spaced_flowgram_seqelse spaced_flowgram_seq flowgram.spaced_flowgramfh.write '%s%d%s\n' % identifier len flowgram spaced_flowgram_seq
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def set_user_tags name tags runas None if runas is None and not salt.utils.is_windows runas salt.utils.get_user if tags and isinstance tags list tuple tags ''.join tags res __salt__['cmd.run_all'] [__context__['rabbitmqctl'] 'set_user_tags' name tags] runas runas python_shell False msg 'Tag s set'return _format_response res msg
def dmp_ground c u if not c return dmp_zero u for i in range u + 1 c [c]return c
def get_dataless_dataset model global yaml_parseglobal controlif yaml_parse is None from pylearn2.config import yaml_parseif control is None from pylearn2.datasets import controlcontrol.push_load_data False try rval yaml_parse.load model.dataset_yaml_src finally control.pop_load_data return rval
def bindeval text rv vim.bindeval as_vimencoding text if not isinstance rv dict list return as_unicode rv return rv
def change_root new_root pathname if os.name 'posix' if not os.path.isabs pathname return os.path.join new_root pathname else return os.path.join new_root pathname[1 ] elif os.name 'nt' drive path os.path.splitdrive pathname if path[0] '\\' path path[1 ]return os.path.join new_root path else raise DistutilsPlatformError "nothingknownaboutplatform'%s'" % os.name
def default_include_dirs return ['/usr/local/include' '/usr/include']
def skipUnlessAnyDBFeature *features return _deferredSkip lambda not any getattr connection.features feature False for feature in features "Databasedoesn'tsupportanyofthefeature s %s" % ' '.join features
def get_music_section host port token library_name api_endpoint append_token 'library/sections' token url urljoin 'http //{0} {1}'.format host port api_endpoint r requests.get url tree ET.fromstring r.content for child in tree.findall 'Directory' if child.get 'title' library_name return child.get 'key'
def itn n digits 8 format DEFAULT_FORMAT if 0 < n < 8 ** digits - 1 s '%0*o' % digits - 1 n + NUL else if format ! GNU_FORMAT or n > 256 ** digits - 1 raise ValueError 'overflowinnumberfield' if n < 0 n struct.unpack 'L' struct.pack 'l' n [0]s ''for i in xrange digits - 1 s chr n & 255 + s n >> 8s chr 128 + s return s
def FindMissingAndroidPlainAssets referenced_images android_assets for name inset in referenced_images.iteritems if inset is not None continueif name in SKIP_PLAIN print 'WARNING %s skippingduetohard-codedexclusioninassets-tool.py' % name continueandroid_name ImageNameAndroid name if android_name not in android_assets name_2x ImageName2X name shutil.copyfile os.path.join IOS_IMAGES_DIR name_2x os.path.join ANDROID_IMAGES_DIR android_name print '%s notinandroidassets copied%s->%s' % name name_2x android_name elif options.options.v print '%s OK' % name
@jsonrpc_method 'os.arch' def os_arch request pipe Popen '/usr/bin/uname-m' stdin PIPE stdout PIPE stderr PIPE shell True close_fds True arch pipe.communicate [0]if pipe.returncode 0 return arch
def submission_allowed user parsed_addon_data return not parsed_addon_data.get 'is_experiment' False or action_allowed_user user 'Experiments' 'submit'
def check_bucket_name_dns_support bucket_host bucket_name if '% bucket s' not in bucket_host return Falsereturn check_bucket_name_dns_conformity bucket_name
def get_uid item return hasattr item 'uid' and item.uid.value
def LONGER fragment return 0 - len fragment
def handle_404 _ response exception logging.exception exception response.set_status 404 response.write jinja_environment.get_template '404.html' .render
def test_fk5_seps a FK5 1.0 * u.deg 1.0 * u.deg b FK5 2.0 * u.deg 2.0 * u.deg a.separation b
def diskfull if cfg.email_full return send T 'To %s\nFrom %s\nDate %s\nSubject SABnzbdreportsDiskFull\n\nHi \n\nSABnzbdhasstoppeddownloading becausethediskisalmostfull.\nPleasemakeroomandresumeSABnzbdmanually.\n\n' % cfg.email_to.get_string cfg.email_from get_email_date cfg.email_to else return ''
def cache_file source try if source.startswith 'salt //' cached_source __salt__['cp.cache_file'] source if not cached_source raise CommandExecutionError 'Unabletocache{0}'.format source return cached_sourceexcept AttributeError raise SaltInvocationError 'Invalidsourcefile{0}'.format source return source
def _indexes gumt gdmt gwmt gdnt try ui gumt / gdmt except ZeroDivisionError ui 0.0try oi gwmt / gdnt except ZeroDivisionError oi 0.0try sw oi / ui except ZeroDivisionError if oi 0.0 sw float 'nan' else sw float 'inf' return ui oi sw
def get_loc_from_db location country row db table.name location .select table.level table.L1 table.L2 table.L3 orderby table.level limitby 0 1 .first if row is None return lookup_loc location country country_code country_codes[country]return country_code row.L1 row.L2 row.L3
def unquote str return re_escaped_char.sub _sub_replacement str[1 -1 ]
def validate_optional_args args optional_args {'json' 'json/simplejsonpythonmodule' json 'secure' 'SSLsupport' HTTPSConnection }for arg info in optional_args.items if getattr args arg False and info[1] is None raise SystemExit '%sisnotinstalled.--%sisunavailable' % info[0] arg
def _bcpath dev return os.path.join _syspath dev 'bcache'
def parse_value s if not s return REMOVE_THIS_KEYelif s[0] in u'"{[0123456789-' or s in u'null' u'true' u'false' return json.loads s else return s
def grey_erosion input size None footprint None structure None output None mode 'reflect' cval 0.0 origin 0 if size is None and footprint is None and structure is None raise ValueError 'size footprintorstructuremustbespecified' return filters._min_or_max_filter input size footprint structure output mode cval origin 1
def chocolatey_version if 'chocolatey._version' in __context__ return __context__['chocolatey._version']cmd [_find_chocolatey __context__ __salt__ ]cmd.append '-v' out __salt__['cmd.run'] cmd python_shell False __context__['chocolatey._version'] outreturn __context__['chocolatey._version']
def is_partition G partition return all sum 1 if v in c else 0 for c in partition 1 for v in G
def get_impl_ver impl_ver get_config_var 'py_version_nodot' if not impl_ver or get_abbr_impl 'pp' impl_ver ''.join map str get_impl_version_info return impl_ver
def handle_static environ start_response path try text open path .read if path.endswith '.ico' resp Response text headers [ 'Content-Type' 'image/x-icon' ] elif path.endswith '.html' resp Response text headers [ 'Content-Type' 'text/html' ] elif path.endswith '.txt' resp Response text headers [ 'Content-Type' 'text/plain' ] elif path.endswith '.css' resp Response text headers [ 'Content-Type' 'text/css' ] elif path.endswith '.js' resp Response text headers [ 'Content-Type' 'text/javascript' ] elif path.endswith '.png' resp Response text headers [ 'Content-Type' 'image/png' ] else resp Response text except IOError resp NotFound return resp environ start_response
def pyzmq_version if __revision__ return '@'.join [__version__ __revision__[ 6]] else return __version__
def create_inspector win ctx *l ctx.inspector Inspector win win win.bind children ctx.inspector.on_window_children on_keyboard ctx.inspector.keyboard_shortcut
def addVoronoiPoint begin end midX loop rotatedBegin rotatedEnd if rotatedBegin.real > midX loop.append begin if rotatedEnd.real < midX beginMinusEnd begin - end rotatedBeginMinusEnd rotatedBegin - rotatedEnd loop.append end + beginMinusEnd * midX - rotatedEnd.real / rotatedBeginMinusEnd.real returnif rotatedEnd.real < midX returnendMinusBegin end - begin rotatedEndMinusBegin rotatedEnd - rotatedBegin loop.append begin + endMinusBegin * midX - rotatedBegin.real / rotatedEndMinusBegin.real
def module_to_dict module omittable lambda k k.startswith '_' return dict k repr v for k v in module.__dict__.items if not omittable k
def format_block block nlspaces 0 import relines str block .split '\n' while lines and not lines[0] del lines[0]while lines and not lines[ -1 ] del lines[ -1 ]ws re.match '\\s*' lines[0] .group 0 if ws lines map lambda x x.replace ws '' 1 lines while lines and not lines[0] del lines[0]while lines and not lines[ -1 ] del lines[ -1 ]flines [ '%s%s' % '' * nlspaces line for line in lines]return '\n'.join flines + '\n'
def nproc try return _number __salt__['cmd.run'] 'nproc' .strip except ValueError return 0
def strip_site_theme_templates_path uri theme get_current_theme if not theme return uritemplates_path '/'.join [theme.theme_dir_name get_project_root_name 'templates'] uri re.sub '^/*' + templates_path + '/*' '' uri return uri
def get_money_supply_bal rdint vs.random request Request vs.MACRO_URL % vs.P_TYPE['http'] vs.DOMAINS['sina'] rdint vs.MACRO_TYPE[2] 0 200 rdint text urlopen request timeout 10 .read text text.decode 'gbk' regSym re.compile '\\ count .*? \\}' datastr regSym.findall text datastr datastr[0]datastr datastr.split 'data ' [1]js json.loads datastr df pd.DataFrame js columns vs.MONEY_SUPPLY_BLA_COLS for i in df.columns df[i] df[i].apply lambda x np.where x is None '--' x return df
def mimedata2url source extlist None pathlist []if source.hasUrls for url in source.urls path _process_mime_path to_text_string url.toString extlist if path is not None pathlist.append path elif source.hasText for rawpath in to_text_string source.text .splitlines path _process_mime_path rawpath extlist if path is not None pathlist.append path if pathlist return pathlist
@cmddef test install sh '%s%s' % PYTHON TSCRIPT
def success_revocation cert_path z_util interfaces.IDisplay .notification 'Congratulations!Youhavesuccessfullyrevokedthecertificatethatwaslocatedat{0}{1}{1}'.format cert_path os.linesep pause False
def vwmodel2ldamodel vw_model iterations 50 model_gensim LdaModel num_topics vw_model.num_topics id2word vw_model.id2word chunksize vw_model.chunksize passes vw_model.passes alpha vw_model.alpha eta vw_model.eta decay vw_model.decay offset vw_model.offset iterations iterations gamma_threshold vw_model.gamma_threshold model_gensim.expElogbeta[ ] vw_model._get_topics return model_gensim
def multiple_file_beta input_path output_dir metrics tree_path rowids None full_tree False metrics_list metricstry metrics_list metrics_list.split ' ' except AttributeError passfile_names os.listdir input_path file_names [fname for fname in file_names if not fname.startswith '.' ]try os.makedirs output_dir except OSError passfor metric in metrics_list try metric_f get_nonphylogenetic_metric metric except AttributeError try metric_f get_phylogenetic_metric metric if not tree_path raise ValueError 'atreefileisrequiredfor' + metric except AttributeError raise ValueError 'Couldnotfindmetric%s.\n\nKnownmetricsare %s\n' % metric ' '.join list_known_metrics for fname in file_names single_file_beta os.path.join input_path fname metrics tree_path output_dir rowids full_tree
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def open_with_auth url scheme netloc path params query frag urlparse.urlparse url if scheme in 'http' 'https' auth host urllib2.splituser netloc else auth Noneif auth auth 'Basic' + urllib2.unquote auth .encode 'base64' .strip new_url urlparse.urlunparse scheme host path params query frag request urllib2.Request new_url request.add_header 'Authorization' auth else request urllib2.Request url request.add_header 'User-Agent' user_agent fp urllib2.urlopen request if auth s2 h2 path2 param2 query2 frag2 urlparse.urlparse fp.url if s2 scheme and h2 host fp.url urlparse.urlunparse s2 netloc path2 param2 query2 frag2 return fp
def envs ignore_cache False if not ignore_cache env_cache os.path.join __opts__['cachedir'] 'hgfs/envs.p' cache_match salt.fileserver.check_env_cache __opts__ env_cache if cache_match is not None return cache_matchret set for repo in init repo['repo'].open if repo['branch_method'] in 'branches' 'mixed' for branch in _all_branches repo['repo'] branch_name branch[0]if branch_name repo['base'] branch_name 'base'ret.add branch_name if repo['branch_method'] in 'bookmarks' 'mixed' for bookmark in _all_bookmarks repo['repo'] bookmark_name bookmark[0]if bookmark_name repo['base'] bookmark_name 'base'ret.add bookmark_name ret.update [x[0] for x in _all_tags repo['repo'] ] repo['repo'].close return [x for x in sorted ret if _env_is_exposed x ]
def item_show item item_id None item_type None show 'show' extra_args None cibfile None cmd ['pcs']if isinstance cibfile six.string_types cmd + ['-f' cibfile]if isinstance item six.string_types cmd + [item]elif isinstance item list tuple cmd + itemif item in ['constraint'] cmd + [item_type]if isinstance show six.string_types cmd + [show]elif isinstance show list tuple cmd + showif isinstance item_id six.string_types cmd + [item_id]if isinstance extra_args list tuple cmd + extra_argsif item in ['constraint'] if not isinstance extra_args list tuple or '--full' not in extra_args cmd + ['--full']return __salt__['cmd.run_all'] cmd output_loglevel 'trace' python_shell False
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' def do_clear_password cs args server _find_server cs args.server server.clear_password
def default_storage request return import_string settings.MESSAGE_STORAGE request
def getDoubleFromCharacterSplitLine character splitLine indexOfCharacter getIndexOfStartingWithSecond character splitLine if indexOfCharacter < 0 return NonefloatString splitLine[indexOfCharacter][1 ]try return float floatString except ValueError return None
def _format_template_content content params def arg_replace matchobj "Takesaregexmatching{{{name}}andreturnsparams['name']"param_name matchobj.group 1 if param_name in params return params[param_name]return TEMPLATE_ARG_REGEX.sub arg_replace content
@handle_response_format@treeio_login_requireddef receivable_view request receivable_id response_format 'html' receivable get_object_or_404 Liability pk receivable_id transactions receivable.transaction_set.all return render_to_response 'finance/receivable_view' {'liability' receivable 'transactions' transactions} context_instance RequestContext request response_format response_format
def _set_del_code f @functools.wraps f def wrapped *args **kwargs f *args **kwargs pecan.response.status 204pecan.override_template None return wrapped
def cancorr x1 x2 demean True standardize False if demean or standardize x1 x1 - x1.mean 0 x2 x2 - x2.mean 0 if standardize x1 / x1.std 0 x2 / x2.std 0 t1 np.linalg.pinv x1 .dot x2 t2 np.linalg.pinv x2 .dot x1 m t1.dot t2 cc np.sqrt np.linalg.eigvals m cc.sort return cc[ -1 ]
def QueryService svc_name hscm win32service.OpenSCManager None None win32service.SC_MANAGER_ALL_ACCESS result Nonetry hs win32serviceutil.SmartOpenService hscm svc_name win32service.SERVICE_ALL_ACCESS result win32service.QueryServiceConfig hs win32service.CloseServiceHandle hs finally win32service.CloseServiceHandle hscm return result
def two_phase_session engine_map versioned True session Session binds engine_map twophase True autoflush True autocommit False if versioned session configure_versioning session return session
def getPartRun alias True retVal NonecommonPartsDict optDict['Enumeration']try stack [ item[4][0] if isinstance item[4] list else '' for item in inspect.stack ]for i in xrange 0 len stack - 1 for regex in 'self\\. get[^ ]+ \\ \\ ' 'conf\\.dbmsHandler\\. [^ ]+ \\ \\ ' match re.search regex stack[i] if match retVal match.groups [0]breakif retVal is not None breakexcept TypeError passif alias return commonPartsDict[retVal][1] if isinstance commonPartsDict.get retVal tuple else retVal else return retVal
def _yield_attached_role_policies conn role_name for resp in _repeat _list_attached_role_policies conn role_name for policy_data in resp['attached_policies'] yield policy_data['policy_arn']
def _format_jid_instance jid job ret _format_job_instance job ret.update {'StartTime' salt.utils.jid.jid_to_time jid } return ret
def _convert_nnn_nl val word '' mod rem val % 100 val // 100 if rem > 0 word to_19_nl[rem] + 'Honderd' if mod > 0 word + ''if mod > 0 word + _convert_nn_nl mod return word
def widont value count 1 def replace matchobj return u'&nbsp;%s' % matchobj.group 1 for i in range count value re_widont.sub replace force_unicode value return value
def compare_tree_to_dict actual expected keys for elem data in zip actual expected for key in keys if elem.get key ! data.get key return Falsereturn True
def single y return linkage y method 'single' metric 'euclidean'
def permutationFilter perm return True
def gen_test func None timeout None if timeout is None timeout get_async_test_timeout def wrap f f gen.coroutine f @functools.wraps f def wrapper self return self.io_loop.run_sync functools.partial f self timeout timeout return wrapperif func is not None return wrap func else return wrap
def get_review_request_field field_id return field_registry.get u'field_id' field_id
def argmax a axis None dtype None out None keepdims False return a.argmax axis axis dtype dtype out out keepdims keepdims
def _api_queue_delete output value kwargs if value.lower 'all' removed NzbQueue.do.remove_all kwargs.get 'search' return report output keyword '' data {'status' bool removed 'nzo_ids' removed} elif value items value.split ' ' del_files int_conv kwargs.get 'del_files' removed NzbQueue.do.remove_multiple items del_files return report output keyword '' data {'status' bool removed 'nzo_ids' removed} else return report output _MSG_NO_VALUE
def check_test_runner from django.conf import settingsnew_default u'django.test.runner.DiscoverRunner'test_runner_setting getattr settings u'TEST_RUNNER' new_default if test_runner_setting new_default message [ u"Django1.6introducedanewdefaulttestrunner '%s' " % new_default u'Youshouldensureyourtestsareallrunning&behavingasexpected.See' u'https //docs.djangoproject.com/en/dev/releases/1.6/#new-test-runner' u'formoreinformation.']return u''.join message
def get_attach_port_index session vm_ref ports _get_vm_port_indices session vm_ref if not ports return 0ports.sort configured_ports_len len ports for port_index in range configured_ports_len if port_index ! ports[port_index] return port_indexreturn configured_ports_len
def griewank individual return 1.0 / 4000.0 * sum x ** 2 for x in individual - reduce mul cos x / sqrt i + 1.0 for i x in enumerate individual 1 + 1
def validate_party_gle_currency party_type party company party_account_currency None if not party_account_currency party_account_currency get_party_account_currency party_type party company existing_gle_currency get_party_gle_currency party_type party company if existing_gle_currency and party_account_currency ! existing_gle_currency frappe.throw _ u'AccountingEntryfor{0} {1}canonlybemadeincurrency {2}' .format party_type party existing_gle_currency InvalidAccountCurrency
def LittleEndianBitStruct *args return Buffered BitStruct *args encoder lambda s s[ -1 ] decoder lambda s s[ -1 ] resizer lambda _ _
def _host_dhcp_opts vif_id None gateway None values []if vif_id is not None values.append _host_dhcp_network vif_id values.append '3' if gateway values.append '%s' % gateway return ' '.join values
def gf_LC f K if not f return K.zeroelse return f[0]
def set_signal_handlers signal_handler_map for signal_number handler in signal_handler_map.items signal.signal signal_number handler
def _user_friendly_size size units [_ 'bytes' _ 'KB' _ 'MB' ]i 0while size > 1024 and i < len units size / 1024i + 1return u'{}{}'.format size units[i]
def start name call None return _query 'grid' 'server/power' args {'name' name 'power' 'start'}
def get_blobinfo blob_key datastore_key datastore.Key.from_path blobstore.BLOB_INFO_KIND blob_key namespace '' try return datastore.Get datastore_key except datastore_errors.EntityNotFoundError return None
def _api_switch name output kwargs value kwargs.get 'value' value2 kwargs.get 'value2' if value and value2 pos prio NzbQueue.do.switch value value2 if output not in 'xml' 'json' return report output data pos prio else return report output keyword 'result' data {'position' pos 'priority' prio} else return report output _MSG_NO_VALUE2
def get_temp_dir temp get_environ_variable 'TMP' if temp None temp get_environ_variable 'TEMP' if temp None or '' in temp and os.name 'nt' temp 'C \\temp'if temp None or '' in temp and os.name 'posix' temp '/tmp'return temp
def _projected_entity_to_message ent message_type msg message_type analyzed _analyze_indexed_fields ent._projection for name sublist in analyzed.iteritems prop ent._properties[name]val prop._get_value ent assert isinstance prop model.StructuredProperty bool sublist if sublist field message_type.field_by_name name assert isinstance field messages.MessageField assert prop._repeated field.repeated if prop._repeated assert isinstance val list val [_projected_entity_to_message v field.type for v in val]else assert isinstance val prop._modelclass val _projected_entity_to_message val field.type setattr msg name val return msg
def email_auth server 'smtp.gmail.com 587' domain '@gmail.com' tls_mode None def email_auth_aux email password server server domain domain tls_mode tls_mode if domain if not isinstance domain list tuple domain [str domain ]if not [d for d in domain if email[ - len d ] d ] return False host port server.split ' ' if tls_mode is None tls_mode port '587' try server Noneserver smtplib.SMTP host port server.ehlo if tls_mode server.starttls server.ehlo server.login email password server.quit return Trueexcept logging.exception 'email_auth failed' if server try server.quit except passreturn Falsereturn email_auth_aux
def logFailed epObj release provider None showid int epObj.show.indexerid season int epObj.season epNum int epObj.episode status quality Quality.splitCompositeStatus epObj.status action Quality.compositeStatus FAILED quality _logHistoryItem action showid season epNum quality release provider
def test_name class C object passC.__name__ 'abc'AreEqual C.__name__ 'abc'
@deprecateddef script_resolve_name script_name name if not name return roslib.names.get_ros_namespace if roslib.names.is_global name return nameelif roslib.names.is_private name return ns_join roslib.names.make_caller_id script_name name[1 ] return roslib.names.get_ros_namespace + name
def relpath path start curdir if not path raise ValueError 'nopathspecified' start_list abspath start .split sep path_list abspath path .split sep if start_list[0].lower ! path_list[0].lower unc_path rest splitunc path unc_start rest splitunc start if bool unc_path ^ bool unc_start raise ValueError 'CannotmixUNCandnon-UNCpaths %sand%s ' % path start else raise ValueError 'pathisondrive%s startondrive%s' % path_list[0] start_list[0] for i in range min len start_list len path_list if start_list[i].lower ! path_list[i].lower breakelse i + 1rel_list [pardir] * len start_list - i + path_list[i ] if not rel_list return curdirreturn join *rel_list
def edit_links scheme source_node sink_node initial_links None parent None log.info 'ConstructingaLinkEditordialog.' dlg EditLinksDialog parent windowTitle 'EditLinks' links scheme.find_links source_node source_node sink_node sink_node existing_links [ link.source_channel link.sink_channel for link in links]if initial_links is None initial_links list existing_links dlg.setNodes source_node sink_node dlg.setLinks initial_links log.info 'ExecutingaLinkEditorDialog.' rval dlg.exec_ if rval EditLinksDialog.Accepted edited_links dlg.links links_to_add set edited_links - set existing_links links_to_remove set existing_links - set edited_links return rval list links_to_add list links_to_remove else return rval [] []
def linkHasRel link_attrs target_rel rel_attr link_attrs.get 'rel' return rel_attr and relMatches rel_attr target_rel
def exec_before_job app inp_data out_data param_dict tool None data_name param_dict.get 'name' 'HbVarquery' data_type param_dict.get 'type' 'txt' if data_type 'txt' data_type 'interval' name data next iter out_data.items data app.datatypes_registry.change_datatype data data_type data.name data_nameout_data[name] data
def _dict_object_help object_name path parent_object_names attributes list graph_reference.get_valid_attributes object_name parent_object_names attributes.sort lines textwrap.wrap repr list attributes width LINE_SIZE - TAB_SIZE - 1 help_dict {'object_name' object_name 'path_string' '[' + ']['.join repr k for k in path + ']' 'parent_object_names' parent_object_names 'attributes_string' ' DCTB ' + '\n DCTB '.join lines }return "Validattributesfor'{object_name}'atpath{path_string}underparents{parent_object_names} \n\n{attributes_string}\n\nRun`<{object_name}-object>.help 'attribute' `onanyoftheabove.\n'<{object_name}-object>'istheobjectat{path_string}".format **help_dict
def handle_setup last_step if last_step < 0 returnlast_step last_step or 0 setup_queue [create_objects create_channels at_initial_setup reset_server]for num setup_func in enumerate setup_queue[last_step ] try setup_func except Exception if last_step + num 1 from evennia.objects.models import ObjectDBfor obj in ObjectDB.objects.all obj.delete elif last_step + num 2 from evennia.comms.models import ChannelDBChannelDB.objects.all .delete raiseServerConfig.objects.conf 'last_initial_setup_step' last_step + num + 1 ServerConfig.objects.conf 'last_initial_setup_step' -1
def atomp lst return not isinstance lst list
def dup_inner_isolate_positive_roots f K eps None inf None sup None fast False mobius False if sup is not None and sup < 0 return []roots dup_inner_isolate_real_roots f K eps eps fast fast F results K.get_field [] if inf is not None or sup is not None for f M in roots result _discard_if_outside_interval f M inf sup K False fast mobius if result is not None results.append result elif not mobius for f M in roots u v _mobius_to_interval M F results.append u v else results rootsreturn results
@retry exception psutil.NoSuchProcess logfun None timeout GLOBAL_TIMEOUT interval 0.001 def wait_for_pid pid psutil.Process pid if WINDOWS time.sleep 0.01
def parole2universal token tag if tag 'CS' return token CONJ if tag 'DP' return token DET if tag in 'P0' 'PD' 'PI' 'PP' 'PR' 'PT' 'PX' return token PRON return penntreebank2universal *parole2penntreebank token tag
def cert_get_not_after cert return cert.not_valid_after
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def find_torrent info_hash torrent_list for t in torrent_list if t.info_hash info_hash return t
def getem arr chunks shape None out_name None fancy True lock False out_name out_name or arr chunks normalize_chunks chunks shape keys list product [out_name] *[range len bds for bds in chunks] slices slices_from_chunks chunks getter getarray if fancy else getarray_nofancy if lock values [ getter arr x lock for x in slices]else values [ getter arr x for x in slices]return dict zip keys values
def CancelBatchJob client batch_job max_poll_attempts MAX_POLL_ATTEMPTS batch_job_service client.GetService 'BatchJobService' 'v201605' batch_job['status'] 'CANCELING'operation {'operator' 'SET' 'operand' batch_job}batch_job_service.mutate [operation] poll_attempt 0while poll_attempt in range max_poll_attempts and batch_job['status'] ! 'CANCELED' sleep_interval 30 * 2 ** poll_attempt + random.randint 0 10000 / 1000 print 'BatchJobnotfinishedcanceling sleepingfor%sseconds.' % sleep_interval time.sleep sleep_interval batch_job GetBatchJob client batch_job['id'] poll_attempt + 1if batch_job['status'] 'CANCELED' print 'BatchJobwithID"%d"hasbeensuccessfullycanceled.' % batch_job['id'] else print 'BatchJobwithID"%d"failedtocancelafterpolling%dtimes.' % batch_job['id'] max_poll_attempts
def group_type_specs_update_or_create context group_type_id group_specs return IMPL.group_type_specs_update_or_create context group_type_id group_specs
def get_enrollment user_id course_id return _data_api .get_course_enrollment user_id course_id
def module_exists module_name try __import__ module_name except ImportError return Falseelse return True
def run_proxy port start_ioloop True app tornado.web.Application [ '.*' ProxyHandler ] app.listen port ioloop tornado.ioloop.IOLoop.instance if start_ioloop ioloop.start
def get_all_bundle_files bundle ctx None if not ctx ctx wrap bundle.env bundle if not isinstance ctx ContextWrapper ctx ContextWrapper ctx files []for _ c in bundle.resolve_contents ctx if isinstance c Bundle files.extend get_all_bundle_files c wrap ctx c elif not is_url c files.append c files.extend bundle.resolve_depends ctx return files
def minimalBases classes if not __python3 classes [c for c in classes if c is not ClassType ]candidates []for m in classes for n in classes if issubclass n m and m is not n breakelse if m in candidates candidates.remove m candidates.append m return candidates
def get_readable_field_data_type field return field.description % field.__dict__
def django_cmd sys settings *args sys 'cms' if sys 'studio' else sys return cmd 'pythonmanage.py' sys '--settings {}'.format settings *args
def efuse_write_reg_addr block word return EFUSE_REG_WRITE[block] + 4 * word
def fixture_to_tables fixture tables []for title content in fixture.iteritems rows []keys content.keys keys.sort rows.append tuple keys row1 []for col in rows[0] row1.append content[col] rows.append tuple row1 tables.append title tuple rows return tables
def SpliceContinuations tree def RecSplicer node 'Insertsacontinuationmarkerintothenode.'if isinstance node pytree.Leaf if node.prefix.lstrip .startswith '\\\n' new_lineno node.lineno - node.prefix.count '\n' return pytree.Leaf type format_token.CONTINUATION value node.prefix context '' new_lineno 0 return Nonenum_inserted 0for index child in enumerate node.children[ ] continuation_node RecSplicer child if continuation_node node.children.insert index + num_inserted continuation_node num_inserted + 1RecSplicer tree
def jinja_error raise Exception 'hehehe'
def _find_console_stream_handler logger for handler in logger.handlers if isinstance handler logging.StreamHandler and handler.stream in sys.stderr sys.stdout return loggerreturn None
def attribute_ac M try import numpyexcept ImportError raise ImportError 'attribute_assortativityrequiresNumPy http //scipy.org/' if M.sum ! 1.0 M M / float M.sum M numpy.asmatrix M s M * M .sum t M.trace r t - s / 1 - s return float r
def _inherited_row row base_rows_from_pillar ret base_rows []for base_row_from_pillar in base_rows_from_pillar base_row __salt__['pillar.get'] base_row_from_pillar if base_row base_rows.append base_row elif base_row_from_pillar ! _DEFAULT_ROW_PILLAR ret.setdefault 'warnings' [] warning_message 'Cannotfindrowpillar"{0}".'.format base_row_from_pillar if warning_message not in ret['warnings'] ret['warnings'].append warning_message base_rows.append row result_row {}for row in base_rows result_row.update row return result_row
def reviewer_required region None moderator False def decorator f @login_required@functools.wraps f def wrapper request *args **kw reviewer_perm acl.check_reviewer request moderator_perm moderator and acl.action_allowed request 'Apps' 'ModerateReview' view_only request.method 'GET' and acl.action_allowed request 'ReviewerTools' 'View' if reviewer_perm or moderator_perm or view_only return f request *args **kw else raise PermissionDeniedreturn wrapperif callable region return decorator region else return decorator
def _auth profile None if profile credentials __salt__['config.option'] profile user credentials['keystone.user']password credentials['keystone.password']tenant credentials['keystone.tenant']auth_url credentials['keystone.auth_url']region_name credentials.get 'keystone.region_name' None service_type credentials['keystone.service_type']else user __salt__['config.option'] 'keystone.user' password __salt__['config.option'] 'keystone.password' tenant __salt__['config.option'] 'keystone.tenant' auth_url __salt__['config.option'] 'keystone.auth_url' region_name __salt__['config.option'] 'keystone.region_name' service_type __salt__['config.option'] 'keystone.service_type' kwargs {'username' user 'password' password 'tenant_name' tenant 'auth_url' auth_url 'region_name' region_name 'service_type' service_type}return suoneu.SaltNeutron **kwargs
def _make_ctx_options ctx_options config_cls ContextOptions if not ctx_options return Nonefor key in list ctx_options translation _OPTION_TRANSLATIONS.get key if translation if translation in ctx_options raise ValueError 'Cannotspecify%sand%satthesametime' % key translation ctx_options[translation] ctx_options.pop key return config_cls **ctx_options
def load_helpers if jingo._helpers_loaded returnjingo._helpers_loaded Truefrom jingo import helpersfor app in settings.INSTALLED_APPS try app_path import_module app .__path__except AttributeError continuetry imp.find_module 'helpers' app_path except ImportError continueimport_module '%s.helpers' % app
def random_identity_search gate_list numgates nqubits gate_size len gate_list circuit for i in range numgates next_gate gate_list[randint 0 gate_size - 1 ]circuit circuit + next_gate is_scalar is_scalar_matrix circuit nqubits False return circuit if is_scalar else None
def client_class_for_service service return _client_classes.get service
def has_win32com if not sys.platform.startswith 'win32' return Falsetry mod __import__ 'win32com' except ImportError return Falsereturn True
def closest_station lat lon cache_dir if lat is None or lon is None or not os.path.isdir cache_dir returnstations bom_stations cache_dir def comparable_dist wmo_id 'Afastkeyfunctionforpsudeo-distancefromlat/lon.' station_lat station_lon stations[wmo_id]return lat - station_lat ** 2 + lon - station_lon ** 2 return min stations key comparable_dist
def require_admin_context f def wrapper *args **kwargs nova.context.require_admin_context args[0] return f *args **kwargs return wrapper
def optionsForClientTLS hostname trustRoot None clientCertificate None acceptableProtocols None **kw extraCertificateOptions kw.pop 'extraCertificateOptions' None or {} if trustRoot is None trustRoot platformTrust if kw raise TypeError "optionsForClientTLS gotanunexpectedkeywordargument'{arg}'".format arg kw.popitem [0] if not isinstance hostname unicode raise TypeError 'optionsForClientTLSrequirestextforhostnames not' + hostname.__class__.__name__ if clientCertificate extraCertificateOptions.update privateKey clientCertificate.privateKey.original certificate clientCertificate.original certificateOptions OpenSSLCertificateOptions trustRoot trustRoot acceptableProtocols acceptableProtocols **extraCertificateOptions return ClientTLSOptions hostname certificateOptions.getContext
def user_generate_apikey context data_dict model context['model']user context['user']session context['session']schema context.get 'schema' or schema_.default_generate_apikey_user_schema context['schema'] schemaid _get_or_bust data_dict 'id' user_obj model.User.get id context['user_obj'] user_objif user_obj is None raise NotFound 'Userwasnotfound.' _check_access 'user_generate_apikey' context data_dict old_data _get_action 'user_show' context data_dict old_data['apikey'] model.types.make_uuid data_dict old_datareturn _get_action 'user_update' context data_dict
def get_fc_wwnns hbas get_fc_hbas wwnns []if hbas for hba in hbas if hba['port_state'] 'Online' wwnn hba['node_name'].replace '0x' '' wwnns.append wwnn return wwnns
def show_delvol_on_destroy name kwargs None call None if call ! 'action' raise SaltCloudSystemExit 'Theshow_delvol_on_destroyactionmustbecalledwith-aor--action.' if not kwargs kwargs {}instance_id kwargs.get 'instance_id' None device kwargs.get 'device' None volume_id kwargs.get 'volume_id' None if instance_id is None instance_id _get_node name ['instanceId']params {'Action' 'DescribeInstances' 'InstanceId.1' instance_id}data aws.query params location get_location provider get_provider opts __opts__ sigver '4' blockmap data[0]['instancesSet']['item']['blockDeviceMapping']if not isinstance blockmap['item'] list blockmap['item'] [blockmap['item']]items []for idx item in enumerate blockmap['item'] device_name item['deviceName']if device is not None and device ! device_name continueif volume_id is not None and volume_id ! item['ebs']['volumeId'] continueinfo {'device_name' device_name 'volume_id' item['ebs']['volumeId'] 'deleteOnTermination' item['ebs']['deleteOnTermination']}items.append info return items
def set bot update args job_queue chat_data chat_id update.message.chat_idtry due int args[0] if due < 0 update.message.reply_text 'Sorrywecannotgobacktofuture!' returnjob Job alarm due repeat False context chat_id chat_data['job'] jobjob_queue.put job update.message.reply_text 'Timersuccessfullyset!' except IndexError ValueError update.message.reply_text 'Usage /set<seconds>'
def p_relational_expression_1 t pass
def _get_allow_bytes_flag import doctestreturn doctest.register_optionflag 'ALLOW_BYTES'
def rot32 w nLeft nLeft & 31if nLeft 0 return wRRR w >> 1 & 2147483647 >> 31 - nLeft sLLLLLL - 1 << 31 - nLeft & w | 2147483647 >> nLeft & w return RRR | sLLLLLL << nLeft
def multicall conf context topic msg timeout None check_serialize msg method msg.get 'method' if not method returnargs msg.get 'args' {} version msg.get 'version' None namespace msg.get 'namespace' None try consumer CONSUMERS[topic][0]except KeyError IndexError return iter [None] else return consumer.call context version method namespace args timeout
def treeWalk moduleList dirname fnames dirname dirname.replace '\\' '.' .replace '/' '.' if dirname.startswith 'Cura.gui' returnif dirname 'Cura.util.pymclevel' returnif dirname 'Cura.util.Power' returnif dirname 'Cura.plugins' returnif dirname 'Cura.resouces' returnfor moduleName in filter lambda f f.endswith '.py' fnames moduleName moduleName[ -3 ]if moduleName '__init__' continuefullName '%s.%s' % dirname moduleName try module __import__ fullName fromlist ['Cura'] level 1 moduleList.append module except print 'Failedtoload %s' % fullName
def mysql_timestamp_converter s if s[4] '-' return DateTime_or_None s s s + '0' * 14 - len s parts map int filter None s[ 4] s[4 6] s[6 8] s[8 10] s[10 12] s[12 14] try return Timestamp *parts except SystemExit KeyboardInterrupt raiseexcept return None
def irfft x n None axis -1 overwrite_x False tmp _asfarray x if not numpy.isrealobj tmp raise TypeError '1stargumentmustberealsequence' try work_function _DTYPE_TO_RFFT[tmp.dtype]except KeyError raise ValueError 'type%sisnotsupported' % tmp.dtype overwrite_x overwrite_x or _datacopied tmp x return _raw_fft tmp n axis -1 overwrite_x work_function
def dist_point_to_segment p s0 s1 p np.asarray p float s0 np.asarray s0 float s1 np.asarray s1 float v s1 - s0 w p - s0 c1 np.dot w v if c1 < 0 return dist p s0 c2 np.dot v v if c2 < c1 return dist p s1 b c1 / c2 pb s0 + b * v return dist p pb
def lastColorizedLine source if not isinstance source bytes source source.encode 'utf-8' w VT102Writer p TokenPrinter w.write .printtokens BytesIO source for token in _tokenize s.readline tokenType string start end line tokenp tokenType string start end line line str w .encode 'utf-8' return line
def environmentfunction f f.environmentfunction Truereturn f
def set_cxxflags value return set_var 'CXXFLAGS' value
def idd_reconint idx proj return _id.idd_reconint idx proj
def streaming_bulk client actions chunk_size 500 max_chunk_bytes 100 * 1024 * 1024 raise_on_error True expand_action_callback expand_action raise_on_exception True **kwargs actions map expand_action_callback actions for bulk_actions in _chunk_actions actions chunk_size max_chunk_bytes client.transport.serializer for result in _process_bulk_chunk client bulk_actions raise_on_exception raise_on_error **kwargs yield result
def get_job_config name None if not name raise SaltInvocationError 'Requiredparameter`name`ismissing.' server _connect if not job_exists name raise SaltInvocationError 'Job`{0}`doesnotexists.'.format name job_info server.get_job_config name return job_info
@keyword tags ['one' 2] def library_keyword_tags_with_documentation_and_attribute pass
@given u'Iusethecurrentdirectoryasworkingdirectory' def step_use_curdir_as_working_directory context context.workdir os.path.abspath '.' command_util.ensure_workdir_exists context
def parse_system_map data module sys_map {}sys_map[module] {}mem_model Nonearch 'x86'for line in data.splitlines str_addr symbol_type symbol line.strip .split try sym_addr long str_addr 16 except ValueError continueif symbol 'arm_syscall' arch 'ARM'if not symbol in sys_map[module] sys_map[module][symbol] []sys_map[module][symbol].append [sym_addr symbol_type] mem_model str len str_addr * 4 + 'bit' if mem_model '64bit' and arch 'x86' arch 'x64'return arch mem_model sys_map
def move_disks session instance disk_info imported_vhds session.call_plugin_serialized 'migration' 'move_vhds_into_sr' instance_uuid instance['uuid'] sr_path get_sr_path session uuid_stack _make_uuid_stack scan_default_sr session root_uuid imported_vhds['root']['uuid']set_vdi_name session root_uuid instance['name'] 'root' root_vdi_ref session.call_xenapi 'VDI.get_by_uuid' root_uuid return {'uuid' root_uuid 'ref' root_vdi_ref}
def clf gcf .clf draw_if_interactive
def retry_if_session_inactive context_var_name 'context' def decorator f try ctx_arg_index p_util.getargspec f .args.index context_var_name except ValueError raise RuntimeError _LE 'Couldnotfindpositionofvar%s' % context_var_name f_with_retry retry_db_errors f @six.wraps f def wrapped *args **kwargs if context_var_name in kwargs context kwargs[context_var_name]else context args[ctx_arg_index]method f if context.session.is_active else f_with_retry return method *args **kwargs return wrappedreturn decorator
def ensure_headings_linkable soups for soup in soups.values existing_anchors find_existing_anchors soup count 100for tag in soup.find_all _heading_re if not tag.has_attr u'id' or tag.has_attr u'name' snippet u''.join [c for c in tag.text if c.isalpha ] [ 20]while True count + 1candidate_id u'heading_{0}_{1}'.format snippet count .lower if not candidate_id in existing_anchors existing_anchors.add candidate_id tag[u'id'] candidate_idbreak
def getTextIfEmpty fileName text if text ! '' return textreturn getFileText fileName
def enforce_nice_config _convert_all_package_confs_to_dir _order_all_package_confs
def _get_children_text parent tag construct unicode return [construct child.text for child in parent.findall _ns tag if child.text]
@loader_option def contains_eager loadopt attr alias None if alias is not None if not isinstance alias str info inspect alias alias info.selectablecloned loadopt.set_relationship_strategy attr {'lazy' 'joined'} propagate_to_loaders False cloned.local_opts['eager_from_alias'] aliasreturn cloned
def _get_index_videos course return list {attr video[attr] for attr in ['edx_video_id' 'client_video_id' 'created' 'duration' 'status']} for video in _get_videos course
def config_true_value value return value is True or isinstance value basestring and value.lower in TRUE_VALUES
@then u'weseedataselected' def step_see_data_selected context _expect_exact context u'yyy' timeout 1 _expect_exact context u'SELECT1' timeout 1
def _pad_binary bin_str req_len 8 bin_str bin_str[2 ]return max 0 req_len - len bin_str * '0' + bin_str
def libvlc_media_list_retain p_ml f _Cfunctions.get 'libvlc_media_list_retain' None or _Cfunction 'libvlc_media_list_retain' 1 None None MediaList return f p_ml
def process_chain callbacks input *a **kw d defer.Deferred for x in callbacks d.addCallback x *a **kw d.callback input return d
def update_first_contribution_msec_if_not_set user_id first_contribution_msec user_settings get_user_settings user_id strict True if user_settings.first_contribution_msec is None _update_first_contribution_msec user_id first_contribution_msec
def register_auth_backend backend_cls warn u'reviewboard.accounts.backends.register_auth_backend isdeprecated.Usereviewboard.accounts.backends.auth_backends.register instead.' DeprecationWarning auth_backends.register backend_cls
def test_probably_html for table in 't/html.html' 'http //blah.com/table.html' 'https //blah.com/table.html' 'file //blah/table.htm' 'ftp //blah.com/table.html' 'file //blah.com/table.htm' '<!doctypehtml>helloworld' 'junk<tablebaz><trfoo><tdbar></td></tr></table>junk' ['junk<tablebaz>' '<trfoo>' '<tdbar>' '</td></tr>' '</table>junk'] '<!doctypehtml>' 'helloworld' assert _probably_html table is True for table in 't/html.htms' 'Xhttp //blah.com/table.html' 'https //blah.com/table.htm' 'fole //blah/table.htm' '<doctypehtml>helloworld' 'junk<tblebaz><trfoo><tdbar></td></tr></table>junk' ['junk<tablebaz>' '<tfoo>' '<tdbar>' '</td></tr>' '</table>junk'] '<!doctypehtm>' 'helloworld' [[1 2 3]] assert _probably_html table is False
def test_list_freeze script data script.pip 'install' '-f' data.find_links '--no-index' 'simple 1.0' 'simple2 3.0' result script.pip 'list' '--format freeze' assert 'simple 1.0' in result.stdout str result assert 'simple2 3.0' in result.stdout str result
@click.command u'export-doc' @click.argument u'doctype' @click.argument u'docname' @pass_contextdef export_doc context doctype docname import frappe.modulesfor site in context.sites try frappe.init site site frappe.connect frappe.modules.export_doc doctype docname finally frappe.destroy
def get_size start_path total_size 0for dirpath __ filenames in os.walk start_path for f in filenames fp os.path.join dirpath f total_size + os.path.getsize fp return total_size
def gcd *a if len a > 1 return reduce gcd2 a if hasattr a[0] '__iter__' return reduce gcd2 a[0] return a[0]
def applyRedirects manifest redirects for binding in redirects for dep in manifest.dependentAssemblies if match_binding_redirect dep binding logger.info 'Redirecting%sversion%s->%s' binding.name dep.version binding.newVersion dep.version binding.newVersion
def cc_test_config append None **kwargs heap_check kwargs.get 'heap_check' if heap_check is not None and heap_check not in HEAP_CHECK_VALUES console.error_exit 'cc_test_config heap_checkcanonlybein%s' % HEAP_CHECK_VALUES blade_config.update_config 'cc_test_config' append kwargs
def pixel_coords latlon ground_width 0 mt None topleft None width None lat lon latlon[0] latlon[1] return mt.coord_to_pixel topleft[0] topleft[1] width ground_width lat lon
def leastsquare measured_vals updated_model weights x y None if y is None model_vals updated_model x else model_vals updated_model x y if weights is None return np.sum model_vals - measured_vals ** 2 else return np.sum weights * model_vals - measured_vals ** 2
def notify notificationName message if sabnzbd.FOUNDATION pool Foundation.NSAutoreleasePool.alloc .init nc Foundation.NSDistributedNotificationCenter.defaultCenter nc.postNotificationName_object_ notificationName message del pool
def build_plugin_tree plugins cache dict p.pk p for p in plugins by_parent_id attrgetter 'parent_id' nonroots sorted filter by_parent_id cache.values key attrgetter 'parent_id' 'position' families cache[parent_id] tuple children for parent_id children in groupby nonroots by_parent_id for parent children in families parent.child_plugin_instances childrenreturn sorted filterfalse by_parent_id cache.values key attrgetter 'position'
def _parse_pre_yarn_history_records lines def yield_record_strings lines record_lines []start_line 0for line_num line in enumerate lines record_lines.append line if line.endswith '.\n' yield start_line len record_lines ''.join record_lines record_lines []start_line line_num + 1 for start_line num_lines record_str in yield_record_strings lines record_match _PRE_YARN_HISTORY_RECORD.match record_str if not record_match continuerecord_type record_match.group 'type' key_pairs record_match.group 'key_pairs' fields {}for m in _PRE_YARN_HISTORY_KEY_PAIR.finditer key_pairs key m.group 'key' value _pre_yarn_history_unescape m.group 'escaped_value' fields[key] value yield dict fields fields num_lines num_lines start_line start_line type record_type
def _check_package pkg_xml zipfilename zf uid os.path.splitext os.path.split zipfilename [1] [0]if pkg_xml.get u'id' ! uid raise ValueError u'packageidentifiermismatch %svs%s ' % pkg_xml.get u'id' uid if sum name ! uid and not name.startswith uid + u'/' for name in zf.namelist raise ValueError u'Zipfile%s.zipdoesnotexpandtoasinglesubdirectory%s/' % uid uid
def dict_with base_dict **kwargs full_dict dict base_dict full_dict.update **kwargs return full_dict
@pytest.mark.parametrize 'api_version' API_VERSIONS def test_thread_label_updates db api_client default_account api_version custom_label headers dict headers['Api-Version'] api_versiongmail_thread add_fake_thread db.session default_account.namespace.id gmail_message add_fake_message db.session default_account.namespace.id gmail_thread resp_data api_client.get_data '/threads/{}'.format gmail_thread.public_id headers headers assert resp_data['labels'] [] category custom_label.categoryupdate dict labels [category.public_id] resp api_client.put_data '/threads/{}'.format gmail_thread.public_id update headers headers resp_data json.loads resp.data if api_version API_VERSIONS[0] assert len resp_data['labels'] 1 assert resp_data['labels'][0]['id'] category.public_id resp_data api_client.get_data '/messages/{}'.format gmail_message.public_id headers headers assert len resp_data['labels'] 1 assert resp_data['labels'][0]['id'] category.public_id else assert resp_data['labels'] []
def absent dest username check_mode if StrictVersion passlib.__version__ > StrictVersion '1.6' ht HtpasswdFile dest new False else ht HtpasswdFile dest if username not in ht.users return '%snotpresent' % username False else if not check_mode ht.delete username ht.save return 'Remove%s' % username True
def boxplot_runtimes runtimes pred_type configuration fig ax1 plt.subplots figsize 10 6 bp plt.boxplot runtimes cls_infos [ '%s\n %d%s ' % estimator_conf['name'] estimator_conf['complexity_computer'] estimator_conf['instance'] estimator_conf['complexity_label'] for estimator_conf in configuration['estimators']]plt.setp ax1 xticklabels cls_infos plt.setp bp['boxes'] color 'black' plt.setp bp['whiskers'] color 'black' plt.setp bp['fliers'] color 'red' marker '+' ax1.yaxis.grid True linestyle '-' which 'major' color 'lightgrey' alpha 0.5 ax1.set_axisbelow True ax1.set_title 'PredictionTimeperInstance-%s %dfeats.' % pred_type.capitalize configuration['n_features'] ax1.set_ylabel 'PredictionTime us ' plt.show
def create_bookmark user usage_key usage_key usage_key.replace course_key modulestore .fill_in_run usage_key.course_key data {'user' user 'usage_key' usage_key}if usage_key.course_key.run is None raise ItemNotFoundErrorif not can_create_more data raise BookmarksLimitReachedError bookmark created Bookmark.create data if created _track_event 'edx.bookmark.added' bookmark return BookmarkSerializer bookmark context {'fields' DEFAULT_FIELDS + OPTIONAL_FIELDS } .data
def refresh_db if 'eix.sync' in __salt__ return __salt__['eix.sync'] if 'makeconf.features_contains' in __salt__ and __salt__['makeconf.features_contains'] 'webrsync-gpg' cmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0 else if __salt__['cmd.retcode'] 'emerge--askn--quiet--sync' python_shell False 0 return Truecmd 'emerge-webrsync-q'if salt.utils.which 'emerge-delta-webrsync' cmd 'emerge-delta-webrsync-q'return __salt__['cmd.retcode'] cmd python_shell False 0
def sha1b64 *data return _hash hashlib.sha1 data .digest .encode 'base64'
def test_extract_reassemble rng np.random.RandomState [1 3 7] topo rng.randn 4 3 * 5 3 * 7 2 dataset DenseDesignMatrix topo_view topo patch_shape 3 7 extractor ExtractGridPatches patch_shape patch_shape reassemblor ReassembleGridPatches patch_shape patch_shape orig_shape topo.shape[1 3] dataset.apply_preprocessor extractor dataset.apply_preprocessor reassemblor new_topo dataset.get_topological_view assert new_topo.shape topo.shape if not np.all new_topo topo assert False
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq.id if result done + 1return len orphaned_build_requests done
def column_width text if isinstance text str and sys.version_info < 3 0 return len text try width sum [east_asian_widths[unicodedata.east_asian_width c ] for c in text] except AttributeError width len text width - len find_combining_chars text return width
def change_value global _GROWL_REG_GROWL_REG False
def salt_extend extension name description salt_dir merge import salt.utils.extendsalt.utils.extend.run extension extension name name description description salt_dir salt_dir merge merge
def GetFeedItems client feed feed_item_service client.GetService 'FeedItemService' 'v201605' feed_items []more_pages Trueselector {'fields' ['FeedItemId' 'AttributeValues' 'Scheduling'] 'predicates' [{'field' 'Status' 'operator' 'EQUALS' 'values' ['ENABLED']} {'field' 'FeedId' 'operator' 'EQUALS' 'values' [feed['id']]}] 'paging' {'startIndex' 0 'numberResults' PAGE_SIZE}}while more_pages page feed_item_service.get selector if 'entries' in page feed_items.extend page['entries'] selector['paging']['startIndex'] + PAGE_SIZEmore_pages selector['paging']['startIndex'] < int page['totalNumEntries'] return feed_items
def get_freq_code freqstr if isinstance freqstr DateOffset freqstr freqstr.rule_code freqstr.n if isinstance freqstr tuple if is_integer freqstr[0] and is_integer freqstr[1] return freqstrelse try code _period_str_to_code freqstr[0] stride freqstr[1]except if is_integer freqstr[1] raisecode _period_str_to_code freqstr[1] stride freqstr[0]return code stride if is_integer freqstr return freqstr 1 base stride _base_and_stride freqstr code _period_str_to_code base return code stride
def get_nipype_gitversion import osimport subprocesstry import nipypegitpath os.path.realpath os.path.join os.path.dirname nipype.__file__ os.path.pardir except gitpath os.getcwd gitpathgit os.path.join gitpath u'.git' if not os.path.exists gitpathgit return Nonever Nonetry o _ subprocess.Popen u'gitdescribe' shell True cwd gitpath stdout subprocess.PIPE .communicate except Exception passelse ver o.decode .strip .split u'-' [ -1 ]return ver
def insertGridPointPair gridPoint gridPointInsetX gridPoints isJunctionWide paths pixelTable yIntersectionPath width linePath getNonIntersectingGridPointLine gridPointInsetX isJunctionWide paths pixelTable yIntersectionPath width insertGridPointPairWithLinePath gridPoint gridPointInsetX gridPoints isJunctionWide linePath paths pixelTable yIntersectionPath width
def _sum_costs costs source def plus pi1 pi2 assert pi1.quantity pi2.quantity return PriceInfo pi1.price + pi2.price pi1.base_price + pi2.base_price quantity pi1.quantity zero_price source.create_price 0 zero_pi PriceInfo zero_price zero_price quantity 1 return functools.reduce plus x.price_info for x in costs zero_pi
def collapseNestedLists items pieces []for i in items if i is None pieces.extend ['' 'NIL'] elif isinstance i DontQuoteMe int long pieces.extend ['' networkString str i ] elif isinstance i bytes unicode if _needsLiteral i pieces.extend ['' '{' intToBytes len i '}' IMAP4Server.delimiter i] else pieces.extend ['' _quote i ] elif hasattr i 'read' d i.read pieces.extend ['' '{' intToBytes len d '}' IMAP4Server.delimiter d] else pieces.extend ['' ' ' + collapseNestedLists i + ' ' ] return ''.join pieces[1 ]
def callConfirmed RepeatIndicator_presence 0 BearerCapability_presence 0 BearerCapability_presence1 0 Cause_presence 0 CallControlCapabilities_presence 0 a TpPd pd 3 b MessageType mesType 8 packet a / b if RepeatIndicator_presence is 1 c RepeatIndicatorHdr ieiRI 13 eightBitRI 0 packet packet / c if BearerCapability_presence is 1 d BearerCapabilityHdr ieiBC 4 eightBitBC 0 packet packet / d if BearerCapability_presence1 is 1 e BearerCapabilityHdr ieiBC 4 eightBitBC 0 packet packet / e if Cause_presence is 1 f CauseHdr ieiC 8 eightBitC 0 packet packet / f if CallControlCapabilities_presence is 1 g CallControlCapabilitiesHdr ieiCCC 21 eightBitCCC 0 packet packet / g return packet
def is_valid_xml_char_ordinal i return 32 < i < 55295 or i in 9 10 13 or 57344 < i < 65533 or 65536 < i < 1114111
def configured_request_log_handlers config prefix 'query_log' default_logger None handlers []for section in config.sections if section.startswith prefix options dict config.items section type_ options.pop 'type' if type_ 'default' logger default_logger or get_logger handler ext.request_log_handler 'default' logger else handler ext.request_log_handler type_ **options handlers.append handler return handlers
def test_dimensionless_to_cgs testunit 1.0 * u.m / 1.0 * u.km assert testunit.unit.physical_type u'dimensionless' assert_allclose testunit.cgs 0.001
def _ipVersionToLen version if version 4 return 32elif version 6 return 128else raise ValueError 'onlyIPv4andIPv6supported'
def package_files generated_json_dir docs_build_dir static_json_dir tag 'master' package_path os.path.join docs_build_dir 'json_build' shutil.rmtree package_path ignore_errors True shutil.copytree static_json_dir package_path shutil.copytree os.path.join generated_json_dir 'google' 'cloud' os.path.join package_path 'json' tag 'google' 'cloud' shutil.copyfile os.path.join generated_json_dir 'types.json' os.path.join package_path 'json' tag 'types.json'
def volume_absent name provider None **kwargs ret _check_name name if not ret['result'] return retvolumes __salt__['cloud.volume_list'] provider provider if name not in volumes ret['comment'] 'Volumeisabsent.'ret['result'] Truereturn retelif __opts__['test'] ret['comment'] 'Volume{0}willbedeleted.'.format name ret['result'] Nonereturn retresponse __salt__['cloud.volume_delete'] names name provider provider **kwargs if response ret['result'] Trueret['comment'] 'Volume{0}wasdeleted'.format name ret['changes'] {'old' volumes[name] 'new' response}else ret['result'] Falseret['comment'] 'Volume{0}failedtodelete.'.format name return ret
def squared_error a b a b align_targets a b return theano.tensor.square a - b
def duplicates_indices fields dup ind get_duplicates fields defaultdict list for i v in enumerate fields if v in dup ind[v].append i return ind
def register_filter f if not issubclass f Filter raise ValueError "Mustbeasubclassof'Filter'" if not f.name raise ValueError 'Musthaveaname' if f.name in _FILTERS raise KeyError 'Filterwithname%salreadyregistered' % f.name _FILTERS[f.name] f
def register_json from anyjson import loads as json_loads dumps as json_dumpsdef _loads obj if isinstance obj bytes_t obj obj.decode return json_loads obj registry.register 'json' json_dumps _loads content_type 'application/json' content_encoding 'utf-8'
def _minimize_trust_ncg fun x0 args jac None hess None hessp None **trust_region_options if jac is None raise ValueError 'JacobianisrequiredforNewton-CGtrust-regionminimization' if hess is None and hessp is None raise ValueError 'EithertheHessianortheHessian-vectorproductisrequiredforNewton-CGtrust-regionminimization' return _minimize_trust_region fun x0 args args jac jac hess hess hessp hessp subproblem CGSteihaugSubproblem **trust_region_options
def _get_coeff_exp expr x from sympy import powsimp c m expand_power_base powsimp expr .as_coeff_mul x if not m return c S 0 [m] mif m.is_Pow if m.base ! x raise _CoeffExpValueError 'exprnotofforma*x**b' return c m.exp elif m x return c S 1 else raise _CoeffExpValueError 'exprnotofforma*x**b %s' % expr
def _copy_future_state source dest assert source.done if dest.cancelled returnassert not dest.done if source.cancelled dest.cancel else exception source.exception if exception is not None dest.set_exception exception else result source.result dest.set_result result
def getNewDerivation elementNode return GridDerivation elementNode
def get_god_player try god_player PlayerDB.objects.get id 1 except PlayerDB.DoesNotExist raise PlayerDB.DoesNotExist ERROR_NO_SUPERUSER return god_player
def load_extra_emacs_page_navigation_bindings registry ConditionalRegistry Registry EmacsMode handle registry.add_bindinghandle Keys.ControlV scroll_page_down handle Keys.PageDown scroll_page_down handle Keys.Escape u'v' scroll_page_up handle Keys.PageUp scroll_page_up return registry
def MakeSuiteFromHist hist label None if label is None label hist.labeld dict hist.GetDict return MakeSuiteFromDict d label
def figsize sizex sizey import matplotlibmatplotlib.rcParams['figure.figsize'] [sizex sizey]
def _vector x type 'row' if isinstance x list tuple x np.array x dtype np.float32 elif not isinstance x np.ndarray x np.array [x] dtype np.float32 assert x.ndim 1 if type 'column' x x[ None]return x
def get_loader module_or_name if module_or_name in sys.modules module_or_name sys.modules[module_or_name]if isinstance module_or_name ModuleType module module_or_nameloader getattr module '__loader__' None if loader is not None return loaderfullname module.__name__else fullname module_or_namereturn find_loader fullname
def show_episodes series start None stop None count False descending False session None episodes session.query Episode .filter Episode.series_id series.id if count return episodes.count if series.identified_by u'sequence' episodes episodes.order_by Episode.number.desc if descending else episodes.order_by Episode.number elif series.identified_by u'ep' episodes episodes.order_by Episode.season.desc Episode.number.desc if descending else episodes.order_by Episode.season Episode.number else episodes episodes.order_by Episode.identifier.desc if descending else episodes.order_by Episode.identifier return episodes.slice start stop .from_self .all
def setwinsize fd rows_cols rows cols rows_colsTIOCSWINSZ getattr termios 'TIOCSWINSZ' -2146929561 s struct.pack 'HHHH' rows cols 0 0 fcntl.ioctl fd TIOCSWINSZ s
def install_js target_jsdir join SERVER 'static' 'js' target_cssdir join SERVER 'static' 'css' STATIC_ASSETS [join JS 'bokeh.js' join JS 'bokeh.min.js' join CSS 'bokeh.css' join CSS 'bokeh.min.css' ]if not all [exists a for a in STATIC_ASSETS] print BOKEHJS_INSTALL_FAIL sys.exit 1 if exists target_jsdir shutil.rmtree target_jsdir shutil.copytree JS target_jsdir if exists target_cssdir shutil.rmtree target_cssdir shutil.copytree CSS target_cssdir
def foobar_explosion radius def get_55 '\nAfunctionthatreturns55.\n'return 55return get_55 * radius
def isiterable obj return hasattr obj '__iter__'
def test_array_precession j2000 Time u'J2000' scale u'utc' j1975 Time u'J1975' scale u'utc' fk5 FK5 [1 1.1] * u.radian [0.5 0.6] * u.radian assert fk5.equinox.jyear j2000.jyear fk5_2 fk5.transform_to FK5 equinox j1975 assert fk5_2.equinox.jyear j1975.jyear npt.assert_array_less 0.05 np.abs fk5.ra.degree - fk5_2.ra.degree npt.assert_array_less 0.05 np.abs fk5.dec.degree - fk5_2.dec.degree
def _get_dt_and_tzinfo dt_or_tzinfo if dt_or_tzinfo is None dt datetime.now tzinfo LOCALTZelif isinstance dt_or_tzinfo string_types dt Nonetzinfo get_timezone dt_or_tzinfo elif isinstance dt_or_tzinfo integer_types dt Nonetzinfo UTCelif isinstance dt_or_tzinfo datetime time dt _get_datetime dt_or_tzinfo if dt.tzinfo is not None tzinfo dt.tzinfoelse tzinfo UTCelse dt Nonetzinfo dt_or_tzinforeturn dt tzinfo
def CheckHeaderFileIncluded filename include_state error fileinfo FileInfo filename if Search _TEST_FILE_SUFFIX fileinfo.BaseName returnfor ext in GetHeaderExtensions basefilename filename[0 len filename - len fileinfo.Extension ]headerfile basefilename + '.' + ext if not os.path.exists headerfile continueheadername FileInfo headerfile .RepositoryName first_include Nonefor section_list in include_state.include_list for f in section_list if headername in f[0] or f[0] in headername returnif not first_include first_include f[1]error filename first_include 'build/include' 5 '%sshouldincludeitsheaderfile%s' % fileinfo.RepositoryName headername
def admin_media_prefix try from django.conf import settingsexcept ImportError return ''return iri_to_uri settings.ADMIN_MEDIA_PREFIX
def versions_from_parentdir parentdir_prefix root verbose dirname os.path.basename root if not dirname.startswith parentdir_prefix if verbose print "guessingrootdiris'%s' but'%s'doesn'tstartwithprefix'%s'" % root dirname parentdir_prefix raise NotThisMethod "rootdirdoesn'tstartwithparentdir_prefix" return {'version' dirname[len parentdir_prefix ] 'full-revisionid' None 'dirty' False 'error' None}
def create_jail name arch version '9.0-RELEASE' _check_config_exists if is_jail name return '{0}alreadyexists'.format name cmd 'poudrierejails-c-j{0}-v{1}-a{2}'.format name version arch __salt__['cmd.run'] cmd make_pkgng_aware name if is_jail name return 'Createdjail{0}'.format name return 'Issuecreatingjail{0}'.format name
def item_from_env env item_name item env.get item_name None if item is None logging.error 'ERROR %scouldnotbefoundinenv!' % item_name return item
def rm_app id response salt.utils.http.query '{0}/v2/apps/{1}'.format _base_url id method 'DELETE' decode_type 'json' decode True return response['dict']
def ensure_vlan_bridge session vif cluster None create_vlan True vlan_num vif['network'].get_meta 'vlan' bridge vif['network']['bridge']vlan_interface CONF.vmware.vlan_interfacenetwork_ref network_util.get_network_with_the_name session bridge cluster if network_ref and network_ref['type'] 'DistributedVirtualPortgroup' return network_refif not network_ref vswitch_associated _get_associated_vswitch_for_interface session vlan_interface cluster network_util.create_port_group session bridge vswitch_associated vlan_num if create_vlan else 0 cluster network_ref network_util.get_network_with_the_name session bridge cluster elif create_vlan vswitch_associated _get_associated_vswitch_for_interface session vlan_interface cluster _get_pg_info network_util.get_vlanid_and_vswitch_for_portgroup pg_vlanid pg_vswitch _get_pg_info session bridge cluster if pg_vswitch ! vswitch_associated raise exception.InvalidVLANPortGroup bridge bridge expected vswitch_associated actual pg_vswitch if pg_vlanid ! vlan_num raise exception.InvalidVLANTag bridge bridge tag vlan_num pgroup pg_vlanid return network_ref
def test_nm2_sample_wrong_X nm2 NearMiss random_state RND_SEED version VERSION_NEARMISS nm2.fit X Y assert_raises RuntimeError nm2.sample np.random.random 100 40 np.array [0] * 50 + [1] * 50
def gather_unique_dicts dict_iterable id_set set result []for obj in dict_iterable if obj['id'] not in id_set id_set.add obj['id'] result.append obj return result
def body_check octet return chr octet ! _QUOPRI_BODY_MAP[octet]
def get_connection service module None region None key None keyid None profile None module module or service svc_mod __import__ 'boto.' + module fromlist [module] cxkey region key keyid _get_profile service region key keyid profile cxkey cxkey + ' conn' if cxkey in __context__ return __context__[cxkey]try conn svc_mod.connect_to_region region aws_access_key_id keyid aws_secret_access_key key if conn is None raise SaltInvocationError 'Region"{0}"isnotvalid.'.format region except boto.exception.NoAuthHandlerFound raise SaltInvocationError 'Noauthenticationcredentialsfoundwhenattemptingtomakeboto{0}connectiontoregion"{1}".'.format service region __context__[cxkey] connreturn conn
def replace_line existing_line new_line try f open '/etc/locale.gen' 'r' lines [line.replace existing_line new_line for line in f]finally f.close try f open '/etc/locale.gen' 'w' f.write ''.join lines finally f.close
def cleanPolyline elem options pts parseListOfPoints elem.getAttribute 'points' elem.setAttribute 'points' scourCoordinates pts options True
def _scrub_uri uri if '/api/authorizations/cookie/' in uri or '/api/authorizations/token/' in uri uri uri.rsplit '/' 1 [0] + '/[secret]' return uri
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def configured_reply self try msg self.msgList.get timeout 1 except Queue.Empty passelse if msg['FromUserName'] self.storageClass.userName actualOpposite msg['ToUserName']else actualOpposite msg['FromUserName']if '@@' in actualOpposite replyFn self.functionDict['GroupChat'].get msg['Type'] elif self.search_mps userName msg['FromUserName'] replyFn self.functionDict['MpChat'].get msg['Type'] elif '@' in actualOpposite or actualOpposite in 'filehelper' 'fmessage' replyFn self.functionDict['FriendChat'].get msg['Type'] else replyFn self.functionDict['MpChat'].get msg['Type'] if replyFn is None r Noneelse try r replyFn msg if r is not None self.send r msg.get 'FromUserName' except logger.warning 'Anerroroccurredinregisteredfunction use`itchat.run debug True `toshowdetailedinformation' logger.debug traceback.format_exc
def color_to_reportlab color if isinstance color colors.Color return colorelif isinstance color str if color.startswith '0x' color.replace '0x' '#' if len color 7 return colors.HexColor color else try return colors.HexColor color hasAlpha True except TypeError raise RuntimeError 'Yourreportlabseemstobetooold try2.7onwards' elif isinstance color tuple return colors.Color *color return color
def pseudo_input lines ilines iter lines def raw_in prompt try return next ilines except StopIteration return ''return raw_in
def cmd_list_available args opts for x in jsonrpc_call opts 'crawler/spiders' 'list' print x
def parse_simpleflake flake timestamp SIMPLEFLAKE_EPOCH + extract_bits flake SIMPLEFLAKE_TIMESTAMP_SHIFT SIMPLEFLAKE_TIMESTAMP_LENGTH / 1000.0 random extract_bits flake SIMPLEFLAKE_RANDOM_SHIFT SIMPLEFLAKE_RANDOM_LENGTH return simpleflake_struct timestamp random
def set_pootle_locale_from_settings if os.name 'nt' returnlang translation.to_locale settings.LANGUAGE_CODE try if lang 'tr' or lang.startswith 'tr_' raise ValueError 'Turkishlocalebrokenduetochangedmeaningoflower ' locale.setlocale locale.LC_ALL lang 'UTF-8' except logging.debug 'FailedtosetlocaletoPootledefault %s ;loadingsystemdefault' lang locale.setlocale locale.LC_ALL ''
def delete_rax_cdb args print "---CleaningCloudDatabasesmatching'%s'" % args.match_re for region in pyrax.identity.services.database.regions cdb pyrax.connect_to_cloud_databases region region for db in rax_list_iterator cdb if re.search args.match_re db.name prompt_and_delete db 'Deletematching%s?[y/n] ' % db args.assumeyes
def bool_from_str val if not val return Falsetry return True if int val else False except ValueError return val.lower 'true' or val.lower 'yes' or val.lower 'y'
def synchronized lock def wrapper func @functools.wraps func def inner *args **kwds lock.acquire try return func *args **kwds finally lock.release return innerreturn wrapper
def step_5b w if w.endswith 'll' and R2 w .endswith 'l' return w[ -1 ]return w
def _graph_is_connected graph if sparse.isspmatrix graph n_connected_components _ connected_components graph return n_connected_components 1 else return _graph_connected_component graph 0 .sum graph.shape[0]
def get_viewport m c_int * 4 glGetIntegerv GL_VIEWPORT m return m
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg 'volume' metavar '<volume>' help _ 'IDofthevolumetoattach.' @utils.arg 'device' metavar '<device>' default None nargs '?' help _ 'Nameofthedevicee.g./dev/vdb.Use"auto"forautoassign ifsupported .Libvirtdriverwillusedefaultdevicename.' def do_volume_attach cs args if args.device 'auto' args.device Nonevolume cs.volumes.create_server_volume _find_server cs args.server .id args.volume args.device _print_volume volume
def strips a b return rstrips lstrips a b b
def VariableExpression variable assert isinstance variable Variable u'%sisnotaVariable' % variable if is_indvar variable.name return IndividualVariableExpression variable elif is_funcvar variable.name return FunctionVariableExpression variable elif is_eventvar variable.name return EventVariableExpression variable else return ConstantExpression variable
def guess_kern_maxfilesperproc return int 0.8 * guess_kern_maxfiles
def from_7L7M lsb msb return lsb + msb << 7
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_tld_list response_xml salt.utils.namecheap.get_request salt.utils.namecheap.get_opts 'namecheap.domains.gettldlist' if response_xml is None return []tldresult response_xml.getElementsByTagName 'Tlds' [0]tlds []for e in tldresult.getElementsByTagName 'Tld' tld salt.utils.namecheap.atts_to_dict e tld['data'] e.firstChild.datacategories []subcategories e.getElementsByTagName 'Categories' [0]for c in subcategories.getElementsByTagName 'TldCategory' categories.append salt.utils.namecheap.atts_to_dict c tld['categories'] categoriestlds.append tld return tlds
def conv_transpose3d input weight bias None stride 1 padding 0 output_padding 0 groups 1 f ConvNd _triple stride _triple padding _triple 1 True _triple output_padding groups return f input weight bias if bias is not None else f input weight
def StringOutputStream data StringIO return OutputStream data
def int_list pages size if address_size 4 fmt '<L'else fmt '<Q'for page in pages curr 0while curr < 4096 and curr < size yield struct.unpack fmt page[curr curr + address_size ] [0] curr + address_size
def do_round value precision 0 method 'common' if not method in 'common' 'ceil' 'floor' raise FilterArgumentError 'methodmustbecommon ceilorfloor' if precision < 0 raise FilterArgumentError 'precisionmustbeapostiveintegerorzero.' if method 'common' return round value precision func getattr math method if precision return func value * 10 * precision / 10 * precision else return func value
def msle actual predicted return np.mean sle actual predicted
@pytest.mark.parametrize u'fromsys' u'tosys' u'fromcoo' u'tocoo' m31_params def test_m31_coord_transforms fromsys tosys fromcoo tocoo from_origin fromsys fromcoo[0] * u.deg fromcoo[1] * u.deg distance m31_dist from_pos SkyOffsetFrame 1 * u.deg 1 * u.deg origin from_origin to_origin tosys tocoo[0] * u.deg tocoo[1] * u.deg distance m31_dist to_astroframe SkyOffsetFrame origin to_origin target_pos from_pos.transform_to to_astroframe assert_allclose to_origin.separation target_pos np.hypot from_pos.lon from_pos.lat atol convert_precision roundtrip_pos target_pos.transform_to from_pos assert_allclose [roundtrip_pos.lon.wrap_at 180 * u.deg roundtrip_pos.lat] [ 1.0 * u.deg 1.0 * u.deg ] atol convert_precision
@Addon.on_changedef watch_status old_attr None new_attr None instance None sender None **kwargs if old_attr is None old_attr {}if new_attr is None new_attr {}new_status new_attr.get 'status' old_status old_attr.get 'status' latest_version instance.find_latest_version channel amo.RELEASE_CHANNEL_LISTED if new_status not in amo.VALID_ADDON_STATUSES or not new_status or not latest_version returnif old_status not in amo.UNREVIEWED_ADDON_STATUSES latest_version.reset_nomination_time elif latest_version.has_files inherit_nomination None latest_version
def proxy opts functions None returners None whitelist None ret LazyLoader _module_dirs opts 'proxy' opts tag 'proxy' pack {'__salt__' functions '__ret__' returners} ret.pack['__proxy__'] retreturn ret
def spsModelAnal x fs w N H t minSineDur maxnSines freqDevOffset freqDevSlope stocf tfreq tmag tphase SM.sineModelAnal x fs w N H t maxnSines minSineDur freqDevOffset freqDevSlope Ns 512xr UF.sineSubtraction x Ns H tfreq tmag tphase fs stocEnv STM.stochasticModelAnal xr H H * 2 stocf return tfreq tmag tphase stocEnv
def square_clustering G nodes None if nodes is None node_iter Gelse node_iter G.nbunch_iter nodes clustering {}for v in node_iter clustering[v] 0potential 0for u w in combinations G[v] 2 squares len set G[u] & set G[w] - set [v] clustering[v] + squaresdegm squares + 1 if w in G[u] degm + 1potential + len G[u] - degm * len G[w] - degm + squares if potential > 0 clustering[v] / potentialif nodes in G return clustering[nodes]return clustering
def get_gid path follow_symlinks True return stats os.path.expanduser path follow_symlinks follow_symlinks .get 'gid' -1
def set_implicit_options role_fn if not hasattr role_fn 'options' or role_fn.options is None role_fn.options {'class' directives.class_option}elif not role_fn.options.has_key 'class' role_fn.options['class'] directives.class_option
def test_epoch_monitor dim 1batch_size 3n_batches 10m n_batches * batch_size dataset ArangeDataset m model SoftmaxModel dim monitor Monitor.get_monitor model learning_rate 0.001data_specs model.get_input_space model.get_input_source cost DummyCost termination_criterion EpochCounter 1 monitor_rate 3em EpochMonitor model model tick_rate None monitor_rate monitor_rate algorithm SGD learning_rate cost batch_size batch_size train_iteration_mode 'sequential' monitoring_dataset dataset termination_criterion termination_criterion update_callbacks [em] set_batch_size False algorithm.setup dataset dataset model model algorithm.train dataset for key val in monitor.channels.items assert len val.val_record n_batches // monitor_rate
def canned_package root version '0.3.2' name 'FooBar'root.makedirs setup_py root.child 'setup.py' setup_py.setContent dedent '\nfromsetuptoolsimportsetup\n\nsetup \nname "{package_name}" \nversion "{package_version}" \npy_modules ["{package_name}"] \n \n' .format package_name name package_version version package_module root.child name + '.py' package_module.setContent dedent '\n__version__ "{package_version}"\n' .format package_version version return PythonPackage name name version version
def mirror op return _mirror.get op op
def align8to32 bytes width mode bits_per_pixel {'1' 1 'L' 8 'P' 8}[mode]bits_per_line bits_per_pixel * width full_bytes_per_line remaining_bits_per_line divmod bits_per_line 8 bytes_per_line full_bytes_per_line + 1 if remaining_bits_per_line else 0 extra_padding - bytes_per_line % 4 if not extra_padding return bytesnew_data []for i in range len bytes // bytes_per_line new_data.append bytes[ i * bytes_per_line i + 1 * bytes_per_line ] + '\x00' * extra_padding return ''.join new_data
def get_ufuncs _lazy_init_db return _ufunc_db.keys
def search_script_tag key None category None return ScriptDB.objects.get_by_tag key key category category
@removals.remove message 'keystoneclientauthpluginsaredeprecated.Usekeystoneauth.' version '2.1.0' removal_version '3.0.0' def register_conf_options conf group conf.register_opt _AUTH_SECTION_OPT group group if conf[group].auth_section group conf[group].auth_sectionconf.register_opt _AUTH_PLUGIN_OPT group group
@opt.register_stabilize@gof.local_optimizer [tensor.mul] def local_sigm_times_exp node if node.op ! tensor.mul return Nonemul_tree parse_mul_tree node.outputs[0] did_something perform_sigm_times_exp mul_tree if not did_something return Nonemul_tree simplify_mul mul_tree out compute_mul mul_tree copy_stack_trace node.outputs[0] out return [out]
def per_instance *args **kwargs instance args[0]unique_retained_instance id instance instance instance_and_rest unique_retained_instance + args[1 ] return equal_args *instance_and_rest **kwargs
def get_devices_from_config config device signal_repetitions config[CONF_SIGNAL_REPETITIONS]devices []for packet_id entity_info in config[CONF_DEVICES].items event get_rfx_object packet_id device_id slugify event.device.id_string.lower if device_id in RFX_DEVICES continue_LOGGER.info 'Add%srfxtrx' entity_info[ATTR_NAME] fire_event entity_info[ATTR_FIREEVENT]datas {ATTR_STATE False ATTR_FIREEVENT fire_event}new_device device entity_info[ATTR_NAME] event datas signal_repetitions RFX_DEVICES[device_id] new_devicedevices.append new_device return devices
def get_python_files all_files None if all_files is None all_files diff_base get_affected_files library_files []non_library_files []for filename in all_files if valid_filename filename if is_production_filename filename library_files.append filename else non_library_files.append filename return library_files non_library_files diff_base
def combine_hashes hashes hasher sha1 for h in sorted hashes hasher.update h return hasher.hexdigest
def _parse_date_asctime dt parts dt.split if len parts 5 parts.insert 4 '+0000' if len parts ! 6 return Nonereturn _parse_date_rfc822 ''.join [parts[0] parts[2] parts[1] parts[5] parts[3] parts[4]]
def _make_multidim_func one_d_func n *args args list args n np.asarray n args list map np.asarray args if all [ x.size 1 for x in [n] + args ] return one_d_func n *args d n.sizefor i in range len args if args[i].size 1 args[i] np.repeat args[i] d nodes []weights []for i in range d ai [x[i] for x in args]_1d one_d_func n[i] *ai nodes.append _1d[0] weights.append _1d[1] weights ckron *weights[ -1 ] nodes gridmake *nodes return nodes weights
def MainCGI method path unused_headers parameters outfile if method ! 'GET' and method ! 'POST' outfile.write 'Status 400\r\n' returnif path _GET_REQUEST_TOKEN_URL OAuthGetRequestTokenCGI outfile elif path _AUTHORIZE_TOKEN_URL OAuthAuthorizeTokenCGI method parameters outfile elif path _GET_ACCESS_TOKEN_URL OAuthGetAccessTokenCGI outfile else outfile.write 'Status 404UnknownOAuthhandler\r\n'
def oozie_to_hue_frequency frequency_string matches re.match FREQUENCY_REGEX frequency_string if matches return matches.group 'frequency_unit' matches.group 'frequency_number' else raise InvalidFrequency _ 'invalidfrequency %s' % frequency_string
def RetryQuestion question_text output_re '' default_val None while True if default_val is not None new_text '%s[%s] ' % question_text default_val else new_text '%s ' % question_text output raw_input new_text or str default_val output output.strip if not output_re or re.match output_re output breakelse print 'Invalidinput mustmatch%s' % output_re return output
def search_by_attributes service **kwargs if 'search' in inspect.getargspec service.list [0] res service.list search 'and'.join '{} {}'.format k v for k v in kwargs.items else res [e for e in service.list if len [k for k v in kwargs.items if getattr e k None v ] len kwargs ]res res or [None] return res[0]
def init mpstate return CmdlongModule mpstate
def fix_unix_encoding folder if not sabnzbd.WIN32 and not sabnzbd.DARWIN and gUTF for root dirs files in os.walk folder.encode 'utf-8' for name in files new_name special_fixer name .encode 'utf-8' if name ! new_name try shutil.move os.path.join root name os.path.join root new_name except logging.info 'Cannotcorrectnameof%s' os.path.join root name
def permanent_delete fid url build_url RESOURCE id fid route 'permanent_delete' return request 'delete' url
def _is_cookie_marked_for_deletion request return getattr request 'need_to_delete_cookie' False
def test_hide_supppressed for f in ['html'] results []for hide_value in False 'after' try pass_through 'a' hide hide_value pass_through 'b' raise_error except results.append format f else assert 0if results[0] ! results[1] print_diff results[0] results[1] assert 0
def pretty_xml_tree elem level 0 indent u'' if not elem.text and len elem > 0 or elem.text and isspace elem.text elem.text u'\n' + indent * level + 1 for i child in enumerate elem pretty_xml_tree child level level + 1 indent indent if not child.tail or isspace child.tail l level + 1 if i len elem - 1 l - 1child.tail u'\n' + indent * l
@task base BaseInstructorTask def send_bulk_course_email entry_id _xmodule_instance_args action_name ugettext_noop 'emailed' visit_fcn perform_delegate_email_batchesreturn run_main_task entry_id visit_fcn action_name
def get_color_dict return _color_dict.copy
def _dataset_id_to_blockdevice_id dataset_id return _PREFIX + unicode dataset_id
def index_create index body None hosts None profile None es _get_instance hosts profile try if index_exists index return Trueelse result es.indices.create index index body body return Trueexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def wipefacls *args **kwargs recursive kwargs.pop 'recursive' False _raise_on_no_files *args cmd 'setfacl-b'if recursive cmd + '-R'for dentry in args cmd + '"{0}"'.format dentry __salt__['cmd.run'] cmd python_shell False return True
def make_test_file content None suffix '.txt' if content is None content 'Iamatestfileforupload.'tdir tempfile.gettempdir file_for_upload tempfile.NamedTemporaryFile suffix suffix dir tdir file_for_upload.write content file_for_upload.seek 0 return file_for_upload
def encode_udp_packet rsv frag address_type address port payload strings [struct.pack '!HBB' rsv frag address_type __encode_address address_type address struct.pack '!H' port payload]return ''.join strings
def create redirect URL f 'new_assessment.iframe' vars {'viewing' 'survey_series.%s' % request.args[0] }
def _mod_priv_opts object_type privileges object_type object_type.lower privileges '' if privileges is None else privileges _privs re.split '\\s? \\s?' privileges.upper return object_type privileges _privs
def collect_files file_paths log_printer ignored_file_paths None limit_file_paths None limit_fnmatch functools.partial fnmatch globs limit_file_paths if limit_file_paths else lambda fname True valid_files list filter lambda fname os.path.isfile fname[0] icollect file_paths ignored_file_paths if valid_files collected_files file_globs_with_files zip *valid_files else collected_files file_globs_with_files [] [] _warn_if_unused_glob log_printer file_paths file_globs_with_files "Nofilesmatching'{}'werefound." limited_files list filter limit_fnmatch collected_files return limited_files
def _create_sailthru_user_vars user profile sailthru_vars {'username' user.username 'activated' int user.is_active 'joined_date' user.date_joined.strftime '%Y-%m-%d' }if profile sailthru_vars['fullname'] profile.namesailthru_vars['gender'] profile.gendersailthru_vars['education'] profile.level_of_educationif profile.year_of_birth sailthru_vars['year_of_birth'] profile.year_of_birthsailthru_vars['country'] unicode profile.country.code return sailthru_vars
def make_flocker_script_test script options command_name class FlockerScriptTestCase TestCase '\nTestforclassesthatimplement``ICommandLineScript``\n'def test_interface self '\nAscriptthatismeanttoberunby``FlockerScriptRunner``must\nimplement``ICommandLineScript``.\n'self.assertTrue verifyObject ICommandLineScript script def test_incorrect_arguments self '\n``FlockerScriptRunner.main``exitswithstatus1andprintshelpto\n`stderr`ifsuppliedwithunexpectedarguments.\n'sys_module FakeSysModule argv [command_name '--unexpected_argument'] script_runner FlockerScriptRunner reactor None script script options options sys_module sys_module error self.assertRaises SystemExit script_runner.main error_text sys_module.stderr.getvalue self.assertEqual 1 [] error.code help_problems command_name error_text return FlockerScriptTestCase
def install_webpi name install_args None override_args False return install name source 'webpi' install_args install_args override_args override_args
def mock_render_to_string template_name context return str template_name sorted context.iteritems
def release_group return Rebulk .rules SceneReleaseGroup AnimeReleaseGroup ExpectedReleaseGroup
def getCarvableObject globalObject object xmlElement archivableObject globalObject archivableObject.xmlElement objectobject.attributeDictionary['id'] xmlElement.getFirstChildWithClassName 'name' .textobject.object archivableObjectcoords xmlElement.getFirstChildWithClassName 'coords' transformXMLElement getTransformXMLElement coords 'transformFrom' if len transformXMLElement.attributeDictionary < 16 transformXMLElement getTransformXMLElement coords 'transformTo' matrix.setXMLElementDictionaryToOtherElementDictionary transformXMLElement object.object.matrix4X4 '' object return archivableObject
def project_get project_id None name None profile None **connection_args auth profile **connection_args if _OS_IDENTITY_API_VERSION > 2 return tenant_get tenant_id project_id name name profile None **connection_args else return False
@locked_functiondef store_in_cache cache_location url response hpath bpath calculate_cache_path cache_location url try outf open hpath 'wb' headers str response.info outf.write headers outf.close outf open bpath 'wb' outf.write response.read outf.close except IOError return Trueelse return False
def _merge_options options defaults __salt__['config.option'] 'solr.dih.import_options' if isinstance options dict defaults.update options for key val in six.iteritems defaults if isinstance val bool defaults[key] str val .lower return defaults
def query_ids_from_blast_result blast_result filter_fn no_filter DEBUG False ok_ids []removed_ids []for id in blast_result for entry in blast_result[id] for subentry in entry if not check_align_percent_field subentry continueif not filter_fn subentry removed_ids.append id continueok_ids.append subentry['QUERYID'] ok_ids set ok_ids removed_ids set removed_ids - ok_ids return ok_ids removed_ids
def deprecatedWorkerModuleAttribute scope attribute compat_name None new_name None module_name scope['__name__']assert module_name in sys.modules 'scopemustbemodule i.e.locals 'assert sys.modules[module_name].__dict__ is scope 'scopemustbemodule i.e.locals 'if new_name is None scope_keys list scope.keys scope_values list scope.values attribute_name scope_keys[scope_values.index attribute ]else attribute_name new_namecompat_name _compat_name attribute_name compat_name compat_name scope[compat_name] attributeif attribute_name msg 'Use{0}instead.'.format attribute_name else msg "Don'tuseit."_deprecatedModuleAttribute Version 'Buildbot' 0 9 0 _WORKER_WARNING_MARK + msg module_name compat_name
def get_pants_cachedir cache_home os.environ.get u'XDG_CACHE_HOME' if not cache_home cache_home u'~/.cache'return os.path.expanduser os.path.join cache_home u'pants'
def directory_arg path optname if not os.path.isdir path raise UsageError '{0}mustbeadirectory given {1}'.format optname path return path
def _getSimplePatterns numOnes numPatterns numCols numOnes * numPatterns p []for i in xrange numPatterns x numpy.zeros numCols dtype 'float32' x[ i * numOnes i + 1 * numOnes ] 1p.append x return p
@utils.arg 'server' metavar '<server>' help _ 'NameorIDofserver.' @utils.arg '--length' metavar '<length>' default None help _ 'Lengthinlinestotail.' def do_console_log cs args server _find_server cs args.server data server.get_console_output length args.length print data
def ErrorDetails exc_info None exclude_robot_traces EXCLUDE_ROBOT_TRACES exc_type exc_value exc_traceback exc_info or sys.exc_info if exc_type in RERAISED_EXCEPTIONS raise exc_valuedetails PythonErrorDetails if not isinstance exc_value Throwable else JavaErrorDetails return details exc_type exc_value exc_traceback exclude_robot_traces
def nsecs_to_timespec ns ns int ns return ns / 10 ** 9 ns % 10 ** 9
def plotting_positions data alpha 0.4 beta 0.4 data ma.array data copy False .reshape 1 -1 n data.count plpos np.empty data.size dtype float plpos[n ] 0plpos[data.argsort [ n]] np.arange 1 n + 1 - alpha / n + 1.0 - alpha - beta return ma.array plpos mask data._mask
def _namespace_package_path fqname pathnames path None working_set pkg_resources.WorkingSet path path list pathnames for dist in working_set if dist.has_metadata 'namespace_packages.txt' namespaces dist.get_metadata 'namespace_packages.txt' .splitlines if fqname in namespaces nspath os.path.join dist.location *fqname.split '.' if nspath not in path path.append nspath return path
def undoc func return func
def _updateNamespace item new_namespace temp_item ''i item.tag.find '}' if i > 0 temp_item item.tag[ i + 1 ]else temp_item item.tagitem.tag '{{{0}}}{1}'.format new_namespace temp_item for child in item.getiterator if isinstance child.tag string_types temp_item ''i child.tag.find '}' if i > 0 temp_item child.tag[ i + 1 ]else temp_item child.tagchild.tag '{{{0}}}{1}'.format new_namespace temp_item return item
def get_fs_info path hddinfo os.statvfs path total hddinfo.f_frsize * hddinfo.f_blocks free hddinfo.f_frsize * hddinfo.f_bavail used hddinfo.f_frsize * hddinfo.f_blocks - hddinfo.f_bfree return {'total' total 'free' free 'used' used}
def _paths_from_list_modifications module_path trailer1 trailer2 if not tree.is_node trailer1 'trailer' and trailer1.children[0] '.' and tree.is_node trailer2 'trailer' and trailer2.children[0] ' ' and len trailer2.children 3 return []name trailer1.children[1].valueif name not in ['insert' 'append'] return []arg trailer2.children[1]if name 'insert' and len arg.children in 3 4 arg arg.children[2]return _execute_code module_path arg.get_code
def get_build_platform try from sysconfig import get_platformexcept ImportError from distutils.util import get_platformplat get_platform if sys.platform 'darwin' and not plat.startswith 'macosx-' try version _macosx_vers machine os.uname [4].replace '' '_' return 'macosx-%d.%d-%s' % int version[0] int version[1] _macosx_arch machine except ValueError passreturn plat
def test_precession j2000 Time u'J2000' scale u'utc' b1950 Time u'B1950' scale u'utc' j1975 Time u'J1975' scale u'utc' b1975 Time u'B1975' scale u'utc' fk4 FK4 ra 1 * u.radian dec 0.5 * u.radian assert fk4.equinox.byear b1950.byear fk4_2 fk4.transform_to FK4 equinox b1975 assert fk4_2.equinox.byear b1975.byear fk5 FK5 ra 1 * u.radian dec 0.5 * u.radian assert fk5.equinox.jyear j2000.jyear fk5_2 fk5.transform_to FK4 equinox j1975 assert fk5_2.equinox.jyear j1975.jyear
def _hessian_wrapper hess x z k_params x_arr np.asarray x params x_arr[ k_params].ravel zh_x np.asarray z[0] * hess params zero_mat np.zeros zh_x.shape A np.concatenate zh_x zero_mat axis 1 B np.concatenate zero_mat zero_mat axis 1 zh_x_ext np.concatenate A B axis 0 return matrix zh_x_ext 2 * k_params 2 * k_params
def import_book dbook in_stream headers True dbook.wipe xls_book openpyxl.reader.excel.load_workbook BytesIO in_stream for sheet in xls_book.worksheets data tablib.Dataset data.title sheet.titlefor i row in enumerate sheet.rows row_vals [c.value for c in row]if i 0 and headers data.headers row_valselse data.append row_vals dbook.add_sheet data
def _fallback_results locale product_slugs products []for slug in product_slugs try p Product.objects.get slug slug products.append p except Product.DoesNotExist pass docs fallback documents_for locale products products docs docs + fallback or [] return docs[ 20]
def delete_directory path shutil.rmtree path onerror _on_error return not os.path.exists path
def _verify_var_type val return isinstance val basestring int float datetime.date
def event_list consul_url None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif 'name' in kwargs query_params kwargs['name']else raise SaltInvocationError 'Requiredargument"name"ismissing.' function 'event/list/'ret _query consul_url consul_url query_params query_params function function return ret
def compile_attributes bases dependants parameters coalesce None label None context SQLExpressionContext bases parameters label label compiler SQLExpressionCompiler for attr in dependants if hasattr attr 'function' and attr.function function_name attr.function.lower function get_aggregate_function function_name column function attr context coalesce else column compiler.compile attr.expression context context.add_column attr.ref column return context.columns
def _get_unique_smem_id name global _unique_smem_id_unique_smem_id + 1return '{0}_{1}'.format name _unique_smem_id
def iand a b a & breturn a
def get_collection_by_id collection_id strict True version None collection_memcache_key _get_collection_memcache_key collection_id version version memcached_collection memcache_services.get_multi [collection_memcache_key] .get collection_memcache_key if memcached_collection is not None return memcached_collectionelse collection_model collection_models.CollectionModel.get collection_id strict strict version version if collection_model collection get_collection_from_model collection_model memcache_services.set_multi {collection_memcache_key collection} return collectionelse return None
def get_size start_path total_size 0for dirpath __ filenames in os.walk start_path for f in filenames fp os.path.join dirpath f total_size + os.path.getsize fp return total_size
def _param_filter_match vobject_item filter_ parent_name name filter_.get 'name' children getattr vobject_item '%s_list' % parent_name [] condition any name in child.params for child in children if len filter_ if filter_[0].tag _tag 'C' 'text-match' return condition and _text_match vobject_item filter_[0] parent_name name elif filter_[0].tag _tag 'C' 'is-not-defined' return not condition else return condition
def add_nylas_headers msg nylas_uid msg.headers['X-INBOX-ID'] nylas_uidmsg.headers['Message-Id'] generate_message_id_header nylas_uid msg.headers['User-Agent'] 'NylasMailer/{0}'.format VERSION
def _prefix_root root path trailing False return normpath join _norm_root root path.lstrip '/' trailing trailing
def rollback_snapshot vm name key 'uuid' ret {}vmadm _check_vmadm if key not in ['uuid' 'alias' 'hostname'] ret['Error'] 'Keymustbeeitheruuid aliasorhostname'return retvm lookup '{0} {1}'.format key vm one True if 'Error' in vm return vmvmobj get vm if 'datasets' in vmobj ret['Error'] 'VMcannothavedatasets'return retif vmobj['brand'] in ['kvm'] ret['Error'] 'VMmustbeoftypeOS'return retcmd '{vmadm}rollback-snapshot{uuid}{snapshot}'.format vmadm vmadm snapshot name uuid vm res __salt__['cmd.run_all'] cmd retcode res['retcode']if retcode ! 0 ret['Error'] res['stderr'] if 'stderr' in res else _exit_status retcode return retreturn True
def forward_substitution lower_triangle variable constant K copy_lower_triangle copy.deepcopy lower_triangle nrow len copy_lower_triangle result []for i in range nrow a K.zerofor j in range i a + copy_lower_triangle[i][j] * variable[j][0] variable[i][0] constant[i][0] - a / copy_lower_triangle[i][i] return variable
def schedule_rebuild_kb if not waffle.switch_is_active 'wiki-rebuild-on-demand' or settings.CELERY_ALWAYS_EAGER returnif cache.get settings.WIKI_REBUILD_TOKEN log.debug 'Rebuildtaskalreadyscheduled.' returncache.set settings.WIKI_REBUILD_TOKEN True rebuild_kb.delay
@utils.arg 'aggregate' metavar '<aggregate>' help _ 'NameorIDofaggregate.' @utils.arg 'host' metavar '<host>' help _ 'Thehosttoremovefromtheaggregate.' def do_aggregate_remove_host cs args aggregate _find_aggregate cs args.aggregate aggregate cs.aggregates.remove_host aggregate.id args.host print _ 'Host% host shasbeensuccessfullyremovedfromaggregate% aggregate_id s' % {'host' args.host 'aggregate_id' aggregate.id} _print_aggregate_details cs aggregate
def _AddListFieldsMethod message_descriptor cls def ListFields self all_fields [item for item in self._fields.iteritems if _IsPresent item ]all_fields.sort key lambda item item[0].number return all_fieldscls.ListFields ListFields
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _collins_crt r R P p K return gf_int gf_crt [r R] [P p] K P * p
def win32_utf8_argv try from ctypes import POINTER byref cdll c_int windllfrom ctypes.wintypes import LPCWSTR LPWSTRGetCommandLineW cdll.kernel32.GetCommandLineWGetCommandLineW.argtypes []GetCommandLineW.restype LPCWSTRCommandLineToArgvW windll.shell32.CommandLineToArgvWCommandLineToArgvW.argtypes [LPCWSTR POINTER c_int ]CommandLineToArgvW.restype POINTER LPWSTR cmd GetCommandLineW argc c_int 0 argv CommandLineToArgvW cmd byref argc if argc.value > 0 return [argv[i] for i in xrange 0 argc.value ]except Exception pass
def CreateParser query input_string antlr3.ANTLRStringStream query lexer QueryLexerWithErrors input_string tokens antlr3.CommonTokenStream lexer parser QueryParserWithErrors tokens return parser
def _flatten_action_profile action_profile indptr N len indptr - 1 out np.empty indptr[ -1 ] for i in range N if isinstance action_profile[i] numbers.Integral num_actions indptr[ i + 1 ] - indptr[i] mixed_action pure2mixed num_actions action_profile[i] else mixed_action action_profile[i]out[indptr[i] indptr[ i + 1 ]] mixed_actionreturn out
@receiver pre_save sender ApiAccessRequest dispatch_uid 'api_access_request_pre_save_email' def send_decision_email sender instance **kwargs if instance.id and not instance.contacted old_instance ApiAccessRequest.objects.get pk instance.id if instance.status ! old_instance.status _send_decision_email instance
def import_pyside2 from PySide2 import QtGui QtCore QtSvg QtWidgets QtPrintSupportQtGuiCompat types.ModuleType 'QtGuiCompat' QtGuiCompat.__dict__.update QtGui.__dict__ QtGuiCompat.__dict__.update QtWidgets.__dict__ QtGuiCompat.__dict__.update QtPrintSupport.__dict__ return QtCore QtGuiCompat QtSvg QT_API_PYSIDE2
def directLoops isWiddershins loops for loop in loops directLoop isWiddershins loop
def raw_system_incron log.debug 'read_file{0}'.format _read_file _INCRON_SYSTEM_TAB 'salt' return ''.join _read_file _INCRON_SYSTEM_TAB 'salt'
def getChildForRequest resource request while request.postpath and not resource.isLeaf pathElement request.postpath.pop 0 request.prepath.append pathElement resource resource.getChildWithDefault pathElement request return resource
@with_settings foo 0 bar False def test_require_key_exists_false_primitive_values require 'foo' 'bar'
def exeOnly file_name Directory.GetCurrentDirectory + '\\fooEXEONLY.cs' file open file_name 'w' print >>file cs_ipy % 'EXEONLY' 100 file.close compileExe file_name
def obj_make_dict_of_lists context list_cls obj_list item_key obj_lists {}for obj in obj_list key getattr obj item_key if key not in obj_lists obj_lists[key] list_cls obj_lists[key].objects []obj_lists[key].objects.append obj for key in obj_lists obj_lists[key]._context contextobj_lists[key].obj_reset_changes return obj_lists
def test_kit2fiff check_usage mne_kit2fiff force_help True
def check_const_string result func cargs offset None if offset check_err result ptr ptr_byref cargs offset return ptr.valueelse return result
def search_vm_ref_by_identifier session identifier vm_ref _get_vm_ref_from_vm_uuid session identifier or _get_vm_ref_from_extraconfig session identifier or _get_vm_ref_from_uuid session identifier return vm_ref
def urlize value from django.utils.html import urlizereturn urlize value nofollow True
def get_sun time earth_pv_helio earth_pv_bary erfa.epv00 *get_jd12 time u'tdb' earth_p earth_pv_helio[... 0 ]earth_v earth_pv_bary[... 1 ]earth_v / c.to u.au / u.d .valuedsun np.sqrt np.sum earth_p ** 2 axis -1 invlorentz 1 - np.sum earth_v ** 2 axis -1 ** 0.5 properdir erfa.ab earth_p / dsun.reshape dsun.shape + 1 - earth_v dsun invlorentz cartrep CartesianRepresentation x - dsun * properdir[... 0] * u.AU y - dsun * properdir[... 1] * u.AU z - dsun * properdir[... 2] * u.AU return SkyCoord cartrep frame GCRS obstime time
def _format_range_context start stop beginning start + 1 length stop - start if not length beginning - 1if length < 1 return '{}'.format beginning return '{} {}'.format beginning beginning + length - 1
def display_menu stdscr menu_y erase_menu stdscr menu_y stdscr.addstr menu_y 4 'Usethecursorkeystomove andspaceorEntertotoggleacell.' stdscr.addstr menu_y + 1 4 'E rasetheboard R andomfill S teponceorC ontinuously Q uit'
def xyxy_to_xywh boxes return np.hstack boxes[ 0 2] boxes[ 2 4] - boxes[ 0 2] + 1
def badge_description course mode if course.end return _ u'Completedthecourse"{course_name}" {course_mode} {start_date}-{end_date} ' .format start_date course.start.date end_date course.end.date course_name course.display_name course_mode mode else return _ u'Completedthecourse"{course_name}" {course_mode} ' .format course_name course.display_name course_mode mode
def positive s threshold 0.1 **kwargs return polarity s **kwargs > threshold
def decrypted_dict data encryption_key None return_data {}if not data return return_datafor prop_name prop_value in data.items method value prop_valuedecrypted_value decrypt method value encryption_key prop_string jsonutils.loads decrypted_value return_data[prop_name] prop_stringreturn return_data
def is_version_of_draft_valid exp_id version return get_exploration_by_id exp_id .version version
def object_description object try s repr object except Exception raise ValueErrorif isinstance s binary_type s force_decode s None s memory_address_re.sub '' s return s.replace '\n' ''
def cr_uid_ids_context method method._api 'cr_uid_ids_context'return method
def _get_read_geometry try import nibabel as nibhas_nibabel Trueexcept ImportError has_nibabel Falseif has_nibabel and LooseVersion nib.__version__ > LooseVersion '2.1.0' from nibabel.freesurfer import read_geometryelse read_geometry _read_geometryreturn read_geometry
@image_comparison baseline_images [u'EventCollection_plot__set_color'] def test__EventCollection__set_color splt coll _ generate_EventCollection_plot new_color np.array [0 1 1 1] coll.set_color new_color np.testing.assert_array_equal new_color coll.get_color check_allprop_array coll.get_colors new_color splt.set_title u'EventCollection set_color'
def get_timezone_name tz_name force_text get_current_timezone_name errors 'ignore' return tz_name.encode 'ascii' 'ignore' .decode 'ascii' .replace '' '_'
def _is_secure_cipher cipher tokens [e.upper for e in cipher.name .split '-' ]if cipher.usedBits < 128 return Falseelif cipher.keyExchangeMethod 'DH' and os.name 'nt' return Falseelif cipher.encryptionMethod .upper .startswith 'RC4' return Falseelif cipher.encryptionMethod .upper .startswith 'DES' return Falseelif 'MD5' in tokens return Falseelif cipher.authenticationMethod in ['aNULL' 'NULL'] return Falseelif cipher.encryptionMethod in ['eNULL' 'NULL'] return Falseelif 'EXP' in tokens or 'EXPORT' in tokens return Falseelif 'ADH' in tokens return Falseelse return True
def activate language if not language return_active.value translation language
def get_resource resource_name key identifier_fields profile 'pagerduty' subdomain None api_key None if 'pagerduty_util.resource_cache' not in __context__ __context__['pagerduty_util.resource_cache'] {}if resource_name not in __context__['pagerduty_util.resource_cache'] if resource_name 'services' action resource_name + '?include[] escalation_policy' else action resource_name__context__['pagerduty_util.resource_cache'][resource_name] _query action action profile profile subdomain subdomain api_key api_key [resource_name]for resource in __context__['pagerduty_util.resource_cache'][resource_name] for field in identifier_fields if resource[field] key if resource_name 'schedules' full_resource_info _query action '{0}/{1}'.format resource_name resource['id'] profile profile subdomain subdomain api_key api_key return full_resource_inforeturn resourcereturn None
def find_files roots generated_resources None ignored_patterns IGNORED_PATTERNS ignored_dirs IGNORED_DIRS ignored_path_regexps IGNORED_PATH_REGEXPS allowed_extensions None if generated_resources is None generated_resources set if isinstance roots string_types roots [roots]if isinstance allowed_extensions string_types allowed_extensions set [allowed_extensions] for root in roots for path dirs files in os.walk root path posixpath.normpath path.replace os.sep '/' _remove_ignored_directories path dirs ignored_dirs ignored_path_regexps for filename in files filepath posixpath.join path filename if filename 'generated_resources.txt' _process_generated_resources path filepath generated_resources continueif not all not fnmatch.fnmatch filename x for x in ignored_patterns continueif not _check_allowed_extension filepath allowed_extensions continue yield filepath
def run_chunk environ lowstate client environ['SALT_APIClient']for chunk in lowstate yield client.run chunk
@register.inclusion_tag 'authority/permission_request_delete_link.html' takes_context True def permission_request_delete_link context perm user context['request'].userif user.is_authenticated link_kwargs base_link context perm 'authority-delete-permission-request' if user.has_perm 'authority.delete_permission' link_kwargs['is_requestor'] Falsereturn link_kwargsif not perm.approved and perm.user user link_kwargs['is_requestor'] Truereturn link_kwargsreturn {'url' None}
def notAfter cert_path return _notAfterBefore cert_path OpenSSL.crypto.X509.get_notAfter
def setup app app.add_role 'rfc' rfclink return
def stat request path if not request.fs.exists path raise Http404 _ 'Filenotfound % path s' % {'path' escape path } stats request.fs.stats path return JsonResponse _massage_stats request stats
def render_tooltip label comment _class 'tooltip' if not comment tooltip ''elif isinstance comment lazyT basestring if hasattr label 'flatten' label label.flatten .strip '*' tooltip DIV _class _class _title '%s|%s' % label comment else tooltip commentreturn tooltip
def skip_if_unavailable modulename def cantimport try __import__ modulename except ImportError return Trueelse return Falsereturn skip_if cantimport
def set_nuage_facts_if_unset facts if 'common' in facts if 'use_nuage' not in facts['common'] use_nuage Falsefacts['common']['use_nuage'] use_nuagereturn facts
def collect_assets systems settings **kwargs for sys in systems collectstatic_stdout_str _collect_assets_cmd sys **kwargs sh django_cmd sys settings 'collectstatic--noinput{logfile_str}'.format logfile_str collectstatic_stdout_str print ' DCTB DCTB Finishedcollecting{}assets.'.format sys
def parse_ssh_config file_obj config SSHConfig config.parse file_obj return config
def _populate_cache platform pkg_cache mount_dir if not pkg_cache returnif not os.path.isdir pkg_cache returnif platform 'pacman' cache_dir '{0}/var/cache/pacman/pkg'.format mount_dir __salt__['file.mkdir'] cache_dir 'root' 'root' '755' __salt__['file.copy'] pkg_cache cache_dir recurse True remove_existing True
def unlabel_rgb colors str_vals ''for index in range len colors try float colors[index] str_vals str_vals + colors[index] except ValueError if colors[index] ' ' or colors[index] '.' str_vals str_vals + colors[index] str_vals str_vals + ' ' numbers []str_num ''for char in str_vals if char ! ' ' str_num str_num + char else numbers.append float str_num str_num ''return numbers[0] numbers[1] numbers[2]
def user_has_resource_db_permission user_db resource_db permission_type if not cfg.CONF.rbac.enable return Trueresolver resolvers.get_resolver_for_permission_type permission_type permission_type result resolver.user_has_resource_db_permission user_db user_db resource_db resource_db permission_type permission_type return result
def valid_date date if not hasattr date 'tzinfo' return Falseif date.tzinfo is None or _total_seconds date.utcoffset < 1.1 return Truereturn False
def make_graph filename dep_info sect gtype dependencies_graph filename dep_info sect.append Paragraph '%simportsgraphhasbeenwrittento%s' % gtype filename
@utils.arg 'aggregate' metavar '<aggregate>' help _ 'NameorIDofaggregatetodelete.' def do_aggregate_delete cs args aggregate _find_aggregate cs args.aggregate cs.aggregates.delete aggregate print _ 'Aggregate%shasbeensuccessfullydeleted.' % aggregate.id
def qbytearray_to_str qba return str bytes qba.toHex .data .decode
@cache_with_key lambda *args display_recipient_cache_key args[0] timeout 3600 * 24 * 7 def get_display_recipient_remote_cache recipient_id recipient_type recipient_type_id if recipient_type Recipient.STREAM stream Stream.objects.get id recipient_type_id return stream.nameuser_profile_list UserProfile.objects.filter subscription__recipient_id recipient_id .select_related .order_by 'email' return [{'email' user_profile.email 'domain' user_profile.realm.domain 'full_name' user_profile.full_name 'short_name' user_profile.short_name 'id' user_profile.id 'is_mirror_dummy' user_profile.is_mirror_dummy} for user_profile in user_profile_list]
def nsga2select population fitnesses survivors allowequality True fronts non_dominated_sort population key lambda x fitnesses[x] allowequality allowequality individuals set for front in fronts remaining survivors - len individuals if not remaining > 0 breakif len front > remaining crowd_dist crowding_distance front fitnesses front sorted front key lambda x crowd_dist[x] reverse True front set front[ remaining] individuals | frontreturn list individuals
@sopel.module.require_privmsg@sopel.module.require_admin@sopel.module.commands u'msg' @sopel.module.priority u'low' @sopel.module.example u'.msg#YourPantsDoesanyoneelsesmellneurotoxin?' def msg bot trigger if trigger.group 2 is None return channel _sep message trigger.group 2 .partition u'' message message.strip if not channel or not message returnbot.msg channel message
def getLinkLocalIPv6Address addresses getLinkLocalIPv6Addresses if addresses return addresses[0]raise SkipTest 'LinklocalIPv6addressunavailable'
@slow_testdef test_browse_raw check_usage mne_browse_raw
def signin_success request identity_url openid_response redirect_field_name REDIRECT_FIELD_NAME **kwargs openid_ from_openid_response openid_response openids request.session.get 'openids' [] openids.append openid_ request.session['openids'] openidsrequest.session['openid'] openid_try rel UserAssociation.objects.get openid_url__exact str openid_ except redirect_to request.REQUEST.get redirect_field_name '' if not redirect_to or '//' in redirect_to or '' in redirect_to redirect_to settings.LOGIN_REDIRECT_URLreturn HttpResponseRedirect '%s?%s' % reverse 'user_register' urllib.urlencode {redirect_field_name redirect_to} user_ rel.userif user_.is_active user_.backend 'django.contrib.auth.backends.ModelBackend'login request user_ redirect_to request.GET.get redirect_field_name '' if not redirect_to or '//' in redirect_to or '' in redirect_to redirect_to settings.LOGIN_REDIRECT_URLreturn HttpResponseRedirect redirect_to
def at_start elem body XPath 'ancestor-or-self h body' elem if not body return Truebody body[0]ancestors frozenset XPath 'ancestor *' elem for x in body.iter if x is elem return Trueif hasattr getattr x 'tag' None 'rpartition' and x.tag.rpartition '}' [ -1 ] in {'img' 'svg'} return Falseif isspace getattr x 'text' None and x in ancestors or isspace getattr x 'tail' None continuereturn Falsereturn False
def acl_create consul_url None **kwargs ret {}data {}if not consul_url consul_url _get_config if not consul_url log.error 'NoConsulURLfound.' ret['message'] 'NoConsulURLfound.'ret['res'] Falsereturn retif 'name' in kwargs data['Name'] kwargs['name']else raise SaltInvocationError 'Requiredargument"name"ismissing.' if 'type' in kwargs data['Type'] kwargs['type']if 'rules' in kwargs data['Rules'] kwargs['rules']function 'acl/create'res _query consul_url consul_url data data method 'PUT' function function if res['res'] ret['res'] Trueret['message'] 'ACL{0}created.'.format kwargs['name'] else ret['res'] Falseret['message'] 'RemovingCatalogitem{0}failed.'.format kwargs['name'] return ret
def target def prep r if r.interactive if r.component_name 'collection' record r.recordtable s3db.dc_collectiontable.location_id.default record.location_idtable.template_id.default record.template_idreturn Trues3.prep prepreturn s3_rest_controller rheader s3db.dc_rheader
def _getSimplePatterns numOnes numPatterns numCols numOnes * numPatterns p []for i in xrange numPatterns x numpy.zeros numCols dtype 'float32' x[ i * numOnes i + 1 * numOnes ] 1p.append x return p
def salustowicz_1d data return exp - data[0] * data[0] ** 3 * cos data[0] * sin data[0] * cos data[0] * sin data[0] ** 2 - 1
@pytest.fixture def _temp_analyze_files tmpdir orig_img tmpdir.join u'orig.img' orig_hdr tmpdir.join u'orig.hdr' orig_img.open u'w+' .close orig_hdr.open u'w+' .close return str orig_img str orig_hdr
def relabel_sequential label_field offset 1 m label_field.max if not np.issubdtype label_field.dtype np.int new_type np.min_scalar_type int m label_field label_field.astype new_type m m.astype new_type labels np.unique label_field labels0 labels[ labels ! 0 ]if m len labels0 return label_field labels labels forward_map np.zeros m + 1 int forward_map[labels0] np.arange offset offset + len labels0 if not labels 0 .any labels np.concatenate [0] labels inverse_map np.zeros offset - 1 + len labels dtype np.intp inverse_map[ offset - 1 ] labelsrelabeled forward_map[label_field]return relabeled forward_map inverse_map
def make_re mask as_string ''.join mask r '[^' + re.escape as_string + ']' return re.compile r
def stream_generator function before_fullname Noneseen_fullnames BoundedSet 301 without_before_counter 0while True newest_fullname Nonelimit 100if before_fullname is None limit - without_before_counterwithout_before_counter without_before_counter + 1 % 30 for item in reversed list function limit limit params {'before' before_fullname} if item.fullname in seen_fullnames continueseen_fullnames.add item.fullname newest_fullname item.fullname yield item before_fullname newest_fullname
def timethis func @wraps func def wrapper *args **kwargs start time.time result func *args **kwargs end time.time print func.__name__ end - start return resultreturn wrapper
def message_from_file fp *args **kws from email.parser import Parserreturn Parser *args **kws .parse fp
def _get_module_and_context context pricing_mod get_pricing_module pricing_ctx pricing_mod.get_context context return pricing_mod pricing_ctx
def _sort_factors factors **args def order_if_multiple_key factor f n factorreturn len f n f def order_no_multiple_key f return len f f if args.get 'multiple' True return sorted factors key order_if_multiple_key else return sorted factors key order_no_multiple_key
def _EMSA_PKCS1_V1_5_ENCODE msg_hash emLen with_hash_parameters True digestAlgo DerSequence [DerObjectId msg_hash.oid .encode ] if with_hash_parameters digestAlgo.append DerNull .encode digest DerOctetString msg_hash.digest digestInfo DerSequence [digestAlgo.encode digest.encode ] .encode if emLen < len digestInfo + 11 raise TypeError 'Selectedhashalgorithhasatoolongdigest %dbytes .' % len digest PS bchr 255 * emLen - len digestInfo - 3 return b '\x00\x01' + PS + bchr 0 + digestInfo
@_np.deprecate message 'scipy.constants.F2Cisdeprecatedinscipy0.18.0.Usescipy.constants.convert_temperatureinstead.Notethatthenewfunctionhasadifferentsignature.' def F2C F return _np.asanyarray F - 32 / 1.8
def math2html formula factory FormulaFactory whole factory.parseformula formula FormulaProcessor .process whole whole.process return ''.join whole.gethtml
@lru_cache def get_babel_locale locale_string return babel.Locale.parse locale_string '-'
def is_error pkt code endian_int pkt[5 7] if code 1064 return Trueelif code 1096 return Truereturn False
def _joint_probabilities_nn distances neighbors desired_perplexity verbose distances astype distances np.float32 copy False neighbors astype neighbors np.int64 copy False conditional_P _utils._binary_search_perplexity distances neighbors desired_perplexity verbose m 'Allprobabilitiesshouldbefinite'assert np.all np.isfinite conditional_P mP conditional_P + conditional_P.T sum_P np.maximum np.sum P MACHINE_EPSILON P np.maximum squareform P / sum_P MACHINE_EPSILON assert np.all np.abs P < 1.0 return P
def convert_Decimal x encoder if encoder.strict is False return float x raise pyamf.EncodeError 'Unabletoencodedecimal.Decimalinstancesasthereisnowaytoguaranteeexactconversion.Usestrict Falsetoconverttoafloat.'
def submit_and_follow app form extra_environ None name None value None **args response webtest_submit form name value value status 302 extra_environ extra_environ **args return app.get url response.headers['Location'] extra_environ extra_environ
def get_all ret _get_systemd_services ret.update set _get_sysv_services return sorted ret
def run_checks checks [check_test_runner check_boolean_field_default_value ]return [output for output in checks if output]
def make_default_app_wrapper name @functools.wraps getattr Bottle name def wrapper *a **ka return getattr app name *a **ka return wrapper
def parse_property_name source name source.get_while PROPERTY_NAME_PART saved_pos source.posch source.get if ch and ch in ' ' prop_name namename source.get_while ALNUM | set '&_-./' .strip if name saved_pos source.poselse prop_name name None prop_name else prop_name Nonesource.pos saved_posreturn prop_name name
def url_for endpoint **kw return url_adapter.build endpoint kw
def _decrypt_object obj if isinstance obj six.string_types return _fetch_secret obj elif isinstance obj dict for pass_key pass_path in six.iteritems obj obj[pass_key] _decrypt_object pass_path elif isinstance obj list for pass_key pass_path in enumerate obj obj[pass_key] _decrypt_object pass_path return obj
def remove_excess_padding text text re.sub '^\\n' '' text text re.sub '\\n$' '' text return text
def ip_to_host ip try hostname aliaslist ipaddrlist socket.gethostbyaddr ip except Exception hostname Nonereturn hostname
def numa_get_reserved_huge_pages bucket {}if CONF.reserved_huge_pages try bucket collections.defaultdict dict for cfg in CONF.reserved_huge_pages try pagesize int cfg['size'] except ValueError pagesize strutils.string_to_bytes cfg['size'] return_int True / units.Ki bucket[int cfg['node'] ][pagesize] int cfg['count'] except ValueError TypeError KeyError raise exception.InvalidReservedMemoryPagesOption conf CONF.reserved_huge_pages return bucket
def fnmatchcase name pat try re_pat _cache[pat]except KeyError res translate pat if len _cache > _MAXCACHE _cache.clear _cache[pat] re_pat re.compile res return re_pat.match name is not None
def warn_deprecated since message '' name '' alternative '' pending False obj_type 'attribute' addendum '' message _generate_deprecation_message since message name alternative pending obj_type warnings.warn message mplDeprecation stacklevel 1
def get_children cluster if is_leaf cluster raise TypeError 'aleafclusterhasnochildren' else return cluster[1]
def pure_nugget theta d theta np.asarray theta dtype np.float64 d np.asarray d dtype np.float64 n_eval d.shape[0]r np.zeros n_eval r[np.all d 0.0 axis 1 ] 1.0return r
def get_timeline_data doctype name return dict frappe.db.sql u"selectunix_timestamp cs.schedule_date count * \n DCTB DCTB from`tabCourseSchedule`ascs `tabStudentAttendance`assawhere\n DCTB DCTB DCTB sa.course_schedule cs.name\n DCTB DCTB DCTB andsa.student %s\n DCTB DCTB DCTB andcs.schedule_date>date_sub curdate interval1year \n DCTB DCTB DCTB andstatus 'Present'\n DCTB DCTB DCTB groupbycs.schedule_date" name
def attach_is_watcher_to_queryset queryset user as_field 'is_watcher' model queryset.modeltype apps.get_model 'contenttypes' 'ContentType' .objects.get_for_model model if user is None or user.is_anonymous sql 'SELECTfalse'else sql 'SELECTCASEWHEN SELECTcount * \nFROMnotifications_watched\nWHEREnotifications_watched.content_type_id {type_id}\nANDnotifications_watched.object_id {tbl}.id\nANDnotifications_watched.user_id {user_id} >0\nTHENTRUE\nELSEFALSE\nEND'sql sql.format type_id type.id tbl model._meta.db_table user_id user.id qs queryset.extra select {as_field sql} return qs
def ThrottleRemoteDatastore throttle remote_datastore_stub None if not remote_datastore_stub remote_datastore_stub apiproxy_stub_map.apiproxy.GetStub 'datastore_v3' if not isinstance remote_datastore_stub remote_api_stub.RemoteDatastoreStub raise remote_api_stub.ConfigurationError 'remote_apiisnotconfigured.' throttler DatastoreThrottler throttle remote_datastore_stub._PreHookHandler throttler.PrehookHandlerremote_datastore_stub._PostHookHandler throttler.PosthookHandler
def make_lpdf mu sigma x T.matrix mu theano.shared mu a x.dimshuffle 0 'x' 1 - mu.dimshuffle 'x' 0 1 / sigma E log_mean_exp -0.5 * a ** 2 .sum 2 Z mu.shape[1] * T.log sigma * numpy.sqrt numpy.pi * 2 return theano.function [x] E - Z
def start_volume name force False cmd 'volumestart{0}'.format name if force cmd '{0}force'.format cmd volinfo info name if name not in volinfo log.error 'Cannotstartnon-existingvolume{0}'.format name return Falseif not force and volinfo[name]['status'] '1' log.info 'Volume{0}alreadystarted'.format name return Truereturn _gluster cmd
def _find_address_range addresses first last addresses[0]for ip in addresses[1 ] if ip._ip last._ip + 1 last ipelse breakreturn first last
def pyramid_soap11_application services tns 'spyne.simple.soap' validator None name None from spyne.protocol.soap import Soap11from spyne.server.pyramid import PyramidApplicationapplication Application services tns name name in_protocol Soap11 validator validator out_protocol Soap11 return PyramidApplication application
def test_install_package_with_root script data root_dir script.scratch_path / 'root' result script.pip 'install' '--root' root_dir '-f' data.find_links '--no-index' 'simple 1.0' normal_install_path script.base_path / script.site_packages / 'simple-1.0-py%s.egg-info' % pyversion from distutils.util import change_rootroot_path change_root os.path.join script.scratch 'root' normal_install_path assert root_path in result.files_created str result
def _is_valid_region_code region_code if region_code is None return Falsereturn region_code in SUPPORTED_REGIONS
def download_progress_hook count blockSize totalSize global last_percent_reportedpercent int count * blockSize * 100 / totalSize if last_percent_reported ! percent if percent % 5 0 sys.stdout.write '%s%%' % percent sys.stdout.flush else sys.stdout.write '.' sys.stdout.flush last_percent_reported percent
@FileSystem.in_directory current_directory 'django' 'dill' def test_use_test_database_setting for i in range 1 2 status out commands.getstatusoutput 'pythonmanage.pyharvest--settings testdbsettings' + 'leaves/features/testdb.feature' assert_equals status 0 out assert 'Harvestercount 1' in out out
def _mod_run_check cmd_kwargs onlyif unless if onlyif if __salt__['cmd.retcode'] onlyif **cmd_kwargs ! 0 return {'comment' 'onlyifexecutionfailed' 'skip_watch' True 'result' True}if unless if __salt__['cmd.retcode'] unless **cmd_kwargs 0 return {'comment' 'unlessexecutionsucceeded' 'skip_watch' True 'result' True}return True
def register_nonexistent_models_with_modm class DropboxFile MODMStoredFileNode _primary_key u'_id'passclass OSFStorageGuidFile MODMStoredFileNode _primary_key u'_id'passclass OSFGuidFile MODMStoredFileNode _primary_key u'_id'passclass GithubGuidFile MODMStoredFileNode _primary_key u'_id'passclass NodeFile MODMStoredFileNode _primary_key u'_id'passclass BoxFile MODMStoredFileNode _primary_key u'_id'passclass FigShareGuidFile MODMStoredFileNode _primary_key u'_id'passclass S3GuidFile MODMStoredFileNode _primary_key u'_id'passclass DataverseFile MODMStoredFileNode _primary_key u'_id'passDataverseFile.register_collection NodeFile.register_collection S3GuidFile.register_collection FigShareGuidFile.register_collection BoxFile.register_collection GithubGuidFile.register_collection OSFStorageGuidFile.register_collection OSFGuidFile.register_collection DropboxFile.register_collection
@service.soap 'Division' returns {'divisionResult' float} args {'a' float 'b' float} def division a b return a / b
def _fit_edges_polyfit x window_length polyorder deriv delta axis y halflen window_length // 2 _fit_edge x 0 window_length 0 halflen axis polyorder deriv delta y n x.shape[axis]_fit_edge x n - window_length n n - halflen n axis polyorder deriv delta y
def get_repository_by_id app id if is_tool_shed_client app return app.install_model.context.query app.install_model.ToolShedRepository .get app.security.decode_id id else sa_session app.model.context.currentreturn sa_session.query app.model.Repository .get app.security.decode_id id
def string_attributes domain return [attr for attr in domain.variables + domain.metas if attr.is_string]
def verify_hook_signature node_settings data headers if node_settings.hook_secret is None raise HookError 'Nosecretkey' digest hmac.new str node_settings.hook_secret data digestmod hashlib.sha1 .hexdigest signature headers.get HOOK_SIGNATURE_KEY '' .replace 'sha1 ' '' if digest ! signature raise HookError 'Invalidsignature'
def traverse_dict data key default delimiter DEFAULT_TARGET_DELIM try for each in key.split delimiter data data[each]except KeyError IndexError TypeError return defaultreturn data
def minibatches inputs None targets None batch_size None shuffle False assert len inputs len targets if shuffle indices np.arange len inputs np.random.shuffle indices for start_idx in range 0 len inputs - batch_size + 1 batch_size if shuffle excerpt indices[start_idx start_idx + batch_size ]else excerpt slice start_idx start_idx + batch_size yield inputs[excerpt] targets[excerpt]
def test_fits_hst_unit x u.Unit u'erg/s/cm**2/angstrom' assert x u.erg * u.s ** -1 * u.cm ** -2 * u.angstrom ** -1
def getcolor color mode color alpha getrgb color 255 if len color 4 color alpha color[0 3] color[3] if Image.getmodebase mode 'L' r g b colorcolor r * 299 + g * 587 + b * 114 // 1000 if mode[ -1 ] 'A' return color alpha elif mode[ -1 ] 'A' return color + alpha return color
def gists_by username number -1 etag None if username return gh.gists_by username number etag return iter []
def invoke_member obj membername *args **kwargs return getattr obj membername *args **kwargs
def fromimage im flatten False mode None if not Image.isImageType im raise TypeError 'InputisnotaPILimage.' if mode is not None if mode ! im.mode im im.convert mode elif im.mode 'P' if 'transparency' in im.info im im.convert 'RGBA' else im im.convert 'RGB' if flatten im im.convert 'F' elif im.mode '1' im im.convert 'L' a array im return a
def get_real_filter layers img_size real_filter np.zeros len layers 2 conv_mode Truefirst_conv_layer Trueexpon np.ones 1 2 for i layer in enumerate layers[1 ] j i + 1 if not conv_mode real_filter[j] img_sizecontinueif is_conv2d layer if not first_conv_layer new_filter np.array layer.filter_size * expon real_filter[j] new_filterelse new_filter np.array layer.filter_size * expon real_filter[j] new_filterfirst_conv_layer Falseelif is_maxpool2d layer real_filter[j] real_filter[i]expon * np.array layer.pool_size else conv_mode Falsereal_filter[j] img_sizereal_filter[0] img_sizereturn real_filter
def parse_query pkt length endian_int pkt[1 5] pkt pkt[5 ]query ''for i in xrange length - 4 query + pkt[i].decode 'hex' return query
def example2_build_forest x y **kwargs if kwargs['iteration'] > 0 returnroom create_object rooms.Room key 'forest' + str x + str y room.db.desc 'Basicforestroom.'kwargs['caller'].msg room.key + '' + room.dbref return room
def _handle_sigusr2 sig stack try import yappiexcept ImportError returnif yappi.is_running yappi.stop filename 'callgrind.salt-{0}-{1}'.format int time.time os.getpid destfile os.path.join tempfile.gettempdir filename yappi.get_func_stats .save destfile type 'CALLGRIND' if sys.stderr.isatty sys.stderr.write 'Savedprofilingdatato {0}\n'.format destfile yappi.clear_stats else if sys.stderr.isatty sys.stderr.write 'Profilingstarted\n' yappi.start
def utm2mgrs e n grid zeros 0 square_set int grid[ -1 ] % 6 ew_idx int e / 100000 - 1 ns_idx int n % 2000000 / 100000 ns_letters_135 'ABCDEFGHJKLMNPQRSTUV'ns_letters_246 'FGHJKLMNPQRSTUVABCDE'ew_letters_14 'ABCDEFGH'ew_letters_25 'JKLMNPQR'ew_letters_36 'STUVWXYZ'if square_set 1 square ew_letters_14[ew_idx] + ns_letters_135[ns_idx] elif square_set 2 square ew_letters_25[ew_idx] + ns_letters_246[ns_idx] elif square_set 3 square ew_letters_36[ew_idx] + ns_letters_135[ns_idx] elif square_set 4 square ew_letters_14[ew_idx] + ns_letters_246[ns_idx] elif square_set 5 square ew_letters_25[ew_idx] + ns_letters_135[ns_idx] else square ew_letters_36[ew_idx] + ns_letters_246[ns_idx] easting '%05d' % e % 100000 northing '%05d' % n % 100000 return ''.join [grid square easting[ - zeros ] northing[ - zeros ]]
def completion callback def _completion f def __completion *a **b d Nonetry d f *a **b return dfinally thread.start_new_thread callback d return __completionreturn _completion
def normalize_timedelta val if type val str val parse_timedelta val if not val return ''hr val.seconds / 3600 mn val.seconds % 3600 / 60 return '%d.%02d' % hr mn * 100 / 60
def test_prompt_should_not_ask_if_no_input_and_rm_repo_dir mocker tmpdir mock_read_user mocker.patch 'cookiecutter.vcs.read_user_yes_no' return_value True autospec True repo_dir tmpdir.mkdir 'repo' vcs.prompt_and_delete_repo str repo_dir no_input True assert not mock_read_user.called assert not repo_dir.exists
def parse_response_for_async_op response if response is None return Noneresult AsynchronousOperationResult if response.headers for name value in response.headers if name.lower 'x-ms-request-id' result.request_id valuereturn result
def setup_event_pipeline conf transformer_manager None default extension.ExtensionManager 'ceilometer.transformer' cfg_file conf.event_pipeline_cfg_filereturn PipelineManager conf cfg_file transformer_manager or default EVENT_TYPE
def _callAppFunction function try function except log.err None u'Unexpectedexceptionfrom%s' % fullyQualifiedName function
def getuserbase global USER_BASEif USER_BASE is not None return USER_BASEfrom sysconfig import get_config_varUSER_BASE get_config_var 'userbase' return USER_BASE
def check_settings base_url None if base_url is None base_url settings.STATIC_URLif not base_url raise ImproperlyConfigured "You'reusingthestaticfilesappwithouthavingsettherequiredSTATIC_URLsetting." if settings.MEDIA_URL base_url raise ImproperlyConfigured 'TheMEDIA_URLandSTATIC_URLsettingsmusthavedifferentvalues' if settings.MEDIA_ROOT and settings.STATIC_ROOT and settings.MEDIA_ROOT settings.STATIC_ROOT raise ImproperlyConfigured 'TheMEDIA_ROOTandSTATIC_ROOTsettingsmusthavedifferentvalues'
@oslo_db_api.wrap_db_retry max_retries 5 retry_on_deadlock True @pick_context_manager_writerdef compute_node_update context compute_id values compute_ref compute_node_get_model context compute_id values['updated_at'] timeutils.utcnow convert_objects_related_datetimes values compute_ref.update values return compute_ref
def show_network network profile None conn _auth profile return conn.show_network network
def test_sobel_zeros result filters.sobel np.zeros 10 10 np.ones 10 10 bool assert np.all result 0
def _fprime score x k_params alpha x_arr np.asarray x params x_arr[ k_params].ravel fprime_arr np.append score params alpha return matrix fprime_arr 1 2 * k_params
def get_debug_values *args if config.compute_test_value 'off' return []rval []for i arg in enumerate args try rval.append get_test_value arg except AttributeError if hasattr arg 'name' and arg.name is not None missing_test_message 'Argument' + str i + " '" + arg.name + "' hasnotestvalue" else missing_test_message 'Argument' + str i + 'hasnotestvalue' return []if len rval 1 return rvalreturn [tuple rval ]
def _fake_specify_ep self season episode _ self season episode
def select_formatter_class formatter_name try return _formatter_registry[formatter_name]except KeyError if ' ' not in formatter_name raisereturn load_formatter_class formatter_name
def brand return s3_rest_controller 'supply' 'brand'
def UnwrapPyTree tree unwrapper PyTreeUnwrapper unwrapper.Visit tree uwlines unwrapper.GetUnwrappedLines uwlines.sort key lambda x x.lineno return uwlines
def resolve_url to *args **kwargs if hasattr to 'get_absolute_url' return to.get_absolute_url if isinstance to Promise to force_text to if isinstance to str if to.startswith './' '../' return totry return reverse to args args kwargs kwargs except NoReverseMatch if callable to raiseif '/' not in to and '.' not in to raisereturn to
def set_challenge_for_url url challenge if not url raise ValueError 'URLcannotbeempty' if not challenge raise ValueError 'Challengecannotbeempty' src_url parse.urlparse url if src_url.netloc ! challenge.source_authority raise ValueError 'SourceURLandChallengeURLdonotmatch' _cache[src_url.netloc] challenge
def make_tags_in_proper_format tags formatted_tags dict for tag in tags formatted_tags[tag.get 'Key' ] tag.get 'Value' return formatted_tags
def _unpad_message text if not text return ''padding_size ord text[ -1 ] if padding_size > AES.block_size return '' unpadded padding text[ - padding_size ] text[ - padding_size ] if any ord x ! padding_size for x in padding return ''return unpadded
@ignore_warnings category DeprecationWarning def check_positive_definite_covars covariance_type rng np.random.RandomState 1 X rng.randn 100 2 X[ -10 ] + 3 3 gmm mixture.GMM 2 params 'wc' covariance_type covariance_type min_covar 0.001 gmm.fit X if covariance_type 'diag' or covariance_type 'spherical' assert_greater gmm.covars_.min 0 else if covariance_type 'tied' covs [gmm.covars_]else covs gmm.covars_for c in covs assert_greater np.linalg.det c 0
def captureWarnings capture global _warnings_showwarningif capture if _warnings_showwarning is None _warnings_showwarning warnings.showwarningwarnings.showwarning _showwarningelif _warnings_showwarning is not None warnings.showwarning _warnings_showwarning_warnings_showwarning None
def safe_filename filename valid_chars '-_. {}{}'.format string.ascii_letters string.digits return ''.join c for c in filename if c in valid_chars
def format_list lst locale DEFAULT_LOCALE locale Locale.parse locale if not lst return ''if len lst 1 return lst[0]if len lst 2 return locale.list_patterns['2'].format *lst result locale.list_patterns['start'].format lst[0] lst[1] for elem in lst[2 -1 ] result locale.list_patterns['middle'].format result elem result locale.list_patterns['end'].format result lst[ -1 ] return result
def hanged_process *args **kwargs def handler sig frame send 'SIGINT' signal.signal signal.SIGINT handler send 'STARTED' while True signal.pause send 'STOPPED'
def enable_deprecations_as_exceptions include_astropy_deprecations True global _deprecations_as_exceptions_deprecations_as_exceptions Trueglobal _include_astropy_deprecations_include_astropy_deprecations include_astropy_deprecations
def max_pooling_2d x ksize stride None pad 0 cover_all True use_cudnn True return MaxPooling2D ksize stride pad cover_all use_cudnn x
def _installHandlerUsingSignal fd if fd -1 previous signal.signal signal.SIGCHLD signal.SIG_DFL else previous signal.signal signal.SIGCHLD _Handler fd if isinstance previous _Handler return previous.fdreturn -1
def dereferring url fn if 'derefer.me' in url _RE_DEREFER re.compile 'content ".*url [^"]+ ">' data fn.read for line in data.split '\n' if '<meta' in line m _RE_DEREFER.search data if m return m.group 1 return None
def truncated_normal shape None mean 0.0 stddev 0.02 dtype tf.float32 seed None if shape return tf.truncated_normal shape shape mean mean stddev stddev seed seed dtype dtype else return tf.truncated_normal_initializer mean mean stddev stddev seed seed dtype dtype
def _add_lists list1 list2 if len list1 < len list2 sol [ a + b for a b in zip list1 list2 ] + list2[len list1 ] else sol [ a + b for a b in zip list1 list2 ] + list1[len list2 ] return sol
def create_table_with_all_types table_name session N alpha_type_list ['primkeyintPRIMARYKEY']col_names ['primkey']start_index ord 'a' for i datatype in enumerate PRIMITIVE_DATATYPES alpha_type_list.append '{0}{1}'.format chr start_index + i datatype col_names.append chr start_index + i session.execute 'CREATETABLE{0} {1} '.format table_name ' '.join alpha_type_list timeout 120 for key in range N params get_all_primitive_params key columns_string ' '.join col_names placeholders ' '.join ['%s'] * len col_names session.execute 'INSERTINTO{0} {1} VALUES {2} '.format table_name columns_string placeholders params timeout 120 return col_names
def _norm_siteconfig_value siteconfig key value siteconfig.get key if value in u'""' u"''" None value u''return value
def tokenize_asdl buf for lineno line in enumerate buf.splitlines 1 for m in re.finditer '\\s* \\w+|--.*|. ' line.strip c m.group 1 if c[0].isalpha if c[0].isupper yield Token TokenKind.ConstructorId c lineno else yield Token TokenKind.TypeId c lineno elif c[ 2] '--' breakelse try op_kind TokenKind.operator_table[c]except KeyError raise ASDLSyntaxError 'Invalidoperator%s' % c lineno yield Token op_kind c lineno
def libvlc_video_set_mouse_input p_mi on f _Cfunctions.get 'libvlc_video_set_mouse_input' None or _Cfunction 'libvlc_video_set_mouse_input' 1 1 None None MediaPlayer ctypes.c_uint return f p_mi on
def _makeDefaultReporter return Reporter sys.stdout sys.stderr
def new_stocks retry_count 3 pause 0.001 data pd.DataFrame ct._write_head df _newstocks data 1 retry_count pause return df
def write_best_job expt_dir best_val best_job expt_grid best_job_fh open os.path.join expt_dir 'best_job_and_result.txt' 'w' best_job_fh.write 'Bestresult %f\nJob-id %d\nParameters \n' % best_val best_job for best_params in expt_grid.get_params best_job best_job_fh.write str best_params best_job_fh.close
def Tukeythreegene2 genes means []stds []for gene in genes means.append numpy.mean gene std.append numpy.std gene stds2 []for std in stds stds2.append math.pow std 2 mserrornum sum stds2 * 2 mserrorden len genes[0] + len genes[1] + len genes[2] - 3 mserror mserrornum / mserrorden
def send_annotation_event module key msg annotated_by 'Ansible' level None instance_id None event_epoch None annotation_api 'https //event-gateway.stackdriver.com/v1/annotationevent'params {}params['message'] msgif annotated_by params['annotated_by'] annotated_byif level params['level'] levelif instance_id params['instance_id'] instance_idif event_epoch params['event_epoch'] event_epochreturn do_send_request module annotation_api params key
def __virtual__ if not HAS_ELASTICSEARCH return False 'Cannotloadmoduleelasticsearch elasticsearchlibrariesnotfound' return True
def get_all_languages def _get if not frappe.db frappe.connect return frappe.db.sql_list u'selectnamefromtabLanguage' return frappe.cache .get_value u'languages' _get
@pytest.mark.parametrize 'progress load_status expected_visible' [ 15 usertypes.LoadStatus.loading True 100 usertypes.LoadStatus.success False 100 usertypes.LoadStatus.error False 100 usertypes.LoadStatus.warn False 100 usertypes.LoadStatus.none False ] def test_tab_changed fake_web_tab progress_widget progress load_status expected_visible tab fake_web_tab progress progress load_status load_status progress_widget.on_tab_changed tab actual progress_widget.value progress_widget.isVisible expected tab.progress expected_visible assert actual expected
def authorable_xblocks allow_unsupported False name None blocks XBlockStudioConfiguration.objects.current_set .filter enabled True if not allow_unsupported blocks blocks.exclude support_level XBlockStudioConfiguration.UNSUPPORTED if name blocks blocks.filter name name return blocks
def cleanup _lib.RAND_cleanup
def test_batch_normalized_mlp_conserve_memory_propagated mlp BatchNormalizedMLP [Tanh Tanh ] [5 7 9] conserve_memory False assert not mlp.conserve_memory assert not any act.children[0].conserve_memory for act in mlp.activations mlp.conserve_memory Trueassert mlp.conserve_memoryassert all act.children[0].conserve_memory for act in mlp.activations
def new_view window text scratch False new_view window.new_file if scratch new_view.set_scratch True if is_ST3 new_view.run_command 'append' {'characters' text} else new_edit new_view.begin_edit new_view.insert new_edit 0 text new_view.end_edit new_edit return new_view
def version_autocomplete request project_slug queryset Project.objects.public request.user get_object_or_404 queryset slug project_slug versions Version.objects.public request.user if 'term' in request.GET term request.GET['term']else raise Http404version_queryset versions.filter slug__icontains term [ 20]names version_queryset.values_list 'slug' flat True json_response json.dumps list names return HttpResponse json_response content_type 'text/javascript'
def connect_ia ia_access_key_id None ia_secret_access_key None is_secure False **kwargs from boto.s3.connection import S3Connectionfrom boto.s3.connection import OrdinaryCallingFormataccess_key config.get 'Credentials' 'ia_access_key_id' ia_access_key_id secret_key config.get 'Credentials' 'ia_secret_access_key' ia_secret_access_key return S3Connection access_key secret_key host 's3.us.archive.org' calling_format OrdinaryCallingFormat is_secure is_secure **kwargs
def edit_distance s1 s2 substitution_cost 1 transpositions False len1 len s1 len2 len s2 lev _edit_dist_init len1 + 1 len2 + 1 for i in range len1 for j in range len2 _edit_dist_step lev i + 1 j + 1 s1 s2 substitution_cost substitution_cost transpositions transpositions return lev[len1][len2]
def discrete_sequence n distribution None cdistribution None import bisectif cdistribution is not None cdf cdistributionelif distribution is not None cdf cumulative_distribution distribution else raise nx.NetworkXError 'discrete_sequence distributionorcdistributionmissing' inputseq [random.random for i in range n ]seq [ bisect.bisect_left cdf s - 1 for s in inputseq]return seq
def available_on_pypi prerelease current_version.is_prerelease client xmlrpclib.ServerProxy 'https //pypi.python.org/pypi' versions client.package_releases 'pwntools' True versions map packaging.version.Version versions if not prerelease versions filter lambda v not v.is_prerelease versions return max versions
def clipMinMax size minSize maxSize return size.expandedTo minSize .boundedTo maxSize
def _compute_proj A U _ _ linalg.svd A full_matrices False return np.identity A.shape[0] - np.dot U U.T.conjugate
def iterateInReactor i from twisted.internet import reactord defer.Deferred def go last try r i.next except StopIteration d.callback last except d.errback else if isinstance r defer.Deferred r.addCallback go else reactor.callLater 0 go r go None return d
def set_margin layout margin layout.setContentsMargins margin margin margin margin
def license_list context data_dict model context['model']_check_access 'license_list' context data_dict license_register model.Package.get_license_register licenses license_register.values licenses [l.as_dict for l in licenses]return licenses
def perspective fovy aspect znear zfar assert znear ! zfar h math.tan fovy / 360.0 * math.pi * znear w h * aspect return frustum - w w - h h znear zfar
def _image_mode backup_mode return backup_mode 'image'
def rcollect expr *vars if expr.is_Atom or not expr.has *vars return exprelse expr expr.__class__ *[rcollect arg *vars for arg in expr.args] if expr.is_Add return collect expr vars else return expr
def validate_positive_float option value errmsg '%smustbeanintegerorfloat' % option try value float value except ValueError raise ValueError errmsg except TypeError raise TypeError errmsg if not 0 < value < 1000000000.0 raise ValueError '%smustbegreaterthan0andlessthanonebillion' % option return value
@commands u'action' @example u'.actioneladwilldevelopameetbot' def meetingaction bot trigger if not ismeetingrunning trigger.sender bot.say u"Can'tdothat startmeetingfirst" returnif not trigger.group 2 bot.say u'try.actionsomeonewilldosomething' returnif not ischair trigger.nick trigger.sender bot.say u'Onlymeetingheadorchairscandothat' returnlogplain u'ACTION ' + trigger.group 2 trigger.sender logHTML_listitem u'<spanstyle "font-weight bold">Action </span>' + trigger.group 2 trigger.sender meeting_actions[trigger.sender].append trigger.group 2 bot.say u'\x02ACTION\x0f ' + trigger.group 2
def _submit_hadoop_job_resp project None cluster None script_name None now None project project or _TEST_PROJECT cluster cluster or _DATAPROC_CLUSTER script_name script_name or _SCRIPT_NAME now now or datetime.utcnow job_elements [script_name _USER_NAME now.strftime '%Y%m%d' now.strftime '%H%M%S' now.strftime '%f' ]job_id '-'.join job_elements + ['-' 'Step' '1' 'of' '1'] dir_name '.'.join job_elements mock_response {'reference' {'projectId' project 'jobId' job_id} 'placement' {'clusterName' cluster 'clusterUuid' '8b76d95e-ebdc-4b81-896d-b2c5009b3560'} 'hadoopJob' {'mainJarFileUri' 'file ///usr/lib/hadoop-mapreduce/hadoop-streaming.jar' 'args' [] 'loggingConfig' {}} 'status' {'state' 'PENDING' 'stateStartTime' _datetime_to_gcptime now } 'driverControlFilesUri' 'gs //dataproc-801485be-0997-40e7-84a7-00926031747c-us/google-cloud-dataproc-metainfo/8b76d95e-ebdc-4b81-896d-b2c5009b3560/jobs/% job_id s/' % locals 'driverOutputResourceUri' 'gs //dataproc-801485be-0997-40e7-84a7-00926031747c-us/google-cloud-dataproc-metainfo/8b76d95e-ebdc-4b81-896d-b2c5009b3560/jobs/% job_id s/driveroutput' % locals }return mock_response
def test_colormap_reversing for name in cm.cmap_d cmap plt.get_cmap name cmap_r cmap.reversed if not cmap_r._isinit cmap._init cmap_r._init assert_array_almost_equal cmap._lut[ -3 ] cmap_r._lut[ -4 -1 ]
def or_ a b return a | b
def expand_gufunc_template template indims outdims funcname argdims indims + outdims argnames ['arg{0}'.format i for i in range len argdims ]checkedarg 'min {0} '.format ' '.join ['{0}.shape[0]'.format a for a in argnames] inputs [_gen_src_for_indexing aref adims _gen_src_for_input_indexing for aref adims in zip argnames indims ]outputs [_gen_src_for_indexing aref adims _gen_src_for_output_indexing for aref adims in zip argnames[len indims ] outdims ]argitems inputs + outputs src template.format name funcname args ' '.join argnames checkedarg checkedarg argitems ' '.join argitems return src
def copy_location new_node old_node for attr in 'lineno' 'col_offset' if attr in old_node._attributes and attr in new_node._attributes and hasattr old_node attr setattr new_node attr getattr old_node attr return new_node
def find_caller stack for frame in stack module inspect.getmodule frame[0] if not hasattr module u'__name__' continueif module.__name__.startswith u'sqlalchemy' continuereturn module.__name__ + tuple frame[2 4] + frame[4][0].strip log.warning u'Transactionfromunknownorigin' return None None None None
def assertReadFromAll testcase client members *args **kwargs members set members used set for _ in range 100 used.add read_from_which_host client *args **kwargs testcase.assertEqual members used
def get_desktop_uri_prefix global _uri_prefixif _uri_prefix is None dt_host desktop.conf.HTTP_HOST.get if dt_host '0.0.0.0' dt_host socket.getfqdn protocol desktop.conf.is_https_enabled and 'https' or 'http' _uri_prefix '%s //%s %s' % protocol dt_host desktop.conf.HTTP_PORT.get return _uri_prefix
def _multilingual function *args **kwargs return getattr _module kwargs.pop 'language' 'en' function *args **kwargs
@login_required@require_http_methods ['GET'] def finish_auth request return render_to_response 'student_account/finish_auth.html' {'disable_courseware_js' True 'disable_footer' True}
def _id_or_key list_item if isinstance list_item dict if 'id' in list_item return list_item['id']if 'key' in list_item return list_item['key']return list_item
def gen_even_slices n n_packs n_samples None start 0if n_packs < 1 raise ValueError 'gen_even_slicesgotn_packs %s mustbe> 1' % n_packs for pack_num in range n_packs this_n n // n_packs if pack_num < n % n_packs this_n + 1if this_n > 0 end start + this_n if n_samples is not None end min n_samples end yield slice start end None start end
def _versionTuple versionStr try v versionStr.strip '.' + '.0.0.0' .split '.' [ 3]except AttributeError ValueError raise ValueError 'Badversionstring `{}`'.format versionStr return int v[0] int v[1] int v[2]
def addXMLLine line xmlLines strippedLine line.strip if strippedLine[ len '<!--' ] '<!--' endIndex line.find '-->' if endIndex ! -1 endIndex + len '-->' commentLine line[ endIndex]remainderLine line[endIndex ].strip if len remainderLine > 0 xmlLines.append commentLine xmlLines.append remainderLine returnxmlLines.append line
def CloseExpression clean_lines linenum pos line clean_lines.elided[linenum]startchar line[pos]if startchar not in ' {[<' return line clean_lines.NumLines -1 if startchar ' ' endchar ' 'if startchar '[' endchar ']'if startchar '{' endchar '}'if startchar '<' endchar '>' end_pos num_open FindEndOfExpressionInLine line pos 0 startchar endchar if end_pos > -1 return line linenum end_pos while linenum < clean_lines.NumLines - 1 linenum + 1line clean_lines.elided[linenum] end_pos num_open FindEndOfExpressionInLine line 0 num_open startchar endchar if end_pos > -1 return line linenum end_pos return line clean_lines.NumLines -1
def aliased element alias None name None flat False adapt_on_names False if isinstance element expression.FromClause if adapt_on_names raise sa_exc.ArgumentError 'adapt_on_namesonlyappliestoORMelements' return element.alias name flat flat else return AliasedClass element alias alias flat flat name name adapt_on_names adapt_on_names
def _check_config config if not _valid_dict config return True '' _community config.get 'community' _community_tmp {}if not _community return False 'Mustspecifyatleastacommunity.' if _valid_str _community _community_tmp[_community] _community_defaults elif isinstance _community list for _comm in _community if _valid_str _comm _community_tmp[_comm] _community_defaults if _valid_dict _comm for _comm_name _comm_details in six.iteritems _comm if _valid_str _comm_name _community_tmp[_comm_name] _clear_community_details _comm_details elif _valid_dict _community for _comm_name _comm_details in six.iteritems _community if _valid_str _comm_name _community_tmp[_comm_name] _clear_community_details _comm_details else return False 'Pleasespecifyacommunityoralistofcommunities.' if not _valid_dict _community_tmp return False 'Pleasespecifyatleastavalidcommunity!' config['community'] _community_tmpfor key in ['location' 'contact' 'chassis_id'] _str_elem config key return True ''
def _assert_vhd_not_hidden path query_cmd 'vhd-utilquery-n% path s-f' % locals query_proc make_subprocess query_cmd stdout True stderr True out err finish_subprocess query_proc query_cmd for line in out.splitlines if line.startswith 'hidden' value line.split ' ' [1].strip if value '1' raise Exception 'VHD% path sismarkedashiddenwithoutchild' % locals
def _netmaskToPrefixlen netmask netlen _count0Bits netmask masklen _count1Bits netmask _checkNetmask netmask masklen return masklen - netlen
def sitrep return s3_rest_controller
def commit_index object_store index return commit_tree object_store index.iterblobs
def subDict d allowedkeys flip False res {}for k v in list d.items if k in allowedkeys ^ flip res[k] vreturn res
def _pre_startup _setup_logging if _options.verbose logging.getLogger .setLevel logging.DEBUG if _options.enable_openflow pox.openflow.launch
def parse_config_h fp g None if g is None g {}define_rx re.compile '#define [A-Z][A-Za-z0-9_]+ .* \n' undef_rx re.compile '/[*]#undef [A-Z][A-Za-z0-9_]+ [*]/\n' while 1 line fp.readline if not line breakm define_rx.match line if m n v m.group 1 2 try v int v except ValueError passg[n] velse m undef_rx.match line if m g[m.group 1 ] 0return g
def load_bytes buf num pos end pos + num if end > len buf raise BadRarFile 'cannotloadbytes' return buf[pos end] end
def test_install_from_wheel_no_deps script data package data.packages.join 'requires_source-1.0-py2.py3-none-any.whl' result script.pip 'install' '--no-index' '--find-links' data.find_links '--no-deps' package pkg_folder script.site_packages / 'source' assert pkg_folder not in result.files_created
def require_context f def wrapper *args **kwargs nova.context.require_context args[0] return f *args **kwargs return wrapper
def dots_to_camel_case dots def return_upper match return match.groups [0].upper return str DOTS.sub return_upper dots
def _make_values_bytes dict_ return {k six.b v for k v in dict_.items }
def _match_emr_step_syslog_path path step_id None return _match_emr_step_log_path path 'syslog' step_id step_id
def clone_design request design_id design authorized_get_design request design_id if design is None LOG.error 'Cannotclonenon-existentdesign%s' % design_id return list_designs request copy design.clone request.user copy.save name copy.name + '-copy' design.doc.get .copy content_object copy name name owner request.user messages.info request _ 'Copieddesign % name s' % {'name' design.name} return format_preserving_redirect request reverse get_app_name request + ' execute_design' kwargs {'design_id' copy.id}
def usd value return Money value u'USD'
def _dot x y if isinstance x np.ndarray and isinstance y np.ndarray return np.dot x y elif sparse.issparse x return x.dot y elif sparse.issparse y return y.T.dot x.T .T
def register_rebroadcast_c_code typ code version Rebroadcast.c_code_and_version[typ] code version
def iterated_wiener noisy_img size 3 noisy_img noisy_imgdenoised_img local_mean noisy_img size size l_var local_var noisy_img size size for i in range 3 res noisy_img - denoised_img noise res ** 2 .sum / res.size noise_level 1 - noise / l_var noise_level[ noise_level < 0 ] 0denoised_img + noise_level * res return denoised_img
def DEFINE_multi parser serializer name default help flag_values FLAGS **args DEFINE_flag MultiFlag parser serializer name default help **args flag_values
def DestroyInteractiveWindow global editif edit is not None and edit.currentView is not None if edit.currentView.GetParentFrame win32ui.GetMainFrame passelse edit.Close edit None
def process_figure_for_rasterizing fig bbox_inches_restore fixed_dpi None bbox_inches restore_bbox bbox_inches_restorerestore_bbox r adjust_bbox fig bbox_inches fixed_dpi return bbox_inches r
def _get_name type_ value return type_._VALUES_TO_NAMES[value] if value is not None else u'None'
def extract_params raw if isinstance raw bytes_type or isinstance raw unicode_type try params urldecode raw except ValueError params Noneelif hasattr raw u'__iter__' try dict raw except ValueError params Noneexcept TypeError params Noneelse params list raw.items if isinstance raw dict else raw params decode_params_utf8 params else params Nonereturn params
def notify_list_user_subscribed e target e['target']if target['screen_name'] ! c['original_name'] returnsource e['source']target_object [e['target_object']]created_at e['created_at']source_user cycle_color source['name'] + color_func c['NOTIFICATION']['source_nick'] '@' + source['screen_name'] notify color_func c['NOTIFICATION']['notify'] 'subscribedtoyourlist' date parser.parse created_at clock fallback_humanize date clock color_func c['NOTIFICATION']['clock'] clock meta c['NOTIFY_FORMAT']meta source_user.join meta.split '#source_user' meta notify.join meta.split '#notify' meta clock.join meta.split '#clock' meta emojize meta printNicely '' printNicely meta print_list target_object noti True
def _api_get_cats name output kwargs return report output keyword 'categories' data list_cats False
def is_installed return get_binstar is not None
def parse_timedelta val if not val return Noneval val.lower if '.' in val val float val return timedelta hours int val minutes 60 * val % 1.0 fHour 'h' in val or ' ' in val fMin 'm' in val or ' ' in val for noise in 'minu teshour ' val val.replace noise '' val val.strip val val.split hr 0.0mi 0val.reverse if fHour hr int val.pop if fMin mi int val.pop if len val > 0 and not hr hr int val.pop return timedelta hours hr minutes mi
def PackKey name value pbvalue ref value._Key__referencepbvalue.mutable_referencevalue .set_app ref.app SetNamespace pbvalue.mutable_referencevalue ref.name_space for elem in ref.path .element_list pbvalue.mutable_referencevalue .add_pathelement .CopyFrom elem
def create_verifier_for_dsa signature hash_method public_key return public_key.verifier signature hash_method
def bzr_wc_version test 'bzr_wc_version'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric.api import runfrom fabtools.files import is_dirfrom fabtools import requireassert not is_dir wt require.bazaar.working_copy REMOTE_URL wt version '2' assert_wc_exists wt assert run 'bzrrevno%s' % wt '2'
def _get_systemd_services contextkey 'systemd.systemd_services'if contextkey in __context__ return __context__[contextkey]ret set for path in SYSTEM_CONFIG_PATHS + LOCAL_CONFIG_PATH if os.access path os.R_OK and not os.path.islink path for fullname in os.listdir path try unit_name unit_type fullname.rsplit '.' 1 except ValueError continueif unit_type in VALID_UNIT_TYPES ret.add unit_name if unit_type 'service' else fullname __context__[contextkey] copy.deepcopy ret return ret
def get_id_from_href href return urlparse.urlsplit '%s' % href .path.split '/' [ -1 ]
def get_implementation cls return symbol_by_name cls ALIASES
def human_seconds_short interval interval int interval return u'%i %02i' % interval // 60 interval % 60
def get_obj_in_list obj_name obj_list for o in obj_list if o.name obj_name return oprint 'Unabletofindobjectbythenameof%sinlist \n%s' % o.name map lambda o o.name obj_list exit 1
def get_foreign_struct namespace name get_foreign_module namespace try return ForeignStruct.get namespace name except KeyError raise ForeignError 'Foreign%s.%snotsupported' % namespace name
def copy_header_subset from_r to_r condition for k v in from_r.headers.items if condition k to_r.headers[k] v
def compression_level n q oversampling 10 min_subspace_size 20 return min max min_subspace_size q + oversampling n
def p_jump_statement_3 t pass
def firstmethod method on_call None def _matcher it *args **kwargs for obj in it try meth getattr maybe_evaluate obj method reply on_call meth *args **kwargs if on_call else meth *args **kwargs except AttributeError passelse if reply is not None return replyreturn _matcher
def s_one_pre topics s_one_pre []for top_words in topics s_one_pre_t []for w_prime_index w_prime in enumerate top_words[1 ] for w_star in top_words[ w_prime_index + 1 ] s_one_pre_t.append w_prime w_star s_one_pre.append s_one_pre_t return s_one_pre
def mapping_delete index doc_type hosts None profile None es _get_instance hosts profile try result es.indices.delete_mapping index index doc_type doc_type if result.get 'acknowledged' False return Trueexcept elasticsearch.exceptions.NotFoundError return Nonereturn None
def generate_pools cidr gateway_ip net netaddr.IPNetwork cidr ip_version net.versionfirst netaddr.IPAddress net.first ip_version last netaddr.IPAddress net.last ip_version if first last return [netaddr.IPRange first last ]first_ip first + 1 last_ip last - ip_version 4 if first_ip > last_ip return []ipset netaddr.IPSet netaddr.IPRange first_ip last_ip if gateway_ip ipset.remove netaddr.IPAddress gateway_ip ip_version return list ipset.iter_ipranges
def recommend username users nearest computeNearestNeighbor username users [0][1]recommendations []neighborRatings users[nearest]userRatings users[username]for artist in neighborRatings if not artist in userRatings recommendations.append artist neighborRatings[artist] return sorted recommendations key lambda artistTuple artistTuple[1] reverse True
def getManipulatedPaths close loop prefix sideLength xmlElement scalePoints loop prefix xmlElement return [loop]
def i0 x return tt.switch tt.lt x 5 1 + x ** 2 / 4 + x ** 4 / 64 + x ** 6 / 2304 + x ** 8 / 147456 + x ** 10 / 14745600 + x ** 12 / 2123366400 np.e ** x / 2 * np.pi * x ** 0.5 * 1 + 1 / 8 * x + 9 / 128 * x ** 2 + 225 / 3072 * x ** 3 + 11025 / 98304 * x ** 4
def _nice_case line l line.lower s ''i 0nextCap 1while i < len l c l[i]if c > 'a' and c < 'z' and nextCap c c.upper nextCap 0elif c '' or c '.' or c ' ' or c ';' or c ' ' or c ' DCTB ' or c '-' or c '_' nextCap 1s + ci + 1return s
def convert_dtypes dtype_template order_code dtypes dtype_template.copy for k in dtypes dtypes[k] np.dtype dtypes[k] .newbyteorder order_code return dtypes
def _create_url_with_params params None controller None action None extras None if not controller controller c.controllerif not action action c.actionif not extras extras {}url url_for controller controller action action **extras return _url_with_params url params
def test_nm2_fit_sample_auto ratio 'auto'nm2 NearMiss ratio ratio random_state RND_SEED version VERSION_NEARMISS X_resampled y_resampled nm2.fit_sample X Y X_gt np.array [[0.91464286 1.61369212] [ -0.80809175 -1.09917302 ] [ -0.20497017 -0.26630228 ] [ -0.05903827 0.10947647] [0.03142011 0.12323596] [ -0.60413357 0.24628718] [0.50701028 -0.17636928 ] [0.4960075 0.86130762] [0.45713638 1.31069295]] y_gt np.array [0 0 0 1 1 1 2 2 2] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def request_user_has_webhook_permission permission_type from st2common.models.db.webhook import WebhookDBdef decorate func @wraps func def func_wrapper *args **kwargs hook '/'.join args[1 ] webhook_db WebhookDB name hook resource_db webhook_dbutils.assert_request_user_has_resource_db_permission request pecan.request resource_db resource_db permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def getRoutes app for rule in app._url_map.iter_rules methods rule.methods.difference ['HEAD'] path translate_werkzeug_rule rule.rule attributes vars app._endpoints[rule.endpoint] .copy if 'segment_count' in attributes del attributes['segment_count'] yield KleinRoute methods methods path path endpoint rule.endpoint attributes attributes
def test_matching_should_be_case_insensitive completer text u'foo'collection [u'Foo' u'FOO' u'fOO']matches completer.find_matches text collection assert len matches 3
def validate_maximum value maximum if maximum is not None and value > maximum raise ValueError u'%rmustbesmallerthan%r.' % value maximum
def check_known_host user None hostname None key None fingerprint None config None port None if not hostname return {'status' 'error' 'error' 'hostnameargumentrequired'}if not user config config or '/etc/ssh/ssh_known_hosts' else config config or '.ssh/known_hosts' known_host get_known_host user hostname config config port port if not known_host or 'fingerprint' not in known_host return 'add'if key return 'exists' if key known_host['key'] else 'update' elif fingerprint return 'exists' if fingerprint known_host['fingerprint'] else 'update' else return 'exists'
def b64decode data if isinstance data six.string_types try data data.encode 'ascii' except UnicodeEncodeError raise ValueError 'unicodeargumentshouldcontainonlyASCIIcharacters' elif not isinstance data six.binary_type raise TypeError 'argumentshouldbeastrorunicode' return base64.urlsafe_b64decode data + ' ' * 4 - len data % 4
def GammaInverse name a b return rv name GammaInverseDistribution a b
def record_present name zone type data profile zones libcloud_dns_module.list_zones profile try matching_zone [z for z in zones if z.domain zone ][0]except IndexError return state_result False 'Couldnotlocatezone' records libcloud_dns_module.list_records matching_zone.id profile matching_records [record for record in records if record.name name and record.type type and record.data data ]if len matching_records 0 result libcloud_dns_module.create_record name matching_zone.id type data profile return state_result result 'Creatednewrecord' else return state_result True 'Recordalreadyexists'
def connectAcknowledge a TpPd pd 3 b MessageType mesType 15 packet a / b return packet
def set_cache_headers f @functools.wraps f def wrapper *args **kwargs ttl 31536000expires datetime.datetime.fromtimestamp int time.time + ttl expires expires.strftime '%a %d%b%Y%H %M %SGMT' headers {'Cache-Control' 'public max-age {0}'.format ttl 'Expires' expires 'Last-Modified' 'Thu 01Jan197000 00 00GMT'}if 'If-Modified-Since' in flask.request.headers return flask.Response status 304 headers headers kwargs['headers'] headersreturn f *args **kwargs return wrapper
def instantiate_bears section local_bear_list global_bear_list file_dict message_queue console_printer local_bear_list [bear for bear in filter_raising_callables local_bear_list RuntimeError section message_queue timeout 0.1 ]global_bear_list [bear for bear in filter_raising_callables global_bear_list RuntimeError file_dict section message_queue timeout 0.1 ]return local_bear_list global_bear_list
def _points_table for i in range 256 for j in itertools.repeat i 256 yield j
def check_pairs func pairs name getattr func 'func_name' getattr func '__name__' '<unknown>' for inp expected in pairs out func inp assert out expected pair_fail_msg.format name inp expected out
def _check_extension_attrs cls extends cls.__extends__eattrs extends.Attributescattrs cls.Attributesckeys set [k for k in vars cls.Attributes if not k.startswith '_' ] ekeys set [k for k in vars extends.Attributes if not k.startswith '_' ] diff set for k in ckeys | ekeys if getattr eattrs k None ! getattr cattrs k None diff.add k attr_names ATTR_NAMES[cls]retval Nonewhile extends is not None retval extendsif len diff & attr_names > 0 return extendsextends extends.__extends__return retval
def get_asset_url module path return '{}/{}/{}'.format settings.STATIC_URL.rstrip '/' module path
def HT_DCPHASE ds count return call_talib_with_ds ds count talib.HT_DCPHASE
def _colonHex val bytecount pieces []for i in range bytecount - 1 -1 -1 piece 255 << i * 8 & val >> i * 8 pieces.append '%02x' % piece chStr ' '.join pieces return chStr
def host_info host None data query host quiet True for id_ in data if 'vm_info' in data[id_] data[id_].pop 'vm_info' __jid_event__.fire_event {'data' data 'outputter' 'nested'} 'progress' return data
def test_read_right_indented_table table '\n#comment withblanklineabove \n \nCol1Col2Col3\n \n33.4foo\n14.5bar\n \n'reader ascii.get_reader Reader ascii.RST dat reader.read table assert_equal dat.colnames ['Col1' 'Col2' 'Col3'] assert_equal dat[0][2] 'foo' assert_equal dat[1][0] 1
def spectral_clustering affinity n_clusters 8 n_components None eigen_solver None random_state None n_init 10 eigen_tol 0.0 assign_labels 'kmeans' if assign_labels not in 'kmeans' 'discretize' raise ValueError "The'assign_labels'parametershouldbe'kmeans'or'discretize' but'%s'wasgiven" % assign_labels random_state check_random_state random_state n_components n_clusters if n_components is None else n_components maps spectral_embedding affinity n_components n_components eigen_solver eigen_solver random_state random_state eigen_tol eigen_tol drop_first False if assign_labels 'kmeans' _ labels _ k_means maps n_clusters random_state random_state n_init n_init else labels discretize maps random_state random_state return labels
def masscan_x509 output certificate output.decode 'base64' newout []for hashtype hashname in [ 'md5' 'MD5 ' 'sha1' 'SHA-1 ' ] hashvalue hashlib.new hashtype cert .hexdigest newout.append '%-7s%s\n' % hashname ''.join hashvalue[i i + 4 ] for i in xrange 0 len hashvalue 4 b64cert certificate.encode 'base64' newout.append '-----BEGINCERTIFICATE-----\n' newout.extend '%s\n' % b64cert[i i + 64 ] for i in xrange 0 len b64cert 64 newout.append '-----ENDCERTIFICATE-----\n' return ''.join newout
def test_get_moon_nonscalar_regression times Time [u'2015-08-2803 30' u'2015-09-0510 30'] get_moon times ephemeris u'builtin'
def fix_call callable *args **kw try val callable *args **kw except TypeError exc_info fix_type_error None callable args kw reraise *exc_info return val
def _a_encode_unicode value mapping assert isinstance value unicode 'VALUEhasinvalidtype %s' % type value value value.encode 'UTF-8' return str len value .encode 'UTF-8' 's' value
@login_required@require_POSTdef join_contributors request next get_next_url request or reverse 'home' group Group.objects.get name 'Contributors' request.user.groups.add group messages.add_message request messages.SUCCESS _ 'YouarenowpartoftheContributorsgroup!' return HttpResponseRedirect next
def _translate string return string
def dehydrate_rating rating_class rating rating_class if rating.label is None rating.label str rating.age or slugify_iarc_name rating if rating.name is None if rating.age 0 rating.name unicode NAME_GENERAL else rating.name unicode NAME_LAZY % rating.age rating.name unicode rating.name return rating
def delete_virtual_disk si vm_obj disk_number hdd_prefix_label 'Harddisk'hdd_label hdd_prefix_label + str disk_number virtual_hdd_device Nonefor dev in vm_obj.config.hardware.device if isinstance dev vim.vm.device.VirtualDisk and dev.deviceInfo.label hdd_label virtual_hdd_device devif not virtual_hdd_device raise RuntimeError 'Virtual{}couldnotbefound.'.format virtual_hdd_device virtual_hdd_spec vim.vm.device.VirtualDeviceSpec virtual_hdd_spec.operation vim.vm.device.VirtualDeviceSpec.Operation.removevirtual_hdd_spec.device virtual_hdd_devicespec vim.vm.ConfigSpec spec.deviceChange [virtual_hdd_spec]task vm_obj.ReconfigVM_Task spec spec tasks.wait_for_tasks si [task] return True
def _parallel_dict_from_expr exprs opt if opt.expand is not False exprs [expr.expand for expr in exprs]if any expr.is_commutative is False for expr in exprs raise PolynomialError 'non-commutativeexpressionsarenotsupported' if opt.gens reps gens _parallel_dict_from_expr_if_gens exprs opt else reps gens _parallel_dict_from_expr_no_gens exprs opt return reps opt.clone {'gens' gens}
def _letter_to_number letter return ord letter - 96
def get_sample datatype return SAMPLE_DATA[datatype]
def ancestor_has_staff_lock xblock parent_xblock None if parent_xblock is None parent_location modulestore .get_parent_location xblock.location revision ModuleStoreEnum.RevisionOption.draft_preferred if not parent_location return Falseparent_xblock modulestore .get_item parent_location return parent_xblock.visible_to_staff_only
def difflist list1 list2 diff []for x in list2 if x not in list1 diff.append x return diff
def default_bucket_name return files._default_gs_bucket_name
def test_require_file_from_string from fabtools.require import file as require_filetry bar_contents 'Thisisthecontentsofthebarfile'require_file 'bar' contents bar_contents assert is_file 'bar' assert run 'catbar' bar_contents finally run 'rm-fbar'
def requireUpgrade obj objID id obj if objID in versionedsToUpgrade and objID not in upgraded upgraded[objID] 1obj.versionUpgrade return obj
def gitlab_notifier registry xml_parent data XML.SubElement xml_parent 'com.dabsquared.gitlabjenkins.publisher.GitLabCommitStatusPublisher'
def show_error string params None strip True indent None string text.format string params strip strip indent indent sublime.error_message u'PackageControl\n\n%s' % string
def Help return _STYLE_HELP
def shell_expand path expand_relative_paths False if path path os.path.expanduser os.path.expandvars path if expand_relative_paths and not path.startswith '/' if 'CONFIG_FILE' in globals CFGDIR os.path.dirname CONFIG_FILE path os.path.join CFGDIR path path os.path.abspath path return path
@blueprint.route '/<job_id>.json' methods ['GET'] @blueprint.route '/<job_id>' methods ['GET'] def show job_id job scheduler.get_job job_id if job is None raise werkzeug.exceptions.NotFound 'Jobnotfound' related_jobs scheduler.get_related_jobs job if request_wants_json return flask.jsonify job.json_dict True elif isinstance job model_images.ImageClassificationModelJob return model_images.classification.views.show job related_jobs related_jobs elif isinstance job model_images.GenericImageModelJob return model_images.generic.views.show job related_jobs related_jobs else raise werkzeug.exceptions.BadRequest 'Invalidjobtype'
def urlencode query if isinstance query dict query query.items return u'&'.join [u' '.join [escape k escape v ] for k v in query]
def check_returncode p out code p.returncodeif code 0 returnerrmap [None RarWarning RarFatalError RarCRCError RarLockedArchiveError RarWriteError RarOpenError RarUserError RarMemoryError RarCreateError RarNoFilesError RarWrongPassword]if UNRAR_TOOL ALT_TOOL errmap [None]if code > 0 and code < len errmap exc errmap[code]elif code 255 exc RarUserBreakelif code < 0 exc RarSignalExitelse exc RarUnknownErrorif out msg '%s[%d] %s' % exc.__doc__ p.returncode out else msg '%s[%d]' % exc.__doc__ p.returncode raise exc msg
@utils.decoratordef non_transactional func args kwds allow_existing True from . import taskletsctx tasklets.get_context if not ctx.in_transaction return func *args **kwds if not allow_existing raise datastore_errors.BadRequestError '%scannotbecalledwithinatransaction.' % func.__name__ save_ctx ctxwhile ctx.in_transaction ctx ctx._parent_contextif ctx is None raise datastore_errors.BadRequestError 'Contextwithoutnon-transactionalancestor' save_ds_conn datastore._GetConnection try if hasattr save_ctx '_old_ds_conn' datastore._SetConnection save_ctx._old_ds_conn tasklets.set_context ctx return func *args **kwds finally tasklets.set_context save_ctx datastore._SetConnection save_ds_conn
def _authenticate_x509 credentials sock_info query SON [ 'authenticate' 1 'mechanism' 'MONGODB-X509' ] if credentials.username is not None query['user'] credentials.usernameelif sock_info.max_wire_version < 5 raise ConfigurationError 'AusernameisrequiredforMONGODB-X509authenticationwhenconnectedtoMongoDBversionsolderthan3.4.' sock_info.command '$external' query
@pytest.mark.parametrize 'fast_writer' [True False] def test_strip_names fast_writer data table.Table [[1] [2] [3]] names 'A' 'B' 'C' out StringIO ascii.write data out format 'csv' fast_writer fast_writer assert out.getvalue .splitlines [0] 'A B C'
def _dual_gap emp_cov precision_ alpha gap np.sum emp_cov * precision_ gap - precision_.shape[0]gap + alpha * np.abs precision_ .sum - np.abs np.diag precision_ .sum return gap
def windowsize folder size None fsr Carbon.File.FSRef folder folder_alias fsr.FSNewAliasMinimal openwindow fsr if not size return _getwindowsize folder_alias return _setwindowsize folder_alias size
def test_is_method assert not hug.introspect.is_method function_with_kwargs assert hug.introspect.is_method Object .my_method
def _get_subclasses cls for i in cls.__subclasses__ for c in _get_subclasses i yield c yield cls
def str_slice_replace arr start None stop None repl None if repl is None repl ''def f x if x[start stop] '' local_stop startelse local_stop stopy ''if start is not None y + x[ start]y + replif stop is not None y + x[local_stop ]return yreturn _na_map f arr
def _preorder_traverse root get_children def dfs elem yield elem for v in get_children elem for u in dfs v yield u for elem in dfs root yield elem
def UninstallDriver bundle_name km objc.KextManager cf_bundle_name km.PyStringToCFString bundle_name status km.iokit.KextManagerUnloadKextWithIdentifier cf_bundle_name km.dll.CFRelease cf_bundle_name return status
def obj_registries cls registryname None if registryname return registryname return cls.__registries__
def TestResult_addSkipped self test err self.skipped.append test str err[1]
def query_params *es_query_params def _wrapper func @wraps func def _wrapped *args **kwargs params {}if u'params' in kwargs params kwargs.pop u'params' .copy for p in es_query_params + GLOBAL_PARAMS if p in kwargs v kwargs.pop p if v is not None params[p] _escape v for p in u'ignore' u'request_timeout' if p in kwargs params[p] kwargs.pop p return func params params *args **kwargs return _wrappedreturn _wrapper
def print_benchmark elapsed print '%-7.2f%s' % elapsed 'secondselapsed' keys ['directories' 'files' 'logicallines' 'physicallines']for key in keys if key in options.counters print '%-7d%spersecond %dtotal ' % options.counters[key] / elapsed key options.counters[key]
def get_random_user users_count Profile.objects.all .count random_index randint 0 users_count - 1 return Profile.objects.all [random_index]
def saltenviron environ if '__opts__' not in locals import salt.config__opts__ salt.config.client_config os.environ.get 'SALT_MASTER_CONFIG' '/etc/salt/master' environ['SALT_OPTS'] __opts__environ['SALT_APIClient'] salt.netapi.NetapiClient __opts__
def _parse_pem_key raw_key_input offset raw_key_input.find '-----BEGIN' if offset ! -1 return raw_key_input[offset ]
def grey_opening input size None footprint None structure None output None mode 'reflect' cval 0.0 origin 0 tmp grey_erosion input size footprint structure None mode cval origin return grey_dilation tmp size footprint structure output mode cval origin
def get_theme_base_dirs theme theme_dirs theme_paths []for _dir in theme_dirs for dir_name in {theme}.intersection os.listdir _dir if is_theme_dir Path _dir / dir_name theme_paths.append Path _dir / dir_name return theme_paths
@with_setup prepare_stdout def test_output_snippets_with_groups_within_redundant_quotes runner Runner feature_name 'redundant-steps-quotes' verbosity 3 no_color True runner.run assert_stdout_lines u'\nFeature avoidduplicatingsamesnippet#tests/functional/output_features/redundant-steps-quotes/redundant-steps-quotes.feature 1\n\nScenario Proposematchedgroups#tests/functional/output_features/redundant-steps-quotes/redundant-steps-quotes.feature 2\nGivenIhave"stuffhere"and"more@#$%\u02c6&bizarsutffh3r3"#tests/functional/output_features/redundant-steps-quotes/redundant-steps-quotes.feature 3 undefined \nGivenIhave"blablabla"and"12345"#tests/functional/output_features/redundant-steps-quotes/redundant-steps-quotes.feature 4 undefined \n\n1feature 0passed \n1scenario 0passed \n2steps 2undefined 0passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u\'GivenIhave" [^"]* "and" [^"]* "\' \ndefgiven_i_have_group1_and_group2 step group1 group2 \nassertFalse \'Thisstepmustbeimplemented\'\n'
def available_versions url session None **kwargs if not session session client_session.Session._construct kwargs return _discover.get_version_data session url
def elapsed_time_to_string elapsed include_millis True prefix ''if elapsed < 0 prefix '-'elapsed abs elapsed if include_millis return prefix + _elapsed_time_to_string elapsed return prefix + _elapsed_time_to_string_without_millis elapsed
def find_with_default node path default v node.find path if v is not None return v.textelse return default
def list_ipsec_site_connections profile None conn _auth profile return conn.list_ipsec_site_connections
@_restore_ownershipdef create_key key_type 'RSA' key_length 1024 name_real 'AutogeneratedKey' name_comment 'GeneratedbySaltStack' name_email None subkey_type None subkey_length None expire_date None use_passphrase False user None gnupghome None ret {'res' True 'fingerprint' '' 'message' ''}create_params {'key_type' key_type 'key_length' key_length 'name_real' name_real 'name_comment' name_comment}gpg _create_gpg user gnupghome if name_email create_params['name_email'] name_emailif subkey_type create_params['subkey_type'] subkey_typeif subkey_length create_params['subkey_length'] subkey_lengthif expire_date create_params['expire_date'] expire_dateif use_passphrase gpg_passphrase __salt__['pillar.get'] 'gpg_passphrase' if not gpg_passphrase ret['res'] Falseret['message'] 'gpg_passphrasenotavailableinpillar.'return retelse create_params['passphrase'] gpg_passphraseinput_data gpg.gen_key_input **create_params key gpg.gen_key input_data if key.fingerprint ret['fingerprint'] key.fingerprintret['message'] 'GPGkeypairsuccessfullygenerated.'else ret['res'] Falseret['message'] 'UnabletogenerateGPGkeypair.'return ret
def action_get_by_request_id context instance_uuid request_id action _action_get_by_request_id context instance_uuid request_id return action
def outer a b out None n a.sizem b.sizeret_shape n m if out is None return core.tensordot_core a b None n m 1 ret_shape if out.size ! n * m raise ValueError 'Outputarrayhasaninvalidsize' if out.flags.c_contiguous return core.tensordot_core a b out n m 1 ret_shape else out[ ] core.tensordot_core a b None n m 1 ret_shape return out
def PairedFastaQualIterator fasta_handle qual_handle alphabet single_letter_alphabet title2ids None from Bio.SeqIO.FastaIO import FastaIteratorfasta_iter FastaIterator fasta_handle alphabet alphabet title2ids title2ids qual_iter QualPhredIterator qual_handle alphabet alphabet title2ids title2ids while True try f_rec next fasta_iter except StopIteration f_rec Nonetry q_rec next qual_iter except StopIteration q_rec Noneif f_rec is None and q_rec is None breakif f_rec is None raise ValueError 'FASTAfilehasmoreentriesthantheQUALfile.' if q_rec is None raise ValueError 'QUALfilehasmoreentriesthantheFASTAfile.' if f_rec.id ! q_rec.id raise ValueError 'FASTAandQUALentriesdonotmatch %svs%s .' % f_rec.id q_rec.id if len f_rec ! len q_rec.letter_annotations['phred_quality'] raise ValueError 'Sequencelengthandnumberofqualityscoresdisagreefor%s' % f_rec.id f_rec.letter_annotations['phred_quality'] q_rec.letter_annotations['phred_quality'] yield f_rec
def person_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'pr' 'person'
def loadavg try load_avg os.getloadavg except AttributeError raise salt.exceptions.CommandExecutionError 'status.loadavagisnotavailableonyourplatform' return {'1-min' load_avg[0] '5-min' load_avg[1] '15-min' load_avg[2]}
def Out text lines text.split '\n' indent ''for line in lines if line.strip for c in line if not c.isspace breakindent indent + c breakn len indent for line in lines if line[ n] indent line line[n ]else for c in indent if line[ 1] ! c breakline line[1 ]VaOutput '%s' line
def _categorize_block df categories index df df.copy for col vals in categories.items if is_categorical_dtype df[col] df[col] df[col].cat.set_categories vals else df[col] pd.Categorical df[col] categories vals ordered False if index is not None if is_categorical_dtype df.index ind df.index.set_categories index else ind pd.Categorical df.index categories index ordered False ind.name df.index.namedf.index indreturn df
def itemfilter predicate d factory dict rv factory for item in iteritems d if predicate item k v itemrv[k] vreturn rv
def rewrite C alpha w v C._schreier_free_group.identityfor i in range len w x_i w[i]v v * C.P[alpha][C.A_dict[x_i]] alpha C.table[alpha][C.A_dict[x_i]]return v
def fit_grid_point X y estimator parameters train test scorer verbose error_score 'raise' **fit_params score n_samples_test _ _fit_and_score estimator X y scorer train test verbose parameters fit_params error_score return score parameters n_samples_test
def get_os_name OS platform.system .lower if OS.startswith 'linux' DISTRO platform.linux_distribution [0]if DISTRO OS OS + '-%s' % DISTRO.split [0].lower return OS
def get_session stored_refresh_token service get_oauth_service r service.get_raw_access_token data {'refresh_token' stored_refresh_token 'grant_type' 'refresh_token'} return service.get_session r.json ['access_token']
def extract_inner_value source attr_chain cur_element sourcefor attr in attr_chain if hasattr cur_element '__getitem__' try cur_element cur_element[attr]continueexcept KeyError TypeError passcur_element getattr cur_element attr None if cur_element is None return Nonereturn cur_element
def make_method_key model method key prefix 'method-cache'if isinstance model basestring name modelelse name model.__name__ if hasattr model '__name__' else model.__class__.__name__ key make_key **key if isinstance key dict else key return u' '.join [prefix name method key]
def explain_c_declaration c_decl parser c_parser.CParser try node parser.parse c_decl filename '<stdin>' except c_parser.ParseError e sys.exc_info [1]return 'Parseerror ' + str e if not isinstance node c_ast.FileAST or not isinstance node.ext[ -1 ] c_ast.Decl return 'Notavaliddeclaration'return _explain_decl_node node.ext[ -1 ]
def download_weekly_bars instrument year csvFile begin dt.get_first_monday year end dt.get_last_monday year + datetime.timedelta days 6 bars download_csv instrument begin end 'w' f open csvFile 'w' f.write bars f.close
def avail_modules desc False cmd u'Find-Module'modules _pshell cmd names []if desc names {}for module in modules if desc names[module[u'Name']] module[u'Description']continuenames.append module[u'Name'] return names
@pytest.mark.skipif not HAS_SCIPY reason u'NoScipy' @pytest.mark.skipif OLDER_SCIPY reason u'Scipytooold' def test_regression_4082 from .. import search_around_sky search_around_3dcat SkyCoord [10.076 10.00455] [18.54746 18.54896] unit u'deg' search_around_sky cat[0 1] cat seplimit u.arcsec * 60 storekdtree False cat3d SkyCoord [10.076 10.00455] * u.deg [18.54746 18.54896] * u.deg distance [0.1 1.5] * u.kpc search_around_3d cat3d[0 1] cat3d 1 * u.kpc storekdtree False
@click.command 'socketio' def setup_socketio from bench.utils import setup_socketiosetup_socketio
def _get_cudafft try from skcuda import fftexcept ImportError try from scikits.cuda import fftexcept ImportError fft Nonereturn fft
def _DecodeUniquifier byte_str client_id num_bytes util.DecodeVarLengthNumber byte_str server_id byte_str[num_bytes ] if num_bytes < len byte_str else None return AssetIdUniquifier client_id server_id
@blueprint.route '/users/<user>/resources' def list_resources_by_user user return _list_resources user user project acl.get_limited_to_project flask.request.headers
def _make_sync_call service call request response resp apiproxy_stub_map.MakeSyncCall service call request response if resp is not None return respreturn response
def check_simple_wiki_locale view_func @wraps view_func def _check_simple_wiki_locale request *args **kwargs if request.LANGUAGE_CODE in settings.SIMPLE_WIKI_LANGUAGES statsd.incr 'wiki.redirect_to_faq' url reverse 'wiki.document' args [SIMPLE_WIKI_LANDING_PAGE_SLUG] return http.HttpResponseRedirect url return view_func request *args **kwargs return _check_simple_wiki_locale
def get_properties_of_managed_object mo_ref properties service_instance get_service_instance_from_managed_object mo_ref log.trace 'Retrievingnameof{0}'.format type mo_ref .__name__ try items get_mors_with_properties service_instance type mo_ref container_ref mo_ref property_list ['name'] local_properties True mo_name items[0]['name']except vmodl.query.InvalidProperty mo_name '<unnamed>'log.trace "Retrievingproperties'{0}'of{1}'{2}'".format properties type mo_ref .__name__ mo_name items get_mors_with_properties service_instance type mo_ref container_ref mo_ref property_list properties local_properties True if not items raise salt.exceptions.VMwareApiError "Propertiesofmanagedobject'{0}'weren'tretrieved".format mo_name return items[0]
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def _extract_subject_public_key_info x509_certificate certificate DerSequence .decode x509_certificate nr_elements 3 tbs_certificate DerSequence .decode certificate[0] nr_elements range 6 11 index 5try tbs_certificate[0] + 1 version 1except TypeError version DerInteger explicit 0 .decode tbs_certificate[0] .valueif version not in 2 3 raise ValueError 'IncorrectX.509certificateversion' index 6return tbs_certificate[index]
def quota_class_get_all_by_name context class_name return IMPL.quota_class_get_all_by_name context class_name
def _apply_forwards_to_bindings forward bindings for var value in bindings.items while id value in forward value forward[id value ]bindings[var] value
def outport port_name '' props [] mac_name None return __create_port_dict 'out' port_name mac_name props
def get_dates args no_of_days date_diff add_days args[u'to_date'] 1 args[u'from_date'] dates [add_days args[u'from_date'] i for i in range 0 no_of_days ]return dates
def _shortpath abspath b os.path.dirname os.path.normpath os.sys.modules[settings.SETTINGS_MODULE].__file__ p os.path.normpath abspath return p[len os.path.commonprefix [b p] ]
def convertlabels ys indices None if indices None ylabel yselse idx np.array indices if idx.size > 1 and ys.ndim 2 ylabel np.array [ '@%s@' % ii[ 2].tostring for ii in ys] [ np.newaxis]else ylabel ys unil unilinv np.unique ylabel return_index False return_inverse True return unilinv np.arange len unil unil
def UppercaseEnum *args return Enum *[ v v for v in args]
def object_download_file self Filename ExtraArgs None Callback None Config None return self.meta.client.download_file Bucket self.bucket_name Key self.key Filename Filename ExtraArgs ExtraArgs Callback Callback Config Config
def retry_job job new_nzb password if job history_db sabnzbd.connect_db futuretype url pp script cat history_db.get_other job if futuretype if pp 'X' pp Nonesabnzbd.add_url url pp script cat history_db.remove_history job else path history_db.get_path job if path nzo_id repair_job platform_encode path new_nzb password history_db.remove_history job return nzo_idreturn None
def expand_power_base expr deep True force False return sympify expr .expand deep deep log False mul False power_exp False power_base True multinomial False basic False force force
def run_all delay_seconds 0 default_scheduler.run_all delay_seconds delay_seconds
def snapshot_get_all_for_cgsnapshot context project_id return IMPL.snapshot_get_all_for_cgsnapshot context project_id
def to_sentiment_json doc_id sent label json_doc {}json_doc['doc_id'] doc_idjson_doc['sentiment'] float '%.3f' % sent json_doc['label'] labelreturn json.dumps json_doc
def when_imported name *hooks global finderfinder.when_imported name *hooks
def test_feature_ptbr_from_string ru Language 'ru' feature Feature.from_string FEATURE language ru assert_equals feature.name u'\u0414\u0435\u043b\u0435\u043d\u0438\u0435\u0447\u0438\u0441\u0435\u043b' assert_equals feature.description u'\u041f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u0441\u043b\u043e\u0436\u043d\u044b\u0439\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043b\u044e\u0434\u0438\u0447\u0430\u0441\u0442\u043e\u0434\u043e\u043f\u0443\u0441\u043a\u0430\u044e\u0442\u043e\u0448\u0438\u0431\u043a\u0438\n\u041d\u0443\u0436\u043d\u043e\u0434\u0430\u0442\u044c\u0438\u043c\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c\u0434\u0435\u043b\u0438\u0442\u044c\u043d\u0430\u043a\u0430\u043b\u044c\u043a\u0443\u043b\u044f\u0442\u043e\u0440\u0435' scenario feature.scenariosassert_equals scenario.name u'\u0426\u0435\u043b\u043e\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u043e\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435' assert_equals scenario.steps[ -1 ].hashes [{u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '100' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '2' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '50'} {u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '28' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '7' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '4'} {u'\u0434\u0435\u043b\u0438\u043c\u043e\u0435' '0' u'\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c' '5' u'\u0447\u0430\u0441\u0442\u043d\u043e\u0435' '0'}]
def _create_backup config temp_dir backup os.path.join temp_dir 'backup' shutil.rmtree backup ignore_errors True shutil.copytree config backup symlinks True return backup
def filter_after_position names position if position is None return namesnames_new []for n in names if n.start_pos[0] is not None and n.start_pos < position or isinstance n.get_definition tree.CompFor tree.Lambda names_new.append n return names_new
def locale name locales [name]
def addVector3ToXMLElement key vector3 xmlElement xmlElement.attributeDictionary[key] '[%s %s %s]' % vector3.x vector3.y vector3.z
def unpack_kwargs kwargs dsk {}kw_pairs []for key val in iteritems kwargs if isinstance val Item dsk.update val.dask val val.keyelif isinstance val Base raise NotImplementedError '%snotsupportedaskwargvaluetoBag.map_partitions' % type val .__name__ kw_pairs.append [key val] return dsk kw_pairs
def _parse_pg_lscluster output cluster_dict {}for line in output.splitlines version name port status user datadir log line.split cluster_dict['{0}/{1}'.format version name ] {'port' int port 'status' status 'user' user 'datadir' datadir 'log' log}return cluster_dict
def load_data path 'mnist.pkl.gz' path get_file path origin 'https //s3.amazonaws.com/img-datasets/mnist.pkl.gz' if path.endswith '.gz' f gzip.open path 'rb' else f open path 'rb' if sys.version_info < 3 data cPickle.load f else data cPickle.load f encoding 'bytes' f.close return data
def batch_rename work_dir old_ext new_ext for filename in os.listdir work_dir file_ext os.path.splitext filename [1]if old_ext file_ext name_list list filename name_list[ len name_list - len old_ext ] list new_ext newfile ''.join name_list os.rename os.path.join work_dir filename os.path.join work_dir newfile
def do_round value precision 0 method 'common' if not method in 'common' 'ceil' 'floor' raise FilterArgumentError 'methodmustbecommon ceilorfloor' if precision < 0 raise FilterArgumentError 'precisionmustbeapostiveintegerorzero.' if method 'common' return round value precision func getattr math method if precision return func value * 10 * precision / 10 * precision else return func value
def hadamard n dtype int if n < 1 lg2 0else lg2 int math.log n 2 if 2 ** lg2 ! n raise ValueError 'nmustbeanpositiveinteger andnmustbeapowerof2' H np.array [[1]] dtype dtype for i in range 0 lg2 H np.vstack np.hstack H H np.hstack H - H return H
def _plot_raw_time value params info params['info']max_times params['n_times'] / float info['sfreq'] + params['first_time'] - params['duration'] if value > max_times value params['n_times'] / float info['sfreq'] + params['first_time'] - params['duration'] if value < params['first_time'] value params['first_time']if params['t_start'] ! value params['t_start'] valueparams['hsel_patch'].set_x value
def set_static_dns iface *addrs addr_index 1for addr in addrs if addr_index 1 cmd ['netsh' 'int' 'ip' 'set' 'dns' iface 'static' addrs[0] 'primary']__salt__['cmd.run'] cmd python_shell False addr_index addr_index + 1 else cmd ['netsh' 'interface' 'ip' 'add' 'dns' 'name {0}'.format iface 'addr {0}'.format addr 'index {0}'.format addr_index ]__salt__['cmd.run'] cmd python_shell False addr_index addr_index + 1 return {'Interface' iface 'DNSServer' addrs}
def schedule_enable enable status salt.utils.mac_utils.validate_enabled enable cmd ['softwareupdate' '--schedule' salt.utils.mac_utils.validate_enabled status ]salt.utils.mac_utils.execute_return_success cmd return salt.utils.mac_utils.validate_enabled schedule_enabled status
@depends HAS_IOSTAT def iostat interval 1 count 5 disks None if salt.utils.is_linux return _iostat_linux interval count disks elif salt.utils.is_freebsd return _iostat_fbsd interval count disks
def scan opts ret {}for root dirs files in os.walk opts['root'] for fn_ in files full os.path.join root fn_ if full.endswith '.py' ret.update mod_data opts full return ret
def OpenOutput path mode 'w' gyp.common.EnsureDirExists path return open path mode
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def fixed_ip_get context id get_network False return IMPL.fixed_ip_get context id get_network
def p_testlist_multi p if len p 2 p[0] p[1]elif isinstance p[1] list p[0] p[1] + [p[3]] else p[0] [p[1] p[3]]
def process_extract_samples samples_to_extract prefs {}if samples_to_extract samples samples_to_extract.strip .strip "'" .split ' ' for j col in enumerate samples key str j prefs[key] {}prefs[key] colreturn prefs
def trace_dot X Y return np.dot X.ravel Y.ravel
def write_trans fname trans check_fname fname 'trans' '-trans.fif' '-trans.fif.gz' fid start_file fname write_coord_trans fid trans end_file fid
def use_fsdev_lib fs_desc disk1_only reinit_disks global FSDEV_FS_DESCglobal FSDEV_RESTOREglobal FSDEV_DISK1_ONLYglobal FSDEV_PREP_CNTFSDEV_FS_DESC fs_descFSDEV_DISK1_ONLY disk1_onlyFSDEV_RESTORE reinit_disksFSDEV_PREP_CNT 0
def zfill x width if type x type '' s xelse s repr x n len s if n > width return ssign ''if s[0] in '-' '+' sign s s[0] s[1 ] return sign + '0' * width - n + s
def cosine_similarity v1 v2 s sum v1.get f 0 * w for f w in v2.items s float s / l2_norm v1 * l2_norm v2 or 1 return s
def html_annotate doclist markup default_markup tokenlist [tokenize_annotated doc version for doc version in doclist]cur_tokens tokenlist[0]for tokens in tokenlist[1 ] html_annotate_merge_annotations cur_tokens tokens cur_tokens tokenscur_tokens compress_tokens cur_tokens result markup_serialize_tokens cur_tokens markup return ''.join result .strip
def compile_dir dfn subprocess.call [PYTHON '-OO' '-m' 'compileall' '-f' dfn]
def pretty_format_tree_entry name mode hexsha encoding 'utf-8' if mode & stat.S_IFDIR kind 'tree'else kind 'blob'return '%04o%s%s DCTB %s\n' % mode kind hexsha.decode 'ascii' name.decode encoding 'replace'
def _image_property_update context prop_ref values session None _drop_protected_attrs models.ImageProperty values values['deleted'] Falseprop_ref.update values prop_ref.save session session return prop_ref
def SmartConnectNoSSL protocol 'https' host 'localhost' port 443 user 'root' pwd '' service 'hostd' path '/sdk' connectionPoolTimeout CONNECTION_POOL_IDLE_TIMEOUT_SEC preferredApiVersions None keyFile None certFile None thumbprint None b64token None mechanism 'userpass' if hasattr ssl '_create_unverified_context' sslContext ssl._create_unverified_context else sslContext Nonereturn SmartConnect protocol protocol host host port port user user pwd pwd service service path path connectionPoolTimeout connectionPoolTimeout preferredApiVersions preferredApiVersions keyFile keyFile certFile certFile thumbprint thumbprint sslContext sslContext b64token b64token mechanism mechanism
def worker_stop worker lbn profile 'default' return _worker_ctl worker lbn 's' profile
@frappe.whitelist def get_account_balance_and_party_type account date company debit None credit None exchange_rate None if not frappe.has_permission u'Account' frappe.msgprint _ u'NoPermission' raise_exception 1 company_currency get_company_currency company account_details frappe.db.get_value u'Account' account [u'account_type' u'account_currency'] as_dict 1 if not account_details returnif account_details.account_type u'Receivable' party_type u'Customer'elif account_details.account_type u'Payable' party_type u'Supplier'else party_type u''grid_values {u'balance' get_balance_on account date u'party_type' party_type u'account_type' account_details.account_type u'account_currency' account_details.account_currency or company_currency u'exchange_rate' get_exchange_rate date account account_details.account_currency company debit debit credit credit exchange_rate exchange_rate }if not party_type grid_values[u'party'] u''return grid_values
def format_ device fs_type 'ext4' inode_size None lazy_itable_init None force False salt.utils.warn_until 'Oxygen' 'Theblockdevmodulehasbeenmergedwiththediskmodule andwilldisappearinOxygen.Usethedisk.format_functioninstead.' return __salt__['disk.format_'] device fs_type fs_type inode_size inode_size lazy_itable_init lazy_itable_init force force
def get_storage_profile_spec session storage_policy profile_id pbm.get_profile_id_by_name session storage_policy if profile_id client_factory session.vim.client.factorystorage_profile_spec client_factory.create 'ns0 VirtualMachineDefinedProfileSpec' storage_profile_spec.profileId profile_id.uniqueIdreturn storage_profile_spec
def demo_repr_rule_format postag ruleformat 'repr'
def get_vlan_device_name src_dev vlan src_dev p_utils.get_interface_name src_dev max_len n_const.DEVICE_NAME_MAX_LEN - MAX_VLAN_POSTFIX_LEN return '%s.%s' % src_dev vlan
def quota_usage_create context project_id resource in_use reserved until_refresh return IMPL.quota_usage_create context project_id resource in_use reserved until_refresh
def _rm_mods pre_mods post_mods pre set post set for mod in pre_mods pre.add mod['module'] for mod in post_mods post.add mod['module'] return pre - post
def raise_if_offline func @functools.wraps func def decorator *args **kwargs if context.is_offline_mode raise RuntimeError _ '%scannotbecalledwhileinofflinemode' % func.__name__ return func *args **kwargs return decorator
def fix_lib64 lib_dir symlink True if [p for p in distutils.sysconfig.get_config_vars .values if isinstance p basestring and 'lib64' in p ] if is_pypy logger.debug 'PyPydetected skippinglib64symlinking' returnlogger.debug 'Thissystemuseslib64;symlinkinglib64tolib' assert os.path.basename lib_dir 'python%s' % sys.version[ 3] 'Unexpectedpythonlibdir %r' % lib_dir lib_parent os.path.dirname lib_dir top_level os.path.dirname lib_parent lib_dir os.path.join top_level 'lib' lib64_link os.path.join top_level 'lib64' assert os.path.basename lib_parent 'lib' 'Unexpectedparentdir %r' % lib_parent if os.path.lexists lib64_link returncp_or_ln os.symlink if symlink else copyfile cp_or_ln 'lib' lib64_link
def liberal_is_HDN text if IPV4_RE.search text return Falsereturn True
def are_permissions_roles_seeded course_id try administrator_role Role.objects.get name FORUM_ROLE_ADMINISTRATOR course_id course_id moderator_role Role.objects.get name FORUM_ROLE_MODERATOR course_id course_id student_role Role.objects.get name FORUM_ROLE_STUDENT course_id course_id except return Falsefor per in STUDENT_ROLE_PERMISSIONS if not student_role.has_permission per return Falsefor per in MODERATOR_ROLE_PERMISSIONS + STUDENT_ROLE_PERMISSIONS if not moderator_role.has_permission per return Falsefor per in ADMINISTRATOR_ROLE_PERMISSIONS + MODERATOR_ROLE_PERMISSIONS + STUDENT_ROLE_PERMISSIONS if not administrator_role.has_permission per return Falsereturn True
def any_symbolic *args for a in args if isinstance a theano.Variable return Truereturn False
def PackGeoPt name value pbvalue pbvalue.mutable_pointvalue .set_x value.lat pbvalue.mutable_pointvalue .set_y value.lon
def _combine_annotations annotations last_samps first_samps sfreq if not any annotations return Noneelif annotations[1] is None return annotations[0]elif annotations[0] is None old_onset list old_duration list old_description list old_orig_time Noneelse old_onset annotations[0].onsetold_duration annotations[0].durationold_description annotations[0].descriptionold_orig_time annotations[0].orig_timeextra_samps len first_samps - 1 onset annotations[1].onset + sum last_samps[ -1 ] + extra_samps - sum first_samps[ -1 ] / sfreq onset np.concatenate [old_onset onset] duration np.concatenate [old_duration annotations[1].duration] description np.concatenate [old_description annotations[1].description] return Annotations onset duration description old_orig_time
def copy_int_big src dest word src.read 4 dest.write word val unpack '>I' word return val
def GetResult Handle IOType Channel if os.name 'nt' staticLib ctypes.windll.LoadLibrary 'labjackud' pv ctypes.c_double ec staticLib.GetResult Handle IOType Channel ctypes.byref pv if ec ! 0 raise LabJackException ec return pv.valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def compute_q_noisy_max_approx counts noise_eps winner np.argmax counts counts_normalized noise_eps * counts - counts[winner] counts_rest np.array [counts_normalized[i] for i in xrange len counts if i ! winner ] gap - max counts_rest q len counts - 1 * gap + 2.0 / 4.0 * math.exp gap return min q 1.0 - 1.0 / len counts
def parse_account_key LOGGER.info 'Parsingaccountkey...' proc subprocess.Popen ['opensslrsa-in/tmp/account.key-noout-text'] stdin subprocess.PIPE stdout subprocess.PIPE stderr subprocess.PIPE shell True out err proc.communicate if proc.returncode ! 0 raise IOError 'OpenSSLError {0}'.format err return out
def _get_objects obj_type lst_objs FakeRetrieveResult for key in _db_content[obj_type] lst_objs.add_object _db_content[obj_type][key] return lst_objs
def exception_handler exc context if isinstance exc exceptions.APIException headers {}if getattr exc u'auth_header' None headers[u'WWW-Authenticate'] exc.auth_headerif getattr exc u'wait' None headers[u'Retry-After'] u'%d' % exc.wait if isinstance exc.detail list dict data exc.detailelse data {u'detail' exc.detail}set_rollback return Response data status exc.status_code headers headers elif isinstance exc Http404 msg _ u'Notfound.' data {u'detail' six.text_type msg }set_rollback return Response data status status.HTTP_404_NOT_FOUND elif isinstance exc PermissionDenied msg _ u'Permissiondenied.' data {u'detail' six.text_type msg }set_rollback return Response data status status.HTTP_403_FORBIDDEN return None
def quotify qtype word terminate if qtype qq return qq + word.replace qq '\\"' + terminate and qq or '' elif qtype q return q + word.replace q "\\'" + terminate and q or '' else return re.sub ' [\\"\\\'\\t\\n\\r] ' '\\\\\\1' word
@pytest.mark.skipif 'notHAS_YAML' def test_write_simple t simple_table out StringIO t.write out format 'ascii.ecsv' assert out.getvalue .splitlines SIMPLE_LINES
def getOutput gcodeText repository None if gcodeText '' return ''if repository is None repository GcodeTimeSegmentRepository settings.getReadRepository repository return GcodeTimeSegmentSkein .getCraftedGcode gcodeText repository
def inputbox text x y w h from plasma.lib.ui.inlineed import InlineEded InlineEd 0 0 0 text 0 [] ed.screen curses.newwin h w y x ret ed.start_view ed.screen if not ret return ''return ed.text
def _transform_orig_meg_coils coils t do_es True if t is None returnfor coil in coils coil_trans np.dot t['trans'] coil['coil_trans_orig'] coil.update coord_frame t['to'] r0 coil_trans[ 3 3] rmag apply_trans coil_trans coil['rmag_orig'] cosmag apply_trans coil_trans coil['cosmag_orig'] False if do_es r0_exey np.dot coil['rmag_orig'][ 2] coil_trans[ 3 2].T + coil_trans[ 3 3] coil.update ex coil_trans[ 3 0] ey coil_trans[ 3 1] ez coil_trans[ 3 2] r0_exey r0_exey
@checker '.rst' severity 2 def check_suspicious_constructs fn lines inprod Falsefor lno line in enumerate lines if seems_directive_re.search line yield lno + 1 'commentseemstobeintendedasadirective' if '..productionlist ' in line inprod Trueelif not inprod and default_role_re.search line yield lno + 1 'defaultroleused' elif inprod and not line.strip inprod False
def test_approve_addons_get_files use_case addon file1 file2 review_type use_caseassert approve_addons.get_files [addon.guid] [file1 file2]
def softmax mat target None if not target target materr_code _eigenmat.apply_softmax mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def get_images_table meta images Table 'images' meta Column 'id' Integer primary_key True nullable False Column 'name' String 255 Column 'disk_format' String 20 Column 'container_format' String 20 Column 'size' BigInteger Column 'status' String 30 nullable False Column 'is_public' Boolean nullable False default False index True Column 'location' Text Column 'created_at' DateTime nullable False Column 'updated_at' DateTime Column 'deleted_at' DateTime Column 'deleted' Boolean nullable False default False index True mysql_engine 'InnoDB' extend_existing True return images
def iteritems_compat d return iter getattr d _iteritems
def ROCR100 ds count timeperiod - 2 ** 31 return call_talib_with_ds ds count talib.ROCR100 timeperiod
def bzr_wc_source_remote test 'bzr_wc_source_remote'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabtools.files import is_dirfrom fabtools import requireassert not is_dir wt require.bazaar.working_copy REMOTE_URL wt assert_wc_exists wt
def _read_coord_trans_struct fid tag shape rlims from ..transforms import Transformfro int np.fromstring fid.read 4 dtype '>i4' to int np.fromstring fid.read 4 dtype '>i4' rot np.fromstring fid.read 36 dtype '>f4' .reshape 3 3 move np.fromstring fid.read 12 dtype '>f4' trans np.r_[ np.c_[ rot move ] np.array [[0] [0] [0] [1]] .T ]data Transform fro to trans fid.seek 48 1 return data
def _parse_repos module cmd _get_cmd '--xmlout' 'repos' from xml.dom.minidom import parseString as parseXML rc stdout stderr module.run_command cmd check_rc False if rc 0 repos []dom parseXML stdout repo_list dom.getElementsByTagName 'repo' for repo in repo_list opts {}for o in REPO_OPTS opts[o] repo.getAttribute o opts['url'] repo.getElementsByTagName 'url' [0].firstChild.datarepos.append opts return reposelif rc 6 return []else module.fail_json msg 'Failedtoexecute"%s"' % ''.join cmd rc rc stdout stdout stderr stderr
def create_hc G path_length nx.all_pairs_shortest_path_length G distances numpy.zeros len G len G for u p in path_length.items for v d in p.items distances[u][v] dY distance.squareform distances Z hierarchy.complete Y membership list hierarchy.fcluster Z t 1.15 partition defaultdict list for n p in zip list range len G membership partition[p].append n return list partition.values
def _GenApiConfigCallback args api_func GenApiConfig service_class_names output_path hostname args.service args.output args.hostname service_configs api_func service_class_names hostname hostname for service_class_name config in service_configs.iteritems _ base_service_class_name service_class_name.rsplit '.' 1 api_name base_service_class_name + '.api' _WriteFile output_path api_name config
def _bq_cast string_field bq_type if string_field is None return Noneelif bq_type 'INTEGER' or bq_type 'TIMESTAMP' return int string_field elif bq_type 'FLOAT' return float string_field elif bq_type 'BOOLEAN' assert string_field in set ['true' 'false'] return string_field 'true' else return string_field
def set_computer_sleep minutes value _validate_sleep minutes cmd 'systemsetup-setcomputersleep{0}'.format value salt.utils.mac_utils.execute_return_success cmd return salt.utils.mac_utils.confirm_updated str value get_computer_sleep
def convert_to_index_sliceable obj key idx obj.indexif isinstance key slice return idx._convert_slice_indexer key kind 'getitem' elif isinstance key compat.string_types if key in obj._data.items return Noneif idx.is_all_dates try return idx._get_string_slice key except KeyError ValueError NotImplementedError return Nonereturn None
def _format_failure failure result failure['result']host result._host.get_name play _get_play result._task if play play play.get_name task result._task.get_name msg result._result.get 'msg' u'???' rows u'Host' host u'Play' play u'Task' task u'Message' stringc msg C.COLOR_ERROR row_format '{ 10}{}'return [row_format.format header + u' ' body for header body in rows]
def canonicalize_address addr parsed_address address.parse addr addr_spec_only True if not isinstance parsed_address address.EmailAddress return addrlocal_part parsed_address.mailbox.lower hostname parsed_address.hostname.lower if hostname in 'gmail.com' 'googlemail.com' local_part local_part.replace '.' '' return '@'.join local_part hostname
def _primitive_in_x0 f fring f.ringring fring.drop_to_ground *range 1 fring.ngens dom ring.domain.ringf_ ring f.as_expr cont dom.zerofor coeff in f_.itercoeffs cont func_field_modgcd cont coeff [0]if cont dom.one return cont f return cont f.quo cont.set_ring fring
def commonPrefix completions def cp str1 str2 '\n return thelongestcommonprefixfor2strings.\n'ls2 len str2 j 1for i in range len str1 if i > ls2 or str1[i] ! str2[i] j 0breakresult str1[ i + j ]return resultstrs [v[len p ] for p v in completions]if len strs 0 return ''if len strs 1 return strs[0] result tail strs[0] strs[1 ] for i in range len tail result cp result tail[i] if result '' breakreturn result
def _version_from_git_describe p subprocess.Popen ['git' 'describe' '--always'] cwd _SCAPY_PKG_DIR stdout subprocess.PIPE stderr subprocess.PIPE out err p.communicate if p.returncode 0 tag out.strip match re.match '^v? .+? - \\d+ -g[a-f0-9]+$' tag if match return '%s.dev%s' % match.group 1 match.group 2 else return re.sub '^v' '' tag else raise subprocess.CalledProcessError p.returncode err
def readData ncd buf ''while '\n' not in buf buf + ncd.read_exact 1 size len buf - 1 print 'Codeofsize%d' % size buf + ncd.read_exact size + 1 * size - 1 return buf.split '\n' [ size]
def _handle_event_colors unique_events color unique_events_id if color is None if len unique_events > len COLORS warn 'Moreeventsthancolorsavailable.Youshouldpassalistofuniquecolors.' colors cycle COLORS color dict for this_event this_color in zip sorted unique_events_id colors color[this_event] this_colorelse for this_event in color if this_event not in unique_events_id raise ValueError '%sfromcolorisnotpresentineventsorevent_id.' % this_event for this_event in unique_events_id if this_event not in color warn 'Colorisnotavailableforevent%d.Defaultcolorswillbeused.' % this_event return color
def service_type stype def inner f f.service_type stypereturn freturn inner
def _match_topic subscription topic if subscription.endswith '#' return subscription[ -2 ] topic or topic.startswith subscription[ -1 ] sub_parts subscription.split '/' topic_parts topic.split '/' return len sub_parts len topic_parts and all a b for a b in zip sub_parts topic_parts if a ! '+'
def to_textfiles b path name_function None compression 'infer' encoding system_encoding compute True out write_bytes b.to_delayed path name_function compression encoding encoding if compute from dask import delayeddelayed out .compute else return out
def _can_use_cache products shop customer product_ids [prod.id for prod in products]for supplier in Supplier.objects.all for sp in ShopProduct.objects.filter product__id__in product_ids if not sp.is_orderable supplier customer customer quantity sp.minimum_purchase_quantity return Falsereturn True
def test_call_accepts_func_kw_params_kw_types @accepts kw_1 int kw_2 int kw_3 int def foo kw_1 5 kw_2 6 kw_3 7 passt time.time for i in range 0 10000 foo 5 6 7 return time.time - t
def _iterate_over_statements sub_policy check_statement_func if type sub_policy['Statement'] is list statements sub_policy['Statement']for statement in statements check_statement_func statement else check_statement_func sub_policy['Statement']
def name_uniquely path names_taken proposed_name None unhide False if not proposed_name proposed_name os.path.basename path.rstrip '/' + os.sep if unhide proposed_name proposed_name.lstrip '.' .lstrip '_' dot_idx proposed_name.find '.' 0 if unhide else 1 if dot_idx -1 prefix suffix proposed_name '' else prefix suffix proposed_name[ dot_idx] proposed_name[dot_idx ] if prefix and proposed_name not in names_taken return proposed_namefor i in itertools.count 1 if prefix name '%s-%d%s' % prefix i suffix else name '%d%s' % i suffix if name not in names_taken return name
def versions runas None ret _rbenv_exec ['versions' '--bare'] runas runas return [] if ret is False else ret.splitlines
def loopbackAsync server client pumpPolicy identityPumpPolicy serverToClient _LoopbackQueue clientToServer _LoopbackQueue server.makeConnection _LoopbackTransport serverToClient client.makeConnection _LoopbackTransport clientToServer return _loopbackAsyncBody server serverToClient client clientToServer pumpPolicy
def reiterate iterable if isinstance iterable list tuple return iterableelse iterator iter iterable try chunk ''while not chunk chunk next iterator return itertools.chain [chunk] iterator except StopIteration return []
def chshell name shell pre_info info name if not pre_info raise CommandExecutionError "User'{0}'doesnotexist".format name if shell pre_info['shell'] return True_dscl ['/Users/{0}'.format name 'UserShell' pre_info['shell'] shell] ctype 'change' time.sleep 1 return info name .get 'shell' shell
def startLogging file *a **kw if isinstance file LoggingFile returnflo FileLogObserver file startLoggingWithObserver flo.emit *a **kw return flo
def no_coverage_env env os.environ.copy env.pop 'COV_CORE_SOURCE' None return env
def get_dns_hosts context network_ref hosts []for fixedip in objects.FixedIPList.get_by_network context network_ref if fixedip.allocated hosts.append _host_dns fixedip return '\n'.join hosts
def get_qos_policy_group_name_from_info qos_policy_group_info if qos_policy_group_info is None return Nonelegacy qos_policy_group_info.get 'legacy' if legacy is not None return legacy['policy_name']spec qos_policy_group_info.get 'spec' if spec is not None return spec['policy_name']return None
@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'instructor' @require_post_params rolename "'instructor' 'staff' or'beta'" def list_course_role_members request course_id course_id SlashSeparatedCourseKey.from_deprecated_string course_id course get_course_with_access request.user 'instructor' course_id depth None rolename request.POST.get 'rolename' if rolename not in ROLES return HttpResponseBadRequest def extract_user_info user 'convertuserintodictsforjsonview'return {'username' user.username 'email' user.email 'first_name' user.first_name 'last_name' user.last_name}response_payload {'course_id' course_id.to_deprecated_string rolename map extract_user_info list_with_level course rolename }return JsonResponse response_payload
def param2id object_id if '-' in object_id return ec2utils.ec2_vol_id_to_uuid object_id else return object_id
def create_subtasks task qs chunk_size *args ts [task.subtask args chunk + args for chunk in chunked qs chunk_size ]TaskSet ts .apply_async
def levenshtein seq1 seq2 limit None oneago Nonethisrow range 1 len seq2 + 1 + [0] for x in xrange len seq1 oneago thisrow thisrow [0] * len seq2 + [ x + 1 ] for y in xrange len seq2 delcost oneago[y] + 1 addcost thisrow[ y - 1 ] + 1 subcost oneago[ y - 1 ] + seq1[x] ! seq2[y] thisrow[y] min delcost addcost subcost if limit and x > limit and min thisrow > limit return limit + 1 return thisrow[ len seq2 - 1 ]
def test_randomize_corrmat_correction a rs.randn 3 20 p_mat algo.randomize_corrmat a 'upper' False p_mat_corr algo.randomize_corrmat a 'upper' True triu np.triu_indices 3 1 npt.assert_array_less p_mat[triu] p_mat_corr[triu]
def write_chunks out chunks out.write _signature for chunk in chunks write_chunk out *chunk
def get_valid_archs archs []try for breed in get_valid_breeds for operating_system in SIGNATURE_CACHE['breeds'][breed].keys archs + SIGNATURE_CACHE['breeds'][breed][operating_system]['supported_arches']except passreturn uniquify archs
def local_port_tcp port ret _remotes_on port 'local_port' return ret
def check_qdatastream stream status_to_str {QDataStream.Ok 'Thedatastreamisoperatingnormally.' QDataStream.ReadPastEnd 'Thedatastreamhasreadpasttheendofthedataintheunderlyingdevice.' QDataStream.ReadCorruptData 'Thedatastreamhasreadcorruptdata.' QDataStream.WriteFailed 'Thedatastreamcannotwritetotheunderlyingdevice.'}if stream.status ! QDataStream.Ok raise OSError status_to_str[stream.status ]
def encode_body body return encodeutils.to_utf8 body
@xfail_py3@xfail wxPython_fail reason 'UnsupportedwxPythonversion' @importorskip 'wx.lib.pubsub.core' def test_wx_lib_pubsub_protocol_arg1 pyi_builder pyi_builder.test_script 'pyi_hooks/wx_lib_pubsub_setuparg1.py'
@utils.arg 'id' metavar '<id>' help _ 'IDofservice.' def do_service_delete cs args cs.services.delete args.id
def avail_images call None if call 'action' raise SaltCloudSystemExit 'Theavail_imagesfunctionmustbecalledwith-for--function orwiththe--list-imagesoption' server user password _get_xml_rpc auth ' '.join [user password] image_pool server.one.imagepool.info auth -2 -1 -1 [1]images {}for image in _get_xml image_pool images[image.find 'NAME' .text] _xml_to_dict image return images
def opener_for ca_bundle None return urllib2.build_opener VerifyingHTTPSHandler ca_bundle or find_ca_bundle .open
def estimate_from_weights log_ais_w ais_w T.vector max_ais_w T.max ais_w dlogz T.log T.mean T.exp ais_w - max_ais_w + max_ais_w log_mean theano.function [ais_w] dlogz allow_input_downcast False dlogz log_mean log_ais_w m numpy.max log_ais_w var_dlogz log_ais_w.shape[0] * numpy.sum numpy.exp 2 * log_ais_w - m / numpy.sum numpy.exp log_ais_w - m ** 2 - 1.0 return dlogz var_dlogz
def default_collate batch if torch.is_tensor batch[0] return torch.cat [t.unsqueeze 0 for t in batch] 0 elif isinstance batch[0] int return torch.LongTensor batch elif isinstance batch[0] float return torch.DoubleTensor batch elif isinstance batch[0] str return batchelif isinstance batch[0] collections.Iterable transposed zip *batch return [default_collate samples for samples in transposed]raise TypeError 'batchmustcontaintensors numbers orlists;found{}'.format type batch[0]
def impact return s3_rest_controller 'impact' 'impact'
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def _os_path_isdir pathname try s _os_stat pathname except OSError return Nonereturn s.st_mode & 61440 16384
def VolMagic vm return Object 'VOLATILITY_MAGIC' 0 vm vm
@image_comparison baseline_images [u'light_source_shading_topo'] extensions [u'png'] def test_light_source_topo_surface fname cbook.get_sample_data u'jacksboro_fault_dem.npz' asfileobj False dem np.load fname elev dem[u'elevation'] dx dy dem[u'dx'] dem[u'dy'] dx 111320.0 * dx * np.cos dem[u'ymin'] dy 111320.0 * dy dem.close ls mcolors.LightSource 315 45 cmap cm.gist_earth fig axes plt.subplots nrows 3 ncols 3 for row mode in zip axes [u'hsv' u'overlay' u'soft'] for ax ve in zip row [0.1 1 10] rgb ls.shade elev cmap vert_exag ve dx dx dy dy blend_mode mode ax.imshow rgb ax.set xticks [] yticks []
def is_bool_list value min None max None return [is_boolean mem for mem in is_list value min max ]
def gf_sqf_p f p K _ f gf_monic f p K if not f return Trueelse return gf_gcd f gf_diff f p K p K [K.one]
def python_implementation return _sys_version [0]
def cleanup_path path if path.startswith u'./' path path[2 ]if path.startswith u'/' path path[1 ]return path
def new_figure_manager_given_figure num figure canvas FigureCanvasMac figure manager FigureManagerMac canvas num return manager
def person_search s3.filter FS 'application.active' True s3.prep lambda r r.method 'search_ac' return s3_rest_controller 'pr' 'person'
def snapshot_destroy context snapshot_id return IMPL.snapshot_destroy context snapshot_id
def metadef_namespace_get_all context marker None limit None sort_key None sort_dir None filters None session None session session or get_session namespaces metadef_namespace_api.get_all context session marker limit sort_key sort_dir filters return namespaces
def find_prev_keyword sql n_skip 0 if not sql.strip return None '' parsed sqlparse.parse sql [0]flattened list parsed.flatten flattened flattened[ len flattened - n_skip ]logical_operators 'AND' 'OR' 'NOT' 'BETWEEN' for t in reversed flattened if t.value ' ' or t.is_keyword and t.value.upper not in logical_operators idx flattened.index t text ''.join tok.value for tok in flattened[ idx + 1 ] return t text return None ''
def hgetall key host None port None db None password None server _connect host port db password return server.hgetall key
def get_headers http_response if hasattr http_response 'getheaders' return http_response.getheaders else headers []for header in 'location' 'content-type' 'content-length' 'age' 'allow' 'cache-control' 'content-location' 'content-encoding' 'date' 'etag' 'expires' 'last-modified' 'pragma' 'server' 'set-cookie' 'transfer-encoding' 'vary' 'via' 'warning' 'www-authenticate' 'gdata-version' value http_response.getheader header None if value is not None headers.append header value return headers
def forward_disable src dst ipaddr run settings.iptables '-D' 'FORWARD' '-i' src '-o' dst '--source' ipaddr '-j' 'ACCEPT' run settings.iptables '-D' 'FORWARD' '-i' dst '-o' src '--destination' ipaddr '-j' 'ACCEPT'
def addMtime document fullpath for node in domhelpers.findElementsWithAttribute document 'class' 'mtime' txt dom.Text txt.data time.ctime os.path.getmtime fullpath node.appendChild txt
def binom_test count nobs prop 0.5 alternative 'two-sided' if np.any prop > 1.0 or np.any prop < 0.0 raise ValueError 'pmustbeinrange[0 1]' if alternative in ['2s' 'two-sided'] pval stats.binom_test count n nobs p prop elif alternative in ['l' 'larger'] pval stats.binom.sf count - 1 nobs prop elif alternative in ['s' 'smaller'] pval stats.binom.cdf count nobs prop else raise ValueError 'alternativenotrecognized\nshouldbetwo-sided largerorsmaller' return pval
def _validate_flavor_service_type validate_type valid_values None if not directory.get_plugin validate_type raise InvalidFlavorServiceType service_type validate_type
def get_relative_path path components split_all path if len components < 1 return os.curdirelse parents [os.pardir] * len components - 1 return os.path.join *parents
def check_network_connection server 'www.google.com' logger logging.getLogger __name__ logger.debug "Checkingnetworkconnectiontoserver'%s'..." server try host socket.gethostbyname server socket.create_connection host 80 2 except Exception logger.debug 'Networkconnectionnotworking' return Falseelse logger.debug 'Networkconnectionworking' return True
def get_system_encoding try encoding locale.getdefaultlocale [1] or 'ascii' codecs.lookup encoding except Exception encoding 'ascii'return encoding
@library.global_function@library.render_with 'landing/newsfeed.html' def newsfeed entries section_headers False return {'updates' entries 'section_headers' section_headers}
def quote_plus string safe '' encoding None errors None if isinstance string str and '' not in string or isinstance string bytes and '' not in string return quote string safe encoding errors if isinstance safe str space ''else space ''string quote string safe + space encoding errors return string.replace '' '+'
def get_mask_ipv4 bits if bits > 32 or bits < 0 raise ValueError 'Amaskcanonlybe0-32bits got%i' % bits elif bits 32 return FULL_IPv4_MASKmask_bin _get_binary 2 ** bits - 1 32 [ -1 ]octets [mask_bin[ 8 * i 8 * i + 1 ] for i in range 4 ]return '.'.join [str int octet 2 for octet in octets]
def delete_mig mig changed Falsereturn_data []actions_filter ['NONE' 'CREATING' 'RECREATING' 'DELETING' 'ABANDONING' 'RESTARTING' 'REFRESHING']instance_names _get_instance_list mig filter_list actions_filter if mig.destroy changed Truereturn_data instance_namesreturn changed return_data
def relative v n float sum v.values or 1.0 s dict.__setitem__for f in v s v f v[f] / n return v
def cxPartialyMatched ind1 ind2 size min len ind1 len ind2 p1 p2 [0] * size [0] * size for i in xrange size p1[ind1[i]] ip2[ind2[i]] icxpoint1 random.randint 0 size cxpoint2 random.randint 0 size - 1 if cxpoint2 > cxpoint1 cxpoint2 + 1else cxpoint1 cxpoint2 cxpoint2 cxpoint1 for i in xrange cxpoint1 cxpoint2 temp1 ind1[i]temp2 ind2[i] ind1[i] ind1[p1[temp2]] temp2 temp1 ind2[i] ind2[p2[temp1]] temp1 temp2 p1[temp1] p1[temp2] p1[temp2] p1[temp1] p2[temp1] p2[temp2] p2[temp2] p2[temp1] return ind1 ind2
def response_text response encoding None encoding encoding or get_encoding_from_headers response.headers or 'utf-8' return response.body.decode encoding 'replace'
def query_log_status module le_path path state 'present' if state 'present' rc out err module.run_command '%sfollowed%s' % le_path path if rc 0 return Truereturn False
def transformation_to_DN eq var coeff diop_type classify_diop eq _dict False if diop_type 'binary_quadratic' return _transformation_to_DN var coeff
def _get_ssl_opts sslopts __salt__['config.option'] 'cassandra' .get 'ssl_options' None ssl_opts {}if sslopts ssl_opts['ca_certs'] sslopts['ca_certs']if SSL_VERSION in sslopts if not sslopts[SSL_VERSION].startswith 'PROTOCOL_' valid_opts ' '.join [x for x in dir ssl if x.startswith 'PROTOCOL_' ] raise CommandExecutionError 'Invalidprotocol_versionspecified!PleasemakesurethatthesslprotocolversionisonefromtheSSLmodule.Validoptionsare{0}'.format valid_opts else ssl_opts[SSL_VERSION] getattr ssl sslopts[SSL_VERSION] return ssl_optselse return None
def collect_glib_share_files *path glib_data_dirs get_glib_system_data_dirs if glib_data_dirs is None return []destdir os.path.join 'share' *path[ -1 ] collected []for data_dir in glib_data_dirs p os.path.join data_dir *path collected + collect_system_data_files p destdir destdir include_py_files False return collected
def document_etag value ignore_fields None if ignore_fields def filter_ignore_fields d fields for field in fields key _ value field.partition '.' if value filter_ignore_fields d[key] [value] elif field in d d.pop field else passvalue_ copy value filter_ignore_fields value_ ignore_fields else value_ valueh hashlib.sha1 json_encoder app.data.json_encoder_class h.update dumps value_ sort_keys True default json_encoder.default .encode 'utf-8' return h.hexdigest
def cluster_sequence creation_sequence triseq triangle_sequence creation_sequence degseq degree_sequence creation_sequence cseq []for i deg in enumerate degseq tri triseq[i]if deg < 1 cseq.append 0 continuemax_size deg * deg - 1 // 2 cseq.append float tri / float max_size return cseq
def post_mortem level 1 if config.DEBUG > level pdb.post_mortem
def dup_add_mul f g h K return dup_add f dup_mul g h K K
def _worktrees_supported try return _git_version > LooseVersion '2.5.0' .encode except AttributeError return False
def get_os if sys.platform 'darwin' return 'mac'elif sys.platform.find 'freebsd' ! -1 return 'freebsd'elif sys.platform.find 'linux' ! -1 return 'linux'elif sys.platform.find 'win32' ! -1 return 'windows'elif sys.platform.find 'sunos' ! -1 return 'solaris'else return sys.platform
def validate_uris value v RedirectURIValidator oauth2_settings.ALLOWED_REDIRECT_URI_SCHEMES for uri in value.split v uri
def libvlc_clearerr f _Cfunctions.get 'libvlc_clearerr' None or _Cfunction 'libvlc_clearerr' None None return f
def do_SpnRegister po if not g_createdSPNLast _option_error po 'SpnCreatemustappearbeforeSpnRegister' SpnRegister _get_option po 'account_name_dn' None g_createdSPNLast dscon.DS_SPN_ADD_SPN_OP return g_createdSPNLast
def Sourceify path if '$ ' in path return pathif os.path.isabs path return pathreturn srcdir_prefix + path
def split_provision value global _provision_rxif _provision_rx is None _provision_rx re.compile ' [a-zA-Z_]\\w* ? \\.[a-zA-Z_]\\w* * ? \\s*\\ \\s* [^ \\s]+ \\s*\\ ?$' value value.strip m _provision_rx.match value if not m raise ValueError 'illegalprovidesspecification %r' % value ver m.group 2 or None if ver ver distutils.version.StrictVersion ver return m.group 1 ver
def find_service_and_method_in_event_name event_name split_event event_name.split '.' [1 ]service_name Noneif len split_event > 0 service_name split_event[0]operation_name Noneif len split_event > 1 operation_name split_event[1]return service_name operation_name
def setattr_on_read func return OneTimeProperty func
def _check_with_col_sign_flipping A B tol 0.0 sign Truefor column_idx in range A.shape[1] sign sign and A[ column_idx] - B[ column_idx] ** 2 .mean < tol ** 2 or A[ column_idx] + B[ column_idx] ** 2 .mean < tol ** 2 if not sign return Falsereturn True
def list_artifacts_opts return [ g copy.deepcopy o for g o in _artifacts_opts]
def ParseMessage descriptor byte_str class _ResultClass message.Message __metaclass__ GeneratedProtocolMessageTypeDESCRIPTOR descriptornew_msg _ResultClass new_msg.ParseFromString byte_str return new_msg
def create_item_version item if not item.version_fields return_hash hashlib.sha1 for attrname in item.version_fields _hash.update repr item.get attrname return _hash.digest
def _get_masked_bits mask if not is_valid_ipv4_address mask raise ValueError "'%s'isaninvalidsubnetmask" % mask mask_bin _get_address_binary mask mask_match re.match '^ 1* 0* $' mask_bin if mask_match return 32 - len mask_match.groups [1] else raise ValueError 'Unabletoconvertmasktoabitcount %s' % mask
def get_prio gtype section try return sabnzbd.config.get_config section '%s_prio_%s' % section gtype except TypeError logging.debug 'IncorrectNotifyoption%s %s_prio_%s' section section gtype return -1000
def replace_vars m var m.group 1 default m.group 2 if not re.match '\\w+$' var raise UnsupportedVariableExpression var translate_vars {'TM_PHP_OPEN_TAG_WITH_ECHO' 'g UltiSnipsOpenTagWithEcho' 'TM_PHP_OPEN_TAG' 'g UltiSnipsOpenTag' 'PHPDOC_AUTHOR' 'g snips_author'}if var in translate_vars newvar translate_vars[var]else raise UnknownVariable var return "`!vexists '%s' ?%s '%s'`" % newvar newvar default
def MakeControlClass controlClass name None if name is None name controlClass.__name__return new_type 'OCX' + name Control controlClass {}
def getTricomplextranslate transformWords translate euclidean.getComplexByWords transformWords return [complex 1.0 0.0 complex 0.0 1.0 translate]
def get_repo_options flocker_version is_dev not is_release flocker_version if is_dev return ['--enablerepo clusterhq-testing']else return []
def libvlc_media_discoverer_new p_inst psz_name f _Cfunctions.get 'libvlc_media_discoverer_new' None or _Cfunction 'libvlc_media_discoverer_new' 1 1 class_result MediaDiscoverer ctypes.c_void_p Instance ctypes.c_char_p return f p_inst psz_name
def iterkeys d return iter getattr d _iterkeys
def get_top_keywords service profile_id return service.data .ga .get ids 'ga ' + profile_id start_date '2012-01-01' end_date '2012-01-15' metrics 'ga visits' dimensions 'ga source ga keyword' sort '-ga visits' filters 'ga medium organic' start_index '1' max_results '25' .execute
def send_email_with_reset_password_hash email link send_email to email action PASSWORD_RESET subject MAILS[PASSWORD_RESET]['subject'].format app_name get_settings ['app_name'] html MAILS[PASSWORD_RESET]['message'].format link link
def test_gpualloc x theano.shared numpy.ones 3 dtype 'float32' 'x' m x.dimshuffle ['x' 0] v tensor.alloc 1.0 *m.shape f theano.function [] v + x mode mode_with_gpu.excluding 'local_elemwise_alloc' l f.maker.fgraph.toposort assert numpy.any [isinstance y.op cuda.GpuAlloc for y in l]
def set_buf_size fd if OS_PIPE_SZ and hasattr fcntl 'F_SETPIPE_SZ' fcntl.fcntl fd fcntl.F_SETPIPE_SZ OS_PIPE_SZ
def profile func stream None def wrapper *args **kwargs prof LineProfiler val prof func *args **kwargs show_results prof stream stream return valreturn wrapper
def setVersion template version for node in domhelpers.findElementsWithAttribute template 'class' 'version' text dom.Text text.data versionnode.appendChild text
def block_device_mapping_get_by_instance_and_volume_id context volume_id instance_uuid columns_to_join None return IMPL.block_device_mapping_get_by_instance_and_volume_id context volume_id instance_uuid columns_to_join
def semanage_port_get_type seport port proto ports port.split '-' 1 if len ports 1 ports.extend ports key int ports[0] int ports[1] proto records seport.get_all if key in records return records[key]else return None
def convert_ip_to_binary ip_address octets ip_address.split '.' ip_addr_bin []for octet in octets bin_octet bin int octet bin_octet bin_octet[2 ]bin_octet pad_binary_digits bin_octet ip_addr_bin.append bin_octet return '.'.join ip_addr_bin
def get_version version None if version is None from gfirefly import VERSION as versionelse assert len version 5 assert version[3] in u'alpha' u'beta' u'rc' u'final' parts 2 if version[2] 0 else 3 main u'.'.join str x for x in version[ parts] sub u''if version[3] u'alpha' and version[4] 0 git_changeset get_git_changeset if git_changeset sub u'.dev%s' % git_changeset elif version[3] ! u'final' mapping {u'alpha' u'a' u'beta' u'b' u'rc' u'c'}sub mapping[version[3]] + str version[4] return str main + sub
def load_example_module example mod __import__ example return mod
def merge_hooks request_hooks session_hooks dict_class OrderedDict if session_hooks is None or session_hooks.get 'response' [] return request_hooksif request_hooks is None or request_hooks.get 'response' [] return session_hooksreturn merge_setting request_hooks session_hooks dict_class
def widont value count 1 def replace matchobj return u'&nbsp;%s' % matchobj.group 1 for i in range count value re_widont.sub replace force_unicode value return value
def _read_temp data tout StringIO tout.write data tout.seek 0 output tout.readlines tout.close return output
@pytest.fixture def admin_user db return User.objects.create_superuser u'admin@example.com' u'password'
def create_menu menu_items parent None nodes []default_fn import_string settings.OSCAR_DASHBOARD_DEFAULT_ACCESS_FUNCTION for menu_dict in menu_items try label menu_dict['label']except KeyError raise ImproperlyConfigured 'Nolabelspecifiedformenuitemindashboard' children menu_dict.get 'children' [] if children node Node label label icon menu_dict.get 'icon' None access_fn menu_dict.get 'access_fn' default_fn create_menu children parent node else node Node label label icon menu_dict.get 'icon' None url_name menu_dict.get 'url_name' None url_kwargs menu_dict.get 'url_kwargs' None url_args menu_dict.get 'url_args' None access_fn menu_dict.get 'access_fn' default_fn if parent is None nodes.append node else parent.add_child node return nodes
def get_openstack_region_for_test config get_blockdevice_config return config['region']
def short_name nt_uri return nt_uri[SHORTNAME_SLICE]
def permute_signs t for signs in cartes * [ 1 -1 ] * len t - t.count 0 signs list signs yield type t [ i * signs.pop if i else i for i in t]
def _remove_old_connections facebook_id current_user_id None other_facebook_accounts _get_old_connections facebook_id current_user_id other_facebook_accounts.update facebook_id None
def addPlainListings document dir for node in domhelpers.findElementsWithAttribute document 'class' 'listing' filename node.getAttribute 'href' val '<pre>\n%s</pre>' % cgi.escape open os.path.join dir filename .read _replaceWithListing node val filename 'listing'
def unpack_thin thin_path tfile tarfile.TarFile.gzopen thin_path old_umask os.umask 63 tfile.extractall path OPTIONS.saltdir tfile.close os.umask old_umask os.unlink thin_path
def RLock *args **kwargs return _RLock *args **kwargs
@register.filter needs_autoescape True def smartcoffee value autoescape True 'andalsodetectssurroundingautoescapeonfilter ifany andescapes'if autoescape value escape value result '<b>%s</b>' % value return mark_safe result
def commify n if n is None return Nonen str n if '.' in n dollars cents n.split '.' else dollars cents n None r []for i c in enumerate str dollars [ -1 ] if i and not i % 3 r.insert 0 ' ' r.insert 0 c out ''.join r if cents out + '.' + cents return out
def get_namespace_keys app limit ns_query datastore.Query '__namespace__' keys_only True _app app return ns_query.Get limit limit
def _RemoveV4Ending addr_string match V4_ENDING.match addr_string if match ipv4_addr '.'.join match.groups [1 ] try socket.inet_aton ipv4_addr except socket.error ValueError raise socket.error 'IllegalIPv4extension %s' % addr_string if int match.group 2 0 raise socket.error "IPv4can'tstartwith0" return '%s %04x %04x' % match.group 'v6' int match.group 2 * 256 + int match.group 3 int match.group 4 * 256 + int match.group 5 return addr_string
def v_measure_score labels_true labels_pred return homogeneity_completeness_v_measure labels_true labels_pred [2]
def parse_role_attrs role_attr_flags if ' ' in role_attr_flags flag_set frozenset r.upper for r in role_attr_flags.split ' ' elif role_attr_flags flag_set frozenset role_attr_flags.upper else flag_set frozenset if not flag_set.issubset VALID_FLAGS raise InvalidFlagsError 'Invalidrole_attr_flagsspecified %s' % ''.join flag_set.difference VALID_FLAGS o_flags ''.join flag_set return o_flags
def MemValues for line in open '/proc/meminfo' .readlines if line.startswith 'MemTotal ' memTotal line.split [1]if line.startswith 'MemFree ' memFree line.split [1]if line.startswith 'Cached ' memCached line.split [1]return memTotal memCached memFree
def get_global_option checker option default None try return getattr checker.config option.replace '-' '_' except AttributeError passfor provider in checker.linter.options_providers for options in provider.options if options[0] option return getattr provider.config option.replace '-' '_' return default
def dump device args None cmd 'blockdev--getro--getsz--getss--getpbsz--getiomin--getioopt--getalignoff--getmaxsect--getsize--getsize64--getra--getfra{0}'.format device ret {}opts [c[2 ] for c in cmd.split if c.startswith '--' ]out __salt__['cmd.run_all'] cmd python_shell False if out['retcode'] 0 lines [line for line in out['stdout'].splitlines if line]count 0for line in lines ret[opts[count]] linecount count + 1 if args temp_ret {}for arg in args temp_ret[arg] ret[arg]return temp_retelse return retelse return False
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def test_rus_fit_sample_half ratio 0.5rus RandomUnderSampler ratio ratio random_state RND_SEED X_resampled y_resampled rus.fit_sample X Y X_gt np.array [[0.92923648 0.76103773] [0.47104475 0.44386323] [0.13347175 0.12167502] [0.09125309 -0.85409574 ] [0.12372842 0.6536186] [0.04352327 -0.20515826 ] [0.15490546 0.3130677] [0.15490546 0.3130677] [0.15490546 0.3130677]] y_gt np.array [0 0 0 1 1 1 1 1 1] assert_array_equal X_resampled X_gt assert_array_equal y_resampled y_gt
def get_zone zone_id profile conn _get_driver profile profile return conn.get_zone zone_id
def _match_sort_key m return m['timestamp'] is None m['timestamp'] or ''
def flatten_list list_of_list [[] []] return sum list_of_list []
def blend_channels_hard_light bottom_chan top_chan dk lt top_chan < 0.5 top_chan > 0.5 output_chan numpy.empty bottom_chan.shape bottom_chan.dtype output_chan[dk] 2 * bottom_chan[dk] * top_chan[dk] output_chan[lt] 1 - 2 * 1 - bottom_chan[lt] * 1 - top_chan[lt] return output_chan
def partition_all n seq args [iter seq ] * n it zip_longest fillvalue no_pad *args prev next it for item in it yield prev prev itemif prev[ -1 ] is no_pad yield prev[ prev.index no_pad ] else yield prev
def _games_in_week year week kind 'REG' return nflgame._search_schedule year week kind kind
def quota_destroy_by_project context project_id return IMPL.quota_destroy_by_project context project_id
def client_end request socket context for channel in socket.channels events.on_unsubscribe.send request socket context channel events.on_finish.send request socket context for channel in socket.channels[ ] socket.unsubscribe channel del CLIENTS[socket.session.session_id]
def verifyChecksum buffer buff0 buffer[0]buff4 buffer[4]buff5 buffer[5]tempBuffer setChecksum buffer if buff0 tempBuffer[0] and buff4 tempBuffer[4] and buff5 tempBuffer[5] return Truereturn False
def git_new_branch name check_call ['git' 'checkout' '-b' name]
def network_get_by_cidr context cidr return IMPL.network_get_by_cidr context cidr
def urlunquote_plus quoted_url return force_text unquote_plus force_str quoted_url
def cosine_distances X Y if X is Y X Y np.asanyarray X else X np.asanyarray X Y np.asanyarray Y if X.shape[1] ! Y.shape[1] raise ValueError 'IncompatibledimensionforXandYmatrices' return 1.0 - ssd.cdist X Y 'cosine'
@cached_classmethoddef get_edit_handler cls if hasattr cls u'edit_handler' return cls.edit_handler.bind_to_model cls tabs []if cls.content_panels tabs.append ObjectList cls.content_panels heading ugettext_lazy u'Content' if cls.promote_panels tabs.append ObjectList cls.promote_panels heading ugettext_lazy u'Promote' if cls.settings_panels tabs.append ObjectList cls.settings_panels heading ugettext_lazy u'Settings' classname u'settings' EditHandler TabbedInterface tabs base_form_class cls.base_form_class return EditHandler.bind_to_model cls
def libvlc_audio_equalizer_set_preamp p_equalizer f_preamp f _Cfunctions.get 'libvlc_audio_equalizer_set_preamp' None or _Cfunction 'libvlc_audio_equalizer_set_preamp' 1 1 None ctypes.c_int ctypes.c_void_p ctypes.c_float return f p_equalizer f_preamp
@cli_app.command 'create-db' @click.option '--app' default 'app' help 'Yourapplicationinitdirectory package ' @click.option '--appbuilder' default 'appbuilder' help 'yourAppBuilderobject' def create_db app appbuilder from flask_appbuilder.models.sqla import Base_appbuilder import_application app appbuilder engine _appbuilder.get_session.get_bind mapper None clause None Base.metadata.create_all engine click.echo click.style 'DBobjectscreated' fg 'green'
def in_box coords box if box[0][0] < coords[0] < box[1][0] and box[1][1] < coords[1] < box[0][1] return Truereturn False
def get_secret_key keyid None fingerprint None user None gnupghome None tmp {}for _key in _list_keys user gnupghome secret True if _key['fingerprint'] fingerprint or _key['keyid'] keyid or _key['keyid'][8 ] keyid tmp['keyid'] _key['keyid']tmp['fingerprint'] _key['fingerprint']tmp['uids'] _key['uids']expires _key.get 'expires' None date _key.get 'date' None length _key.get 'length' None owner_trust _key.get 'ownertrust' None trust _key.get 'trust' None if expires tmp['expires'] time.strftime '%Y-%m-%d' time.localtime float _key['expires'] if date tmp['created'] time.strftime '%Y-%m-%d' time.localtime float _key['date'] if length tmp['keyLength'] _key['length']if owner_trust tmp['ownerTrust'] LETTER_TRUST_DICT[_key['ownertrust']]if trust tmp['trust'] LETTER_TRUST_DICT[_key['trust']]if not tmp return Falseelse return tmp
def bytes_to_text s encoding if isinstance s bytes return six.text_type s encoding u'replace' else return s
@require_context@contextlib.contextmanagerdef pinned *arylist pmlist []for ary in arylist pm current_context .mempin ary driver.host_pointer ary driver.host_memory_size ary mapped False pmlist.append pm yield del pmlist
def detect_fakeroot return os.getenv 'FAKEROOTKEY' ! None
def _server_namespace_handler k v atoms k.split '.' 1 if len atoms > 1 if not hasattr cherrypy 'servers' cherrypy.servers {} servername k atomsif servername not in cherrypy.servers from cherrypy import _cpservercherrypy.servers[servername] _cpserver.Server cherrypy.servers[servername].subscribe if k 'on' if v cherrypy.servers[servername].subscribe else cherrypy.servers[servername].unsubscribe else setattr cherrypy.servers[servername] k v else setattr cherrypy.server k v
def stop name kill False runas None args [_sdecode name ]if kill args.append '--kill' return prlctl 'stop' args runas runas
def IdentifiersConcat def step ctxt key val ctxt.append u'%s %s' % key val def finalize ctxt return u' '.join ctxt return [] step finalize
def install_memory_dumper dump_signal signal.SIGPROF signal.signal dump_signal dump_memory
def fix_win_pythonw_std_stream if sys.platform 'win32' and os.path.basename sys.executable 'pythonw.exe' if sys.stdout is None sys.stdout open os.devnull 'w' if sys.stderr is None sys.stderr open os.devnull 'w'
def write_chunk outfile tag data '' outfile.write struct.pack '!I' len data outfile.write tag outfile.write data checksum zlib.crc32 tag checksum zlib.crc32 data checksum outfile.write struct.pack '!i' checksum
def GetDriverVersion if os.name 'nt' staticLib.GetDriverVersion.restype ctypes.c_floatreturn str staticLib.GetDriverVersion elif os.name 'posix' staticLib.LJUSB_GetLibraryVersion.restype ctypes.c_floatreturn '%.2f' % staticLib.LJUSB_GetLibraryVersion
def LoadYamlConfig config_file_name loaders exporters bulkloader_config.load_config config_file_name increment_id IncrementId for cls in loaders Loader.RegisterLoader cls for cls in exporters Exporter.RegisterExporter cls
def build_empty_response search_path operation_name service_model response Noneoperation_model service_model.operation_model operation_name shape operation_model.output_shapeif search_path for item in search_path.split '.' item item.strip '[0123456789]$' if shape.type_name 'structure' shape shape.members[item]elif shape.type_name 'list' shape shape.memberelse raise NotImplementedError 'Searchpathhitsshapetype{0}from{1}'.format shape.type_name item if shape.type_name 'structure' response {}elif shape.type_name 'list' response []elif shape.type_name 'map' response {}return response
def _wait_for_vhd_coalesce session instance sr_ref vdi_ref vdi_uuid_list if len vdi_uuid_list 1 LOG.debug 'OldchainissingleVHD coalescenotpossible.' instance instance returnparent_vdi_uuid vdi_uuid_list[1]if _count_children session parent_vdi_uuid sr_ref > 1 LOG.debug 'Parenthasotherchildren coalesceisunlikely.' instance instance returnmax_attempts CONF.xenserver.vhd_coalesce_max_attemptsgood_parent_uuids vdi_uuid_list[1 ]for i in range max_attempts _scan_sr session sr_ref parent_uuid _get_vhd_parent_uuid session vdi_ref if parent_uuid and parent_uuid not in good_parent_uuids LOG.debug 'Parent% parent_uuid snotyetinparentlist% good_parent_uuids s waitingforcoalesce...' {'parent_uuid' parent_uuid 'good_parent_uuids' good_parent_uuids} instance instance else LOG.debug 'Coalescedetected becauseparentis %s' parent_uuid instance instance returngreenthread.sleep CONF.xenserver.vhd_coalesce_poll_interval msg _ 'VHDcoalesceattemptsexceeded %d givingup...' % max_attempts raise exception.NovaException msg
def test_magnetic_dipole trans Transform 'mri' 'head' info read_info fname_raw picks pick_types info meg True eeg False exclude [] info pick_info info picks[ 12] coils _create_meg_coils info['chs'] 'normal' trans r0 np.array [0.0 13.0 -6.0 ] for ch coil in zip info['chs'] coils rr ch['loc'][ 3] + r0 / 2.0 far_fwd _magnetic_dipole_field_vec r0[np.newaxis ] [coil] near_fwd _magnetic_dipole_field_vec rr[np.newaxis ] [coil] ratio 8.0 if ch['ch_name'][ -1 ] '1' else 16.0 assert_allclose np.median near_fwd / far_fwd ratio atol 0.1
def validate_not_blank value if not value.strip raise ValidationError 'Thisfieldmaynotbeblank.'
def cache_page *args **kwargs if len args ! 1 or callable args[0] raise TypeError 'cache_pagehasasinglemandatorypositionalargument timeout' cache_timeout args[0]cache_alias kwargs.pop 'cache' None key_prefix kwargs.pop 'key_prefix' None if kwargs raise TypeError 'cache_pagehastwooptionalkeywordarguments cacheandkey_prefix' return decorator_from_middleware_with_args CacheMiddleware cache_timeout cache_timeout cache_alias cache_alias key_prefix key_prefix
def exit_sab value sys.stderr.flush sys.stdout.flush if getattr sys 'frozen' None 'macosx_app' sabnzbd.SABSTOP Truefrom PyObjCTools import AppHelperAppHelper.stopEventLoop sys.exit value
def _check_decim info decim offset if decim < 1 or decim ! int decim raise ValueError 'decimmustbeaninteger>0' decim int decim new_sfreq info['sfreq'] / float decim lowpass info['lowpass']if decim > 1 and lowpass is None warn 'Themeasurementinformationindicatesdataisnotlow-passfiltered.Thedecim %iparameterwillresultinasamplingfrequencyof%gHz whichcancausealiasingartifacts.' % decim new_sfreq elif decim > 1 and new_sfreq < 2.5 * lowpass warn 'Themeasurementinformationindicatesalow-passfrequencyof%gHz.Thedecim %iparameterwillresultinasamplingfrequencyof%gHz whichcancausealiasingartifacts.' % lowpass decim new_sfreq offset int offset if not 0 < offset < decim raise ValueError 'decimmustbeatleast0andlessthan%s got%s' % decim offset return decim offset new_sfreq
def should_overwrite settings return settings.get 'GZIP_CACHE_OVERWRITE' False
def update_csp for key in 'CSP_SCRIPT_SRC' values getattr settings key new set for value in values if value.startswith 'https //' and settings.DEBUG res value.replace 'https //' 'http //' for v in value res new.add v continueelif value.startswith 'http //' and not settings.DEBUG continueelse new.add value setattr settings key tuple new
def raise_if_duplicate_entry_error integrity_error engine_name def get_columns_from_uniq_cons_or_name columns uniqbase 'uniq_'if not columns.startswith uniqbase if engine_name 'postgresql' return [columns[ columns.index '_' + 1 columns.rindex '_' ]]return [columns]return columns[len uniqbase ].split '_x_' if engine_name not in ['mysql' 'sqlite' 'postgresql'] returnm _DUP_KEY_RE_DB[engine_name].match integrity_error.message if not m returncolumns m.group 1 if engine_name 'sqlite' columns columns.strip .split ' ' else columns get_columns_from_uniq_cons_or_name columns raise exception.DBDuplicateEntry columns integrity_error
def pid_file pid_path None pid_file None port 0 global DIR_PIDif not sabnzbd.WIN32 if pid_path and pid_path.startswith '/' DIR_PID os.path.join pid_path 'sabnzbd-%s.pid' % port elif pid_file and pid_file.startswith '/' DIR_PID pid_fileif DIR_PID try if port f open DIR_PID 'w' f.write '%d\n' % os.getpid f.close else os.remove DIR_PID except logging.warning 'CannotaccessPIDfile%s' DIR_PID
def maybeName obj try return obj.__name__except AttributeError return str obj
def __routes_doctest pass
def test_simple_cons entry tokenize ' a.b ' [0]assert entry HyCons HySymbol 'a' HySymbol 'b'
def host_tuple url if not url.isValid raise InvalidUrlError url scheme host port url.scheme url.host url.port assert schemeif not host raise ValueError 'GotURL{}withouthost.'.format url.toDisplayString if port -1 port_mapping {'http' 80 'https' 443 'ftp' 21}try port port_mapping[scheme]except KeyError raise ValueError 'GotURL{}withunknownport.'.format url.toDisplayString return scheme host port
def delete_ssh_key username _xml '<RIBCLVERSION "2.0">\n<LOGINUSER_LOGIN "admin"PASSWORD "admin123">\n<USER_INFOMODE "write">\n<MOD_USERUSER_LOGIN "{0}">\n<DEL_USERS_SSH_KEY/>\n</MOD_USER>\n</USER_INFO>\n</LOGIN>\n</RIBCL>'.format username return __execute_cmd 'Delete_user_SSH_key' _xml
def is_octal string return all ch in OCT_DIGITS for ch in string
def get_sample_ids map_data map_header states name_to_col dict [ s map_header.index s for s in states] good_ids []for row in map_data include Truefor s vals in states.items curr_state row[name_to_col[s]]include include and curr_state in vals or '*' in vals and not '!' + curr_state in vals if include good_ids.append row[0] return good_ids
def Get keys **kwargs return GetAsync keys **kwargs .get_result
def build_real_request wsgi_environ config testing.setUp settings DEFAULT_SETTINGS includeme config request pyramid_request.Request wsgi_environ request.registry config.registryreturn request
def kursawe individual f1 sum -10 * exp -0.2 * sqrt x * x + y * y for x y in zip individual[ -1 ] individual[1 ] f2 sum abs x ** 0.8 + 5 * sin x * x * x for x in individual return f1 f2
@app.route '/html' def view_html_page return render_template 'moby.html'
def getFloatFromCharacterSplitLine character splitLine lineFromCharacter gcodec.getStringFromCharacterSplitLine character splitLine if lineFromCharacter is None return Nonereturn float lineFromCharacter
def isFixedGroup kexAlgorithm return _IFixedGroupKexAlgorithm.providedBy getKex kexAlgorithm
def is_votable origin filepath fileobj *args **kwargs from . import is_votableif origin u'read' if fileobj is not None try result is_votable fileobj finally fileobj.seek 0 return resultelif filepath is not None return is_votable filepath elif isinstance args[0] VOTableFile VOTable return Trueelse return Falseelse return False
def to_rfc1123 when assert when.tzinfo is None return when.strftime _RFC1123 + 'GMT'
def hessian image scale_range 1 10 scale_step 2 beta1 0.5 beta2 15 filtered lambdas _frangi_hessian_common_filter image scale_range scale_step beta1 beta2 filtered[ lambdas < 0 ] 0out np.max filtered axis 0 out[ out < 0 ] 1return out
def get_project_build account_project url make_url '/projects/{account_project}' account_project account_project response requests.get url headers make_auth_headers return response.json
def user_can_edit_snippets user snippet_models get_snippet_models for model in snippet_models if user_can_edit_snippet_type user model return Truereturn False
def list_vpnservices retrieve_all True profile None **kwargs conn _auth profile return conn.list_vpnservices retrieve_all **kwargs
def dilate input factors output np.zeros tuple s - 1 * f + 1 for s f in zip input.shape factors dtype input.dtype output[[slice None None factor for factor in factors]] inputreturn output
def record_user_logged_in user_id user_settings get_user_settings user_id strict True user_settings.last_logged_in datetime.datetime.utcnow _save_user_settings user_settings
def version_parts best False return _distro.version_parts best
def proxy_bypass_environment host proxies None if proxies is None proxies getproxies_environment try no_proxy proxies['no']except KeyError return 0if no_proxy '*' return 1 hostonly port splitport host no_proxy_list [proxy.strip for proxy in no_proxy.split ' ' ]for name in no_proxy_list if name name re.escape name pattern ' .+\\. ?%s$' % name if re.match pattern hostonly re.I or re.match pattern host re.I return 1return 0
def parse_qs qs keep_blank_values False strict_parsing False encoding 'utf-8' errors 'replace' dict {}pairs parse_qsl qs keep_blank_values strict_parsing encoding encoding errors errors for name value in pairs if name in dict dict[name].append value else dict[name] [value]return dict
def parent_document_link obj if not obj.parent return ''url reverse 'admin wiki_document_change' args [obj.parent.id] return '<ahref "%s">Translated&nbsp;from&nbsp; #%s </a>' % url obj.parent.id
def get_change_lines_in_file_for_tag tag change_dict cleaned_lines []data_list change_dict.get 'data' [] for data_dict in data_list block data_dict.get 'block' '' lines block.split '\\n' for line in lines index line.find tag if index > -1 line line[index ]cleaned_lines.append line return cleaned_lines
def check_data_fields header mapping_data errors warnings disable_primer_check False has_barcodes True char_replace '_' variable_len_barcodes False added_demultiplex_field None errors check_dna_chars_primers header mapping_data errors disable_primer_check if has_barcodes errors check_dna_chars_bcs header mapping_data errors has_barcodes if not variable_len_barcodes and has_barcodes warnings check_bcs_lengths header mapping_data warnings errors check_bc_duplicates header mapping_data errors has_barcodes variable_len_barcodes added_demultiplex_field errors check_sampleid_duplicates header mapping_data errors warnings check_chars_data_fields header mapping_data warnings warnings check_fields_past_bounds header mapping_data warnings warnings check_empty_fields_before_bounds header mapping_data warnings return errors warnings
def laplace_transform f t s **hints if isinstance f MatrixBase and hasattr f 'applyfunc' return f.applyfunc lambda fij laplace_transform fij t s **hints return LaplaceTransform f t s .doit **hints
def setup_axes fig rect tr Affine2D .scale np.pi / 180.0 1.0 + PolarAxes.PolarTransform extreme_finder angle_helper.ExtremeFinderCycle 20 20 lon_cycle 360 lat_cycle None lon_minmax None lat_minmax 0 np.inf grid_locator1 angle_helper.LocatorDMS 12 grid_locator2 grid_finder.MaxNLocator 5 tick_formatter1 angle_helper.FormatterDMS grid_helper GridHelperCurveLinear tr extreme_finder extreme_finder grid_locator1 grid_locator1 grid_locator2 grid_locator2 tick_formatter1 tick_formatter1 ax1 axisartist.Subplot fig rect grid_helper grid_helper ax1.axis[ ].toggle ticklabels False fig.add_subplot ax1 ax1.set_aspect 1.0 ax1.set_xlim -5 12 ax1.set_ylim -5 10 return ax1
@jit nopython True def _has_sorted_sa_indices s_indices a_indices L len s_indices for i in range L - 1 if s_indices[i] > s_indices[ i + 1 ] return Falseif s_indices[i] s_indices[ i + 1 ] if a_indices[i] > a_indices[ i + 1 ] return Falsereturn True
def test_untied_ae ae Autoencoder 5 7 act_enc 'tanh' act_dec 'cos' tied_weights True model UntiedAutoencoder ae model._ensure_extensions
def triu m k 0 return m * 1 - tri m.shape[0] m.shape[1] k k - 1 dtype m.dtype
def get_last_modification fileName return QtCore.QFileInfo fileName .lastModified
def prepare_asides func @functools.wraps func def wrapper *args **kwargs '\nSupportedkwargs \nasides-listwithconnectedasidesdataforthepassedblock\n'if 'asides' in kwargs kwargs['asides'] prepare_asides_to_store kwargs['asides'] return func *args **kwargs return wrapper
def isoparse iso_str dt_args [int p for p in _NONDIGIT_RE.split iso_str ]return datetime *dt_args
@click.command 'disable-production' def disable_production from bench.config.production_setup import disable_productiondisable_production bench_path '.'
def get_minimal_bsgs base gens G PermutationGroup gens base gens G.schreier_sims_incremental if not _is_minimal_bsgs base gens return Nonereturn base gens
def tx_partition app txid murmur_int mmh3.hash64 app + str txid [0]return bytearray struct.pack '<q' murmur_int
@pytest.mark.parametrize 'url expected' 'hTTp //u p@Some.Host/path' 'http //some.host.proxy' 'hTTp //u p@Other.Host/path' 'http //http.proxy' 'hTTps //Other.Host' None 'file ///etc/motd' None def test_select_proxies url expected proxies {'http' 'http //http.proxy' 'http //some.host' 'http //some.host.proxy'}assert select_proxy url proxies expected
def u s return s if PY3 or type s is unicode else unicode s.encode 'string-escape' 'unicode_escape'
def set_stream_rates if not msg_period.trigger and mpstate.status.last_streamrate1 mpstate.settings.streamrate and mpstate.status.last_streamrate2 mpstate.settings.streamrate2 returnmpstate.status.last_streamrate1 mpstate.settings.streamratempstate.status.last_streamrate2 mpstate.settings.streamrate2for master in mpstate.mav_master if master.linknum 0 rate mpstate.settings.streamrateelse rate mpstate.settings.streamrate2if rate ! -1 master.mav.request_data_stream_send mpstate.settings.target_system mpstate.settings.target_component mavutil.mavlink.MAV_DATA_STREAM_ALL rate 1
def check_opts conf opts names []for opt in opts names.append opt.name check_opt_value conf names
def filter_table_to_core table sample_ids None fraction_for_core 1.0 filter_f get_filter_to_core_f table sample_ids fraction_for_core return table.filter filter_f axis 'observation' inplace False
def node_method node method_name for n in node.local_attr method_name if isinstance n astroid.Function return nraise astroid.NotFoundError method_name
@register_stabilize@register_specialize@local_optimizer None def local_det_chol node if node.op det x node.inputsfor cl xpos in x.clients if isinstance cl.op Cholesky L cl.outputs[0]return [tensor.prod extract_diag L ** 2 ]
def url_params_from_lookup_dict lookups params {}if lookups and hasattr lookups 'items' items []for k v in lookups.items if callable v v v if isinstance v tuple list v ' '.join str x for x in v elif isinstance v bool v '0' '1' [v]else v str v items.append k v params.update dict items return params
def urlunsplit components scheme netloc url query fragment _coerce_result _coerce_args *components if netloc or scheme and scheme in uses_netloc and url[ 2] ! '//' if url and url[ 1] ! '/' url '/' + url url '//' + netloc or '' + url if scheme url scheme + ' ' + url if query url url + '?' + query if fragment url url + '#' + fragment return _coerce_result url
def import_site_symbol path module name dummy None modulefile None module import_site_module path module modulefile modulefile if not module return dummycant_import object obj getattr module name cant_import if obj is cant_import logging.debug "unabletoimportsitesymbol'%s' usingnon-siteimplementation" name return dummyreturn obj
def run _task
def _scrub_headers headers headers dict headers if 'Authorization' in headers auth headers['Authorization']if auth.startswith 'token' headers['Authorization'] 'token[secret]'return headers
def unpicklechops string return loads zlib.decompress base64.decodestring string
def _parse_settings_bond_6 opts iface bond_def bond {'mode' '6'}for binding in ['miimon' 'downdelay' 'updelay'] if binding in opts try int opts[binding] bond.update {binding opts[binding]} except ValueError _raise_error_iface iface binding ['integer'] else _log_default_iface iface binding bond_def[binding] bond.update {binding bond_def[binding]} if 'use_carrier' in opts if opts['use_carrier'] in _CONFIG_TRUE bond.update {'use_carrier' '1'} elif opts['use_carrier'] in _CONFIG_FALSE bond.update {'use_carrier' '0'} else valid _CONFIG_TRUE + _CONFIG_FALSE _raise_error_iface iface 'use_carrier' valid else _log_default_iface iface 'use_carrier' bond_def['use_carrier'] bond.update {'use_carrier' bond_def['use_carrier']} return bond
def create_ohlc open high low close dates None direction 'both' **kwargs if dates is not None utils.validate_equal_length open high low close dates else utils.validate_equal_length open high low close validate_ohlc open high low close direction **kwargs if direction is 'increasing' ohlc_incr make_increasing_ohlc open high low close dates **kwargs data [ohlc_incr]elif direction is 'decreasing' ohlc_decr make_decreasing_ohlc open high low close dates **kwargs data [ohlc_decr]else ohlc_incr make_increasing_ohlc open high low close dates **kwargs ohlc_decr make_decreasing_ohlc open high low close dates **kwargs data [ohlc_incr ohlc_decr]layout graph_objs.Layout xaxis dict zeroline False hovermode 'closest' return graph_objs.Figure data data layout layout
def _GetRemoteAppId url throttle email passin raw_input_fn raw_input password_input_fn getpass.getpass throttle_class None scheme host_port url_path _ _ urlparse.urlsplit url secure scheme 'https' throttled_rpc_server_factory remote_api_throttle.ThrottledHttpRpcServerFactory throttle throttle_class throttle_class def AuthFunction return _AuthFunction host_port email passin raw_input_fn password_input_fn app_id server remote_api_stub.GetRemoteAppId host_port url_path AuthFunction rpc_server_factory throttled_rpc_server_factory secure secure return app_id server
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
@_replace_by '_tifffile.decode_packbits' def decode_packbits encoded func ord if sys.version[0] '2' else lambda x x result []result_extend result.extendi 0try while True n func encoded[i] + 1 i + 1if n < 129 result_extend encoded[i i + n ] i + nelif n > 129 result_extend encoded[i i + 1 ] * 258 - n i + 1except IndexError passreturn ''.join result if sys.version[0] '2' else bytes result
def makeCloneMap columnsShape outputCloningWidth outputCloningHeight -1 if outputCloningHeight < 0 outputCloningHeight outputCloningWidth columnsHeight columnsWidth columnsShapenumDistinctMasters outputCloningWidth * outputCloningHeight a numpy.empty columnsHeight columnsWidth 'uint32' for row in xrange columnsHeight for col in xrange columnsWidth a[ row col ] col % outputCloningWidth + row % outputCloningHeight * outputCloningWidth return a numDistinctMasters
def _filter_configured_apps module app_found Trueif hasattr settings 'LETTUCE_APPS' and isinstance settings.LETTUCE_APPS list tuple app_found Falsefor appname in settings.LETTUCE_APPS if module.__name__.startswith appname app_found Truereturn app_found
def check_job_access_permission exception_class PopupException def inner view_func def decorate request *args **kwargs if 'workflow' in kwargs job_type 'workflow'elif 'coordinator' in kwargs job_type 'coordinator'else job_type 'bundle'job kwargs.get job_type if job is not None job Job.objects.can_read_or_exception request job exception_class exception_class kwargs[job_type] jobreturn view_func request *args **kwargs return wraps view_func decorate return inner
def activate_packages module port_path packages activate_c 0for package in packages if not query_package module port_path package module.fail_json msg 'failedtoactivate%s package s notpresent' % package if query_package module port_path package state 'active' continue rc out err module.run_command '%sactivate%s' % port_path package if not query_package module port_path package state 'active' module.fail_json msg 'failedtoactivate%s %s' % package out activate_c + 1if activate_c > 0 module.exit_json changed True msg 'activated%spackage s ' % activate_c module.exit_json changed False msg 'package s alreadyactive'
def RemoveOneFlag flag_name flag_values FLAGS if flag_name in flag_values.FlagDict flag_values.__delattr__ flag_name
def get_user_contributions user_id strict False model user_models.UserContributionsModel.get user_id strict strict if model is not None result UserContributions model.id model.created_exploration_ids model.edited_exploration_ids else result Nonereturn result
def dmp_gf_sqf_list f u K all False raise NotImplementedError 'multivariatepolynomialsoverfinitefields'
def create_rpc deadline None callback None if deadline is None deadline get_default_fetch_deadline return apiproxy_stub_map.UserRPC 'urlfetch' deadline callback
def glob_many *globs result []for pattern in globs result.extend glob pattern return sorted result
def CheckUserForLabels username authorized_labels token None authorized_labels set authorized_labels try user aff4.FACTORY.Open 'aff4 /users/%s' % username aff4_type aff4_users.GRRUser token token if authorized_labels.intersection user.GetLabelsNames authorized_labels return Trueelse raise access_control.UnauthorizedAccess 'User%sismissinglabels required %s .' % username authorized_labels except IOError raise access_control.UnauthorizedAccess 'User%snotfound.' % username
def aggregate method value self spec getattr method '_returns' None if spec model _ _ specif model 'self' return sum value self.browse elif model return sum value self.env[model] return value
@register.filter 'phone2numeric' is_safe True def phone2numeric_filter value return phone2numeric value
def _translate_volume_summary_view context vol image_id None d {}d['id'] vol['id']d['status'] vol['status']d['size'] vol['size']d['availability_zone'] vol['availability_zone']d['created_at'] vol['created_at']d['attachments'] []if vol['attach_status'] 'attached' attachment _translate_attachment_detail_view context vol d['attachments'].append attachment d['display_name'] vol['display_name']d['display_description'] vol['display_description']if vol['volume_type_id'] and vol.get 'volume_type' d['volume_type'] vol['volume_type']['name']else d['volume_type'] str vol['volume_type_id'] d['snapshot_id'] vol['snapshot_id']d['source_volid'] vol['source_volid']if image_id d['image_id'] image_idLOG.audit _ 'vol %s' vol context context if vol.get 'volume_metadata' metadata vol.get 'volume_metadata' d['metadata'] dict item['key'] item['value'] for item in metadata elif vol.get 'metadata' and isinstance vol.get 'metadata' dict d['metadata'] vol['metadata']else d['metadata'] {}if vol.get 'volume_glance_metadata' d['bootable'] 'true'else d['bootable'] 'false'return d
def _fsencoding encoding sys.getfilesystemencoding or sys.getdefaultencoding if encoding 'mbcs' encoding 'utf8'return encoding
@utils.arg 'cell' metavar '<cell-name>' help _ 'Nameofthecell.' def do_cell_show cs args cell cs.cells.get args.cell utils.print_dict cell.to_dict
def get_host_from_body fn def wrapped self req id body *args **kwargs if len body 1 and 'host' in body host body['host']else raise exc.HTTPBadRequestreturn fn self req id host *args **kwargs return wrapped
def _find_gap_open sequenceA sequenceB ali_seqA ali_seqB end row col col_gap gap_char score_matrix trace_matrix in_process gap_fn target index direction dead_end Falsetarget_score score_matrix[row][col]for n in range target if direction 'col' col - 1ali_seqA + gap_charali_seqB + sequenceB[col]else row - 1ali_seqA + sequenceA[row]ali_seqB + gap_charactual_score score_matrix[row][col] + gap_fn index n + 1 if rint actual_score rint target_score and n > 0 if not trace_matrix[row][col] breakelse in_process.append ali_seqA[ ] ali_seqB[ ] end row col col_gap trace_matrix[row][col] if not trace_matrix[row][col] dead_end Truereturn ali_seqA ali_seqB row col in_process dead_end
def get_parser description 'Runtoxenvironment s inallsub-packages.'parser argparse.ArgumentParser description description parser.add_argument '--tox-env' dest 'tox_env' help 'Thetoxenvironment s toruninsub-packages.' packages_help 'Optionallistofsub-packagestobetested.'parser.add_argument 'packages' nargs '*' default UNSET_SENTINEL help packages_help return parser
def method_decorator decorator def _dec func def _wrapper self *args **kwargs @decoratordef bound_func *args2 **kwargs2 return func self *args2 **kwargs2 return bound_func *args **kwargs @decoratordef dummy *args **kwargs passupdate_wrapper _wrapper dummy update_wrapper _wrapper func return _wrapperupdate_wrapper _dec decorator _dec.__name__ 'method_decorator %s ' % decorator.__name__ return _dec
def movvar x windowsize 3 lag 'lagged' m1 movmoment x 1 windowsize windowsize lag lag m2 movmoment x 2 windowsize windowsize lag lag return m2 - m1 * m1
def join_cluster host user 'rabbit' ram_node None runas None cmd [__context__['rabbitmqctl'] 'join_cluster']if ram_node cmd.append '--ram' cmd.append '{0}@{1}'.format user host if runas is None and not salt.utils.is_windows runas salt.utils.get_user stop_app runas res __salt__['cmd.run_all'] cmd runas runas python_shell False start_app runas return _format_response res 'Join'
def onGlobalBases key value DEBUG_MSG 'onGlobalBases %s' % key
def _getSlotValue name slotData default None for slotFrame in slotData[ -1 ] if slotFrame is not None and name in slotFrame return slotFrame[name]else if default is not None return defaultraise UnfilledSlot name
def set_proxy_win server port types None bypass_hosts None if __grains__['os'] 'Windows' return _set_proxy_windows server port types bypass_hosts
def _broadcast_onto src_ndim src_shape dest_ndim dest_shape if src_ndim > dest_ndim return 0else src_index 0dest_index dest_ndim - src_ndim while src_index < src_ndim src_dim_size src_shape[src_index]dest_dim_size dest_shape[dest_index]if dest_dim_size ! 1 if src_dim_size ! dest_dim_size and src_dim_size ! 1 return - dest_index + 1 elif src_dim_size ! 1 dest_shape[dest_index] src_dim_sizesrc_index + 1dest_index + 1return dest_index
def file_upload_quota_broken request response file_upload_echo request request.upload_handlers.insert 0 QuotaUploadHandler return response
def osx_clipboard_get p subprocess.Popen ['pbpaste' '-Prefer' 'ascii'] stdout subprocess.PIPE text stderr p.communicate text text.replace '\r' '\n' text py3compat.cast_unicode text py3compat.DEFAULT_ENCODING return text
def get_course_enrollment_info course_id include_expired False course_key CourseKey.from_string course_id try course CourseOverview.get_from_id course_key except CourseOverview.DoesNotExist msg u'Requestedenrollmentinformationforunknowncourse{course}'.format course course_id log.warning msg raise CourseNotFoundError msg else return CourseSerializer course include_expired include_expired .data
@skip 'multiple_execute' @skip 'netstandard' def test_addreferencetofileandpath_conflict code1 '\nusingSystem;\n\npublicclassCollisionTest{\npublicstaticstringResult {\nreturn"Test1";\n}\n}\n'code2 '\nusingSystem;\n\npublicclassCollisionTest{\npublicstaticstringResult {\nreturn"Test2";\n}\n}\n'tmp testpath.temporary_dir test1_cs test1_dll path_combine tmp 'test1.cs' path_combine tmp 'CollisionTest.dll' test2_cs test2_dll path_combine tmp 'test2.cs' path_combine sys.prefix 'CollisionTest.dll' write_to_file test1_cs code1 write_to_file test2_cs code2 AreEqual run_csc '/nologo/target library/out ' + test2_dll + '' + test2_cs 0 AreEqual run_csc '/nologo/target library/out ' + test1_dll + '' + test1_cs 0 clr.AddReferenceToFileAndPath test1_dll import CollisionTestAreEqual CollisionTest.Result 'Test1'
def select_best_available_language target_code available_codes None target_code lcode_to_django_lang target_code store_cache Falseif available_codes is None if target_code in __select_best_available_language return __select_best_available_language[target_code]else store_cache Trueavailable_codes get_installed_language_packs .keys available_codes [lcode_to_django_lang lc for lc in available_codes if lc]if target_code in available_codes actual_code target_codeelif target_code.split '-' 1 [0] in available_codes actual_code target_code.split '-' 1 [0]elif settings.LANGUAGE_CODE in available_codes actual_code settings.LANGUAGE_CODEelif 'en' in available_codes actual_code 'en'elif available_codes actual_code available_codes[0]else raise RuntimeError 'Nolanguagesfound' if store_cache __select_best_available_language[target_code] actual_codereturn actual_code
def try_march_flag flags test_code textwrap.dedent '#include<cmath>\nusingnamespacestd;\nintmain intargc char**argv \n{\nfloatNx -1.3787706641;\nfloatSx 25.0;\ndoubler Nx+sqrt Sx ;\nif abs r-3.621229 >0.01 \n{\nreturn-1;\n}\nreturn0;\n}\n' cflags flags + [ '-L' + d for d in theano.gof.cmodule.std_lib_dirs ] compilation_result execution_result GCC_compiler.try_compile_tmp test_code tmp_prefix 'try_march_' flags cflags try_run True return compilation_result execution_result
def remove_packages module xbps_path packages changed_packages []for package in packages installed updated query_package module xbps_path package if not installed continuecmd '%s-y%s' % xbps_path['remove'] package rc stdout stderr module.run_command cmd check_rc False if rc ! 0 module.fail_json msg 'failedtoremove%s' % package changed_packages.append package if len changed_packages > 0 module.exit_json changed True msg 'removed%spackage s ' % len changed_packages packages changed_packages module.exit_json changed False msg 'package s alreadyabsent'
def get_promo country_code programming_language gold_project False gold_user False promo_queryset SupporterPromo.objects.filter live True display_type 'doc' filtered_promos []for obj in promo_queryset if obj.programming_language and not show_to_programming_language obj programming_language continueif country_code and not show_to_geo obj country_code continuefiltered_promos.append obj promo_obj choose_promo filtered_promos if not promo_obj house_promo SupporterPromo.objects.filter live True name 'house' .order_by '?' if house_promo.exists promo_obj house_promo.first if gold_user gold_promo SupporterPromo.objects.filter live True name 'gold-user' if gold_promo.exists promo_obj gold_promo.first if gold_project gold_promo SupporterPromo.objects.filter live True name 'gold-project' if gold_promo.exists promo_obj gold_promo.first return promo_obj
def transform_headers headers for key value in headers.items headers[key] str value return headers
def p_error_handler t pass
def _node default '' try import socketexcept ImportError return defaulttry return socket.gethostname except socket.error return default
def getShouldReverse xmlElement return evaluate.getEvaluatedBooleanDefault True 'reverse' xmlElement
def _expand_glob_path file_roots unglobbed_path []for path in file_roots try if glob.has_magic path unglobbed_path.extend glob.glob path else unglobbed_path.append path except Exception unglobbed_path.append path return unglobbed_path
@register.filter name 'unix_ms_to_datetime' def unix_ms_to_datetime unixtime if unixtime return datetime.datetime.fromtimestamp unixtime / 1000 return _ 'Notime'
def generic_recursive_equality_test a b class_history dict_a a.__dict__dict_b b.__dict__for key in dict_a assert key in dict_b u'Didnotpickle{0}'.format key if hasattr dict_a[key] u'__eq__' eq dict_a[key] dict_b[key] if u'__iter__' in dir eq eq False not in eq assert eq u'Valueof{0}changedbypickling'.format key if hasattr dict_a[key] u'__dict__' if dict_a[key].__class__ in class_history passelse new_class_history [dict_a[key].__class__]new_class_history.extend class_history generic_recursive_equality_test dict_a[key] dict_b[key] new_class_history
def group_snapshot_get context group_snapshot_id return IMPL.group_snapshot_get context group_snapshot_id
def block_device_mappings vm_ return config.get_cloud_config_value 'block_device_mappings' vm_ __opts__ search_global True
def _number text if text.isdigit return int text try return float text except ValueError return text
def expected_cost numobj region_codes region_codes_for_country_code numobj.country_code if len region_codes 0 return ShortNumberCost.UNKNOWN_COSTif len region_codes 1 return expected_cost_for_region numobj region_codes[0] cost ShortNumberCost.TOLL_FREEfor region_code in region_codes cost_for_region expected_cost_for_region numobj region_code if cost_for_region ShortNumberCost.PREMIUM_RATE return ShortNumberCost.PREMIUM_RATEelif cost_for_region ShortNumberCost.UNKNOWN_COST return ShortNumberCost.UNKNOWN_COSTelif cost_for_region ShortNumberCost.STANDARD_RATE if cost ! ShortNumberCost.UNKNOWN_COST cost ShortNumberCost.STANDARD_RATEelif cost_for_region ShortNumberCost.TOLL_FREE passelse raise Exception 'Unrecognizedcostforregion %s' cost_for_region return cost
def _prepare_message txt def plain val 'ReturnTruewhenvalisplainASCII'try val.decode 'ascii' return Trueexcept return Falsecode 'ISO-8859-1'msg Message payload []body Falseheader Falsefor line in txt.encode code 'replace' .split '\n' if header and not line body Trueif body payload.append line else m RE_HEADER.search line if m header Truekeyword m.group 1 .strip value m.group 2 .strip if plain value msg.add_header keyword value else header Header value code msg[keyword] headermsg.set_payload '\n'.join payload code if not msg.has_key 'Content-Transfer-Encoding' encode_quopri msg return msg.as_string
def get_default_address doctype name sort_key u'is_primary_address' out frappe.db.sql u'select\n DCTB DCTB DCTB parent \n DCTB DCTB DCTB select`{0}`fromtabAddressawherea.name dl.parent as`{0}`\n DCTB DCTB from\n DCTB DCTB DCTB `tabDynamicLink`dl\n DCTB DCTB where\n DCTB DCTB DCTB link_doctype %sand\n DCTB DCTB DCTB link_name %sand\n DCTB DCTB DCTB parenttype "Address"\n DCTB DCTB '.format sort_key doctype name if out return sorted out lambda x y cmp y[1] x[1] [0][0]else return None
def next_prime starting_value if starting_value < 2 return 2result starting_value + 1 | 1 while not is_prime result result result + 2 return result
@pytest.mark.skipif 'notHAS_BEAUTIFUL_SOUP' def test_soupstring soup BeautifulSoup '<html><head></head><body><p>foo</p></body></html>' soup_str html.SoupString soup assert isinstance soup_str str assert isinstance soup_str html.SoupString assert soup_str '<html><head></head><body><p>foo</p></body></html>' assert soup_str.soup is soup
def glBufferData target data usage if isinstance data int size datadata ctypes.c_voidp 0 else if not data.flags['C_CONTIGUOUS'] or not data.flags['ALIGNED'] data data.copy 'C' data_ datasize data_.nbytesdata data_.ctypes.datares _lib.glBufferData target size data usage
def esxcli host user pwd cmd protocol None port None esxi_host None esx_cmd salt.utils.which 'esxcli' if not esx_cmd log.error 'Missingdependency Thesalt.utils.vmware.esxclifunctionrequiresESXCLI.' return Falseif port is None port 443if protocol is None protocol 'https'if not esxi_host esx_cmd + "-s{0}-u{1}-p'{2}'--protocol {3}--portnumber {4}{5}".format host user pwd protocol port cmd else esx_cmd + "-s{0}-h{1}-u{2}-p'{3}'--protocol {4}--portnumber {5}{6}".format host esxi_host user pwd protocol port cmd ret salt.modules.cmdmod.run_all esx_cmd output_loglevel 'quiet' return ret
def rules_2prereq rules prereq defaultdict set for a _ impl in rules.items if isinstance a Not a a.args[0]for i _ in impl if isinstance i Not i i.args[0]prereq[i].add a return prereq
def get_string_scope project code resource None return get_string_module project code resource .get_scope
def _mat_ptrs a if len a 1 return cuda.cupy.full 1 a.data.ptr dtype numpy.uintp else stride a.strides[0]ptr a.data.ptrreturn cuda.cupy.arange ptr ptr + stride * len a stride dtype numpy.uintp
def test_ast_good_assert can_compile u' assert1 ' can_compile u' assert1"Assertlabel" ' can_compile u' assert1 +"spam""eggs" ' can_compile u' assert112345 ' can_compile u' assert1None ' can_compile u' assert1 +2"incomingeggsception" '
@register.simple_tag takes_context True def expand_fragment_link context expanding tooltip expand_above expand_below text None lines_of_context context[u'lines_of_context']image_class u'rb-icon-diff-expand-%s' % expanding expand_pos lines_of_context[0] + expand_above lines_of_context[1] + expand_below return render_to_string u'reviews/expand_link.html' {u'tooltip' tooltip u'text' text u'comment_id' context[u'comment'].id u'expand_pos' expand_pos u'image_class' image_class}
def get_object model **kwargs for value in kwargs.values if not value return Nonethe_object model.objects.filter **kwargs if len the_object 1 the_object the_object[0]else the_object Nonereturn the_object
def import_setting name value getattr settings name None return import_object value
def _fileobj_to_fd fileobj if isinstance fileobj six.integer_types fd fileobjelse try fd int fileobj.fileno except AttributeError TypeError ValueError raise ValueError 'Invalidfileobject {0!r}'.format fileobj if fd < 0 raise ValueError 'Invalidfiledescriptor {0}'.format fd return fd
def check_tree_subset fasta_labels tree_fp raw_fasta_labels set [label.split '_' [0] for label in fasta_labels] tree_f open tree_fp 'U' tree DndParser tree_f tree_tips set tree.getTipNames labels_not_in_tips []for curr_label in raw_fasta_labels if curr_label not in tree_tips labels_not_in_tips.append curr_label if len labels_not_in_tips 0 labels_not_in_tips Truereturn labels_not_in_tips
def module_enabled module enable_module module reload_service 'apache2'
def wait_ready package popen if package DATASTORE datastore_wait_ready popen elif package PUBSUB wait_ready_prefix popen _PS_READY_LINE_PREFIX elif package BIGTABLE wait_ready_prefix popen _BT_READY_LINE_PREFIX else raise KeyError 'Packagenotsupported' package
def change_keys recs key 'uuid' filter_func None new_recs {}for ref rec in recs.iteritems if filter_func is not None and not filter_func rec continuenew_recs[rec[key]] recnew_recs[rec[key]]['ref'] refreturn new_recs
def _editor_progress limited_reviewer False types ['nominated' 'pending']progress {'new' queue_counts types days_max 4 unlisted False admin_reviewer True limited_reviewer limited_reviewer 'med' queue_counts types days_min 5 days_max 10 unlisted False admin_reviewer True limited_reviewer limited_reviewer 'old' queue_counts types days_min 11 unlisted False admin_reviewer True limited_reviewer limited_reviewer }def pct p t return p / float t * 100 if p > 0 else 0 percentage {}for t in types total progress['new'][t] + progress['med'][t] + progress['old'][t] percentage[t] {}for duration in 'new' 'med' 'old' percentage[t][duration] pct progress[duration][t] total return progress percentage
def pool currentLimit threadFactory Thread def startThread target return threadFactory target target .start def limitedWorkerCreator stats team.statistics if stats.busyWorkerCount + stats.idleWorkerCount > currentLimit return Nonereturn ThreadWorker startThread Queue team Team coordinator LockWorker Lock LocalStorage createWorker limitedWorkerCreator logException err return team
def nsmallest n iterable if n < 0 return []it iter iterable result list islice it n if not result return result_heapify_max result _heappushpop _heappushpop_maxfor elem in it _heappushpop result elem result.sort return result
def reverse_course_url handler_name course_key kwargs None return reverse_url handler_name 'course_key_string' course_key kwargs
def getPathByKey key xmlElement if key not in xmlElement.attributeDictionary return []word str xmlElement.attributeDictionary[key] .strip evaluatedLinkValue getEvaluatedLinkValue word xmlElement if evaluatedLinkValue.__class__ list return getPathByList evaluatedLinkValue xmlElementObject getXMLElementObject evaluatedLinkValue if xmlElementObject None return []return xmlElementObject.getPaths [0]
@pytest.fixture autouse True def _annotate_environment request environment getattr request.config '_environment' None if environment behave_version behave.__version__environment.append 'behave' behave_version
def escape_sql_like_special_characters term escape '\\' for ch in escape + _special_characters term term.replace ch escape + ch return term
def get_body_region defined scope defined.get_scope pymodule defined.get_module lines pymodule.linesnode defined.get_ast start_line node.linenoif defined.get_doc is None start_line node.body[0].linenoelif len node.body > 1 start_line node.body[1].linenostart lines.get_line_start start_line scope_start pymodule.logical_lines.logical_line_in scope.start if scope_start[1] > start_line start pymodule.source_code.index ' ' start + 1 while pymodule.source_code[start].isspace start + 1end min lines.get_line_end scope.end + 1 len pymodule.source_code return start end
def _enum_to_int value try return int value except ValueError TypeError return value
def bfs_beam_edges G source value width None if width is None width len G def successors v 'Returnsalistofthebestneighborsofanode.\n\n`v`isanodeinthegraph`G`.\n\nThe"best"neighborsarechosenaccordingtothe`value`\nfunction higherisbetter .Onlythe`width`bestneighborsof\n`v`arereturned.\n\nThelistreturnedbythisfunctionisindecreasingvalueas\nmeasuredbythe`value`function.\n\n'return iter sorted G.neighbors v key value reverse True [ width] for e in generic_bfs_edges G source successors yield e
def repeat stmt 'pass' setup 'pass' timer default_timer repeat default_repeat number default_number return Timer stmt setup timer .repeat repeat number
def nlargest n iterable key None in1 in2 tee iterable it izip imap key in1 imap neg count in2 result _nlargest n it return map itemgetter 2 result
def format_source_url url if sabnzbd.HAVE_SSL prot 'https'else prot 'http 'return url
def decode_byte_list byte_list decoded_items []for item in byte_list decoded_items.append item.decode __salt_system_encoding__ return decoded_items
def _revs_equal rev1 rev2 rev_type if rev1 is None and rev2 is not None or rev2 is None and rev1 is not None return Falseelif rev1 is rev2 is None return Trueelif rev_type 'sha1' return rev1.startswith rev2 else return rev1 rev2
def random_shift x wrg hrg row_axis 1 col_axis 2 channel_axis 0 fill_mode 'nearest' cval 0.0 h w x.shape[row_axis] x.shape[col_axis] tx np.random.uniform - hrg hrg * h ty np.random.uniform - wrg wrg * w translation_matrix np.array [[1 0 tx] [0 1 ty] [0 0 1]] transform_matrix translation_matrixx apply_transform x transform_matrix channel_axis fill_mode cval return x
def add_indep x varnames dtype None if isinstance x np.ndarray and x.ndim 2 x x.Tnvars_orig len x nobs len x[0] if not dtype dtype np.asarray x[0] .dtypexout np.zeros nobs nvars_orig dtype dtype count 0rank_old 0varnames_new []varnames_dropped []keepindx []for xi ni in zip x varnames xout[ count] xirank_new np_matrix_rank xout if rank_new > rank_old varnames_new.append ni rank_old rank_newcount + 1else varnames_dropped.append ni return xout[ count] varnames_new
def _media_path_url_from_info root_desc path_url return '% root supload/% service_path s% path s' % {'root' root_desc['rootUrl'] 'service_path' root_desc['servicePath'] 'path' path_url}
def delete_blob call None kwargs None global storconnif not storconn storconn get_conn StorageManagementClient if kwargs is None kwargs {}if 'container' not in kwargs raise SaltCloudSystemExit 'Acontainermustbespecified' if 'blob' not in kwargs raise SaltCloudSystemExit 'Ablobmustbespecified' storageaccount azure.storage.CloudStorageAccount config.get_cloud_config_value 'storage_account' get_configured_provider __opts__ search_global False config.get_cloud_config_value 'storage_key' get_configured_provider __opts__ search_global False storageservice storageaccount.create_block_blob_service storageservice.delete_blob kwargs['container'] kwargs['blob'] return True
def formatstring cols colwidth _colwidth spacing _spacing spacing * ''return spacing.join c.center colwidth for c in cols
def count_sprintf_parameters string return len _sprintf_placeholder_re.findall string
def roundrobin *iterables pending len iterables nexts cycle iter it .next for it in iterables while pending try for next in nexts yield next except StopIteration pending - 1nexts cycle islice nexts pending
def update_single f new frappe.db.begin frappe.db.sql u'updatetabSinglessetfield %swheredoctype %sandfield %s' new f[u'parent'] f[u'fieldname'] frappe.db.commit
@image_comparison baseline_images [u'colorbar_extensions_uniform' u'colorbar_extensions_proportional'] extensions [u'png'] def test_colorbar_extension_length _colorbar_extension_length u'uniform' _colorbar_extension_length u'proportional'
def get_documentation from ._compat import StringIO sys.stdout _ StringIO sys.stdout help vim.eval 'a word' sys.stdout out _ sys.stdout.getvalue vim.current.buffer.append str out .splitlines 0
def _get_lut data_dir op.join op.dirname __file__ 'data' lut_fname op.join data_dir 'FreeSurferColorLUT.txt' return np.genfromtxt lut_fname dtype None usecols 0 1 2 3 4 5 names ['id' 'name' 'R' 'G' 'B' 'A']
def add_resource_manager_extra_kwargs_hook f hook if not hasattr f 'resource_manager_kwargs_hooks' f.resource_manager_kwargs_hooks []names [h.__name__ for h in f.resource_manager_kwargs_hooks]if hook.__name__ not in names f.resource_manager_kwargs_hooks.append hook
@pytest.fixture scope 'session' def stubs return stubsmod
def _initial_nodes_a n k tauk _compute_tauk n k sigk cos 0.5 * tauk ** 2 a n % 2 - 0.5 nu 4.0 * floor n / 2.0 + 2.0 * a + 2.0 xksq nu * sigk - 1.0 / 3.0 * nu * 5.0 / 4.0 * 1.0 - sigk ** 2 - 1.0 / 1.0 - sigk - 0.25 return xksq
@register.simple_tagdef disqus_id_for obj return u'%s-%s' % obj._meta.object_name obj.id
def get_CC_operators i symbols 'i' below_fermi True cls Dummy a symbols 'a' above_fermi True cls Dummy t_ai AntiSymmetricTensor 't' a i ai NO Fd a * F i i j symbols 'i j' below_fermi True cls Dummy a b symbols 'a b' above_fermi True cls Dummy t_abij AntiSymmetricTensor 't' a b i j abji NO Fd a * Fd b * F j * F i T1 t_ai * ai T2 Rational 1 4 * t_abij * abji return T1 T2
def failing_job raise RuntimeError u'JOBFAILURE'
def _enqueue revent __context__['inotify.queue'].append revent
def dnslib_record2iplist record assert isinstance record dnslib.DNSRecord iplist [x for x in str r.rdata for r in record.rr if re.match '^\\d+\\.\\d+\\.\\d+\\.\\d+$' x or ' ' in x ]return iplist
def install_setuptools python_cmd 'python' use_sudo True setuptools_version package_version 'setuptools' python_cmd distribute_version package_version 'distribute' python_cmd if setuptools_version is None _install_from_scratch python_cmd use_sudo elif distribute_version is None _upgrade_from_setuptools python_cmd use_sudo else _upgrade_from_distribute python_cmd use_sudo
def target_info_from_filename filename basename osp.basename filename storedir osp.dirname osp.abspath filename target filename.split '.' [ -1 ]return storedir basename target
def BoundedSemaphore *args **kwargs return _BoundedSemaphore *args **kwargs
def _raise_document_too_large operation doc_size max_size if operation 'insert' raise DocumentTooLarge 'BSONdocumenttoolarge %dbytes -theconnectedserversupportsBSONdocumentsizesupto%dbytes.' % doc_size max_size else raise DocumentTooLarge 'commanddocumenttoolarge'
def test_pick_bio names 'A1A2FzOBIO1BIO2BIO3'.split types 'magmageegeegbiobiobio'.split info create_info names 1024.0 types idx channel_indices_by_type info assert_array_equal idx['mag'] [0 1] assert_array_equal idx['eeg'] [2 3] assert_array_equal idx['bio'] [4 5 6]
def html_unquote v for ent repl in [ '&nbsp;' '' '&gt;' '>' '&lt;' '<' '&quot;' '"' '&amp;' '&' ] v v.replace ent repl return v
def collect_emojis emojis dict full_path os.path.join _basedir 'static' 'emoji' if not os.path.exists full_path return emojisfor emoji in os.listdir full_path name ending emoji.split '.' if ending in ['png' 'gif' 'jpg' 'jpeg'] emojis[name] emojireturn emojis
def redirect url code None if code is None code 303 if request.get 'SERVER_PROTOCOL' 'HTTP/1.1' else 302 location urljoin request.url url raise HTTPResponse '' status code header dict Location location
def lv_check vg_name lv_name cmd 'lvdisplay'result utils.run cmd ignore_status True lvpattern 'LVPath\\s+/dev/%s/%s\\s+' % vg_name lv_name match re.search lvpattern result.stdout.rstrip if match logging.debug 'Providedlogicalvolume%sexistsin%s' lv_name vg_name return Trueelse return False
def raw_cron user if _check_instance_uid_match user or __grains__.get 'os_family' in 'Solaris' 'AIX' cmd 'crontab-l'lines __salt__['cmd.run_stdout'] cmd runas user rstrip False python_shell False .splitlines True else cmd 'crontab-u{0}-l'.format user lines __salt__['cmd.run_stdout'] cmd rstrip False python_shell False .splitlines True if len lines ! 0 and lines[0].startswith '#DONOTEDITTHISFILE-editthemasterandreinstall.' del lines[0 3]return ''.join lines
def create_logger app Logger getLoggerClass class DebugLogger Logger def getEffectiveLevel self if self.level 0 and app.debug return DEBUGreturn Logger.getEffectiveLevel self class DebugHandler StreamHandler def emit self record if app.debug and _should_log_for app 'debug' StreamHandler.emit self record class ProductionHandler StreamHandler def emit self record if not app.debug and _should_log_for app 'production' StreamHandler.emit self record debug_handler DebugHandler debug_handler.setLevel DEBUG debug_handler.setFormatter Formatter DEBUG_LOG_FORMAT prod_handler ProductionHandler _proxy_stream prod_handler.setLevel ERROR prod_handler.setFormatter Formatter PROD_LOG_FORMAT logger getLogger app.logger_name del logger.handlers[ ]logger.__class__ DebugLoggerlogger.addHandler debug_handler logger.addHandler prod_handler logger.propagate Falsereturn logger
def get_future_timestamp idx timestamps if idx len timestamps - 1 return get_past_timestamp idx timestamps elif timestamps[idx] return timestamps[idx][0]else idx min len timestamps idx + 1 return get_future_timestamp idx timestamps
def splitline text index text.find '\n' + 1 if index return text[ index] text[index ] else return text ''
def get_host_numa_usage_from_instance host instance free False never_serialize_result False instance_numa_topology instance_topology_from_instance instance if instance_numa_topology instance_numa_topology [instance_numa_topology] host_numa_topology jsonify_result host_topology_and_format_from_host host updated_numa_topology numa_usage_from_instances host_numa_topology instance_numa_topology free free if updated_numa_topology is not None if jsonify_result and not never_serialize_result updated_numa_topology updated_numa_topology._to_json return updated_numa_topology
def _get_service_result_parser run utils.run global _service_result_parsertry return _service_result_parserexcept NameError result_parser _result_parsers[get_name_of_init run ]_service_result_parser _ServiceResultParser result_parser return _service_result_parser
def update gems ruby None runas None gem_bin None try gems gems.split except AttributeError passreturn _gem ['update'] + gems ruby gem_bin gem_bin runas runas
def dtlz7 ind n_objs gval 1 + 9.0 / len ind[ n_objs - 1 ] * sum [a for a in ind[ n_objs - 1 ]] fit [ind for ind in ind[ n_objs - 1 ]]fit.append 1 + gval * n_objs - sum [ a / 1.0 + gval * 1 + sin 3 * pi * a for a in ind[ n_objs - 1 ]] return fit
def make_letterboxed_thumbnail image shape assert len image.shape 3 assert len shape 2 shrunk fit_inside image shape letterboxed letterbox shrunk shape return letterboxed
def Pluralize count singular '' plural 's' return singular if count 1 else plural
def random_reduce circuit gate_ids seed None from sympy.utilities.randtest import _randrangeif not gate_ids return circuitif isinstance circuit Mul circuit circuit.argsids flatten_ids gate_ids randrange _randrange seed while ids i randrange len ids id ids.pop i if find_subcircuit circuit id ! -1 breakelse return circuitreturn replace_subcircuit circuit id
def write_cron_file user path if _check_instance_uid_match user or __grains__.get 'os_family' in 'Solaris' 'AIX' return __salt__['cmd.retcode'] _get_cron_cmdstr path runas user python_shell False 0 else return __salt__['cmd.retcode'] _get_cron_cmdstr path user python_shell False 0
def get_img_channel image_path img load_image image_path img pil_to_nparray img try channel img.shape[2]except channel 1return channel
def get_partial_date_formats warnings.warn "'django.utils.translation.get_partial_date_formats'isdeprecated.Pleaseupdateyourcodetousethenewi18nawareformatting." PendingDeprecationWarning from google.appengine._internal.django.conf import settingsyear_month_format ugettext 'YEAR_MONTH_FORMAT' month_day_format ugettext 'MONTH_DAY_FORMAT' if year_month_format 'YEAR_MONTH_FORMAT' year_month_format settings.YEAR_MONTH_FORMATif month_day_format 'MONTH_DAY_FORMAT' month_day_format settings.MONTH_DAY_FORMATreturn year_month_format month_day_format
def generate_cert domain result __salt__['cmd.run'] 'icinga2pkinew-cert--cn{0}--key/etc/icinga2/pki/{0}.key--cert/etc/icinga2/pki/{0}.crt'.format domain return result
def test_resample x rng.normal 0 1 10 10 10 x_rs resample x 1 2 10 assert_equal x.shape 10 10 10 assert_equal x_rs.shape 10 10 5 x_2 x.swapaxes 0 1 x_2_rs resample x_2 1 2 10 assert_array_equal x_2_rs.swapaxes 0 1 x_rs x_3 x.swapaxes 0 2 x_3_rs resample x_3 1 2 10 0 assert_array_equal x_3_rs.swapaxes 0 2 x_rs assert_array_equal resample [0 0] 2 1 [0.0 0.0 0.0 0.0]
def _is_resumable exc checker _SELECT_ERROR_CHECKERS.get exc.__class__ None if checker is not None return checker exc else return False
def _iexp x M L 8 R _nbits x << L // M T - int -10 * len str M // 3 * L y _div_nearest x T Mshift M << R for i in range T - 1 0 -1 y _div_nearest x * Mshift + y Mshift * i for k in range R - 1 -1 -1 Mshift M << k + 2 y _div_nearest y * y + Mshift Mshift return M + y
def safecall f name *args **kwargs lwork kwargs.get 'lwork' None if lwork in None -1 kwargs['lwork'] -1 ret f *args **kwargs kwargs['lwork'] ret[ -2 ][0].real.astype numpy.int ret f *args **kwargs if ret[ -1 ] < 0 raise ValueError 'illegalvaluein%d-thargumentofinternal%s' % - ret[ -1 ] name return ret[ -2 ]
def interval_distance label1 label2 try return pow label1 - label2 2 except print 'non-numericlabelsnotsupportedwithintervaldistance'
def ensure_completely_loaded force False global COMPLETELY_LOADEDif COMPLETELY_LOADED and not force return Truefrom django.apps import appsif not apps.ready returnimport djangofrom distutils.version import LooseVersionif LooseVersion django.get_version < LooseVersion u'1.8' for model in apps.get_models for cache_name in u'_field_cache' u'_field_name_cache' u'_m2m_cache' u'_related_objects_cache' u'_related_many_to_many_cache' u'_name_map' try delattr model._meta cache_name except AttributeError passmodel._meta._fill_fields_cache if hasattr apps u'cache' apps.cache.get_models.cache_clear if apps.ready COMPLETELY_LOADED Truereturn True
def _lookup_syslog_config config lookup {'default-timeout' 'DefaultNetworkRetryTimeout' 'logdir' 'LocalLogOutput' 'default-size' 'LocalLoggingDefaultRotationSize' 'logdir-unique' 'LogToUniqueSubdirectory' 'default-rotate' 'LocalLoggingDefaultRotations' 'loghost' 'RemoteHost'}return lookup.get config
def create_comment request comment_data thread_id comment_data.get 'thread_id' if not thread_id raise ValidationError {'thread_id' ['Thisfieldisrequired.']} cc_thread context _get_thread_and_context request thread_id if cc_thread['closed'] raise PermissionDenied_check_initializable_comment_fields comment_data context serializer CommentSerializer data comment_data context context actions_form CommentActionsForm comment_data if not serializer.is_valid and actions_form.is_valid raise ValidationError dict serializer.errors.items + actions_form.errors.items serializer.save cc_comment serializer.instancecomment_created.send sender None user request.user post cc_comment api_comment serializer.data_do_extra_actions api_comment cc_comment comment_data.keys actions_form context request track_comment_created_event request context['course'] cc_comment cc_thread['commentable_id'] followed False return api_comment
def notify_info_yielded event def decorator generator def decorated *args **kwargs for v in generator *args **kwargs send event info v yield v return decoratedreturn decorator
def _validate_snap_name name snap_name strict True runas None snap_name _sdecode snap_name if re.match GUID_REGEX snap_name return snap_name.strip '{}' else return snapshot_name_to_id name snap_name strict strict runas runas
def get_avg_dists state1_samids state2_samids distdict state1_avg_dists []for sam1 in state1_samids dists []for sam2 in state2_samids if sam1 sam2 continuedists.append distdict[sam1][sam2] state1_avg_dists.append numpy.mean dists return state1_avg_dists
def in6_get6to4Prefix addr try addr inet_pton socket.AF_INET addr addr inet_ntop socket.AF_INET6 '\x02' + addr + '\x00' * 10 except return Nonereturn addr
def test_sobel_h_horizontal i j np.mgrid[ -5 6 -5 6]image i > 0 .astype float result filters.sobel_h image i[ np.abs j 5 ] 10000assert np.all result[ i 0 ] 1 assert np.all result[ np.abs i > 1 ] 0
def farray ptr shape dtype None if not isinstance shape utils.INT_TYPES shape shape[ -1 ]return carray ptr shape dtype .T
def secgroup_info call None kwargs None if call ! 'function' raise SaltCloudSystemExit 'Thesecgroup_infofunctionmustbecalledwith-for--function.' if kwargs is None kwargs {}name kwargs.get 'name' None secgroup_id kwargs.get 'secgroup_id' None if secgroup_id if name log.warning "Boththe'secgroup_id'and'name'argumentswereprovided.'secgroup_id'willtakeprecedence." elif name secgroup_id get_secgroup_id kwargs {'name' name} else raise SaltCloudSystemExit 'Thesecgroup_infofunctionrequireseitheranameorasecgroup_idtobeprovided.' server user password _get_xml_rpc auth ' '.join [user password] info {}response server.one.secgroup.info auth int secgroup_id [1]tree _get_xml response info[tree.find 'NAME' .text] _xml_to_dict tree return info
def _make_complex_eigvecs w vin dtype v numpy.array vin dtype dtype m w.imag > 0 m[ -1 ] | w.imag[1 ] < 0 for i in flatnonzero m v.imag[ i] vin[ i + 1 ]conj v[ i] v[ i + 1 ] return v
def _sig_key key date_stamp regionName serviceName kDate _sign 'AWS4' + key .encode 'utf-8' date_stamp if regionName kRegion _sign kDate regionName kService _sign kRegion serviceName else kService _sign kDate serviceName kSigning _sign kService 'aws4_request' return kSigning
def validate_int_or_basestring option value if isinstance value integer_types return valueelif isinstance value string_type if value.isdigit return int value return valueraise TypeError 'Wrongtypefor%s valuemustbeanintegerorastring' % option
def get_database_password name password DATABASES[name].PASSWORD.get if not password password DATABASES[name].PASSWORD_SCRIPT.get return password
def retrieve_token userid secret dtnow datetime.datetime.now dtutcnow datetime.datetime.utcnow delta dtnow - dtutcnow newhour newmin divmod delta.days * 24 * 60 * 60 + delta.seconds + 30 // 60 60 newtime '%s%+02d %02d' % dtnow.isoformat newhour newmin custom_data {'issuedAt' newtime 'consumerKey' secret 'userId' userid 'ttl' 86400}newtoken create_token secret custom_data return newtoken
def parse229 resp peer if resp[ 3] ! '229' raise error_reply resp left resp.find ' ' if left < 0 raise error_proto resp right resp.find ' ' left + 1 if right < 0 raise error_proto resp if resp[ left + 1 ] ! resp[ right - 1 ] raise error_proto resp parts resp[ left + 1 right].split resp[ left + 1 ] if len parts ! 5 raise error_proto resp host peer[0]port int parts[3] return host port
def getFloatListListsByPaths paths floatListLists []for path in paths floatListList []for point in path floatListList.append point.getFloatList return floatListLists
def _get_pnics host_reference return host_reference.config.network.pnic
def getFundamentalsPath subName '' return getJoinedPath getGeometryUtilitiesPath 'evaluate_fundamentals' subName
def locks registry xml_parent data locks dataif locks lw XML.SubElement xml_parent 'hudson.plugins.locksandlatches.LockWrapper' locktop XML.SubElement lw 'locks' for lock in locks lockwrapper XML.SubElement locktop 'hudson.plugins.locksandlatches.LockWrapper_-LockWaitConfig' XML.SubElement lockwrapper 'name' .text lock
def p_additive_expression_1 t pass
def _skip_bytes f n f.read n return
def cheby2 N rs Wn btype 'low' analog False output 'ba' return iirfilter N Wn rs rs btype btype analog analog output output ftype 'cheby2'
def flatten_const_node_list environment node_list output []eval_ctx EvalContext environment for node in node_list if isinstance node Output for node in node.nodes try const node.as_const eval_ctx eval_ctx if not isinstance const six.text_type raise Unflattenable const output.append const except Impossible raise Unflattenable node else raise Unflattenable node return u''.join output
def count return partial _force sequence _advance lambda x x
def paginated model query None increment 200 each True queryset model.find query paginator Paginator queryset.all increment for page_num in paginator.page_range page paginator.page page_num if each for item in page.object_list yield item else yield page.object_list
def get_best_language accept_lang LUM settings.LANGUAGE_URL_MAPNSL settings.NON_SUPPORTED_LOCALESLC settings.LANGUAGE_CODElangs dict LUM langs.update k.lower v if v else LC for k v in NSL.items if k.lower not in langs langs.update k.split '-' [0] v for k v in LUM.items if k.split '-' [0] not in langs ranked parse_accept_lang_header accept_lang for lang _ in ranked lang lang.lower if lang in langs return langs[lang]pre lang.split '-' [0]if pre in langs return langs[pre]return False
def shlex_quote s if not s return "''"if _find_unsafe s is None return sreturn "'" + s.replace "'" '\'"\'"\'' + "'"
def SynthesizeUserId email user_id_digest _MD5_FUNC email.lower .digest user_id '1' + ''.join [ '%02d' % ord x for x in user_id_digest] [ 20] return user_id
def distros_for_filename filename metadata None return distros_for_location normalize_path filename os.path.basename filename metadata
def get_xstatic_dirs XSTATIC_MODULES HORIZON_CONFIG STATICFILES_DIRS []HORIZON_CONFIG['xstatic_lib_files'] []for module_name files in XSTATIC_MODULES module import_module module_name if module_name 'xstatic.pkg.jquery_ui' if module.VERSION.startswith '1.10.' files [ 'ui/' + files[0] ]STATICFILES_DIRS.append 'horizon/lib/' + module.NAME module.BASE_DIR if hasattr module 'MAIN' files module.MAINif not isinstance files list files [files]files [file for file in files if file.endswith '.js' ]for file in files file 'horizon/lib/' + module.NAME + '/' + file HORIZON_CONFIG['xstatic_lib_files'].append file return STATICFILES_DIRS
def reset_extensions_translations_locales apps schema_editor Extension apps.get_model u'extensions' u'Extension' Translation apps.get_model u'translations' u'Translation' extensions Extension.objects.all for extension in extensions translations_ids filter None [extension.name_id extension.description_id] lang extension.default_language.lower Translation.objects.filter id__in translations_ids .update locale lang
def metric_to_Christoffel_2nd expr ch_1st metric_to_Christoffel_1st expr coord_sys expr.atoms CoordSystem .pop indices list range coord_sys.dim matrix twoform_to_matrix expr s_fields set for e in matrix s_fields.update e.atoms BaseScalarField s_fields list s_fields dums coord_sys._dummiesmatrix matrix.subs list zip s_fields dums .inv .subs list zip dums s_fields christoffel [[[Add *[ matrix[ i l ] * ch_1st[ l j k ] for l in indices] for k in indices] for j in indices] for i in indices]return ImmutableDenseNDimArray christoffel
def log_loss actual predicted return np.mean ll actual predicted
def db_exists name user None password None host None port None authdb None dbs db_list user password host port authdb authdb if isinstance dbs string_types return Falsereturn name in dbs
def build_graph ifilenames graph num_threads 1 tags False if tags eat graph.consume_fasta_and_tag_with_reads_parserelse eat graph.consume_fasta_with_reads_parserfor _ ifile in enumerate ifilenames rparser khmer.ReadParser ifile threads []for _ in range num_threads cur_thread threading.Thread target eat args rparser threads.append cur_thread cur_thread.start for thread in threads thread.join
def change_state api_url post_data for _ in range LOGIN_RETRIES req requests.post urljoin ZM['url'] api_url data post_data cookies ZM['cookies'] timeout DEFAULT_TIMEOUT if req.status_code ! requests.codes.ok login else breakelse _LOGGER.exception 'UnabletogetAPIresponsefromZoneMinder' return json.loads req.text
def _chunk_write chunk local_file progress local_file.write chunk progress.update_with_increment_value len chunk
def tokenize_annotated doc annotation tokens tokenize doc include_hrefs False for tok in tokens tok.annotation annotationreturn tokens
def listen target identifier fn *args **kw _event_key target identifier fn .listen *args **kw
def quietRun cmd **kwargs return errRun cmd stderr STDOUT **kwargs [0]
def no_4byte_params f def wrapper *args **kwargs def _is_match some_str return isinstance some_str six.text_type and REGEX_4BYTE_UNICODE.findall some_str ! [] def _check_dict data_dict for key value in six.iteritems data_dict if isinstance value dict _check_dict value else if _is_match key msg _ "Propertynamescan'tcontain4byteunicode." raise exception.Invalid msg if _is_match value msg _ "%scan'tcontain4byteunicodecharacters." % key.title raise exception.Invalid msg for data_dict in [arg for arg in args if isinstance arg dict ] _check_dict data_dict for arg in args if _is_match arg msg _ "Paramvaluescan'tcontain4byteunicode." raise exception.Invalid msg _check_dict kwargs return f *args **kwargs return wrapper
def device_exists_with_ips_and_mac device_name ip_cidrs mac namespace None try device IPDevice device_name namespace namespace if mac ! device.link.address return Falsedevice_ip_cidrs [ip['cidr'] for ip in device.addr.list ]for ip_cidr in ip_cidrs if ip_cidr not in device_ip_cidrs return Falseexcept RuntimeError return Falseelse return True
def renyientropy px alpha 1 logbase 2 measure 'R' if not _isproperdist px raise ValueError 'pxisnotaproperprobabilitydistribution' alpha float alpha if alpha 1 genent shannonentropy px if logbase ! 2 return logbasechange 2 logbase * genent return genentelif 'inf' in string alpha .lower or alpha np.inf return - np.log np.max px px px ** alpha genent np.log px.sum if logbase 2 return 1 / 1 - alpha * genent else return 1 / 1 - alpha * logbasechange 2 logbase * genent
def get_sequential_open_distrib course_id db_query models.StudentModule.objects.filter course_id__exact course_id module_type__exact 'sequential' .values 'module_state_key' .annotate count_sequential Count 'module_state_key' sequential_open_distrib {}for row in db_query row_loc course_id.make_usage_key_from_deprecated_string row['module_state_key'] sequential_open_distrib[row_loc] row['count_sequential']return sequential_open_distrib
def highlight code lexer formatter outfile None return format lex code lexer formatter outfile
def get_res_pool_ref session cluster res_pool_ref session._call_method vutil 'get_object_property' cluster 'resourcePool' return res_pool_ref
def url_replace_param url name value url_components urlparse force_str url query_params parse_qs url_components.query query_params[name] valuequery urlencode query_params doseq True return force_text urlunparse [url_components.scheme url_components.netloc url_components.path url_components.params query url_components.fragment]
def libvlc_hex_version try return _dot2int bytes_to_str libvlc_get_version .split [0] except ValueError return 0
@commands u'title' @example u'.titlehttp //google.com' u'[Google]-google.com' def title_command bot trigger if not trigger.group 2 if trigger.sender not in bot.memory[u'last_seen_url'] returnmatched check_callbacks bot trigger bot.memory[u'last_seen_url'][trigger.sender] True if matched returnelse urls [bot.memory[u'last_seen_url'][trigger.sender]]else urls re.findall url_finder trigger results process_urls bot trigger urls for title domain in results[ 4] bot.reply u'[%s]-%s' % title domain
def is_threshold_sequence degree_sequence ds degree_sequence[ ]ds.sort while ds if ds[0] 0 ds.pop 0 continueif ds[ -1 ] ! len ds - 1 return Falseds.pop ds [ d - 1 for d in ds]return True
def path_tail apath bpath position bpath.find apath if position ! 0 return ''rposition position + len apath result bpath[rposition ]if not result.startswith '/' result '/' + result return result
def _url_replace_regex prefix return u'\n ?x #flags re.VERBOSE\n ?P<quote>\\\\?[\'"] #theopeningquotes\n ?P<prefix>{prefix} #theprefix\n ?P<rest>.*? #everythingelseintheurl\n ?P quote #thefirstmatchingclosingquote\n'.format prefix prefix
def _check_user user group err ''if user uid __salt__['file.user_to_uid'] user if uid '' err + 'User{0}isnotavailable'.format user if group gid __salt__['file.group_to_gid'] group if gid '' err + 'Group{0}isnotavailable'.format group return err
def group_remove groupname user None host None port None maintenance_db None password None runas None return _role_remove groupname user user host host port port maintenance_db maintenance_db password password runas runas
def safe_open_w path mkdir_p os.path.dirname path return open path 'w'
def remove_elasticbeanstalk docs_dir_location os.path.join PROJECT_DIRECTORY '.ebextensions' if os.path.exists docs_dir_location shutil.rmtree docs_dir_location filenames ['ebsetenv.py']if '{{cookiecutter.use_heroku}}'.lower ! 'y' filenames.append 'requirements.txt' for filename in filenames os.remove os.path.join PROJECT_DIRECTORY filename
def _poll_for fd readable writable error timeout event_mask 0if readable event_mask | select.POLLINif writable event_mask | select.POLLOUTif error event_mask | select.POLLERRpollable select.poll pollable.register fd event_mask if timeout event_list pollable.poll long timeout * 1000 else event_list pollable.poll return bool event_list
def generate_jmx_configs agentConfig hostname checknames None from jmxfetch import JMX_CHECKSif not checknames checknames JMX_CHECKSagentConfig['checksd_hostname'] hostnamegenerated {}for check_name service_disco_check_config in _service_disco_configs agentConfig .iteritems if check_name in checknames and check_name in JMX_CHECKS log.debug 'GeneratingJMXconfigfor %s' % check_name sd_init_config sd_instances service_disco_check_configcheck_config {'init_config' sd_init_config 'instances' sd_instances}try yaml config_to_yaml check_config generated['{}_{}'.format check_name 0 ] yamllog.debug 'YAMLgenerated %s' yaml except Exception log.exception 'UnabletogenerateYAMLconfigfor%s' check_name return generated
def geoserver_pre_delete instance sender **kwargs if getattr ogc_server_settings 'BACKEND_WRITE_ENABLED' True if not getattr instance 'service' None if instance.typename cascading_delete gs_catalog instance.typename
def makeMissingCustomDataframe nrows ncols density 0.9 random_state None c_idx_names True r_idx_names True c_idx_nlevels 1 r_idx_nlevels 1 data_gen_f None c_ndupe_l None r_ndupe_l None dtype None c_idx_type None r_idx_type None df makeCustomDataframe nrows ncols c_idx_names c_idx_names r_idx_names r_idx_names c_idx_nlevels c_idx_nlevels r_idx_nlevels r_idx_nlevels data_gen_f data_gen_f c_ndupe_l c_ndupe_l r_ndupe_l r_ndupe_l dtype dtype c_idx_type c_idx_type r_idx_type r_idx_type i j _create_missing_idx nrows ncols density random_state df.values[ i j ] np.nanreturn df
def make_rng rng_or_seed None default_seed None which_method None constructor None if isinstance which_method six.string_types which_method [which_method]if rng_or_seed is not None and all hasattr rng_or_seed attr for attr in which_method rng rng_or_seedelif rng_or_seed is not None rng constructor rng_or_seed elif default_seed is not None rng constructor default_seed else rng constructor 42 return rng
def register_babel app from flask_babel import Babelbabel Babel app supported app.config.get 'BABEL_SUPPORTED_LOCALES' ['en' 'zh'] default app.config.get 'BABEL_DEFAULT_LOCALE' 'en' @babel.localeselectordef get_locale return request.accept_languages.best_match supported default
def _manageRoles mo firstHalf mo.group 1 secondHalf mo.group 2 newRoles []roles secondHalf.split '/' for role in roles role role.strip if not role continueroleID analyze_imdbid role if roleID is None roleID u'/'else roleID + u'/'newRoles.append u'<divclass "_imdbpyrole"roleid "%s">%s</div>' % roleID role.strip return firstHalf + u'/'.join newRoles + mo.group 3
def list_option s return ListValueComponent.create s
def make_filter name op values datastore_types.ValidateProperty name values properties datastore_types.ToPropertyPb name values if isinstance properties list filters [PropertyFilter op prop for prop in properties]return CompositeFilter CompositeFilter.AND filters else return PropertyFilter op properties
def vertical_flip image_data output_encoding PNG quality None correct_orientation UNCHANGED_ORIENTATION rpc None transparent_substitution_rgb None rpc vertical_flip_async image_data output_encoding output_encoding quality quality correct_orientation correct_orientation rpc rpc transparent_substitution_rgb transparent_substitution_rgb return rpc.get_result
def _plot_option_logic plot_options_from_call_signature default_plot_options copy.deepcopy DEFAULT_PLOT_OPTIONS file_options tools.get_config_file session_options session.get_session_plot_options plot_options_from_call_signature copy.deepcopy plot_options_from_call_signature for option_set in [plot_options_from_call_signature session_options file_options] utils.validate_world_readable_and_sharing_settings option_set utils.set_sharing_and_world_readable option_set if 'filename' in option_set and 'fileopt' not in option_set option_set['fileopt'] 'overwrite'user_plot_options {}user_plot_options.update default_plot_options user_plot_options.update file_options user_plot_options.update session_options user_plot_options.update plot_options_from_call_signature user_plot_options {k v for k v in user_plot_options.items if k in default_plot_options }return user_plot_options
def _parse_tdim tdim m tdim and TDIM_RE.match tdim if m dims m.group 'dims' return tuple int d.strip for d in dims.split ' ' [ -1 ]return tuple
def make_ip_network port network ip_address netaddr.IPAddress port['fixed_ips'][0]['ip_address'] return netaddr.IPNetwork ip_address.value network.prefixlen
def makeUnicode text if isinstance text str text unicode text 'ISO-8859-1' elif not isinstance text unicode text unicode text text regex_control_code.sub lambda regs controlchars[ord regs.group 1 ] text text re.sub '\\\\x0 [0-7] ? [^0-7]|$ ' '\\\\\\1' text return text
def beacon config log.trace 'twilio_txt_msgbeaconstarting' ret []if not all [config['account_sid'] config['auth_token'] config['twilio_number']] return retoutput {}output['texts'] []client TwilioRestClient config['account_sid'] config['auth_token'] messages client.messages.list to config['twilio_number'] log.trace 'Nummessages {0}'.format len messages if len messages < 1 log.trace 'Twiliobeaconhasnotexts' return retfor message in messages item {}item['id'] str message.sid item['body'] str message.body item['from'] str message.from_ item['sent'] str message.date_sent item['images'] []if int message.num_media media client.media message.sid .list if len media for pic in media item['images'].append str pic.uri output['texts'].append item message.delete ret.append output return ret
def get_service hass config discovery_info None api_key config.get CONF_API_KEY sender config.get CONF_SENDER recipient config.get CONF_RECIPIENT return SendgridNotificationService api_key sender recipient
def softmax mat target None if not target target materr_code _eigenmat.apply_softmax mat.p_mat target.p_mat if err_code raise generate_exception err_code return target
def dmp_swap f i j u K if i < 0 or j < 0 or i > u or j > u raise IndexError '0< i<j< %sexpected' % u elif i j return f F H dmp_to_dict f u {} for exp coeff in F.items H[ exp[ i] + exp[j] + exp[ i + 1 j] + exp[i] + exp[ j + 1 ] ] coeffreturn dmp_from_dict H u K
def ceil_shift n b if not isinstance n int long or not isinstance b int long raise TypeError 'unsupportedoperandtype s %rand%r' % type n .__name__ type b .__name__ assert n > 0 and b > 0 mask 1 << b - 1 if n & mask return n >> b + 1 else return n >> b
def yield_address space start length None reverse False if not length length linux_process_info.address_sizecont Truewhile space.is_valid_address start and cont try value read_address space start length yield value except struct.error cont False yield None if reverse start - lengthelse start + length
def _get_col_o2o parent subname subcls fk_col_name deferrable None initially None ondelete None onupdate None assert subcls.Attributes.table_name is not None '%rhasnotablename.' % subcls col_args col_kwargs sanitize_args subcls.Attributes.sqla_column_args _sp_attrs_to_sqla_constraints parent subcls col_kwargs pk_column get_pk_columns subcls pk_key pk_spyne_type pk_columnpk_sqla_type _get_sqlalchemy_type pk_spyne_type if fk_col_name is None fk_col_name subname + '_' + pk_key assert fk_col_name ! subname 'Thecolumnnamefortheforeignkeymustbedifferentfromthecolumnnamefortheobjectitself.'fk ForeignKey '%s.%s' % subcls.Attributes.table_name pk_key use_alter True name '%s_%s_fkey' % subcls.Attributes.table_name fk_col_name deferrable deferrable initially initially ondelete ondelete onupdate onupdate return Column fk_col_name pk_sqla_type fk *col_args **col_kwargs
def fix_iteration_tables cursor connection.cursor cursor.execute 'DROPTABLEtko_iteration_attributes' cursor.execute _CREATE_ITERATION_ATTRIBUTES cursor.execute 'DROPTABLEtko_iteration_result' cursor.execute _CREATE_ITERATION_RESULTS
def traverse_tree course queue [course]while len queue > 0 node queue.pop queue.extend node.get_children return True
def retrieve_cors_header response key headers response.get_headers for header_name in headers if header_name.upper .strip key.upper return headers[header_name].strip return None
def _conf family 'ipv4' if __grains__['os_family'] 'RedHat' if family 'ipv6' return '/etc/sysconfig/ip6tables'else return '/etc/sysconfig/iptables'elif __grains__['os_family'] 'Arch' if family 'ipv6' return '/etc/iptables/ip6tables.rules'else return '/etc/iptables/iptables.rules'elif __grains__['os_family'] 'Debian' if family 'ipv6' return '/etc/iptables/rules.v6'else return '/etc/iptables/rules.v4'elif __grains__['os'] 'Gentoo' if family 'ipv6' return '/var/lib/ip6tables/rules-save'else return '/var/lib/iptables/rules-save'elif __grains__['os_family'] 'SUSE' return '/etc/sysconfig/scripts/SuSEfirewall2-custom'else raise SaltException 'Savingiptablestofileisnot' + 'supportedon{0}.'.format __grains__['os'] + 'PleasefileanissuewithSaltStack'
def addif br None iface None return _os_dispatch 'addif' br iface
def apply_label node return node.op.__class__.__name__
def test_table_deletion deleted set class TestTable table.Table def __del__ self deleted.add id self t TestTable {'a' [1 2 3]} the_id id t assert t['a'].parent_table is t del tgc.collect assert the_id in deleted
def missing_dependencies missing_deps []for dependency in DEPENDENCIES if not dependency.check and not dependency.optional missing_deps.append dependency if missing_deps return status deps missing_deps linesep '<br>' else return ''
def submit_jobs commands prefix qiime_config load_qiime_config CLUSTER_JOBS_SCRIPT qiime_config['cluster_jobs_fp']if not CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotsetinconfigfile!' if not exists CLUSTER_JOBS_SCRIPT or which CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotin$PATHorprovidedasfullpath!' outfilename join get_qiime_temp_dir '%s_commands.txt' % prefix fh open outfilename 'w' fh.write '\n'.join commands fh.close cmd '%s-ms%s%s' % CLUSTER_JOBS_SCRIPT outfilename prefix system cmd remove outfilename
def lab2rgb lab illuminant 'D65' observer '2' return xyz2rgb lab2xyz lab illuminant observer
def server_list_detailed profile None conn _auth profile return conn.server_list_detailed
def bool_from_string subject if isinstance subject bool return subjectelif isinstance subject int return subject 1 if hasattr subject 'startswith' if subject.strip .lower in 'true' 'on' '1' 'yes' 'y' return Truereturn False
def getLiftedOutput derivation geometryOutput xmlElement if derivation.moveType.lower [ 1] 'm' return geometryOutputgeometryOutputVertexes matrix.getConnectionVertexes geometryOutput translation Vector3 0.0 0.0 - euclidean.getBottomPath geometryOutputVertexes euclidean.translateVector3Path geometryOutputVertexes translation return geometryOutput
def hash_rename filename hashvalue path name ext split_filename filename newfilename u''.join name u'_0x' hashvalue ext return os.path.join path newfilename
def create_resource deserializer wsgi.JSONRequestDeserializer serializer wsgi.JSONResponseSerializer return wsgi.Resource Controller deserializer serializer
def setup_proxy element config if not hasattr element.props u'proxy' or not config.get u'hostname' returnelement.set_property u'proxy' httpclient.format_proxy config auth False element.set_property u'proxy-id' config.get u'username' element.set_property u'proxy-pw' config.get u'password'
def assign_regions resource for i in range 0 randint 0 5 random_index randint 0 Region.objects.all .count - 1 region Region.objects.all [random_index]resource.regions.add region
def freqs_zpk z p k worN None k np.asarray k if k.size > 1 raise ValueError 'kmustbeasinglescalargain' if worN is None w findfreqs z p 200 kind 'zp' elif isinstance worN int N worNw findfreqs z p N kind 'zp' else w worNw atleast_1d w s 1j * w num polyvalfromroots s z den polyvalfromroots s p h k * num / den return w h
def test_bti2fiff check_usage mne_bti2fiff
def timeuntil value arg None from django.utils.timesince import timesincefrom datetime import datetimeif not value return ''if arg return timesince arg value return timesince datetime.now value
def replaceInFile filename oldToNew os.rename filename filename + '.bak' f open filename + '.bak' d f.read f.close for k v in oldToNew.items d d.replace k v f open filename + '.new' 'w' f.write d f.close os.rename filename + '.new' filename os.unlink filename + '.bak'
def read_headers rfile hdict None if hdict is None hdict {}while True line rfile.readline if not line raise ValueError 'Illegalendofheaders.' if line CRLF breakif not line.endswith CRLF raise ValueError 'HTTPrequiresCRLFterminators' if line[0] in SPACE TAB v line.strip else try k v line.split COLON 1 except ValueError raise ValueError 'Illegalheaderline.' k k.strip .title v v.strip hname kif k in comma_separated_headers existing hdict.get hname if existing v ' '.join existing v hdict[hname] vreturn hdict
def people_type return s3_rest_controller
def captured_stdout return captured_output 'stdout'
@login_required@permission_required 'flagit.can_moderate' def queue request content_type None return render request 'flagit/queue.html' {'objects' FlaggedObject.objects.pending }
def CheckInstalledVersion name desired explicit CallSetAllowedModule name desired find_version PACKAGES[name][0]if name 'django' global _DESIRED_DJANGO_VERSION_DESIRED_DJANGO_VERSION 'v' + desired.replace '.' '_' installed_version find_version try desired_version distutils.version.LooseVersion desired except AttributeError desired_version LooseVersion.parse desired if not EqualVersions installed_version desired_version raise UnacceptableVersionError '%s%swasrequested but%sisalreadyinuse' % name desired_version installed_version installed[name] desired explicit
def restrict permission def decorator fx def wrapper *args **kwargs UserManager.get .require_permission extract_context permission return fx *args **kwargs return wrapperreturn decorator
def logsafe val if isinstance val six.text_type return valelif isinstance val bytes return val.decode 'utf-8' 'replace' elif isinstance val subprocess.CalledProcessError try return six.text_type val except UnicodeDecodeError return str val .decode 'utf-8' 'replace' else return val
def deb_packages attrs None where None if __grains__['os_family'] 'Debian' return _osquery_cmd table 'deb_packages' attrs attrs where where return {'result' False 'comment' 'OnlyavailableonDebianbasedsystems.'}
def descrFromDoc obj if obj.__doc__ is None or obj.__doc__.isspace return Nonelines [x.strip for x in obj.__doc__.split '\n' if x and not x.isspace ]return ''.join lines
def find_gwt_dir site_gwt os.path.join _AUTOTEST_DIR 'site-packages' 'gwt' if os.path.isdir site_gwt return site_gwtif not os.path.isdir _DEFAULT_GWT_DIR logging.error 'UnabletofindGWT.Youcanuseutils/build_externals.pytoinstallit.' sys.exit 1 return _DEFAULT_GWT_DIR
def determine_format request serializer default_format u'application/json' format request.GET.get u'format' if format if format in serializer.formats return serializer.get_mime_for_format format if u'callback' in request.GET and u'jsonp' in serializer.formats return serializer.get_mime_for_format u'jsonp' accept request.META.get u'HTTP_ACCEPT' u'*/*' if accept ! u'*/*' try best_format mimeparse.best_match serializer.supported_formats_reversed accept except ValueError raise BadRequest u'InvalidAcceptheader' if best_format return best_formatreturn default_format
def get_pymodule_path modulename *joins if not u'public' in joins joins [scrub part for part in joins]return os.path.join os.path.dirname get_module scrub modulename .__file__ *joins
def iter_first sequence it iter sequence try if PY3 return next it else return it.next except StopIteration raise ValueError
@library.global_function@contextfunctiondef display_context context include_callables False if not settings.DEBUG return ''keys sorted context.keys parts ['<dt>{key}</dt><dd>{value}</dd>'.format key key value repr context[key] for key in keys if include_callables or not callable context[key] ]html '<dlclass "jinja-context">{parts}</dl>'.format parts ''.join parts return Markup html
def run_param registry xml_parent data pdef base_param registry xml_parent data False 'hudson.model.RunParameterDefinition' XML.SubElement pdef 'projectName' .text data['project-name']
def is_docstring physical_line previous_logical line physical_line.lstrip start max [line.find i for i in START_DOCSTRING_TRIPLE] end max [ line[ -4 -1 ] i for i in END_DOCSTRING_TRIPLE] if previous_logical.startswith 'def' or previous_logical.startswith 'class' if start is 0 return Trueelse return end and start in -1 len line - 4
def _generate_cache_key request method headerlist key_prefix ctx hashlib.md5 for header in headerlist value request.META.get header None if value is not None ctx.update value path hashlib.md5 iri_to_uri request.get_full_path cache_key 'views.decorators.cache.cache_page.%s.%s.%s.%s' % key_prefix method path.hexdigest ctx.hexdigest return _i18n_cache_key_suffix request cache_key
def get_location vm_ None return __opts__.get 'location' config.get_cloud_config_value 'location' vm_ or get_configured_provider __opts__ default DEFAULT_LOCATION search_global False
def test_continuous_regression_with_overlap signal np.zeros 100000 times [1000 2500 3000 5000 5250 7000 7250 8000]events np.zeros len times 3 int events[ 2] 1events[ 0] timessignal[events[ 0]] 1.0effect hann 101 signal np.convolve signal effect [ len signal ]raw RawArray signal[np.newaxis ] mne.create_info 1 100 'eeg' assert_allclose effect linear_regression_raw raw events {1 1} tmin 0 [1].data.flatten
def check_forhash filename if isinstance filename list filename filename[0] path name os.path.split filename if re.search u' _0x[a-z0-9]{32} ' name hashvalue re.findall u' _0x[a-z0-9]{32} ' name return True hashvalue else return False None
def unregister_models engine models Image ImageProperty for model in models model.metadata.drop_all engine
def save_to_store content name mime_type location content_location Transcript.asset_location location name content StaticContent content_location name mime_type content contentstore .save content return content_location
def _uninstall_flocker_ubuntu1604 return sequence _disable_flocker_systemd + [_uninstall_flocker_ubuntu ]
def test_special_bindings keyhint key_config_stub key_config_stub.set_bindings_for 'normal' OrderedDict [ '<a' 'cmd-<a' '<b' 'cmd-<b' '<ctrl-a>' 'cmd-ctrla' ] keyhint.update_keyhint 'normal' '<' assert keyhint.text expected_text '&lt;' 'yellow' 'a' 'cmd-&lt;a' '&lt;' 'yellow' 'b' 'cmd-&lt;b'
def annotate_webext_incompatibilities results file_ addon version_string channel from .utils import find_previous_versionprevious_version find_previous_version addon file_ version_string channel if not previous_version return resultsis_webextension results['metadata'].get 'is_webextension' False was_webextension previous_version and previous_version.is_webextension if is_webextension and not was_webextension results['is_upgrade_to_webextension'] Truemsg _ 'Weallowandencourageanupgradebutyoucannotreversethisprocess.OnceyourusershavetheWebExtensioninstalled theywillnotbeabletoinstallalegacyadd-on.' messages results['messages']messages.insert 0 {'tier' 1 'type' 'warning' 'id' ['validation' 'messages' 'webext_upgrade'] 'message' msg 'description' [] 'compatibility_type' None} results['warnings'] + 1elif was_webextension and not is_webextension msg _ 'YoucannotupdateaWebExtensionsadd-onwithalegacyadd-on.YouruserswouldnotbeabletouseyournewversionbecauseFirefoxdoesnotsupportthistypeofupdate.' messages results['messages']messages.insert 0 {'tier' 1 'type' 'error' if channel amo.RELEASE_CHANNEL_LISTED else 'warning' 'id' ['validation' 'messages' 'webext_downgrade'] 'message' msg 'description' [] 'compatibility_type' None} results['errors'] + 1return results
def test_evoked_arithmetic raw events picks _get_data epochs1 Epochs raw events[ 4] event_id tmin tmax picks picks evoked1 epochs1.average epochs2 Epochs raw events[4 8] event_id tmin tmax picks picks evoked2 epochs2.average epochs Epochs raw events[ 8] event_id tmin tmax picks picks evoked epochs.average evoked_sum combine_evoked [evoked1 evoked2] weights 'nave' assert_array_equal evoked.data evoked_sum.data assert_array_equal evoked.times evoked_sum.times assert_equal evoked_sum.nave evoked1.nave + evoked2.nave evoked_diff combine_evoked [evoked1 evoked1] weights [1 -1 ] assert_array_equal np.zeros_like evoked.data evoked_diff.data
def _get_proc_create_time proc try return proc.create_time if PSUTIL2 else proc.create_time except psutil.NoSuchProcess psutil.AccessDenied return None
def get_disk_bus_for_device_type virt_type image_meta None device_type 'disk' if image_meta key 'hw_' + device_type + '_bus' disk_bus image_meta.get 'properties' {} .get key if disk_bus is not None if not is_disk_bus_valid_for_virt virt_type disk_bus raise exception.UnsupportedHardware model disk_bus virt virt_type return disk_busif virt_type 'uml' if device_type 'disk' return 'uml'elif virt_type 'lxc' return 'lxc'elif virt_type 'xen' if device_type 'cdrom' return 'ide'elif device_type 'disk' return 'xen'elif virt_type in 'qemu' 'kvm' if device_type 'cdrom' return 'ide'elif device_type 'disk' return 'virtio'return None
@require_contextdef volume_glance_metadata_get_all context return _volume_glance_metadata_get_all context
def get_sid_string principal try return win32security.ConvertSidToStringSid principal except TypeError principal get_sid principal try return win32security.ConvertSidToStringSid principal except pywintypes.error raise CommandExecutionError 'Invalidprincipal{0}'.format principal
@auth_decoratordef token_authenticated self if self.get_current_user_token is None raise web.HTTPError 403
def add_prerequisite course_key prereq_content_key milestone milestones_api.add_milestone {'name' _ 'Gatingmilestonefor{usage_key}' .format usage_key unicode prereq_content_key 'namespace' '{usage_key}{qualifier}'.format usage_key prereq_content_key qualifier GATING_NAMESPACE_QUALIFIER 'description' _ 'Systemdefinedmilestone' } propagate False milestones_api.add_course_content_milestone course_key prereq_content_key 'fulfills' milestone
def lag_select data max_lags 5 ic None pass
@register.tag 'cache' def do_cache parser token nodelist parser.parse 'endcache' parser.delete_first_token tokens token.contents.split if len tokens < 3 raise TemplateSyntaxError u"'%r'tagrequiresatleast2arguments." % tokens[0] return CacheNode nodelist tokens[1] tokens[2] tokens[3 ]
def scroll_page_up event w _current_window_for_event event b event.cli.current_bufferif w and w.render_info line_index max 0 min w.render_info.first_visible_line b.document.cursor_position_row - 1 b.cursor_position b.document.translate_row_col_to_index line_index 0 b.cursor_position + b.document.get_start_of_line_position after_whitespace True w.vertical_scroll 0
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def is_staging srv return srv constants.STAGING_URI or 'staging' in srv
def is_equal var val try v get_scalar_constant_value var return v val except NotScalarConstantError return False
def draw_if_interactive pass
def unparse input_dict output None encoding 'utf-8' full_document True short_empty_elements False **kwargs if full_document and len input_dict ! 1 raise ValueError 'Documentmusthaveexactlyoneroot.' must_return Falseif output is None output StringIO must_return Trueif short_empty_elements content_handler XMLGenerator output encoding True else content_handler XMLGenerator output encoding if full_document content_handler.startDocument for key value in input_dict.items _emit key value content_handler full_document full_document **kwargs if full_document content_handler.endDocument if must_return value output.getvalue try value value.decode encoding except AttributeError passreturn value
def HTTPInfoFromException value if isinstance value web.HTTPError return value.status_code value.log_message elif isinstance value InvalidRequestError return 400 value.args[0] elif isinstance value HttpForbiddenError return 403 value.args[0] elif isinstance value NotFoundError return 404 value.args[0] elif isinstance value ServiceUnavailableError return 503 value.args[0] else return 500 str value
def _make_entity_from_pb annotations return [EntityAnnotation.from_pb annotation for annotation in annotations]
def title_from_columns cols if cols is not None cols_title copy cols if not isinstance cols_title list cols_title [cols_title]return str ' '.join cols_title .title .title else return None
def get_database_string fname f open fname dtb f.read f.close return dtb
def get_github_releases project url u'{}/{}/tags'.format GITHUB_API project response requests.get url response.raise_for_status versions get_versions response.json return sorted versions reverse True key operator.attrgetter u'order'
def freecpu return node_info ['free_cpus']
def unexpected_fail_on_npm_install arg if 'npminstall' in arg raise BuildFailure 'Subprocessreturncode 50' else return
def chars_to_ranges s char_list list s char_list.sort i 0n len char_list result []while i < n code1 ord char_list[i] code2 code1 + 1 i + 1while i < n and code2 > ord char_list[i] code2 + 1i + 1result.append code1 result.append code2 return result
def formstyle_divs form fields table FIELDSET for id label controls help in fields _help DIV help _class 'w2p_fc' _controls DIV controls _class 'w2p_fw' _label DIV label _class 'w2p_fl' table.append DIV _label _controls _help _id id return table
@require_role 'admin' def idc_edit request header_title path1 path2 u'\u7f16\u8f91IDC' u'\u8d44\u4ea7\u7ba1\u7406' u'\u7f16\u8f91IDC' idc_id request.GET.get 'id' '' idc get_object IDC id idc_id if request.method 'POST' idc_form IdcForm request.POST instance idc if idc_form.is_valid idc_form.save return HttpResponseRedirect reverse 'idc_list' else idc_form IdcForm instance idc return my_render 'jasset/idc_edit.html' locals request
def makeSplitter lstrip None sep '|' comments True origNotesSep ' ' newNotesSep ' ' strip None def splitter x if not x return xx x.strip if not x return xif lstrip is not None x x.lstrip lstrip .lstrip lx x.split sep lx[ ] filter None [j.strip for j in lx] if comments lx[ ] [j.replace origNotesSep newNotesSep 1 for j in lx]if strip lx[ ] [j.strip strip for j in lx]return lxreturn splitter
@lower_getattr_generic types.BaseNamedTuple def namedtuple_getattr context builder typ value attr index typ.fields.index attr res builder.extract_value value index return impl_ret_borrowed context builder typ[index] res
def _wait_until_complete operation max_attempts 5 retry RetryResult _operation_complete max_tries max_attempts return retry operation.poll
def md5SessionKey params password keys 'username' 'realm' 'nonce' 'cnonce' params_copy {}for key in keys params_copy[key] params[key]params_copy['algorithm'] MD5_SESSreturn _A1 params_copy password
def _validator validator name validator.__name__doc validator.__doc__def fget self return self._tls[name]def fset self val self._tls[name] validator self val def fdel self self._tls._current.pop name None return property fget fset fdel doc
def _get_globals from __main__ import __dict__ as namespaceshell namespace.get '__ipythonshell__' if shell is not None and hasattr shell 'user_ns' return shell.user_nselse return namespacereturn namespace
def mutShrink individual if len individual < 3 or individual.height < 1 return individual iprims []for i node in enumerate individual[1 ] 1 if isinstance node Primitive and node.ret in node.args iprims.append i node if len iprims ! 0 index prim random.choice iprims arg_idx random.choice [i for i type_ in enumerate prim.args if type_ prim.ret ] rindex index + 1 for _ in range arg_idx + 1 rslice individual.searchSubtree rindex subtree individual[rslice]rindex + len subtree slice_ individual.searchSubtree index individual[slice_] subtreereturn individual
def text_ s encoding 'latin-1' errors 'strict' if isinstance s binary_type return s.decode encoding errors return s
def gf_compose_mod g h f p K if not g return []comp [g[0]]for a in g[1 ] comp gf_mul comp h p K comp gf_add_ground comp a p K comp gf_rem comp f p K return comp
def makeListCompatible fn def newfn *args 'Generatedfunction.Closure-ish.'if len args 1 return fn *args args ''.join map str args return fn args setattr newfn '__name__' fn.__name__ setattr newfn '__doc__' fn.__doc__ return newfn
def parse_kwarg string_ try return KWARG_REGEX.match string_ .groups except AttributeError return None None
def short_group_names groups groups groups.split ' ' short_group_list []if helpers.set_up_anidb_connection for groupName in groups try group sickbeard.ADBA_CONNECTION.group gname groupName except AniDBCommandTimeoutError logger.log u'TimeoutwhileloadinggroupfromAniDB.Tryingnextgroup' logger.DEBUG except Exception logger.log u'FailedwhileloadinggroupfromAniDB.Tryingnextgroup' logger.DEBUG else for line in group.datalines if line['shortname'] short_group_list.append line['shortname'] elif groupName not in short_group_list short_group_list.append groupName else short_group_list groupsreturn short_group_list
def delete_comment request unit **kwargs_ unit.commented_by Noneunit.commented_on Nonelanguage request.translation_project.languagecomment_form_class unit_comment_form_factory language form comment_form_class {} instance unit request request if form.is_valid form.save return JsonResponse {} return JsonResponseBadRequest {'msg' _ 'Failedtoremovecomment.' }
def regex_uri e regexes tag default None path e['PATH_INFO']host e.get 'HTTP_HOST' e.get 'SERVER_NAME' 'localhost' .lower i host.find ' ' if i > 0 host host[ i]key '%s %s //%s %s%s' % e.get 'REMOTE_ADDR' 'localhost' e.get 'wsgi.url_scheme' 'http' .lower host e.get 'REQUEST_METHOD' 'get' .lower path for regex value custom_env in regexes if regex.match key e.update custom_env rewritten regex.sub value key log_rewrite '%s [%s][%s]->%s' % tag key value rewritten return rewrittenlog_rewrite '%s [%s]->%s notrewritten ' % tag key default return default
def concatenate_paths paths vertices []codes []for p in paths p make_path_regular p vertices.append p.vertices codes.append p.codes _path Path np.concatenate vertices np.concatenate codes return _path
def test_prefer_deep dsk {'a' 1 'b' f 'a' 'c' f 'b' 'x' 1 'y' f 'x' }o order dsk assert o {'c' 0 'b' 1 'a' 2 'y' 3 'x' 4}
def validate_key key shape rows cols shapeif not isinstance key tuple if rows 1 key slice 0 1 None key elif cols 1 key key slice 0 1 None else raise IndexError 'Invalidindex/slice.' key format_slice slc dim for slc dim in zip key shape return tuple key
def test_end_pos_error_correction s u 'defx \n.' m ParserWithRecovery load_grammar s .modulefunc m.children[0]assert func.type 'funcdef' assert func.end_pos 3 0 assert m.end_pos 2 2
def int_from_geom func zero False func.argtypes [GEOM_PTR]func.restype c_intif zero func.errcheck check_zeroelse func.errcheck check_minus_onereturn func
def defoveate_channel img rings dense_input start_idx ring_w numpy.sum rings inner_h img.shape[1] - 2 * ring_w inner_w img.shape[2] - 2 * ring_w end_idx start_idx + inner_h * inner_w inner_img dense_input[ start_idx end_idx].reshape -1 inner_h inner_w img[ ring_w ring_w + inner_h ring_w ring_w + inner_w ] inner_imgidx 0start_idx end_idxfor rd in rings start_idx restore_ring img idx rd dense_input start_idx idx + rdreturn start_idx
def _get_constant name field_re re.compile '__{}__\\s+ \\s+ .* '.format re.escape name path os.path.join BASEDIR 'qutebrowser' '__init__.py' line field_re.search read_file path .group 1 value ast.literal_eval line return value
@webob.dec.wsgify@util.check_accept 'application/json' def get_resource_provider req uuid util.wsgi_path_item req.environ 'uuid' context req.environ['placement.context']resource_provider objects.ResourceProvider.get_by_uuid context uuid req.response.body encodeutils.to_utf8 jsonutils.dumps _serialize_provider req.environ resource_provider req.response.content_type 'application/json'return req.response
def get_request_location request context if context.location ! '' return context.locationcontext.location Noneif getattr request 'via_cdn' False g.stats.simple_event 'geoip.cdn_request' cdn_geoinfo g.cdn_provider.get_client_location request.environ if cdn_geoinfo context.location cdn_geoinfoelif getattr request 'ip' None g.stats.simple_event 'geoip.non_cdn_request' timer g.stats.get_timer 'providers.geoip.location_by_ips' timer.start location location_by_ips request.ip if location context.location location.get 'country_code' None timer.stop return context.location
def cache_key_prefix request cache_key u'%s.%s.%s.' % settings.CACHE_MIDDLEWARE_KEY_PREFIX current_site_id device_from_request request or u'default' return _i18n_cache_key_suffix request cache_key
def ttost_paired x1 x2 low upp transform None weights None if transform if transform is np.log x1 transform x1 x2 transform x2 else xx transform np.concatenate x1 x2 0 x1 xx[ len x1 ]x2 xx[len x1 ]low transform low upp transform upp dd DescrStatsW x1 - x2 weights weights ddof 0 t1 pv1 df1 dd.ttest_mean low alternative 'larger' t2 pv2 df2 dd.ttest_mean upp alternative 'smaller' return np.maximum pv1 pv2 t1 pv1 df1 t2 pv2 df2
def s3_addrow form label widget comment formstyle row_id position -1 if callable formstyle row formstyle row_id label widget comment if isinstance row tuple list for subrow in row form[0].insert position subrow if position > 0 position + 1else form[0].insert position row else addrow form label widget comment formstyle row_id position position return
def sync_output saltenv 'base' return salt.utils.extmods.sync __opts__ 'output' saltenv saltenv [0]
def getRandomInteger N randfunc None if randfunc is None _import_Random randfunc Random.new .readS randfunc N >> 3 odd_bits N % 8 if odd_bits ! 0 char ord randfunc 1 >> 8 - odd_bits S bchr char + S value bytes_to_long S return value
@bdd.given bdd.parsers.parse 'Iset{sect}->{opt}to{value}' def set_setting_given quteproc httpbin sect opt value if value '<empty>' value ''value value.replace ' port ' str httpbin.port quteproc.set_setting sect opt value
def is_nvcc_available def set_version p_out output_subprocess_Popen [nvcc_path '--version'] ver_line decode p_out[0] .strip .split '\n' [ -1 ] build version ver_line.split ' ' [1].strip .split assert build 'release' global nvcc_versionnvcc_version versiontry set_version return Trueexcept Exception p os.path.join config.cuda.root 'bin' 'nvcc' if os.path.exists p global nvcc_pathnvcc_path ptry set_version except Exception return Falsereturn Trueelse return False
def collect_driver_info driver info {'name' driver.class_name 'version' driver.version 'fqn' driver.class_fqn 'description' driver.desc 'ci_wiki_name' driver.ci_wiki_name}return info
def OAuthTokenFromHttpBody http_body token oauth.OAuthToken.from_string http_body oauth_token OAuthToken key token.key secret token.secret return oauth_token
def _safe_getattr obj attr default None try return getattr obj attr default except Exception return default
def makeBasicResponseCycles cycles 10 nCorrect 4 nIncorrect 4 length None responsesCorrectPerCycle np.ones nCorrect dtype np.int responsesIncorrectPerCycle np.zeros nIncorrect dtype np.int responses np.tile np.r_[ responsesCorrectPerCycle responsesIncorrectPerCycle ] cycles .tolist if length is not None return responses[ length]else return responses
def visitors start_date end_date visitors {}request _build_request date start_datewhile date < end_date date_str str date visitors[str date ] int request.get ids 'ga ' + profile_id start_date date_str end_date date_str metrics 'ga visitors' .execute ['rows'][0][0] date + timedelta days 1 return visitors
def sample_role name rawtext text lineno inliner options {} content [] pass
def get_lti_consumer return LtiConsumer consumer_name 'ConsumerName' consumer_key 'ConsumerKey' consumer_secret 'ConsumerSecret'
def _ls_emr_step_stderr_logs fs log_dir_stream step_id None matches _ls_logs fs log_dir_stream _match_emr_step_stderr_path step_id step_id return sorted matches key _match_sort_key reverse True
def GetSingleListItem list default None if list assert len list 1 listreturn list[0]return default
def getDocumentationPath subName '' return getJoinedPath getFabmetheusPath 'documentation' subName
def test_download_exit_status_code_when_no_requirements script result script.pip 'download' expect_error True assert 'Youmustgiveatleastonerequirementtodownload' in result.stderr assert result.returncode ERROR
def create_option_values_for_optionable optionable_type **options if not issubclass optionable_type Optionable raise TypeError u'Thegiven`optionable_type`wasnotasubclassof`Optionable` {}'.format optionable_type option_values {}registration_function _options_registration_function option_values optionable_type.register_options registration_function option_values.update **options return create_option_values option_values
def probitloglike params endog exog q 2 * endog - 1 X exogreturn np.add.reduce stats.norm.logcdf q * np.dot X params
def first_ip network atoi lambda addr struct.unpack '!I' socket.inet_aton addr [0] itoa lambda addr socket.inet_ntoa struct.pack '!I' addr address netmask network.split '/' netmask_i 4294967295 << 32 - atoi netmask & 4294967295 return itoa atoi address & netmask_i + 1
@opt.register_specialize 'stabilize' 'fast_compile' @gof.local_optimizer [tensor.Elemwise] def local_logsoftmax node if isinstance node.op tensor.Elemwise and isinstance node.op.scalar_op scalar.basic.Log and len node.inputs 1 and node.inputs[0].owner is not None and isinstance node.inputs[0].owner.op Softmax inVars node.inputs[0].owner.inputs[0]new_op LogSoftmax ret new_op inVars ret.tag.values_eq_approx values_eq_approx_remove_infcopy_stack_trace [node.inputs[0] node.outputs[0]] ret return [ret]
def stChromaFeaturesInit nfft fs freqs numpy.array [ f + 1 * fs / 2 * nfft for f in range nfft ] Cp 27.5nChroma numpy.round 12.0 * numpy.log2 freqs / Cp .astype int nFreqsPerChroma numpy.zeros nChroma.shape[0] uChroma numpy.unique nChroma for u in uChroma idx numpy.nonzero nChroma u nFreqsPerChroma[idx] idx[0].shapereturn nChroma nFreqsPerChroma
def _set_nxm_headers nxm_headers def _set_nxm_headers_dec self self.nxm_headers nxm_headersreturn selfreturn _set_nxm_headers_dec
def send_summary for d in frappe.get_all u'DailyWorkSummary' dict status u'Open' daily_work_summary frappe.get_doc u'DailyWorkSummary' d.name daily_work_summary.send_summary
def getVertexGivenLine line splitLine line.split return Vector3 getFloat splitLine[1] getFloat splitLine[2] getFloat splitLine[3]
def splantider tck n 1 if n < 0 return splder tck - n t c k tcksh slice None + None * len c.shape[1 ] for j in range n dt t[ k + 1 ] - t[ - k - 1 ] dt dt[sh]c np.cumsum c[ - k - 1 ] * dt axis 0 / k + 1 c np.r_[ np.zeros 1 + c.shape[1 ] c [c[ -1 ]] * k + 2 ]t np.r_[ t[0] t t[ -1 ] ]k + 1return t c k
def load_random_chromosome chr_name cur_chromosome BasicChromosome.Chromosome chr_name num_segments random.randrange num_possible_segments for seg in range num_segments if seg 0 cur_segment BasicChromosome.TelomereSegment elif seg num_segments - 1 cur_segment BasicChromosome.TelomereSegment 1 else cur_segment BasicChromosome.ChromosomeSegment color_chance random.random if color_chance < color_prob fill_color random.choice color_choices cur_segment.fill_color fill_colorid_chance random.random if id_chance < id_prob id get_random_id cur_segment.label idcur_chromosome.add cur_segment return cur_chromosome num_segments
def _generate_python_path pkg rospack if pkg in _bootstrapped return []m rospack.get_manifest pkg if m.is_catkin _bootstrapped.append pkg return []packages get_depends pkg rospack packages.append pkg paths []try for p in packages m rospack.get_manifest p d rospack.get_path p _append_package_paths m paths d _bootstrapped.append p except if pkg in _bootstrapped _bootstrapped.remove pkg raisereturn paths
def is_user_capable user api_name user urllib.unquote user sys.stderr.write 'checkingpermissionsforuser' + user + 'onapi' + api_name + '\n' secret_file open '/etc/appscale/secret.key' 'r' secret secret_file.read secret secret[0 -1 ]secret_file.close uaserver_file open '/etc/appscale/hypersoap' 'r' uaserver uaserver_file.read uaserver_file.close server SOAPpy.SOAPProxy 'https //' + uaserver + ' 4343' capabilities server.get_capabilities user secret if not isinstance capabilities str return Falsecapabilities capabilities.split ' ' sys.stderr.write 'user' + user + 'hasthefollowingcapabilities ' + str capabilities + '\n' if api_name in capabilities return Trueelse return False
def register linter linter.register_checker ExceptionsChecker linter
def get_all_objects gc.collect gcl gc.get_objects olist {}_getr gcl olist del olist[id olist ]del olist[id gcl ]del olist[id sys._getframe ]return olist
def collect_data_files package include_py_files False subdir None if not isinstance package string_types raise ValueError pkg_base pkg_dir get_package_paths package if subdir pkg_dir os.path.join pkg_dir subdir datas []for dirpath dirnames files in os.walk pkg_dir for f in files extension os.path.splitext f [1]if include_py_files or extension not in PY_IGNORE_EXTENSIONS source os.path.join dirpath f dest remove_prefix dirpath os.path.dirname pkg_base + os.sep datas.append source dest return datas
def add_metadata_type ir buf []for line in ir.splitlines if re_metadata_def.match line if None is re_metadata_correct_usage.search line line line.replace '!{' 'metadata!{' line line.replace '!"' 'metadata!"' def sub_metadata m return 'metadata{0}'.format m.group 0 line re_metadata_ref.sub sub_metadata line line line.lstrip 'metadata' buf.append line return '\n'.join buf
def isLineIntersectingLoops loops pointBegin pointEnd normalizedSegment pointEnd - pointBegin normalizedSegmentLength abs normalizedSegment if normalizedSegmentLength > 0.0 normalizedSegment / normalizedSegmentLengthsegmentYMirror complex normalizedSegment.real - normalizedSegment.imag pointBeginRotated segmentYMirror * pointBegin pointEndRotated segmentYMirror * pointEnd if isLoopListIntersectingInsideXSegment loops pointBeginRotated.real pointEndRotated.real segmentYMirror pointBeginRotated.imag return Truereturn False
def sequences_add_start_id sequences start_id 0 remove_last False sequences_out [[] for _ in range len sequences ]for i in range len sequences if remove_last sequences_out[i] [start_id] + sequences[i][ -1 ] else sequences_out[i] [start_id] + sequences[i] return sequences_out
def seteuid uid uid parse_uid uid if uid ! os.getuid os.seteuid uid
def dylib_info filename is_dylib DYLIB_RE.match filename if not is_dylib return Nonereturn is_dylib.groupdict
def check_paths paths for path in paths if is_binary path continuefor line in open path 'r' match RE_OBJ.search line msg 'cookiecuttervariablenotreplacedin{}'assert match is None msg.format path
def _compute_mi x y x_discrete y_discrete n_neighbors 3 if x_discrete and y_discrete return mutual_info_score x y elif x_discrete and not y_discrete return _compute_mi_cd y x n_neighbors elif not x_discrete and y_discrete return _compute_mi_cd x y n_neighbors else return _compute_mi_cc x y n_neighbors
def po_due_followups query FS 'followup_date' < datetime.datetime.utcnow .date & FS 'completed' ! True resource current.s3db.resource 'po_household_followup' filter query return resource.count
def vsepr_build_correct_answer geometry atoms return {'geometry' geometry 'atoms' atoms}
def _get_enabled_tax_rules taxing_context tax_class tax_rules TaxRule.objects.may_match_postal_code taxing_context.postal_code .filter enabled True tax_classes tax_class if taxing_context.customer_tax_group tax_rules tax_rules.filter Q customer_tax_groups taxing_context.customer_tax_group | Q customer_tax_groups None tax_rules tax_rules.order_by '-override_group' 'priority' return tax_rules
def sixteen data n 0for b in serial.iterbytes data yield '{ 02X}'.format ord b b.decode 'ascii' if '' < b < '\x7f' else '.' n + 1if n 8 yield '' '' elif n > 16 yield None None n 0if n > 0 while n < 16 n + 1if n 8 yield '' '' yield '' '' yield None None
def texts i e return pq e .text
def inv_item_quantity try item_id request.args[0]except raise HTTP 400 current.xml.json_message False 400 'Novalueprovided!' table s3db.inv_inv_itemptable db.supply_item_packquery table.id item_id & table.item_pack_id ptable.id record db query .select table.quantity ptable.quantity limitby 0 1 .first d {'iquantity' record.inv_inv_item.quantity 'pquantity' record.supply_item_pack.quantity}output json.dumps d response.headers['Content-Type'] 'application/json'return output
def get_job_count_by_state request username res {'completed' 0 'running' 0 'failed' 0 'killed' 0 'all' 0}jobcounts request.jt.get_job_count_by_user username res['completed'] jobcounts.nSucceededres['running'] jobcounts.nPrep + jobcounts.nRunning res['failed'] jobcounts.nFailedres['killed'] jobcounts.nKilledres['all'] res['completed'] + res['running'] + res['failed'] + res['killed'] return res
def html4annotation htmlpage baseurl None proxy_resources None htmlpage add_tagids htmlpage cleaned_html descriptify htmlpage baseurl proxy proxy_resources return cleaned_html
def test_prompt_should_ask_and_rm_repo_dir mocker tmpdir mock_read_user mocker.patch 'cookiecutter.vcs.read_user_yes_no' return_value True autospec True repo_dir tmpdir.mkdir 'repo' vcs.prompt_and_delete_repo str repo_dir assert mock_read_user.calledassert not repo_dir.exists
def add_close_action widget return add_action widget N_ u'Close...' widget.close hotkeys.CLOSE hotkeys.QUIT
def _du real_path total_size 0if os.path.isdir real_path for dirpath dirnames filenames in os.walk real_path for filename in filenames total_size + os.path.getsize os.path.join dirpath filename else total_size + os.path.getsize real_path return total_size
@click.command @click.option 'console' '--ipython' default True flag_value 'ipython' help 'Startwithipythonconsole' @click.option 'console' '--ptpython' flag_value 'ptpython' help 'Startwithptpythonconsole' @click.option 'console' '--bpython' flag_value 'bpython' help 'Startwithbpythonconsole' @click.option 'console' '--python' flag_value 'python' help 'Startwithpythonconsole' def shell console context {'app' app 'db' db}return create_shell console extra_vars context
def simple_parse_to_segments formatted_text if 'message_parser' in dir hangups segments hangups.ChatMessageSegment.from_str formatted_text else segments kludgy_html_parser.simple_parse_to_segments formatted_text return segments
def setup_request_bound_data config def attach_bound_data request parent getattr request 'parent' None return parent.bound_data if parent else {} config.add_request_method attach_bound_data name 'bound_data' reify True
@bp.route '/<urlname>' def view urlname node Node.query.filter_by urlname urlname .first_or_404 page force_int request.args.get 'page' 1 0 if not page return abort 404 paginator Topic.query.filter_by node_id node.id .order_by Topic.id.desc .paginate page paginator.items fill_topics paginator.items status Noneif g.user status NodeStatus.query.filter_by account_id g.user.id node_id node.id .first return render_template 'node/view.html' node node paginator paginator status status
@contextmanagerdef safe_concurrent_creation target_path safe_mkdir_for target_path tmp_path u'{}.tmp.{}'.format target_path uuid.uuid4 .hex try yield tmp_path finally if os.path.exists tmp_path safe_concurrent_rename tmp_path target_path
def var_label var precision 3 if var.name is not None return var.nameelif isinstance var gof.Constant h np.asarray var.data is_const Falseif h.ndim 0 is_const Trueh np.array [h] dstr np.array2string h precision precision if '\n' in dstr dstr dstr[ dstr.index '\n' ]if is_const dstr dstr.replace '[' '' .replace ']' '' return dstrelse return type_to_str var.type
def validate_required_iff **kwargs def _validator form field all_conditions_met Truefor key value in kwargs.iteritems if getattr form key .data ! value all_conditions_met Falseif all_conditions_met if field.data is None or isinstance field.data str unicode and not field.data.strip or isinstance field.data FileStorage and not field.data.filename.strip raise validators.ValidationError 'Thisfieldisrequired.' else field.errors[ ] []raise validators.StopValidation return _validator
def import_no_virt_driver_import_deps physical_line filename thisdriver _get_virt_name virt_file_re filename thatdriver _get_virt_name virt_import_re physical_line if thatdriver is not None and thisdriver is not None and thisdriver ! thatdriver return 0 'N311 importingcodefromothervirtdriversforbidden'
def _convert_to_array_of_opt_val optvals array_of_optv DataObject array_of_optv.OptionValue optvalsreturn array_of_optv
def setup_user_info if os.geteuid ! 0 returnglobal g_user_uid g_user_gid g_user_uid g_user_gid desktop.lib.daemon_utils.get_uid_gid SETUID_USER SETGID_GROUP
def _setup_styles conditions style_dict style default tags set [tag for cond in conditions for tag in cond.split '/' ] msg "Can'tmapbetweenconditionsandtheprovided{0}.Makesureyouhaveprovidedkeysintheformatof'/'-separatedtags andthatthesecorrespondto'/'-separatedtagsfortheconditionnames e.g. conditionslike'Visual/Right' andstyleslike'colors dict Visual 'red' '.Theoffendingtagwas'{1}'."for key in style_dict for tag in key.split '/' if tag not in tags raise ValueError msg.format style tag condition_warning 'Condition{0}couldnotbemappedtoa' + style style_warning '.Usingthedefaultof{0}.'.format default for condition in conditions if condition not in style_dict if '/' not in condition warn condition_warning.format condition + style_warning style_dict[condition] defaultfor style_ in style_dict if style_ in condition.split '/' style_dict[condition] style_dict[style_]breakreturn style_dict
def dijkstra_predecessor_and_distance G source cutoff None weight 'weight' weight _weight_function G weight pred {source []}return pred _dijkstra G source weight pred pred cutoff cutoff
def atleast_2d *arys res []for a in arys if not isinstance a cupy.ndarray raise TypeError 'Onlycupyarrayscanbeatleast_2d' if a.ndim 0 a a.reshape 1 1 elif a.ndim 1 a a[None ]res.append a if len res 1 res res[0]return res
def last_month_day tm year month tm[ 2]day _DAYS[month]if day 28 and year % 4 0 day 29return day
def _reduce_function func globs if func.__closure__ cells [cell.cell_contents for cell in func.__closure__]else cells Nonereturn _reduce_code func.__code__ globs func.__name__ cells
def unpickleStringO val sek x _cStringIO x.write val x.seek sek return x
def is_full_slice obj l return isinstance obj slice and obj.start 0 and obj.stop l and obj.step is None
def langnames_to_langcodes names iso639 _load_iso639 translate _ans {}names set names for k v in iso639['by_3t'].iteritems tv translate v if tv in names names.remove tv ans[tv] kif not names breakfor x in names ans[x] Nonereturn ans
def spherical_yn n z derivative False if derivative return _spherical_yn_d n z else return _spherical_yn n z
def current_year_and_week _update_week_number return _cur_year _cur_week
def _chk_asarray a axis if axis is None a ravel a outaxis 0else a asarray a outaxis axisreturn a outaxis
def test_large_angle_representation a Angle 350 u.deg + Angle 350 u.deg a.to_string a.to_string u.hourangle repr a repr a.to u.hourangle str a str a.to u.hourangle
def Gamma name k theta return rv name GammaDistribution k theta
def make_subprocess cmdline stdout False stderr False stdin False universal_newlines False cmdline cmdline.encode 'ascii' logging.info "Runningcmd'%s'" % cmdline kwargs {}kwargs['stdout'] stdout and subprocess.PIPE or None kwargs['stderr'] stderr and subprocess.PIPE or None kwargs['stdin'] stdin and subprocess.PIPE or None kwargs['universal_newlines'] universal_newlinesargs shlex.split cmdline logging.info "Runningargs'%s'" % args proc subprocess.Popen args **kwargs return proc
def addStreamHandler addHandler logging.StreamHandler stream sys.stdout
def rfft inp norm None s inp.shape[1 ]cond_norm _unitary norm scaling 1if cond_norm 'ortho' scaling T.sqrt s.prod .astype inp.dtype return rfft_op inp s / scaling
def useTest vm prompt Prompt old vm.logfileif old stdout log '*Temporarilydisablingloggingtostdout' vm.logfile Nonelog '*Switchingtointeractiveuse-presscontrol-]toexit' vm.interact if old stdout log '*Restoringloggingtostdout' vm.logfile stdout
def mask_between_time dts start end include_start True include_end True time_micros dts._get_time_micros start_micros _time_to_micros start end_micros _time_to_micros end left_op right_op join_op _opmap[ bool include_start bool include_end start_micros < end_micros ]return join_op left_op start_micros time_micros right_op time_micros end_micros
def _json_plays drive data plays []seen_ids set seen_desc set for playid in map str sorted map int data p data[playid]desc p['desc'] p['time'] p['yrdln'] p['qtr'] if playid in seen_ids or desc in seen_desc continueseen_ids.add playid seen_desc.add desc plays.append Play drive playid data[playid] return plays
def get_course_updates location provided_id user_id try course_updates modulestore .get_item location except ItemNotFoundError course_updates modulestore .create_item user_id location.course_key location.block_type location.block_id course_update_items get_course_update_items course_updates _get_index provided_id return _get_visible_update course_update_items
def served_by_perl url r requests.get url allow_redirects False status r.status_code 302 perl 'x-perl-redirect' in r.headers and r.headers['x-perl-redirect'] 'True' return all [status perl]
def b64c b return string.translate b B64C_TRANSLATE B64C_STRIP
def conjuncts expr return And.make_args expr
def create_submission conf transform_valid transform_test None features None if transform_test is None transform_test transform_validkwargs subdict conf ['dataset' 'normalize' 'normalize_on_the_fly' 'sparse'] kwargs.update randomize_valid False randomize_test False valid_set test_set load_data kwargs [1 3]if not conf.get 'sparse' False valid_set valid_set.get_value borrow True test_set test_set.get_value borrow True if features is not None valid_set valid_set[ features]test_set test_set[ features]valid_repr transform_valid valid_set test_repr transform_test test_set save_submission conf valid_repr test_repr
def get_azimuth_value label _check_is_integral 'azimuth' label if label -1 return Noneelse if label % 2 ! 0 or label < 0 or label > 34 raise ValueError 'Expectedazimuthtobeanevennumberbetween0and34inclusive or-1 butgot%sinstead.' % str label return label * 10
def ajax_editable_boolean attr short_description def _fn self item return ajax_editable_boolean_cell item attr _fn.short_description short_description_fn.editable_boolean_field attrreturn _fn
def get_minions log.debug 'sqlite3returner<get_minions>called' conn _get_conn ret None cur conn.cursor sql 'SELECTDISTINCTidFROMsalt_returns'cur.execute sql data cur.fetchall ret []for minion in data ret.append minion[0] _close_conn conn return ret
def daemonize for module in sys.modules.keys if module.startswith 'gevent' raise ValueError 'Cannotdaemonizeifgeventisloaded' if hasattr os 'fork' child_pid os.fork else raise ValueError 'Daemonizingisnotavailableonthisplatform.' if child_pid ! 0 os._exit 0 os.setsid subchild os.fork if subchild os._exit 0 maxfd get_maxfd closerange 0 maxfd os.open REDIRECT_TO os.O_RDWR os.dup2 0 1 os.dup2 0 2
def show_check request name try check CHECKS[name]except KeyError raise Http404 'Nocheckmatchesthegivenquery.' ignore 'ignored' in request.GET url_params {}if ignore url_params['ignored'] 'true'checks acl_checks request.user .filter check name ignore ignore if 'language' in request.GET checks checks.filter language__code request.GET['language'] url_params['language'] request.GET['language']if 'project' in request.GET return redirect_param 'show_check_project' encode_optional url_params project request.GET['project'] name name checks checks.values 'project__slug' .annotate count Count 'id' return render request 'check.html' {'checks' checks 'title' check.name 'check' check 'url_params' encode_optional url_params }
def test_batch_normalized_mlp_mean_only_propagated_at_alloc mlp BatchNormalizedMLP [Tanh Tanh ] [5 7 9] mean_only True assert mlp.mean_onlyassert not any act.children[0].mean_only for act in mlp.activations mlp.allocate assert all act.children[0].mean_only for act in mlp.activations
def gf_pow_mod f n g p K if not n return [K.one]elif n 1 return gf_rem f g p K elif n 2 return gf_rem gf_sqr f p K g p K h [K.one]while True if n & 1 h gf_mul h f p K h gf_rem h g p K n - 1n >> 1if not n breakf gf_sqr f p K f gf_rem f g p K return h
def run_tests_in_emulator package env_vars PACKAGE_INFO[package]start_command get_start_command package proc_start subprocess.Popen start_command stdout subprocess.PIPE stderr subprocess.PIPE try wait_ready package proc_start env_init_command get_env_init_command package proc_env subprocess.Popen env_init_command stdout subprocess.PIPE stderr subprocess.PIPE env_status proc_env.wait if env_status ! 0 raise RuntimeError env_status proc_env.stderr.read env_lines proc_env.stdout.read .strip .split '\n' for env_var in env_vars line_prefix 'export' + env_var + ' ' value [line.split line_prefix 1 [1] for line in env_lines if line.startswith line_prefix ]os.environ[env_var] valuerun_module_tests package ignore_requirements True finally cleanup proc_start.pid
def filter_tool context tool return False
@contextfilterdef number_format context value value str value negative Falseaddzero Noneif value[0] '-' value value[1 ]negative Trueif '.' in value point value.rindex '.' if point len value - 2 addzero Trueelse point len value while point < len value - 3 if value[ len value - 1 ] '0' value value[ len value - 1 ]else breakwhile point > 3 value value[ point - 3 ] + ' ' + value[ point - 3 ] point value.index ' ' if addzero value + '0'if negative value '-' + value return value
def timedelta_to_integral_minutes delta return timedelta_to_integral_seconds delta // 60
def test_odd value return value % 2 1
def cut_threshold labels rag thresh in_place True if not in_place rag rag.copy to_remove [ x y for x y d in rag.edges_iter data True if d['weight'] > thresh ]rag.remove_edges_from to_remove comps nx.connected_components rag map_array np.arange labels.max + 1 dtype labels.dtype for i nodes in enumerate comps for node in nodes for label in rag.node[node]['labels'] map_array[label] ireturn map_array[labels]
def flavor_destroy context flavor_id return IMPL.flavor_destroy context flavor_id
def parse_owner_mappings type options fatal opt_name '--map-' + type value_rx '^ [^ ]+ [^ ]* $'if type in 'uid' 'gid' value_rx '^ -?[0-9]+ -?[0-9]+ $'owner_map {}for flag in options option parameter flagif option ! opt_name continuematch re.match value_rx parameter if not match raise fatal "couldn'tparse%sas%smapping" % parameter type old_id new_id match.groups if type in 'uid' 'gid' old_id int old_id new_id int new_id owner_map[old_id] new_idreturn owner_map
def get_total_project_memberships project return project.memberships.count
def indexable *iterables result []for X in iterables if sp.issparse X result.append X.tocsr elif hasattr X '__getitem__' or hasattr X 'iloc' result.append X elif X is None result.append X else result.append np.array X check_consistent_length *result return result
def getTricomplexTimesColumn firstTricomplex otherColumn dotProductX firstTricomplex[0].real * otherColumn.real + firstTricomplex[1].real * otherColumn.imag dotProductY firstTricomplex[0].imag * otherColumn.real + firstTricomplex[1].imag * otherColumn.imag return complex dotProductX dotProductY
def file_upload_echo request r dict [ k f.name for k f in request.FILES.items ] return HttpResponse json.dumps r
def urlquote_plus url safe u'' return force_text quote_plus force_str url force_str safe
def migrate_cohort_settings course cohort_settings created CourseCohortsSettings.objects.get_or_create course_id course.id defaults {'is_cohorted' course.is_cohorted 'cohorted_discussions' list course.cohorted_discussions 'always_cohort_inline_discussions' course.always_cohort_inline_discussions} if created manual_cohorts CourseUserGroup.objects.filter course_id course.id group_type CourseUserGroup.COHORT .exclude name__in course.auto_cohort_groups for cohort in manual_cohorts CourseCohort.create course_user_group cohort for group_name in course.auto_cohort_groups CourseCohort.create cohort_name group_name course_id course.id assignment_type CourseCohort.RANDOM return cohort_settings
def get_account_created name ret _get_account_policy_data_value name 'creationTime' unix_timestamp salt.utils.mac_utils.parse_return ret date_text _convert_to_datetime unix_timestamp return date_text
def restore_asset_from_trashcan location trash contentstore 'trashcan' store contentstore loc StaticContent.get_location_from_path location content trash.find loc store.save content if content.thumbnail_location is not None try thumbnail_content trash.find content.thumbnail_location store.save thumbnail_content except Exception pass
def _parse_date_rfc822 dateString data dateString.split if data[0][ -1 ] in ' ' '.' or data[0].lower in rfc822._daynames del data[0]if len data 4 s data[3]i s.find '+' if i > 0 data[3 ] [s[ i] s[ i + 1 ]]else data.append '' dateString ''.join data elif len data 5 and data[4].lower .startswith 'etc/' data[4] data[4][4 ]dateString ''.join data if len data < 5 dateString + '00 00 00GMT'tm rfc822.parsedate_tz dateString if tm return time.gmtime rfc822.mktime_tz tm
def add_cohort course_key name assignment_type log.debug 'Addingcohort%sto%s' name course_key if is_cohort_exists course_key name raise ValueError _ 'Youcannotcreatetwocohortswiththesamename' try course courses.get_course_by_id course_key except Http404 raise ValueError 'Invalidcourse_key' cohort CourseCohort.create cohort_name name course_id course.id assignment_type assignment_type .course_user_grouptracker.emit 'edx.cohort.creation_requested' {'cohort_name' cohort.name 'cohort_id' cohort.id} return cohort
def find_email string unique True string u string .replace u'\u2024' '.' matches []for m in RE_EMAIL.finditer string s m.group 0 if not unique or s not in matches matches.append s return matches
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnadd_devices TelldusLiveSensor hass sensor for sensor in discovery_info
def H_from_ransac fp tp model maxiter 1000 match_theshold 10 from PCV.tools import ransacdata vstack fp tp H ransac_data ransac.ransac data.T model 4 maxiter match_theshold 10 return_all True return H ransac_data['inliers']
def __update_loaders z non_local['loaders'] []for filename in z.namelist if not isinstance filename str_cls filename filename.decode 'utf-8' non_local['loaders'].append filename
def fminbound func x1 x2 args xtol 1e-05 maxfun 500 full_output 0 disp 1 options {'xatol' xtol 'maxiter' maxfun 'disp' disp}res _minimize_scalar_bounded func x1 x2 args **options if full_output return res['x'] res['fun'] res['status'] res['nfev'] else return res['x']
def _conf family 'ipv4' if __grains__['os_family'] 'RedHat' if family 'ipv6' return '/etc/sysconfig/ip6tables'else return '/etc/sysconfig/iptables'elif __grains__['os_family'] 'Arch' if family 'ipv6' return '/etc/iptables/ip6tables.rules'else return '/etc/iptables/iptables.rules'elif __grains__['os_family'] 'Debian' if family 'ipv6' return '/etc/iptables/rules.v6'else return '/etc/iptables/rules.v4'elif __grains__['os'] 'Gentoo' if family 'ipv6' return '/var/lib/ip6tables/rules-save'else return '/var/lib/iptables/rules-save'elif __grains__['os_family'] 'SUSE' return '/etc/sysconfig/scripts/SuSEfirewall2-custom'else raise SaltException 'Savingiptablestofileisnot' + 'supportedon{0}.'.format __grains__['os'] + 'PleasefileanissuewithSaltStack'
def prelu x W return PReLUFunction x W
def mark_as_titlepage container name move_to_start True ver container.opf_version_parsedif move_to_start for item q linear in container.spine_iter if name q breakif not linear item.set u'linear' u'yes' if item.getparent .index item > 0 container.insert_into_xml item.getparent item 0 if ver.major < 3 for ref in container.opf_xpath u'//opf guide/opf reference[@type "cover"]' ref.getparent .remove ref for guide in get_guides container container.insert_into_xml guide guide.makeelement OPF u'reference' type u'cover' href container.name_to_href name container.opf_name else container.apply_unique_properties name u'calibre title-page' container.dirty container.opf_name
def batch_det a return BatchDet a
def _get_content_range start end total start start or 0 end end or total - 1 return 'bytes%s-%s/%s' % start end total
def _compose_linear_fitting_data mu u for k in range u['nterms'] - 1 k1 k + 1 mu1n np.power mu[0] k1 u['y'][k] u['w'][k] * u['fn'][k1] - mu1n * u['fn'][0] for p in range u['nfit'] - 1 u['M'][k][p] u['w'][k] * np.power mu[ p + 1 ] k1 - mu1n
def _fit_dipoles fun min_dist_to_inner_skull data times guess_rrs guess_data fwd_data whitener proj_op ori n_jobs from scipy.optimize import fmin_cobyla parallel p_fun _ parallel_func fun n_jobs res parallel p_fun min_dist_to_inner_skull B t guess_rrs guess_data fwd_data whitener proj_op fmin_cobyla ori for B t in zip data.T times pos np.array [r[0] for r in res] amp np.array [r[1] for r in res] ori np.array [r[2] for r in res] gof np.array [r[3] for r in res] * 100 residual np.array [r[4] for r in res] .Treturn pos amp ori gof residual
def _compare_by_version path1 path2 if path1.source path2.source if path1.source_version_num > path2.source_version_num return path1else return path2return None
def _gen_gce_as_policy as_params asp_data {}asp_data['maxNumReplicas'] as_params['max_instances']if 'min_instances' in as_params asp_data['minNumReplicas'] as_params['min_instances']if 'cool_down_period' in as_params asp_data['coolDownPeriodSec'] as_params['cool_down_period']if 'cpu_utilization' in as_params and 'target' in as_params['cpu_utilization'] asp_data['cpuUtilization'] {'utilizationTarget' as_params['cpu_utilization']['target']}if 'load_balancing_utilization' in as_params and 'target' in as_params['load_balancing_utilization'] asp_data['loadBalancingUtilization'] {'utilizationTarget' as_params['load_balancing_utilization']['target']}return asp_data
def parse_atom tokens options token tokens.current result []if token in ' [' tokens.move matching pattern {' ' [' ' Required] '[' [']' Optional]}[token]result pattern *parse_expr tokens options if tokens.move ! matching raise tokens.error "unmatched'%s'" % token return [result]elif token 'options' tokens.move return [AnyOptions ]elif token.startswith '--' and token ! '--' return parse_long tokens options elif token.startswith '-' and token not in '-' '--' return parse_shorts tokens options elif token.startswith '<' and token.endswith '>' or token.isupper return [Argument tokens.move ]else return [Command tokens.move ]
def str2bin value classic_mode True text ''for character in value if text ! '' text + ''byte ord character text + byte2bin byte classic_mode return text
def python_implementation return _sys_version [0]
def require_cuda_ndarray obj if not is_cuda_ndarray obj raise ValueError 'requireancudandarrayobject'
def slicable dim pad 0 dim0 np.prod dim[ -1 ] + pad return dim0 dim[ -1 ]
def is_ssh_uri url return urllib_parse url [0] in ssh_uri_schemes
def _Cobject cls ctype o object.__new__ cls o._as_parameter_ ctypereturn o
def randitems_from_structure fmt t memlen itemsize _ _ _ _ treturn gen_items memlen // itemsize '#' + fmt 'numpy'
def is_ascii word def onlyascii char if ord char > 127 return ''else return charfor c in word if not onlyascii c return Falsereturn True
def det_perm M args []s Truen M.rowstry list M._matexcept AttributeError list flatten M.tolist for perm in generate_bell n fac []idx 0for j in perm fac.append list[ idx + j ] idx + nterm Mul *fac args.append term if s else - term s not s return Add *args
def validate_ok_for_update update validate_is_mapping 'update' update if not update raise ValueError 'updateonlyworkswith$operators' first next iter update if not first.startswith '$' raise ValueError 'updateonlyworkswith$operators'
def instance_key model instance_or_pk return '%s.%s %d' % model._meta.app_label model._meta.model_name getattr instance_or_pk 'pk' instance_or_pk
def gen_arg_base_type fn mod fn.modulefnty fn.type.pointeeconsts [lc.MetaDataString.get mod str a for a in fnty.args]name lc.MetaDataString.get mod 'kernel_arg_base_type' return lc.MetaData.get mod [name] + consts
def test_elemwise_collapse2 shape 4 5 9 a cuda_ndarray.CudaNdarray theano._asarray numpy.random.rand *shape dtype 'float32' a theano._asarray numpy.random.rand *shape dtype 'float32' a2 tcn.shared_constructor a 'a' a3 a2.dimshuffle 0 'x' 1 2 b tcn.CudaNdarrayType False False False False c a3 + b f pfunc [b] [c] mode mode_with_gpu v theano._asarray numpy.random.rand shape[0] 5 *shape[1 ] dtype 'float32' v cuda_ndarray.CudaNdarray v out f v [0]assert numpy.allclose out a.reshape shape[0] 1 *shape[1 ] + v
def libvlc_video_get_title_description p_mi f _Cfunctions.get 'libvlc_video_get_title_description' None or _Cfunction 'libvlc_video_get_title_description' 1 None ctypes.POINTER TrackDescription MediaPlayer return f p_mi
def generateUUID return str uuid.uuid4
def show_frontends socket '/var/run/haproxy.sock' ha_conn _get_conn socket ha_cmd haproxy.cmds.showFrontends return ha_conn.sendCmd ha_cmd
def resolve_hostname hostname res socket.getaddrinfo hostname None [0] family socktype proto canonname sockaddr resreturn sockaddr[0]
def is_safe_path_component path return path and '/' not in path and path not in '.' '..'
def findTwistedProjects baseDirectory projects []for filePath in baseDirectory.walk if filePath.basename 'topfiles' projectDirectory filePath.parent projects.append Project projectDirectory return projects
def displayFile filename print 'File' + filename + 'isbeingdisplayed.' fileText archive.getFileText filename gcodec.writeFileMessageSuffix filename displayText fileText 'Thegcodelogfileissavedas' '_log'
def num_windows_of_length_M_on_buffers_of_length_N M N return N - M + 1
def get_storage_hash storage if isinstance storage LazyObject if storage._wrapped is None storage._setup storage storage._wrappedif not isinstance storage six.string_types storage_cls storage.__class__storage '%s.%s' % storage_cls.__module__ storage_cls.__name__ return hashlib.md5 storage.encode 'utf8' .hexdigest
def convert_to_RGB_255 colors rgb_components []for component in colors rounded_num decimal.Decimal str component * 255.0 .quantize decimal.Decimal '1' rounding decimal.ROUND_HALF_EVEN rounded_num int rounded_num rgb_components.append rounded_num return rgb_components[0] rgb_components[1] rgb_components[2]
def canonicalize_emails changelog mapping for alias email_address in mapping.iteritems changelog changelog.replace alias email_address return changelog
def _ordered_count iterable c OrderedDict for elem in iterable c[elem] c.get elem 0 + 1 return c
def bin iterable key lambda x x value lambda x x m defaultdict list for x in iterable m[key x ].append value x return m
def validate_color s if s.lower 'none' return 'None'if is_color_like s return sstmp '#' + s if is_color_like stmp return stmpcolorarg smsg ''if s.find ' ' > 0 stmp ''.join [c for c in s if c.isdigit or c '.' or c ' ' ] vals stmp.split ' ' if len vals ! 3 msg '\nColortuplesmustbelength3'else try colorarg [float val for val in vals]except ValueError msg '\nCouldnotconvertallentriestofloats'if not msg and is_color_like colorarg return colorargraise ValueError '%sdoesnotlooklikeacolorarg%s' % s msg
def tob data enc 'utf8' return data.encode enc if isinstance data unicode else bytes data
@raise_if_offlinedef schema_has_column table_name column_name bind op.get_bind insp sa.engine.reflection.Inspector.from_engine bind if not schema_has_table table_name returnreturn column_name in [column['name'] for column in insp.get_columns table_name ]
def resolve_link stats return stats
def _fix_global_ids html html re.sub 'id "\\d+"' 'id "###"' html global_id 1while len re.findall 'id "###"' html > 0 html re.sub 'id "###"' 'id "%s"' % global_id html count 1 global_id + 1return html
def build_arg_list fn env kw {}argspec inspect.getargspec fn if argspec[2] kw envelse argnames argspec[0][1 ]for name in argnames if name in env kw[name] env[name]return kw
def get_asset_dir_prefix asset_dir_prefix ''if feconf.IS_MINIFIED or not feconf.DEV_MODE cache_slug get_cache_slug asset_dir_prefix '/build/%s' % cache_slug return asset_dir_prefix
def GetReportByName name report_class REGISTRY.GetRegisteredPlugins [name]report_object report_class return report_object
@RegisterWithArgChecks name 'neighbor.attribute_map.get' req_args [neighbors.IP_ADDRESS] opt_args [ROUTE_DISTINGUISHER VRF_RF] def get_neighbor_attribute_map neigh_ip_address route_dist None route_family VRF_RF_IPV4 core CORE_MANAGER.get_core_service peer core.peer_manager.get_by_addr neigh_ip_address at_maps_key const.ATTR_MAPS_LABEL_DEFAULTif route_dist is not None at_maps_key ' '.join [route_dist route_family] at_maps peer.attribute_maps.get at_maps_key if at_maps return at_maps.get const.ATTR_MAPS_ORG_KEY else return []
def getRoundedToThreePlaces number return str round number 3
@task ignore_result True def email_membership_change group_pk user_pk old_status new_status from mozillians.groups.models import Group GroupMembershipgroup Group.objects.get pk group_pk user User.objects.get pk user_pk activate 'en-us' if old_status in [GroupMembership.PENDING GroupMembership.PENDING_TERMS] if new_status GroupMembership.MEMBER subject _ 'AcceptedtoMozilliansgroup"%s"' % group.name template_name 'groups/email/accepted.txt'elif new_status is None subject _ 'NotacceptedtoMozilliansgroup"%s"' % group.name template_name 'groups/email/rejected.txt'else raise ValueError 'BADARGSTOemail_membership_change' else raise ValueError 'BADARGSTOemail_membership_change' context {'group' group 'user' user}template get_template template_name body template.render context send_mail subject body settings.FROM_NOREPLY [user.email] fail_silently False
def site_enabled config enable_site config reload_service 'apache2'
@pytest.mark.parametrize 'constructor attrs expected' [ False {} '<test_utils.Obj>' False {'foo' None} '<test_utils.Objfoo None>' False {'foo' "b'ar" 'baz' 2} '<test_utils.Objbaz 2foo "b\'ar">' True {} 'test_utils.Obj ' True {'foo' None} 'test_utils.Obj foo None ' True {'foo' "te'st" 'bar' 2} 'test_utils.Obj bar 2 foo "te\'st" ' ] def test_get_repr constructor attrs expected assert utils.get_repr Obj constructor **attrs expected
def cmp_version ver1 ver2 return cmp [int v for v in ver1.split '.' ] [int v for v in ver2.split '.' ]
def git_status path cmd git_cmd_base path + ['status' '--porcelain'] return run_subprocess cmd stderr None universal_newlines True [0]
def build_encoder_bi tparams options embedding tensor.tensor3 'embedding' dtype 'float32' embeddingr embedding[ -1 ]x_mask tensor.matrix 'x_mask' dtype 'float32' xr_mask x_mask[ -1 ]proj get_layer options['encoder'] [1] tparams embedding options prefix 'encoder' mask x_mask projr get_layer options['encoder'] [1] tparams embeddingr options prefix 'encoder_r' mask xr_mask ctx tensor.concatenate [proj[0][ -1 ] projr[0][ -1 ]] axis 1 return embedding x_mask ctx
def locate_prefix_by_name ctx name if name ROOT_ENV_NAME return ctx.root_dirfor envs_dir in chain ctx.envs_dirs + os.getcwd prefix join envs_dir name if isdir prefix return prefixraise CondaEnvironmentNotFoundError name
def _parse_qsub_job_id qsub_out return int qsub_out.split [2]
def filter_non_model_columns data model columns [c.name for c in model.__table__.columns]return dict k v for k v in six.iteritems data if k in columns or isinstance getattr model k None associationproxy.AssociationProxy
def publish_string source source_path None destination_path None reader None reader_name 'standalone' parser None parser_name 'restructuredtext' writer None writer_name 'pseudoxml' settings None settings_spec None settings_overrides None config_section None enable_exit_status False output pub publish_programmatically source_class io.StringInput source source source_path source_path destination_class io.StringOutput destination None destination_path destination_path reader reader reader_name reader_name parser parser parser_name parser_name writer writer writer_name writer_name settings settings settings_spec settings_spec settings_overrides settings_overrides config_section config_section enable_exit_status enable_exit_status return output
def alignment_summary alignment index '' answer []alignment_len alignment.get_alignment_length rec_count len alignment for i in range min 5 alignment_len answer.append index + col_summary alignment[ i] + 'alignmentcolumn%i' % i if alignment_len > 5 i alignment_len - 1 answer.append index + col_summary '|' * rec_count + '...' answer.append index + col_summary alignment[ i] + 'alignmentcolumn%i' % i return '\n'.join answer
def _check_module_dependencies is_imbalanced_dataset_installing False for module_name module_metadata in REQUIRED_MODULE_METADATA if not is_imbalanced_dataset_installing and not module_metadata['required_at_installation'] _import_module_with_version_check module_name module_name minimum_version module_metadata['min_version'] install_info module_metadata.get 'install_info'
def create_mpl_fig fig None figsize None if fig is None plt _import_mpl fig plt.figure figsize figsize return fig
def stash_conf_values conf {'bind_host' CONF.bind_host 'bind_port' CONF.bind_port 'tcp_keepidle' CONF.cert_file 'backlog' CONF.backlog 'key_file' CONF.key_file 'cert_file' CONF.cert_file}return conf
def _strxfrm s return s
@celery_app.task base ArchiverTask ignore_result False @logged 'make_copy_request' def make_copy_request job_pk url data create_app_context job ArchiveJob.load job_pk src dst user job.info provider data['source']['provider']logger.info 'Sendingcopyrequestforaddon {0}onnode {1}'.format provider dst._id res requests.post url data json.dumps data if res.status_code not in http.OK http.CREATED http.ACCEPTED raise HTTPError res.status_code
def name_validator value context if not isinstance value basestring raise Invalid _ 'Namesmustbestrings' if value in ['new' 'edit' 'search'] raise Invalid _ 'Thatnamecannotbeused' if len value < 2 raise Invalid _ 'Mustbeatleast%scharacterslong' % 2 if len value > PACKAGE_NAME_MAX_LENGTH raise Invalid _ 'Namemustbeamaximumof%icharacterslong' % PACKAGE_NAME_MAX_LENGTH if not name_match.match value raise Invalid _ 'Mustbepurelylowercasealphanumeric ascii charactersandthesesymbols -_' return value
def _estimate_rank_meeg_cov data info scalings tol 'auto' return_singular False picks_list _picks_by_type info scalings _handle_default 'scalings_cov_rank' scalings _apply_scaling_cov data picks_list scalings if data.shape[1] < data.shape[0] ValueError "You'vegotfewersamplesthanchannels yourrankestimatemightbeinaccurate." out estimate_rank data tol tol norm False return_singular return_singular rank out[0] if isinstance out tuple else out ch_type '+'.join list zip *picks_list [0] logger.info 'estimatedrank %s %d' % ch_type rank _undo_scaling_cov data picks_list scalings return out
def delete_vpc_peering_connection name conn_id None conn_name None region None key None keyid None profile None log.debug 'CalledstatetodeleteVPCpeeringconnection' ret {'name' name 'result' True 'changes' {} 'comment' 'BotoVPCpeeringstate'}if conn_name vpc_ids __salt__['boto_vpc.describe_vpc_peering_connection'] conn_name region region key key keyid keyid profile profile .get 'VPC-Peerings' [] else vpc_ids [conn_id]if not vpc_ids ret['comment'] 'NoVPCconnectionfound nothingtobedone.'return retif __opts__['test'] if vpc_ids ret['comment'] 'VPCpeeringconnectionwouldbedeleted'return retlog.debug 'CalledmoduletodeleteVPCpeeringconnection' result __salt__['boto_vpc.delete_vpc_peering_connection'] conn_id conn_id conn_name conn_name region region key key keyid keyid profile profile if 'error' in result ret['comment'] 'FailedtodeleteVPCpeering {0}'.format result['error'] ret['result'] Falsereturn retret['changes'].update {'old' '' 'new' result['msg']} return ret
def _type_check arg msg if arg is None return type None if isinstance arg basestring arg _ForwardRef arg if isinstance arg _TypingBase and type arg .__name__ u'_ClassVar' or not isinstance arg type _TypingBase and not callable arg raise TypeError msg + u'Got%.100r.' % arg if type arg .__name__ in u'_Union' u'_Optional' and not getattr arg u'__origin__' None or isinstance arg TypingMeta and _gorg arg in Generic _Protocol raise TypeError u'Plain%sisnotvalidastypeargument' % arg return arg
def relpath_to_site lang target_lang path _SITES_RELPATH_DB.get lang target_lang None if path is None siteurl _SITE_DB.get lang _MAIN_SITEURL target_siteurl _SITE_DB.get target_lang _MAIN_SITEURL path posixpath.relpath get_site_path target_siteurl get_site_path siteurl _SITES_RELPATH_DB[ lang target_lang ] pathreturn path
def get_bucket conn bucket_id bucket conn.get_bucket bucket_id if not bucket msg _ 'CouldnotfindbucketwithID% bucket_id s' % locals LOG.debug msg raise exception.NotFound msg return bucket
def entails expr formula_set {} formula_set list formula_set formula_set.append Not expr return not satisfiable And *formula_set
def create_gzip_cache pelican for dirpath _ filenames in os.walk pelican.settings['OUTPUT_PATH'] for name in filenames if should_compress name filepath os.path.join dirpath name create_gzip_file filepath should_overwrite pelican.settings
def test_gnb_pfit_wrong_nb_features clf GaussianNB clf.fit X y assert_raises ValueError clf.partial_fit np.hstack X X y
def url_decode s charset 'utf-8' decode_keys False include_empty True errors 'replace' separator '&' cls None if cls is None cls MultiDictreturn cls _url_decode_impl str s .split separator charset decode_keys include_empty errors
def comment return s3_rest_controller
def data_to_tfrecord images labels filename print 'Convertingdatainto%s...' % filename cwd os.getcwd writer tf.python_io.TFRecordWriter filename for index img in enumerate images img_raw img.tobytes label int labels[index] example tf.train.Example features tf.train.Features feature {'label' tf.train.Feature int64_list tf.train.Int64List value [label] 'img_raw' tf.train.Feature bytes_list tf.train.BytesList value [img_raw] } writer.write example.SerializeToString writer.close
def pearson_score list1 list2 size len list1 sum1 sum list1 sum2 sum list2 sum_sq1 sum [pow l 2 for l in list1] sum_sq2 sum [pow l 2 for l in list2] prod_sum sum [ list1[i] * list2[i] for i in range size ] num prod_sum - sum1 * sum2 / float size den sqrt sum_sq1 - pow sum1 2.0 / size * sum_sq2 - pow sum2 2.0 / size return num / den
def detect stream try json.loads stream return Trueexcept ValueError return False
def is_inside_except node current nodewhile current and not isinstance current.parent astroid.ExceptHandler current current.parentreturn current and current is current.parent.name
def libvlc_media_list_player_get_state p_mlp f _Cfunctions.get 'libvlc_media_list_player_get_state' None or _Cfunction 'libvlc_media_list_player_get_state' 1 None State MediaListPlayer return f p_mlp
def fixed_ip_get_by_host context host return IMPL.fixed_ip_get_by_host context host
def download_cover log title None authors None identifiers {} timeout 30 rq Queue abort Event run_download log rq abort title title authors authors identifiers identifiers timeout timeout get_best_cover True results []while True try results.append rq.get_nowait except Empty breakcp msprefs[u'cover_priorities']def keygen result plugin width height fmt data resultreturn cp.get plugin.name 1 1 / width * height results.sort key keygen return results[0] if results else None
def interface_is_portchannel interface module intf_type get_interface_type interface if intf_type 'ethernet' command 'showinterface' + interface body execute_show_command command module try interface_table body[0]['TABLE_interface']['ROW_interface']except KeyError AttributeError IndexError interface_table Noneif interface_table state interface_table.get 'eth_bundle' if state return Trueelse return Falsereturn False
def wc_reducer word counts yield word sum counts
def process_validation validation is_compatibility False file_hash None validation fix_addons_linter_output validation if is_compatibility mangle_compatibility_messages validation validation.setdefault 'ending_tier' 0 if not validation['ending_tier'] and validation['messages'] validation['ending_tier'] max msg.get 'tier' -1 for msg in validation['messages'] if file_hash ValidationComparator validation .annotate_results file_hash limit_validation_results validation htmlify_validation validation return validation
def _installHandlerUsingSetWakeup fd if fd -1 signal.signal signal.SIGCHLD signal.SIG_DFL else signal.signal signal.SIGCHLD _Handler None siginterrupt signal.SIGCHLD False return set_wakeup_fd fd
def filter_labels train label classes None if isinstance train theano.tensor.sharedvar.SharedVariable train train.get_value borrow True if isinstance label theano.tensor.sharedvar.SharedVariable label label.get_value borrow True if not isinstance train numpy.ndarray or scipy.sparse.issparse train raise TypeError 'trainmustbeanumpyarray ascipysparsematrix oratheanosharedarray' if classes is not None label label[ classes]if scipy.sparse.issparse train idx label.sum axis 1 .nonzero [0]return train[idx] label[idx] condition label.any axis 1 return tuple var.compress condition axis 0 for var in train label
def find_dest_path_comp_key files src_path None src files['src']dest files['dest']src_type src['type']dest_type dest['type']if src_path is None src_path src['path']sep_table {'s3' '/' 'local' os.sep}if files['dir_op'] rel_path src_path[len src['path'] ]else rel_path src_path.split sep_table[src_type] [ -1 ]compare_key rel_path.replace sep_table[src_type] '/' if files['use_src_name'] dest_path dest['path']dest_path + rel_path.replace sep_table[src_type] sep_table[dest_type] else dest_path dest['path']return dest_path compare_key
def get_config ini_path os.path.join THIS_DIRECTORY 'version.ini' if not os.path.exists ini_path ini_path os.path.join THIS_DIRECTORY '../../../version.ini' if not os.path.exists ini_path raise RuntimeError "Couldn'tfindversion.ini" config ConfigParser.SafeConfigParser config.read ini_path return config
def norm_constraint tensor_var max_norm norm_axes None epsilon 1e-07 ndim tensor_var.ndimif norm_axes is not None sum_over tuple norm_axes elif ndim 2 sum_over 0 elif ndim in [3 4 5] sum_over tuple range 1 ndim else raise ValueError 'Unsupportedtensordimensionality{}.Mustspecify`norm_axes`'.format ndim dtype np.dtype theano.config.floatX .typenorms T.sqrt T.sum T.sqr tensor_var axis sum_over keepdims True target_norms T.clip norms 0 dtype max_norm constrained_output tensor_var * target_norms / dtype epsilon + norms return constrained_output
def test_wheel_compiles_pyc script data script.pip 'install' '--compile' 'simple.dist 0.1' '--no-index' '--find-links ' + data.find_links exists [os.path.exists script.site_packages_path / 'simpledist/__init__.pyc' ]exists + glob.glob script.site_packages_path / 'simpledist/__pycache__/__init__*.pyc' assert any exists
def coverage fn fp TraceFuncCoverage fn def new_fn *args **kw return fp *args **kw new_fn.__doc__ fn.__doc__new_fn.__name__ fn.__name__new_fn.__dict__ fn.__dict__new_fn.__module__ fn.__module__return new_fn
def SetupSharedModules module_dict output_dict {}for module_name module in module_dict.iteritems if module is None continueif IsEncodingsModule module_name output_dict[module_name] modulecontinueshared_prefix ModuleNameHasPrefix module_name SHARED_MODULE_PREFIXES banned_prefix ModuleNameHasPrefix module_name NOT_SHARED_MODULE_PREFIXES if shared_prefix and not banned_prefix output_dict[module_name] modulereturn output_dict
def test_ada_fit_invalid_ratio ratio 1.0 / 10000.0 ada ADASYN ratio ratio random_state RND_SEED assert_raises RuntimeError ada.fit X Y